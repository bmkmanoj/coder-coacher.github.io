<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Big Data Analytics Interactive and Real-Time | Coder Coacher - Coaching Coders</title><meta content="Making Big Data Analytics Interactive and Real-Time - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making Big Data Analytics Interactive and Real-Time</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UelLOvXdOJs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
record it all right so pleased to see a
big crowd and here to welcome matei from
berkeley so Mateo of course is a
candidate is interviewing with the
number of different groups here today
and tomorrow Microsoft matei is well
known for his work in sort of big data
or a cloud computing or cluster
computing depending on how you look at
it no we're building systems you know
ranging from me so Stu spark and systems
which have actually achieved already
achieved a significant adoption industry
which is unusual for many graduate
students mckays also had a lot of
success on the academic side you know
last year he was fortunate to win two
different best paper awards sing common
and SDI in his interests are
wide-ranging you know in addition to the
sort of big data cloud computing area
for example he's also worked with folks
here at Microsoft and things like gene
sequencing made some significant
advances there so let's welcome matang
before do good talk all right well
thanks thanks for the introduction rich
yeah so I'm going to talk today about
big data analytics and basically
bringing that the new types of
applications that need to process data
faster than before and so you know I'll
feel free to ask questions and stuff
throughout the talk so I think I don't
need to talk really about the big data
problem at Microsoft everyone here is
probably very familiar with it but
basically the problem is in a lot of
domains not just web applications but
also things now like scientific
instruments or gene sequencing or things
like that data is going faster than then
computation speeds and basically what we
have are these data sources that keep
reducing it you know either you have
many more users using your application
on mobile devices on the web or you have
scientific instruments like gene
sequencing
instruments or telescopes that are
speeding up faster than Moore's Law and
you have cheap storage so you don't ever
throw away the data you just buy more
disks and store it but you have stalling
clock rates and it's getting harder and
harder to work with it so as a result
people are now running on a very
different type of infrastructure they're
running applications on these very large
clusters and that that's kind of the
only way to actually deal with this data
and because of that people are also
adopting a new class of systems to work
with with these clusters so just as an
example hadoop mapreduce the open-source
implementation of MapReduce you know
started out at a bunch of web companies
but it's now used at places like Visa
and bank of america and a whole bunch of
places in more traditional enterprises
and it's a going market its projected to
reach 1 billion dollars by 2016 so for
people you know doing research in
systems this is this space is both
exciting and challenging so first of all
it's exciting because these large
clusters are a new kind of hardware
platform with new requirements and
basically a whole new software stack is
emerging for them and there's a chance
to actually influence this software
stack often in most areas of systems may
be less so at a company like Microsoft
but in general in many areas of systems
it's hard to go from you know doing some
research to seeing it actually being out
there and seeing what happens if people
try to use it how it actually works in
practice but in this space this is a
space where people are adopting new
algorithms new systems even new
programming languages to deal with this
kind of data and so as a researcher
there is a chance like actually get get
your things try it out and see how they
work at the same time though it's also
challenging and this is because apart
from just the large-scale of these
systems which you know has its own
problems the demands on them are going
so in particular users have growing
demands about performance flexibility
and availability by performance I just
mean they want to get answers faster
with you know even though the amount of
data is going or they wanted move say
from a batch computing model to
streaming and close
to heal type by flexibility I just mean
more types of applications that they
want to run in parallel with different
requirements and by availability I mean
basically in Ohio availability so when
you're hunting you know mapreduce every
night to build a web index it's okay if
you miss it one night but when you're
hunting us to do fraud detection in
close to real time and that breaks
you're actually losing money so people
want all these things out of big data
systems so my work has been a software
stack that addresses two of the core
problems in this field and these are
programming models and multi-tenancy so
for for programming models there's been
a lot of work out that batch systems
which are really great for AG making
this data accessible but users also
wanted to support interactive quays
complex applications things like machine
learning algorithms and streaming
computation and these are the
programming models I worked on for
multi-tenancy one of the major problems
that happens when you have these
clusters is you know they're large and
they shared across many users so many of
the problems that happen in a
traditional operating system you know
with multi-tenancy em you know it's kind
of the mainframe type operating system
are happening again here and you need
algorithms to share these clusters
efficiently between users so this is the
stack of systems I worked on basically
at the top the things in blue are
parallel execution engines I'm going to
go into more detail but the spark is the
underlying engine and on top of that we
built a streaming engine spark streaming
and also something called shark which is
which does sequel in the middle Mason
Orchestra are two systems for Israel
saying messages for resources on the
machines like CPU and memory Orchestra
as for sharing the network among
parallel applications and the ones at
the bottom these are a bunch of
scheduling algorithms I worked on that
tackled different problems that happen
in these data centers like fairness for
multiple resource types or data locality
or stragglers and these are both about
determining the right policy and also
coming up with efficient algorithms to
deal with the
things so the work at the top and this
is the first problem of programming
models the work at the bottom is about
multi-tenancy in this stock I'm going to
focus mostly on the top part but then
I'm going to also come back at the end
and talk a little about one problem here
because I think there are some cool
problems with with algorithms and
policies as well okay so let me just
start with some some really basic
background and as I think you people you
probably mostly notice but basically
when you're running in these large data
centers there are really two things that
make it hard and that are different from
your previous parallel environments
people have considered and these are
failures and stragglers so the problem
with failures is that anything you know
that can go home you know fairly early
on a single machine will start happening
a lot more often on a thousand machines
or 10,000 so if you have a server for
example at the mean time between
failures you know on a typical server
might be three years and you put a
thousand of those now you're mean time
between failures as a day and if you put
your 10,000 it something's going to fail
every couple of hours so that's that's
one problem stragglers are actually even
more common thing which is a machine
hasn't just outright failed but for some
reason it's slow maybe there's a
component that's that's dying but it's
not actually filled yet like a disk on
it and that's reading really slowly
maybe there's contention with other
processes maybe there's a bug in in the
operating system or the application and
the problem is you're doing this
parallel computation on a thousand notes
but if one of them is slow and everyone
waits for that you know you're losing
all the benefits of that so Google's
MapReduce was one of the first systems
to handle this automatically and the
thing that was interesting about
MapReduce was not really the programming
model but just the fact that it did
these things automatically and basically
you know if you haven't seen at the
point of MapReduce is just that these
two phases of map and reduce tasks you
eat from a replicated filesystem and you
build up this graph of processes that
that talk to each other and if any of
them goes away the system knows how to
launch a new copy of that and splice it
into the graph or if one of them
though it can launch second copy and
splice it in so MapReduce was really
great for for batch computations but
it's only this one pass batch computing
model and what we found in you know
talking to users is that users who put
their data into entities very quickly
needed to do more and in particular user
is needed to do three things they needed
to learn more complex algorithms that
are multipass things like machine
learning or graph computation that go
over the data multiple times they needed
to do more interactive ways so it's
great that you can you know sort of call
the web and and build an index in a few
hours every night but now if I have a
new question can you answer that
question in two seconds or do I have to
wait two hours again to build something
and they also wanted to do real time
stream processing so you know you build
say spam detection classify and you
train that every night now can you train
it you know in real time as new spam
messages come up to move that
application into into something you can
run in real time okay so what are the
action to these needs is that people
build specialized models for some of
these applications so for example
Google's bagels a model for graph
processing there have been a bunch of
iterative MapReduce is there's a system
from Twitter called storm that's very
popular for streaming but there are two
problems with this first of all these
specialized systems only come up you
know one use case at a time so if you
have a use case that it has it's still a
complex application but maybe it's not
graph processing the systems out there
might not be good for it and the second
one is that even if you have models for
all the things you want to do it's hard
to compose them into a single
application and in in in sort of the
real world many users want to start by
you know say start by doing a sequel
like way you build something that's a
graph now you run a graph algorithm and
the result you know now you had a
MapReduce or so a machine learning
algorithm and the result of that and
with separate systems it becomes hard so
our observation behind all this work is
that the
complex streaming and interactive apps
actually all have a common need and
there's one thing they need that map is
your slacks and that thing is efficient
primitives for data sharing so these are
all applications that actually perform
data sharing between different parallel
steps and that's that's the thing that
that would make them work better so I'll
just show a couple of examples this one
here is a iterative algorithm and this
is a common pattern in many algorithms
you can take that that's actually my my
coach yeah okay yeah so this is okay so
yes so this is a common thing for
example if you imagine something like
page rank page rank is basically a
sequence of MapReduce jobs and if you
hunt this on something like just googles
MapReduce or Hadoop the problem is that
between each job you're storing your
state in in the distributed file system
and just reading and writing to the file
system is slow because of data
replication across the network and also
because of this guy own so it just makes
it slow another case is interactive
quays so interactive ways you often
select some subset of the input that
you're going to ask a bunch of questions
about and so all these quays share
common data source and I'm going to come
back to streaming later but streaming
also involves a lot of stationing as
well because you maintain state across
time in the computation so these things
if you just turn them with you know
MapReduce and sort of the Google like
stack they're slow because the of the
application and disk i/o that happens in
in the storage system but those two
aspects are also necessary for fault
tolerance so that's that's why the file
system replicates data so constant
hoarsely systems when using replicated
intermediate file for this reason yeah
digestion you can have intermediate
files but that are single applicated but
if you have if you have so for example
in in this case it's it's hard to do
that it because you don't even know
which quiz you're going to ask in the
future so if you have a thing like dryad
where you submit a whole graph at once
you can do it but if it here the
abstraction that you see as a user is
just you know I can make files and then
I can hunt map a juices on them yeah
yeah so you're saying the system doesn't
know if it's a nervous yeah exactly it's
just it's just that there's no yeah
there's no explicit abstraction across
parallel jobs yeah for data sharing
yeah but what I'll talk about is
definitely you know based on what people
do when they do know the future graph
yeah okay so so our goal with this was
too can we do this saying at the speed
of memory and the reason to do it is
really simple is because memory is
easily ten to a hundred times faster
than than the network or the disk and
you know if you think about it even if
you have a very fast full bisection kind
of network like say you have 10 gigabit
or 20 gigabit ethernet such as in flat
data center storage that's actually
still about a factor of 20 or 30 slower
than the memory bandwidth in a machine
in a machine you can easily get about
400 gigabytes per second of memory
bandwidth so so we that's why we want to
do this at the speed of memory but the
challenge there is how do we actually
make it fault-tolerant if we just said
that the disk and the network are things
we can't push data over so there have
been a bunch of existing storage systems
that put data and memory but problem is
neither of none of them actually have
this property of doing everything at
memory speed and the reason why is
because they're based on this very
general shared memory abstraction so
basically these systems give you
abstraction of a mutable state that's
sitting out there and that you can do
fine going the operations on like reads
and writes to a cell in a table and the
these include things like databases key
value store is RAM cloud file systems
all these kinds of things that's the
abstraction they provide and these all
require replicating the data or you know
things like update logs about what you
did over the network for fault tolerance
and we just said that replicating it is
is much slower than than the speed of
hiding to memory so the problem we
looked at then to deal with these is can
we provide fault tolerance without doing
application and the we came up with a
solution to this called resilient
distributed data sets or Hardy DS and
basically rd these are a restricted form
of shared memory that makes this
possible so I did these are
restricted in two ways first of all the
immutable once you create them so
they're just partition collections of
Eckerd's you can write them once and
then the immutable and second you can
only build them through coarse-grained
deterministic operations so instead of
building these by reading and writing
cells in a table you do something like
apply a map function to a data set or
apply a filter or do a join and there's
all kinds of operations you can do in
there now what this enables is to do
fault recovery using lineage instead of
application so instead of logging the
data to another machine we're going to
just log the operation we did on it and
then if something fails we're going to
recompute just the last partitions of
the data set so just to give you an
example of what this looks like here's
some operations you might do with with
ID DS so maybe you start with an input
file its spread across you know three
blocks three different machines and
maybe you start by doing a map function
you give a function f that you're going
to apply to every element so now you're
going to build a data set this is an RDD
and basically the circles there are
partitions and whole thing you know is
an RDD as a data set and this is not
going to be replicated there's just one
partition sitting on each machine you
might then do for example a group by so
better the function G and you do another
operation on this data and we might do a
filter where you pass it a function H so
this this is how you've built your data
set you've done these these parallel
operations yeah we do require them to be
deterministic that's a that's an
assumption we're making yeah yeah ok
yeah so that's that's what you get and
now if something goes missing you can
look at this dependency graph to rebuild
things so for example if this guy goes
missing here we can rebuild it by just
applying H to the this partition of the
band data set and if and and we can get
it back and even if multiple chunks go
missing you can go ahead and you know
build them again in a topological order
the other thing is doesn't show by that
actually matters a lot in
practices in practice on each machine
you are going to have many different
data partitions and when a machine fails
you can rebuild the different partitions
in parallel so the recovery process can
often be a lot faster than the initial
process of computing this thing and
that's that's what makes this recover
quickly as well so the next question
with this is how general is it so you
just said we're going to limit shared
memory to these coarse grained
operations and we found out that
actually despite the restrictions are
td's going to express a lot of different
parallel algorithms that people want to
do in practice and this is because just
by nature of data parallel algorithms
the algorithms apply the same operation
too many data items at the same time so
this strategy of logging the one
operation that you're going to do to you
know a billion items instead of logging
the billion you know results makes a lot
of sense in that setting and in fact we
showed that using our ID DS we can
express and unify many of the existing
programming models out there so we can
express the data flow models like
mapreduce andrea that kind of build a
single graph like this but we also found
some of these specialized models people
propose such as bagel or a power graph
from CMU or iterative MapReduce can be
expressed using our DD operations and by
this I don't mean just kind of the
Turing completeness argument of egg will
get the same result but we're also
expressing the same data partitioning
across nodes and controlling you know
what's in memory and what is it so it's
really going to execute in the same way
with the same optimizations and we also
found that we could do new applications
that some of these models couldn't so if
you look at this in kind of a trade-off
space of parallel storage abstractions
this is what it would look like so you
can have this trade-off between the
granularity of updates the system allows
and the write throughput and basically
things like key value stores you know
in-memory databases Ram cloud allow very
fine-grained updates but they're stupid
is limited by network bandwidth because
they replicate the data things like
Google file system actually they're not
really designed for fine grained updates
and despite that people have won a lot
of
algorithms on them you know because of
the data parallel nature of the
algorithms but they're still limited by
by network throughput and r dds are
instead limited by by memory bandwidth
ok yeah one thing that this is not
showing is the cost or the speed of the
coming right let's speed up wake up yeah
if you have to get data then you could
recover instantaneous that is to ya say
so here there'll be a constant you cover
yeah i'll talk a bunch about speed up
recovery later on though yeah things
like working yeah so you don't have to
have IDs in memory if you don't want you
can have them on disc it's still or RN
SSDs or you know on hayde and it will
still save you from sending stuff over
the network so in our system actually
the system is designed to spill
gracefully to disk and to keep doing
sequential operations if you do that
yeah it looks a little confused why it
keeps you from setting things over the
network in other words by keeping things
it seems like you're complaining right
into this yeah versus keeping things in
memory that's one thing versus doing
things local interesting machine versus
present yeah reducing for many machines
so I mean you're limited by the network
not by disputed that is gonna have to
memory yeah yeah yeah it's actually it's
mainly for the network that we're doing
this yeah I mean it seems like that
significantly changes the semantics the
computation you knows you're saying it
can be faster by not writing a
distributed out more than just by
writing it up but but it's not going to
be local so we still have operations
across nodes if you go back to this guy
so so the group buys an operation across
nodes but what I'm saying is just when
you write this like you know if you
created this data set with with a map
reduced for example you would be writing
this to a distributed file system and
then the next job like say you didn't
know you want to do a group by next you
just you save this result you hold it
out to the file system and then later
you come in and do a group by three
show the next slide you showed that you
were not never fanless on the game or
your react that was limited yeah if
you're doing a group buy or something in
your then you are okay yeah that's
that's absolutely right yeah so this is
more about this is after you've got the
data group the way you want when you're
actually doing the right to this storage
system yeah so the applications of
course so yeah this is just you know
after they've computed the reduce
function or whatever they're writing it
out yeah applications can definitely
still be network about if they
communicate yeah fastball action is that
again it the reconstructing failboat it
seems like it's a trend unattended in
their value and what MapReduce does get
better yes as you pointed out also whoa
yeah yeah we redo a copy to know it's
it's it's a similar so basically what we
took is we took that kind of a
construction and put it in a storage
abstraction so that it persists across
across things you across parallel jobs
you do on that rather than being just
inside one job but it's definitely it's
inspired by the same thing yeah and I'll
show i think the cool thing actually is
like how we do this with with streaming
which I'll show later which is yeah so
for jobs that are actually network bound
yeah does this approach only
the lazy me seems like if a job is
network I don't use your real estate
this yeah and eventually get a point
where you're saturating network let's
say yeah it depends on how much
intermediate data you have so if your
network if you don't have a lot of in
the media data you're just doing a big
shuffle then this isn't gonna matter but
we found in a lot of jobs even and
things like page rank that do a
significant amount of shuffling and have
a lot of state this this can help yeah
prior to this correctly where you really
saving on network route for intermediate
state is that by not replicating it even
office of a network because it wants
here and it goes over probably three
times exactly yeah yes exactly and yeah
and also that can be a yeah it can be a
significant fraction of the job earning
time yeah yeah yeah let's 32-bit systems
like to do control the replication at
the end you
oh you said you can definitely control
it but then the problem is if something
fails you yourlust like Hadoop doesn't
keep track of oh I did this map function
before to rebuild it so yeah so what
we're doing is pushing that information
in the storage abstraction yeah we're
going to tell you basically using some
form of a former buggy to rebuild yes
most exact exact right after you make
end up paying more for it but you have
to actually do to be covered yeah yeah
you may yeah you may have yeah although
it actually well it depends on what your
computing but if you compared to the
cost of like having to always replicate
the thing that's a fixed cost so yeah it
depends a lot on your failure
assumptions yeah just part I'm really
good night there's another metric there
which is failure things like mean time
to failure right what feeling what is it
assuming that's how is very frequent and
yeah okay no yes if there are cases
where you want to do application instead
yeah it's waiter and yeah I'll talk I'll
talk a bit about this in streaming also
it's like you can you can still combine
this with application sometimes if you
want one of the cool things is you can
also do the application asynchronously
because now if you didn't do it right
away you know that you have some way out
to a cover so there's different ways ya
okay what are the scenarios are you
cannot recover so some wii it is near
that you can already so we can recover
actually we can lose all the nodes in
our system as long as the input data on
the original file system like the ones I
showed you know the this file here is
still available we can recompute
everything yeah so its design so any
subset of the nodes can fail yeah so I'm
so David is a database guy so this is
logging I'm a programming or a nice guy
and I see this is incremental
computation yeah
there's a lot of all this oh yeah it's
definitely it's definitely it's inspired
by lots of systems have done this kind
of logging I think the thing I mean
honestly the thing that's interesting
about this is the applications we
applied it to say you know when Google
wrote the peggle paper is a whole paper
and it says they actually don't even
have this kind of fine-grained recovery
they just take checkpoints and then they
say we're working on a thing where we
think we could do fine grained recovery
and peggle we implemented bagel with
fine-grained recovery in 200 lines of
code so it's just it's yeah the fault
the others follow on is what you have
incremental complication then you can
use it for lots of other but that's
stupid thats true yeah so you can change
part of the data and yeah yeah yeah we
actually haven't done that in our system
by it's an interesting things that try
to do next is definitely yeah yeah
I'm sorry databases there lots lots of
things they can do it yeah okay you
should never tell database people they
can't do something that's been a lesson
I've learned without you respected yeah
okay okay so that's that's kind of the
abstraction let me also tell you a
little bit about the system and then
I'll go to like to some of the things we
did we did next with it so we built the
system called spark that implements this
and I just wanted to show a little of
how it works basically so spark exposes
our dd's to this nice and simple
interface in the scholar language which
is kind of Java with functional
programming go as bill describes it it's
kind of like C sharp so that so then is
it's like C sharp with stranger syntax
and we didn't by the way I'm not saying
we invented this model so models very
much inspired by the API of diet link
but it lets you write applications in a
very concise way and one of the cool
things we did that I think is unique to
our system is we also allow you to use
it interactively from the scholar shell
and it makes for like you know it makes
it very easy to explore data so this is
you know kind of some of the syntax of
it basically you create your your data
set you apply transformations like
filter and this funny-looking stuff in
head here is scholar syntax for function
literal or closure so it's like lambda X
X that starts with air and then you can
keep doing you know operations on it and
keep building a lineage graph and
computing things so I wanted to show you
this on an actual hunting system just so
you can see the kind of things it does
so basically in this I've set up a spark
cluster on amazon ec2 let's check that
everything's still there it is okay and
I have 20 nodes and I have a Wikipedia
data said I loaded on this it's like
just a plain text dump of all of
Wikipedia that 60 gigabytes so it's not
huge but it's a thing that would take a
while to actually
look look on look at on a single machine
and I'm just going to show you how you
can use this interactively to do things
so this is the spark shell you can do
your standard scholar stuff in there and
you have the special variable SC or
spark context we move this up a little
bit that lets you access the cluster
functionality so first thing I'm going
to do is represent the text file i have
sitting in the Hadoop file system and
this is going to give us back an idd of
strings so it's a distributed collection
of strings and so we can actually start
looking at it even without doing stuff
in Palo so there's a few operations you
can do that will just speak at the
beginning of the file so if i do filed
at first that gives me the first string
and you can see what the format is like
so this is a tab separated file you have
article ID you have the title this and
yet and yet is the first thing maybe
alphabetically in in this wikipedia you
have date modified you have an xml
version and you don't see the last field
but there's a plain text field at the
end as well so what you can do is you
can take this and convert it and into a
form that's easier to work with so for
example i'm going to define a class to
represent articles and i'm going to just
pull out the title and the text from it
and now i'm going to do some map
functions to turn these lines of text
into article objects so first i'm going
to take you try and split it by tabs and
that syntax again is the same as doing
this so it's it's like a lambda syntax
basically it's the shorthand form and
then i'm going to filter so some of
these things actually don't have the
last field the plain text because
they're things like images so i'm going
to just filter out the ones with exactly
five fields and i'm going to map I have
this array of fields
new article and I'll take F 0 or so f 1
is the title and f4 so you can see that
but it exists somewhere up there okay so
so now you know I have this article
object so all these things happen lazily
it doesn't actually compute it until it
needs to but I can do stuff like this to
see articles you know first article is
still and yet and yet so the last thing
I'm going to do is tell it that I want
articles to persist in memory across the
cluster you can choose which data sits
in memory which ones just computed their
family as you go along so I'll market
deadly so so now I'm going to do a
question on the whole data set and i'm
going to count for example oops how many
of these contain berkeley and so I
actually this needs to be that text
contains both the plain text of the
article and so now it's actually
submitting these these tests to the
cluster and it's going to go and on on
HDFS so is scheduling the test according
to where the data is place and doing it
stuff and you know it goes along and
basically so all the you know the class
article i typed in the functions i typed
in get shipped to the worker nodes and
and they got to run over there and this
is kind of the straggler problem but
hopefully hopefully it'll finish yea
there you go so that is its life it's
happening on amazon i'm sure the
Microsoft cloud never has stragglers so
yeah okay so so yeah so we scanned this
thing and there were fifteen thousand
articles but it took 27 seconds not
exactly interactive so let's try to do
it again now and now the data will be in
memory because we called persist so if
we do it again we get back the same
thing in you know in point six seconds
and we can ask other questions now so
for example the one isla like to ask is
Stanford so Berkeley was 15,000 and
let's try
let's try this one and this is only
13,000 there you go okay and so now I
hope no one's farm Stanford oh yeah so
last thing I want to show this is sort
of the risky part of the demo so we have
20 nodes in this cluster so let's try to
get rid of one of them so these are the
ones i'm just going to pick a random one
and see a weird Firefox menu and just
kill it so there you go so it takes a
little bit of time to shut down but once
we look at it here eventually it will it
will drop out yeah so you can see now
the only 19 so and you can see this guy
was also notified that it's lost and it
says we lost we lost this out so let's
try to do this again and see whether we
get the same answer and now at the end
you know that if you yeah so you can see
at the end well it went kind of quickly
but there are fewer there like the last
30 tasks or whatever that were on that
node will last and those were he built
across the cluster so this is what I'm
saying you can recover pretty quickly
even if a couple of failures happen
because you do this in parallel so
that's that's kind of it and of course
now that it's now it's actually in
memory again so if we do this again you
know it's back to its usual self so
that's that's kind of what the system
looks like and what it lets you do it
okay so let me see so apart from doing
kind of searching of Wikipedia this is
also good for things like machine
learning algorithms so we took a couple
of very simple algorithms but that that
that that we ran on this and basically
these iterative algorithms are hunting a
bunch of MapReduce is on the same data
and if you share that data using our
dd's you can go a lot faster so
depending on how much computing it does
k means there's a bit more computing
that was 30 times faster and this is
about a hundred times faster and other
people have built in memory engines for
these algorithms piccolo is one but most
of the engines out there don't either
don't provide fault tolerance or do it
using checkpointing which you have to
periodically save your state out and
that that cost something
so we get similar speed ups to what they
got but we have this fine grain fault
tolerance model as well it's all swear
you have fellows during the run I'm not
be using to see how that would actually
be cool yeah so actually well I mean we
did in our paper we have some results
with failures and the same thing happens
like the adoration wear something fails
takes longer to recover but I don't have
them on the slide here yeah yeah so
there's a distance between this slide
and part of the motivation for your talk
when you're giving the motivation who
are saying that computation speed and
Moore's law just can't it is slowing if
cpu speeds are slowing down and can't
keep up that data and what this slide
would seem to say is that the CPU speeds
are just fine it's the communication in
the algorithm that's true so yeah I
guess what I meant to say there's the
capabilities of a single machine yeah
but yeah it's too many of these things
are not cpu-bound they are actually the
thing that is really causing clusters to
become bigger is actually disk bandwidth
disk bandwidth hasn't gotten very fast
and so you can buy these dis they're
huge you know but it takes like you know
to read a terabyte off a disk and it
will take you know many hours so you
need to put you know thousands of this
can parallel that's actually the thing
that I think really causes this yeah
okay well so that's yeah that's kind of
the system and one other thing I want to
say is we you know as I said at the
beginning we wanted to show this this is
pretty general and so we implemented a
bunch of these other models on it as
well that people have proposed we have
these iterative ones that that we
implemented GraphLab if you're familiar
with that we can only do the synchronous
version because that's versions
deterministic and another cool thing we
implemented it actually appears that
this year's sigmod is a sequel engine
called shark and the story there is you
know at least in the database community
though was this kind of debate between
databases and MapReduce people thought
that ok well MapReduce adds fault
tolerance during Quay execution most
parallel databases don't have that but
the cost of the fault tolerance is so
high that it's not worth it so shark
actually gets similar speed ups over
Hadoop that the parallel databases do so
it can run these quays you know 10 100
times faster and it simultaneously has
the fault tolerance that that you saw
before and the thing about this also is
it's not just a matter of saying you
know I think is more general it also
means applications can now intermix
these models so for example one of the
things we're doing and shark is letting
you call into machine learning
algorithms that are hidden in spark and
you know data never has to be hidden to
some intermediate file system in between
it just runs in the same engine and
final thing we've been lucky and doing
this to also have going community of
actual users so we we open sourced spark
in 2010 and in the past few days we've
really seen a lot of growth and who's
doing things with that so just some
quick stats on that we held the training
camp on spark in August and 3,000 people
watched online like to learn how to use
it online we have a meet up in person
meet up in the Bay Area and we have over
500 members that that come there and we
have in the past year 14 companies have
contributed code to spark the some of
the companies
universities that have done things with
it at the bottom so you can find more
about that on the website yeah I did
actually yeah I've shown the demo to
some central people in the past so yeah
okay so yeah I'm okay so so that that
was kind of the spark part i also want
to talk a little bit so that covered the
interactive ways and iterative
algorithms i also want to talk about
streaming and this is kind of a system z
bit that that we did next i think we're
actually still working on a bit now okay
so the question here was just how do we
perform fault tolerant streaming
computation at scale and the motivation
for this is that a lot of big data
applications we have today receive data
in real time and see sort of real value
from acting on it quickly so things like
fire detection spam filtering even
understanding statistics about what's
happening on a website you know after
you make a change to it or you launch an
ad campaign and for example Twitter and
Google have hundreds of nodes that are
doing streaming computations in various
ways to try to deal with this data so
our goal was to look for applications
with latency needs between half a second
to two seconds so we're not looking at
like millisecond you know quantitative
trading stuff but we think this is still
pretty good but be able to hunt them on
hundreds of notes the problem though is
that stream processing at scale is
pretty hard it's harder than batch
processing because these issues of
failures and stragglers can really
really break the application so the
fault recovery fast fault recovery was
kind of a nice thing to have in the
interactive case but here if you don't
do it quickly you might just fall behind
and you've suddenly lost the whole point
of doing real time computation same
thing with stragglers if a node go
slowly you know headed and you know
making a joke about it in the talk here
now you know seven seconds behind where
you are supposed to be in the stream so
there's been a lot of work on streaming
systems but traditional streaming system
designs don't deal well with these
problems so traditional streaming
systems
because we're calling a continuous
processing model and it's a very natural
one but it becomes streaky to scale so
in this model you have a bunch of nodes
in a graph and each note has a
long-lived mutable state and for each
record you update your state and you
push out new records to the other notes
so state by the way is is the main thing
that makes the streaming tricky because
so example of state is you want the
count clicks by a URL that a person
clicked so you have this big table you
know maybe you partition it across nodes
and everyone keeps track of counts for a
slice of the URLs and you know this is
how these systems are set up so when you
have this model and you want to add
fault tolerance there's two ways that
people have explored replication and
upstream backup so the most common one
that's done in special basically most of
the parallel database work and systems
like borealis and flux is replication in
application you send a copy of the input
to you know you send the inputs the two
copies of the processing graph and each
copy does the message passing and state
updating in parallel there's also a
subtle thing an application though which
is that you need to synchronize the
copies and that's due to non determinism
in message order across the network so
for example in this one imagine node 1
and node 2 are both sending a message to
note 3 now at roughly the same time now
which of those gets there first will
depend on what happens on the network
but note C state might be different if
it got this one before that one so the
copy here of note C needs to know that
and so these protocols borealis and flux
do a lot of fairly complicated stuff to
actually keep these in sync and keep
them in sync even if a node fails and
another one comes back and stuff like
that but even discounting the cost of
that you know basically this this model
gives you fast recovery from faults
instantaneous but you pay at least 2x
the hardware costs okay the upstream
backup model is another one that's been
proposed in that one you don't have
extra copies instead nodes you know
checkpoint
periodically and they buffer messages
they send since the checkpoint and if a
node fails you have to bring up another
copy of it and splice it into the graph
and this model has less hardware costs
but it's also slower to recover in
particular at high load the new node
needs to not just the cover from a
checkpoint but also keep up with
deriving stream so it can take pretty
long time to actually catch up with the
rest of the system and a bigger problem
is that neither of these approaches
handle stragglers very well so in the
application approach because of the need
to keep the replicas in sync if one of
the nodes is slow you he'll end up
slowing both replicas and in the
upstream backup about you don't really
have a anything you could do except
maybe treat the slow node as a failure
and then it's expensive to recover so we
wanted to design a streaming system that
met a set of you know fairly ambitious
goals to actually be able to do this at
scale so we wanted to have a system that
can scale to hundreds of nodes and has
minimal costs beyond just the basic
processing so no 2x application or
anything like that we wanted to tolerate
both crashes and stragglers and we
wanted to be able to attain sub-second
latency and subsequent fault recovery
okay so the way we did this is by
starting with the observation about the
batch processing models like map pages
and spark so these models actually
managed to provide fault tolerance of in
a very efficient way now without
replicating a lot of stuff because of
this deterministic recomputation that we
saw so they divide the work into small
deterministic tasks and then if a node
fails they up de vere on those in
parallel on others so our idea was can
we just run streaming computations as a
series of very short but deterministic
you know bash like jobs and then we
could apply the same recovery models but
at a smaller time skill so you know I
tasks instead of being several seconds
in length might be like several hundred
milliseconds and so it kind of becomes
this like system optimization
like just making a system that does that
quickly and destroy the state between
time steps we're going to use our d DS
which are you know we came up with this
way to store state in memory so we call
that's that's what we ended up doing and
we call this model discretized stream
processing and basically the idea of the
model is will divide time into small
steps and the data that arrives in each
step is put into a data set and it's in
it basically it's an immutable data set
and this the input data we have to store
reliably because if we lose that you
know we can't we can't go back and
compute stuff so this this will be
replicated but you probably want to
store that data anyway after that you do
a batch operations deterministic and you
produce new data sets and this can
either be output or they can be state
that you're going to use on your next
time step and these are stored in memory
on replicated as an idd and you know we
can reconstruct them with with lineage
and on the next time step you take your
new data you know you take your old
state and you do again a small you know
map pages like computation and yeah
today like this state either become if
you use this thing have to reconstruct
it yeah you really mean anything because
you're
you're either going to have to go back
suppose it's of what we window oh yeah
they're going to have to construct it
from a law bit of a week's worth of
activity oh yeah I'll have had to have
squirreled it away somewhere so that you
can reload it ya know so yeah the way
you do it is you do periodic
checkpointing but the key is you don't
need to check point everything like for
example you say you're doing this every
second and then every 10 seconds you
store that data set reliably just like
asynchronously write it out to another
copy so that's what we're going to do
okay yeah the target is a lineage that
one of the strategies that you talked
about earlier uh yeah it is but but the
difference yeah I mean you the
difference is you you don't you don't
hold back the whole application when it
fails so check pointing and his parallel
computing systems usually means if a
node fails I just kill everything and
they can't recover and I go back to the
previous checkpoint here i Justi compute
the last stuff and that can be
significantly faster so some of us like
you're applying the technique from the
street e sitting in advance in order to
found a batch to have to roll back the
bash okay yeah I'm sorry I understood
well yeah I thought you were doing
something different and screaming
recover your appliance training recovery
to about sitting in order to improve
recovery I know she you mean I'm
applying the battery cover to a
streaming setting going oh right okay
dude we're not doing you mean the
application way yeah what would
basically yeah a check points a
truncated how far back in the log you
need yeah absolutely yeah but I
checkpoint is different from what I
showed as application because
checkpointing just means so the
replication approach had to keep the
state and sync had to do this
synchronization protocol checkpointing
just means I have a copy in memory I'm
going to also send it to another guy and
you know maybe I'm also going to hide it
to disk so it's an asynchronous thing
and doesn't require them to be in any
way you know oh yeah quick question it
but it's a trying to figure out what the
size of this data set is going to be for
iteration so could you do something the
point I'm trying to get to say that
cause I afraid of distributed battle ISM
if the data per iteration is small in
most cases and deal with the way
Elizabeth pro-life may not get 100 SSDs
on a 10 oh yeah yes so if the stream
fits on a single machine you could do it
we're we're specifically targeting
things that need to earn a higher
degrees of parallelism and there's two
reasons why like either the stream might
be big for example you're collecting log
so I'm you know all the machines in your
data center and each one's logging you
know many whatever kilobytes per second
or something or or the computation might
be big so one of the applications we did
was an online machine learning algorithm
it's very CPU heavy and it needs to hunt
unlike many nodes to actually do he'll
data yeah so that's what we're targeting
yeah what is the computations for
series of time scales yeah starting with
t 12 yeah so so we have yeah we have we
don't have so I don't have slides on
this but we do have operators that do
that and basically an operator can go
back and take data from farther back
time steps it's not just the previous
one yeah and we do incremental sliding
windows like where you add current data
and subtract stuff from you know 10
seconds ago so we do stuff like that we
implement it basically a lot of the
optimizations people did for stream
processing and databases you can express
them this way because all you're doing
is doing the same thing but in these
little batches right like it's an
algorithmic optimization you can still
use yeah okay so that's it yeah thanks
good questions about the model yeah so
so basically I talked about this already
so the way we do fault recovery is we
have to do this checkpoint periodically
but it's asynchronous it just means you
know everyone has to like write their
stuff out you know to another node and
you also don't need to do it too often
because recovery is parallel and we have
the same story as before something goes
away now other nodes can work in
parallel to rebuild that and so if you
look at it compared to previous recovery
approaches we have faster recovery then
upstream backup but without that 2x cost
of application so that's you know that's
kind of the model so the question is you
know we did this we broke this thing
into these little batch jobs how fast
can we actually make it go and we found
that compared to two other systems out
there it can actually go pretty fast so
we were able to process up to 60 million
records per second or six gigabytes per
second of data on 100 nodes at
sub-second latency so this this graph
here is showing two applications this is
just like searching for regular
expression and top K is a sliding window
word count followed by top K and they
both scale pretty much linearly to up to
a hundred nodes and the lines here are
showing if we allow a latency target of
one second versus two seconds how
you know how much stupid can we get and
even with you know sort of sub-second
latency I think these were around five
or six hundred milliseconds you can
still get a pretty good or stupid we
compared it with a few existing systems
so in though its impacted by the size of
the windows were doing the little
windows and that because there's some
communication and scheduling costs to
launch these things yeah the checkpoint
frequency is not a huge deal it that
affects recovery time but the checkpoint
frequency can be pretty low like even if
you checkpoint every 10 seconds like
only one-tenth of the windows it's
actually you can recover quickly I'll
show about that later yeah haha yeah
like what's the difference will be
seconds uh actually I I don't know I I
think we tried a few bigger windows but
it was a while back so I'm not sure with
the coin sister i don't think it's huge
i think maybe there's a difference like
you know maybe up to fifty percent
something like that but it's not huge
because when you're getting to
ten-second window you're getting like
into the realm of normal spark jobs like
the machine learning ones I showed you
know they were doing one iteration in
like one second or four seconds so then
it's not a big deal where this is more
interesting is where we push it to like
you know multi like this is a
three-stage kind of MapReduce job that's
happening in 600 milliseconds that's
what it becomes more interesting yeah
once you break out into very fine grain
when ready you can't you eat the more
resources and to finish the the same job
as because you break down become less
efficient it is true though yeah exactly
that's what it is there's the straight
of it but it becomes an engineering kind
of problem of like let's make a fast
scheduler for these things which is a
thing we can you know we're happy to
deal with yeah yeah okay so yeah so just
you know get to what we did here so we
compared this to a few existing system
so in the in the open source world
probably the most commonly used system
is a storm from twitter which is this
kind of message passing system and in
general we didn't expect to be faster
for any reason but we just wanted to
show that were in the same ballpark and
in storm we were actually faster
depending between 4 and 2 times so it
depends what we're doing but it's mostly
i think is slightly better engineering
and what we did but the point is it's
comparable performance to sort of this
fuel system and commercial streaming
database systems they don't have very
specific numbers but they say you know
we can do maybe 500 thousand or a
million records per second in total for
the whole system and this is usually
they don't really scale out across notes
and but what we did is we did about this
many records per second per node and the
results I showed before but we also
scale linearly to 100 notes and the
other thing is the way these guys do
fault tolerance so storm doesn't
actually have fault tolerance for state
the way we do it only just ensures each
message will be seen at least once and
these systems use application so we are
able to do this while also providing
nicer recovery mechanisms and apart from
speed of computation there is also speed
of recovery and we found that even with
like you're pretty big checkpoint
intervals you were able to recover quite
quickly so often we could do it in less
than a second so this one here is
showing the sliding like word count with
a ten second checkpoint interval and
this is just the processing time of each
batch of data and when we when we get
rid of a note here that that little
chunk of data takes about another extra
second to process and then there's this
window here that's ahead because we're
doing a sliding window we keep going
along and like taking new data and
subtracting data from 10 seconds ago so
there's this window of vulnerability we
may have to recompute other stuff and
then after that we're back to back to
normal operation basically and one other
thing i want to show you here is how
this varies with with the checkpoint
interval and cluster size so one of the
things so for example we tried doing
30-second checkpoints on
20 nodes instead of the 10 second that I
showed before and even with 30 second
checkpoints you you can recover in about
three or four extra seconds from what
you were normally doing and the other
cool thing is as you add more notes to
the system the company gets faster so
when we add 40 nodes instead of 20 we're
actually covering about twice as fast so
at school about this is this is a
recovery mechanism y scale is is an
advantage where as in the previous ones
the synchronization all that stuff gets
harder with scale it does go up yeah so
that's true actually it's a good
question of on average will it help on
that maybe on average is still you're
breaking me but actually because I twice
as many faults but you're here cover
twice as quickly oh but that's still
that's a good point i didn't have it
better about that ok cool yeah ok so i
have so i I've had you know decent
amount of questions but if you guys want
to stick around for five minutes I can
talk about this stuff too why do you
think rich think it's a good idea ok
yeah so I also wanted to talk very
briefly about this and you know we can
chat about it after in person one one of
the things we did here so but from
looking at systems I do like to look at
scheduling algorithms and policies and
you try to analyze things that and so
one of the cool problems we looked at
here is a multi resource fairness so let
me just set that up real quick so
basically in lots of computer systems
need to do need to divide resources
across users and the most common way
they've done it is a weighted fishing or
proportional saying in the operating
system world and examples of that fair
queuing network links or lottery
scheduling for the CPU so first sharing
basically it divides one he's always
like the CPU cycles you have or the link
bandwidth according to weights for each
user so for example if the users all
have equal weights it's going to split
this you know each get a third of it but
the problem we saw as we were building
these cluster applications is that
cluster applications have different
demands in terms of multiple
of resources so some applications might
compete on cpu other applications I've
just been talking about how it's
important to use memory you know some
applications might be bottlenecked an
i/o bandwidth and so on so you can't
really do a scheduler for these systems
that only looks at one of these
resources or tries to split them up in a
fixed ratio so the question we had is
how can we generalize fair sharing to
multiple resources just as an example of
this what you're going to see you know
you say you have a cluster and you have
equal numbers of CPUs and memory 100 CPU
is 100 gigabytes and you have one user
has you know bag of tasks they want to
hunt that each use six CPUs and one
gigabyte of RAM the other user has needs
the CPUs and four gigabytes so how many
should you give to each one so we tried
a few policies here if you love the
natural ones and found that a bunch of
interesting problems happen that don't
happen with a single lasers so first
thing we tried is something we call
tacit fairness and the idea there was
just let's treat you know the resources
as kind of the same let's say currency
so having one percent of the CPU is the
same value as one percent of memory and
let's try to equalize the users overall
shapes so in the number is in the
example we had before you end up with
this so first user gets six nines of the
CPU one-ninth of memory the second user
gets three nines of the CPU and four of
em and in total you know they each have
79 but with this policy even though is
really natural to do it there's actually
a problem so the problem is that one of
the users get less than half of both
resources and we call this the property
so you said it's violates a Shang and
scent of property and by sharing
incentive we mean that you know if users
contributes a equal amounts to the
cluster so they have equal weights one
user should be able to get at least half
of you know of one weezer so they should
be at least as well off as if they had
just gone off and built two separate
smaller clusters and now this guy here
because you know the top guy is not
using memory memory very much
the one at the bottom is getting less
than half of both one thing we tried to
fix this it has other problems is called
bottleneck fairness this is another
really natural thing so you might say
let's take the resource that's most
contended and split that equal so here
you know you're not contending for
memory so we'll give second person will
let them get more memory this is this
this looks again looks like a normal you
know like a pretty natural thing to do
but there's actually another problem
here which is that users can start to
game the system so it's not it's not
strategy poof so for example here the
bottleneck was CPU and user one only got
half the CPU but he really wants to use
CPUs what that user can do is change the
demand he gave to the system instead of
saying I need six CPUs and one gigabyte
of RAM I actually need five gigabytes of
RAM and then he'll get them and just not
use them and that ships the bottleneck
the memory and now this user gets more
of the CPU that they actually want it as
well so these are some problems that
just don't happen with one reasors so
our approach was basically to
characterize the properties of single
resource fairness that make it nice and
try to come up with a multi resource
policy that has the same and you know in
a nutshell the one we came up with
called dominant resource fairness and
it's to equalize the user share of the
resource they use most so here this
user's show of CPU and this is a show of
memory are going to be equal and we
showed that this has this always has the
same incentive property above its
strategy poof there's no benefit to
lying about your consumption and it has
a bunch of other properties as well and
we compared it with a few policies of so
just a sec one of the things we compared
with this is a preferred sharing policy
and economics competitive equilibrium
which is basically a perfect market and
we found that that actually lacks some
of the properties that drf has yeah
useful for the two users yeah they do
these are for end-user isn't
like my sis yeah yeah so this is
something that you're going to that they
use up is specified the resources cool
to one another I mean so you say yeah
six CPUs and a gigabyte of memory yeah
so it's assuming they use it in a fixed
ratio so it's not like it's definitely
not a general thing if a user has two
types of things they are nor whatever
it's not going to cover it but it's just
we started with this one where they have
a fixed ratio and we wanted to come up
with something for that yeah yeah ah
good question actually i'm not i'm not
sure exactly what she's done lately i
saw what she was doing in the past but i
think one of the differences in her work
was that she did mostly I cash resources
on like a buffer cache saying that
between applications and looking at my
cargo mechanisms to even enable that to
happen I think the policy is something
you might use you might use that I don't
think they looked at this problem of
just what the right policy is they
looked at what's the hardware mechanism
I might be wrong though because I
haven't looked at it in a while yeah
yeah so this so actually yes right so so
this is actually resistant to collusion
as long i think as each user uses some
of each resource I think if some users
have 00 demand for users then you can
cheat so one of the interesting things
so we didn't prove that but the
interesting thing that happened is a
bunch of economist actually looked at
this after and try to look at other
properties away and that's one of the
ones that that they said yeah seems to
assume that there is a dominant resource
then oh yeah let me leave for five years
ago 0 which right yeah you've got a
large enough memory then I'm if you can
give me the full memory on a machine
that I'm I may not care about network
bandwidth yeah so memory is my dummbell
assuming that memory assuming that's
never going to happen o as in network
bandwidth maybe my dominant resource so
you think your application my yes your
application has different ways of
learning based on the resources you've
got the fish games based on different
yes so we did yeah we didn't deal mr.
Chi it's not a great so does lots of
ways to try to generalize this and
actually I'm interested in doing some of
it we've done a bit already but yeah we
didn't deal with that yeah where do you
say this thing bought me this is the
level of a single machine oh it's good
yeah so we applied it in a plastic
scheduler mesos which i didn't talk
about one of the cool things is actually
the Hadoop team is now applying this in
Hadoop there independently implementing
this and we had this paper at sigcomm
last year where we applied it in
software-defined routers and middleboxes
also so where you have flows that you'll
go through different modules I contusion
detection they might stress different
resources they occupied the club part of
all your resources now you want to share
Billy among about yeah yes yes it's the
model is you have users within an
organization it's not an economic thing
where you're paying for his races
perhaps one of these issues about
cheating lying oh yeah resource table is
important yeah actually the cheating
thing came because we start people doing
this in in real clusters so some so for
example one interesting story there from
google they used to have this policy
that if you have
utilization above a certain level
they'll give you dedicated machines and
then they found yeah they found users
with actually as I expend loops and
things so we have yeah we talked and
there was a similar thing with Hadoop
users so users are get very creative one
of the Hadoop things like Yahoo built
these like 3,000 note Hadoop clusters
and users wanted to an MPI so people
like oh the map function that runs MPI
init and you can imagine that like
really messed up the networking and the
data locality and all that for the other
jobs yeah how does compared to an actual
working system yeah if you assign a
price per unit reason yeah so this is a
good question so this is kind of what
the competitive equilibrium does so
competitive equilibrium is if we had a
perfectly competitive market what would
it allocate now it's not the same as
user is actually bidding but the problem
is with uses bidding it becomes very
complex for the users to do stuff so but
it's competitive equilibrium is kind of
the outcome if they did bid in a in a
perfectly competitive market yeah and
the problem is the assumption of
perfectly competitive which can make
some things okay cool so yeah I'd be
glad to talk more about this with people
after so let me let me just wrap up so
just one one other thing I wanted to say
so so I do like to build sort of
applications will in real systems and
working in this space especially because
it is such a new space I've been lucky
you know I've tried to open such things
that I've been lucky to have people
actually try to use some of these so I
talked about spark and shark but some of
the other systems that I've worked on
have also been you know used outside so
it may source cluster manager well it's
actually used that Twitter it to manage
their nodes they have over 3,000 notes
now that they're managing drf is being
in the play independently implemented in
the Hadoop to point no design late an
algorithm for straggler handling is also
in in Hadoop delay scheduling which is I
think i did for data locality i actually
wrote one of the most popular schedule
is for hadoop called the Hadoop file
scheduler
as part of that work and it's still
being used today at places like facebook
and ebay and so on and finally the thing
i've been working on with with folks
here snap sequence aligner which is
really fun but totally different thing
looking at gene sequencing is actually
starting to be used so there's a group
at UCSF that's been using it to try to
build a pipeline to find viruses faster
so you know so basically this is one of
the things I really like about this
space is like there is room to actually
I build things that people will use so
just to summarize basically I hope I've
you know you guys already know Big Data
Systems problems but I hope I've shown
you know some of the problems that can
happen than some of the research
challenges and I've talked about these
two things I've talked about this way of
dealing with false when you have coarse
grained operations and which is very
common in data parallel algorithms and
we've applied this to both batch and
streaming and I've also talked about the
multi-regional staring problem which is
one of the few that that you can look at
in these clusters so that's it i'd be
glad to take any more questions people
have so my question is about the first
part of it yourself yeah how did you
make sure that you're wearing our group
our conservators
how did you make it so the user
basically so we don't enforce the
determinism if you happen to call a
library that's not deterministic like
you call maths at random but we do
provide ways so for so the operations we
provide as long as you pass it added a
deterministic function it will produce
the same result and for example for
things like random number generation or
sampling we have a sampling operation we
just see that with the sort of task ID
so that it's always the same ID when you
when you offer yeah we just it's a bit
simpler we just we just see the like
random number generators things like
that but if users are doing you know
stuff that is non-deterministic we don't
catch it and it would be interesting to
try to enforce that or even the detected
we do have some some work now that will
detect it by just check summing the
output and seeing whether it's the same
but it will you know it won't tell you
until you've already messed up so yeah
yeah I did catch with wind is an RTG guy
when do you not even worried you just
get rid of it or yeah we have yeah good
question we have you can actually set
what happens where is different storage
levels so one is just drop it and if I
need it I'll be computed again the other
one is spill it to disk and we basically
have like an LRU cache in there so each
node keeps accumulating data while it
can and then things drop out at the end
yeah so if you use if you are keeping it
stores and you have to assume that
reading to memory is effectively the
cost of reading to disk because in the
organs build something up you're gonna
have to build something yeah well that's
that's only two if you use the storage
level where they spill out to disk so by
default actually we just drop it and if
you ever come back to it will be
computed from the input
yeah but that just me all that means is
normally like in my demo I made all
these intermediate data set each time I
do a map or filter it's another hard ed
but although by default they're not even
save the memory they're just you
computed in kind of a streaming fashion
and then you drop it out once you've got
the results so only only the ones you
call persistence so basically RTD is
just is just to recipe for computing our
data set and if you mark it as a thing
you want to keep around then it's it
stays yeah yeah it's kind of a weird
thing it's but it's that's just the
programming model that made sense
because people build up data set out of
many transformations and they don't want
to save the intermediate result it what
needs to be poses to the dough to some
extent but it's still expensive to just
allocate space and like write it though
if you could do it so for example if you
do a map and then another map and none
of those is being persisted we do it
like one record at a time so we do it in
a pipeline fashion and it's just better
for cash usage and memory bandwidth and
stuff like that yeah this is meant to
replace your immediate data
reducer it doesn't actually change the
way that works it's more between
MapReduce jobs so between a mapper and
reducer we still we in our system we
still have the maps actually write out a
block and again it's in memory for is
then it goes the disk and we don't
actually push yeah yeah ok welcome
disguise streams yeah I guess my mentor
is like what was about to make a sauce
that considers Gator wasn't memory to
delay order oh yeah it actually wasn't
mostly it was so the things that that
can be problems are network bandwidth so
for example when we were receiving I
said we receive like I don't know how
many gigabytes per second like part of
the problem is you have to replicate the
input data also and that that can
actually really be a bottleneck so that
was one thing the other thing that will
happen in large versions of this now is
eventually the scheduling will become a
bottleneck so I think a cool like future
topic would be how can we make the
scheduling faster and can we even do
things like the centralized scheduling
or work stealing way it doesn't need to
be done by one node yeah
all right any other questions
okay well thanks for</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>