<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Brains, Minds and Machines - Joshua Tenenbaum | Coder Coacher - Coaching Coders</title><meta content="Symposium: Brains, Minds and Machines - Joshua Tenenbaum - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Brains, Minds and Machines - Joshua Tenenbaum</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OZ_Rr_yFYq8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so let me introduce now Josh Tannenbaum
he also does not need an introduction I
will only say that he represents
cognitive science in the center and
today and I think that's a big important
part of understanding human intelligence
the brain and the mind and I would like
to add that josh has been instrumental
in getting our centers at all without a
map the center would not exist Josh okay
great thanks to all the organizers uh
Tommy let me return that a number of
times over um we owe so much in the
center to you and thanks for putting
together along with Max and Gabriel a
great workshop that tries to show this
vision to the rest of the community and
all of you I mean you're all here so I
am very pleased to see people interested
in the connections between the study of
intelligence in brains minds and
machines I have here the names of all
the people whose work I'm it actually
talking about and but they'll be
highlighted on the particular slides and
I should thank them in advance I tend to
go a little bit over it and so I want to
make sure that I say that very clearly
i'm going to be talked about the work of
a number of really brilliant people who
have been lucky to work with and I'm
very happy to share it with you guys
here I'm uh like many of the other
speakers I I felt like I had to start
off with some history and I won't i'll
just flash this history by you now it's
exactly the same history you just heard
about but the thing i want to point to
here is that there's a success story for
the study of intelligence across brains
minds machines it's just the one that
the speaker in question are we're just
debating about before and it's really
about one aspect of intelligence though
which we could call pattern recognition
it's striking going back more than 50
years right that the very same circuit
elements that seem to be there in early
visual cortex in the work of Hubel and
Wiesel what we now call
linear classifier seem to be useful for
solving the classic problems of pattern
recognition like say taking a letter X
and being able to recognize it
regardless of where it appears in the
image or what other things might be
cluttering it up and then over a couple
of decades write that idea was was
scaled out into multi layer layer
hierarchies the Neo cognate Ron again
motivated by the same kind of basic
pattern recognition problems but mostly
on very simple theoretical examples and
then keep going another decade or two
the work of young McCune and and many
colleagues at AT&amp;amp;T just one one place
where you take the right really really
smart and hardworking engineering
dedicated engineering trying to make
this real world combined it with good
real-world datasets like the end this
data set and then you have something
that's actually useful technology that
now it can recognize letters and numbers
on handwritten checks and envelopes and
so on okay again keep going forward make
the data set a lot bigger and maybe a
lot more interesting for real-world
pattern recognition problems like many
classes of objects many many examples
and then you know the rest is history
you have image and that you have Alex
net and and we've all seen that okay and
then again from the standpoint of brains
minds and machines it's quite striking
that these same kinds of ideas have have
actually provided great qualitative and
quantitative insight into the behavior
and the brains of object recognition in
in humans and other primates okay so
what else is needed what why are we not
done well here's the basic thesis of my
talk and I think you can see this in
common with many other speakers which is
that intelligence is more than just
pattern recognition okay in particular
what I want to talk about is the aspects
of intelligence that we could call
modeling the world so this means
explaining and understanding what we see
imagining things that we don't see but
could write problem solving and planning
actions to make those things actually
exist in the world and then building new
models as we learn more about the world
these are the problems that I think are
particularly interesting about human
intelligence and that I want to
understand
now it's important that this is not the
same distinction this distinction
between pattern recognition and modeling
the world is not the same as the
distinction between say perception and
more general flexible thinking you can
see all these more interesting kinds of
thinking like processes in perception
and I'm going to talk about work we've
been doing which is basically in within
the domain of higher level more
cognitive perception partly because
that's where I think the connection
between brains minds machines is most
readily made in particular I'm going to
talk about two kinds of sophisticated
perception as understanding and modeling
the world one having to do with how we
go beyond just recognizing patterns and
images to really grasp the whole
physical world I mean look around you
just look around the scene where you are
right here and for all of you who are
familiar with the state of the art in
pattern recognition in computer vision
just think about how little of what you
can see and how much of the texture of
the objects where they are all the
things you could do if you were going to
plan actions move around move things
around move people around how little of
that is really being tackled currently
another thing I want to talk about is
learning and in particular something of
this a really distinctively interesting
kind of learning that we see in humans
and maybe rats but it's really mostly
about humans kind of one-shot learning
the ability to learn some kind of a
model of the world from very little
experience maybe even just one example
and the approach that's in common to all
of these is really sort of an old
approach I mean all the good ideas are
old it you could you could put call it
something like this it's basically about
a causal perception namely that what
we're doing is we're trying to invert
the causal processes that generate
scenes and then the generate images from
scenes it's an idea that is in many ways
attributed first to Helmholtz although
I'm sure you can find versions of it
going back to Aristotle at least in the
Western tradition Geoff Hinton was what
was and continues to be one of the best
components of this idea for people who
are familiar with the Helmholtz machine
an earlier version of deep learning or
one version of deep learning a lot of
what I'm going to be talking about can
be seen as a version of this idea only
instead of representing the causal
models with neural networks we're going
to be representing them with a kind of
representation called a probabilistic
program this is just a figure from a
very nice recent paper by zubin garg
money in nature
surveying a number of developments in
probabilistic AI machine learning
including probabilistic programs and for
those of you who i mean i'm sure pretty
much everybody here knows about
graphical models you can think of a
probabilistic program as a
generalization of a graphical model
where you use programs to represent the
causal process and not just graphs so
just to sum up the approach very clearly
here right we're trying to we have the
idea that we're going to be doing
reasoning with these richer causal
models as a kind of Bayesian inference
on generative models defined by programs
as opposed to say graphical models in
Bayesian networks and we're going to
talk about then vision a richer kind of
vision that really graphs more of the
physical structure of the world as
inverting these graphics programs the
kind of programs that you might use
actually like in the video games that
Dennis was talking about you know we're
like game engine graphics renderers and
then concept learning as inverting a
generative process that produces objects
as a kind of program induction or
program synthesis ok and for those of
you who are interested in deep networks
I would it's important to say this is
not meant to be mutually exclusive with
a neural network approach in fact I
think it's quite complimentary and one
of the things I'll briefly talk about is
ways they can come together but maybe
that's something we can talk about in
the panel so first starting with the
problem of perceiving the physical world
maybe to motivate this more concretely
think about some hard problems of person
detection things that go beyond the
current pattern recognition approach to
say identifying localizing parsing out
bodies and images I'm I think it's I
think it's fair to say that conventional
say for example detectors for people
which are quite good in a lot of
settings would have trouble with most of
these images here they might be able to
tell you for say the image in the upper
left they might be able to find the
people who are in the front row of that
bicycle group of bicyclists but they're
not going to be able to tell you that
there's maybe something like 30 or 40
bicyclists in that scene or to tell you
that in this scene over here in the
upper right that there's a couple of
hundred people or here maybe about 50 60
people and here 0 people right so think
about how is your brain able to do that
or to take a problem take this problem
here this is an airplane full of
computer vision researchers from the
last computer vision CPR conference
again conventional systems for detecting
people or parsing out body pose are not
going to be able to find most of the
people in the scene because most of the
people are mostly invisible yet you have
no trouble combining all the thought you
know all your knowledge about the
physical world about bodies about
airplanes and not only can you detect
the people but you can sort of parse out
where their bodies are so let's just
take if you can see here I mean it's
hard with the big room I don't know
let's let's take this guy here okay do
you see his head in the shoulder yeah
this is an interactive demo okay now
think about so you see his head here his
shoulder here think about where his
right hand is and I just want you i'm
going to move the arrow over here / over
the image i just want you to hum when i
get to where his right hand is is it
over here
you're supposed to harm not laughs okay
think about his um left big toe okay hum
when I get to wear his left big toe is
okay very good yeah so how are you able
to do that nobody can see is left big
toe but you have a model of bodies along
with the rest of your model of images
that allows you to solve that problem or
let art to take a problem in face
recognition again where there's been a
lot of success in what I call the easy
problems of face recognition here's a
harder problem which at least until
recently I mean I'm sure there's some
experts on face recognition here and I'm
actually excited that in the last couple
of months some of the best machine face
recognition systems are starting to be
able to solve this kind of problem but
say going back even a year certainly
more than that the best say deep phase
type systems you know basically would
just say this problems too hard we're
not even going to try to solve this so
here's a picture of my collaborator
postdoc ill creole durham this guy on
the left does anybody know who the guy
is on the right it's also a alert okay
how many people can see that they're the
same person raise your hand if you can
see that the same / so that's at least
plausible okay so um then the rest of
you should just be more daring okay so
as we've as we've shown in experiments
you can vary you could I can show you
someone you've never seen before and
very the viewpoint and the lighting
conditions quite severely and you can't
perfectly identify the person you know
you're not going to be ninety-nine
percent correct but you're going to be
well above chance I'd say a hard same
different tasks like this and we'd like
to understand how you can do it okay so
here's an example of doing this with one
of these kind of probabilistic programs
a probabilistic graphics program this is
work the first part of this work is was
led by tejas Kulkarni one of our
graduate students and presented at the
last cvpr and the idea here is to write
down with a simple kind of graphics
program there's a face there's a part of
it is actually modeling the 3d structure
of the face and the texture this is
based on work from Thomas Vedder and
colleagues and their basal face model
and then there's a simple kind of
graphics rendering thing that you put on
top of that to model the way but the
lighting works and the camera angle and
then as you can see here on the on the
right on the right hand of the slide
those are samples from the generative
model like samples from the prior you
run this random face graphics program
forward and you get random images of
faces if
random viewing conditions all right and
then perception is like running that
backwards so for example conditioning on
this image of a face you haven't seen
before and then asking your graphics
program to generate a likely posterior
sample which means to say what what way
of setting the latent variables the
inputs of the graphics program and most
likely have made an image that looks
like that kind one of many places where
we've been interested in integrating
deep networks here for example is taking
advantage of the fact that they are
really good at pattern recognition they
learn really good features for pattern
recognition which in this case might
provide a good similarity metric for
matching the outputs of the graphics
engine with the image namely you don't
necessarily try to match the pixels but
maybe just say some continent features
that's that's that's one such approach
now just to show this thing in action
illustrating what I hope will be some
somewhat at least a little bit
impressive and also something that
should trouble to you here I'm showing a
face on the left that's an input image
and on the right I'm showing you the
models kind of hypothesis as it tries to
search around using a kind of mcmc
algorithm an elliptical slice sampler in
its latent space trying to match that
image trying to come up with a good
posterior sample and so you can see it
kind of an action it starts off with
basically a random guess and reasonably
quickly narrows into something pretty
good as well as I'll come to in a minute
it's it's it's reasonably quickly but
it's not that quick in fact it's way too
slow your brain is able to perceive this
face you know in well under a second
whereas this system takes much longer it
takes a number of iterations of mcmc but
what you have is not just a match at the
image you have a 3d model that you can
then do some nice things with like you
can re render that face imagining what
it would look like from very different
viewpoint or lighting conditions and
that serves as the basis for a pretty
powerful invariant face recognizer more
powerful than you would get as I'll show
you in a bit then just use just trying
to find traditional feature invariance
you can do the same kind of thing for
bodies where now you have a graphics
model of a body here on the lower left
you're just seeing some random samples
of body poses and then for example if
you now take an input image of this
Usain Bolt up here sprinting here's an
example of trying to match that with
again doing mcmc in the space of
possible inputs to the graphics program
and again we're not trying to match here
trying to match pixels we're trying to
match a kind of enhanced edge map so
what you see in the middle between the
the movie and the and the image is the
sort of intermediate representation but
again something like confident features
might might be good I mean this is not
implausible sort of thing for a
mid-level continent representation and
again you see if you wait a little bit
you know this this thing pretty quickly
figures out this interesting non-trivial
pose and on some pretty hard pose
recognition problems it actually beats
some standard specially engineered and
discriminately train de for below parts
models so we see these as successes a
but again I want I want to what I'm
interested more in where their
limitations are so in particular while
they can do pretty rich seen
interpretation by inverting a graphics
model they're way too slow so here's one
place where we've thought about going
back to the helmets machine idea from
Hinton and so on which is to say well
maybe we could try to learn a
recognition model this is basically
exactly the Helmholtz machine it's in
the same way we have a top-down
generative model we're learning a
bottom-up recognition model in this case
the bottom of recognition model can be
defined in a pretty effective way by
using a confident and I think that's
that's not unrelated to what those
contents were effectively engineered to
do basically to invert this kind of
graphics pipeline the key thing about
what we're doing here is that the
continent can be trained just as in the
helmets machine idea from a purely self
supervised data so you don't need any
label data you're just you're drawing
samples or fantasies from the generative
model and training the convent to invert
that to be able to guess what from the
images to be able to guess the latent
variables to the graphics program if you
then use this basically to initialize
mcmc what you can see in this curve over
there in the lower right is just that's
just basically the log-likelihood as a
function of time and it solves the
problem almost perfectly from the
beginning blue is what I showed you
before red is the conv net enhanced
initialized mcmc it's it's not perfect
this is sort of a log likelihood on the
log scale so even though so that red
curve there is uh is it's still there
still actually of a number of log points
and if you look closely you can see that
the guess is that the continent
recognition model makes right away kind
of look almost right but you can if you
look at them for it for you know even
just a second you can tell they're not
quite right what we've been doing this
is now work of ilker yield
and colleagues we've been using this
kind of combination top-down bottom-up
model to provide what what to us are the
best fits so far for a range of
interesting hard behavioral tasks in
face recognition we have harder and
easier problems of varying pose and
lighting and we also vary the timing so
this is just a preview of some
unpublished work to be submitted pretty
soon showing that this model I was able
to fit pretty well a range of behavioral
tasks and then in collaboration with VIN
Rick free Walt is another one of these
brains mind machine center partners
Tommy mentioned the work that he and
Doris sounded this model is also helping
to extend the kind of successes that
that Tommy and Jolie bow and others had
in modeling their mid-level face patches
now to the most high level face patches
okay so I want to just briefly before
leaving perception just talk about where
where you can go with this idea what
I've talked about is by inverting these
graphics models we can get something
about the 3d structure of the world but
then of course when I talk about having
a causal model it's not just about
finding what's out there but about
imagining and reasoning with it so I
just want to point briefly to some work
that Pete Battaglia and just Hamrick did
with us a couple of years ago Pete
continues doing this kind of work in
deep mind and I think it's really
exciting that Dennis that the vision
that Dennis has includes this sort of
idea to say well um if you look at these
scenes for example you can recognize
that there's block stacked up but you
also get a sense of what we call the
intuitive physics there right that the
ones say in the upper left are those are
those are stable whereas under gravity
they're just going to stay where they
are whereas the ones in the lower right
look like they should be falling over
and we can take this idea of say running
a probabilistic graphics program
backwards to get a 3d scene of the of
the blocks and then combine that with
probabilistic programs for simulating
physics again basic kind of game physics
engines run that forward a few time
steps to imagine what would happen and
as you can see here this system and then
imagines that the blocks are going to
fall over so that's how it can make a
judgment that these this is an unstable
tower of blocks here's another sample
from the same probabilistic program
pipeline again an inverse graphic sample
to figure out the 3d position of the
blocks and then a forward sample through
the physics engine and you can see
they're sort of different but the same
basic thing happens after a couple of
times
most of the blocks fall over so our
model here does a kind of very sort of
poor man's montecarlo gets an estimate
from a few samples like this of what's
likely to happen and we've been able to
show that that provides a very nice
quantitative model of people's intuitive
physics judgments in a range of natural
scenes so here i'm just showing three
examples of towers stimuli that people
judge in a graded way how likely this is
to fall under gravity and that scatter
plot just shows that our model
predictions versus human judgments in a
range of these stimuli the same kind of
thing though and this is really
important when we're talking about the
more sort of interesting kinds of
intelligence going beyond pattern
recognition and and very much
dovetailing with some of what Dennis was
talking about having this generative
model doesn't just let you solve this
task the very same model lets you say
answer many other questions like how far
is that are that are the blocks going to
fall or which direction they're going to
fall in or suppose I tell you that these
notice here that you have some of the
blocks or one color some of the other
colors suppose I tell you that the grey
blocks are ten times heavier than the
green blocks or vice versa how will that
change which way you think this is going
to fall or if you see that the blocks
fall in an unexpected direction can you
figure out that one color is ten times
heavier than the other it's not
restricted to blocks of all the same
shape and size the blocks can be
different shapes and sizes we it's not
restricted to just forces that are the
standard ones like gravity and friction
but for example we suppose I tell you
that the table is bumped from one angle
or another the very same model provides
pretty much the same level of
quantitative prediction in all these
cases you can also as something this is
something that Pete continues to do a
deep mine use it to actually plan your
actions in simple physics based video
games and if you saw maybe some of you
saw the poster that a couple of current
people in our lab judge and woo and
ilker Yildirim and others have been
doing is basically another way of trying
to integrate physics engine approach
that here they're analyzing simply
simple sort of blocks rolling down
inclined plane examples a physics engine
approach with a deep learning system for
trying to make good guesses about the
physical properties of objects and then
use that to initialize again in a
probabilistic physics program for trying
to parse out and reason about and
predict the motions of objects now
taking into account things like friction
and and density
okay um so we know in the last few
minutes I want to turn to the second
topic of one-shot learning and just
again let me just ground this in some
concrete examples and I know it's late
but these demos are more fun if you join
with me okay um raise your hand if you
know what this is okay raise your hand
if you've never seen this before okay
good so most of you haven't seen this
before that I could have asked the
question raise your hand if you were
rock climber and I would have gotten the
same thing because this is a very
standard piece of rock climbing
equipment called a cam all right now the
next question is mostly as well is
really only for the people who haven't
seen it before the non climbers okay so
here's a complicated scene of a climber
laying out their equipment can you find
the other cams I'll just move my mouse
around and just hum if I'm pointing over
one of those things again here here's
the object now here these are okay very
good you found them notice they're
different they're different colors
they're slightly different shapes
slightly different versions there in
very different positions you know in 3d
but you still did okay okay here's
another thing raise your hand if you
know what this is okay very good
everybody's knows this segue but
remember the first time you saw one
right you didn't think you didn't think
it was a bicycle you didn't think it was
a unicycle or a motorcycle or a car it
was like something kind of like those
but you were able to recognize oh this
is a new kind of vehicle or personal
vehicle and you could see other things
and you could tell it apart from the
familiar ones as well as recognize the
new examples right how many segways are
in this scene just to get us all on the
same page too right ok now this ability
to learn a new object concept from one
example is not just about recognizing
things right it's not just being able to
pick out new instances you have the
ability to parse things into you know to
parse it in two parts and that's
probably partly how you're able to do it
right by knowing something about wheels
and handlebars and so on that's your
ability to parse this thing into its
parts is probably part of how you
recognize it you can generate new
instances you can draw depending on how
good a sketchy or i can draw new
examples that you haven't seen before
imagine what they'd be like you can
imagine combinations of these and other
objects to produce yet still more
fanciful objects
this kind of motor unicycle that you
know maybe you haven't seen but you can
imagine so we've been trying to study
these kinds of one-shot learning
abilities where again the interesting
thing is kind of the combination of how
how much we can learn so quickly the
ability to learn basically a generative
model of these object concepts from just
one example something that then supports
one-shot categorization but also these
other more creative tasks we've been
studying this particularly in the
context of a data set of handwritten
characters that we created originally
under Russell oh kudi novel he was a
postdoc in the lab and the recent paper
that we're very excited it just came out
today in science it's the this is work
of Russ but primarily Brendan Lake who
finished his PhD leading this effort and
is now at NYU and I particularly excited
to tell you about this because I hope
that this will inspire a number of
people to try to work on these problems
of interesting one shot learning and it
and I i think the data set that we
collected here will be of value to many
people regardless of whether you like
our kind of approach or other sorts of
approaches so I really just want to
emphasize that that all the data and
code for these kind of one-shot learning
of hadron characters are available from
Brendan's web page as well as his github
site and we you know please have fun
okay so here's that here's let me tell
you show you this if you haven't seen
these data before it's we were very
inspired by the stuff i started out the
talk with in particular yawns work on
trying to study in you know he was he
was trying to really make pattern
recognition with deep nets work and he
had what i think was the right idea of
go deep into the into this domain of
handwritten characters where there's
really a lot to be done developed the
basic ideas and then once they got to a
point of maturity those same principles
people showed could apply to a much
wider range of interesting real-world
pattern recognition problems we when we
first came up with this data set we
thought of it is kind of like the
transpose of em nist where m nuh stint
at aghori 'he's with thousands of
examples of each we wanted to generate
data set of thousands of categories with
only a few examples each and we we did
this by going to a wonderful website
called omni glatt so we've named our
data set the omni lots data set after
the website that's collected examples of
basically all the world's writing
systems so you can see
some of the examples of these simple
visual concepts again they're basically
no more complex than M missed as
individual items but there's a lot of
them so for example we have many
alphabets that probably you've never
seen before we have some alphabets that
nobody's seen before because they are
made up like from the television show
futurama it's again a remarkable thing
about alphabets that people can make up
new characters and whole new alphabets
and you can do one shot learning here so
just again one more interactive demo
actually there will be one more
interactive demo so here's this here's
this example in does anyone know the
South event yeah what was it what is
that it so there's there's a range of
Indian alphabet is that yeah okay so I
don't even know the alphabet but let's
let's play this game um so um okay so i
want you to hum again or well let's do
clapping clap so here's here's a here's
one character of these 20 characters
down here one of them is the same one so
i want you to clap when i get to it okay
here we go oh sorry Rick okay
okay very good yeah so people are
basically perfect at this and it's quite
amazing um how can you do this well
here's an idea we I mean we think you do
this by basically thinking about how you
would draw the characters in some form
and there's a lot of neuroscience as
well as previous psychology suggesting
that this is in fact something about the
way people represent characters as well
as many other related concepts like
spoken words and speech okay so look at
this character and in the it just
imagine and just in the air draw how you
would draw this character so just
everybody do it draw the character okay
you um you probably did something like
this right okay it turns out that
people's drawings are quite consistent
again even for characters they don't
know so for fairly simple characters
like these ones with just two strokes or
even for more complex characters like
these ones here which have a number of
different parts basically people draw
them in very consistent ways even when
you you don't know the alphabet so we
try to formalize this idea of a
generative model like a kind of
probabilistic drawing program this isn't
this is an example of it we call it
bayesian program learning because
basically we're doing a hierarchical
Bayesian inference on a multistage
probabilistic program in particular
there's one stage of publicity program
which captures the motor program the
thing that you guys were just doing
right there it's like the commands to
your arm that generates instances and
it's probabilistic because you don't
draw it the same way twice and different
people might draw it a little bit
differently you need to capture that
variance to be able to do all the tasks
we're talking about but those programs
themselves are generated by a higher
level program that's the prior it's a
program generating program that captures
your knowledge about this domain your
knowledge about how to read and write
basically okay and then a perception
inference and learning is basically
trying to invert this causal process I
won't go into the details but again you
can read them in the paper um in order
to make this work there's a kind of a
learning to learn process so we have a
sort of held out background set in the
paper we mostly consider a very big
background set that we hope everybody
would be pleased with like a 30
alphabets we also have smaller alphabets
smaller background sets which are more
like the experience of humans so you can
try that out if you like like try just
trying to try to learn your inductive
bias or your representation of how
characters work from only
alphabets that's more challenging and
then you can use these generative models
to do all the tasks we showed you like
classification so for example here if I
if I show you one instance of these
again these two patterns up there it's
two characters and then I have the one
on the bottom and i want to say which
one is it well I think we can all see
it's much more likely to be able on the
left than the one on the right and we
can do that because basically the
inferred stroke motor program for the
one on the left provides a much better
fit to just the pattern of ink they're
right I mean we can measure this in
terms of log likelihood and it's about a
thousand log points better okay so now
this we we did a bunch of different
tasks here we did at these challenging
one shot learning tasks where there's a
twenty way classification task you can
again see one is just like the one we
did before and and we quantified how
good people are is at this as well as a
number of different models people again
are basically getting this error rates
down under five percent where chances
ninety-five percent error rate or
success rate of ninety-five percent in
chances five percent and that's all our
bayesian program learning model is also
able to do that whereas a range of other
models including sort of lesions
versions of our model that leave out
this the key aspects some of the key
aspects of the probabilistic program and
it's and the learning to learn don't do
as well but also we compared a range of
you know various kinds of deep networks
confidence and so on and again with a
lot of hard work you can get them sort
of close to human level performance but
there's there's there's still a quite
significant gap the more interesting
thing though that you do with these
generative models that are you know
again just really go beyond the pattern
recognition paradigm that we've
inherited from deep networks are these
more creative tasks so so here's a task
where for example we ask people we give
people a character and we say draw
another example of the character don't
copy it just make another instance of
one we ask nine people to do that and
then we asked our model to do that nine
times and then we can do a kind of
little Turing test where we show other
people the humans vs machines and we ask
can you tell the humans for the machine
so this will be our last interactive
demo for each of these cells up here
nine of these characters were drawn by
the human and nine we're drawn by the
machine so just say which of these left
or right were drawn by the human or the
machine so in particular machine so we
haven't raise your hand if you think
this one this
ones here we're drawn by the machine
okay raise your hands if you think this
one's drama the machine okay I don't
remember who's right we'll find it okay
um well what about raise your hand if
you think this was drawn by the machine
raise your head raise your hand if you
think this was drawn by the machine okay
how about here raise your hand if you
think this was drawn by the machine
raise your hand if you think this was
drama the machine okay raise your hand
if you think this was drawn by the
machine okay machine okay here's right
answer did anybody get them all right a
couple people all right how about here
Bay basically you can't tell we've
quantified this and people a few people
about ten percent of people are above
chance statistically on this task but
most people can't tell and and we did it
these simple little visual Turing test
for a number of other creative tasks
like for example a more interesting one
even asking people giving people
characters in a new alphabet and say now
draw a whole new character in the
alphabet these are just examples of our
computer program doing that okay um I
think I'm basically out of time so I'll
just say we think that this kind of
approach is of course just just as we
saw with you know con nets and other
classic approaches in pattern
recognition we think the principles here
of you know are much more general than
just recognizing characters there's a
number of other kinds of kinds of
concept learning tasks that people are
able to learn from very few examples and
generalize in interesting ways and we're
excited to try to apply these approaches
there but that's very much future work
so just to wrap up then I started off
calling the slide conclusions but it's
really it's not conclusions it's looking
forward and I think if we want to see
what is the future study of intelligence
integrating across brains minds and
machines well we want to say looking
back we had 50 or 60 years of studying
pattern recognition and we made a lot of
progress it may not be solved but I from
my perspective it's getting pretty close
and i think it's it's it's time and it's
very exciting that we're now able to
move on to these more well more
interesting aspects of more human-like
intelligence beyond pattern recognition
to building causal models of the world
that support explaining imagining
planning and things that are more like
thinking i think that we're going to
need powerful tools more powerful tools
than say the neural network toolbox has
given us to capture these kinds of
generative
and here I've shown you a little bit
about how we're trying to do that with
probabilistic programs and program
induction and shown you how these tools
are already letting us capture
interesting aspects of perception and
learning and build more human-like
perception and learning systems in
machines but there are many open
questions and I hope some of you will be
interested in working on these like for
example for probabilistic programs how
can we scale up inference to be much
faster and much more general if you're
interested in that check out the black
box inference of workshop on saturday um
how can we scale up learning to more
complex kinds of probabilistic programs
than just the very simple programs that
we did for these hundred characters how
can we integrate these ideas with neural
networks on the engineering side and
maybe most interestingly how do these
kinds of richer causal models and causal
model building abilities work in the
brain these are things that we hope will
be able to address in the coming years
and again I hope many of you will be
interested in working on them to thank
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>