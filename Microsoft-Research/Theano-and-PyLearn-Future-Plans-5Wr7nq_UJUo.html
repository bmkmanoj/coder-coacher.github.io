<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Theano and PyLearn Future Plans | Coder Coacher - Coaching Coders</title><meta content="Theano and PyLearn Future Plans - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Theano and PyLearn Future Plans</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5Wr7nq_UJUo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so in the tan dando in the pretty short
term we wanted to make it easier to do
see extension related to handle it is
something that is already documented but
the documentation is not the best and we
want to be meant to make that better and
we wanted to make it easier we have
learned that some people yes sir how to
do it a little bit and was afraid of
that so we will try to make that simpler
we know that for pretty by for big graph
10,000 nodes and more the compilation
time itself can be slow and we are
working on that because the medela not
chasing the size of the wet but in the
number of node in the modeling shoots
grow at the same time so we are working
on that when we will when we continue to
work on the multi-gpu to make it
available inside to handle and not just
in the inside the lib GPU ra there is
support for a looping phone to make a
terranan and other such functionality
and our implementation work but we will
continue to make it better there's some
overhead issue in some case and other
stuff lined up right now when we check
point some handle function depending how
we do it it can be done with such a way
that it get bind to the GPU so when you
want to reload it you must have a GPU so
you train a full model and just want to
see the weight later you need a GPU just
to visualize the way so that's not fun
and if you there is work around it but
there are not fun so we will try to make
it much simpler to be completely GPU
transparent I think it's the only place
that is where we
see the GP that isn't transparent I'm
sure right now in the ten new memory
allocation there's two mode the default
mode is during computation when there's
temporary memory that we don't need any
more you will free them and show at each
stand 0 function call we reallocate all
the time / temporary memory region there
is another mode is where we keep all of
them and so the next call to the Tendo
function you don't do anymore allocation
if the input size didn't change but we
can find something in between for
example automatically automatically find
that some of the temporary element are
of the same shape and automatically
shared the storage and free it only when
the last user of it so we can have
something in between that could be done
after the trick for that will be W which
we may find any which is you just have a
counter of the number of times you use
it is in the rain then every 10 times
you accept it yeah something you
so the idea is that you do an amortized
approach so you're still going to be
allocating memory occasionally yeah but
the overhead about being been real to
reduced by factor of 10 and then or
whatever never you have to choose I
don't I don't have that sin when you
finish using you don't need to figure
out you don't need to match shapes or
figure out the things are thinking same
amount it's a very simple trip we just
keep count the number of times that you
would have treated you don't actually
free it can you keep a buffer of eyelid
available object that's one way to do it
different so you have yeah you have
chunks of memory which you can allocated
yeah you have a counter to that shown
and that counter goes up every time you
call free on it and then but you don't
actually put it unless the counter is
value is equal to 10 and they said reset
the counter 20
after button on that side on the GPU
entiendo the way we plan to do it right
now it's when you bullet the end of
function when it is compile it all
operation have already a determinate
where they will be executed so it will
be static in the graph it won't be
something dynamic so we can do where it
is at something new and there's a faster
convolution that we are working on is
pretty much done we are trying to ram
finish for implementing the cafe
convolution that use a call to blast and
a 50 convolution well I've already
working version but there are more
updates that can be done on them Oh
leave the periodic if there is other
people interested to use it the goal was
to become on but right now where there
is us so we want more functionality as
pie inside lip zipper area inside Python
inside the end oh I think we rapid
mostly all of new pie right now we want
to finish to move the functionality that
we have entiendo inside the lipsy parity
and to the sea level and we want to be
able to optimize the colonel selection
depending of the GPU that we use
I'll mention a few
okay so I'm actually know if you think
that we're planning to do in pollen tube
as mentioned before a lot of these
things are are simply things that are
currently being worked on in our lab
that people have been implementing and
now it's just a matter of cleaning them
up and pushing them to the public
repositories for the things like
variational auto encoders or machine
translation recurrent neural networks
have been implemented in pile on tues
it's another thing that's currently as a
pull request open and just needs unit
testing and I would go in documentation
is still a big issue you notice that is
the user base gross documentation
becomes more and more important so
checkpoints are important you know this
because you know training times can be
very long sometimes days sometimes even
weeks for some experiments so we want to
make sure it becomes almost transparent
up in your process crushes or someone
shuts down your computer to
automatically continues again which
right now requires a few lines of code
better support for sparse data sets
better had parameters torture for all
this kind of examples of features that
are up and coming to show that uh we're
still extending mostly that they're more
efficiently stored in memory and that
right now there are certain parts where
it actually needs to explicitly create
the things in memory dude it's advice
first examples sorry it did suffice
first yeah at some parts which makes
things very inefficient and it doesn't
really warn you or anything that I
desktop but yeah I think that's it so if
there are any questions then
so what's the strategy behind well right
now there's no you can use whatever you
want but it's not automated so it's
going to do hide the parameter search
you basically just everyone does it some
people just due to the spreadsheet other
people have written their own scripts or
their own kind of things but we don't
have any system in parlin to that you
can use to do a hyper parameter search
because everyone does it differently
some people just kind of you know do it
by touch other people just do a brute
force search or grid search or whatever
you little users provided later wait so
yeah so what we want to do is implement
some sort of methods so that people can
do more intelligent ways of the asian
optimization of the high parameters but
we need to create like a framework like
an infrastructure that allows people to
implement that so I've been facing the
same issue with VW and I'm trying to
figure out so BW uses news program
options I'm trying to figure out how to
kind of automatically extract from the
boost program options data structure
through the set of options in a manner
which could be fed into other algorithms
ok have you thought about that maybe I
can talk a little bit more the I / opt
is a separate project that exists it was
started by chance that's one of the
original author of Gandil death rate
after his release when one of his last
paper when we finish it in the lab it
was about random search on the internal
matter is much better than the grid
search and then from there he wanted to
find even bit something even better than
random search and that's what was
working on so you find some algorithm
that find the better I parameter
combination
unless pride and random search and we
also developed in a framework where you
can wear it is the user that this I perp
animator have this search space and
you'll also make sure that some a
parameter are conditional on other I
parameter so is the user that provide
the search space of the I prepared
network but it's not something trivial
to make a good interfaces to describe
that so if you want you can set more
into life I apotheke I'm sure and
meaningless the answer question if you
have personal foul which there is
already a wrapping of that inside panel
to to make running to be able to release
it but i'm not sure maybe it's in the
food requests or its merchant but in our
case it's not documented so it's not
much usable with our assistant effort
ok</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>