<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intersection Workshop - Learning to Constrain Deformable Surfaces | Coder Coacher - Coaching Coders</title><meta content="Intersection Workshop - Learning to Constrain Deformable Surfaces - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intersection Workshop - Learning to Constrain Deformable Surfaces</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AwprjmxnOH0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay so I'd like to take this
opportunity to tell you a bit about what
we've been doing recently on modeling 3d
surfaces from single images something
we've been doing for a while now and
before David Forsyth asked me why I do
this I'll try to answer preemptively
which is of course you could say why
bother this is the home of the kinect
who needs a monocular modeling of
surfaces with a single camera and the
answer is well the Estelle cases where
it's hard to use a kinect and also where
we want to go in the end is we want to
do this on the mobile device so it's not
clear that you will have this kind of a
sensor in mobile devices anytime soon so
first i would like to present what we
had done so far and then go on to how
we've extended it recently so the kind
of problem we've addressed for a while
is let us say I have a different ball
surface I have a one image which I'm
going to call the reference image in
which I actually know the shape so in
this case it's flat it doesn't have to
be but it in this specifically it is and
so this is essentially a template and
now i am given a second image which i'm
going to call the input image in which
the surface is deformed and i want to
recover the 3d shape so of course this
is not stereo because the shape is
different between the two images so the
way that we formulate the problem is as
follows we have our reference shape we
know where it projects in a reference
image and we establish correspondences
between the reference image
and the input image and what we're going
to try to compute is our unknown X which
are the 3d coordinates of all the verses
in the mesh and what metrosouth man who
used to be one of my students and now is
a research in Australia showed is that
you can do a kind of DLT and formulate
this as a simple linear program problem
where X must be the solution of an
equation of the form MX equal 0 if X is
expressed in the cap in the in the
camera coordinate system so you could
say well it's easy just so that done the
problem it's not quite so easy because
the the M matrix is very ill conditioned
in fact if you do an SVD one-third of
its singular values are 0 almost zero
having to do essentially with the depth
uncertainty and so you can't gone just
so you have to impose additional
constraints and what maturity then the
thesis has try sexually many ways of
imposing constraints and in the end the
conclusion was one of the best ways was
to enforce in extensibility constraint
in the form of inequality constraint
saying the distance between individual
versus cannot be greater than the
judging distance and with one who twist
is that if you only impose this kind of
constraint nothing prevents your mesh
the one you're trying to reconstruct to
shrink to nothing so you have to add
something that's akin to balloon forces
that pushes the mesh as far as possible
away from the camera until as many of
the iniquity constraints becoming sorry
qualities and whether you show that is
that this in fact is a convex problem
it's an SOC p so you can minimize and
find a global optimum
and generate results like those the
final result is bottom right so you have
let us manly chest and the
reconstruction in the in the lower right
and sat and what's it what's important
is this is really done one frame at a
time we are not tracking we are
reconstructing in every frame
individually and it's pretty stable so
it works nicely but it has one problem
is that we are solving this SOC piece
convex that's nice but it has lost
variables because we have a mesh that
about 40 x 30 that's 1200 verse east and
333 600 variable that's a lot it doesn't
run fast it's nowhere near real time so
one thing we have looked at since is how
can you reduce the number of variables
so that you solve the problem with far
fewer variables and that's a free work
we did with Raquel and mature again and
and one observation is you could train a
system to reproduce it so we are
limiting ourselves to the case of
inaccessible surfaces and one way to
reduce number of variables would be to
come up with a latent variable model in
terms of far fewer variables at the 3600
I've talked about that with parameter is
the space of inaccessible surfaces so
the simplest thing you could do and
we've played with this is to UPC it is a
latent variable model unfortunately it
doesn't preserve length so when you add
deformation modes length between
vertices are not preserved another thing
we tried is well you could actually
learn a Gaussian process and then we
have the influence of this harkens back
actually two things we did was Raquel
David and Erin on body tracking so
actually it is a good example of the
interaction between graphics and vision
same algorithm I think this whole thing
started the graphics animation kind of
kind of thing and you could learn a
Gaussian process by essentially given
examples of the phone mesh and you could
learn from supposed GP LVN that would
have few parameters the problem with
this and the reason it was not complete
the factory is to make it work well and
to make it preserve length for all
possible values of the variables you
need a huge training database and large
enough that it's actually not practical
so that's the work with it more recently
so first let's start with the simple
thing which is lets us say X are going
to be my little variables the Y's are
going to be the meshes I'm trying to
reconstruct I could imagine having a
database of these things and learning a
mapping of non linear mapping in this
way so this is the so the primal problem
would be something like this with a
critic loss and the quadratic
organization and if I curl eyes all this
I get a GP that would essentially
produce meshes whose lengths are
preserved that they are near the
training samples but not if they're far
away so the little twist that we added
was to say ok what we are going to do is
we are going to have the same training
database for which we have both a set of
latent variables and a mesh we are going
to minimize the same loss function but
we are going to introduce other latent
variables for which we don't have the
why and we are going to impose that for
those the mapping preserves the length
and so what what's interesting about
this is you can if you work out the math
you get actually something that's fairly
similar to
and you get a non linear mapping that
actually preserves better the length
over the whole naydan space there they
are the X so you start for example from
for the weights of the pcas like it's
the same way when you compute a GP LVN
you start with the weights of the pca
and then you do an optimization and you
do exactly the same thing in this case
and so what that does is you can see the
two I should run it back you what you
can see is the reconstruction using
three possible methods we've played with
either you do it with PCA or you do it
with the the unconstraint GP or you do
it with a constraint GV and you get
better accuracy it's better trained when
we impose this constraint during the
training here's another example along
the same lines where these graphs are
the errors frame by frame and you can
see generally speaking the red curve is
below the others so this is a way of
learning a model that essentially
enforces the constraint so it's a
mapping non linear mapping that whose
output really tries to satisfy the
constraints even for values of latent
variables for which you don't have a
corresponding Y yes
vertices in English space yes but then
to derive the deformation caused problem
because there are several solutions by
phenom Lee it is the next time in
extensively constraints that make it
well posed so if you don't impose that
the distance between vertices is bounded
then you hadn't you have an infinity of
solution if you now try to preserve it
you have one solution that preserves it
better than the others I'm not sure I
can't prove it but practically in
practice yes
no because it's a it's a convex is it
convection no it's not it's not convex
but it's essentially I think we would
have what makes it work is that we start
close enough so that we do get
convergence with this and what's
interesting about this is I have
formulated this in terms of learning am
at the mapping that preserves distances
between vertices but I mean this is a
complete generic formulation so you
could this idea of these constrained lvm
s is actually I believe applicable to
other other problems if if you so choose
ok any more questions on this right
which is essentially what we use to do
because in in the previous method we did
this the advanta potential advantage of
this is we have far fewer variables to
deal with because we don't do the
projection we are directly in the late
in space no we guarantee that we are
close we don't we don't satisfy them
strictly but we've tried and I mean on
many examples we run empirically they
are close to being satisfied
there's no very generic combination that
says it has to be a piece of actually
right that means we've played I don't
have the results here but we've played
for example with the human ever datasets
where the kind of things we impose is
that the distance between joints are
preserved and it's no I mean the
mathematics are the same
what happens with extreme so where the
limits it's probably it would have to do
with the side of the size of Laden space
essentially the size of Laden space is
going to control how much you can deform
your your surface yeah if you want to
really sharp falls you're going to need
more training samples so have you
results which I lost weight very kind of
said like you know we see these kind of
papers move around or some sure but I
mean the form of old surface like a dog
running or like quite off all
deformations right so yeah it met a
challenge it of course is a challenge
and that's exactly what I try to tell me
by grad students we've seen angry we've
seen enough paper and we should see
different things and hopefully we will
see them and but we've been moving if
you look at some of the recent papers we
are really have made an effort to go
towards thing that creeps sharply and
can get somewhere in that direction of
course it becomes increasing
increasingly difficult not least because
when it creases sharply you don't have
the the course bonuses anymore then I
understand minute I cut I completely
agree completely agree
not that much because it's there is a
robust scheme to eliminate outliers so
you do an iterative thing the first fit
get rid of the outliers and fit again
I'm sorry right yes miss Verity it's a
it's a completely standard outlier
rejection scheme I'm sorry can you can
you speak louder please okay so actually
give me a moment because that's my next
comment is of course you've all noticed
the examples I've showed you where very
texture it's a good reason for that
because where there is no texture I
don't have any information so actually
thank you for providing me my transition
that's the next problem on the list what
do you do with surfaces that are not
very textured and there you essentially
try to revisit shape from shading so
here is our version of revisiting shape
from shading in the light of what we
know about learning these days so here's
an example of so aidan who's a Gretchen
who did a lot of this work is here he's
holding I'm sorry he's still holding a
piece of paper but you may know this
that this piece of paper that he's
holding doesn't have that much texture
on it this so it has a bit of texture in
the center and not that much on on the
side plus is actually in his office
where the lighting is not a point simple
point light sources whatever it is
there's this big window on the right
side it's an extended light source
that's what you have to deal with if you
want to do shape from shading so I
how do we handle this is what we're
going to do is we are actually going to
calibrate the lighting so initially we
we thought we were going to lot to learn
the lighting as well and that proved for
the time being that proved too difficult
we weren't able to do it so we put we
stick we stuck a light probe in in the
environment and learn a mapping model in
terms of spherical harmonics which for
this environment actually seems to be
enough and then what we wanted to do is
give given the sliding model and given
the image of the sheet of paper that we
have what can we say about the shape so
without the essentially its shape from
shading but without some of the
simplifying assumptions and what we try
to do is to say well we can learn a
mapping between deformations and
intensity patterns so for individual
patches on the surface what we did is to
actually compute deformation modes this
time this was done strictly in terms of
PCA it could actually be done in terms
of what address presented but since we
did this actually before the other that
was done in terms of PCA deformation
modes and to each of these things what
we computed were given the shading model
for a particular shape of a patch we can
predict what the intensity is supposed
to look like and we can also do a PCA
style decomposition which means we can
associate a set of intensity modes to a
set of deformation modes and again we
learn the GP between one and the other
so that when we see a little patch of
the surface we can actually predict what
shape it might be so Associated why
right so it's not be dosed constant it
is a shady but it some more slightly
more generic way form of shading so it's
easy to say one of the problem is it
doesn't quite work this way because it's
actually you cannot learn one mapping
this way because you can have several
shapes that produce the same intensity
pattern and the way around that is to
say it's true there is not a one-to-one
mapping if you don't say anything about
the average normal of the patch but if
you partition the space the training
data base according to the average
normal of the patch then for each
average orientation you do get a pretty
good mapping so which means that so
that's how we train we essentially learn
several GPS one for every single average
orientation and then at one time when we
see a patch we predict several possible
shapes according to the normal so we
associate several hypotheses to every
little patch and then when we do wonder
when we do the reconstruction what we do
is for every patch we got a bunch of
hypotheses and we run the Markov random
field to find those that are globally
consistent and that's actually why there
is a texture patch in the middle that's
what's needed to make it work which is
especially that gives us boundary
conditions it gives one patch for which
we actually can compute the shape using
the previous technique and by then
enforcing consistency and everything
else we get the complete shape which is
what you see on the right on these
papers and t-shirts
yes definitely I mean that's it's
obvious that one other thing we we are
missing on the silhouettes that we
should definitely use yes we've trained
for this particular kind of object so
they are as I said that they are there
for one specific scale and I guess I
didn't quite understand your question
right right yes that's what it is but
actually we are not using boundary
condition in this case when I was
answering is sure it would be I mean it
probably would constrain anything a lot
more but in this specific case we
weren't using them really except for the
detector patch
aww
no well it's using using basically the
spherical harmonics model and the
diffuse model yes right so again it's
kind of yeah it's numbering and for the
time being it's good so basically what
you assuming is constant albedo in every
single patch it does not to be the same
patch to patch but within a patched
constant
it's not the only way to use the
illumination weren't just complexes you
no it's sure sure so this was an attempt
at getting away from the
okay so to be honest so the conclusion
of this i mean i wouldn't sell this as
the solution to shape from shading quite
yet our observation is this works nicely
provided you calibrate your camera well
photometrically and that was what a
dean's experience was with this
technique which is until he did the
radiometric calibration of the camera
correctly it wasn't working when he did
it it started working correctly so means
it's not really the answer to the
universe but it's hopefully an
interesting step forward
but so at the time me the old SR I stuff
was still a point light source with the
usual assumptions because I had never
heard of a statistical learning at that
time okay so here are some results where
we compare what we get so we're not
complete luddites we do use connects
once in a while just if if i'll need to
produce the ground truth and where we
can show that at least on these examples
we get some some reasonable
reconstructions and of course they are
better than the one we obtained using
the previous technique because we chose
our examples right there is not enough
correspondences on this piece of paper
to do the correspondence only thing and
that gives you may be also so here's
another example of what we can do and
one way we actually validate this is
this particular implementation actually
does not enforce the geodyssey
constraint does not enforce the the the
lengths constraints so it's actually a
good way to measure to to find out if
the result we get is reasonable and so
we've checked that when the regressions
we get these distances are actually
preserved on something that we know to
be in extensible ok so to conclude its
what the direction we are going in
slowly slowly but hopefully in the right
direction is essentially a generic
paradigm where you have a methods where
by with a simple camp of sensible webcam
essentially you can reconstruct the
textured poly surface using
correspondences you can reconstruct the
constant albedo parts using the method
that just shown you the shape of
training style technique you can use
these two things to learn a model of the
deformations and
and use that to reconstruct the retsoor
surface that you couldn't handle well
was a good without a good deformation
model and so the end I mean that we're
still going to be working on this for a
while and I promise that we will try to
show other things than paper and
t-shirts is something that would be
generally applicable that one of these
days we'll run on the phone and it
doesn't yet but if you at cvpr will have
a demo so we will be happy to show you
that it actually works for real in real
time on the laptop thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>