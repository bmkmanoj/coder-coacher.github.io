<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Two basic problems in finite stochastic optimization | Coder Coacher - Coaching Coders</title><meta content="Two basic problems in finite stochastic optimization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Two basic problems in finite stochastic optimization</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MSGnrHojwSk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hello and we're delighted to have
Sebastian blue back from Princeton tell
us about two basic problems in finite
stochastic optimization thank you one ok
so I think I prepared the way too much
but so maybe it will be only one basic
program in st. suggesting optimization
we'll see so feel free to interrupt me
if anything is not here so I'm going to
start with and maybe only talk about
that but I'm going to start with roughly
my favorite problem in research so this
is this problem so you have K unknown
probability distributions which are
submissions so unlucky unknown
probability which are sub gotten with
variants boxy bounded by one or
something like that and what you want is
to find the distribution which has the
maximal mean so the goal is to find the
one that has the maximal means of the
arc max of mui mui is defined as the
expectation of x when x is born from New
I and you want the Arg max which we want
let's call this I star and I'm going to
assume that it's unique okay so my goal
is to find I star and so okay so now I
need to tell you how do I interact with
this probability distribution so what i
can do is i have a budget of n samples
so i can sequentially queries the query
the probability distribution and I get
we I get realization from this
probability distribution so I want to
find I star using n observations which
are sequentially chosen so more
precisely so little bit more formally we
have a sort of sequential game so the
time is going to go from one
to up to n and at each time step what do
i do I choose I t which is in 12 k so i
choose an index i choose one of this
probability distribution and what I
receive is so choose I t and i receive a
realization so i receive YT which is
drawn from new IT and this drawing is
independent of everything else
conditionally on IT ok once i have done
these n samples at the end what I want
is to output one of the probability
distribution so I out to j n which is in
k and my hope is that JN is going to be
I star the best one okay and how am I
evaluated I'm evaluated by what is the
mean of this guy compared to the true
best min ok so my my regrets so the
regret at time M is the difference
between mu i star so the best means that
i could have obtained and I compare it
to MU J n which is the mean of the
selected probability distribution so i'm
going to call this k probability
distribution i'm going to call them arms
ok so that's my terminology that i use
from the multi-armed bandit terminology
and i put an expectation here so this is
what i call the simple regret so it's
just my optimization error right I want
to optimize this mu I and instead of the
max I got this guy and I look at the
distance and I want this thing to be as
small as possible ok if you if you know
about right yes then you go out you
inspect this going one by one yes then
you will select add code so you have the
option to select this guy or the
challengers don't selected and watch
so this you have total freedom when you
choose IT in 12 k right this this choice
is going to be dependent on all the
previous observations that you made I
don't imagine I made plenty of trials
and now i'm going to choose to observe
vdt distribution number three and at the
next time step i choose to absorb
probability distribution number 10 I can
return I can do anything I want to
return to the same things absolutely so
i will need to try so to estimate the
mean of m1 points and i will need to try
it many many times right to have an
estimate an accurate estimate because
the first time i try it imagine this is
a Bernoulli distribution with parameters
mu 1 I try it I get a one I try it and
so on time I get 20 I want to run it I
want to learn I essentially I want to
learn the new star right ok so that's
what I want to do so i'm not really the
first one to look at this program as you
can expect i mean this is as basic as it
gets right i just want to find the max
of k finer things but the issue is that
roughly there has been two approaches
which are minimax and by asian because
what i want i want to find the optimal
in some sense allocation strategy I want
to find the best allocation strategies
so as to minimize this simple regret but
this problem is not well defined I a
priori right there is an optimal
allocation strategy if if I know the new
the new eyes I do whatever I want but at
the end I out to the best guy ok this is
optimal now in minimax what you say is
that you take you design your education
strategy and then I can choose which set
of probability distribution I'm going to
throw at you and I look at what is your
regret in that case that's minimax then
best is well defined ok it's a mean of a
max
there is no normalization there is no
normalization so this this right so in
in a minimax sense the answer is that RN
the optimal RN is a folder square root
of K over N but the best you can do and
that's not very difficult to prove and I
think that's totally uninteresting so
trivial strategy will get you k log K
over N okay log n but you you have to
work a little bit to remove the lock but
that's really not the point we will see
that you can gain order of magnitudes
with a new point of view what does it
mean what so coffee also goshen it just
means the usual thing so it doesn't
normalization which all right right
right yeah yeah so sub Gaussian with
constant one of with known constant so
calcium to be used no it's okay so sub
gosh I said it quickly i said so with
the proxy for the balance is bounded by
one okay cool guy is this yeah it's not
the main / imagine everything against
Gaussian we parents one and then the
talk makes sense and it's non-trivial so
so minimax that gives you this okay so
this has been studied since the 50s etc
by asian what you do is that you put a
prior over possible parameters for the
probability distribution and then you
want to find the allocation strategies
that minimizes the expected simple
regret where the expectation is with
respect to the draw from the prior okay
so this is also well defined but then
you have to come up with a prior etc and
it's not it's not clear out to do it so
I want to go beyond these things and I
will propose a new sort of a new
perspective which allows you to talk
about optimal strategies which without
making an assumption such as mini
maximization ok I will come back to this
so for those of you know about Milton
then this feels like a multi-armed
bandit program
except that the performance measure is
different so in bandits what we look at
is this capital R n which is
accumulative regret so we look at the
sum of the simple instantaneous regret
at every time step okay so we look at
the some forty equals one to n so at
every time step we could have played the
optimal arm we would have gotten new I
star but instead we played I T so we got
new IT and I'm going to look at this in
expectation let's call the cumulative
regret and a trivial the trivial thing
is that the simple regret is upper
bounded by the cumulative regret divided
by n right what i can do is that at the
end one when you asked me to output
something i can just select a time step
at random I'll put the actions that I
played at that time and that gives me
this bound okay so this is always true
and this gets you the minimax rate but
now I'm going to show that you can get
much better so okay yes yes actually I
so its expectation with respect to
everything so in four weeks with respect
to IT so I T could be randomized but
even if it's deterministic it depends on
the previous observations which are
themself on them so I take expectation
it's it's it's a complicated expectation
it's not I mean it's simple but to
analyze it's not obvious how to do it
you take this flight how many you want
to select from them just the maximum of
them you want to right that's exactly
what I'm going to talk about how how do
you do this right what what is the
allocation strategy how do you choose
this guy so let's several times you
choose one at a time that you will make
n selections make installation oh boy
and it is
event and is given to you and it's given
to it arbitrarily large crop you can't
find it yes but the question is you want
the optimal rate you want to make the
most out of it like with n you will see
so let me let me show you one trivial
thing so that we are all on the same
page so what is trivial is just you have
you have a budget of n samples your k
options so you just allocate end over K
to each arm right so you just try each
option and other k times right so what
what does it give you so one thing is
that to simplify for the talk i'm going
to look at this thing which is so the
regret let's say if every all the means
are in constant this is certain is
smaller than en which is the arrow 8
which is a priority that j n is not
equal to Y star ok let's say that all
awesome you eyes they live in the
interval 0 1 for instance ok I'm going
to denote it's going to be important for
the rest of the talk Delta I is new star
mu i star minus mu I so Delta I is the
sub optimality gap is the distance
between the quality of I and the quality
is the best quality that you can get so
this is certainly larger or so that
delta x y n where delta is a smallest
gap delta is the mean of the Delta eyes
of i not equal to i style right so in
first order approximation it's fine to
focus on en tierra rate ok so I'm most
of the talk i am going to talk about the
error rate rather than the simple regret
so let's see what is the error rate of
this simple thing so you just apply
Chernov right so the deviation deviating
by epsilon is going to be bounded by
exponential minus T times epsilon
squared if I sample T times someone what
I need is that everybody stays in an
interval of size roughly data I if this
is the case and there is no way that at
the end I out put somebody else on the
basket
right if everybody's into an interval of
size Delta I then I get the best thing
so right so I have mu I if it stays
within let's say one half of Delta I if
the empirical so I'm going to denote by
mu hat I so that's my empirical estimate
using my samples if the empirical
estimate stays within an interval of
size one half Delta I for every I then
at the end I just look at the best one
and and I will get the true best okay so
what does this give me so with an Indian
bound we just get the song for i equals
1 to K exponential minus n over K that's
the number of samples that i get x delta
I square that the deviations that I'm
looking at and a constant okay so let me
so 2 comments on this the first one is
that this goes exponentially fast 20 ok
so the priority of making a mistake goes
exponentially fast 20 and this is going
to be small Ruffy when so this is going
to be dominated by the largest of these
terms the largest of these terms happens
when I look at I which minimizes the
gaps so this is small this is small when
n over K times Delta is loves when n K
Delta squared is large so it's smaller
than Delta if this is larger than log 1
over Delta so what we need so it's small
when n is at least Omega of K over Delta
square so if the number of samples the
number of trials that I can make the
number of experiments is at least k over
delta square just uniform allocation
will find the best action
right I want to not another lucky I
absolutely want another look so I want
let's say if if this is log K of a delta
then we party at least 19 is delta i
find it because that's precisely what i
get okay so so is this good is this is
this result good so clearly it doesn't
feel very good because you spend I mean
you try everybody but it could be that
very early on you identify that some of
these guys they are not competitors
right they will there is almost no
chance that these guys will be the best
one but still you keep them so what you
want maybe is to focus your attention of
the guys which look difficult to
distinguish okay so okay so what I'm
going to do now is I'm going to show you
a first what are the limits of these
problems so here we said that if n is a
cloud we can find it now how how large
need I mean if n is smaller than
something you also can't find it so this
is a this was a main theorem that we did
in back in 2010 with driver Deaver
myself and my nose and this is really
this room is really what gives this new
point of view which is neither minimax
know by Asian so it goes as follows so
for any new sonu is a product of the new
eyes and I'm going to look at a new
which is just a Gaussian distribution so
it's going to be allowable so if I
respect to Gaussian distribution that's
fine so it's it's a Gaussian
distribution with mean mu and with
covariance the identity in dimension K
so it's just a product of nui one for
any algorithm so in particular this for
any for any means
that this algorithm can depend on mute
maybe we know mew I'm going to say that
there exists Sigma which is a
permutation of the indices such that if
i look at the probability of error of
this algorithm on nu sigma 2 nu sigma
which means that i have just / muted the
distribution ok so now instead of
driving mean mu I on arm I i have mean
mu mu sigma I on are mine this is larger
than some constant times exponential
minus some other constant times n over
what we called H and you have a log k
where h is the sum of the inverse gap
square sum of 1 over delta i square i
not equal to i stop so what this means
is that to be small to existing smaller
so this is equivalent to saying that en
are smaller than delta must imply that n
is larger than h some constant over low
key so if if you have if you find if you
priority of error is smaller than delta
so and you have a log 1 over delta if
you have a small probability of error
then it means that the number of samples
that you have must be larger than the
complexity we call h is the hardness of
the problem h divided by log k and h is
the sum of 1 over delta i square so now
if you compare this to this result
downstairs you see that here instead of
h i have k over delta square but k over
Delta Squad can be much bigger than h
right so potentially for some news
h could be much smaller than K over
Delta square in the worst case they are
the same right and that's why the
minimax analysis is not interesting
because in the minimax analysis the
worst case is basically when h is equal
to K over delta squared and in that case
uniform is almost optimal uniform
allocation so this this is a result that
goes beyond that right it its
distribution dependent it depends on the
distribution and it tells you that this
is the right measure of hardness of the
I mean not yet but yes and so far but at
the end of the day here is just a proxy
to the simple great absolutely if all
the other the same this will be terrible
but simple regret will be easy
absolutely so this is yes that's
definitely correct so this is only a
first step right so it's I mean step by
step right so it's here this tells us
something very precise about en but it's
not very precise for RN I mean for
little island for the simple regret it's
it's an approximation only for the
simple wicked this is not this is not
the end of the story this is the end of
the story I think for the error rate but
not for the simple guitar you agree I
don't know what is a full answer for the
simple regret absolutely so it's exactly
along the lines of the classical lion
Robbins wizard yeah absolutely so its
exact it's some sense a way to
understand it is that it for those of
you know what is the lion Robbins result
it's exactly the version of Lion Robbins
for the simple regret rather than the
cumulative regret now the proof
techniques are completely different so
now I know how to prove this for the
community so let me just spend two
minutes on this so i know how to prove
this theorem for the community regret
now but lion Robbins is not that right
lion Robin they have to assume something
about the orgasm lion Reubens I proved a
lower bound for the cumulative regret
but they say that the algorithm has to
be consistent for any possible
distribution no matter what what is the
distribution you have to be consistent
and go at a certain rate here I need to
assume nothing about the Argyll could be
terrible for some distributions it just
and actually lion Robbins in that sense
is not true you can get you can get
constant regret if you know if you know
the distribution up to a permutation so
it's similar but it's not exactly so now
this is not the end of the story right
now I need to tell you can you get this
H right so you can almost so you can
almost and this is strategy which is
basically just writing down
mathematically what what the intuition
was which is you try a little bit
everybody's and there is one guy which
looks clearly is not going to be the
best well then just stop stamping it and
then focus on the rest and so on and so
forth so this is a successive reject so
successive rejects work like this so
it's going to go by faces so your face k
equals 1 a 2 K minus 1 and it will have
a set of active arms so at the beginning
a is everything and during a phase you
sample NK minus n K minus 1 times
everyone in a so I need to tell you I
will tell you what is our formulas for
this thing so all the arms that are
still active you sample them a certain
number of times and then remove from a
the worst guy to worst yeah
so you do that and at the end at the end
of K minus one you are left with only
one winner and you say okay this is the
guys that I believe to be the best and
the serum is that with NK which is some
formulas when K is proportional to n
over capital K minus 1 plus 1 minus
little k you get that the priority of
arrow is bounded by a constant so
actually k times exponential minus n / h
times log squared okay so so this
strategy so this means that n needs to
be a further h times log Cuba okay
it's a number of arms number of action
little k is an index in India gozum
right i go by phases and in phase little
k that's how many times i sample is just
a formula that comes out of journalists
so if you compare to to the lower bound
over there the Robin was that you need
at least h of a lot k and here you need
right you need you need so if you have
more than this your small awesome delta
ok so it's tied up to the logs so this
was in in in 2010 now in just recently
there has been a very very nice work
from a group of people i think at at
yahoo and what they did so this is a
karen tomor quran and summer in icml
2013 they can get down to so they get so
they modify successive jacket still the
overall same idea and i get h times log
k times blog ladki but it's roughly see
the same idea but it's the analysis is a
little bit different i'm not going to
explain in details so we still have a
gap but i can also improve the lower
bound i can remove this log k so except
that it's not so easy to remove it so so
this proof is difficult it's this proof
is the only only thing which is
difficult which other written on the
board so far and and you cannot really
go into the proof and and try to trick
some things I mean everything is really
it's tightly together but I can modify a
little bit the assumption and get
merge simple proof so maybe these are
some value because means the statement
is in a sense less powerful but the
proof technique is so much simpler that
it could be applied to other settings
that's what I want to talk about now so
this is a serum to be written with Emily
Kaufman so let's put a 14 so this young
goes as follows so for any new for any
new which is again an n mu ik and for
any algorithm so the beginning is the
same now the invariance is not going to
be over permutations because that's what
makes this proved difficult is that
there is not much you can work with
right you have to permute this guy and
this guy is not nice you can be in
trouble now what I'm going to do is that
instead of looking at permutations I'm
going to take one of the suboptimal arm
and maybe this guy i will put it up so
i'm going to define let Phi I of MU so
that's a vector in R d such that Phi I
of new let's say is a J's component is
equal to MU J if I is not if j is not
equal to i and it's equal to MU J plus 2
Delta so mu I let's say plus 2 Delta I
if j equals I so I am I have my victim
you right and i have this operator phii
it takes the ice coordinate and just
pull it up to be the best one right so
the first thing to observe is that the
hardness measure so note that H mu so
the hardness of MU is always larger than
the harness off I I of new I can only
make the problem simpler by doing that
because when I pull this guy up then
everybody
is further away from the best arm than
it was previously by the distance so in
you you have a certain distance to the
best guy but in thigh of news the best
guy becomes the ice one which is above
the best before so so the gap increases
the harness measure is decreasing by
this operation and what I can show is
that they exist so for any new and for
any algorithm there exists I search that
the regret to so the simple regret on
thigh I of MU is lower bounded by
exponential minus a constant times n / H
right so so this gets rid of this log K
over there and this proof is five lines
let's say maybe even four lines compared
to four pages here now it's weaker right
because I mean this week it's in a sense
it's weaker because the algorithm as the
it's not to say if it's weaker or
stronger because here the class over
which we take the maximum is a class of
size factorial K right here it's only a
class of size K sorry I put rd but it
was ok but anyway so so now we know we
know the result up to a lot k right the
lower bound is H exactly h and the upper
bound is H lock Caleb lucky I think the
truth is H perhaps up to a log log for
the reasons and this is really a
fundamental problem and we only know
basically one algorithm which is this
everything else is a variant this one
it's a variant it's not this algorithm
so instead of having for instance
instead of having k phases they have log
k phases so it's but but it's still the
same structure and I think you need to
get rid of the logs you need something
much smoother like you don't need to be
tied to a schedule that you had
beforehand like the schedule should be
adaptive but we don't know how to
analyze this one more time mr. SOT yeah
with the locust engine we move half
every every time yeah so that's the
acronym no I said no because no I think
very far from it but it's not it's not
clear so multiplicative weights are
typically designed for the minimax rate
they are not adaptive in this sense
exact the great weakness is that they
work with almost no assumption but if it
turns out that the world is much nicer
than they don't adapt and here it's
really about trying to adapt as much as
possible but we even want to adapt as
much as if we knew exactly the muse so
right so you see be there is a 20-minute
story so let me try to do it in two
minutes so you see be you can prove you
can probably show that you cannot go at
an exponential rate so the probability
of error will be polynomial now you can
do a modification of UCB which is which
actually goes at this rate but the
modification so you see be it looks like
it plays a time step T so the action
that maximizes the current mean plus
square root of two log t over TI t so
this you can show that this is not going
to work what you can do is the
modification which is called UCB e we
did also in 2010 which goes exists a
constant per square root and your
implies the two lochte by n / h oj t so
you need to know h so if you know h and
you do this algorithm then you get
exactly at this rate okay
but not knowing age you could try to
adapt to it online but we don't know how
to prove anything about it but now let
me say something from a practical point
of view in practice these programs
coming back to one of your earlier
question this one is only interested in
the range where n is a photo H if n is
much much larger than H anything will
find the best action like just do
uniform and you will find it what is
interesting is that when you are in the
problem where it's hard like it's just
just that where this is close to a
constant but if this is close to a
constant when to lock key is also a
constant so you can view the analysis of
this as an analysis of the true you see
be closed the cases where n is of order
H so this is showing that the basic you
see me should work in something so now
let me just quickly show you some
pictures so can I get the pink down
thanks um yes right so i'm going to show
you an experiment like this so i'm ok so
i'm just going to show you two
experiments so the first one we have 15
arms so in this experiment we have
boundaries distributions everywhere and
the mean of the best arm so the best
time is on one and it's mean is point
five okay so in the first experiment
which i call experiment five see the
mean goes down in in an arithmetic
progression okay so you have point 5
minus and then point 0 25 times I ok for
I equals to 2 15 and what I plot here so
the bars are the probability of error
for different algorithms and so the
first one is just uniform sampling so
you see uniform sampling as the worst
probability of error as expected it's
the most naive algorithm so in this
program for instance so n is 4000
uniform something will get you
right arm we party at least one minus
point 35 something like that then two to
four were algorithm called having races
that appeared in the literature
previously so they perform a little bit
better than uniform but not too much
then the five is this successive reject
that I just told you about about 6 to 9
are this UCB this finely tuned UCB and
the rest are the UCB e where I try to
estimate online H using a procedure
which is non-trivial um so you see
successive reject desert better than
than all the other I'm enzyme to
previous strategies it almost divided
like here you see in this second
experiment the priority of error of
uniform is closed 2.6 and the priority
of successive reject is close to point
to okay so you can get real improvement
so this second experiment by the ways is
what you are what you just talked about
right so we have one good guy which has
a mean point five then we have five guys
which have a mean point 45 so close buys
and another group at at Point 43 and
another group so this is three groups of
bottom and here you see with three group
of atoms like this it really it's really
worth trying to adapt so these are goes
on day we quickly remove all the very
bad ones and focus on the good ones um
okay so this is a numerical experiment
now let me move on to something else
which is what if instead of finding the
best option you want to find the n best
okay so now maybe you want to find the
five best arms instead of just the best
one so here I plot again the same to
experiment the name of experiment seven
changed to six but at the same on on the
y-axis I have the priority of error and
on the x-axis I have how many ARMs do I
want the algorithm to output so the
first point here that corresponds to the
previous slide I just want to find the
best one blue corresponds to uniform
allocation and agenda returns
and best yes yes I at least one of them
is one so you are good only if you get
the M correct that's not just a
difficult task or sorry or during this
world no no no no no that's the key
point you don't care about the ordering
you just want to find the end best
within the ambesed you don't care about
the other right so so uniform is in blue
and successive rejected in red so as in
the previous slide red is much below
blue that's very good but now look at
what happens when you move n then
suddenly successive reject which was
almost optimal for M equals 1 becomes
really bad compared even to uniform so
what this is saying is I mean this was
to be expected in some sense but
successive reject because it was
designed to find the best one it has a
very rough idea of the ranking below the
best one videos the first two best like
see also guys it doesn't really know
what's going on so if you ask him to
output the five best arms it has a very
bad job right so what this says is that
you fundamentally need to modify the
orgasm when you want to find the M best
you cannot just do successive rejecter
actually this is a variant of successive
reject where you don't have k I mean we
rightly tune the number of phases and
the samples / phrases so you need to
modify it so the modifications that we
did with two students is this green line
which is called successive accept and
reject so the key and only new idea of
this paper is that when you want to find
the M best you not only reject bad guys
but you also need to stop sampling guys
that look good because they look good so
now just stop sampling them and say okay
this one is going to be in the batch
that I accept and that's it right so
this is a successive accept and reject
now the difficulty is at the end of a
phase how do you decide if in this phase
you should accept someone or you should
reject someone so what you do is that
compare how confident in some sense you
are about the acceptance and the
rejection and you do whatever is the
best for you and so the analysis is is
harder than for M equals one but you see
in practice it really works right at the
Green Line and here was yours or
experiment it really works it's really
better and gap is is a parent all right
is there any question on this can you
get it up can you get the screen up
thanks
okay so is there any question on this
yes twice
so different from what yes when you try
to accept the best guys can you just
treat it as the very problematic problem
but now you have to version just
absolutely the question is where do you
put the baseline right you where do you
invert like where do you put you see you
see what I mean like you say you want to
take the negative but but when do you
start taking the negative so that's
exactly the key point right so basically
the key is that if when you want to find
the best one let's assume that mu1 is
larger than Mewtwo etc up to meuk then
the new gaps that i define are so if you
are in the best one if one if you are
one of the best then you look at the
distance between mui and mu n plus 1 so
you look at the distance between you and
the first guy who is not in the am best
and conversely for those who are not in
the am best you look at your distance to
the last guy with one of the M best so
you have those gaps and what the Argos
and does is that it estimates these gaps
and then it decides to accept or reject
based on those gaps those estimated gaps
that is along the lines of what you just
said and the complexity what you can
show that in this case the complexity is
the sum of these guys 1 over this guy
squared so maybe just one open program
on this and then I will spend 10 minutes
on the other topic one open problem is
that here we won't find the M best arms
but we put no structural assumption on
the end based on what would be very
interesting is is the following more
combinatorial problem where I assume
that you have a graph and in the arms so
you have a graph G and on like this g on
K edges right so you have K edges and on
each edge you have a priority
distribution and now what you want to
find a
is maybe the best spanning tree okay so
fine the best spanning tree and so let's
say that the spanning trees have a
certain size m in this in this example
so now we want to find a subset of size
M of the K edges but this subset also
has to satisfy some structural
properties so more generally we are
given a subset see of 2 to the K right
so it's a set of subset of 12 k and what
you want is to find the Ark max over
let's say s in C of the sum over I in s
of mu i right so you want to find a
subset of the armed with a certain
combinatorial structure given by C which
maximize the sum of the values within
this arm I think this is completely open
and I don't think there is a general
series that will I don't think there is
a general algorithm that takes see as an
input and then if I find the best
structure at the optimal rate I think
you need to to avoid gerson to really
fill out for every single problem the
first one is the best planning tree I
don't know how to do it you could try to
think about finding the best matching
let's say you have a bipartite the
complete bipartite graph and what you
want is to find the best perfect
matching I have no idea how to do that I
mean you can go through the list of all
combinatorial optimization problem and
try to redo things in this stochastic
framework with this point of it right
with the point of view of optimal rate
optimal distribution dependent rate
no so the issue if the minimax is that
more or less you gain only lock factors
here you get order of magnitudes that
you you move from k of a data square to
H so but but no we don't know for
minimax is no it can't be it's going to
be much smaller than this I mean
something trivial would be to view each
spanning tree as an arm and then find
the best mid but that's exactly not what
you want to do but but what you are
saying is is a trivial upper bound and
the key is that it's not going to be
like this so one thing that could be
just how how influential is this edge so
let's say you look at what is the best
spanning tree that goes is a contain
this ad this is the best spanning tree
that does not contain this edge if the
gap between these two value is smaller
than maybe it says that this is I mean
maybe it's what it's the sum of one over
this gap squirrel but I don't think so
that I think there are also non-trivial
correlations between the edges so I
don't know what is the answer okay now i
want to quickly talk about something
else so one nice thing about this series
that i talked to quite a few people
about practical problems and of discrete
optimization and often they can be
casted within this this framework but
sometimes they can and I will give you
one example where you have to think to
get something so I have a set X X is a
countable set but is known to me an a is
a subset of X so think of X is a set of
integers and a is a set of prime numbers
okay so a is a set of interesting
interesting elements
in some sense but I don't know a okay I
don't know it and what I want is to
discover a I want to discover as many
elements of a as possible and so now I
need to tell you how do I alack how do i
access these these sets so I access them
through expert so I have expert which
opera t distribution new one up to nuke
a probability supported on X and now i
can place the same game as before so
sequentially i can make requests to this
expert to this priority distribution
when i make a request I get a random
verbal drawn from the underlying
priority distribution and then I observe
did I get an interesting element or not
ok so the game goes like this so choose
I t inkay receive YT which is run from
nu IJ and I also observe whether or not
YT is in a so observe the indicator that
is I teen a and what I want is after n
samples I look at F of n which is a
number of interesting items that I found
so how many interesting items did I
found well I found these items y 1 up to
yn that's the set of items that I found
which one were interesting well it's the
intersection with a how many did I find
it's a cardinality of this thing ok so
now I want to maximize F of n Doel it
sir women except when i receive an what
you told if it's interesting enough so
does the modern make sense so imagine i
have distribution on the integers I
don't know what are prime numbers and
and I sample from one of the
distribution i get an integer and then
somebody tells me if it's a prime or not
ah yes now you you're the one yes no
absolutely so I actually think ad are
many but but I don't know yet many so I
no one imagines that you have a big
graph it's it's really enormous let's
say the electrical grid in the United
States okay and you have nodes right so
the nodes are going to be your element
in X and now there are few nodes in the
amines are some nodes in this network
which are 40 right so there is something
going on with this not you actually need
to physically go there and fix the node
what you can do is that given a node you
can run a security analysis and test
whether or not whether or not the node
is 40 and if it's 40 you can go there
and fix it but of course you cannot run
the security analysis for every node in
the network but then what you do is that
you hired your high or some engineers
and I think hard about the program and
what they could come up with maybe are
some kinds of random walks on these
networks which are biased towards 40
note maybe the the rest mods i were able
to do that so you have k of these
engineers and they each came up with
their own heuristics okay so you have K
random walks are rather probability
distribution on the network and what you
can do is you have only let's say you
have only one computer that can run the
security analysis so every day you need
to choose one of the key engineer run
his or her heuristic and then run the
security analysis and then move on to
the next day ok that is this a good
example you could also have I don't know
you want to you you have code for a
computer code and you have you you want
to find all the bugs in your code and
you have different heuristics to find
elements of codes that could be wrong
and you want to combine these heuristics
in the best way
different heuristics know that I mean
three about combination this program
with exactly is it equivalent to the
previous problem so I don't think so
because the reason is that this is much
more dynamic so look at what happens if
new one is a Dirac on an interesting
item so this guy gives me an interesting
item but he gives gives it to me only
once right i mean when i come back to
him it always gives me the same
interesting item so it's not interesting
to more to me anymore so this guy could
be super good for one time step and then
bad forever so there is this dynamical
aspect that was not in the previous
framework no no no it's just that it's
it's just regular set so meaning exactly
is that if you see twice the same
interesting item it doesn't count twice
it counts only once that's that's what
if if it wasn't like that it would be
exactly like the previous one but
because it counts on you want yeah it's
exactly its discovery you want to
discover it that's the problem of so we
called it a optimal discovery with
expert advice so now what can you do
well so what would be the optimal so
imagine you knew the distribution you I
what would you do what what would be a
simple thing to do what if you knew the
distribution new I you could for each
distribution estimate what is the
probability that you will get an
interesting item that you have not seen
yet ok so you could define this mi are
quantities which is the missing mass
which is the probability mass that new I
put on the set a where you removed
everything that you observed so far so
let's call this am I of T right so if I
knew what were what was a and new I I
could compute those things and what i
would do is just pull
the AG max I mean go to the guy that
maximizes this thing but I don't know
those those am I of T right but what i
can do is that i can estimate them so
this is a famous problem it's this thing
is a good ring estimator so it's it's
something very famous to to estimate the
missing mass so you can have an unbiased
estimator of this guy and you can even
have concentration inequalities and so
what you do is the algorithm that we did
is that you sample this guy plus a
confidant stem which is given by the
deviations so i'm going to show you now
some experiment that we did with this
algorithm so can i get the screen again
so is the algorithm sort of clear so we
for each expert we estimate the missing
mass and we add the confidence term
which is given by the deviations which
you can derive and so so now this is an
example so know so that so the miss em I
of T was if I knew the distribution but
then I can do the glittering estimator
which does not require to know the the
new int a what you do is you just
estimate for each experts you estimate
how many interesting items did I see
exactly once in my sequence and the
normalized quantity normalizes an
estimator which is a good during a
swindle so here I look at a problem
where I have seven experts so the qs q 1
equals 51-percent q 2 equals twenty-five
percent etc that the proportion of
interesting item for each distribution
so expert one as a priority mass of 51%
on the interesting items the
distribution of the joint and n is the
overall size of the problem so each
distribution is uniform on the set of
size 1 28 in this plot 500 in this plot
1000 in this one and ten thousand
so I've distribution which are uniform
on set of different size and they have
different proportion of these sets are
interesting and you see something is
going on right you can see this
convergence so what I put sorry what I
plot is a number of interesting items
that you found so this is time and this
is a number of interesting items that
you found the top is this Oracle
strategy that place the arms that
maximizes the missing mass this one is
our algorithm the second one and this
one is just uniform you just allocate
things uniform and you can see that we
have a uniform convergence of the number
of interesting items that we found for
our strategy as the size of the problem
grows so that's what we call we gave it
the name of macroscopic limit so as the
size of the problem growth our strategy
is uniform the optimal in time so this
is completely different from the
multi-armed bandit program so the
multi-armed bandit or the other one
before was i was looking at as n goes to
infinity here for any fixed and as the
problem size goes to infinity I'm being
optimal so it's it's a very different
kind of limit so this was for this joint
set of distribution this one is the one
with integers and prime numbers and ok
gives it gives the same we give we
obtain the same result so we have a CRM
and etc but I thought that time to
explain and so these are just some
references at the 2010 paper are with
the lower bound that this optimal
discovery and that's the book with
Nicholas choose a monkey on Milton
bandit program if you want to know more
about this that's it thank you
everyone so when you see the first part
you display yet so you haven't been to
us this H 0 ver lo que yes yeah and then
you said you would remove the rotate
that was changing the problem yes for
the problem with the permutations no
idea how to do it I saw the best problem
still there yes yes and then the other
bomb that you quoted from correct yeah
yeah yeah so that found was for which
problem with the only ship one of them
no so right so so the upper bound are
assuming nothing so the upper bounds are
when you know nothing about the problem
and still you can you can adapt at the
right rate so so the upper bound holds
for both setting if you want right well
what this theorem says is that at most
gives you an improvement in a log factor
but it could be no no we don't know it's
an excellent question maybe maybe with
the log it's ty I mean I don't think so
but it would be nice to have a better
proof for for the case where you just
have permutations but Jackie trick was
to change the problem so as to simplify
the proof that's that was the point yes
the road thousand here are the problems
sorry prom together yes so I say
something about a problem
right so the programming that
independent clowns are basically tribute
emits its immediate to get the optimal
one over scrotum rate there is nothing
really interesting to do there and
that's why despite the simplicity of the
program it has not been really looked at
in the past it's because this if you
look at it from the simple point of view
of minimax it's not interesting you have
to do something else than minimax to
make it interesting basically but people
in practice I've been looking at it
because in practice it's it's an
interesting problems that people face
know so I want yeah so originally so I
can just tell you something just one
thing which is this lower bound from
actually even before from 2009 if you
look at the simple regret right so this
was this things that could go
exponentially this thing i can now
abound it for any strategy by
exponential minus a constant times the
cumulative regret so if so optimal
cumulative regret our folder login so if
you are optimal for the cumulative
regret then you have a polynomial decay
for the simple regret so this lower
bound this was a start of the work
because it says that it's a completely
different problem minimizing the
chromatic regret on the simple yet if
you try to optimize for the community
regret you don't get optimal strategies
for the simple regret yeah start oh yes
oh sorry yes yes this is so for the
capital RN we know strategies which do
capital iron is smaller than some
constant times log in and
and for smaller n oh you mean small line
and not en is that is at your point yeah
no we don't know anything beyond
applying those strategies but I believe
that those strategies are good for
little errand I think those strategies
are good for the simple you get I just
don't know how to do a better analysis
and the trivial one no I think the be
yes but but I don't know how to prove
something beyond trivialities I mean you
can say trivialities but but anything
beyond I don't know thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>