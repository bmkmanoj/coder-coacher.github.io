<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Social Computing Symposium 2016: Post Screen Personas and Listening Machines | Coder Coacher - Coaching Coders</title><meta content="Social Computing Symposium 2016: Post Screen Personas and Listening Machines - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Social Computing Symposium 2016: Post Screen Personas and Listening Machines</b></h2><h5 class="post__date">2016-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/R1yUf7pIkmM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
anyway so what I'm going to be talking
about today is trust and cute machines
attractive machines all kinds of
machines that make us want to like them
trust them and it's really this entire
talk is in a way a question for you all
and mainly a provocation to get the
conversation going because there's I
think it's one of the biggest things
we're facing now is the rise of machines
that in various ways we cannot
distinguish from not necessarily
intelligent humans but sentient beings
of different kinds and this has been at
sort of at the heart of AI since the
very beginning in 1950 Alan Turing wrote
a paper called Computing Machinery and
intelligence in which he you know this
is a very famous paper you're all
familiar with what's called down the
Turing test in which he posited what was
essentially a game of deception where
his take on the question can a machine
think he said it's too vague there's no
way to answer that and he said if
instead we could have machines where if
you play this form of a parlor game you
can't distinguish the machine from the
human that at that behavior level is
what we should care about or it's at
least what we can care about and if
they'd come indistinguishable we'll have
to just think of them as intelligent and
following up on that a the game Eliza
was created by MIT professor joseph
wisin bomb and Eliza is as probably many
of you know a online psychotherapist but
wisin bomb was not making the
psychotherapist to prove that you could
do this kind of that he was doing it to
prove that you could do it easily but
his point was that you could do it so
easily you could make a machine that in
this is in 1964 so this is a very
primitive computer program that
basically it was framed as a Rogerian
psychologist you would type something at
it it would respond sort of as a
psychologist would and you could have
this dialogue going and his point in
doing this was so that people would say
oh yes you are right language it turns
out
is not really the right metric to make
this measurement into whether something
is intelligent we should think of this
as irrelevant we've proved this point
but instead it quite backfired on him
and people for instance first his
secretary insisted he leave the room
when he was corresponding with it
because she said I'm having a private
conversation please stay away people
love this psychiatrist they like talking
to it they like this interaction he was
so horrified he never did any more
computer programs spent the rest of his
career he wrote a very interesting book
that's still quite prescient called
computer power and human reason in which
he said warned about the sort of coming
apocalypse of a world in which computers
became more important and they were all
being built by people with no social
skills but anyway so but you know if we
go fast forward now this notion of a
computer psychologist is still very
active I recently gave a paper to a
presentation about this to the annual
meeting of the psychoanalysts
Association which one waves fasten
excitedly talked to tech audiences
you're all sitting up there y'all typing
and everything's a very different
feeling when you look into a room of 90
psychoanalysts because they listen very
very carefully oh well I've never had an
audience that just listened so well it
was a little intimidating so the morning
was like a couple of people speaking in
the afternoon they all watched her
together all the sex scenes from her and
discussed it which is fascinating but
this is yeah this was another slide you
know I talked to you about them this is
like a a now we're doing somewhat more
intricate online psychoanalysts the
eliza program was based on the Rogerian
model where they just sort of answer you
back by turning your questions around
it's not the most sophisticated one but
now they're building sort of CBT based
psychotherapy programs there's a very
good side of it a lot of people who
could use therapy are not cannot afford
their in rural regions so a lot of the
questions I'm asking here is it's very
easy to say this is horrible this is
scary but you know here it's looking at
you it you know here's the part of the
slide on this side of showing the
division system behind it is there you
know there's also we
very good site these can be really
really helpful interventions so a lot of
the question here and the other side is
you know if you're sitting in a room
paying a psych psychoanalysts two
hundred dollars to listen to you what
are they really thinking you know what
is the value of it actually being a
human being what if the human being is
actually sitting there thinking oh my
god this is the most boring
self-absorbed person ever I can't stand
them yeah if that's what the
psychoanalyst is actually thinking
though they've been well trained to hide
it maybe you know are you better off
which is something that can
algorithmically correspond to you and
say something useful what is it for if
we're going to say we really want that
human relationship what is it that we
care about in it and so that's the main
provocation I want to think about today
is to the extent that we can look at
some of these machines and say oh we
want the real thing we want the real
human we want the real sentient being
let's think more deeply about why we
want that so this is sort of because i
think this notion of what's between
being human and proving that you're
human knowing what a robot is sort of
like the key 20 essed that we're going
to be dealing with in the 21st century
and why do we care just another way of
thinking about this issue of why we care
is we are surrounded everyday we're used
to dealing with people in a service
economy that's a lot of you know man how
many of you have worked as a waitress
yeah you know or some other service job
where your job was about faking an
emotion you did not feel you know you
don't I don't go to a restaurant
thinking I really really want to know
what you're thinking of me which might
be like a table full of like 350 old
ladies like they never tip well I hate
them yeah but you know but what I really
get is like what a wonderful choice you
know we live in a world where an
enormous number of our interactions are
not actually all that straightforward
and would we particularly want to live
in the world where they are and I think
these are the frameworks we'd not and
think about behind these robots this is
pero is being developed it's a robot
seal the kind of person responds it
doesn't have word
but it's a very it's like a stuffed
animal much more responsive it can curl
up around you etc so it feels much more
like the affection of a living being
when you when they were first introduced
they were introduced as a children's toy
and there was a lot of nervousness
around that people didn't like that but
now they're being used there put out by
Japanese company and the idea is that
they're being used in nursing homes
where you have these elderly patients
with dementia it's found that if there's
an animal around they do much better but
they're completely incapable of taking
care of an actual animal so what are the
ethics behind using something like pero
in this situation where you are truly
faking someone they may well think that
this is a living being that they're
responding to it helps them and you know
it helps settle them down and everything
it's fake it's not but an animal
wouldn't necessarily benefit by being
held by this person and I think a lot of
the questions here for instance with
with artificial animals really force us
to think about our relationships with
pets and animals in general is are we by
moving into a world where the animal
where is taken care of is fake is this a
wasting of human emotion are we wasting
affection are we learning to lavish
affection on a creature that doesn't
benefit from it or is this a kindness
what if you have a three-year-old who
tends to pull the cat's tail is it
better that you have a artificial pet so
when again do we care about what's real
and where the benefit is Tamagotchi is
like sort of a very early artificial pet
you know for those these were for one
they're really interesting note on how
easy it is to really really care about
the life of a nonliving thing because
basically the comp time ago to is this
little pocket pet that you had to pay a
lot of attention to you had to click its
little button to feed it to clean its
little environment etc and if you didn't
do this this is also the difference
between the Japanese and the American
version the Japanese version it would
die and it would not come back to life
the American version we don't we don't
really deal with a half
endings that well so they would
eventually come back to life but you
know it would eventually die now some of
the interesting pieces here are are you
teaching kids that Oh things that really
die it's all just a game haha you'll
just get another one or are you actually
teaching responsibilities with it if you
have a child that's sitting at your
Thanksgiving grandma's here we have this
kid who has to get up every three
minutes to go feed their Tamagotchi on
the one hand are you saying here's this
game that has found a way to just move
itself into every dimension of life and
this is a horrible disruption and I
don't care if your game dies do you have
actual human beings here at the table
that you should be paying attention to
it's ridiculous that your privileges
artificial being over them or are you
saying I can't give it that this child
this message because this is like a
training ground and I want them to be
responsible I don't want them to think
oh well let's not feed the chicks and
okay they'll die but I wanted to go on
vacation that this is like a training
ground for caring about a living thing
so a lot of it is the framework in which
we put it put these creatures to
understand what kind of lesson we're
trying to draw from them and as you know
we have a long history of manufacturing
things to be cute um you know and it's
something that this kind of that sort of
neonatal look so we've had a lot of toys
it's not like adding robotics changes
these things we don't get freaked out
usually when a child loves a teddy bear
and part of the difference with the
intelligence though is that line of how
fake is it because with the teddy bear
once you're you know beyond the age of
three we're at the entire world is sort
of a weird psychedelic trip I think for
the experience of the child they get
older you understand the difference
between a doll and a real person or
between a stuffed animal and a real one
and that a lot of it is about a game of
imagination that at some level the child
knows it's about building imagination
which it's hard to know where power 0
falls in but as you get animals that are
increasingly designed to be interactive
when we add the intelligence and the
interactivity where that imagination
comes in is a little bit different and
where the belief that there's actual
sentence in that thing is different and
understanding the effects of that is an
enormous question now and that's part of
what one of the questions I want to
throw out to you all for discussion is
what is the change when the intelligence
and the interaction is coming from the
creature from the physical thing itself
and it's not something that's coming
fully from the child's imagination just
on the love of cuteness this is this is
a cat I really like cats but if you look
at them they have also we've effectively
evolved we look at the difference
between a lion and a cat a lot of it is
that the cat over time has evolved to
have these like these cute features this
roundness its interaction there's great
work that's been done with wolves and
dogs there's a Russian experiment that
if you haven't heard of it's fascinating
they tried to breed wolves to be nicer
just what happens if you keep reading
the nicest ones it turns out that if you
keep reading them for personality they
also end up having neonatal faces and so
they ended up with bigger eyes and
smaller chins and everything it's been
wolves and with foxes that kind of
cuteness certainly has been used by
marketers for a long time and it's very
very disarming again here is a machine
that's been marketed as being cute it's
not an intelligent machine but it's
certainly been very effective at the
marketing level but now we're moving
into the world where this is a jebo that
is being marketed as you know sort of a
personal lifestyle assistance that will
live in your house but it's you know a
listening machine but it's a very
disarming listening machine because yes
I'm said last night a lot of that
cuteness is something that we have
evolved to be disarmed by you know
babies are not all that nice but if we
didn't like babies as a species we
wouldn't last very long so we have at a
very very deep
level in affection for things that have
big eyes little button noses that kind
of little chin so what we're dealing
with now are machines that instead of
using words to help us to train us to
react to them in particular way use this
kind of neonatal look and so when you
look at something like this it brings
out its every trick that you can do to
say trust me I am innocent there's
excellent work that's done by a
psychologist named Deborah zebra wits I
Brandeis where she has looked at what
she calls the over generalization of the
baby-faced effect and she looks at for
instance in court like how much just
having to have the facial structure of a
baby will make you be seen as much more
innocent in particular in court cases
etc we've already mentioned today hello
Barbie but hello Barbie also has a
listening machine as mentioned earlier
is recording a lot of children's voices
so here one of the trust issues is you
have this kind of trustworthy looking
being who you are confiding all kinds of
things to its taking those words and
moving them somewhere else and then this
is I think why Kate invited me back to
and give this talk it's because that our
previous talk I said these are the deep
sea angler fish of technology and this
is an angler fish has is a creature that
has evolved to have something that looks
like a small delicious treat at the end
of its of a little spine that it has and
so it attracts other animals with its
own little angler and then it comes and
eats them and so I think there's a level
where if you make something that's
disarming and cute enough to in order to
get you to interact in a particular way
in order to gather your words and use
them elsewhere at what point does this
go from being a very very helpful
assistant to being a computational
angler fish and just a couple more quick
examples of some of the things we want
to think about
in terms of trust this is work that was
done obviously several elections ago by
Jeremy balancin but what he was
interested in is how if you take a
person's face and you more fit with for
instance a presidential candidate so
that in state you can ask them what they
think of the candidate when they're
looking at a picture of the candidate as
themselves but when you take a morph of
the candidates face and the person's own
face people don't necessarily notice
that their own face has been morphed
into the candidates face but they then
find the candidate much more trust
worthy we tend to trust people who look
like us so when he was doing this it was
very interesting but this types of
technologies that we have now hadn't
permeated the population to quite the
extent they do now but just think of it
given that almost all of the messages
that we receive for instance from
politicians are targeted it's very easy
for them to be targeted with something
like this it says not only with the
words they use so that they can target
your words two things you're interested
in but even target how they appear so
that you will find them much more
trustworthy so our understanding of what
are the things that we need to think
about in terms of how we perceive the
world how we perceive trust our growing
and this is just something because I
thought you should see it this big your
next trophy wife one hundred percent
titanium just to remember it's not
simply cuteness that is disarming but
sexiness that's disarming as came up
recently with Ashley Madison when it
turned out that most of the people who
actually wanted to have a tryst with
married you were actually machines and
so I'd like to leave you with a quote
from Harry Potter which is Ginny said
mr. Weasley flabbergast lamberg acid
haven't I taught you anything where what
have I always told you never trust
anything that can think for yourself
you can't see where it keeps its brain
thank you thank you so much enter the
computational angle of fish we're coming
up on time I'm really sensitive to the
fact that that meals are important but
there is so much to talk about here that
what I'm going to suggest is that we
move in to start eating delicious things
and continue to ask questions of Judith
of Suresh of Tim of Dennis of everybody
on this panel and continue the
conversation while we eat thank you so
much if you could thank all the
panelists that would be grand</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>