<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>IMS-Microsoft Research Workshop: Foundations of Data Science - Graph Cluster Randomization | Coder Coacher - Coaching Coders</title><meta content="IMS-Microsoft Research Workshop: Foundations of Data Science - Graph Cluster Randomization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>IMS-Microsoft Research Workshop: Foundations of Data Science - Graph Cluster Randomization</b></h2><h5 class="post__date">2016-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/te6GxNO2HzE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
the last talk in this session will be
again on really important experimental
design issues it's presented by Johann
Uganda who is a postdoc at MSR and
heading off to Stanford next year and
he's going to talk about some work he
did it at Facebook looking at trying to
design randomized experiments in cases
where manipulating one observer may have
spillover effects to others and I think
IDO we'll talk about some of that
related ideas in the session on
computational social science so I'm
going to start with it so when you're
considering a complicated problem you
should always take the simpler version
make sure everybody is on that page so
maybe testing is randomized trials in an
online setting so you're trying to sell
a flag and you're interested in you have
this debate among engineers and
designers that maybe the buy button
should be green or yellow and so you
take a big population of users and you
flip a coin and you give some of those
users the version with the green Buy
button some of them the version with the
yellow Buy button and then you measure
the purchase rate and you put error bars
on it and you decide whether you want to
move forward from that from that sort of
data-driven decision-making approach so
this gets a lot more complicated in
social networks where you have all these
different users and you're running
various sort of your variously modifying
their web experience via various
experiments on either the layout or
actual sort of under the hood algorithms
that are doing ranking and when you sort
of assign these types of treatments to
the users via flipping coins let's take
a really egregious or a very complex
example you want to launch a new video
chat feature on a site like Facebook the
problem was running an a/b test the
video chat in this scenario is that
you're then going to sort of if you're
going to try and measure the behavior of
the users that have video chat versus
the favor of the users I don't have
video chat you have users
have video chat would have no one to
talk to so it's very important that you
respect the social nature of the product
change that you're trying to launch in
these types of contexts and ideally
there's sort of this fundamental problem
or causal inference that has come up
earlier that you have these two kind of
universes that you would like to compare
the version where nobody has video chat
in the version where everyone has video
chat but you can't observe both these at
the same time so you need to do some
version of counterfactual reasoning and
you know maybe you're interested in the
average treatment effect which is what
is the average time on site in this
world versus the average time on site
and the other world and you can't really
get that without kind of having access
to different universes so this is a sort
of ubiquitous problem and lots of social
web social media contacts you're doing
product changes in a sling like Skype or
you're changing pricing plans and cell
phone networks like orange you are
affecting social product design and
products like skype Foursquare linkedin
people you may know ranking algorithms
you have market mechanisms like the auto
add auction problem that Leon was
talking about you have Airbnb has
inventory problems odesk is the labor
market with some of our inventory
problems when they run experiments and
then in Facebook and Twitter you have
the newsfeed algorithms actually have
huge spillover effects where if you
improve somebody's newsfeed you improve
their engagement they end up producing
more content you end up actually seeing
effects of the treatment on a user on
their friends so these are all kind of
various versions of sort of spillover
effects in experimentation problems in
online settings so there's I want to
talk now for a few slides about the the
mechanisms that one can think about in
these types of settings so we're going
to this kind of panel view where y is
the responses at time T and sort of
stacked in time and Z is the treatment
of some intervention that we're
considering and this is a very very
small version of Facebook and if we have
this person here in the middle we could
say that okay here's something that's
maybe reasonable we're concerned that
the treatment
of the other person's response depends
upon their treatment and also the
treatment of their friends so in order
to appreciate video chat you need your
friends to have video chat now this is a
simplification because really a lot of
these types of problems flow through
behavior so you're actually oftentimes
not responding to your friends treatment
but you're responding to your friends
behavior which leads to long-range
dependence which means that it's no
longer after any sort of any amount of
time it's no longer just about your
friends behavior it's about the behavior
people several steps away from you and
potentially the whole network and you're
back to this problem that you only have
one network and these two settings where
when you're sort of willing to view
things as a so there's a treatment
interference versus a behavior
interference are quite different beasts
where there is sort of more possibility
of success in the treatment scenario
than in the behavior scenario so here
you still need to model some version of
sort of the human behavior of what is it
that affects your behavior is it do all
your friends need to have video chat do
some of your friends need to have video
chat but in this setting you need to
sort of model contagion in really
complicated ways in terms of product
adoption here if you're willing to make
some assumptions you can get unbiased
estimators here you're wrestling a lot
more with bias variance trade-offs and
to give sort of just a pointer to the
flavor some of the more technical
version or contents of some of this work
that I'm doing in this setting if you're
willing to make sure to monotone
treatment of assumptions you can start
to bound the bias and variance you're
willing to assume that when everybody
gets this product they only increase
their adoption if they go in different
ways then the variously the arithmetic
becomes a lot more math becomes a lot
more complicated but I'm mostly going to
talk about this context as an
approximation of this context today but
I also have worked on this problem
explicitly so there's a subtitle in this
talk which is about design and analysis
which are these two opportunities to
kind of get somewhere on this problem if
we have this this network as I hinted at
before
one of the problems is that this person
here doesn't have and you want to talk
to so one approach would be to say okay
let's focus on the users who are
surrounded let's do iid coin flipping
let's focus on the users where they have
the product that all their friends have
the product but the problem with that is
that when we did this coin flip on this
network the only people who ended up
having all their friends also having the
same product as them sort of properly in
treatment the sense of Bay a video chat
and all their all their friends at video
chat and this person's in control and
everybody they know is in control is
that these are the really low degree
users these are the users that only one
front so you're going to know if you go
down this road naively you're going to
go end up making decisions based on
people who don't have any friends Kurt
and that's not a great way it's a sort
of updates to true choose the direction
of your of your enterprise if you're a
company like Facebook or any other
social product the other side of this is
that you say okay well I know how to
solve that problem I know how to cut
graphs so you say okay I'm going to flip
these coins in a correlated way and I'm
going to say ok let's give treatment
let's find a good graph cut let's give
let's flip the coin and give treatments
one half of the graph and control to the
other half of the graph but that's
actually not that approach at face value
is not a very good approach because you
have really strong correlates of network
structure so a lot of the times network
structure follows from something like
geography and if you run these
experiments in the US you would end up
using something like the Mississippi
River to as you're dividing line and
this find this great graph cut and then
you're going to be effectively looking
at an average treatment effect where
you're comparing the East Coast and the
west coast or variously the west coast
and east coast and you have a very huge
bias in terms of the the populations and
treatment and control are very different
so the question is then how to cluster
how do you how should you do this type
of clustering if it seems like a good
idea so I'm going to to in order to talk
about how analysis and design kind of
make progress on the problem i'm going
to lay out some of the basic notation so
if we have a treatment of a person just
sort of this index i zi is either one or
zero if they got if they get a product
or if they don't and their response is
that
for example they either spend 60 minutes
on the Saturday or 45 minutes on the
side a day and then we have this sort of
two universes that we can't observe
quantity that we would ideally like to
estimate sort of an average treatment
effect and the a/b testing approach is
that we do I ID randomization coin
flipping and we look at sort of the
people who showed up when we flip these
coins when the people who showed up with
one and the people who showed up 20 and
we do inverse probability weighting on
what we actually saw in treatment or we
actually saw in response and we have
this sort of this estimator of the
average treatment effect so that is not
no longer sort of an appropriate
approach when you have these really
complicated network effects and the
basic gist of the approach that I've
been working on for this is that you say
well let's actually rather than having a
person be in treatment when they have Z
i equals 1 let's look at which part of
this 01 vector are they responding as if
they're in treatment so for what what
sets in the 01 sort of vector of all the
possible ways you can assign their
friends are you responding as if
everybody was in 0 oh I flip these sorry
and what what instances of the 01 the
back of the assignment vector are you
responding as if everybody was in
control and this is sort of the natural
version of this is to say well it's when
all your friends are in treatment and
and you're in treatment or all your
friends are control and your control but
there's there's there's choices there
and there's different ways you can
approach that problem based on how you
think the behavior goes for example if
one of your friend has a highly
infectious disease that is very
significant if you're looking at an
epidemiological context it's not just
about all your friends don't have to
have a very infectious disease for you
to be worried about hanging out with
them so so the question is done sort of
what how does the the behavior becomes a
very important part of sort of
approaching this problem in performing
these estimations now simply speaking
once you have made this decision of what
you think is a good approximation of
when somebody's in treatment when their
network exposed to treatment in the
language we use you're just changing the
estimation problem to saying okay I'm
going to pay attention to them when they
are when there's the
when Z fell in the in that set of
vectors that they are sort of
approximately not expose and then I need
to compute the probability of z being in
that set so what's the probability of me
having more than eighty percent of my
friends its treated or having more than
a person my friends and control
computing those probabilities is a is a
tricky part of this problem that I'm not
sort of giving a forward point or two
but essentially that's the that's the
whole meat of trying to look at these
experiments when you're on networks
where you're interested in not just your
own treatment rather to those treatments
and then understanding what these
probabilities are under more complex
clusterings where you're not just doing
iid randomization so I said I was
alluding this concept of kind of network
exposure we're really normally we have
treatment and control and you're in
treatment if you're treated and you're
in control if you're in control or in
the control condition ah being in
control is something else so this
concept of being sort of network exposed
to a treatment or network exposed to
control two basic versions is that
you're fully neighbor your full
neighborhood exposure is when you're
exposed and all your friends are exposed
so a fractional version of it is you're
exposed and eighty percent of your
friends are exposed there's much more
complicated exposure conditions that you
can come up with and are I think very
interesting and analyzed but are only
more difficult than some of these more
basic versions that we have been able to
make progress on for example this person
this person here has two other three
friends in the treatment condition so
you say okay they you know most of their
friends have video chat that's great but
the problem you could think about this
is that well but one of their friends
what doesn't doesn't satisfy this
condition they are only only half of
that person's friends have the video
chat so even though this person is sort
of sixty-six percent sort of exposed to
the treatment this person is much less
exposed and is that person really going
to adopt the whole video chat product
because that person did and actually
this maps into sort of understanding
what the probability that somebody is in
the cake or
River graph and fractional k cores for
heterogeneous degree graphs and things
like that and so understanding what the
probability of that happening is sort of
this interesting discrete probability
problem that comes up for trying to
understand these types of experiments so
that's how you can analyze now the
question is okay so how do you design
with respect to the fact that you're
looking to surround people and
understand sort of that probability of
you being network exposed you want to
make that as large as possible how do
you design for that so here's a really
good approach use new zealand and this
is actually how a lot of companies solve
this problem it is yeah so it's
english-speaking it has a pretty good
graph cut its media doesn't talk too
much to the US media but you do get sort
of in the in the tech-savvy news you get
headlines on TechCrunch like Oh reports
coming out of New Zealand that there's a
change in the sort of lay out of
something definitely come up because
because this is a really hard problem to
solve and it sort of the the
generalization of this though is that
hey actually geography is a pretty good
embedding of a large-scale social
network and variously how can you sort
of cluster this graph at a fine level
and at what level should you cluster the
graph should you use countries should
you use cities should you use high
schools should you use pairs of friends
to cluster where but the two extremes
you have iid randomization which is a
factor two approximation to max cut so
you're cutting is a lot of edges and at
the other end you have sort of the min
cut which is sort of the Atlantic Ocean
and where between those two extremes
should you actually run your
randomization is sort of one of the key
problems in this in this design space
that on the one hand you have you want
to surround people on the other hand you
have geographic correlates and other
attribute correlates
do the site the London lives based on
our yep so and actually you might want
to find some that's orthogonal to
geography because you're concerned about
that or as soon as you start using
geography you also start introducing
things like the latency to servers are
very different and if you're using
European users in one case you might
only be seeing the effect that I did
their connection that the servers are
slower in this yeah so geography is a
good starting point but the better
version is to use graph various graph
clustering techniques that can do things
like go against geography absolutely but
roughly speaking once we have these
types of clusters in this approach we're
forming the clusters and then we're
flipping the coin of the hope for the
whole cluster at once and then it's this
very tractable tractable problem of
asking okay this individual this was the
small Network we ended up with four
clusters what's the probability that all
their friends got assigned and that's
just sort of P to the number of clusters
they're connected to fifth or everybody
if you're asking questions what's the
probability that eighty percent of this
person's friends got assigned then it's
this dynamic programming problem that
you can solve without any major
difficulties even at scale because it
paralyzes across just the local
neighborhoods of all of the entire graph
and then you say okay rather than using
geography can we use more advanced
highly scalable graph clustering
techniques and this is actually the
approach this is how I came into the
problem because that's something that I
have worked on a lot before for sort of
infrastructural challenges at Facebook
and other things like that so you have
sort of label propagation and global
propagation with constraints you have
sort of large-scale streaming algorithms
these are all great approaches to
clustering really really large graphs
sort of the really really really large
graphs context another thing that's
highly scalable that we analyzed in some
of the sort of theoretical aspects of
this work is just using kind of
basically epsilon nets or two or three
nuts clustering the graphs greedily and
if you make some restricted growth
assumptions diving into a gun technical
literature you can bound the variance of
the estimators under that assumption
because if you use 3.net clustering you
can guarantee that people aren't
puttering too many clusters independent
of their degree so
that's that's very useful I think that
one of the things that I think is really
interesting here is that there's a huge
literature on community detection and
graph clustering that has had a slight
identity crisis over the last few years
of what is the actual objective as
people got better and better at this
people started wanting okay well in a
lot of these settings or what is the
community etc for me an interesting sort
of large gap project is to ask how do
these different clustering algorithms
work and experimental settings which
sort of you applying community affection
for in experimental design of these
highly clustered experiments and it also
kind of plugs into a large scale
framework the way that I like to think
about this at a high level is the whole
process of running an experiment on
network is to say okay step one create a
social network with 1.5 billion users
but sort of you know you have some graph
that you're you're handed and then
you're done yo this is design
opportunity to sort decide how you do
the assignment do you do it I ID or how
do you most generally how do you
correlate assignment across the graph
the subset of correlation structures
that I've been working with is how to do
partitioning and then flip SI make
assignments sort of one partition of the
time but most generally you could look
at other correlations and then you sort
of run the world the outcome generation
process where people behave and this is
a process that is very complicated and
then after that you try and discern who
was really exposed based on how your
design came out and look at their
responses and try and understand what
would happen if you turned on the a for
the whole graph or turned on be for the
whole graph and various results boil
down to reducing the bias and the work
that I'm doing on the problem blow now
it's reducing the bias in the variance
some time going to close with a an
example sort of a case study that on
something that I worked on while at
Facebook which is in the status update
prompts on facebook there's this
question of what's on your mind it's
been there for a while and on
Thanksgiving in the year before I worked
with Dean on those vehicles at Facebook
and Brian car also Dean had said on
Thanksgiving
you run an experiment Thanksgiving where
he replaced it with what are you
thankful for and he saw that a bunch of
users you know their news lots of people
both in the treatment condition so he
flipped a coin I ID and half of the u.s.
received what's on your mind and half
the people in the US received what are
you thankful for and then he saw both in
the treatment condition on in the
control condition huge amounts of status
updates about being really thankful and
the problem with this is that well we're
people in the control condition was
there a huge increase and how much they
were talking about being thankful
because of thanksgiving or was it
because their newsfeed was totally
overblown by behavior from the other
treatment condition because half of the
US was being prompted to talk about
being thankful so he said okay can we
somehow separate these two worlds where
we create clusters of the u.s. that
receive what are you thankful for and
clusters the u.s. they receive what's on
your mind sort of as the control
condition and one of the tricky things
about this problem in practice is that
it grabs like Facebook are very very
dense they were relatively speaking so
we were actually looking at the
interference graph that we considered
was just people who saw each other in
news feed not the full social network so
if you it's also a directed graph and
there's other things that's nice about
that because there's a symmetries that
you can look at specifically use some of
these advanced algorithms to create a
lot of clusters have this unique
opportunity to be able to use P equals 0
point 5 usually when you're on
experiments you only get to sort of
assign one or two percent to a treatment
condition but here we could really
started go 5050 and then look at how
people responded to these two treatments
as a function of how they were exposed
so we actually were interested in
something more subtle than just the
everything off everything on condition
because Dean who has studied pure
effects variously in a lot of context
was interested in kind of a causal
causal answer to some of these difficult
questions and we were looking at the
difference between the direct effect
I've sort of asking the person what's on
your mind and the indirect effect which
is asking everyone else what's on their
mind we're asking everyone else what did
it thankful for and then the the two
universes that I've been talking about
for most of this talk are the two
corners but we're also interested in
direct versus indirect effects and
in this clustering algorithm if you were
in the thankful case most users out of
this sort of top 10 newsfeed friend
graph had this is a y-axis is
logarithmic so most users had sort of
the majority of their friends and
thankful and people were in control of
the majority used as control ideally
this graph would sort of look that if
you are in control like friends finger
trolling through and treatment or
friends winter feeding but this just
sort of goes to show that these graphs
are hard to cluster and you don't get
there but you still have a million
people surrounded in both of the cases
so you have people in the in the corners
absolutely and then you get this was one
of the versions of the results from this
which is sort of the y-axis is the
probability of using thankful words in
your slot your slides in your in your
status update and the x-axis is the
number of peers that have been assigned
and the pink line is the thankful
condition and the black line is the
control condition and you see this
strong direct effect and also sort of a
week indirect effect where one of the
difficulties with this the size of the
dots is the number of people in each of
these cases and one of the tricky things
about this is actually there's
computational difficulties on getting
error bars on this craft that I can that
I could talk about at length but I'm not
going to but I want to include with sort
of an opportunities overview because
that's actually how i do this area right
now there's lots opportunity to apply
various graph clustering and community
action ideas to experimental design on
networks there's kind of statistical
theory opportunities to understand and
characterized by experience trade-offs
of these estimators there's
computational challenges on how to
compute various exposure propensity zand
really their probabilities on these sort
of in these more complex exploration
conditions like what I talked about k
cores and most generally graphs were
becoming increasingly important for the
types of response that people have to
the designs of social systems and so how
can we understand sort of develop graph
matching techniques for how people are
responding similarly under more general
views of how they are positioned with
respect to a global treatment and things
like that so thank you in questions
so I guess this is a question about this
Thanksgiving sorry got that one it seems
like you can do these these rap
clustering techniques but at the end of
the day it was very strong effects as to
what occurs in your newsfeed yeah and it
seems like what you're gonna you know
taking the kind of econometrics that's
how you use some sort of regression
where you condition take some person
look at us in a number of friends that
posted in the feed and look and see if
you know which question they were asked
it and you're going to try to just do
some regression and look at the
coefficients to try to see which one
significant and and it seems like you
know all these tests that you and if you
split things in half like you're going
to do some regression like really that
they would Mississippi or one side of
Mississippi River versus the other this
correctly boy what you could potentially
try to do is look at this set of
coverage you're gonna correct for and
cluster based on this sort of split on
the things that you might think of as
causal effect yeah absolutely so I guess
one of the ways that I view the
clustering is that you're increasing the
kind of the dispersion of how many peers
were co assigned and sort of in in the
worst case for everybody is 100 friends
you and you were do 50 clustering you
get some sort of concentration where
most people and very few people had
anything other than between 45 and 55
kind of trends treated and then your
regression would you'd have a hard time
extrapolating out of that range when
you're running kind of regression on how
many peers were assigned or something
like that so that in that sense I agree
with the huge utility of all those
methods and in in the application of
those I still think that these types
tick introduce field because they kind
of put more people and more extreme
conditions as and then you put done you
need to correct for the fact that high
degree people are harder to surround on
crafts and things like that so you use
some of these probability things to
correct for that but yeah all those
techniques are super useful let's take
one last quick question and then we can
take a break in and
talk about all the talks during that can
you go one slide back yes yeah so you
you mentioned this this effect is a
strong effect between these two curves
um now if you look at the numbers it's a
twenty-two percent versus seven point
six percent so can you explain by that's
a strong effect some people might say it
snowed like yeah sure so that would be a
matter of n is huge and the the so the
I'll speak briefly about the error bar
question so one claim would be 0 but all
the air bars here at huge and all their
bars here at huge and is this really
affect um the direct effect we've been
able to clearly bound as very very
statistically significant I mean this is
then then your your point is well-taken
that a lot of studies and social media
have such a large end that they can
claim statistical significance about any
effect and technically we didn't
pre-register hypothesis with an outside
agency etc so you have your you're well
founded and having all sorts of
questions about that the the harder
error bar is actually a the sort of
across the different directs the
different amounts of peers a sign
because you have two outer bound the
vert the variance and those are
conservative estimates and work and side
about that ah that but it's a sort of a
valid claim that we're seeing ultimately
what is a small effect but I but it's
it's definitely there so I guess my
question is for these type of network
problems is an effect of point four
percent it important um it could be a
hundred million peak yeah yes the regs
I'm gonna do the not to reference it too
loudly but the the emotional contagion
study which was a newsfeed experiment
there the effect was very very very
small but they had sort of an end that
was so large that and part of the
questions about why there is much
controversy over was that the effect was
sort of incredibly small what are we
actually concerned that I would within
the category of kind of results that
I've seen Ron
when the experiments were done in news
feed I wouldn't do this to be a fairly
sizable effect and it was about
understanding sort of here is an example
here's a kind of model problem for peer
effects are people actually saying
things based on what they're seeing in
their newsfeed was the real question so
then it was really we're trying it's the
indirect effect that we were trying to
understand and that's why it's sort of
the lack of the difficulty to analyzing
the error bars there is the more they're
there I don't have a solid claim that
people are responding to what's what is
in their newsfeed but they are
responding to this little prompt so
let's thank you johanna and the three
earlier speakers we have a break now
until 11 20 each year microsoft research
helps hundreds of influential speakers
from around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>