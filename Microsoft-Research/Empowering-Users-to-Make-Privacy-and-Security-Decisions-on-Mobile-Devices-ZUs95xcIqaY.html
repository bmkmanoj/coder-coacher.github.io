<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Empowering Users to Make Privacy and Security Decisions on Mobile Devices | Coder Coacher - Coaching Coders</title><meta content="Empowering Users to Make Privacy and Security Decisions on Mobile Devices - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Empowering Users to Make Privacy and Security Decisions on Mobile Devices</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZUs95xcIqaY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
good morning everyone highs my pleasure
to welcome back Sergey ego men and
Sergey we all know him very well he
interned here twice and he's a frequent
collaborator with some of us and today
sir surgery is intervening with the
security privacy research group and he's
going to tell us about his work over the
past couple years UC Berkeley as a
postdoc thank you sir thanks for the
introduction I was going to preface this
with so this is mostly work that I've
been doing over the past year and a half
at Berkeley looking at permissions on
mobile devices and helping users to make
better decisions about how they grant
third-party applications access to their
personal data Helen graciously invited
me to speak about this in July and so
I've been agonizing about what to what
news data to put in here whereas what
background information to leave and so
I'll warn you for those of you who saw
the talk in July that the first 20
minutes or so might be a repeat so feel
free to take a nap and I'll wake you
when i get to the new stuff that works
too um so just step back for a second so
most of the stuff that I do is within
the usable security space and what that
means is I try and solve computer
security problems by designing
interfaces that are better suited for
humans so applying HCI methodologies to
solve security problems and within that
space they're generally to recognized
major problems that we see frequently so
the first problem is there are a lot of
unnecessary security interactions and
these result in habituation what that
means is people become accustomed to
seeing lots of security information that
they otherwise might not care about to
the point that when they see the
information that they do care about
their use to just swatting it away the
second problem is frequently users are
asked to make decisions that they're
simply unqualified to make so that's
another big problem and a lot of the
solutions to these
though can be learned from looking at
the classic hazard avoidance literature
and so looking at that we see there
really three different ways of dealing
with hazards in order of preference so
you know in the best case when we can
eliminate a hazard we should do so that
way there's nothing really for the user
to fall victim to or anything extra for
them to do if we can't do that we should
try and mitigate the hazard in some way
and then in the you know the worst case
if we can't do any sort of mitigation
we're stuck with warning the user and
frequently what we see within the
computer security space is that we jump
to the third one warning when we could
probably be doing other things that are
preferable and so looking at the mobile
space why is mobile interesting well
fifty percent of the US population has a
smartphone which means that they have a
mobile device which has the ability to
install third-party apps and you know
these apps can take advantage of all
sorts of sensor data which create really
rich user experiences but with great
power comes great responsibility we see
threats such as malware and gray we're
so malware unwanted apps that can cause
damage so taking your personal
information may be holding your data
hostage stuff that users don't want on
very devices but that's pretty rare
since most of these marketplaces are
centralized when that stuff gets
identified it's removed quickly and
pulled from the users devices more
frequently what we see is grey ware so
these are apps that users actually
desired they intentionally installed on
their devices but the apps might be
using data in ways that were unexpected
to the user and so the question is how
could we make them aware of this so
looking at one scenario say user finds
unexpected SMS charges on ver bill they
suspect an app might be responsible what
could they do to determine what app is
responsible so here's a screenshot from
Android a lot of this work was done on
Android but I firmly believe that the
results are generalizable to most of the
mobile platforms out there so the first
step would be you know selecting the
menu brings up all the apps and now we
have to find the Settings app they
scroll down click the Settings app it
brings up this whole new screen they
have to know the to click the
applications sub panel which then brings
up more information to read they have to
know to click manage applications and
then that brings up a list of
applications on the device and then they
have to sequentially go through app by
app bringing up those app settings
knowing to scroll to the bottom to see
the list of permissions that that app
has been granted and so ostensibly the
user would do this for every single app
on your device to determine the subset
of apps that have the ability to send
SMS messages and even then once they've
done all that it's not clear what app
was actually responsible if they've just
narrowed the list down so there's a lot
we can do to better convey information
about how apps are using their data so
in the talk for today it's going to talk
about some of these problems with the
current choice architecture is how users
make decisions about what apps do with
their data how we can improve this by
applying some better intelligence in
terms of choosing permission mechanisms
and then finally showing that in some
cases it's much better to simply beg for
forgiveness than ask permission and then
I'm gonna talk about some future work so
with regard to the current problems we
did some work about a year ago looking
at whether Android users understand
permissions on their devices so we did
this online survey of little over 300
actual Android users we were sure the
fairy Android users because we recruited
them using AdMob so that we could be
assured that they were seeing the survey
on their device because we advertised
within another Android app and we showed
every participant three different
permission requests and we have multiple
choice questions asking them to define
what the permission allowed an
application to do so in this example we
have granting internet access there are
four options plus none of these and I
don't know we removed the people who
left these completely blank since we had
an explicit none of these option we also
remove people who
answered I don't know so we only look at
looked at people who selected one of the
five options in this case the correct
answer would be loading advertisements
and sending information to the
application server so every participant
had three of these and what we found was
on average of the three they got point
six questions correct and so we could
you know calculate the distribution of
expected answers from random guessing we
have for multiple choice responses three
times the expected value would be I
guess about a third of what we observed
so this is you know statistically
significant it indicates that people
weren't just randomly guessing they put
some effort into this but at the same
time the majority of people weren't able
to identify any of these permissions
only eight people got all three correct
so there are some problems here with
comprehension we followed this up with
the laboratory experiment to get
qualitative data on why these
comprehension rates were so low we
recruited 20 for Android users from
craigslist and we had them do three
different things the first two tasks
using their own devices we observe them
install two applications we gave them
scenarios for instance install a coupon
saver application and so they went to
the the market and we're allowed to
download whatever application they
wanted that they felt fulfilled the
scenario and we observed whether they
viewed the permission request screen
during this process they did that twice
and then the third task was using their
device again we asked them about an
application their choice that they've
used frequently and we had them open
that application interact with it then
we had them go to the permission screen
that I showed you at the beginning of
the talk which lists all the permissions
that that application had been granted
and we simply asked them whether the
application had the ability to send SMS
messages so what we observed was during
the installation task fewer than twenty
percent viewed the permissions during
the install the request came up after
they click the install button and they
simply click through them without
reading them
which was kind of expected this is also
likely an upper bound we perform this in
the laboratory so it's likely that they
were under pressure to maybe apply more
diligence to the task than they would
have otherwise and then also when we
asked them whether this app that they
were already familiar with and for which
they could view the permissions could
send SMS messages a majority of them
were unable to answer this correctly and
the reason for this is they knew the
permissions that it was granted but they
didn't know that the permissions it
hadn't requested so they didn't know
that SMS was a separate permission so
being able to state definitively whether
an app can do a particular action
requires some sort of familiarity with
both the granted permissions as well as
the ones that weren't granted so from
this we came up with several suggestions
on how permissions could be improved
more generally so one people were
habituated to the requests since they'd
seen these requests with every single
application they've installed very used
to clicking through them so one
suggestion might be only prompting one
necessary these application stores are
well curated and bad ones are taking
down so might it not be rational to
ignore the Commission screen um yes I
know so ver curated for stuff that's you
know outright bad right so things that
you know that's malicious but things
where it comes down to user preference
so you know specifically privacy stuff
so people have a wide range of privacy
preferences in some cases you know some
people care about disclosing location
others do not and so basically it comes
down to user choice so the next
suggestion was people were a plurality
of our participants were simply unaware
that these things even existed since
Farah so habituated to clicking this
after the install screen a lot of them
said well they thought this was just
another EULA and it wasn't really about
granting abilities to an application so
the information was maybe being
presented at the wrong time during the
installation process another thing is
there are possible cognitive biases so
maybe after clicking install seeing this
they were subject to choice confirmation
bias they don't want to
is it that a choice that they already
made so maybe this information needs to
be provided at a different time maybe
earlier when they're browsing
applications or maybe even later at
runtime for instance when the
permissions are actually used and
finally there's this problem of
understanding what an application is
doing requires understanding what it's
not doing or what it's not asking to do
so maybe we should narrow the list of
possible permissions so in android they
have over a hundred different
permissions I think Windows Phones Allah
is a lot better there are fewer than 20
iOS has they've changed it used to be
that only location and notifications
were prompted at runtime and they have
expanded that to add a photo the phone
access to the photo library and contacts
um and so this brought about a much
broader discussion on permission
granting mechanisms generally so these
were all problems with install time
mechanisms but maybe there are other
ways of asking for permission and this
is applicable to more than just
smartphones frequently well because
we're heading towards an environment
where there's a lot more centralized app
distribution such as you know having a
store bundled with the OS we see this
both in Windows now as well as on the
Mac certainly the permission requests
are integrated in that so again looking
at install time warnings there are pros
and cons to these very adaptable to many
permit many different permissions
because it's simply just a you know
little text box here where you describe
what's being requested so there's
nothing really dynamic about that it's
easy to write these they could also be
used to grant future abilities so at the
time that the permissions granted isn't
the time that it's actually used the
problem is especially in the mobile
space there's limited real estate so in
this case there are just three different
permissions the user sees by default
unless they scroll all the way down so
it's easy to overlook the other problem
is they lack context so when these are
actually used it's not clear what
they're going to be used for as opposed
to maybe a runtime warning which adds
contextual information so when the user
sees a request for location they were
due
something to trigger that request and so
they might have a better idea of why
it's being requested likewise these
could be made dynamic by including you
know other environmental information so
over here we have a bluetooth request we
can state the name of the device
obviously you can't do that at install
time but these have problems too so
everyone's probably familiar with this
so habituation when users see these you
know frequently they stop paying
attention to them and so you know
they're used to the benign situations
but when there's a potentially malicious
one they've now become trained to
dismissing these without reading because
they see them as a barrier to completing
a primary task but at the same time
there are also things that we could do
to grant permission without interrupting
the user so there's curation so if we
have in our market some sort of review
process so that every app that's
distributed has gone through some sort
of you know heuristics maybe that's a
way of preventing the user from being
inundated with too much security
information the problem with this is
it's very resource intensive so it's
really hard to do this automatically
there needs to be some sort of human
oversight especially if you're going to
be you know either revisiting decisions
and pulling apps off devices or
rejecting apps from paying developers
the process is also completely opaque to
both users and developers alike this is
what Apple has been doing but we've seen
lots of problems with it so everyone's
probably familiar with the path fiasco
so path was a sort of social networking
app turns out in Apple's terms of
service they prevent developers from
accessing the contact list on the device
but there's no actual enforcement of
this it's supposed to be enforced
through the curation process somehow
this slipped through the cracks millions
of users were using this application
when it became clear that it had been
you know pretty frequently violating the
terms of service agreement so curation
might not be the best way but there are
other emerging approaches for granting
permission without interrupting the user
so what I call trusted UI elements so
these are system drawn
components or access control gadgets the
developer essentially specifies an area
on their app to draw a button or some
other component and then the OS is
responsible for drawing that and these
are advantageous because the only way of
granting the permission is by
interacting with the OS drawn widget
rather than a developer drawn one so
there's no real way to spoof them
certainly developers could spoof the
look and feel but interacting with that
spoofed widget doesn't actually grant
permission another thing you could do
this with this is granular access
control which doesn't really hasn't
really been enforced before so maybe you
have a widget for adding stuff to the
calendar a nap request this the user
then interacts with the system drawn
widget and can add a subset of the
events or can make you know changes the
request before it's granted and then the
app you know can't override those
decisions but these have some drawbacks
so one case is you know you can't it's
hard to grant stuff in perpetuity also
it's hard to grant stuff where the
initial request wasn't generated by the
user certainly you could do this with
various callbacks but I argue that this
breaks the users flow and sort of you
know these devolved into just another
confirmation dialog if they are
explicitly performing some permission
granting task to grant a future
permission and then this came up this
idea of implicit access came up so in
certain cases if our goal is to minimize
the bitumen ah'd bothering the user with
unwanted interactions when the risks are
really minor or can be completely
reversed maybe we shouldn't ask a priori
instead we should grant the permissions
but allow the user to audit what happens
so that when the misbehavior occurs they
can go back and undo it and so from this
we've created sort of a mechanism
hierarchy in terms of desirability the
base case are the install time warnings
which are generally undesirable but
they're sort of a one-size-fits-all
approach for applicable to pretty much
any permission on the other end of the
spectrum there is the implicit access we
our most desirable but you can't always
use them or you know to put another way
so then the issue is deciding between
which one of these mechanisms is most
appropriate for a given situation or to
put another way grant me the serenity to
accept that some permission requests
cannot be eliminated the courage to
eliminate the ones that I can and the
wisdom to know the difference so then
that brings up the question is how do we
know the difference so we did this
thought experiment mean a couple grad
students in the group where we amassed a
collection of all of the possible
permission requests that a user might
see we came to this by gathering all the
permissions from Android Windows Phone
iOS and the Mozilla Web API we removed
all the duplicates and we also remove
the ones that the user probably has no
business seeing you know things like
enabling multicast mogees most users
that's one of those decisions that most
users just aren't qualified to make and
for each of these we individually ask
what's the best way of granting
permission we went through and then you
know met together to try and reach
consensus and we found that the way that
we reasoned about this there were a
couple common questions that arose so
the first you know factor that we looked
at is what's the risk level of granting
one of these what's the one of the
consequences if this were to be abused
so one example might be a permission to
permanently disable the device so you
might have some sort of security it you
know software on there so if your device
is stolen you go to some website and it
you know destroys all your data so this
is pretty severe especially now that we
see a lot of malware which is hosting
you know holding devices hostage hoping
to try and you know profit is this
reversible well it's specifically
designed to not be reversible is there
an incentive for widespread abuse yeah
so the consensus here is since we're
granting a future permission really the
only way of doing this would be an
install time warning another example on
the other end of the spectrum is
changing the time so what's the the risk
level here well certainly you can come
up with some sort of James Bond style
plot that
hinges on changing the time on someone's
phone but for the most part that's not
really applicable to most people and
really the risk is just an annoyance the
user could go and change the time back
some question wasn't passed away tell
you gives you the example of you did you
come up objective way to decide what's
up fast I Liz come and get the next
slide okay good okay and so based on the
patterns that emerged in terms of how we
reasoned about in these individually we
came up with a flowchart for determining
the most effective way for granting
permissions i I'm not gonna I'm not
going to say this is the best way this
is a formal way that we came up with
based on a lot of discussions and I
think this still needs to be validated
but I think this is an improvement and
it provides a process to a developer's
platform developers in choosing what
mechanisms to use so we have five
questions here and so the first is we
have this notion of revert ability so
could the device be reverted to a
previous state if something were to go
wrong if the answer is yes then you
should always just grant those
permissions implicitly but offer some
sort of audit mechanism so that users
can identify misbehaving apps um
likewise if it can't be necessarily
undone but if it's just an annoyance
then we should do the same thing there
but if the risk level rises above that
the question is did the user initiate
the request and if so then in every case
we should be able to use trusted UI
components or acgs if the user didn't
necessarily initiate it but maybe we can
allow the user to grant a subset of the
request we could still use you know
system drawn components or choosers to
allow the user to do so and then finally
if the answer to that is no we're stuck
with either a runtime warning or an
install time warning and the way that
you differentiate those is whether the
ability needs to be granted in the
future in which case you really need an
install time warning so using this model
we went back and looked at our list of
permissions and what we found was that
the majority of them could simply be
done away with and replaced
with audit mechanisms we found that
about a quarter could also be replaced
with trustee UI and at the other end of
the spectrum there the install time
warnings now recall that on Android that
was a hundred percent we've now reduced
that to six percent by applying this
model so this could dramatically reduce
unnecessary interactions the reason why
implicit access you do more off you put
that at the head at the top of the full
flow chart I supposed to trust you eyes
they just every trusted you I could want
to create a cognitive load after
recognize a certain type of widget damn
so yeah nobody so 23% sounds like a lot
of widgets to know about um it's not
necessarily the user has to know about
it because you know honestly if the only
way of granting well okay it needs to be
intuitive that that widget does the you
know desired thing so you know maybe a
button for the shutter of the camera but
if the only way of achieving those
actions is through the trusted you I it
just needs to meet be made obvious that
those components you know will complete
the primary task the user doesn't have
to memorize you know all the trust of UI
components flowchart start with trust
you i shouldn trusted you I'd be the
first go-to thing I mean because if it's
so easy um can I make it the first
clarification the user does not need to
recognize your trust what if the cause
of you I is now used permissions not
or that it will not be achieved well but
so I mean it needs to be so user trying
to complete a primary task right and so
the you know the trusted UI components
need to facilitate that but the user
doesn't have to you know be cognizant of
the fact that these are their granting
permission through these why is
interested you I beginning of a full
chakra set of partway through because
they're also you know other constraints
so balancing needs of developers so
simply telling developers that you know
you no longer have the flexibility to do
this you have to use a system drawn
component might be overreaching and
might stifle some innovation so for the
things that are truly minor we should
just not care about that balls and plus
access connecting to the internet why do
user need to care about connecting they
don't that's my point um and so when we
were doing the ACG work
the only scope to only common user home
resources sure don't think not work sure
I mean we arrived at this by starting
with you know what are all the
permissions the users are confronted
with now rather than yeah absolutely
you're absolutely right um yeah but I
mean so take connecting to the internet
you know you're not going to have a you
know system drawn button for every app
so that it can get internet access
that's ridiculous instead response to
user actions so they would go past that
in the project yeah why don't you cut
you off to the denominator the point is
um the the harm from that is
sufficiently minor if you're not say you
know internationally roaming most people
have you know pretty good data plans you
know often unlimited if there's an app
that's abusing this we can have an audit
mechanism as we're going to get to so
that people can identify the apps that
are abusing this even though it's been
granted without consent um and so this
you know sets up this research agenda
which is you know the first looking at
well which permissions are necessary to
grant which ones aren't and then of
those that are necessary how can we
design better or that aren't necessary
you know to be explicitly granted how
can we design better audit mechanisms
and the other side of that is for the
requests that you know do require user
interaction how can we optimize those
and so on the rest of the talk is a
current stuff that I've been working on
to improve the audit mechanisms or what
I like to refer to as begging
forgiveness instead of asking for
permission because I guess what we're
doing here is not asking for the
permission a priori but allowing the
user to revisit those decisions so the
first question in exploring this is our
audit mechanisms likely to be effective
so I conducted this online survey using
people on Mechanical Turk we didn't
press specifically screen based on what
smartphone platform they used instead we
did that post talk we had a free
response this way they weren't
incentivized to cheat one way or the
other and we just screened out android
and iOS users the reason being that
both have some existing audit mechanisms
and we also got too few responses from
windows phone and blackberry users to
really include them we only got like two
or three from each anyway so there are
two questions that we hope to answer
through the survey the first is so do
users understand that applications
running the background can access the
same resources as those running in the
foreground this is important because if
they're not aware of this when a Miss
behavior occurs on their device they're
likely to just blame whatever app was
running in the foreground not
understanding that it could have been
anything that was also running at the
same time um and if that's the case that
hints at the need for better audit
mechanism so that they can dis
disambiguate the cause of Miss behaviors
the second is that some both these
platforms have some existing audit
mechanisms built in and so we want to
look at whether users were aware that
these existed each other where this
oddly two mechanisms we want average
user I don't need to know what's
happening on the platform and just I
mean this year me the platform like iOS
or Windows Phone app developers
patient right I mean if something going
to know I don't know if something
happens on your device you probably want
to find what apps responsible so that
you can take corrective action are
really in many other scenario in the
real world right by those are all
something I don't know how to fix it
I'll call someone I'll find someone was
expert if it's a problem it doesn't
necessarily mean how we need to put
everything in the Euler's hands sure but
if we if we can do it in an unobtrusive
way so that it's simpler for the user
that I mean that's still a net win
because it's empowering more users
certainly not every user is going to
take advantage of that but it's
empowering more users to make better
decisions about how their data is being
used I it seems like the background
running in the background and ottoman
they sound orthogonal to me I mean if
I'm using angry birds and it's sending
SMS messages while I'm running it that's
just as annoying as yeah absolutely but
if you get in a survey about a lot of
mechanisms why does it have the in the
background what does that matter because
of their needs to be a way of
disambiguating whether really was angry
birds or something else that happened to
be running at the same time I mean
you're not going to know you're just
going to get some charges on your bill
oh so you you think that there will be a
charge and says 235 km in the user will
remember oh I was running angry birds
235 km on SMS is a bad example because
the way that they get notified is you
know dissing time in the future but say
your device just starts vibrating too
just to be clear so you're suggesting
auditing as an alternative to asking for
Gran Chaco I mean SMS is a bad example
because that's not something that's
benign you'd grant permission for SMS
since you know users are concerned with
running up costs
yeah so like vibrating the device having
you know make noise so these are
annoyances and the user will want to
maybe stop these at the moment that they
start if it's an ongoing event yep so
the first question was we had a multiple
choice question about what happens to
apps in the background we had five
possible answers from I don't know it
simply exits it runs with fewer
abilities it goes into a suspended state
and doesn't actually do anything until
you resume it or it runs with the same
abilities which was the correct answer
so yeah oh so 22% selected the same
abilities but we see you know we do a
binomial task and see that if people
were randomly guessing there's still a
twenty five percent chance that at least
this many would have guessed this so
what this illustrates is people really
have no idea what happens when an appt
goes in the background which means that
maybe we should have some sort of
provenance for apps when they do miss
behaviors on the device so to give one
example data usage on Android so Android
4.0 added the ability to view the data
usage so in the the Settings app there's
a panel there's a thing here for data
usage if the user selects that they get
a sub panel and all the way at the
bottom here if they scroll down it'll
show it's sorted by individual app so
they can see which app was responsible
for using most of their data this has
been a deployment for over a year there
haven't been any you know public
education campaigns about this so our
question was our Android users aware of
this have they discovered this on their
own just because it's been on their
devices so what we did was we asked a
question um we had a scenario that you
get a you know hefty bill and it's due
to data usage how would you go about
finding the cause of this using your
device this was a free text response so
we just had like you know an essay box
and we wanted to see whether they would
describe the steps involved in getting
to the Settings app unprompted and we
found was almost three-quarters of
android 4.0 users were
aware of this they they wrote out all
the steps involved in getting to the
data usage screen very aware of its
existence if we look at the ninety-five
percent confidence interval this means
as high as eighty five percent of users
are simply aware of this because they've
had it on their devices looking at users
of prior versions of Android as well as
iOS who didn't have this ability their
responses were all over the place a
plurality simply said they would you
know blame whatever app they most
recently used um though the next popular
response was they would inspect device
settings which indicates that maybe if
you know on these other platforms that
feature were available users would have
stumbled upon it um another thirteen
percent said that they check app reviews
and while this is probably the the most
viable strategy of the ones listed it's
not you know guaranteed solution either
and so we thought from this is users
generally expect to find this provenance
information within the Settings app
regardless of whether or not it's
actually there so this might be a good
place to have annotations to indicate
what app most recently changed a certain
setting question I was going to ask so
this is not really the auditing
mechanism or it's more about it's almost
like is even more general than just
it's basically about configurations a
configured miles yeah I guess that's why
I've been saying provenance I guess
rather than auditing noemi's behavior
there's not be enemies behavior is just
my application does something I come to
go to do something and then later I
think and you did I want to know sure I
could turn it off then yes and is it
could be used to audit but it's not in
and of itself necessarily yeah he is
very natural for all the configuration
to happen so yeah yeah um insulin that
brings the the second question so all of
this was well a follow-up question all
this was about you know changes to
settings and where do users go to find
the cause of that what about ongoing
events so maybe the device starts
vibrating is it reasonable to expect
that they go to the Settings app to do
that to figure out what's causing that
and that brings about notifications so
pretty much every platform has some sort
of notification bar where it has icons
which indicate what apps are doing so
here on Android this is the SMS 1 and if
i were to drag that down it would expand
and show me that you know i have a text
and it even show me some information
from that text um and so the question is
you know our users aware that these
exist do they understand that they can
interact with them to yield more
information about the cause of certain
behaviors so we followed up the survey
with a qualitative interview with eight
different participants recruited from
craigslist all were existing Android
users gender was pretty well split as
were the ages we asked them to perform
three different scenarios using a
smartphone that we provided them so the
first scenario was we asked them the
same scenario that we gave to our online
participants how would you identify the
cause of a data overage and just based
on that information half our
participants immediately navigated to
the screen so that sort of validated
those results the remaining four
immediately said things like well I
would use my phone to call my provider
or I would look at my bill online of
course those strategies won't actually
break
down on a per-app basis and so then
after we prompted them to investigate
the device they to immediately navigated
to the settings so this sort of
validates that you know this is an
intuitive location for that type of
information in the second scenario we
told them to imagine that the wallpaper
has changed on ver device what would
they do to figure this out now currently
there's no way of auditing this but the
purpose of this scenario was to see
whether they too would go to you know
the Settings panel where such changes
are generally made to see if it would
yield any information and of course all
of them did that there are two different
ways so they can either click the
desktop for a prolonged period which
brings up a chooser or from the settings
panel there's this display settings they
can configure wallpaper from there so
all of them did one of these two things
to see if any information would be there
about the cause of such a change but
only one participant understood that
applications could be responsible for
these type of changes the rest of the
participants said well they expect it
maybe someone else borrowed their phone
and changed it they didn't understand
that this is something that apps could
do unexpectedly and finally we looked at
notifications so we had them read a news
reader on the phone and while we're in
the process of doing that task we made a
notification appear with a little video
icon here and if they were to expand it
it said that another app was accessing
video we wanted to observe whether they
would notice these and expand them on
their own what it was they say anything
about facebook or other apps um yeah and
so what we found was so without
prompting only three of them
investigated this on their own and we
suspect that's because it wasn't their
phone they were in a public place when
they were using it so um a lot of them
said that you know after we prompted
them they knew you know exactly what it
meant they just didn't really care it
wasn't alarming enough but when we
prompted them everyone but one person
knew that they could expand that menu to
see what app was responsible
oh can I trust Facebook report my life
oh we didn't actually test that the
whole point was whether they would know
to expand it whether they would you know
know there's more information available
about what app is causing that um so
from this we had a couple observations
so the first was that users expect to
find this provenance information in
either the you know system-wide Settings
app or wherever else those changes can
be made we also found that users are
familiar with the notification bar and
know that they can use it to get more
information so we decided to instrument
our phones with some of these with these
two audit mechanisms to observe whether
people would do this in the lab interact
with them when Vera put in a position to
motivate them to do so I guess I refer
to this as adversarial usability testing
where we try and you know mimic a threat
model and see whether users will use the
provided mitigations to counter that
threat so we had 76 Android users
recruited from craigslist it's skewed
towards male the average age was mid-30s
so we think this was relatively
generalizable and we performed a
controlled experiment we randomly assign
people to two different conditions we
ran several sessions we had 20 different
phones half of them were flashed with an
experimental condition the other flat
half were flashed with the control where
they didn't have audit mechanisms and we
didn't actually know what condition
people were assigned to until we pulled
the logs off the devices at the end of
the experiment and the questions we want
to answer were when devices misbehave
and they're provided with audit
mechanisms will people use those audit
mechanisms to find the cause of the Mist
behaviors we intentionally designed the
study to make this task ambiguous in the
control condition by having them
interact with applications that all
requested the same abilities so we
specifically looked at the ability to
vibrate the device so we have three
different apps that they interacted with
that all had this ability and three
different apps that could change the
wallpaper um and so
obviously when this you know miss
behaves we want to make sure that every
single one of these apps was already
running in the background so that it's
you know plausible that it could have
been any of them that was causing the
misbehavior and so what we did was we
used some deception and we told them
that they were there to simply write
reviews for apps that way we could be
assured that they had run several apps
in a short amount of time and the apps
were running in the background so with
regard to the vibration audits so these
were only available in the experimental
condition when the device started
vibrating since this was an ongoing
annoyance we had a notification icon
appear and if they were to interact with
that it would attribute that to a
particular app that they had used in the
control condition the only way of
identifying the app would be to launch
the task list and individually kill apps
until the vibration stops and we did
observe that behavior with regard to mmm
so the veneration I observable for
cotton system
um no we actually didn't implement that
so we didn't ask them to you know stop
the vibration we just the only data
point that we point that we collected
was whether they interacted with it and
then in their questionnaires we asked
them which app was responsible but yeah
that was a oversight we that we talked
about in the paper that several people
did you know try and click that button
in the exit survey we asked them what
behavior they would have expected after
clicking the button and it was about
evenly split between launching the
application responsible or going to some
central settings panel to disable it yes
that's something that we should have
instrumented but didn't yes yeah exactly
i think that you know having that go to
the Settings panel is probably the best
way of handling it because if these are
going to be drawn by the OS and if it's
a potentially you know malicious app it
should be the OS that handles you know
terminating the behavior with regard to
the wallpaper changes we simply added
annotations to the Settings panels there
were two of them so in the display
settings we added it here right under
the wallpaper where they would go to
change the wallpaper as well as that
chooser that I showed you from the
desktop and so again this was only
available in the experimental condition
um and so actually in the control
condition there was no good way of
determining what app is responsible for
changing the wallpaper in a best-case
scenario people could go through and see
what apps have the ability to do so but
that only narrows it down to a subset
and doesn't definitively tell them yeah
I can throw for different places for
different
missions on different events but
alternative way working on a desktop and
windows has this a system mark it's a
big list of all the events that ever
happened sure i'll call you can search
you can do other thing i'm doing it to
make a sense but anyway I thought we
should provide a psycho place for people
to look at the events and the
permissions because the gucci album if I
know where to look for wallpaper change
all it's obvious but for the other hand
there was there a market where you guys
like a power user as I am I thought it's
pretty hard to figure out to what's
going on there but even there the
central place I can easily search
through it yeah potentially I think
that's a separate question and I agree
completely I actually in the future work
that I wanted to discuss I've thought
about that a little bit i'll try and get
to that i should get to at the end okay
if this is not a good
um yes fine so my question is the iphone
also has the in a setting it already so
why you I fully scrum faced provisions
so it also tells you do you want this
application to send you a notification
then later you can also custom
configured so is that pretty close to
what you're proposing oh yes yes exactly
now we actually looked at that a little
bit so we did a previous experiment some
summer undergrads actually set up a
mechanical turk task to get people to
upload screenshots of that panel just to
observe whether by default people just
have that all enabled or if they've
actually done some you know if there's
any intelligence applied to disabling
that on a per-app basis they were trying
to take a machine learning approach to
see whether they could predict what
applications would have those things
disabled and all of the I know the
classifiers we use weren't able to find
any trends which was kind of interesting
that it seemed that on just you know it
all came down to preference but it was
surprising that people actually have
taken steps to disable that in our the
first online survey that we did with
this that I prevent presented a few
slides ago I did have some questions
about iOS 6 which now has those audit
mechanisms for sharing contacts and
photos and while we found that on
average more people were aware of those
then the yet we had them select multiple
choice options or what audits are
available on their device and we
included a whole bunch of ones that
didn't actually exist on average you
know people were more likely you know
the the means were higher for those you
know among iOS 6 users but there wasn't
a statistically significant difference
but also only 40 of our 200 some
participants were confirmed using iOS 6
so it's hard drawing any conclusions
whether I guess those have moved into
the public consciousness that those
options are available at this point I
guess it's only been available for six
months
um anyway moving on so in the lab when
we examined this we had them do each
misbehavior we had occurred twice the
first time we refer to it as the
implicit misbehavior so we had them
doing some other task and then we
triggered the misbehavior and that was
simply to observe whether they would
notice that it was occurring and
interacts with the audits unprompted and
then we followed that up with an
explicit misbehavior after they
completed all the other tasks we told
them you know your device is now one of
the apps is causing your device to
vibrate please identify which one it is
so that was sort of to get both a lower
bound and an upper bound on the
effectiveness of these audit mechanisms
so the full sequence of steps was so we
randomized whether the wallpaper or
vibration one occurred first so this
listing is just as an example but had
the wallpaper one bin first once they
arrived at the lab we told them that
they needed to write reviews for three
different drawing apps and as a first
step all these apps are installed on the
phone they should spend two or three
minutes interacting with each one to
become familiar with it and after they
did all three of those in random order
we then asked them to interact with a
desktop widget and the reason why we had
them interact with a desktop widget was
so that we can be assured that they
could view the desktop when we change
the background to Justin Bieber um and
then after that you know we tried we
didn't prompt them about this we just
did it and then we observe we asked them
to write the reviews for the apps and
afterwards we read through those reviews
to see if they documented this
misbehavior within ver a preview we
followed this up with the vibration
misbehavior so we had them do the same
thing with three different timer apps
again we chose these apps because they
all had the ability to vibrate the
device and then as the fourth distractor
task we asked them to play with the dice
app the reason for this was so that we
could be assured that they were holding
the device in their hand because it was
accelerometer based so they had to shake
the device to roll the dice that way
when we had it start vibrating
incessantly we knew that they would be
able to detect that because it was in
their hands again after that we asked
them to write reviews for the apps to
observe whether they would include that
Miss behavior in any particular app
review
after they did those all those tasks we
then had them go back and we told them
okay one of the apps just changed the
wallpaper on your device please you know
indicate which app was responsible and
also report the degree of confidence you
have in your selection using a
five-point likert scale we did that
again with the vibration and then we had
an exit survey so um regarding the
unprompted a vibration which was
represented with the notification icon
we found that about half of them
commented on the vibration in Vera views
so they noticed it but the difference
with regard to identifying a particular
app was significantly different between
well so 17 of the 20 one who noticed it
identified it whereas only two of the
six who notified it who noticed it in
the control condition were able to
identify it so of the people who noticed
it but didn't identify it they wrote in
multiple reviews that you know one app
was vibrating I'm not sure which one was
responsible going through the logs that
we stored on the devices every single
one of the 17 who correctly identified
the app did so by you know expanding the
notification bar so this was intuitive
to them they didn't need to be prompted
to do it regarding the explicit
misbehavior so we told them you know
your device is now vibrating please
report which app is responsible over
eighty percent in the experimental
condition were able to correctly do so
whereas only about thirty percent in the
control condition of course though of
the multiple choice the multiple choices
that we provided the number in the
control condition was not statistically
significant than simply randomly
guessing and arriving at the correct one
and so finally looking at the strategies
that people took almost everyone opened
the notification bar after the device
started vibrating even the people in the
control condition they expected that you
know there's a some sort of something
going on maybe there's something the
notification bar even though there
wasn't
of the 12 participants who identified
the correct app in the exit survey 10 of
them outright said it was due to random
guessing whereas two of them killed apps
individually until they found the right
app and so finally of the incorrect ones
there was a plurality who admitted
random guessing because they didn't know
what to do twenty-nine percent name the
last app and what's interesting both on
this misbehavior and the other one there
was a small minority who simply inferred
the abilities based on the UI so they
said within this particular app there's
a settings panel for controlling a
vibration feature I don't see this in
the other apps so therefore you know
this must be the one that's responsible
so very inferring abilities based on
what you I features are available as
opposed to what permissions have been
actually granted to the application and
then also in the experimental condition
it was the only one where there was a
significant correlation between
confidence in the correct answer and
actually having a correct answer so
finally a wallpaper we were a little
disheartened to observe that very few
people actually documented the change so
we after we be burped our participants
um only about fifteen percent noted it
in the reviews and afterwards we asked
them in the exit survey and a lot more
people had been aware of it but thought
maybe it was something they did with the
widget they were interacting with and so
they blamed the thing that they were
using at the time that the Miss behavior
occurred their phone it was your phone
that were using white yeah so could be
just the thing is from the drawing out
maybe this is not driving out to right
yeah okay um and so then when we
explicitly called their attention to
this and told them it was one of the
apps fade previously used please
identify it and specify your confidence
there was a statistically significant
improvement and difference in the
experimental condition um but it was
only about thirty percent so of the
twelve who correctly identified it to
admitted to randomly guessing and
arriving at the answer so there were
really only ten who got here through the
audit mechanism and this was confirmed
through the logs six of them went to the
Settings app and observed
annotation 3 saw the wallpaper chooser
and one saw both um and so the incorrect
ones again it came down to random
guessing looking at the last use app and
again there is this phenomenon where ver
inferring abilities based on the UI
features available so some of them said
you know a particular app they saw the
option to set wallpaper they didn't
notice this and the other apps therefore
must be this app and again confidence
correlated with correctness so from this
there are a couple open questions so we
confirmed our previous findings
regarding people intuitively going to
the Settings app to look at the cause of
changes but the question is should that
thirty percent in the wallpaper can
during the wallpaper misbehavior should
that be considered a success while this
was a you know significant improvement
over the status quo thirty percent seems
like a low number I would argue that yes
this is a success what we've observed in
previous studies is most users don't
actually read the direct disclosures
from apps about how data is being used
instead we rely on third parties such as
reviews or word of mouth and so actually
having a small number of savvy users
aware of these features that information
is then eventually going to get
disseminated into reviews and more users
will become aware if a particular
application is systematically causing
this behaviors um and so then some of
the you know the future questions are
you know if apps are drawing a you know
these not notification or a system you
know we have system.drawing
notifications we also have appt drawn
ones how do we make this difference
intuitive to end-users um yeah thank you
should we be designing these props to
target our users
if they're the ones most likely reason
potentially I mean this was one you know
one misbehavior and so it's hard to draw
conclusions from that I mean what we
also found is you know so in the you
know the stuff in the Settings app with
the you know the data usage so that had
been deployed for a year right and you
know up to eighty-five percent are aware
of that so maybe if these notifications
you know we're in widespread use maybe
in a year that number is going to be
greatly improved it's hard to say but I
think this is promising no we recruited
from the general public I usually avoid
recruiting people from campus we had
them you know we collected ages gender
and also occupation and we found that
there was actually a pretty good
distribution with regard to a you
patient there weren't very many in
technical jobs but there was a huge
range from blue-collar to white collar
people with you know higher education
degrees so I think this is relatively
generalizable um one problem that Cormac
sort of hit at is the the moral hazard
element so they were using our phones
and not verifone so maybe some of these
miss behaviors they simply just didn't
have an incentive to look at because
they weren't the ones who are bearing
any lasting harm so maybe you know maybe
these are considered lower bounds as a
result of that so a future work just
about done is that the grand vision for
all of this and I think more generally
with previous work that I've done is in
the usable security space we've gone
leaps and bounds over say ten years ago
where things were sort of designed
without the user in mind and now a lot
of a lot of things systems have been
improved by focusing on the user doing
user centered design but at the same
time all of the experiments that we do
sort of cater to the average user but no
such user actually exists and I think
that there are probably clusters of
behaviors and I think one of the future
things that I'm really interested in
working on over the next few years is
trying to cater security mitigations to
individuals and this comes back to your
question about you know having some you
know thing we're all that in
information is aggregated well there's
the habituation problem and obviously
that could cause you know some sort of
overload I think less so than with the
warnings because it's a you know the
push versus pull nature of it people are
going there to seek information out but
there's still some intelligence that we
could apply in terms of displaying the
things that we think a particular user
finds most important and also that's the
case if you know if a lot more you know
if fifty percent of permissions are
replaced with notifications obviously
that could overwhelm the you know the
status bar and create a lot of clutter
but if we know you know what an
individual here is about we can
prioritize and only show the things that
are relevant to them um and the amount
of data that's out there especially on
mobile devices and you know backing up
stuff to the cloud makes this really
possible so to give an example so you
know Gustavo has a smartphone he uses it
to make public check-ins on foursquare
anyone can read his posts on foursquare
um he sends tweets that include his
location so having some sort of you know
middleware or even at the OS level the
smartphone can infer that he probably
doesn't care about location and further
prompting him to disclose you know
whether he wants to disclose his
location is probably just gonna
habituate him to request that he might
care about more um and so we could do a
lot in this space by learning what
individual users care about um or you
know maybe as a first cut just you know
segmenting the population into a couple
discrete personas and catering security
mitigations around that before we get
you know all involved in a machine
learning approached visit contradict
sense i mean i left a facebook and other
social apps to access my photo album
doesn't mean and I like the Google+
access oh yeah sure it's true I mean
what really happened to me ok Google
pasa I'll do not get uploaded all my
pictures sure once I feel information
yeah no I mean that that's a good
example and I don't think you know this
this isn't supposed to be a you know I'm
not designing a system around this
particular use case but I mean this is
just to illustrate on how we can do
customization and make inferences about
individual users to minimize the number
of unnecessary security interactions so
the conclusion is that the current
choice architectures are really failing
users because there are too many
requests that they don't care about
which means that the important ones you
know tend to go unnoticed at the same
time we know that users do want some
control of how information is shared
with third-parties and by performing
iterative human subjects experiments we
can yield generalizable knowledge to try
and give them that okay how's that
passion I have the same Santa is
basically what you said auditing can be
used in young permissions aside in some
sense in this Omaha I'm security people
but in some sense if you will care about
the usability on fixing a problem more
than security and the provision sure
percentage mind so in some I mean have
you started looking at it is a more
appliance auditing on how we use our
resolve an issue broadly instead of just
for permission related issues um
something like that perhaps in the
question for instance I mean you-you-you
up high you were looking auditing
because you want to allow user to
reverse permissions sure but not look
how you're living work I said man if you
can help 54 some people are 64 some
people to figure out the wallpaper phone
because I saw the same problem on my
wife's for my daughter with this Sam is
a cool new or issue I mean that happens
way more often than permission issues
yeah absolutely i mean i think you know
there's a permission for saying
wallpaper but now i understand your
point and I think that more generally
what this points to is I guess using
saying permissions as a misnomer I think
that what we're really concerned with
our outcomes and unexpected outcomes or
undesirable outcomes and whether that's
through
you know inappropriately granting one
permission a set of permissions or just
unexpected behavior the head and nothing
to do with permissions yeah you're
absolutely right and that sort of falls
under though this notion of provenance
and trying to make it easier to
understand you know for users how a
change or unexpected event occurred
generally okay based on your study here
what would you what would you say that
apple should do in addition to go they
happen because they seem to already have
a mechanism like in setting you can kind
of undo the things things up computer
your abs yeah so what do you think they
should do you know Lucien they stop oh I
think that actually based on our some of
the earlier research which I didn't
include in this talk we've done these
couple surveys looking at unexpected
outcomes in order to sort of rank
consequences to see what people are most
concerned with and of the four things
that ought that Apple has provided audit
mechanisms for those tend to end up at
the bottom of the list in terms of user
concern and so you know I think that the
way that they're doing it is intuitive
to people and haven't you know what we
found is having it in this you know the
Settings panel it does get found by
users but I think that they're focusing
on the wrong things oh I'm sorry oh
let's get David hurt so so just quickly
any photo you're using
parties that might have a view across
hopefully example at rogue as messes
imagine the OS told carrier which APIs
onion and your carrier pancetta gain
search this chest timer this is really
yeah I mean I've thought about that um
um I haven't thought about that more
generally I've thought about the the SMS
issue and I think that that's a larger
economics problem so you know on some
level you know the carrier's sort of
have an incentive to not do anything
about that because they're getting you
know they're getting money at the same
time what yeah the platform is that okay
sure it doesn't I'm replace the carrier
with look out oh sure you know mcafee or
semantics or some other hands and vipers
you see a new antivirus in the model
where I let these people sort of see
what apps are saying SMS yeah and I
think that's the model that we're going
to now there used to be this notion that
you know if if if anything bad can
happen then you know the systems
insecure and should be abandoned but I
think what we're you know the model that
we're going to now is there always when
new malware comes out or a new you know
vulnerability is discovered there are
some sort of you know there are some
expected losses but then the crowd you
know learns of it and adjust and so you
know we see that with you know what I
say you know malware isn't really a
problem on most these platforms
certainly when malware gets uploaded
there are a few users who are impacted
right but eventually you know it gets
detected and gets you know pulled off
the devices know that a few users you
know are adversely impacted before it
gets detected is bad but I think we're
poor we'd be poorly allocating resources
if that's the main problem we're
focusing on
it's windows 8 Mac seem to be moving
rates store models for the desktop as
well yeah you think they have a
usability problems the same are the
easier harder I haven't actually spent
much time looking at them but i think
that most of this is applicable to that
certainly with respect to you again i
don't think malware and detecting
malware is really the problem it's
simply empowering users to you know
decide how their information is shared
with third-parties and certainly the you
know central app repositories on the
desktop could you know go leaps and
bounds to improve that the notification
bar seems like a useful place to notify
people that vibration because it's
intuitive because vibration is typically
used for notifying people tonight so I
would imagine that when my phone
vibrates I think oh that's probably
something I should ensure but but it's
seen as not to fit so much with the
phone is getting hot or the tough time
just change or or do this I don't know
we haven't investigated that so time
change I don't think is I don't know I
mean that might be more appropriate for
settings the idea that we're thinking
about is you know using the notification
bar for ongoing things because you have
a passive indicator and if the user is
concerned about something that they
notice that's currently happening you
know it's just you know they just have
to glance up I don't never yeah I
honestly don't know I think that's an
interesting test case but you have time
for more you but we also</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>