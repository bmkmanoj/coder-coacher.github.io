<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intersection Workshop - Relighting Objects in Images | Coder Coacher - Coaching Coders</title><meta content="Intersection Workshop - Relighting Objects in Images - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intersection Workshop - Relighting Objects in Images</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/5WC2I5nqa5c" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay delighted to be a thank you card so
there's a clock on the wall which has
revealed itself to me which seems to be
invisible to me so I'll try and keep the
time so I live in the cornfield
surrounded by about a million corneas
and many people don't know what's going
on out there two pieces of news from
agriculture land one is the second
edition of the book I have a co-author
who is taking complaints and take my own
little edges so send it to him and the
other is we just hired by others Evan I
should have mentioned the names of the
innocent bystanders who contributed to
the talk that i'm going to give
including Derek Lowe my my colleague my
student Kevin cash ditching they are my
student and our extent varsha header so
I stuck in a bit of ideology because I'm
just a visual recognition workshop last
week and in the old days we used to
believe that recognition worked by
assembly generalized cylinders and then
good things happen then we'd be fine and
then we changed our minds because this
was all obvious nonsense after about ten
years and then we started believing a
new thing which said object categories
are fixed and known and every instance
belongs to one category and you can get
good training data so you fool around
features bung it in a classifier and run
and then that comes right now this is
also clearly obvious nonsense in ways
that are reasonably easy to explain but
there are some Unity's between these
nonsensical vehicles and these Unity's
are over worried what is this view that
recognition is a process that plods
through stages from early vision to
mid-level vision to high-level fish and
actually is coming option why probably
what happens is interpreting the visual
world is a kind of spaghetti a little
bit of information happens here
move to their another piece comes from
here and they all kind of bump into each
other or the right thing happens and I'm
actually going to illustrate a piece of
spaghetti with a reasonably plausible
story about materials so there's not a
classical view of material estimation
which says it's an early visual process
we do some color constancy we do a bunch
of sort of texture discriminative stuff
and then we know what things are made
but i'm going to show you an alternative
which is you figure out a whole bunch of
geometric stuff about the world you
figure out an illumination context and
then you can just read the material off
so where does it start well for some
years Derek and I have been thinking
about rooms why would you think about
rooms people live in rooms although the
geometries are complex you can get
fairly natural simple parametric
approximations doesn't matter too much
if you get them slightly wrong you can
think about priors from building codes
and objects tend to be made of
interesting things for their manager so
about three years ago varsha head out
but this thing where you could figure
out you first figured out a bunch of
vanishing points that's the top row
green red blue and then you could make a
rough guess as to what the walls look
like and that's the middle right so the
back wall is yellow the floor is green
and so on and the purple stuff is
clutter and then once you've made that
estimate you'd say well the clutter
isn't going to tell me anything about
the room are now what I'm going to do is
ignore the clutter re-estimate and I'll
get the box of the room automatically
and those boxes are not perfect but
they're moderately good and they give me
a kind of structural and geometric
context for a room so once you've done
that you can build a bed detector how
can you build a bed detector well bed to
access a line if I know the orientation
of the floor and the walls then what i
can do is figure out defamations of the
image that make the sides of the bed the
top of the bed be frontal build little
detectors in those frames for bits of
bed and then put them all together by a
little sort of geometric co-occurrence
reasoning and then we had the world's
best bed detector for what for what it's
worth and it works really pretty well so
we put boxes on top of the beds and we
know where the beds are in the rooms so
what might you do about this
well one thing you could do is you could
say well there's all sorts of other
geometric reasoning you could do about a
room so for example eben I've gotta and
colleagues said look if I go a picture
of a room and I know a little bit of
geometry where the box is where maybe
the bed or furniture is then I can
figure out where people can do things
you can sit with your back on this you
can sit without your back on the lower
one with a guy sitting on the purple you
can lie down in the pink places and you
can reach and touch with different kinds
of reaches different colored places now
when you look at these pictures just
actually put your fingers in your ears I
don't want to hurt your feelings but
when you look at these pictures some of
these people are pretty gigantic for the
room spaces and that suggests that
estimating this 3d structure involves a
little more than sticking on lines on
images and about the right place so the
scale over there is a little wonky with
respect to people and that's just
because it's hard so then what could you
do well what you could do is say I want
to know more about furniture now the
problem with furniture when you say that
is you very quickly discover most pieces
of furniture are difficult to tell apart
sofas look like beds big fluffy on
chairs look like ger sort of boxy tables
and it's just a mess so instead it seems
kind of natural to try and parse the
room into free space here are the boxes
that are occupied this is where you
could move and then later on where you
know when you know what the boxes are
figure out what kind of boxes so
estimating free space is tricky of
course because small areas of 2d give
really big errors in 3d but one can do
it so we've got a process for finding
boxy objects we're going to assume that
their axis aligned a little bit of
search will make that go away um you
could quantize to a small set of aspect
ratios I don't need to get the aspect
ratio exactly right I just want to know
where the boxy object is and then what
I'm going to do is group local cubes
little bits of parallel line corners and
that sort of staff to find proposal
boxes this is something that might be a
box that might be something that would
be a box now when you try this you
discover that there are an awful lot of
potential
as in images there are lots of little
local cues that react to one another if
you build a decent search you can get a
box out of almost anything and then what
you have to do is check which ones are
right and you can do that with
contextual cues you can say look you
want to be a box over here what boxes
are next to you what boxes are inside
you what are their scores look like and
we're going to rescore everybody and say
I believe you but not you and you can
make it discriminant and then you can
refine the boxes so the refinement is a
mildly tricky thing we would really like
to get the Box in the right place the
problem is that most furniture is not
actually a box it's a box with little
legs and sticks down and if you get the
little legs wrong then you're not going
to get the box right so what you need to
do is at the bottom of the boxes in the
image search for evidence of legs and
move the box around just a little bit to
get its position right and you can do
that you'll earn a scoring function you
move the base around you adjust until it
looks good and then the box is improved
and this is stuff that wash your head
out as in this year cvpr and it really
helps so the top row shows a bunch of
automatically determined boxes in rooms
and you can see they're all a little bit
wonky with respect to the position on
the floor and on the bottom row that
contrast refinement has been done so
this delius sofa has quite long legs the
original box was in the wrong place now
we've got it in about the right place
and down here what you're seeing is
estimates of the floor right so this is
the initial box the little green target
is the thing you want to put your purple
box into so this is where the box
actually is on the floor not in the
image so it's a 3d thing and here's what
happens with the refine box as you
refine them they tend to go into the
right place by the way many of them are
wrong I don't want to apply by these
pictures would we get them all right but
you can infect score your ability to
identify free space in 3d and you
probably should that's where free space
camp is not in the image so once we've
done all this we can detect boxes i'm
showing you sort of
mated pauses of rooms made by the boxy
object detector using the room context
works nicely what do we do next so what
else is in rooms and the thing in route
that is in rooms and that gets neglected
is light like why well the great hero of
studies of elimination in both human and
computer vision is standing here on a
beach and then if you look around if you
have a sense that if an object just
happened to be there it would be
brightly and uniformly eliminate whereas
if you went over to this room and you
put in our deck down in this corner it
would be dark because there isn't very
much like but if you put it up here in
the front and the scene it would be a
little bit brighter but if you pushed it
back into the coroner under this light
source would be really very well and
people have percepts of this form you
can look at a scene and you can say it
would be bright over there and it would
be dark over there that can reg has
demonstrated in some experiments that
with all sorts of ifs ands and buts
people are moderately good at that now
what we have is a rough geometric
description of a scene we could get it
automatically but right now for the
stuff i'm going to show you most of its
been marked out but it's at the same
kind that i showed you for room so you
figure out the box of the room you stick
a little box in you know where things
are now what I want to do is insert
object so I'm going to do that and I've
inserted a bunch of objects what's near
it's not that easy to tell right so
semantics helps a lot something
everything going on in the projector
over here i think is reducing my images
to six bits which makes a little bit
worse can see some stuff going on there
we don't have torres's on the floor like
so that's probably a fake nobody really
has little bits of geometric not Theory
lying on their tables so that's probably
a fake that bullet turned up in every
computer graphics paper since about
nineteen ninety so that's probably a
fake but what else is fake so
penguin yelled I was about to tell you
what audiences did which is they
identify the penguin as a fake it's not
the crystal ball is the fake and we can
see that by going backwards and fort so
I'm asked penguin was always there okay
so how do we do well it's actually very
straightforward and we've got pasted all
over the shop by referees for not doing
anything complicated but it's neat and
it works oh there you are I've got an
input image and I i estimate geometry
now right now we estimate geometry by
having people mark the top of that table
and they can either take the automatic
box estimate and say they like it or
they can fix it but you could see from
the stuff I talk to you about pausing
that mainly that estimation of geometry
could be automatic fairly soon then
having done that we do something an
awful lot like rednecks to figure out
the albedo's of the surfaces involved
and then we estimate lighting right now
nobody has a nice light finder so we
tell people to mark the lighting and
then just mark it on top of the scene
and there's a secret sauce here which
I'll show you in a sec and then what I'm
going to do is I now have a model of the
room very simple geometric model box
over here box on the outside of the room
I stick my assorted pieces of computer
graphics into that model and then i
render them with a physical realm of
physical radar is over wonderful things
nothing to worry about and then i can
possible question
um all sorts of interesting things give
me a second i'll show you some examples
the things we can't do right when happy
on that so one sort of important and
really useful thing is re s timate
enlight parameters right so over here
you can see this is in fact the initial
estimate of geometry rendered with the
initial estimate of lighting for this
room and it looks pretty lousy one
reason it looks pretty lousy is that the
material estimation algorithm rings in
the way of these things and you can see
these funny little ridges in the ceiling
with a caused by and if you simply took
this estimate of the environment and
rendered objects with then you get funny
bright looking bits of geography that
would be a bit of time so there's a
really simple trickier what I'm going to
do is I'm going to take my illumination
position estimates I'm going to take my
arm and then I'm going to take my albedo
estimate on my box estimate and I'm
going to render that and then I got to
move the lights around until the picture
looks most like the image I've got and
then i will stop that gives me a way to
duck some of your question but not all
of it right if the light really is
coming from space I'm in trouble but if
there's just a little bit of light that
I'm not sure about I can fix it up like
that and if i do that things get a whole
hell of a lot better so the light they
moved around the render the world still
looks a bit funny but the compositing
will take care of that but because I've
moved the light around my objects look
better these little blue rings have
nothing to do with me blame the
projector and if the only projector
that's ever done me too so there's a
little group looming over there let's
move moving over there it's not in the
original image oh because you saying
we've light around you I mean literally
shift the colors of light changes
interested strange because of the user
marked it right it's a correct decision
none I guess you try to you mean there's
a lot of intellect incisors London it's
a very reasonable thing to the first of
the user may not about to write secondly
there are errors in my geometric
representation thirdly there errors in
my material estimation right so what I'm
trying to do is say look adjust the
light so
errors tend to compensate for each other
if I get them to compensate for each
other and not really about canonical
estimation if I can get me the the
errors to compensate I'm going to be
better and that's small it simple um now
there are other things I'm going to want
to do as well so in rooms like this one
there are holes in the ceiling and they
let the light in from the Sun and I want
to figure out where they are because
they're going to have illumination of X
how am I going to do that well that's a
sort of inverse shadow process you can
think about those as inverse shadows so
we fire up to dawn Richard well shadow
detector and it tells us those are the
mic shaft and then we can render things
real picture plus extra bits of computer
graphic real picture various graphics
tab a real picture various graphics tat
real picture statue inserted this one a
lot real picture statue in sir see what
the skylines did very nice sort of
pretty effect on the surface and of
course you can do this for movies that
thing started life as a photograph on
flickr and you can play billiards on the
surface than the mytouch fight like why
because we got that simple geometric
representation of the simple elimination
representation this is I think our best
movie arm that started life as a
photograph on flickr little glowing ball
wanders into the room flies around gets
reflected in mirrors does all sorts of
other staff casting shadows and looks
right now the important thing about this
from the vision perspective is this
thing looks really quite good with a
very very limited quality model of the
world our geometry is simple our albedo
estimates are almost circus somewhat
wrong and a lighting estimates that
almost certainly somewhat wrong and it's
still it's fine so we had some trouble
with referees because everybody could
spot the errors in the pictures we
produced even if they weren't fake
pictures so then what we did was we did
a user starting to establish whether
people could spot lighting errors and
it's a fairly straightforward thing here
are two pictures are for one of them all
of the stuff on the table is fake
in the sense that we took a photograph
of a flat table with nothing on it and
then we inserted some computer graphics
for the other one the objects actually
physical objects in the tackle and you
just have to choose which is which and
I'm not that good at left and right this
one all that remember the pink stuff on
the table has to do with the projectors
nothing to do with us and the little
green hello there again the projectors
doing something to the last step so you
might think that this was a little like
natural you might also think that that
was a little unnatural you might be
worried that this is bry and that isn't
as bright it's not that easy to spot
which one is right but it turns out that
the offset use as far as I've given up
trying to remember it because I get it
wrong Ronnie hmm yeah yeah he didn't
estimate the transmission coefficient us
cry okay and we did a user study and
basically what happens is if you show
that test of people for a whole bunch of
images about a third of the time they
choose us over the real picture and the
rest of the time they choose the real
picture remember chance would be fifty
percent so we did pretty well um now
there's all sorts of neat stuff we can
do with an idea like this so here's the
material story starting and now my story
is going to get patchy I'm just
sketching where we're going the thing
about this is I've demonstrated fairly
comprehensively that I know where light
is in a picture right why because I can
stick things in the picture and the
light looks right now if I have a
photograph of an object where I know
some information about its shape I know
all of the light coming in and I know
all of the like going out the reason I
know the like going out as I see it in
the picture so i should be able to make
material estimates like albedo speculate
oh fun parameters roughness that sort of
stuff and the material estimate i want
to make is the stuff that modern
renderers used why because a whole lot
of stuff is known about how to use it
and what to do with it oh that's a
photograph of a bunch of spray painted
test spheres they're always called
spheres or
test objects after the consequences of
not calling them ping-pong spheres I
stuck a little Buddha in that picture
that's a computer graphics quarter now
what we do is steal the material from
the gold sphere and stick it on the book
right he looks good if you are really
discriminating you'll notice a very tiny
color ship again there's plenty little
green things which are not my fault of
course we might want other materials so
we can steal the material from the red
sphere and bug it on the butter and then
from the dull blue sphere and from the
Bronx one and you'll notice that the
gold one is nice and high 90 the red one
is not quite as glossy the blue one is
really quite dull and the bronze one is
more highlighting just the way the place
one so that's currently from here oh you
want the specularity look for glossy
bits around his whatever that you don't
have it's not like a dick Cherie velvety
or anything I haven't shown you any
numbers here ok look at them will get
them not going to show you any numbers
today we'll get okay now what would we
do about more complex materials so
there's a just a sketch about what you
could do with simple material parameters
but materials come with all sorts of
really complex spatial phenomena and we
kind of not need to know what to do
about so here's one potential
application you could try and reshape
fragments instead of reshaping geometric
object and that's obviously much more
interesting because the fragments are
going to have hair and fur and all sorts
of other stuff so I want to take a
segment out of an imagery shade it and
stick it into another picture how would
I do that well some time ago bunch of
people pointed out including Alyosha
there is just wonderful to make pictures
out of pieces of other pictures the
problem is if you choose the things with
the wrong shading then it looks out so
if you look over here this teapot it has
to be floated as does that one and the
ostrich is a bit funny because there's
something funny about destined empathy
we just these are just plunked on top of
the picture now if you do it right it
looks like that but you can see the
teapots casting a shadow the little
green fringes on the shadow of something
to do with the projector the ostriches
out of focus as it should be the other
team part is actually creating a
specularity were all sort of happy how
would you do that well really rough
shape from contoured to get really rough
probably wrong estimate of fragment
shape then I could get albedo from a
rednecks like algorithm and then what
I'm going to do is say all of the other
stuff about the materials on the surface
that I don't know is going to live in
detail maps and those detail maps would
be image-based when I reach a dime going
to reshape the rough shape so the shadow
will move from the left to the right but
all of the little hairs on the
check the shadows will be where they
used for those pets but nobody can do
that consistency problem anyhow meaning
people can't spot it you need to be a
real specialized photo forgery detector
before you can tell so we're going to
sort of hope the battle encode the
missing things and I'll define my
detailed maps really simply it's going
to be the frame minus what I get by
realizing that bad shape estimate with
the okay but not spectacular albedo
estimate and various different infernal
eyes and each of these will give me a
different detailed back and then I can
composite the detail Maps back once
every like real at the object and my
rendering process is going to be what I
did last time I'll shave the approximate
shape with the approximate albedo in the
environment lighting and then at the
last moment i'll add in the detailed
maps with whatever waits appeal to me so
for example on the top i've got a
cut-and-paste of a bunch of little hand
drawn and painted figures on a
photograph and you'll see they seem to
sort of sit on top of the photograph now
if we do what I described with different
amounts of details so these are
different detailed maps or rather
different weights on the detail and you
can see they appear to be made of
different things and different stuff is
emphasized you get a series of different
pictures whether you like one or the
other is largely up to you however all
of them look like paper cutouts sitting
in the space rather than on top of the
pitcher and you can get quite nice
results with these detailed maps so
there's a dragon over there again this
is an image segment no 3d model and
you'll see he's got sort of big scales
and stuff we're going to drop him in the
room light him from above and he's got
that his scales stick out and he's got
little specularity s and so it really
looks pretty good we've got a koala bear
covered in fur no hope of doing anything
sensible a fraught with shape from
shading or anything else bung him in
there looks pretty good again sorry
yes started life as a picture um the way
we get normal information the only
normal information we have is normal
information that's smooth in from the
ePub we have no other normal information
and that gives us a shape from contour
estimate that I can almost guarantee his
rock that's not wrong in spectacularly
bad ways so for example because he's
look from above we know to make this
darker than that lighter because it
bulges out but we do not have normal
information for the staff now there's an
actually question here which is whether
you could get it and there's some
evidence based on the previous material
stuff I showed you that you might
actually be able to get but we don't
have it right now so we knock while in
the snow and the graduate student
involved confesses he's never seen a
penguin so he does know how big it
should be but that's again a just a
segment of a penguin and he looks pretty
good yeah that's what the albedo thing
is all about ok- with the albedo
estimate comes from now the thing about
this is you preserve a sense of material
in a way that's possible so there's sort
of suggestions about the representation
of material which are kind of attracted
the original object is legend wager
similarly here
yeah and I wish I had a metric for
telling you when I was succeeding
because then i could tell you roughly
what would blow me up so sometimes you
can get really big changes of like other
times you up dead and i don't have any
more sensible statement than that so we
have a shallow this is a room it's a box
we got a bag spoiler shadow I mean under
shadows on the floor or another
direction the light is traveling it so
we know this one stick a koala um no but
I but you can't do shaken shadows anyhow
and I've got a shape and contour
estimate of the Koala which is just a
bug OIC sister when you connect a teddy
sister yeah so examples where this fails
oh yeah oh yeah so do i have them with
me in the slides no i'm not you know
wishing to trot all of my failures out
but i don't worry yet folks so what are
the things we one of the things we tried
to do and this will give you an idea of
what's going on is faces and the thing
about faces is depending on how the
light moves you might be okay or you
might not so the course shack model is
always above if the light moves are bit
and doesn't reveal the fact in the
shadow movement that you actually know
where the nose is it's fine if it moves
a lot you know from down here from up
there two down there you are dead why
can I tell you what we can get away with
nada
is the tree shadow and the show yes ah I
think that's a rendering question what
the composer I think got it right it's
probably shout yeah but it might be a
compositing oh I wish so way to make the
new fuck game or maybe right maybe next
year okay another thing it's kind of fun
about this is these detailed maps
conceal some of your ignorance about
shape so this is a picture from the MIT
shape data set and that's the albedo a
guesstimate so it's flat it's just
Albion and then up there is our shakers
and I'll show you the real picture in a
second of the real show and you'll see
our shape estimate really is pretty
hopeless um that's our shape estimate
plus a detailed map like that it just
begins to look like a thing it's not
quite right so this is the actual this
is the actual picture and that's John
barons photometric stereo estimate of
the show which isn't as creepy as you'd
like who in fact sorry I'm wrong that's
John bands photometric stereo estimate
of the shape this is John's photometric
stereo estimate rendered with albedo and
some directed life and it doesn't quite
look like a piece of paper if we then
add our detail map on it just looks more
realistic right that's our sheykh
rendered with our detailed map pale
light and that's John's shape John shape
is better it helps to get a reasonable
shape estimate but it's not catastrophic
to have a lousy okay give me a second
alarm so I'm just finishing and really
thirsty I think there's a recognition
stuff because we're reasoning about what
objects are made up and that's
recognition but it's not a sequence of
steps information is sort of wandering
around the landscape
picking things up and the ideology that
I imposed last week is we're having
trouble talking about early mid-late
vision because we don't know what needs
what and we don't really know what's
important than it would be nice though
more but so cute it's a photometric
seriously I don't know how John got John
sat down with the a bunch of the MIT
surface intrinsic images data set and
did the photometric stereo
reconstruction system you might want to
one might want to argue with him about
why there aren't creases but I rather
suspect he's done it well because all
the other stuff is done is done for a
crumpled piece of paper then I'll be on
top it's the one that John is
propagating as ground truth we just took
it from its we could try and do our
reconstruction see supra got it better
music so basic facts that when you we
like things with dodgy geometry it
doesn't seem to really maximize that
just because of human perception or is
that just because it's accordingly
problem
so it was my belief that this is worth
trying it because people are extremely
bad at assessing the consistency of
shadow directions between small shadows
and large shadows you can do all sorts
of nonsense when you make photo fake
photographs with shadows so that famous
examples of two people standing next to
each other and one of them has the nose
shadow going this way and the guy on
this side has the nose shadow going that
way which means the Sun is about 10 feet
in front of you the people are really
bad at you know it's dark on my left
side and lighten my right side but my
nose shadow is going there and this is a
play on that I don't believe I've
certainly never found anything in the
literature that says how bad at what and
what you can get away get away with ah
yeah but you know the crispness that I
was talking about is not really that the
psychophysics that says kevin i says
shadows of dark which is helpful but you
know within limits there's a bunch of
stuff about shadow inconsistency and
there's a bunch of stuff about you know
down Kirsten Bosio chatters but
something that says you can do this with
people won't like this and you can't do
that it's just which is not there the
material representation that I'm
suggesting here says that at least some
of the way you want to think about
material is as a sort of image based
add-on to cover macroscopic complexity
for microscopic detail because you can
get away people just don't notice that
you've been up
it seems like when you're interacting
with the scene your license right you're
going to start discovering problems and
wondering in your experience because of
the geography overshadowed by driving
experience has how easy is it for those
of you face um I think it's a very deep
question so if you think about making a
movie like this if you want to make a
nice movie you really really want to
keep away from the things you don't know
so for example imagine i say i want to
make a movie of a ball bouncing on the
walls of a room and you know with a
little bit of Carrick and make sure that
it follows a robotic putt it's going to
go near every piece of jelly and
eventually it's going to expose the fact
that my model of this wall for example
is that it's flat without a little set
or at least close in fact that yeah I'm
actually thinking about being flat now
from the point of view of geometric and
emotions that that's a really big deal
right if you're trying to walk the
pictures you can you conduct that
question from the photometric point of
view so if you are computing lighting
compensation does it cost you very much
not to know that this is sticking out of
for the odds basically now to what
extent let me move some of this
Australian in a bit mystery but you
could conceal your ignorance really
significant that means if you one of you
see
mr. you don't miss certainly together
but we basically no variable about this
picture and we can do a whole bunch of
stuff there are things we can't but
other things we can do other more
interest questions looks like um we've
done some we've already done that
because when we cut the fragment out of
one picture we don't actually know what
the camera was but so in our shape and
contour we have to introduce deliberate
errors to ensure that there is a crease
on the bounding contour of the object
because when we stick it in the new
picture we're actually going to be
viewing it from a different viewing
direction than the old one and if we
didn't put a crease on the bounding
contr then a whole bunch of pixels would
come into view that we don't know
anything about right so we sort of duct
a bullet over the camera has already
moved just a little bit can you move it
more probably a little bit eventually
when you move it you expose your
ignorance about the shape just in the
same way it is if if you move a light
around ahead eventually the fact that
you don't know where their noses is
going to become apparent how much I do
not
real objects how users able to notice
that several views of the same two or
three
and how soon they were able to realize
that the two
let me pass over a fact you which
suggests there that would be much
messier than you might think so when we
did this user study this is to
alternative forced choice and we did it
because of the referees we were doing it
simply wouldn't believe that they
couldn't get the answer right I'd say
you rack up a bunch of users and that's
a little easier um one of the things we
noticed is that people got the answer
right or often earlier in the study
right so your first couple of pictures
you tend to make the judgment right and
then as far as we can tell what happens
in Sydney what happened to me was I
thought cheap this is a reliable q2
what's going wrong and then I screwed up
a whole bunch of other images by
basically over generalizing on the queue
and there's some mild evidence now user
study that other people were doing that
as well so you know the question you're
asking has layers of complexity in it
would be very difficult for me to spec
no no no no no it will sense questions
what do you need to know about a picture
that seems like an interesting question
here's another one um how should I
estimate the materials and objects the
usual thing is you know you look at the
picture you figure it out I'm giving you
completely different arts figure out the
geometric context the scene figure out
what the light is doing and you can
reopen until there are practical
applications so if you have a very
expensive leather sofa you want to sell
to someone then they can take a
photograph of their living room and you
can put your sofa into their living room
and it looks like it was there and
everybody's happy so that you know
that's got packages but I think they're
fairly deep questions about vision there
our community is very largely chickened
out on so almost nobody does a shape and
shading or talks about it I do today was
the first time I've heard about it for
years intrinsic images albedo that sort
of stuff people been quite about for
decades with the Honorable exception of
Ted Olson and Bill Freeman in those
recent papers are questions about what
light is doing in space and what you
know about illumination just haven't
been touched it's palpable that people
know something about what illumination
is doing in space like there's evidence
of the psychophysical literature back to
the seventh without having objects
no it's just a physics council free you
stick it in a physical right around that
do it yeah we can talk about physical
rendering details for hours but you know
we we know how to do that we've known
for years this is we just use that stuff
you don't well I do some of it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>