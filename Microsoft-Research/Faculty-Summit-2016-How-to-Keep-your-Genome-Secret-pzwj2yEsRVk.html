<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit 2016 - How to Keep your Genome Secret | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit 2016 - How to Keep your Genome Secret - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit 2016 - How to Keep your Genome Secret</b></h2><h5 class="post__date">2016-07-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pzwj2yEsRVk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright so thank you very much for your
patience thank you very much for
inviting me Melissa and everybody else
I'm really excited today to talk to you
a little bit about what I believed to be
is the let's say the good news and the
bad news stemming from recent progress
that we have seen in genomics and
genomics research so when I started
working in this area it was very
interesting to me how costs of old
genome sequencing were dropping how fast
we're dropping so much faster than what
Moore's law will predict I'm sure many
of you have seen had this gruff before
but you know it's it is clear to me that
we really went from what it sounded like
a futuristic venture like the Human
Genome Project which took 13 years three
billion dollars in investment to
sequence one human genome to you know an
increasingly affordable technology right
so we have companies in this space like
alumina or Oxford nanopore that can
fully sequence a human genome in a
matter of hours for you know costs in
the order of one thousand dollars if not
less and so this is enabling you know a
number of initiatives aimed at
sequencing large amounts of individuals
worldwide so in the UK we have a project
to sequence 100,000 genome hundred
thousand genomes in in the US you know
of course everything has to be bigger so
we have a project to sequence 1 million
people and you know in general we have
seen an increasing number of individuals
having access to two genetic testing
having they're getting their their
genome sequence so why is a whole genome
sequencing such a big deal right so you
know for for for decades we we have used
we have been doing genetic testing and
we have used what typically is referred
to as genotyping which essentially are
in vitro processes
in vitro tests to essentially looking
for known genetic differences using a
set of markers so you go and look for
the presence of let's say genetic
mutation for instance right but now you
know the ability to completely sequence
a human genome kids hope to scientists
so that they will be able to study they
you know essentially the entire genome
sequence and understand what they don't
know and how the genome as a whole works
so how you know the different genes work
together let's say to direct the growth
the development and maintenance of an
organism's right so an important point
that I want to make is that you know the
whole genome sequencing is already
helping researchers to gain a better
understanding of diseases and their
relationship with genetic features and
you know this is already bearing fruits
in let's say the clinical setting not
not only in the research setting which
maybe you have you have heard of a
little bit more like cancer you know
research of cancer or Alzheimer's and so
on so you know there is more and more
news coming from from our hospitals
where you know sequencing has safe life
right so we have been able to to to to
diagnose and cure patients thanks to
whole genome sequence however you know
this kind of genomics revolution if you
let me use this expression it's not only
happening within the walls of our
research labs our hospitals you know
it's something that is entering our our
our society let's say right so and I
chose to to pick the example of Angelina
Jolie who was diagnosed with a genetic
predisposition to breast and ovarian
cancer and you know her decision to to
undergo double mastectomy and
hysterectomy really put let's say
genetic testing in the spotlight if not
for the debate that is generated there's
also an increased market of companies
that are commonly known as
direct-to-consumer genetic testing
companies
like 23 Emmy is definitely the most
known one so I mean there they
essentially sell products marketed about
a hundred dollars or so where there is
no involvement of a doctor of
professional so customers essentially
get a DNA sample DNA kit they deliver a
saliva sample they mail they mailed that
in and after a few days they have access
to a website that you know displays the
users you know the results of this
genetic testing so they can learn things
like whether or not they turn red if
they drink alcohol or you know whether
or not they carry some some trait so
some some genetic variants that are
known to you know cause some genetic
disease or you know the predisposition
to certain diseases or how they would
respond to certain drugs for instance
like warfarin a common blood-thinning
drug so in general as I said there is an
increased number of individuals that are
they do get access to genetic testing
motivated by you know medical reasons or
personal curiosity so for instance they
want to find out about their genetic
ancestry so their ethnicity and you know
they learn that are nine percent finish
or something like that so there are
companies like again 23andme or aunt
sassy com that offered these services
and again like 23andme and others that I
also allow you to find what they believe
to be your relatives in genetic terms
let's say so for instance a cured third
cousin or your fixed cousin looking at
other customers of of 23 me and keep in
mind that 23 me has more than 1 million
customers so you know it's a it's a
non-negligible size right so you know
now having said that you know I as I am
a computer scientist right so I'm not a
geneticist I'm not I don't work in
biology and you know to me whole genome
sequencing really sort of means turning
this like a double-stranded polymer of
nucleotides into
days right data right so this is a the
output of I think luminous sequencing
machine is a some files and you know it
contains reads like these nucleotides
these letters and some additional
information but you know as as any with
any kind of data we computer scientists
and by infirmity shins we need to store
it store data somewhere you know we need
to essentially provide tools for
researchers or for clinicians to you
know search this data perform queries
computation and so on right but it's
clear now as a as the privacy
researchers is clear that not all data
are created equal so some are maybe a
little bit more sensitive than others so
I like to maybe discuss a little bit
what I believe to be the specific
features of genomic information so you
know it is clear I would say that you
know genomic data is a treasure trove of
sensitive information in that if you
have access to to my let's say sequence
genome you can quickly figure out my
ethnic heritage maybe police my
predisposition predisposition to
diseases maybe even including mental
conditions and so on right it is also i
mean a genome let's say by design is a
unique identifier right it's a the
ultimate identifier and as such also
considering its hereditary nature it
becomes extremely hard to anonymize
effectively anonymize or d identify
genomic information and you know this
also means that you know if you leaking
one's genome essentially implies leaking
close the genome of close relatives
right which also means that you know the
sensitivity of this data is almost
perpetual right so even let's say 50
years from now if you get a hold of my
of my genomic information I might not be
around or may not be able to complain
but you know my kids and grandkids might
right so because the genomes are so
close close to each other right so in a
sense
it's kind of I mean it is a unique
threat here in the sense that you know
with other kind of sensitive information
like I don't know if someone compromises
your credit card information your
password or even your social security
number you have mechanisms to recover
from that right and you know you can
issue even issue new security social
security numbers I guess but you cannot
really issue a new genome to yourself
right and you know as I said its
sensitivity extends probably beyond one
person's lifetime so this is sort of
creating may be a conflict between
privacy and the greater good you know
the fact that research in genomics is
extremely great news for us is helping
us fight cancer and so on and you know
maybe I'm stating the obvious here but
you know the progress advances in
genomic research is highly dependent on
on the availability of data on data
sharing but it's an important asset for
for researchers worldwide in fact in
certain countries access to public
funding for genomic research means that
you you have to make a best effort to
make data available to other researchers
so if you sequence you know thousands of
individuals you should make this data
available right and even if costs drop
quite quickly you know it's it's
unfeasible to assume that every research
lab has the ability to sequence
thousands of people right so you know
and let's not forget that a lot of the
studies like what we call genome-wide
Association studies where you know
really you you try to do to understand
if a variant and genetic mutation let's
say is associated with a trait really
require access to large number of
genomes okay so this is sort of
motivating a new research community
which I'm going to call the genome
privacy research community which
essentially has been doing the past few
years two things one starting the
privacy issues carefully analyzing
those issues and and to designing
privacy-preserving genetic testing
algorithms and there is this amazing
website genome privacy org that has been
keeping track of essentially all papers
published in in this area so if you're
if you want to know a little bit more
this is a great resource so in the rest
of the talk i'm just going to give an
overview of what I believe are you know
the main results in this area starting
you know with with with studying privacy
issues and you know these are I'm going
to select let's say the most visible
papers may be the first one so you know
if you're in the audience and I don't
cite your paper I apologize I'm going to
blame time constraints okay so the first
the first one I want to talk about is
the anonymous relates to the
anonymization of genetic information so
there was these high-profile paper back
in 2013 published by a science where
Melissa game racket at all showed
essentially the feasibility of Rio
Dental DNA donors from a public research
database using information publicly
available on popular general ergy
website like ancestry com and other
available information so you know you
you have some part of data that is
supposedly an anonymous like this
research database Personal Genome
Project and you have some other
information that contains identifiers in
this case was actually down to family
names or a class name and now you
correlate this data using the fact that
genetic information is hereditary by
nature and and so they were able to pin
down a last name of anonymous donors in
forty percent of cases so for those of
you are familiar let's say with the
famous Netflix the anonymous Asian paper
I mean the techniques are sort of
similar ok so the internal organization
is hard you know we should if we go that
route we should be extremely careful but
how about aggregation right so
aggregation is
so very hard in genomics so I mean
there's been a couple of high-profile
studies that show that you know even
from even statistics from allele
frequencies so just let's say reporting
you know how many how many donors
exhibit certain characteristics can be
used to read n tify genetic trial
participants so too for instance test
for the presence of a specific
individual let's say a victim in a group
so you know even aggregating data so
doing privacy by by aggregation it's
something that should be done extremely
carefully and I mean these are just two
example of the attacks that have been
presented in this space another study
that I want to cite is one that comes
from epfl that looked at the concept of
kin privacy as I mentioned before you
know if your genome is leaked then
privacy of your close relative is also
hurt and so you know they were motivated
by this kind of real-life case of
henrietta lacks who was a cancer patient
that you know died many years ago and
without her consent researchers
worldwide have been you know using her
genome for cancer research okay so you
know again she's no longer with us but
her family still is I her her
descendants right so you know this paper
try to really quantify how much privacy
relatives lose when once you know miss
leaked and if you're interested a little
bit more in understanding you know
besides this genome privacy dark website
there is a couple of nice surveys
including ours sorry for ever for the
shame shameless self-promotion that kind
of look at all the results in this base
I also want to make the point that you
know these studying privacy issues is
not something that has been done only by
computer scientists you know looking at
these kind of characteristics of data
but you know also social science and you
know anthropology and psychology
ethics communities have looked for
instance at studying individuals fears
and concerns related to genetic testing
and genomics okay so as I mentioned
before I mean this this kind of fears
may be related to you know disclosing of
sensitive information so they usually
relate to fears of being discriminated
let's say in the workplace or by elf
insurance providers so researchers have
looked also a perceptions of of people
as well as reactions to Learning tests
outcomes you know like having
predisposition of to get cancer or
Alzheimer's and also learning you know
results that you did not really expect
like this case where someone learned
they had a half-brother and is
ultimately led to their parents getting
divorced okay ok so now going to the
second line of work so how can we enable
genetic testing while preserving privacy
of individuals okay so one important
result in the space came back in 2013
when aaron johnson vitalis particle
investigated the feasibility of applying
differential privacy for you know
genome-wide Association study so the
differential privacy for those of you
who are not familiar with it consists in
adding noise to data set with the goal
of supporting statistical queries while
you can probably preserve the privacy of
individuals whose information is
contained in the data set yeah so in
this case you know you trade off
accuracy with privacy and you can
support you know queries like computing
the number or location of snips so these
genetic variants associated to a disease
or you know significant correlation and
you know there's the results I mean they
do suffer from an accuracy loss but you
know they they showed us that this was a
viable
ebony there's also been a lot of work
and I think we will hear about it in by
from from the next two speakers on
computation over encrypted genomes so
there's been a lot of work coming out of
Microsoft as well as people in Estonia
that have been using you know what we in
cryptography we refer to as multi-party
computation using secret sharing so
essentially you have multiple parties
that you know and you assume that the
majority of them doesn't collude with
each other and then you can you know
distribute this computation in such a
way that you know the input is not
disclosed but only the output another
line of work deals with personal genomic
tests so more similar to let's say the
23andme a scenario where you know you
have individuals who want to have access
to to their genome and they want to have
access to genetic testing so they won't
allow doctors clinicians testing
facilities to do to do this test right
so in this setting privacy for us means
that individuals should retain control
of their sequence genome but still allow
you know doctors for instance to run
genetic tests in such a way that the
genome itself is not disclosed so they
don't have to forego their privacy let's
say only the test output is and I'm
going to give a little bit more details
here but it's also important to
recognize that in some cases also the
test specifics should be kept
confidential so if you know have a
pharmaceutical company let's say that
designs a certain genetic test two for
instance assess the right dosage for
warfarin then I mean these test specific
is kind of like their secret sauce so it
is intellectual property and it should
not you know you should not be revealed
so there is two main approaches for in
this space one essentially relies on on
cloud storage providers that are same I
trust standing in the sense that there
not assume to collude with the testing
facility itself so the idea is that we
have a genomic information it gets
encrypted and stored on to these clouds
the storage and processing unit in this
in this picture and now you know a
testing facility can access it can
perform for instance disease risk
competition without learning the actual
the actual data but just the test output
and you know these are maybe the first
papers in in the space came came were
published back in 2013 but there is
there is much more and the second kind
of approach is to actually let users
keep their sequence genome so not
storing it on on to the cloud but for
instance giving it giving it to the
users in on a on a dedicated device for
instance okay so now what we do actually
is to reduce genetic testing to
evaluating a function right which we can
do right so you want to test for
presence of certain mutations you want
to test you know so you want to find
some patterns did you can express as a
function right and in cryptography we
know how to securely evaluate a function
in that only the test result is this
cool so only the output of the function
is disclosed so nothing is revealed
beyond the test result and so here there
is a number of critter frac
cryptographic techniques that we can use
like garble circuits or morphic
encryption private set operations and
and so on so a lot of papers have been
you know using these techniques to
support genetic testing like you know
testing for snips you know doing this
personalized medicine style tests or you
know paternity ancestry testing and so
on and you know in a sense this kind of
started with our ccs paper in 2011 where
we showed how to essentially scale up to
whole genome sequencing ok so now I'm
kind of getting ready to wrap up and
leave the floor to the other panelists
so I also want to point out that it is
still a lot of open
problems in the space and essentially
one one of the big things that we have
to discuss is that you know maybe
encryption by itself or cryptography by
itself in the space might not solve all
the problems right and the clear one is
the fact that you know encryption we
cannot guarantee the security of any
encryption scheme essentially that are
used today past 30 or 50 years right so
even if i use aes 256-bit you know this
is assumed to be secure for 30 years and
again you know the sensitivity of
genomic information will not degrade in
30 years all right so we need to think
carefully about this and of course other
problems relate to you know efficiency
reliability availability which are
challenged by the use of cryptography
right not to mention that it
cryptography itself makes it
significantly harder to deal with
sequencing errors which do happen today
so you have you know when you read the
genome you know you have insertion you
have deletion you have actually
sequencing errors so instead of reading
an a you read a G right so designing
algorithms that are resilient to errors
is much harder when you're operating
over encrypted data okay and of course
it's also the you know as the
consideration that when you do involve
users you know how much understanding
you require from them in terms of you
know protecting these data saving Keys
saving passwords explain to them what it
means to provably protect their privacy
and so on all right so this concludes my
talk I also want to thank my
collaborators and my funders and you
know I'll be happy to answer your
questions after in the Q&amp;amp;A session thank
Thanks emiliana that was a great talk
our next speaker is going to be shouting
Jan he's an assistant professor in the
bioinformatics biomedical informatics
department at UCSD he's also an
associate editor of the BMC medical
informatics and decision making and on
the Editorial Board of the journal of
american medical informatics association
and today he's going to tell us about
some of the workshops he's been running
on looking at genomic privacy among
other things thanks Melissa for
introducing so I'm going to talk about
Irish privacy and security workshops a
community effort to access the state of
our privacy and security models in
genomic research so as Malini romneya
know has just a mentioning the DNA data
is important to genomic research
biomedical study and it's even becoming
part of electronic health record but at
the same time it also highly sensitive
it brings a lot of issues to privacy and
security so Ling and automating 2004
showed only 75 snip is enough to read n
Phi a unique individual and there are
many other examples for example like the
surname identification by jemerick paper
and recently another paper shows that
even 3d face can be reached contract
reconstructed from the DNA data so the
grand challenge here is really how can
we analyze genomic data in a way that
preserve the privacy of the data donor
or donor without undermining the utility
of the data or impairing it's convenient
dissemination so this really a trade-off
between privacy and utility we can
safeguard competition process using
secure primitives but it has computation
costs we can add noise to the outcome to
mask sensitive information but introduce
artifacts may render the output into
youth use the useless information the
question here is can a state of our
technique to be used to support
biomedical research in practice so I
dash is one of the national center for
biomedical computing center
at a university of california at san
diego where the only center that
focusing on integrating data for
analysis anonymized aging and sharing so
we've been hosting this workshop several
years in a row and recently we have been
turning this workshop into a competition
and we try to use real study to
understand the impact of data
anonymization and latest secure models
to real work biomedical studies we try
to use real human genome data and high
dimension at a practical skill to
evaluate the solutions we seek solutions
a balance and a trade of the privacy and
the utility so in 2014 we hosted our
first workshop on UCSD campus and the
first competition is to evaluate how
effective the best the privacy
protecting technology can protect human
genomic data and analysis result in this
workshop we focus on the challenge to
protect the sharing aggregated snip data
a low-frequency in specific and the
top-k snip identification as query read
out 4G was study so we have a number of
teams participating and quite a few
online attendees and we have two
challenges the first challenge is to
understand the privacy utility balance
achievability when publicly released
snip data anonymous for a realistic gia
study so we define our utility as the
chi-square association test in terms of
significant snip before and after
anonymization and we used one of the
strongest reallocation statistical
attack the likelihood ratio test to
access the resident of the attack model
after anonymization so the attack model
looks like this so given a low frequency
of interest individual of interest x at
each position j we compared with the
allele frequency p and p head of the
case and the control group will
accumulate we can tell whether an
individual is more likely to be in a
case group if there's a highly likely
that the individual is in a case
group then the identity is revealed so
we implement the online tool for the
participants to access their model and
the utility is evaluated on the case
control association chi-square test so
at each snip we have a minor and a major
ally and given case and the control
group we have a two-by-two contingency
table and we can derive the expected
Keynesian table accordingly and then the
difference between those give us whether
the snip is significant the second
challenge is not to anonymize data but
instead to protect the query result so a
goal is given a privacy protection
standard evaluate how much utility and
name how much top kek a significant snip
in terms of the plaintext operation can
be preserved after the Ottoman
anonymization is inserted to the outcome
and our utility is the percentage of the
top K most significant snip in terms of
chi-square test s'okay ranges from 15 to
10 and so on and our privacy privacy
criteria is differential privacy and we
set a privacy budget equal to 1 so
differential privacy is a privacy
criteria proposed by dr. Cynthia to walk
at Microsoft to quantify the information
leakage of statistical information
release and we prepare the data from two
public domain when is from the Personal
Genome Project and the other is from the
hapmap project and for each of the
challenge we prepare two data sets or
why it's released for the participant to
tune their algorithm and then we reserve
the larger data set for evaluation for
the first competition we check the
utility based on true positive rate
false positive rate at different
cut-offs for chi-square statistic and
then we also check the vulnerability of
the anonymized model based on the Rio
Dental occasion power at 0.95
significance level overall the McGill
University demonstrated most balanced
solution for the second competition we
were checking on average of a thousand
iterations how many
topcase nips our return of the
anonymized algorithm because
differential privacy has some stochastic
property so this number is it's a mean
of a southern run as you can see UT
Austin team leader competition and after
competition we concluded that it still
remains a challenge to do
privacy-preserving data sharing of
aggregated human genomic data while
maintaining the utility of Ja study even
for a low side of a few hundred snips
the utility is largely damaged after we
enforce the privacy protection it is
unlikely the current technology will
scale well for the whole genome and but
on the other hand on the other hand and
the privacy technology shows good
promise unpublishing outcome like us
like analysis higher accuracy has been
demonstrated only when only a small
number of significant snippet query and
this is well aligned with the data
computation model to release only the
data to the user so motivated by the
success of the first year we hosted a
second workshop and this year in 2015 we
switch this year to secure genome
analysis competition and to foster
research to address secure outsourcing
and secure multi-party collaboration in
biomedical studies we put two main
application scenario one is for secure
genome-wide Association study the other
is for secure genome competition based
on comparison based on Hamming and edit
distance we have expanded the number of
teams participate and the event was
reported by nature news and genomeweb
eleven teams from 12 institution
participated in the competition for the
first competition we are seeking
solutions of homomorphic encryption
based a protocol to analyze encrypted
DNA data and trusted server and the
first task is to calculate minor allele
frequency and a chi-square statistic
because mine are low frequency requires
comparison and chi-square statistic
requires division these are not trivial
operations in homomorphic encryption and
the second task is
to calculate Hamming distance and added
distance and the protocol should return
only the encrypted result for example
the minor allele frequency a chi-square
statistic and distance which only can be
decrypted by the owner of the data and
that the second task is to run solutions
to enable two parties to work together
to perform a genomic analysis across the
DNA data set without actually exposing
their data the first task is to develop
a distributed a cryptographic protocol
to securely aggregate a minor allele
frequency into data set and the
calculated chi-square statistic of the
given snips and the second task is to
develop a distributed protocol to
securely compute hamming and added
distance between two sequences in remote
institutions so for each of the
submission we require the participant
team to submit their solutions in preset
virtual machines either on a single
server for the first tag task of into
two servers located at UCSD and Indiana
respectively and we recorded a memory
usage runtime and communication of these
solutions so for the first task of the
first track in the homomorphic
encryption Stanford MIT team
demonstrated the most efficient solution
in terms of mine alia frequency and a
chi-square statistic for the Hamming
distance calculation there are three
teams participating all of them shows
accurate result comparing to the
plaintext operation and the IBM team
demonstrate the most efficient solution
for the approximate added distance
microsoft team demonstrate the most
accurate result and lead the competition
we also evaluate the smc solutions in a
similar way for the chi-square statistic
we evaluate them on a large data set and
solutions proposed by universe and Notre
Dame and the University of Maryland are
very close to each other but maryland
team does not utilize a third party and
for the hamming distance calculation
university of virginia maryland UCI all
proposed
pretty good solution and Virginia has a
balanced performance in terms of
communication and memory usage and time
and for the last track in the added
distance we evaluate are the solutions
over Henry cave variation sites and UCI
has a overall balanced solution so we're
very excited and it's a great pleasure
to award the winners with a big check
thanks for human activity for the
generous support and after the workshop
we think we are moving much closer to
practical usage in a few aspects for
example in analyzing encrypted DNA
humming an added distance approximation
can be done within 10 minutes over a
hundred K sequences and secure
collaboration over the internet for the
duel study can be done in a few minutes
for a few hundred snips and for the
Hamming and edit distance within 20
seconds on a 10 megabyte bandwidth we
can finish the calculation between
Indiana and San Diego so we're really
close to protecting some of the genomic
analysis tasks however there still a lot
of gaps needs to be closed full-fledged
she was still not efficiently than
encrypted DNA and due to the challenge
of performing divisions and comparison
and sorting and hme homomorphic
encryption requires multi gigabyte of
memory in your competition and we also
see SMG solutions transmitted multi
gigabyte of data across internet for
analyzing even just a hundred case lens
of sequence operations that usually can
be done within seconds takes minutes
even hours and accurate added distance
is still way off the table so motivated
by the previous two workshops we are
hosting a third workshop this year
actually we are changing our location
from San Diego to Chicago this year in
November to co-locate our event to one
of the biggest medical conference by
medical conference called a Mia and so
we try to engage more human
genetic researchers to join our
community and provide more use cases and
so far we have already engaged more than
50 teams sign up for the competition
over 13 countries and we're receiving a
lot of questions weekly-based and we are
very excited to obtain the solutions
august 31st and evaluate them and others
this year we are trying to combine the
scenes from the previous two years we
set ups three tracks the first track is
similar to the competition in the first
year we try to solicit for solutions to
protect genome query service to protect
its outcome so we're trying to use
beacon as example beacon is a genome
query service that answers whether a
database contains a certain variation in
its database recently a Stanford faculty
doctor postman he has demonstrated just
using this query we can identify
individuals in the presence of the
database so we try to develop solutions
to mitigate that risk and the second and
the search track is inherited from the
last year but we're trying to expand it
for the second track we are going to
solicit solutions to search similar
cancer patient across organizations so
this time we require a much elevated
edit distance calculation because the
previous approximation might not work in
our stead scenario and the last task is
to test the genetic diseases in
encrypted data and we're trying to
expand this to the full fledge genome of
5 million and lastly I want to thank all
my co-organizers doctors often one hi
should hung strong one and looks Lana
Machado for their support and the
previous two years we have been lining
up with BMC medical informatics and
decision making to publish a special
channel and this year we are luckily to
have a medical genomics lined up to
publish this special issue thank you for
listening
resting talk and so our last speaker way
to be Kim Lane is actually a postdoc
here in the cryptography group and
Microsoft Research so Kim joined us from
Berkeley in the math department but in
the last year he's been becoming our
expert on the fully homomorphic
encryption and in particular building of
the library that was I think recently
released and but so he'll tell you a lot
more about that
just this one okay works
can you hear me alright great so thank
you melissa so the title of my my part
of this talk is private predictions with
homomorphic encryption so in the
previous talks we heard about some of
the problems associated with well for
example genomic data but there are often
similar problems with other types of
medical data also and and I want to
propose here or demonstrate some
possible solutions to some possible like
concrete solutions to solving such such
problems using in this case homomorphic
encryption like our group is at the
moment very strongly focusing on
computation and encrypted data
techniques different ways of doing sort
of applying functions to somehow private
data in such a way that no no were like
extra information is leaked here and one
of the techniques that we've been using
is home orphic encryption so so here I'm
going to show some results some results
about that so the sort of first part of
this talk is explaining what what we
mean by privacy in prediction it's maybe
already sort of obvious from this these
previous talks but but one of the ways
of how we like to think about this is
that since this Microsoft likes to
provide services to other companies
we're thinking of like a prediction
service that we could set up which would
do may may be a medical prediction
genomic prediction some may be financial
prediction and we wouldn't sell her we
would somehow need to convince people
with somehow need to convince other
organizations other companies medical
centers hospitals to actually send us
data to be processed if we if we
developed some models for example for
like medical or genomic or financial
financial applications I mean
we need to somehow be able to convince
our customers potential customers that
they can indeed like trust us with their
data and you just learned that this is
possibly a very difficult task
especially in the case of the genomic
information because in that case you
have you have also these issues related
to for example the family relations and
stuff like that which might not appear
in the medical or financial applications
so right so so if you talk to machine
learning people there of course super
excited about like providing such
services and training these models and
everything and then you rarely talk
about the privacy aspects I mean by
doing neural networks linear mixed
models trees you can do amazing amazing
machine learning models and you can use
these to provide all kinds of predictive
services but but then the privacy is
huge concerning in many of these so so
here's a very simple kind of service
that we're imagining where you would
encrypt your genome and you would send
it to a cloud service maybe the cloud
services microsoft maybe it maybe it's
some other company and you hope that
this cloud service would compute some
risk for example that you get some kind
of disease or maybe it does some kind of
genomic prediction or this could be some
kind of other medical prediction it
doesn't have to be genomic but then
there is this obvious question like who
else is going to see your DNA sequence
during this prediction and maybe who
else is going to see the result you know
maybe in an extreme case like there
could be a malicious admin @ at the
company who just like steals this
records that you sent to them and if
things go like really horribly wrong you
try to apply for your maybe health
insurance and now your genome or your
medical information has been leaked and
they say
okay well no health insurance for you or
well it doesn't look like you're someone
good who could do this job so based on
your genomic information so sorry no
need to come to an interview or
something else I mean this it's still
like I think that at this point we still
don't even understand how much
information we can get from the genome
it's like so new still so it seems like
there is this huge duality between data
utility and privacy so yeah maybe you
have a tons of data done stuff like
really detailed data maybe maybe you're
the owner of some Hospital and you have
all these patient records and everything
and you would want to maybe you would
want to train some machine learning
models or something you would want to
perform some kinds of computations on
this maybe you're an individual you have
your genome sequence and you would want
to get some predictions than on this so
you have data but you know you have to
like pay a price in privacy to get the
utility out of that and like was
mentioned in the previous talk or
previous talks one of the ways of
solving this problem at least partly
it's using encryption now unfortunately
it's not totally trivial at all because
typically sorry typically when you take
some data and you encrypt it and you try
to do some kind of computation on it
well outcomes nonsense because you can't
just take some IES encrypted data and do
anything with it it's it's completely
garbled so so in this sense like
whenever you send your data to a cloud
service they would have to have the
ability to first decrypt it and then
they can do whatever computation they do
maybe they train a machine learning
model maybe they do a genomic prediction
or medical prediction but there are some
very special types of encryption schemes
that can do this so
this is sort of a schematic explanation
of what we want to do so we want to use
a very special encryption technique
namely homomorphic encryption we want to
encrypt our or you rather want to
encrypt your genome with this with this
Homer Figg encryption send it to a cloud
service where it stays encrypted at all
times it's it's at no point decrypt that
the cloud does not have any key
information they can still apply a
function to it a computation and they
get an encrypted result and they want to
send it back to you so so this is in
fact sort of possible so i'm going to
show talk about this and and explain
some of the problems here and some of
the possibilities here but the technique
that allows such thing is called
homomorphic encryption so it's a very
recent idea by well originally by Craig
Gentry from 2009 to construct such an
encryption scheme that allows you to do
these computations now how does that
actually work well the idea is that if
you own the private data in the upper
left corner you can either compute the
function on it and you get f of X but
again in these scenarios that I
explained you might not know the
function like say say this is some
genomic prediction like you don't you
don't have the genomic prediction model
you haven't spent you know five million
dollars developing this model so so
instead you encrypt your data and now by
the power of this homomorphic encryption
the cloud service you send it to the
cloud service and they can compute the
function on the encrypted data and when
you decrypt it you actually get the f of
X out from this
so at no point the service provider sees
any any information unfortunately the
restriction or the restrictions here are
rather strong namely we can only compute
polynomials okay well not too bad we can
only compute low degree polynomials
let's say rather efficiently but once
you want to come once you like how to
compute higher degree polynomials it
gets increasingly difficult so well of
course we want to like try this and we
want to study this in practice and we
want to run some examples and stuff like
this so we had to develop or we decided
to develop our own homomorphic
encryption library called seal simple
encrypted arithmetic library so it's
actually freely available so if you want
to try it you can download it from seal
crypto codeplex com it's written in C++
and there's dotnet wrappers available if
you like c-sharp we're sort of actively
actively working on developing this and
so it's like focusing on I would say
good engineering style good programming
style and good API design and it has no
external dependencies so it's very easy
to start to use so here's some example
but I'm actually going to skip that
because because there isn't that much
time instead I want to demonstrate some
things that we can do because that's a
much more interesting than hearing about
the restrictions so uh huh interesting
okay yeah so the first example that we
decided to implement using the C library
is this genomic prediction using a
linear mixed model so these are models
that are used all the time for genomic
risk prediction in this case we're not
predicting any risk we're predicting the
flowering time of a flower from its
genome and in this case we use two
hundred thousand locations in the genome
something like up to a million locations
up to 10 million locations in the human
genome is totally reasonable and and
sort of the practical scale so this
200,000 is totally practical scale so
what's going on here is that the flowers
genome is encrypted using homomorphic
encryption it's stored in a service in a
cloud service this is what we would
imagine doing here if we had such like
genomic prediction service the gene the
genome of the customers they would be
stored in the cloud service encrypted
using homomorphic encryption and now the
customer requests a query so let's
request request a query how long does it
take for this flower to or this plant to
produce a flower well that didn't take
too long we sent the request to the
server the server did 1.5 seconds of
computation on these two hundred
thousand locations in the genome and
sent the result back to us and we
decrypted it then we got 29.1 days
expect that time so you know if you use
1 million locations 10 min allocations
it's just you just scale the time
basically by that however much you want
going up from 200,000 locations and this
gives like perfectly good accuracy there
is no accuracy loss per se happening
when you use homomorphic encryption
if you don't like genome or I don't know
if that makes sense but if instead you
want to see some medical risk prediction
we have another example where we wanted
to predict how dangerous pneumonia is
for a patient who has been admitted to a
hospital or who comes to a hospital and
and is diagnosed with pneumonia we want
to like know how dangerous is that to
the patient and this kind of prediction
can be done pretty accurately based on
some simple medical attributes so here
we have I think for a different medical
variables that the hospital can measure
and we simply apply a degree for
polynomial model again because we're
using homomorphic encryption we have to
use polynomial models because that's all
we can evaluate unencrypted data but
turns out that with this model we get
actually really good accuracy or area
under the curve which is the correct
measure of accuracy here so we get like
really good really good performance with
such a model and again it took like
eight seconds to do this computation one
second to decrypt and again by the power
of homoerotic encryption we actually did
a little trick here we batch together
four thousand medical records into one
so there's actually four thousand
patient cases here done simultaneously
so I can just like skip on to the next
one the slider here tells how whether
the patient should go home to chicken
soup chicken soup or whether they should
be really admitted to the hospital so so
such predictions these genomic
predictions these medical predictions
are totally reasonable totally possible
to do with homomorphic encryption and
it's just a few seconds at the question
like of course if you do it on plain
text data it's like some milliseconds
but like the question is the question is
not so much about about that time
difference the question is are you
willing to wait this like eight seconds
or two seconds
get your medic you know medical risk
prediction or your genomic prediction or
is that you know is that the next
acceptable time to you so I believe I'm
pretty much done it grace come back we
can take some questions from the
audience sir I have some questions as
well I think there's a question over
there is somebody have if you wanted to
you could discriminate against people
based on genomic information for years
how much Melman you produce your X
chromosome count and there's a lot of
trades in which clearly the only
solution is legal hiding the fact and
you know if someone who wanted to be a
bad after your DNA is very easy to get I
can't shake your hand so what am I
doesn't um just really quick the
question was sort of are there problems
here that we should be thinking about
from a legal perspective rather than
from a technological perspective so
maybe you're not missing anything uh
possibly not but like possibly you are
like it so suppose there are these
genomic testing services for example and
and they operate for 15 years now how
many medical how many patient records do
they have there i like how many patient
records go through them if this kind of
database is leaked that might be kind of
primal of course what you say is
completely true it really is to get if
you decide okay you are my Victim I'm
going to get your DNA yeah that's very
easy it's so I would say it's a matter
of
scalability right of the attack so I
mean it's much cheaper and you know more
damaging to hack into a database than
target single individuals right you you
actually need physical access to to them
or at least let's say you know they're
my glass over there or you know my hair
that I might I might have shed while
listening to the talks right but I mean
if I can add one thing i think as i
agree i think in the sense that we do
need also legal and you know policy
regulations which for sure we know tend
to lag behind and very often but i think
we need both I think we need you know
the kind of technical protection of data
but also the bigger ones and what we
don't want is having privacy fears
towards progress in genomics right so if
we can help with that maybe it's it's
good thing for everybody right I gotta
make coming jacking my voice but uh he's
the mic anyway sure oh it is recording
okay great so I got two questions one
starting with something that Emiliano
said in his talk the nature of not even
protecting the data but also protecting
the tests there are being run on the
data I forget the exact wording you had
but I think that was a general context
wait sorry I the word that I used yeah I
think secret sauce or test specific sir
okay we're in the vernacular either way
so is that an actual need in the
industry I mean because my understanding
and I am a computer scientist not a
medical person that a lot of these tests
how to go through some sort of FDA
vetting or some sort of public vetting
and that they have to be out there
anyway is I mean other than you know
probably very experimental testing is
that is that a real perceived need in
the community right so I mean
I would answer with one case that
actually happened is when Myriad
Genetics try to patent a specific test
one for BRCA mutation which is
associated to breast and ovarian cancer
so that's you know the test is very
simple in in that you you look at I
think you know a few dozens possible
mutation in a specific gene right so
they try to patent that and you know the
Supreme Court told them you can't patent
this because you know you're essentially
pattern trying to pattern a human genome
while you try to patent the gene right
so I mean in that setting it I mean
there are only other possibility for
them is to you know keep the locations
that they go and test confidential I
mean they have to disclose it to the FDA
if they're planning to use it you know
in for on real patients of course but
you know they might not want to disclose
it openly and say okay now I can you
know if I have access to my own data I
just do the test myself by the open
source and or you know everybody can do
it right so I mean it might be a natural
requirement in in this setting when you
know you have companies of
pharmaceutical companies they have to
protect their intellectual property
let's say I mean Adam my life you agree
yeah she's real neat because for example
like a pharmaceutical company want to
access some data center and the
information they are going to check is
actually relate to what they are to go
into the researcher it's very sensitive
so they may not want the data center to
know what they are actually looking at
I had a short question for Kim and a
longer question for shock king carl
gunther from the University of Illinois
Kim on on your thing I wonder how much
it has it been studied to find out
whether there are any side channels that
are problems for these homomorphic
encryption for example you might imagine
an algorithm that terminates very
quickly if it finds a high risk you know
maybe there's some dominant traits and
it looks for those and if it finds them
it stops and so like you'd see different
runtimes for different kinds of results
okay so so the algorithm running on the
server on the cloud service in the cloud
service that has to have the same run
time no matter what because it has to
touch basically all of the data and it
has to do the same computation no matter
what the encrypted message is so in that
there there cannot be anything like that
it's it's because if it if somehow the
runtime depended on the underlying
message then yes it would be leaking it
would be possible leaking a huge amount
of data who knows but that's not the
case it in fact it in fact does the same
computation no matter what same
operations no matter what so in other
words you think there's a low risk
either side channel like that but our
other actually mathematical proofs I
mean like there are the other things
yeah there's like a mathematical proof i
would i would say i mean you have to do
the same operation at every time it's
like a property of the encryption scheme
that that the ciphertext don't leak
anything about about the message yeah
but but i mean there could be other
types of attacks and i think it is
definitely true or at least I feel like
it's true that homework encryption has
been studied a lot from this kind of
very cryptographic point of view and it
has been studied less
in the context of such complicated
scenarios where you have these protocols
yeah it's like given your success that
might be a next step is to look at some
of that if it hasn't been done yet I had
in one more question for jogging okay so
I was looking at your contest yeah and I
was involved in thinking about the
beacon problem okay so maybe for the
audience you could repeat what the
beacon problem is but the thought I had
was for some of these things non
technical solutions might be much easier
than technical solutions so for example
with the with the beacon problem NIH has
a system for people to kind of register
themselves as institutions and so if you
could simply authenticate to some degree
the parties they're using the beacons
then that might may be much better than
any kind of technical solution you could
deploy and so what is wondering is is
there any way for your contest to take
into account maybe there's some
no-brainer non technical solution and
then your guys are like you know trying
to show you can take it down from 15
hours to 14 hours and you know so is
there a way to like incorporate non
technical issues in that yeah actually
this is a very good question so let me
recap on what the beacon is speaking is
so is provided for from g4 judge Global
Alliance for global health so they have
alliance of like a over 100 genomic data
base all over the world what the Soviets
can provide is you ask at which
chromosome which position if you have a
variation and then each database answer
yes no yes no not found and that's all
but it was given you have so many snips
or so many variations you can keep on
asking this question and you build a
binomial test and essentially you can
identify whether the target of interest
is waiting for example or chosen beacon
and then that leaks sensitive
information so we actually consider like
there's simple solutions if you will use
e I Commons or open ID to authenticate
people then we know like we can trace
their pattern actually we can compare
this with normal patterns
but we talked to the beacon like
organizers and they were thinking they
still want to keep the public service
available to the public so we need a way
I think we should have a tier way to to
protect this service so for example if
you want a low frequency and the number
of query you need to read n Phi
individual information it's much less
than it just answer yes no not fun so in
that sense they are actually enforcing
people to authenticate with AI commands
they just don't enforce that on the
yes/no answers but we have some
technical solutions I think that we can
trace how much has been reviewed on
individual people and whether we want to
keep that person in the database or not
this year we actually has some
innovation award for solutions that are
not forcing to the traditional
technology realm and we encourage those
to be submitted and we will consider
giving a word to those solutions as well
maybe there's some very easy no bring a
solution that solves the problem yes we
have other questions from the audience
license for the source code of seal how
that code can be reused for other for
specialized purpose like by medical
creations second question is what do you
think I mean I am understanding the
series for general purpose for home for
morphic encryption how do you think that
the performance is in terms of the
memory usage or speed can be optimized
to a certain specific function
evaluation or what do you do plan to do
any kind of application exam fine okay
so first of all about the license so
it's published published under this MSR
license agreement so it's freely
available you can use it for academic
purposes
I think really i mean the license is
there on the website and i don't exactly
know what it says but it's pretty short
and I think it's just like for academic
purposes it's freely usable can you
breathe oh can you like change it and
then publish it again well probably not
why not but if you would want to do
something like that and there's like a
good reason for you to want to do
something like that you should contact
us and we can set up some other way and
for the other question so this library
actually hasn't been in development for
very long and we mostly until very
recently we focused on like making it
really really easy to use and focused on
like perfect in the API and things like
this only now we are starting to like
focus more on the on the performance
aspect so all these results in fact are
done with that i showed you are done
with an older version of the library in
fact we haven't really run them with the
newer version which was just released
some weeks ago so there's huge a sort of
general performance improvement
happening and it's going to be happening
for probably several a few more months
at least the the results that you saw
the performance results are the result
of tweaking the encryption parameters to
be particularly suitable for the tasks
that we were doing so so sort of the
results that we got our good or pretty
good because we know kind of well what
we're doing if someone who doesn't
really know how to do much home orphic
encryption would start doing it they
would do it maybe in the sort of most
obvious way maybe it wouldn't be quite
that fast it would take maybe some work
to to improve it to like find you in the
parameter
years but it wouldn't be probably that
far off but in any case typically in
homomorphic encryption you always want
to tune the parameters and sort of tune
the system for your specific computation
so that's how homework encryption works
these days you can do more like in
theory you can do more general something
called fully homomorphic encryption
where you where you actually can do it
like an unlimited number of operation
you can do anything but that's only in
theory in practice we always kind of
fine tune it a little bit and if you
want to get these really good results
then you have to find you and it may be
a little bit more and that might require
some some expertise but the basically
getting sort of acceptable results for
many many simple tasks many simple
computations should be very easy with
the current API of the library
at the IBM team in terms of the
performance my question is do you have a
new comparison based the existing home
or fake encryption library I could help
develop it that I be empty okay so
currently we have not performed such
comparisons it's so different
homomorphic encryption libraries sort of
focus on a little bit different things
and and we are heavily focused on or
heavily focusing on encrypting integers
at a time like maybe some other library
libraries are better suited for
encrypting bitwise things and and they
have functionality that is really useful
for such things we are focusing really
heavily unencrypted encrypting integer
by integer so the different libraries
have different pros and cons and I'm
sure at the moment IBM's library is
probably a way faster they're using
they're using you know some number
theory libraries for arithmetic that has
been divided in development for like you
know a decade I don't know I mean at
this point we haven't done any
comparisons yet but once we find a good
benchmark then maybe it's actually not
that easy to come up with even a good
benchmark so Kim actually I've got a
couple more questions about your library
and exciting stuff um that exciting work
that you're doing so you know you're
exactly right all these diverse
libraries have they're all kind of
various benefits and trade-offs and
primer ization challenges and they're
just kind of a mess to use and it takes
like a team of PhDs to figure out which
is great you know you're a team of one
good for you maybe there's all the
people and find this curtains also so so
what scheme did you implement and then
you said you're optimizing for integers
and i'm also very curious about your
application data so the the flour
example i mean what did you actually
encrypt i mean that there's a lot of
data is out there is it a VCF files as
something else particularly for doing
encoding some that data as integers and
running computations and i even saw the
pneumonia exam
that you're outputting a floating point
number which is not an integer also so
there's gotta be some some tricks that
you're probably learning about how to
encode data and then they encoded data
what you're actually running on the
computation and what actually are you
running for the computation to get those
those kinds of outputs that you are ok
so first of all the encryption scheme
that we use is the fun workout torrent
scheme which is scale invariant
homomorphic encryption crip shun scheme
with security based on the hardness of
our lwe so as far as we're we know RW is
a very hard computational problem to
solve using these parameters that we
have that we're using and at the moment
we we have reason to think that it's
secure so that's what that's what we're
using the fun vercauteren scheme there
are other schemes like the BG v scheme
used by IBM's library for example and
the performance of these is probably
pretty much the same it they're very
very similar they just do things in a
slightly different order a little bit
different for the other question about
what exactly was the data like well in
the ok now i have to say that i wasn't
the genomics person who was working on
the flower thing so I am NOT I can't
remember what the data looked like but
presumably it was just integers 0 1 2
for this for this look at the snips
dislocations in mutations and then we
had some rational number coefficients in
this model now what we did here was we
in fact scale the rational numbers to be
integers now we also have some methods
of directly encrypting rational numbers
in seal this technique has some
downsides and actually we're currently
actively working on some solutions to
those downside so so there is a way of
there are several ways proposed in in
actually pretty recent
papers of encrypting rational numbers
directly seal uses one trick of doing
that it's currently maybe not as good as
it could be but we're actively actively
working on a solution that we have but
for the moment we've seen that typically
it's better in many of these like
especially when you want like really
high high performance results you almost
always want to probably scale to
integers but it will see where this goes
because we have some interesting ideas
about this are there other questions
from the audience so I have one question
for all of you I guess maybe a sort of a
high-level question what do you think is
the most sort of promising area for some
of these privacy techniques to be
deployed like what what application
scenarios do you think will be the first
place that that will be be deploying any
of these different techniques I can
started I think like a clinical genetic
testing is one of the most interesting
scenario so for example kids with rare
disease can deposit the genome in the
cloud and then when the new biomarkers
gets revealed and they can be tested in
encrypted manner and then we can
constantly feed back to the parents if
the new findings relate to their kids so
there could be a good scenario now if i
might add another one is I think you
know we need to follow closely this kind
of direct-to-consumer genomics area you
know now that 23andme or many others
have sequenced millions of people in
just a few countries where they operate
and also for instance 23 Emmy allows you
to actually get the raw data that they
did they produce and so now you can even
share it with researchers using you know
the Apple elf kit so I think you know
this data is going to to be out there so
there is opportunities for us as
researchers to look look for ways to
protect it but also you know for
research
too and also doctors I to top on this
data and you know mix it with your your
medical information environmental
factors to it was kind of you know have
realize this dream of personalized
medicine so probably it's not something
immediate but my personal prediction
would be that you know five years from
now this is going to be a reality yeah
if not less so anything privacy will be
a component of that well I I hope so yes
yeah I i really think that if we could
get you know inference and machine
learning like the learning component of
machine learning to work very
efficiently on encrypted data or or at
least on like shared sort of private
data across several hospitals if we
could get that to work we if we could
train things like trees or random
forests or if we could train neural
networks that would be incredible like
we could do so much there could be so
many because you could have so much data
coming from like hospitals all around
the world that would be really really
incredible thanks so that's there any
other questions which I think maybe we
can thank all three of our panelists
thank you all for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>