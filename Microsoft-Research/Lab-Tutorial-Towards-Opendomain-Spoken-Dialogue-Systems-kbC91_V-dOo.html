<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lab Tutorial: Towards Open-domain Spoken Dialogue Systems | Coder Coacher - Coaching Coders</title><meta content="Lab Tutorial: Towards Open-domain Spoken Dialogue Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lab Tutorial: Towards Open-domain Spoken Dialogue Systems</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kbC91_V-dOo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so I'm going to talk about spoken
dialogue systems as Torres said I've
been working on this for some time now
and before I just sort of bring it into
focus let me just say what I think I was
being a spoken dialogue system I come
very much from the speech area and
worrying about the fact speech
recognition doesn't work so great
especially in difficult environments so
I haven't really focused very much on
the kind of very rich knowledge domains
and and the the issues of fine grained
semantics and so on so the topics I work
on are still pretty simple limited the
main topics if you look at a spoken
dialogue system and just think of in
block diagram terms now you have
something that looks like on the slide
here so we going end to end the user
speaks use often the request there's
some there's some application most of
them are working for the last few years
has been on finding tourist information
primarily restaurants information but
also hotels and other things initially
in Cambridge more recently in San
Francisco so a user might say I'd like a
cheap Italian on the east side of town
and there's some kind of semantic
decoding and belief tracking takes place
which first of all tries to extract the
meaning from what is said in some
abstract form and then maps that meaning
on to some continuing state-based
representation of what the user wants
because the assumption here is that for
many applications a single voice command
is not going to be sufficient to gain
gather all the information maybe because
it's actually quite a complex query or
maybe it's simply because the speech
recognition is so bad it's almost
certain that you're going to have to go
back and confirm and ask people to
repeat things till it's it's confident
that it's understood you properly
oh so it also might Experian Polly yes
yes that goes from speech that uses
speaking and ASR goes to words yeah and
and this is just some arbitrary simple
abstract representation now if you're in
a dialogue situation and what this is
again a bit cartoon-like but it's meant
to illustrate the source of
representations were thinking of so if
it's in a restaurant the main you think
there's something like a sorry if it's
in a tourist domain there's some kind of
type of venue you're looking for it in
this case a restaurant but could be a
hotel or a bar and if it is a restaurant
you might want to know the food type and
there's lots of them there's so each of
these vertical bars is meant to
represent the probability that the user
wants that specific food so in this
particular example again remember it's
just a cartoon it's not meant to be real
but Italian and Indian I've got quite
high probability there's a don't care
option which is lower probability and so
on so for every possible dialogue state
variable there's a probability
distribution and the goal of course is
to get Delta functions on all of these
or as close to Delta functions as we can
get so that we're pretty certain about
what the user wants
so for each after each term we look at
what the system does is it looks at
these distributions and decides whether
to ask what to do access the database or
ask a question so in this particular
case the dialogue manager using a policy
which is tells it how to what what the
decision logic should be the dialogue
manager issues some kind of action which
again this is a very simple abstract
notation in this case confirm request
food what that means is will confirm the
stuff that we've probably pretty certain
about and request to Fuchs I don't
really know what that was and this some
kind of response planner takes
quite abstract form adds some and extra
information to it like confirm that the
price is cheap and the area is east
still they're not sure what the food is
so the output is okay so you'd like a
cheap restaurant on the east side of
town what kind of food would you like so
that's just setting out the scenario
that's what our spoken dialogue system
does for me and what I've been working
on for the last 10 years is is trying to
get to the point where every piece of
that end-to-end sense system was was had
no rules in it it was a statistical
model of some description it was
entirely trained from data and when we
started working on this 10 or so but
more than that now it was 15 years ago
but the goal here was as I said it was
can we build an end-to-end pipeline
trained entirely from data no rules and
and crucially exploiting the full speech
recognition output so remember I came
originally from worrying mostly about
dealing with the fact that speech
recognition was pretty awful 15 years
ago it was a lot more awful than it is
today
so but what we could always do is
generate quite a rich distribution from
the outputs of the recognizer and if you
were to search around in the things that
the recognizer postulated you probably
find what actually the person said it
just wasn't the most likely thing
probability terms so the argument then
was history this leads to reduce
maintenance costs not so much
handcrafting of rules and deploying
systems and twiddling around with them
to get them to work
improved robustness to noise and use a
confusion and the ability to adapt to
improve online and so we explored
various ideas and we run tests and so on
are we more or less demonstrated with a
sequence of papers over the years that
we can indeed improve robustness and we
can actually more or less do all of
these things and what I wanted to do for
the next probably 20 minutes or
a bit longer it's just a cancer through
some of the the techniques we've looked
at it's in order to do this to give you
an idea of the sorts of algorithms that
we use and then to to say a little bit
about the the bit about towards open
domain because all of my examples assume
that we know what the domain is and
there's a simple very simple ontology or
database that effectively defines what
all of those state variables might be
and so on and and makes the whole thing
tractable so speech understanding an
area I know lots of people in Microsoft
have been working on this is the bit
that does the mapping and there's
essentially three different ways to do
this
broadly speaking the traditional ways
you write rules so again I'm using very
simple examples so if we probably from
the first slide I like a cheap Italian
on the east side of town
you can relatively easy write some rules
what a system that was commonly used 20
years ago if so is something called
Phoenix I think it was actually written
by Carnegie Mellon it's a sort of
rule-based parser but it's it's got
features that allow you to be robust to
speech recognition errors it's a fair
it's the sort of context driven word
spots are actually and it can generate
things with the right rules generate so
these frame like things which translates
the sequence of words into a set of
attribute value pairs more recently
people have looked at what is now called
semantic tagging the computational
linguistics community is done a lot of
work on this sort of thing the idea here
is you just treat the input as a
sequence of words that you want to tag
with useful semantic tags
now of course groups of words correspond
to single semantic elements so what did
what people typically do is use
something like what's nowadays called
the bi o notation which is rather
trivial it means that you you tag words
like
and the big B just means begin and I
means inside and o means something else
over so I'd like you might tag us in
being for my inform a II don't care
about cheap Italian let's begin price
Italian this begins food east is begin
area side is inside the area always
inside the area of town it's inside the
area maybe I mean the tagging the
tagging depends on your own conventions
but the idea is if you can train some
kind of model which given the sequence
of words X can give you a probability
distribution over the secret sequence of
tags Y but if you've got those tags it's
relatively trivial to pass the tags and
extract the information you want people
like this cuz it's a sorry how do they
know that Italian meant food rather than
I don't know well from data so if you so
you train so what you have is you have a
large corpus of of data along which is
tagged and you basically learn this
probability distribution so if you've
got examples in the corpus you'll learn
it if you haven't you might not sorry so
just the neighboring well so people set
this up well the initial work on this
using hidden Markov models was
essentially just using the words like as
a raw symbol sequence and see
conditional random fields which has sort
of taken over somewhat probably it's
about the best the at the moment that
the most accurate method we have of
doing this so a conditional random field
because it can it can it can take as an
input a set of a wider span of features
typically you put engrams in as the tag
so it's looking at the current word plus
the previous the next maybe the count
how many words are we from the begin
build your own feature set there's
hundreds of the papers playing around
with lots of these things more recently
people have started to look at
alternatives to this sequential labeling
of course because this doesn't allow you
to incorporate anything like hierarchy
or in the in the linguistic sense so an
alternative is to say okay well maybe
what we should be doing is turning the
problem round and we should be searching
for things like tuples so if I could
have just design a classifier whose only
job was to look at this sequence of
words and tell me where the price equals
cheeps in there or not you could design
an SVM to do that you could stick all
the words in all of the engrams anything
you like and if you if the classifier is
cheap so I forgive the pun you could
have hundreds or thousands of them and
you just throw this sequence of words at
them all in parallel and those that pop
up with us and say I think this area R
equals East food because the Italian in
there will light up and you can you can
take the output and these various forms
of this and I'm just showing one we
worked on here not surprisingly with the
interest in deep learning this kind of
the kind of frameworks now given way to
neural networks which are being tried to
do the same thing one of the other
issues is how you actually deal with
multiple ASR output and and the desire
to generate not just one hypothesis but
a ranked list of hypotheses so there's
again multiple architectures for this
when we first started looking at this we
used from the recognition the automatic
speech recognition we generates them by
strings and then you could just treat
each string as an individual hypothesis
pause it with a DSL you we
your algorithm was getting then a list
of n best I'm calling them dialogue acts
here this is just attack what we call
our abstract representation merge
duplicates and there you are
an alternative is and one of the
problems with this kind of architecture
is this if you take the end based list
from a speech recognizer there's
actually I have to go pretty deep into
the list before you pick up all of the
interesting information because lots of
the top hypotheses are just small
variants of each other and actually mean
the same thing
so there's a comprar various compact
forms of this one of which is what
speech people call a confusion network
and it's basically they also call them
sausages for obvious reasons you
basically have a set of Arc's and and
the between the dots the dots mean
sequence in time but not necessarily I
synchronously so you have a set of words
and the arcs represent our alternative
words in each word as a posterior
probability so you can find lots and
lots of routes through the confusion
network and you've got a posterior on
each word and from that you can
construct many different hypotheses and
from that you can construct features
which go into a single I sell you and
give you an inverse list and again I'm
not one thing I know this was sort of
meant to be tutorial but I actually want
to skim over the top and give you an
idea of what works and what doesn't work
and this is a test done on the data set
which is collected in the motorcar it's
people asking for restaurants
information there are 10,000 training
utterances and 4,800 test set l
Torrance's and what's shown here are the
results just from those particular
examples I gave you so our sort of best
phoenix parser gives these scores now
the F score is is just the
you're probably familiar with EFT scores
it's the it's a sort of geometric mean
of precision and recall it's the it's
the ability of the system to retrieve
the the attribute value pairs from them
from the from the input from the one the
most likely hypothesis and so you can
figure with the sort of percentage
accuracy in the way the ice score is
unusual and it's symmetric you won't be
familiar with but what we found is that
the on the end-to-end dialogue system
what matters most is the quality of the
distribution over possible hypotheses
not the one best accuracy if we always
got if the second best was always
correct our dialogue system can do
pretty well but we would have a system
which you know with a very low won best
act so a one best very high one best
accuracy might still not work very well
and the isometric ice stands for what
does it stand for item cross-entropy so
an item is an attribute value pair and
this is a measure which we've we've
found is a very good correlates very
well with overall dialogue performance
and it's a sort of instant you can think
of it as a sort of an entropy base
metric distance between the true and the
lying distribution and the distribution
that the decode is produced so small is
good and the thing about this sequence
is mostly that this def scores going up
in the ice scores going down so they're
in sort of rank order and the numbers
don't matter so much I just wanted you
to see what was what matters and what
doesn't matter the the top two is
Phoenix and this CRF
semantic tagger using the single best
hypothesis from the recognizer and
engrams here is just shorthand the
semantic tuple classifier so this
happens to be done with using SVM's
but you wouldn't get very different
numbers using any of your favorite
classifier so it's putting all the
engrams from the best output from the
air
into a classifier and the performance is
basically the same
it wasn't improve very much all the ice
score is a bit better
we then explore what happens when you
extend the list as an best list adding
in the second-best improves it a bit I
think in the ten best doesn't make much
difference at all and that's consistent
with what we we know because it's not
much extra information in there but when
we moved to a confusion Network and we
wait the engrams according to the
posteriors of the words in the in the
confusion Network we get a reasonably a
reasonably decent input in f-score and
again another drop in in this
cross-entropy metric and when we add it
feeding some contextual information it
improves again so as we'll see in a
minute this this sort of bag-of-words
thing is rather convenient because it it
opens the door to all your favorite
classifier you treat all of these inputs
as you can choose whatever features you
like it's kind of quite flexible and it
works pretty well so if I move on to
belief tracking I'll come back to that
point in a minute so belief tracking is
a similar problem what's different for
belief tracking is you've got state
information so remember we're not trying
to just extract the information from a
single hypothesis now we're trying to
extract information from a sequence of
things that the user saying to us and
this is this is kind of non-trivial
because if the racket if you if the user
says I like in Italian and you recognize
Italian correctly but then you decide to
confirm it and you say so you want an
Italian then the user or you recognize
no or you think they use is negating
what you just said there's a question of
how do you forget all together that the
since an Italian or do you think we'll
okay I'm not sure now so let's ask
another question so the belief tracking
is non-trivial it gets even more
non-trivial when people change their
mind which they do of course because you
know you say well there isn't Italian
Brits four miles away so they say okay
is there something nearer forgetting is
actually rather a hard problem what you
forget and what do you remember so again
there are a number of different
approaches that have been used for this
we have we've looked at three different
where we start real bases always a kind
of benchmark systems not very
interesting we've looked at two basic
schemes generative scheme based on
dynamic Bayesian networks and a
discriminative model based on recurrent
neural networks just to give you a
flavor of the sorts of things we've
we've been doing first of all on Bayes
net using a Bayesian network the idea
here is to decompose what you're trying
to the knowledge you're trying to apply
in two different bits of information
so for each hidden variable in this case
type in other words the type of the
venue then there is a hidden variable
which represents the goal and the goal
is in the case of a venue it's but does
the user want a bar a restaurant or a
hotel then there's a user act so that
means the last user act so it says did
the user ez is the last input from the
user
referring to this goal or not because
you might want a restaurant but you
might think it's so obvious you don't
actually explicitly say so and then
there's a question of what your what you
observe of course is the recognition
output so you have to take account of
recognition errors and you also want to
take account of history as the user
mentioned this before and so based on
the simple ontology you can construct a
dynamic base
Network other attribute pairs may depend
on this so if the user wants food
they're more likely to want food if they
if the goal type is a restaurants rather
than the bar some bar surf foo but less
less common so you might condition the
food type on the gold type same sort of
structure you can build this
automatically from a simple ontology and
then of course because it's a time
series you have to link all of these to
the next time slice and I'm not showing
it here but all nodes are conditioned by
the previous action or the previous
question and you can use expectation
propagation such that given your
observations you can infer back what the
goals were recurring your networks are
rather different now the problem with
the the bayesian network is it's
actually very difficult to get a
Bayesian network to forget at least to
forget quickly so if the user changes
their mind it tends to retain it's
rather persistence about thinking you
know the user wants something in once
Italian and they've changed their mind
now they want to Chinese and also it's
rather prone to suffering from
correlations in the data which you
haven't modeled explicitly in the
network so it can overestimate
probabilities for example because it
doesn't have the necessary conditional
links in there so more recently like
everyone else we've been looking at
neural networks and particularly a
recurrent neural networks and again you
can set these things up in the rather
simple way so recurrent neural network
we we just encode the belief state as a
set of outputs with some kind of softmax
and so we can serve them as
probabilities we add some memory just a
row of hidden variables and we
have a usual kind of loopback scheme and
then for input we can simply encode the
the last user action the SL u and we can
encode this in different ways but and
I've put ASR or SL u there for a reason
we started off just encoding the
abstract semantic decoder output and
that works okay and then we thought well
why do we need a semantic decoder at all
why don't we just feed the words into
this and so we tried that and here's a
we ran in as it happened we were
involved in an international challenge
to build it so called the dialogue state
tracking challenge which was started by
Jason Williams over at Redmond in
Microsoft he did the first one and then
we followed that with a second one with
a rather richer database but again this
restaurant data and various groups tried
using it and these are this there are
our results but they're they're
consistent with everyone else's so for
this tracking problem they again two
measures the accuracy is how accurate is
the in percentage terms is the goal the
set of goals at each turn so you would
to get high numbers here it's quite a
challenge so even for the restaurant
domain that there are about four or five
different goals and so if even if you've
got five percent probability getting
each one run because you've got to get
all four right two to be scored as
correct it's it's obviously you know 70
or 80 percents pretty good and then the
l2 is just the l2 norm between the
distribution compared to the to the
ground truth so again for dialogue
systems it's important to have a small
l2 because you want the belief the
belief
distribution to be as accurate as
possible so the top four lines here give
you the performance for the base line
it's very simple rule based system the
Bayesian network which does a bit better
than the rule based system but actually
not all much and one of the problems
with its data set is it does have
examples of people changing their mind
and the Bayes net it really really
struggles with that and then we have
something called the de lexicalized
recurrent neural network and that's a
network that's been trained on all of
the training data but the slots the
actual values have been replaced by some
kind of single label so instead of
saying food equals Italian it's just got
food equals food value so it doesn't it
doesn't have to see every instance of
every possible value that the user might
ask for and then the full RNN is where
we add to the D lexical RNA essentially
another network in parallel which is
learning specific values and you can see
that first of all the R and n is really
really pretty competitive in fact it's
better we return the best results of any
of the systems that we tried and from
other groups as well with ones one
exception for which it's a bit of an
outlier interestingly if you throw away
the D cut semantics decode there
altogether and put words directly into
the belief tracker it does even better
so we're losing interest rapidly in
semantic decoding clearly there's
there's enough information in the word
network and the network and is much
better at deciding what to keep and what
to throw away than your abs your
abstract representation is people
actually are working on this for speech
recognition believe it or not they're
now sticking waveforms directly into
recurrent neural networks and trying to
see what they can get from it
Chris and I have been around long enough
to remember the 80s when people were
trying the same things without success
it's all a bit mysterious why all of a
sudden we we can do cut out the
middleman entirely yeah so I see from
the clock I'm taking too long as usual
dialogue management is the partially
observable Markov decision process this
is a this is a different source of
problem it's no longer a mapping problem
or a classification problem this is a
planning problem with delayed rewards
because if we're having a dialogue with
the user what we're trying to do
ultimately is is satisfy the users
request or information need or whatever
so we swim we score dialogues based on a
reward function and our reward function
is very simple at the moment we give a
significantly positive reward if we give
the user the information they want we
subtract one from the reward for every
turn so that we're encouraging the
system to learn how to do things quickly
and we give a negative reward if the
system gives the user by the information
and so what the goal of the dialogue
management is to take this belief state
distribution to construe to have some
sort of function and this is actually a
probability distribution but
conventionally in the literature the
probability of a of some action a given
the belief state B is written with PI
and the goal is to find up a PI which
such that the expected value of reward
you get from running a dialog is
maximized and this is a sort of classic
reinforcement learning problem for which
there of course is a very large
literature and and you can choose your
favorite algorithm to so many extents
we have focused on two specific sorts of
algorithm over the last few years we've
looked quite extensively at a direct
implementation of this district this
distribution they're maximizing it by
gradient descent because they the issue
there is how you how you actually
parameterize this distribution and we've
used things like radial basis functions
and similar formulations and we've also
more recently been working looking at
using a Gaussian process approximation
and that's the one I'll just briefly
touch on now because that's turned out
to be have some really quite helpful
properties so GP s-- our sir is now
standard reinforcement learning
technique not not invented by us and the
idea here is instead of modeling the
policy directly what you try to do is
model the so called q function and
reinforcement only a q function is is a
function which gives you an estimate of
the expected reward given that you're in
some state b and you take some action a
following some policy PI so you imagine
a dialogue context you're some way in
the middle of the dialogue the Q
function will tell you for given the
current belief state for all of the
possible actions I can take it tells you
what the what your expected reward is so
the obvious policy to follow is the
policy which is going to maximize the
reward so the Q function is gives you
effectively a policy to execute and if
you have some data in the form of a
sequence of belief action pairs and then
the resulting reward when you come this
is essentially a regression problem and
you can use GP regression to solve it
it's slightly tricky because you can't
actually observe the intermediate
rewards you can only really observe the
final reward and there's a neat way of
dealing with that so given some trait at
reduced so called jackdrury ie a
sequence of poor
then it's it's relatively
straightforward it's like textbook these
days to write down what the posterior of
the cue function is and you can then
sample the mean and and use this to
decide to determine the policy and if
you put this in a kind of learning loop
you get something which is equivalent to
the original Sasser algorithm for
reinforcement learning again not going
into the details but the basic idea is
you have a cue from your current
estimate of the cue function as
determined by the GP process you take an
action you update the belief state to
the next the next belief state you
observe the reward and then you update
the cue function you go round and round
the loop and you can show this actually
converges on on the optimal policy in
order to do that though you have to
occasionally take the wrong action in
order that you can explore space and one
of the neat things about GP is when
you're deciding when to explore and when
to follow the the best possible policy
by just sampling the thing that
maximizes Q then you've also got know
what the the covariance is and therefore
you can you can you can adjust your your
exploration depending on how certain or
otherwise you are the Q function in this
bit of space so it all works really
quite neatly but the thing that's really
useful about GP from our point of view
is whereas previously using nak we
required something like a hundred
thousand dialogues with GP you can learn
useful policies after two or three
thousand dialogues so it's it's it's
much more data efficient so much of our
work has been done with simulators
because we started with algorithms which
required way too many dialogues but
we're using Jeep unlikely with GP you
can do online learning and then you can
start training policies with real users
which is where it gets much more
interesting and here's just some
headline number
on particular tests we did this is paper
is here but and this is just to give you
a feel for for how it works so if we
train a system on the simulator using
nak and the user seem that this all
works at the abstract dialog level so
this isn't a simulator that that that
generates some speech and then waits for
the system's response and recognizes it
and so on it's actually done at that
abstract end after the semantic decoding
so it's dialogue acts in dialogue acts
out if we train an ACK policy using a
simulator and the simulator we've worked
on for years so it's a real floor in the
whole thing you can say I can say well
we can deploy systems that require no
rules and no training and it's magic but
we did spend five years developing a
simulator it kind of takes the edge off
it a bit but but it's a pretty good
simulator by now it's pretty realistic
but obviously not realistic enough it
doesn't represent all users so this is a
test we did over the telephone so all
the testing is real we're not testing on
the simulator we're just training on the
simulator and we're testing with real
people in the sense that they are warm
blooded humans but they're recruited via
Amazon Mechanical Turk so their
motivations are are questionable and
what we do is we we give we we get
people on the webpage we say imagine
you're in Cambridge and you're looking
for somewhere to eat or you're looking
to sleep overnight in a hotel and then
they call this number and get the
information you need it's that kind of
setup for testing so training on the
simulator knack and GP SAS are actually
a pretty similar which is might be what
you expect there's a large number of
training cycles but the interesting
thing really is that with GPA we can do
this online so we can whilst the whilst
of the Amazon Mechanical Turk Turkish
are using the Syst
we can actually collect the data and
update policy and let the system learn
and there we see a significant
improvement performance in fact the
success rate on that particular trial
was 97 percent and that's where the
speech recognizer which is still making
more than 20% word error rate and the
tasks not entirely trivial so I mean
that's starting to get a level of
performance which is really quite
encouraging but the crucial bit is to be
able to learn from real users rather
than learning from simulated users I
think I'm going to skip generation
because it's something we haven't worked
on very much I have just to give you a
flavor for how these systems work this
is a video made more than 18 months ago
I guess but it gives you a flavor of the
kind of system this is a system it's
fully trained from data there are no
rules at all in this system if I can
make it work
so y'all make hurry get a phone call
it's a bit noisy hello welcome to the
Cambridge restaurant system you can ask
for restaurants by area price range or
food type how may I help you today I did
some Italian food cheap you are looking
for a restaurant is that right yes an
Italian restaurant what part of town do
you have in mind I don't really care
Pizza Hut city center is a nice
restaurant in the center of town serving
Italian food not recommend us cheap
pizza hot city center is a great
restaurant serving Italian food and it
is in the cheap price range the phone
number of Pizza Hut city centre is 0 1 2
2 3 3 2 3 7 3 7 thank you goodbye
so you can see an example of finding a
okay so the rightness obviously the
first thing people do is I say well
synthesizer sounds terrible it's true
it's enough to shelf statistical hmm
bass synthesizer the reason for using it
is primarily because I can genuinely say
every component in the loop was trained
by us using our data and obviously you
could connect it to a much better
synthesizer assembly the recognizers our
recognizer although using other people's
recognizes is more problematic because
it does rely on having a rather
well-designed
work confusion network output you can
see that say it was a fairly noisy
conditions and it's it's not to say this
is a wonderful system simply to give you
a flavor of the kind of system that this
that we've been working with now just
for the last oh gosh the last few
minutes I need to justify the title for
my talk so from limited to open domain
so this is something that we're now
working on and about to start a new
research project funded by the EPSRC on
this how do we go from a system like
this to a system that can talk about
anything no I'm obviously when I say
anything at least initially what I mean
is any any topic that you could
plausibly imagine designing a system a
similar capability to handle so it's not
that we're trying to solve deep AI or
handle sort of very rich
question-answering things but if it was
if you think about what you can do on
the web you can look for restaurants you
can look for movies you can buy shoes
you can do all of these sorts of things
they're all grounded into actually some
pretty basic semantics but the problem
is this has many many topics and if you
had the user who just wanted to flip
from one topic to another
how would you do that given that there
are thousands of topics and although one
could collect data and train a system
like this on each individual topic it
would it would be tedious and that I'm
sure the user would quickly find
something you haven't got any data for
so the so the the particular sort of
aspect we're looking at here is we're
saying okay we have an end-to-end system
what are the key issue what would it be
the real problems in scaling this to a
very large set of topics and the the
obvious problem would be scaling so that
instead of just a few your belief
distribution in serving over a few
specific variables is potentially over
thousands of variables and then you'd
need a huge amount of data to Train it
well an obvious way to to deal with the
complexity issue is to still think of
this as a very large number of
individual dialogue systems you can
imagine the person speaking and instead
of speaking to one you're speaking to a
thousand or a million in parallel and
you just the one that actually has any
clue what you're talking about it's
probably the topic that you're talking
about and it and it produces the
response so you can think of this as
also as kind of multi-domain so a
potential solution is to employ a sort
of distributed representation it says
it's one policy and one semantic decoder
or whatever have a whole have just
distribute them and and I tend to think
of the ontology as being the the
framework on which I want to distribute
all of my my dialogues so I imagine of
an ontology covering the whole space of
interest something like Google's
knowledge graph or whatever you guys
call your graph and attached to each
node in the graph tis a little dialogue
engine that knows how to talk about the
nodes in that graph now if you wanted to
do that you would have to think well how
do I get this and let's suppose that the
idea is to collect data online
and learn as I by interacting with the
user collecting data improving the
models if you were to say if you to set
things up like that how would you
bootstrap it how would you how would you
deal with the bits of the graph that for
which there's no data so what we're
looking at at the moment is the extent
to which you can use generic models and
a sort of an inheritance idea in order
to be able to execute a conversation
sufficiently well that it's good enough
to get the user speaking and then of
course as more and more users use that
you collect the data and you improve so
let me just finish with an example this
is the first experiment we've done so is
again it's that because we've got the
data and the models already suppose
we're talking we have we imagine we've
got hotels and restaurants and we
imagine we've got no data at all or very
little data so let's say well I don't
have enough data to train a hotel or
restaurant but you know that the venue's
after all they've got a location develop
locations names quite a lot in common
suppose I was to have enough just very
enough data to train a model for venues
could I use that to talk about hotels
and restaurants and if I could do that
well enough once the users have started
to use the system well first of all of
course I could just collect more data to
get my venue generic venue model working
well enough and then when I think I've
got enough data I can obviously just
devolve this downwards split the data
set into two for one for hotels and one
for restaurants and then essentially
using the venue as a prior I can update
the models for the restaurants and the
hotels and now I've got more specific
dialog relating to those two now
obviously I have to do this for the
understanding bit
the belief tracking the the dialogue
management the generation and we've been
playing around with those I just want to
talk about the dialogue management today
so how do we design a generic dialogue
policy where some of the information is
different for the venue from hotels the
restaurants because it could be many
other kinds of venues well we we've
actually been running some trials in San
Francisco as part of another project so
we had a bunch of data for hotels and
restaurants in San Francisco and when we
look at the slot or the attributes that
that are in the data that are actually
just for common attributes name area
near and price cardinality that just
tells you you see so it's a very small
very small piece of San Francisco it's
there are only 239 names in this
particular data set covering 155 areas
and there's some landmarks so you can
say it's near Union Station or whatever
and price is grouped into cheap moderate
expensive hotels of for price ranges
current exactly what they are and for
hotels is a few binary features like
dogs are allowed and has internet and
accept credit cards and for food is
obviously the type of food served
apparently 59 different cuisines in San
Francisco and whether it's good for meal
this is is it good for lunch or evening
meal and our kids are our children alone
okay so how do we model that well an
obvious way to do it is is to say well
let's just take the slots of the common
and let's take the slots that aren't
common and just give them abstract names
which might appear a little funny but
you have to remember that most of what
the dialogue system is doing is trying
to establish the belief on a particular
slot is trying to construct the
delta function rather than a uniform
across all possible values it's not
actually that bothered what the actual
slot means it's mostly interested in
asking the right question to get more
information to make that and and when
you look at the decisions it's making
it's actually often quite crude it's
it's basically along the lines of do I
and know anything about this slot or do
I know quite a lot about it and that
obviously is just a shape of the
distribution so in many cases it doesn't
matter whether its food or it's the
price of petrol or whatever it's the
shape of the distribution it's actually
most interested in and and that's so
what we do is we so for GP you need to
define the kernel function and so the
kernel is just a just tells you for any
to belief points effectively how similar
are they we use a very simple inner
product for our kernel function and then
what we do is we construct the kernel
for the whole belief state by just
summing up inner products over the over
the beliefs for each individual slot and
since these slots have different sizes
we very crude we replace we be just pad
out the lower cardinality slots with
zeros so we just add zeros to for
example has internet so it's got the
same color cardinality as the other
slots so it's a very simple experiment
and what we find is is I think the
results are really quite interesting so
first of all what's this table showing
you we'll just focus for them the minute
on the in domain and the generic that's
the first and the third line so the the
first line is is what happens when you
train two completely separate dialogue
managers one for restaurants and one for
hotels and you train them with just 250
dialogues and you compare the
with the generic venue model trained
with exactly the same data set so it
says 500 here that's just because it's
got 250 hotels and 250 from dialogues
and you see that the performance is
considerably better in both cases so
when something's badly on the train it's
better to pull the data even though it's
a rather more approximate model than it
is to try to use sparse data and do what
you can with the individual domains so
even curiously and we don't really quite
understand this when you double the
amount of data in each subdomain you
it's still not quite as good as the
generic model so that's we're
effectively with as much data in each
subdomain as this has got in total we
think that's again because when it's
sparse you're actually better having
these somewhat more abstract slots and
focusing on the common slots when you
increase the data you get a similar
effect so when you go to 2,500 and
compare it with the pooled data it's
still actually slightly worse but now
when you have 5000 in domain it's
actually about the same now you might
expect why isn't this better and I think
this is because this is all done with a
simulator and and the simulators not a
great model for how users behave when we
actually try to run this system live
this is what happens a chair forgotten
to put the edge of the success rates on
here but the this is the moving average
reward as it's learning starting and
it's it's actually averaged over I think
a hundred dialogues in the horizontal
axis so it's somewhat smooth so the
lower curve is that is training a single
domain from scratch and the upper curve
is starting with the generic venue and
and training that using it sorry
starting with the generic venue as a
prior and then training the individual
domains and you can see that starting
from the prior and then refining to -
this is the cat I think this one
actually is training the restaurants so
this is a venue the generic venue prior
being used as a prior for training the
restaurant domain and what you find is
the reward is never terrible it starts
off okayish and and it actually improves
quite quickly see even after 150
dialogues it's it's reasonably good ten
is a reasonable reward for this task the
this is training the restaurants from
scratch and here the problem is for the
first 150 or so conversations the
systems close to unusable the rewards
negative which means it's failing in a
large number of cases so what when we
measure the performance here the system
trained from the prior is getting
significantly higher success rates so
this is a very early experiment what it
shows I think is that the basic idea is
is is is plausible that you can deploy a
system and by using generic policies you
can provide something which is usable so
you don't make your customers suffer
terrible performance whilst the system's
learning and you can imagine a system
which starts off with just a few very
high-level policies are very few
high-level dialogue models and then the
more people use it the more those dialog
models get refined and become more
specialized and the performance improves
so I'm sorry I've spoken too long this
is my so my conclusions are giving you a
flavour what I mean by a fully
statistical spoken dialogue system it's
it's plausible to construct one and we
can show it works we can show it
actually more robust in difficult
conditions than anything we can do is
real based systems scaling from limited
domains to large multi domain systems is
constrained by
place it in the lack of data and this
simple possible way forward is to have
this kind of hierarchy of policies
distributed across the domains in which
you start with generic policies and then
use those as priors in order to
bootstrap much more and more specialized
policies I've shown you how we can do
that with the dialog management policy
we've also tried doing it for a free
recurrent neural network and it's still
early days but it looks like you can do
similar things with those as well
whoops oh that's the end sorry it wasn't
meant to be the end it's got one more
slide a very important one I of course
don't do this personally there's a large
number of people that contributed with
all right thank you very much for this
very interesting tutorial walking us
through this impressive body of work in
this area questions dear Chris your
objective measurement was success in
booking a restaurant and you penalize
the system I think for the more terms it
took to get to that objective and I
think I read somewhere that 95 percent
of human conversation is not about
exchanging information it's more of a
social phenomenon if you wanted to build
a dialogue system that had to have an
interesting discussion obviously that's
a much more challenging task than when
you've tackled many thoughts about how
you might yes
actually I haven't told you the one the
one floor in this and you're probably
thinking well I don't really believe any
of the complicated stuff but the real
the real floor in its Dale is we
actually can't tell when the system was
successful or not which is sort of goes
to your point a bit it's actually very
difficult to automatically get to the
end of it all when we were real you so
we knew it when the can
paid subjects of course because we've
told them what the task is we can
measure whether they fulfill the task or
not for real users it's very hard to
know exactly what they want and whether
you've you've whether you've satisfied
their need or not so what we've been
doing recently is looking much more
distributed reward functions where we
start to score and using techniques like
reward shaping rather than changing the
reward function so looking for features
of the desirable and not desirable so
presumably Corrections are undesirable
apparently making progress because
you're moving from topic to topic is
desirable and giving those individual
scores so I guess to get that sort of
chat system you would you would have
something like that how well it would
work I really don't know because we
haven't really focused on it we're sort
of very pragmatic with you know we want
to take the applications effectively
providing the sort of the grounded
semantics of what we're actually trying
to achieve and working back to say how
do we get the dial to drive this
application and they're mostly
goal-directed things and the question
and if it's a superficial thing but
you've the dialogue you demonstrated in
other ones as I third slow and heavy
just the speed what needs to be done to
make it more fun to interact with well
certainly one of the one of the flaws is
that humans don't adopt this turn-based
were you quiet whilst the system speaks
and then you dutifully respond with an
answer and then wait for the response I
mean real humans don't interact like
that and and we have sort of done some
stuff on much more what's called sort of
micro term type stuff where you you're
continually listening to this the user
if it's clear that they're off track you
sir up them similarly if the system's
off-track they interrupt the system and
that's much harder to do I mean there's
other engineering problems with that but
to get a system that works the way you
would like it to work that's what you
have to do you have to be continuously
listening so this idea of turning the
recognizer on and off is a no-no has to
be completely listening all the time
your dialogue policies need to be
evaluating it every - every every word
but suddenly every chunk what should I
do here shall I interrupt shall I just
keep listening or you know so the policy
needs to be it's a much more
fine-grained level and it's a very
interesting area and I think that is
very interesting I mean in the future
one when one sort of things about more
subtle sort of evaluation evaluating
such subtle effects how would one of
these simulators well I don't want to
simulate so I'm very eager to get rid of
it altogether so I haven't really
thought about that
I mean the simulator is what we do we
want to be learning online from real
users interacting with real systems
there's no question in my mind about
that
we have to find ways to do it question
that you need to have some bootstrap
process right otherwise the users might
not even come I mean if you only need a
few thousand dialogues to get started
you paid people to do it still better
than the simulator and with especially
you know the opportunities a company
like Microsoft has for just putting
online things that are games and so on
you just get people to use them much
better than the simulate okay I think
maybe we can continue discussions over
nibbles and wine but before that let's
thank Steve for a very nice</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>