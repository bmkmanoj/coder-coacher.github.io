<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Case for Continuous Time | Coder Coacher - Coaching Coders</title><meta content="The Case for Continuous Time - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Case for Continuous Time</b></h2><h5 class="post__date">2016-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Gj9NlYwTNIo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so I'm now very pleased to welcome
Christian Shelton he's Miz's hit proof
of that UC Riverside he got a PhD from
MIT and did a postdoc at Stanford before
that he was one of the pioneers in
continuous time Marvin Christian Shelton
thank you so my research is in machine
learning and I'm particularly dynamic
systems so I've been interested in all
forms of dynamic systems and for about
the past 10 years or so I've been
interested in models of continuous time
systems sort of systems that are
asynchronous so let me give an example
of some asynchronous stochastic systems
so phylogenetic trees so you have
genetics and they you know different
species change at different rates over
times social networks I'll give an
example of some social network examples
what I'm going to be spending the next
year on my sabbatical ICU patients this
is a large stochastic system that you'd
like to to reason about in control
software verification for a long time
has dealt with models of stochastic
systems and some others what's
interesting about all these systems is
that they evolve in naturally in
continuous time there are discrete
events that occur in these systems and
that the rate of these events can change
drastically from component to component
in the system in over time so there's
not maybe a constant rate of change in
these systems so what I this talk is
organized sort of in three components
the first component is I'm going to try
to explain why continuous time is an
important modeling tool so my computers
themselves are naturally discrete-time
entities right there's a clock that runs
on your computer but just like we use
real values when we derive our
algorithms by the fact they're gonna be
implemented in a computer and
essentially on integer arithmetic
treating time as a continuous quantity
is important so that's why I'm going to
talk about first then I'll talk about
some of the work that we've done in in
models of such continuous time systems
and then I'm going to show some examples
so here are some theoretical and then
I'm also some experimental reasons why a
continuous time has end
so consider the typical discrete-time
system is a Markov chain so you have a
system involves over time this is sort
of a very simple Markov chain here we
have a row stochastic matrix describing
that chain that is the probability of
staying in the first state from one time
so it's the next is 75% otherwise you
move to the other state and if you're in
state two then you you switch to 50% of
the time okay so that's fine if so it
depends on why you've described the
system but if you're your actual system
was in continuous time and evolved and
you just happen to be sampling at this
particular rate and you end up with a
matrix like this we can ask the question
of okay so what would the stochastic
matrix look like if we were interested
in in sort of it at twice the sampling
rate or half the the window size so if
that means that we need basically a
castex square root matrix so in a matrix
like this and in this case that gives us
that matrix there okay so that's fine
this describes the same system at twice
the sampling rate so good so now what if
my system looks like this okay so the
system that flips back and forth we can
ask the same question again and we end
up with this matrix okay and I guess if
you're in quantum mechanics it doesn't
bother you but of floresta so we don't
like having imaginary components to our
probabilities okay
so there is no Markov system at half the
rate that is equivalent to this system
at this rate and it's not a feature that
I happen to have zeros in there if I
make them point one that's the same
thing happens okay it's just the numbers
are more messy okay so there are a
couple ways of viewing this one is that
the space of discrete time Markov
systems is larger than the space of
continuous time Markov systems there are
systems that at a discreet time are
Markovian but there is no continuous
time that is Markovian okay so so if
you're viewing your Markov assumption
there as a say regularization or a
convenience okay then maybe this doesn't
bother you but if you believe the reason
I chose this state is that the
underlying system is truly Markovian in
this state you may if using
discrete-time go off an estimate a
system that actually doesn't correspond
to any Markovian continuous
system underneath me about this is that
in real life like social level
mm-hmm I mean if this is just occurred
to often you just simply we do the your
somebody time what are struggling
smaller and then you avoid all this
power yeah mmm sure well well yeah Suman
that you you you so do you have to know
ahead of time how small you need it to
be and then your computational time
grows so I'm going to talk about the
computations having other factors yeah
that's right okay so the other problems
I want to represent I don't show up into
sort of this flat Markovian system to
show up in a in a structured one so you
know if you have n states you need an N
by n matrix to describe it to discrete
time Markov system but I usually
describe things in terms of things to
describe in terms of assignments to
variables so if you have like say n
binary variables that means you need to
there are two to the n different
assignments those binary variables I
need to the N by 2 DN matrix okay and so
the answer is that I need some compact
representation for that because that's
not tractable for any reasonable and you
know decision diagrams have been used in
the computer science literature dynamic
Bayesian networks or more common machine
learning and AI but there's some
problems here I'm going to focus on DP
ends because I think that's more
familiar to this audience so here's the
simplest dbn I can have so I have two
processes process a you know it's a
Markov process that doesn't depend
anything else that goes its merry way
and process B um depends on a because
Villas in pattern a then I have a really
truly simple system so now let's ask the
following problem a question so what
happens if I unroll that for another
time step and again I asked a similar
question which is um what if I instead
wanted ebn that describe the system
across two time steps instead of across
one I don't like my sampling rate I'd
like some other sampling rate so I have
this one here and I marginalize out the
two variables in between and I get this
at least if I want to describe it in
terms of the DB and I get this structure
you notice the structure has changed I
have an extra edge here that didn't show
up here before okay what does that mean
it means in some sense that this
particular structure was not just a
function of the underlying processes
function online process and a particular
sampling rate yep okay so put
differently if I have this underlying
structure at at half the sampling rate
and now I ask the question what
structure could I have marginalized to
get here the answer is there are none
which isn't to say there isn't a DB n
there's a DB n but its structure doesn't
come out like this when you marginalize
it this independence assumption here is
hidden inside the inside of the
probability distributions here it's not
it's not representable as in the
graphical model framework okay so the
basic thing here isn't to say that
necessarily something's wrong but it is
to say that your structure is therefore
sensitive to your time slice width so if
your time slice with truly is something
that's you know inherent in your process
then fine that's great you have a
process that naturally has a rate to it
but if you have a process that does not
naturally have some global rate to it
then your your structure you've
estimated is not some inherent property
so those are two theoretical reasons
maybe not to like a discrete time model
or to be someone concerned about it
empirically these are also true if you
talk to practitioners they kind of know
this excuse me so here's the simplest
example I have a process of four
variables okay
the first variable is a Markov process
it recedes as it wants at a rate of
approximately 1 the next process tries
to follow the one above it the third
process tries to follow the second one
in throat it's the fourth one tries to
follow the third one that is if they
disagree with their parent they switch
relatively quickly and otherwise they
tend not to switch okay now I'm going to
sample a bunch of trajectories from
those and then I'm gonna try to learn
back the network structure and I'll use
a dbn so here I'm increasing the number
of samples I have and here I'm um
increasing this the sample width I'm
decreasing the rate of sampling okay and
you get obviously a slightly different
structure back every time but these are
pretty indicative structures of the ones
you get back so if I have a lot of
samples in a very long width compared to
the actual sort of natural rate of the
process I basically learned back a
stationary distribution for this process
right this one's very good here if I
have a very fine width and I and I have
a lot of data then I basically learned
back the correct structure and in
between I learned back all sorts of
crazy things but more importantly is
this plot so let's take each of those
ones learned let's run this experiment a
few hundred times and compare the model
I get back how well it predicts future
data and some sense of proxy for the KL
divergence to the to the true
distribution so up on top is if I use
the correct model okay and this is if I
use a very finely fine a time model and
this is a rule let's see this is sort of
the one that's at the natural rate and
this is a very coarse screen of time
model and the thing interesting here is
the correct time slice to select depends
on how much data you have yes that's a
problem if you're going to go about if
you're gonna pick something yes that's
that's a that's inconvenient and
annoying right so so in this data regime
you do better here so what I'm going to
show you is it is a method that produces
this okay now some of this a little
cheating the mall and produces exactly
the one from which this data came okay
so it's not surprising and do well but
right very tight error bounds and and
and beats them all okay alright so
what's the alternative just to give some
background I think people are more
familiar with discrete time models and
continuous time models what's the
background so here's a here's this
stochastic matrix here there are a
couple ways of interpreting the
stochastic matrix let's take a
particular row here right they all sum
to one one view is that after a total if
I'm in state one what this row means is
that after one time step there's a
eighty percent chance I'll be in the
same state and a 10 percent chance will
be in state I guess I've labeled from 0
so obsessed chance will be in state one
and 10 percent chance will be in state
two okay the other way of viewing this
is that in terms of dwell times so in
that I stay in state 0 for a
geometrically distributed number of time
steps ok and then afterwards I switch to
one of these two states up proportional
to the to the element in that matrix
that's that it's equivalent view of the
same thing so the alternative in
continuous time system is to describe a
rate matrix and intensity matrix or
sometimes a Q matrix depending on what
you like this is a matrix in which
all run rows sum to zero the diagonal
elements are non positive and the off
diagonal ones are non-negative we have a
similar interpretation there's one row
per state this row here describes what
happens if I'm currently in state zero
and the two views are somewhat similar
so this row here means that after a
infinitesimally small period of time
that is as epsilon goes to 0 ok those
are the limit is that the probability I
stay in the same state over that period
of time is 1 minus this quantity here
times Epsilon and the probability I move
here is this times Epsilon the problem
up here is this times Epsilon hey that's
the incontestable generator
alternatively I can view this in terms
of dwell times okay so this states that
I stay in state 0 as an exponential the
continuous version of a geometric with
rate 0.24 and that once I leave of
course I can't come back to the same
state otherwise that means I didn't
leave I leave I go to this state
proportional to this amount in this
state portion of this amount so again
there's an even chance am I going to the
two yeah
yeah so it's this is only valid as
epsilon goes to 0
yes the limit sorry I didn't make that
more that's right yes yeah it yes that's
right it's the limit okay so now how do
you use this sort of thing a standard
question to ask of this matrix is to
marginalize out or push time forward so
I have a marginal distribution
represented as a row vector over time
zero and now to push forward I
essentially do a matrix multiplication
that gives me the marginal distribution
at time one okay if I want the marginal
dispute in time two I essentially will
do the same thing again which amounts to
multiplying by T squared etc okay so
down here the equivalent question is and
now I'm using this notation to note that
the argument is of possibly real valued
number so I have a row vector here that
represents the distribution at time zero
to push forward to time T I use the
matrix exponential so they give you that
sort of equivalent to this so use the
matrix exponential their matrix
exponential of course is this Taylor
expansion there which I'll touch on a
little bit later alternatively it's the
solution to this part this ordinary
homogeneous differential equation so
sort of the most straightforward
differential equation you get to answer
ask okay so the first question usually
is well that seems a lot harder right
differential equations can read a matrix
multiplication that doesn't seem to be
any better
so what well so I have a three state
system so essentially to solve this
difference equation I'm trying to
integrate this so this is just the
derivative of that right over time so I
have a distribution here at time zero
and I'm trying to get distribution let's
say at time eight but actually
computationally not not to write the
algorithm but to have the computer
actually run the algorithm this can be a
lot simpler why because I'm not going to
do this integration by just sort of some
standard neo Euler integration I'm going
to do it by some adaptive integration
method in which I take an estimate of
what the derivatives are here on what
the curvatures are and decide how far I
can jump out so in time periods when
these distributions are changing
drastically I will spend a lot of
computational time to
to make very careful if it goes on here
but industry times periods where things
are not changing very much
I will adapt my integration step size
and take large jumps and so
computationally I can get by with taking
probably many fewer jumps to get the
same accuracy over here than what if I
just treat it as a discrete system and
sampled at some particular rate ok I'll
touch on that later so so these are you
know like runga kind of runge-kutta
Feldberg methods right are these these
sort of adaptive integration methods
where you take a bunch of derivatives
near your point you see how far and how
fast you can go without increasing your
error by too much and then you take
adaptive step size okay so so what we
want to do is actually build models like
this that are for systems or describe in
terms of variables not in terms of a
flat state space like I was doing before
so just to sort of set a little bit what
we're talking about so I'm gonna talk
about a factored model I'm going to talk
about continuous time Bayesian networks
which is the factored model that we
developed there are some others from the
verification literature Petri Nets and
things like this they tend to be very
focused on steady state distribution
properties and not on learnability
estimation from data so I don't want to
give you the impression that this hasn't
worked on before but that's sort of the
work I'm kind of ignoring here sorry so
basically what I'm trying to is I'm
trying to describe a distribution over
trajectories a trajectory would look
like this if I have three variables it
would say the variables start at this
particular moment and then
asynchronously at various real valued
times they switch those switches from
light green to dark green here and then
shortly after when this switches from
orange to red and then here this one
switches from dark blue to light blue
etc so I'm trying to describe the
distribution over this a particular
sample trajectory can be described by a
finite but unbounded number of switches
and the x with two switches happen
there's a real value x in the the state
after the switch the evidence I might
care about might look something like
this this is the same trajectory I've
just removed parts I didn't know about
so at various instance I might know the
value of certain variables just for an
instant we call that point evidence for
other periods of time it might know that
it was green solidly from here to here
and dark blue
from there there that we call that
interval evidence over some freezers
that over some periods of interval
evidence that might actually observe
transitions so I know that a transition
happened here and here I know that no
transition happened there are other
kinds of evidence you might have you
might know that between here and here
and only transitioned once but you don't
know exactly when things like that you
can incorporate all those into this kind
of evidence model um it depends what you
mean so I mean dbn is an example of a
factor discrete time model yes yes so
right so you certainly uh you certainly
are mat modeling trajectories whether or
not you view that you've captured
everything so if I know it's light green
here and then at this point I know it's
dark green do I know it only
transitioned once in between or two or
three times in between so a discrete
time model does not tell you what
happens between those time points hope
is that you won't correct and so ends
right so the more precise you want
represented the more computational time
you're going to take to propagate across
a particular unit of time if I want to
use a delta T of you know 0.001 then to
propagate across one time step I have to
propagate a hundred times that's right
yes I'm gonna build a factored model a
factor model essentially means that the
state at any time is an assignment to
variables right and so I'm saying as an
example in continuous time what that
would look like is not not at this time
I have this and this time I have this in
this time of this but continuously over
time a trajectory will look like this so
I'm trying to okay there like so a ctvn
is essentially built on the graphical
model framework it's a graphical model
each node is a process okay not a random
variable but now whole process a Markov
well no us a kind of a Markov process
Edge's here represent instantaneous
influence so the simplest one I can give
is this so I have a process and a
process B process a proceeds without
caring about anybody else in the process
B depends on process a so what do I need
process a is therefore a Markov process
I have to describe in addition to its
starting distribution which I'm ignoring
for this talk I have to describe its
rate matrix so there's an example of
rate matrix not chosen arbitrarily and
for process B instant I have to rate
matrices so at any given instant its
rates of changing are governed by the
instantaneous at that points state that
a is in okay so if state a is in state
zero if this is the transition rates for
B and if aliens to state 1 these are the
transition rates for be so selfish is
always implied if you if the state of a
does not depend on its state in the
instant before then I don't know what
that means but instant literally instant
by instant right then I haven't
uncountably since all right so so I'm in
the discrete time equivalent of true
white noise right which has infinite
power and so yeah so I don't mean that
right yeah yes that's right yes yes
continue even of any variable that has
sort of some meaning as having a some
continuity to it even in a very you know
instantaneous mul interval that's right
okay goodness that's right this notice
or this zone is the whole process that's
right that's right
and so the whole thing together also
represents it can use time Markov
process over the joint space of those
two
in some sense yes the the rates of these
switch based on this one here that's
right hmm okay so right so this whole
thing here describes a joint Markov
process over the state space of a and B
and just to give you some idea that the
semantics look like that means that I
should be able to build a rate matrix
over the joint assignments so a 0 and B
0 is 1 B 0 etc and I can do that for a
fairly straightforward way first of all
no two variables allowed to change at
exactly the same instant this is pretty
common if you think of the two events
can't happen at exactly the same time
they can have an arbitrarily close to
other than exactly the same time so and
this particularly simple example that's
the anti diagonal but in general there
are more zeroes than that so any case
where this assignment in that assignment
to disagree by more than one variable
the rate is 0 mmm if they disagree on a
then I just look up so you know this is
the rate of transitioning from a zero
days one so that goes here because this
differ just days changes this differs
just days changes so trip and then for
instance when a is 0 and B changes I can
look up those from the green matrix and
when a is 1 and B changes or those from
the blue matrix and then that since I
fill in everything except for the
diagonal and the diagonal I filling just
to make sure that the rows sum to 0 ok
so that's in some sense my semantic
meaning behind this is one way of
viewing the semantic meaning now I don't
want to construct this matrix in general
because it's exponentially large in
terms of the number of variables but you
know you can least theoretically think
about having constructed
to be we detect this switching so so I'm
just one you're only processing a
brand-new process so you don't know okay
so we can talk what I haven't talked yet
about what you do with it I'm just
talking about a formal formal a formal
definition of a joint process then we
can talk about what sort of questions
you might want to ask or the process in
a bit so this is the general equation
essentially says the same thing if the
two of these are joint assignment if
that you joined a Simas different by
only one variable then you just read it
off from the relevant local rate matrix
for that the diagonals happen to be
these particular sums and everything
else is zero okay so I want to point
something out here if you have n binary
variables this joint matrix says 2 to
the n rows and columns okay
each row has order n nonzero elements so
my original description is more compact
than ace than your standard sparse
matrix representation a sparse matrix
representation it contains at least one
bit of information for every row right
ok and I have sort of this description
here has sort of a polynomial number of
very information per variable okay
it's exponential in the in degree of the
graph but it's polynomial in the number
of nodes in the graph just like a
standard by a Bayesian network so here's
a classic example from our first paper
it's purely synthetic generated but
cycles are ok right so whether or not
I'm eating affects whether or not my
stomach's full which affects whether or
not I'm hungry which affects well than
I'm eating that's ok
all right so edges here have a causal
interpretation when you can we can argue
over exactly what form of causality it
is it's certainly Granger causality
whether or not it's a stronger notion of
causality well we can argue about that
offline so d separation still holds like
in Bayesian networks so a variable is
independent of its non-descendants given
as parents ok
and the similar notion of a Markov
blanket exists so you're independent of
everything else given your parents your
children your children's parents thing
you have to remember is that your
children and your parents may be the
same people because you have cycles in
the graph ok but if that worried you
about notation in graph theory than
those other sorts of things issue
you a lot more okay but the notion of
given means the entire trajectory so
does this work so concentration is
independent of hungry given full stomach
okay but it's asked me I know the entire
trajectory from zero to whatever time
point I care about a full stomach
finally I'm sort of partial of it that's
not true okay and this is a little like
in a hidden Markov model well it's
harder to say in hidden Markov model
okay so it's hard to say anymore you
just have to observe the whole thing
that's what I can say otherwise you you
don't have a full observation of this
variable okay the other important part
here is that marginalization does not
produce a Markov process so uptake is a
Markov process right it isn't it doesn't
pay anything else if I marginalize it
out and try to incorporate into
concentration the result is not Ammar as
not a Markov process this is like a
hidden have a hidden in discrete time I
have hidden hidden hidden Markov model I
have the X States and the Y's that come
off of it if I try to marginalize out
the X's the distribution over the Y's
it's not a Markovian process that's
still purpose of having a hidden Markov
model right okay so the same thing is
true here if I marginalize out this
variable the description I'm left with
here is not a Markov process anymore
okay in fact if I marginalize everything
out and the description the size of
description grows exponentially okay so
this is a member of the exponential
family like all good distributions I
suppose the sufficient statistics are
for each variable for each value its
parents can take on for each pair of
values it can take on X I and X I prime
it's the number of times in the
trajectory it transitioned from xx I
while its parents had value P I Pai and
it's the amount of time that variable
spent in this particular state while its
parents were in that particular State
those two things are sufficient
statistics and then you get this linear
form in terms of sufficient statistics
and the and the parameters of the
distribution alright so was the sum over
every variable of every instantiation to
his parents every Stan shishun to that
variable and every other instantiation
to that variable X I doesn't X i prime
not equal exile oops wrong button okay
okay so other questions is a machine
learning person you might be interested
in or how can you learn such a process
how can estimate such parameters so
let's assume I give you the structure I
just want you to estimate the local rate
matrices the Q matrices for that's
trivial basically you have a bunch of
multinomial distribution amounts of
exponential distributions and you just
go read off the parameters from the from
the sufficient statistics here okay it's
it really is it depends it depends I'm
saying if you have a system in which you
have complete data that is I observed
all variables at all times then this is
trivial maybe I don't know I might know
those I might not I'll cover that
sectional so the structure here is also
particularly simple so unlike a Bayesian
network in which learning structure is a
somewhat difficult process okay it's not
true for a ctvn because cycles are okay
the whole thing that makes Bayesian
network learning difficult is that you
can't allow cycles so therefore you have
to search among the set of a cyclic
graphs which is not a nice set to search
under okay I don't have to search under
that set here so if I bound the in
degree of my graph then it is a
polynomial time algorithm for searching
for the best graph and I find the global
maximum because I can consider each
variables parent set independently and
just optimize it independently okay fact
you could do it for a Bayesian network
too if you love cycles so for incomplete
data that is there are at least some
time points at which I didn't observe
some variables right there might be
variables I never observes IB variables
I didn't observe for a particular period
of time I might have only sampled it at
some regular rate but I want I didn't
know what happened in between then to
learn parameters you need to you
expectation maximization works
essentially I just have to estimate the
expected sufficient statistics okay and
I'm back up there and I'll talk about
that a little bit of the next slide and
actually the structure is not too bad so
structurally M works
I mean structurally and works for
Bayesian
works - it's a little more of an art um
it's not so bad here mainly because this
structure search step is exact I get to
the global optimum so I don't have to
worry about as many think I might be
running off here and then maybe I didn't
find the global optimum and how do I
trade off you know iterations of the of
the structure search versus iterations
of my II step and things like that you
have to worry about that as much not to
say you couldn't worry about it but you
don't have to okay so how about for
inference so this is the task if I give
a partial trajectory and I want to infer
what in some sense what happened when I
wasn't looking or where I wasn't looking
okay so I think I mentioned before the
marginalization produces non Markovian
processes so you can't just do sort of
variable elimination style algorithm
because the the result of your your
representation size will grow without
bound as you do that okay so furthermore
if I'm trying to do filtering I can't
just push the distribution forward over
time because as I push over any interval
suddenly all the variables become tied
together just like what happens with
entanglement in the DPN so actually
these things happen in discrete time
models - like in DB ends
it's just that they aren't as a parent
it looks DV ends look like the other
Bayesian networks and Bayesian networks
are nice this way so they look a little
bit better but when you actually like
start working TV ends you find you have
all these same problems again so it's
not like I've introduced new problems
I've just made them sort of more obvious
from beginning ok so you probably have a
favorite approximate inference algorithm
hopefully it's on this list and somebody
has done it for a continuous time
Bayesian network and that's what I'm
gonna say so expectation propagation
importance sampling particle filtering
Gibbs sampling general Markov chain
Monte Carlo mean field belief
propagation recently and then this one's
a little bit special to continuous-time
so I don't have time to cover all of
those and you don't have patience to
listen to all those I assure you I don't
know if that makes inference any easier
the structure learning is simpler
because of that because I don't run the
graph but if I'm given a graph and the
parameters estimating what happened when
I wasn't looking it I don't know if the
cycles make things easier or worse I
know I don't think it changes it much
okay so I want to get into a little bit
behind this one in this one because I
think they show some interesting things
about continuous time processes and I'm
going to show them in a bit of a
high-level so one of them is mine and
one of them is not that makes me feel
sort of more you know egalitarian about
this okay so I'm filtered the first one
is is is mine and it's filtering so I've
now decided to turn the distribute the
time axis on its head so here I have
three variables so what is filtering
look like filtering is I want to
maintain a distribution over the state
of the system given everything I've seen
thus far so I start with some
distribution over where I think the
system started I'll represent it like
this and then at some real value time
later I observe the states blue and that
states red so what do I do I need to
propagate this distribution forward and
then I need to condition it on the
evidence this is a standard propagating
forward oh I do have animations
who put that in there okay so then then
later I'll observe something else
I'll propagate that forward and I'll
condition that and I'll continue on okay
so I might have some other evidence I'm
not I'm only going to talk about point
evidence this works for a non point
evidence but let me just make a let me
just say it works in we'll move on so
there are a couple things to note here
the conditioning is standard
distribution conditioning of some
distribution you just you know don't
allow it to be certain values and you
you renormalize this propagation is by
the matrix exponential right I represent
if I represent this as a joint vector I
just supposed to multiply it by the
matrix exponential and I'm good so this
is essentially the step I want to
concentrate on so I'm not going to
calculate the matrix X special directly
I'm going to said calculate it's pre
multiplication by a vector because
that's more numerically stable much like
it's better not to take a matron and
matrix inverse but instead solve a a
linear system for the particular thing
you're going to multiply your matrix
inverse by okay so the question is how
do you compute that and Moeller and van
loan have this great
paper it's called 19 dubious ways to
calculate the matrix exponential in fact
it's such a good paper the 25 years
later they wrote 19 dubious ways to
calculate exponential revisited 25 years
later okay if you're really interested
you should read it
it basically says there's no good way to
calculate the matrix exponential it's
just not one of those computations
that's amenable so the Taylor expansion
is the most obvious thing and it's
unstable why is it unstable the Q matrix
is negative definite already negative
diagonal elements has to be original
Thank You Def in it so I have a Taylor
expansion that alternates signs and we
know that you don't want to estimated
something with Taylor expansions
alternate signs okay so I'm going to
show you essentially I do use
uniformization to solve that there's
some other methods Krylov subspace
approximation and this integration which
which we've played around with but I'm
going to build this off of the Taylor
expansion uniformization so let me talk
about that just quickly I think this is
interesting so I'm going to take my
continuous-time system I'm going to
convert it into a discrete-time system
okay but there are a couple different
with discrete-time systems you might be
thinking of I could be imagine I could
choose to essentially discretize time at
some rate and calculate the equivalent
okay I'm not gonna do that
the other is I could talk about the
embedded Markov chain that is I don't
care when things happen I just care what
sequence of events happened I'm not
gonna do that one either okay but I
built a different one so I'm going to
let my Q matrix be equal to some scalar
that doesn't look like the right of
quick yes that's great some scalar times
a stochastic matrix M minus the identity
matrix or put differently I'm going to
build a stochastic matrix M by taking Q
dividing it by some scalar and adding
the identity matrix and provided my
scalar is greater than or equal to the
absolute value of the biggest element in
the matrix the resulting M matrix is a
stochastic matrix it amounts to the
system in which I sample x from an
exponential distribution with rate
parameter alpha and then at each time I
sample the next state of the system from
this stochastic matrix so I can have
self transitions on that stochastic
matrix cuz it might be that that wasn't
time to actually get a generation of a
next event okay I didn't come up with
that that's been that's old so now if I
have P to the EQ T that can be broken up
like this so in general this is the
somewhat Americas in general e to the a
plus B is not e to the a times e to the
B alas they know life to be simple but
if they have the same eigen vector or
structure than they are and I has any
eigenvectors you want so so these two
dudes commute like that okay so this is
a scalar this is this is a scalar I'll
just pre compute that right and then
this here I can do with the Taylor
expansion on M and now M is positive
definite and so this doesn't have
alternating signs and I'm okay okay so
far so good that's great so the
essential calculation then is I have the
first element is P the next LM is P
times n the next one is P times M times
M and then P times M times times M so
I'm essentially need to compute this I
remember I don't M is big mmm you know 2
to the N by 2 to the N so I don't want
to do that so and in fact even if Q has
compact structure and will have the same
compact structure but multiplying by it
will destroy any structure that might
have been in V so you might have had
some nice structure and V that
multiplied by M it will essentially
destroy that ok so there number of
things in the in the Markov chain
literature that deal with using some
sparse representation which is great for
tightly coupled systems I want to use a
factored representation one more similar
to like say the BK algorithm from the
for Bayesian networks and that's good
for a sort of more loosely coupled
systems so let me show you basically
what happens I have P I want to compute
P times e to the Qt here's an exact way
of doing that well I've have an infinite
computation time I take PE I multiply it
by M and multiply that by am a multiply
that by M and then I sum all those guys
up with you so the appropriate weights
from my Taylor expansion there we go
okay so I'm not going to do that since
I've been filtering for a while I don't
have an exact answer so I'm going to
start with some approximate answer here
okay I'm going to multiply that by M but
then the result is going to be too big
to Ripper
so before I even compute the result I'm
going to project it back onto the space
of distributions that are completely
factored okay and then I'm gonna
continue use that multiply and project
multiply that and project all the way
down and I'm gonna sum all those up okay
and the question is I started with
something this is what I wanted this is
what I started with this is what I
wanted to give you this is what I
actually computed can I say anything
about how these two things relate to
each other can i bounce some sort of
error here and the error shows up in
three cases so there's some error that
started off I'm gonna talk about the KL
divergence error okay because the quell
divergence error in expectation goes
down as you condition on things and like
the l2 or l1 there so because I'm gonna
be conditioning so there's some Cayley
versions I started with here this step
is an approximation of that step so I
introduced some error there
I used that error multiple times I sum
up a bunch of these things which also
introduce some error and then I didn't
do this for an infinite amount of time
right we should I supposed to do okay
the saving grace here is that M is a
stochastic matrix so then a stochastic
system over time it tends to couple that
is it loses its memory right okay
so that means that as I multiply these
things together if I start with
something as approximate then over time
actually I'll end up sort of towards the
same thing if I let it run the latest
forecast adjustment for a long time and
it's an ergodic system I'll end up in
the stationary distribution I've
completely forgotten where I came from
okay so so that means that if i
propagate through m there'll be some
that's supposed to be a subscript
there'll be some contraction rate by
which this my KL divergence shrinks and
the projection error can be bounded by a
constant and so essentially the good
news is that if I have a multiplication
contraction rate in a constant error
write a geometric series converges okay
so the complete bound looks like this
that's lovely isn't it yes okay so let's
see um I started off with you don't
wanna see the proof okay so I started
off with KL divergence I began
with that contracts by some global
contraction right now this is gamma
prime not gamble explained that
difference in moment um there's an
additive factor here and then this just
comes out from the fact I truncated the
Taylor expansion this determined
practice is very very small at least if
you're willing to spend a little bit of
time at so they're basically two
questions here the first is what's gamma
prime and why is it not gamma the
contraction rate for the whole thing and
the second is why can't I just use the
Boyne color analysis for DB NS which
essentially does a similar thing and let
me see if I can just quickly say that
what is so the contraction rates you can
think of each local variable having its
own contraction right so we're gonna
build off of that
and the reason I can't use the DB n
thing directly is that when I do this
uniformization I don't end up with a DB
n I end up with a mixture of DB ends and
so Boyan color doesn't exactly apply
there so one interesting thing is that
the percept contraction rate scales as 1
over n with the number of variables it's
actually not good but if I take the
entire process of pushing this forward
the whole process contraction rate does
not scale with the number of variables
it's constant okay so and you know the
details are in the paper ok so let me
talk about somebody else's work yeah I'm
good so we thought by somebody else's
work so mean field is this other method
right for the approximate distribution
and that I sort of I take this
distribution this is the distribution of
that all the processes and I approximate
it in a factored form it says the
product over a set of local
distributions so in their work they
represent each of these Q's as a in
homogeneous Markov process and so their
number of different ways of
parameterizing in homogeneous Markov
processes this is the one that works for
them mu at a particular time is a vector
it's the marginal distribution at that
time ok and the other natural thing
would be have the local q matrix at that
time which is a function of time as wise
in homogeneous but instead what they do
is something a little different it's
sort of like the density of transitions
and I'm not going to get into the
details exactly why but it's certainly
related to Q ok so the algorithm is you
pick
bunch of cues you hold you hold all the
others constant you pick one of them and
you try to maximize or minimize to kill
divergence between your approximation
and the true distribution all right it's
this it's a it's a variational approach
okay so what so then you work through a
lot of math and what do you get you get
that your nu nu I I'll just do the me
wise I won't do the gammas your nu mu I
a particularly you I your gammas that
you've already computed and then sort of
the processes in your Markov blanket
okay so why is this good is this is a
differential equation I have to solve
but that's good because again I can use
some sort of adaptive integration method
here alright so I pull out you know this
particular process and to go estimate
its distribution I do some adaptive
integration that means at certain times
I take large jumps and other times I
work down small and be approximate this
also means that each variable has a
different adaptive integration
associated with it so some variables I
can reason about very quickly other
variables I take time and carefully
reason about them which is good for most
systems you have some system you know I
have the weather that evolves at a much
slower time rate then you know the
traffic that I'm trying to estimate then
the actual individual vehicles on the
road okay okay so this representation
here ends up being naturally adaptive by
variable by time and so you're gonna
save computational effort now I'm not
saying you could not do this in a
discrete time model but I think it'd be
much harder to try to figure out how to
do it it wouldn't be as natural to try
to reason about okay I'm gonna jump for
time steps ahead or five times upstage
you don't I mean you could do it but
it's not as it's not as natural
certainly you'd have to take integer
jumps energy value jumps okay so let me
talk about two ways in which we've
applied this the first is to network
monitoring so I have a bunch of
computers they're hooked up to a network
and what I want to do is I want to put
something on the neck here so that I
analyze the packets that come in and out
and tell you whether or not you
currently have some malicious thing
running on your software or some
software running here left ok so I'm
going to build a particular ctvn I'm not
learning the structure I'm fixing it
essentially I'm gonna take the traffic
and I am going to separate it by
destination ports we'll assume these are
not servers these are clients so you
know all my web traffic 280 only web
traffic to you know to some other you
know alternate port all my DNS traffic
centric my ports I think I'm gonna pick
out the top ten ports or something or
nine ports and then one catch-all for
everything else other than separating it
by port I am NOT going to care about
anything except the exact timings so I'm
not looking at payloads other than two
port numbers destination port numbers
I'm gonna build this as a plate model so
I assume that the traffic in general
from your computer is generated from
some hidden node that has four states
okay I'm not going to give any semantic
meaning to those those are just states
that can couple things over time for
each port their end ports for each port
there's a hidden variable is ng
dictating how that cursor of traffic is
being generated okay and hanging off of
that hidden variable I have four
variables one to indicate packet came in
one indicated packet came out when did
indicate a connection was started in one
day okay the connection was stopped so
is it good okay so so these are these
are timing events here packets in
packets out the rest of it okay so we
looked around we found two data sets the
Maui data set is some pacific backbone
data that comes from japan in this study
we assumed that we took the UC we take
the 10 most active IPS we assume that
that's all the traffic is being
generated for that IP which is clearly
false for this data set you know I mean
anything that's stayed within Japan we
didn't see anything that went to
somewhere else in Asia we probably
didn't see LBNL has some enterprise
traffic I don't know what enterprise
network it's from it might be LBNL
network they might have gotten it for
someplace else I can't remember so we
took that that's this is at the routers
inside the networks this is probably a
reasonable approximation everything that
happened for those hosts we I think
split the data 50/50 we trained on the
data assuming was clean so as we built a
model of what the normal traffic is it
comes out of this computer we took the
test set data at certain periods of time
we inserted
Wurm traffic from from running a worm
and gathering the traffic comes off and
inserting it in there now these worms
are pretty easy to find
they tend just go poo and spam bunch of
packets so we scaled them back down to
1% or 0.1% of their natural running rate
so they blend into the background take a
more difficult problem and then over a
sliding window of 50 seconds we
calculate what's the probability under
our model of that 50 second window of
events condition everything seen this
far okay and if that probability is too
low we say that's abnormal that's
strange something strange happened in
this window okay so here are let's see
there ROC curves so here ROC curves
these are the two data sets these are
three different worms of various forms
our line is the black line that's on top
I'm shocked okay so so that's our model
notice the false positive rates here go
from zero to 0.1 and the true positives
go from zero to one we compare it
against the number of other standard
machine learning techniques this dashed
green line which you may or may not be
able to see is a nearest neighbor based
on some features proposed in the network
literature um actually this was a paper
in the network literature the one that
actually beats us at one point is a
connection counts just count the number
of connections that have is too big
definitely something strange is
happening let's see this is a partisan
density window estimator sort of built
on the same thing as the nearest
neighbors and the purple one is a SVM
with a kernel design for this sort of
anomaly detection method okay so there's
an example of using this to detect
network traffic we've also used to
detect wire now where it came from so we
took the same ten hosts and then we took
a 50 second window of traffic and asked
it to say which under which host was
this most probable so imagine they all
sit behind NAT right and we can fairly
accurately describe which which host it
came from so you can do host
identification
yeah so why did the LBNL in the my doom
worm yeah we looked at it it wasn't
entirely clear to us I agree that's
strange
and we couldn't figure out why did we
want to know we wanna know because then
we could improve our method right what
is it no we don't know it wasn't clear
to us exactly what that combination was
doing there because you notice that if
you change if you unilaterally change
add the two dimensions you do fine it
wasn't clear to us hey there are
millions of packets that we couldn't go
look through them all but yeah at least
initially as time as you're just as
you're so the ctvn is the limit of a DB
n as the time wave goes to zero okay but
it's computationally more efficient than
his time was goes you're your
computational time also blows up here
here I mean like this so the answer is
essentially that as you vary the
threshold you you suddenly grab a bunch
of you suddenly grab a bunch of the a
bunch of the traffic and that's all you
can get that makes sense
so so some of the time windows the same
threshold was me it instantly push you
across them it wasn't helpful so so the
threshold is on the probability of that
window right so so certainly I drop the
threshold let's see over here the
probability is really really high right
really really low sorry probably is
really really low as I increase that
probability it's one of the two as I
increase that probability basically move
from here to here there aren't sort of a
aren't very many operating points in
between yep oh yeah that's a good
question we didn't do that so one thing
you'll notice is that you have to use an
approximate inference about here we're
using a raw black wise particle filter
actually so I didn't tell you that's
another one you can do about black was
one reason rot and if I went off and
implemented the same thing in the
discrete time you could have distinct
qualms about how I chose to implement
that particular one so I don't know what
the equivalent one but one thing is the
rates here do change drafts of the rest
time right the computers off the rate
events happening is very very slow then
the computer comes on you know rate
events happening is very very fast so
you'd have to have a pretty small time
with window to capture a lot of the
stuff that happens here because there
are times when you know I'm really
capturing every packet whether or not
they're only microseconds apart or
milliseconds at least apart and if I
wanted to sign slice it that way this
would be intractable on a DPN
the performance approaches
yes as I said it certainly if I took the
time slice with to go to zero and I had
that I don't have that much computation
time this year but if I did then I would
get these results the ctvn is truly the
limit of a DB n as the time slice with
goes well I'm saying is the only
comparable one I have here is a time
slice at the smallest event between two
the smallest time with between two
events so okay so so I have events if I
have packet a packet emission another
package emission if I want to capture
them both in the DB n model I have to
sample at a rate that's that narrow us
with if I sample at that rate there's no
way I'm I can compute this in a year or
two yeah okay so I get so I can do that
so I can try to aggregate then I have a
DV n that's a little different right
then I'm saying it's Markovian and the
number of samples that have happened
between here and here and then you have
a different model than I have yeah and
so then I can't if you're just talking
about a comparison on computational
point of view I can't make you
comparison there because you know you're
saying it's Markovian and the number of
samples that have happened in the past
time with and I'm saying it's Markovian
right in in this global state that went
on and so you really have a different
kind of model this is the hard part
about like comparing the two is if I
time slice it's finally enough I can't
compute the DVM one and if I don't if I
do something like that now we have
different sort of Markovian assumptions
and you know yeah we have we have other
problems comparing yeah
yeah so all of this was taken from one
week so that's why the hidden variable
is here so we don't we don't we don't
automatically do anything about it we're
hoping the hidden variable captures that
kind of semantic meaning that is from
the past window I'm going to have my
current state have some estimate of
let's say G that captures the fact that
it's currently you know Monday afternoon
and things are different Monday
afternoon force I'll say yeah four
states were enough and it was also
enough that we could do the computations
so is this balance between express
ability and computational power now
again this was this is traffic across I
think it I think it was a week it might
have even been shorter than that okay so
I don't want to claim some broad thing
about yeah this would work you know
across months or something like that
yeah this was also done about four years
ago when our ability to do exact or
approximate inference and exact
inference it wasn't as good so I think
we can we can crank these numbers up now
with both better numeric algorithms in
okay I did that okay so the last one is
social networks okay so a lot of people
look at static social networks in fact a
lot really smart people looking at
static social networks so I don't do
that because I want to compete with
really smart people so actually there's
tomorrow's for our people again dynamic
social networks if there's fewer of them
so so here's the idea is that I'm
monitoring the communications let's say
in a social network either I've seen
people's emails or I see people's phone
calls or I see people's Facebook
postings or whatever it is okay depends
on you know what institution you live in
which is a reasonable model and what I
want to do is I want to estimate this
the changing underlying social network
okay so what we do is we basically build
a generative model of the social network
of the actors internal parameters and of
the
serving communication patterns we take
that model we conditioned on the
observed communications we actually saw
and we try to reason about what the
social network might be okay
so we call this the hidden social
network model it's built on some work in
sociology so sociology has been looking
at social models for a long time and
they even have continuous-time markov
models of how social networks might
change
we took the one from Schneider's it's
the network attribute coevolution model
so it essentially says that the network
evolves so links between two people
change based on the attributes of those
people so if I smoke and you smoke then
chances are you know will form a there's
a higher chance we'll form a friendship
than if not and my internal attributes
like whether or not I like football
might change based on one of my friends
like football okay so the network
attribute coevolution model broadly
looks like this they're two kinds of
variables Y IJ is whether or not there's
a directed link from I to J at a
particular time and Zi is whether the
attribute of actor I think incident so
so I so I'm going to define the model
but I'm not going to observe that
variable to make sense
ah yeah so I'll talk about the
verification moment it gets a little
tricky yeah
yes in fact I'd love to have a better
data set in which to do it
but I'll show you what we can do okay so
the model from Schneider's is best
described as sort of a forward sampling
model every actor has a rate of change
when their rate comes up you know the
event fires they look at their current
network in their current attribute their
local like who their friends within
their local attribute and they consider
any unilateral change so I make or
destroy one friendship or I change my
attribute by one value okay
well this is continues time so one
person would be one look that's correct
okay so so I compute those utilities
someone bigger than others I put them
essentially into a Boltzmann
distribution so it's just a Vegas Lea
softmax and I picked the one that's
essentially including the one I'm
currently in the central Assaf Mac so if
I'm currently in a local minimum or
maximum I guess in this case right I
tend not to move away from it but I
might hey that's the model and the only
question is what does this utility
function look like and he essentially
proposed it should be some linear
function of some things and the ones who
use our popularity number of mutual
links similarity of your attribute to
your friends stuff like that okay all
right so essentially I have one variable
for every possible link in this network
so there are n squared variables ok so
recall I have let's say I just have 10
actors that's roughly a hundred
variables that are all binary that's a
state space of two to the hundredth so
I'm definitely not representing this
thing exactly all right
and then to add communications okay so
there's a there's a CG BN that describes
relationship between these it's kind of
hard to describe it's essentially
involves context-sensitive independence
so I'm not going to describe it but it
essentially amounts to a CTP n the the
social model I just described so I do is
add a communication variable here and
it's tied only to these two so this is
the communication pattern between I and
J and it depends only instantaneously
and whether or not I considers J to be a
friend and whether not J considers I to
be a friend and so this might be you
know they might they might have a few
states like they're calling each other
they're not calling each other send a
text message sends an email you know
that sort of thing so you have a number
of states about what the communication
is at a given instant so these change
fairly rapidly these change is certainly
much more less rapidly over time all
right so here's the data set we used
this is the reality mining data set we
actually use the first versus the data
set there's a there's a second more
complete version out essentially some
people to MIT convinced a number of
students to put on their mobile phone a
little application that monitored when
they took particular who they called
when and when they sent messages
actually monitored a bunch of other
stuff too but we're ignoring that part
for this one I was of course about a
year
we chose everybody in there who has sort
of sensually had a valid phone number we
don't know the phone owners themselves
but the data was kind of being consisted
in some ways so we through it anyone was
coming consistent we resulted with 25
people from the Sloan Business School
54 people from the MIT Media Lab this is
not surprising those were the two groups
involved with setting up the study yes
and then 13 people who we don't know
their affiliation because they were not
enrolled in the study so these people
who do not choose to be part of the
study but more than one person they knew
it chose to be part of the study and
called them at some point yes okay this
is important to understand right so
nothing was running on their cell phone
until it happened but you know some of
their friends were blabbing about what
their what they were doing okay okay so
it only is this phone messages and text
message the phone calls and text
messages okay so we learned a bunch of
parameters so we do we take all that
data we only observe the communication
patterns we do p.m. to estimate the
parameters okay then I'm going to view
parameters and we'll do something else
with it so first we get the network
dynamics this is from Schneider's model
we get the rate of changes everything
here is in units of days well this one
is these are just unitless numbers so
this essentially states that you don't
tend to make random friends so all the
things vehicle you're attending not to
propose a friendship with someone random
this says that you really tend to
propose friendships to people who
already friendships with friends with
you and that activity in popularity
which are sort of measures of the number
of people connected to you who are
connected to somebody else are not as
important an interesting thing is we've
tried this same model on other kinds of
datasets so there's one that has some
panel data where they interviewed or
surveyed a set of teenage girls like
early teenage girls in some school
somewhere in Europe I think it was
Scotland I can't remember where and they
asked them a number of attributes like a
year 1 year 2 and year 3 you see how the
friendships change we actually get kind
of similar numbers out here that was
just kind of interesting
no no no that's this this is the rate at
which you propose a change to your
network so that means on average once
every 40 days is what this is it's
related to it and just a little
complicated cos involves this then when
you go to make a change you then score
any change you can make I could drop you
as a friend I could add him as a friend
I I could drop you as a friend or I can
add him or add him around him I change I
consider you know what one unilateral
change I score them all okay and then i
roughly pick the one that's max that
gives me the back score and the question
is how do i score them and the answer is
the resulting network I score according
to its density my local network density
the reciprocity the activity the popular
now I combine them with these linear
weights okay so this says I tend to
prefer things that I have I tend to move
to networks that have a reciprocity in
okay now the communication pattern these
are the rates through the communication
pattern so that that's the rate for the
underlying social network is rate for
the communication patterns so this is so
this is communication
from K to L this is whether or not
neither them can serve each other friend
K doesn't consider Al to be a friend but
L considers K to be a friend the reverse
and they both consider each other to be
a friend okay
and so if we'll just take this line here
this essentially means that the average
time or an expectation they tend to
contact each other once every 3 to 4
days 80% of those are phone calls 20% or
text messages this was you know 2004
text messages weren't as popular then I
guess and the average conversation here
this is the end rate for a conversation
the average conversation ends in about 5
minutes on average right ok and you
notice the rates here differ by huge
numbers orders of magnitude I'm not
gonna be able to capture these things
very well efficiently in a uniformly
time slice model okay so then if we fix
these parameters we can go back and ask
okay what's our estimate essentially a
smooth estimate I have all this
observation what's massaman at this time
step of what the social network looked
like and so here's the estimate for
instance at August 19th and number 17th
actually at midnight because it's a
continuing
I'm number and the February 15th and now
here's what I'd love it if they'd gone
back and asked people with their
friendships were so I could go validate
it and I don't have that information was
data said it's hard to find a data set
that has good information like that so
all I can do is say doesn't this look
reasonable and it's not a very it's yeah
it's not as convincing I'll perfectly
admit that okay so so one thing to note
is that the algorithm did not know these
groups okay and we can see there have a
more dense I mean they were just all
given a random ID okay so the algorithm
tends to cluster you know the Sloane
people know each other the Media Lab
people certainly know each other and you
know business school students are more
social than Media Lab students hey right
yeah I'm there's a selection bias there
right okay and furthermore these
thirteen people who we don't know who
they were they seem to more related to
the Sloane Business School students
right then but here's something
interesting I'm estimating social
network connect so what is the heat map
I should make its closures white means
we're pretty sure there's not a
connection there's probabilities right
black means we're pretty certain there's
a connection and you know orange is
reasonably sure and yellow is not so
short right okay so I'm estimating here
friendships among two people whom I've
never observed the communication pattern
between them because their phones were
not monitored
I only observed when they called someone
in this network furthermore the people
who were in this study came in and out
of the study it's not like I observed
them continuously over entire block of
time someone performance study here and
drop this study here I'd love to be able
to verify these so how do I do that at
all the so it's not that I observe they
didn't communicate to each other
it's I didn't observe whether or not
they communicated to each other but I
have certain notions of what social
network should look like if there's a
reciprocity in terms of you know
community and stuff like this of the
social network and that least gives me
an estimate here now I don't know how
accurate that estimate is these are
really hard they didn't agree to
participate in the study all right I
can't go track them back down but I'd
love to know whether or not you know
that because there's this one here
that's solid oh no no I have anonymous
versions of their phone numbers yeah I
think they got you know
they got hashed it one way hash done to
some number yeah called him up high back
in 2000 back in 2004 did you happen to
know somebody with this phone number
oops oh no that was terrible hang on let
me and I'm essentially done here so let
me just go here okay
so I'll give two plugs one is the code
for almost all the CTP and algorithms I
have available on the website we hoping
to release a new version of it soon
that's the current version it's there is
not as numerically fast as we like we
completely under redid the whole matrix
package with a with eigen which is a
pretty fast matrix package and works
much better I'm giving an you ai
tutorial on continuous time processes
along with John Franco Chardo who's a
professor in verification gives sort of
the other side of this these kinds of
models been used in verification Petri
nets so that sort of stuff that you AI
holds or do a tag-team kind of tutorials
see some of the same slides but not all
of them anyway I and the last thing is
I've tried to at least argue the case to
avoid time slicing there's certainly
some cases where your data is naturally
time slice so if you want to model the
daily high temperatures there's a
natural time rate for that right day by
day in fact it isn't a continuous sort
of thing okay so alright so there are
certainly cases where you know discrete
time is the only way to go but if the
underlying process is continuous time I
think it's at least you should least
admit it just like you know I'm gonna go
implement this algorithm in a computer
but I nevertheless think I have infinite
precision floating point numbers when I
go to analyze the algorithm and develop
it that's harder to say you notice I
haven't covered a continuous state right
so this is discrete state so we've done
some work on continuous state right the
this is the common filter has a
continuous version right and these sorts
of things that use stochastic
differential equations and and you know
the the classic option pricing is built
on stochastic differential equations
that do exactly this they treat it as a
continuous time process yeah I haven't
done I've only done discrete time I mean
we can talk later about the continuous
state one but I've you know finite
amount of time in the talk yeah
that's okay a good case against so but
what's the objection to thinking of a
model where just every time an event
occurs that's my time okay so you're
saying what I could do is I could build
it's called the Marty Oh the underlying
uh Markov process is on the the the
skeleton the underlying Markov the
underlying skeleton right just okay you
can do that the question is you might
care about the timings I might care so
you say I go from state one to state two
to state one to state two to state one
to say two but I might care the one I'm
in state one I stay there for you know
three times as long as when I stay there
in state two yeah you can you can do
that um you don't end up with a Markov
process you end up with maybe a a yes
semi Markov process or something else
like this I mean one of the one of the
large drawbacks behind Markov processes
is discrete time or continuous time is
that the dwell time in a state has to be
either geometrically exponentially
distributed right the geometric req
Spencer's distribution is the only
self-similar distribution of my
condition on having been in this
distribution for this amount of time the
amount of time I remain is still the
same distribution okay that's that's
what needs to be Markovian so if you
want something as that is not that way
you have to move to at least a semi
Markov process we've done that a little
bit haven't shown this here we've done
things where the rates vary cyclically
based on say the time of day those are
things you can incorporate that in here
to make sort of these semi Markov
processes
yeah if all you care about is the
sequence of events and not their timings
then that's right then you have then you
definitely have a discrete time problem
and you should treat it as that I'm not
gonna argue against that yeah answer
your question I successfully skirt
around your question - I'm not trying to
skirt around it I just um the other
thing is right I may have observations
here's the other way I have observations
that are tied to x usually right I asked
a sensor what's its value is a
particular time I don't ask it how many
events have happened since the beginning
of time so I know how to put you in a
time line right and so you're you're
talking about a model in which if I made
observations have an IV need to know the
number of events that have happened or
is this more natural know the amount of
time that's happened maybe that's a
that's that's a different answer I'll
say yeah so this is I mean you can build
these things off of you know plus one
point processes right yeah is is
directly related to yeah poised on point
rates that's right yeah so how how big
can I build this up - well it depends so
the the the social network right has a
very large state space if you don't
include the communication variables you
just include the you just include the
other ones because we case you varies I
essentially always view then I've got
the state space is two to the
ninety-seven squared ninety seven people
there okay 97 squared minus 97 okay you
know possible arcs and two - that's the
state space there okay
that's big I'd argue that's that's
that's decent-sized
the read the what the what let us do
that is we're doing sampling on this
case and there's a lot of internal
structure right the essentially a few
rates are governing a lot of what
happens I assume people are essentially
homogeneous okay for things in which
that's not the case you can do exact
inference
none of these things are executives you
can do exact inference for Oh at least
somewhere between ten and fifteen
variables okay and then how well you can
do approximate inference after that sort
of depends on how much time you
willing to throw at it and what fidelity
of your answer you need so we can go up
to you know somewhere between 10 and 100
variables easily sort depending on that
and then beyond that you probably rely
on something else currently I'll say
also that each year we get a little bit
better about figuring out how to how to
make our approximate methods a little
bit better so I wouldn't be surprised if
you know a couple years I can come back
and say we can do a thousand variables
is that a problem but currently that's
probably not feasible for our software
the sampling ones are you know
ridiculously easy to parallel eyes yeah
so they can be parallelized yes so
slowly the learning can all be easily
parallelized the that first my showed
why are you pushing forward you getting
this approximation it's an approximate
of something approximation that one the
matrix multiplications you can do some
parallelism on it it's not as it's at a
much finer grain and harder to do yeah
it would be it would be it is to
certainly be feasible we haven't yet
looked at that but yeah great thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>