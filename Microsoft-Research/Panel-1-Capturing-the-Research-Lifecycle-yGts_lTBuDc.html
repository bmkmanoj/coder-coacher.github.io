<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Panel 1 - Capturing the Research Lifecycle | Coder Coacher - Coaching Coders</title><meta content="Panel 1 - Capturing the Research Lifecycle - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Panel 1 - Capturing the Research Lifecycle</b></h2><h5 class="post__date">2016-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/yGts_lTBuDc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by microsoft
corporation may be used for internal
review analysis or research only any
editing reproduction publication
reblogged showing internet or public
display is forbidden and may violate
copyright law
so good morning everybody and welcome to
the first panel of the morning and
entitled capturing the research
lifecycle my name is Courtney Soderbergh
and I'm the statistical and
methodological consultant at the Center
for open science we're a non-profit
startup in Charlottesville Virginia and
this morning we have a great panel of
people who are working on increasing the
openness reproducibility and
accessibility of many different points
across the entire research lifecycle so
over the past couple of years there's
been a growing movement to increase the
openness and transparency of science as
well as the reproducibility of science
and so what we will be happy you today
is leading organizations and companies
who are working towards that movement
we're going to talk a little bit about
how we are trying to accomplish those
goals and also some of the challenges
we've encountered while working towards
those goals so together our panelists
represent work that is going on at many
different points in the research
lifecycle so we have tim gardner from
riffin a company that is working on
automating data acquisition and analysis
to increase reproducibility arfin smith
from github a company working on sharing
and collaborative coding Ryan Dooley
from Texas Advanced Computing Texas
Advanced Computing Center there we go a
leading youth University
high-performance computing center that's
working on sharing code and scientific
data we also have Lars Nielsen from zen
odo a project out of CERN working on the
sharing inside ability of data and code
we have jon lees Miller from overleaf a
company working on creating
collaborative tools for publishing and
writing we have Robert Spiegel from
publicized an organization working on
increasing the dissemination of
scientific research and we have me less
awkward way to say that from the Center
for open science a nonprofit working on
increasing the connectivity
documentation and openness across the
entire scientific workflow using our
infrastructure project to open science
framework so how this is going to work
is we'll start out with everybody giving
two to three minute lightning talk so
you get a better understanding of who we
all are and what we do but the majority
of the panel will be four panel
discussion and Q&amp;amp;A from the audience
so I'll go ahead and start us off as I
mentioned I'm from the Center for open
science we're a nonprofit organization
who is dedicated to increasing the
openness reproducibility and
transparency of the ensign of the entire
scientific workflow and we do this
through three major efforts don't worry
so the first is our meta science project
so we do science where's the cyclic ah
so right so the first is meta science
project so we do science on science and
we do this to be able to track the
extent of reproducibility issues and
also look at how changes in scientific
behavior leads to changes in the quality
of scientific output we also have
community efforts so working on training
scientists and better open and
reproducible practice as well as getting
journals to adopt open standards and
practices and finally we have our
infrastructure project to the open
science framework which is really about
it's a free open-source platform that is
trying to make it easy for scientists to
implement these open and reproducible
practices so as I mentioned the open
science framework is a free open source
web tool and it's really trying to
connect document and archive and also
make openly accessible the entire
research workflow so everything from the
beginning implementation of a project
idea all the way through publication and
post-publication discussion to making
that research and data searchable and
discoverable by other researchers so the
OSF does this by allowing researchers
and their collaborators to upload all
the files related to a research project
so they can upload all the input and
output of research problem sorry
research project in one central location
there's also automatic logging and
versioning so that the evolution of a
project is documented and then with one
click of a button up here they can
either make the entire project or parts
of that project publicly accessible and
searchable so that other researchers can
find their research output and input and
also use it inside it so the research
kind of propagates to other research
projects
and so by making this very easy for
scientists to do and putting it at all
one location what we hope to do is make
open and reproducible practices more
normative throughout science we also
connect the OSF to a growing growing
list of add-ons which currently includes
dataverse big share dropbox github and
amazon s3 and the reason we do this is
to allow researchers to continue to work
with the tools that they like and they
are familiar with so rather than rather
than requiring researchers to make this
huge overhaul to their workflow in one
fell swoop we allow them to kind of make
slow changes to the workflow so they can
still use these tools but they're all
connected in one central hub and the
reason why this is useful is that a
makes things less likely to get lost so
if you have some of your project and
your email and some on a server and some
on your collaborators laptop these
pieces and parts can get easily
disconnected and things can go missing
but it also makes it easier to share
that entire project with your
collaborators and with other scientists
and so it's really about meeting
researchers where they are so allowing
these kind of incremental changes to the
workflow which will lower the barriers
to implementation by scientists because
they don't have to make this huge
overhaul and so the aim is to make it
easy for researchers to make these
choices and these workflow changes to
allow open transparent and reproducible
scientific workflows for everyone all
right so next up are these all on one
slide deck or okay yep cool okay thank
somebody um so my name is almost myth I
work at a company or yeah and we've got
a cool thing in the corner oh there we
go all right so I'm apologies for the
stupid title I was trying to think of
something funny so I work at github
before get hub i co-founded a
crowdsourcing platform called universe
we did lots of citizen science I'm
interested in tools that help people do
research better together basically so
very briefly
I go to the next late clicker this one
okay so what's github well github is a
place where people do software
development together why can't I scroll
this way just get page to page sorry all
right let's just see how we got them
okay so github is a platform where
people build software together there's
about 10 million people working up there
and there's about 15 million software
repositories so these are places where
people actually collaborate around
software development together the the
way that I usually explain research to
researchers version control is this most
of you probably have a folder on your
computer or many folders on your
computer that look exactly like this
maybe with some other versioning
technology that you're using my PhD
supervisor by the way used underscores
instead of naming conventions like this
because if you put a number and an
underscore at the start of a file name
in most operating systems that jumps to
the top of the tree so you can put
multiple underscores if you really want
to make it the latest one and that is
what he did this is obviously a terrible
idea so there are better ways to do this
which things like get so this is a
versioning technology here we've got
about 50 people writing mathematical
textbook hour and as you can see there's
sorry for the transitions this is the
way it's going to work you can see
time-based changes and each of those
changes if you look at those are you
know there's an explicit red-green-red
four lines taken away green four lines
added this is a technology get the
technology that powers this as a
technology that was developed originally
for managing the 20 or so million lines
in the linux kernel so the thing that I
spend most of my time thinking about in
github is increasing the status of
software in academia there's a in my
mind that I think in lots of people's
mind a fundamental problem and the way
that we do research and we credit
research activities that right now you
don't have a particularly good career if
you spend a lot of time writing software
in academia and so one of the one of the
things we can do to help with that is do
things like this this is a integration
that we put together
by our mutual api's with dinoto Lars is
going to talk in a second looking about
this may be a bit more about sort of
hacking the existing system so getting a
DOI for a github repo does that make it
sigh tible well it was already sizable
with its URL but it gives it something
that smells a little bit more like an
academic citation and so this is
actually something being used about
1,500 times now in the last six or so
months and fifteen hundred times as 1500
research software packages that have
been archived in zone odo not just you
know that's a relatively small fraction
of the tens of millions of repose up on
github but these are research ones the
thing that I'm most excited about when
thinking about github and the
opportunities of the platform within
academia is that there's actually a way
that open source communities people
build software together that's very
different from the way the academics
usually work and in short open source
communities are better at collaborating
than most of us because they have to be
because otherwise they wouldn't be able
to build something together and so when
we talk about open source lots of people
think this is a kind of sort of open or
Die rant about doing all of our doing
all of our software development or all
of our research open and in the public
and it doesn't actually have to mean
that the principles of open source ways
of working are actually things that we
would all recognize as a thing of value
and those are pretty simple they're
things like electronic communications
with all your communications being
available this doesn't mean email email
is not available unless you're going to
give everyone access to your inbox so
it's about everything having a URL the
process by which decisions were made
being exposed and this is again this is
actually an internal conversation thread
this is a screen grab of one of our
internal repositories that github where
we're making we're having a conversation
about a change in the product but I can
go back and look at that three years
later and see how that process came
about and this is a technology thing but
again some technologies allow lots of
processes to happen in parallel and then
conversations approval and increments
improve improvements in what you're
working on there
decision can be deferred till later so
this is actually the CMS software that
runs the detector on the Large Hadron
Collider this is lots and lots of
different development branches all been
worked on in parallel together at the
same time and decisions being made when
when sign-off is ready so open source
collaborations are lower friction and
academic ones usually and actually
fernando perez who writes the ipython
notebook had a great frozen a blog post
of his where he described open sources
being reproducible by necessity and i
think this is something there are
communities who work in reproducible
ways because they have to and so i think
i just wanted to say because we're about
to have a panel and you meant to set
yourself up by saying something stupid
you're going to regret later I don't
think reproducibility is a technology
problem or a new technology problem I
think reproducibility is actually a
workflow and cultural one and so I'll
stop there ok so I'm Ryan Dooley I'm
from Texas Advanced Computing Center it
is a if you've never heard of tak tak
focuses on operating a lot of the large
supercomputers for the academic science
computer I'm located in austin we're
hiring if you want to live in austin and
do cool stuff and play with great
technology come talk to me afterwards
but i am here talking about agave right
and gaba is the sciences service
platform and what do we mean by that
well it means that we it allows you to
run your scientific codes on HBC or
there's high-performance computers these
big big bay leaf clusters
high-throughput computing lots of little
computer spread out all over the place
they just needed to turn through a bunch
of work or cloud resources manage your
data from the web and remember how you
did it all right it's it really just an
api platform very restful it's
multi-tenant hosted identity management
so we
and provide you with you know your your
ldap if you need it or we can plug into
your local identity solution we support
multiple IDPs like I said we have a you
know a standards-based authentication
mechanism we provide API management we
can run on-site or off-site there's a
lot of flexibility the point is that
it's a platform that allows you to build
your digital lab all right so whereas I
think the the Kino is talking quite a
bit about that the need for
infrastructure and the need to have kind
of these fundamental building blocks
that that other people can just kind of
take for granted like the utility grid
that's really what what a gobby does
right so it was funded by the National
Science Foundation for about ten years
now it's adopted in several countries
joint funded internationally we have
data replication all over the world and
it's free free to use I'm just coming
use it you can fork it on github or
bitbucket and take it to do whatever you
want what to do but it's easiest if you
just think of it like a Salesforce for
science so it kind of meets your needs
if your developer great you have API is
to use if your service provider great
there's stuff for you to integrate with
if your infrastructure provider there's
ways for you to delegate and kind of
modernize your infrastructure you're an
educator it gives you rooms to gives you
a facility to really spur discussion
without having to understand the
underlying technology if you're a
researcher it just tells you to do your
science faster right so it's used in a
lot of different places these are kind
of larger funded project to the building
web applications on at the left hand
side we also build mobile apps on it at
TAC are we eat our own dog boots our
mobile app is built on top of it and
it's also used to extend existing
processes so you know for all the coders
in the room here's the terminal okay so
one of the interesting things and I
think kind of the reason I'm here today
is it we've been working a lot with
docker read recently to release /
reproducible science and whereas a gamma
really focuses on infrastructure and
providing you the mechanism for for
conducting your science and capturing
those experiments in a reproducible way
the code themselves tends to be a big
tripping point if you want to run in
differ
environments it becomes very difficult
just having a social coding platform is
helpful for the development but you
still have to set up your environment I
mean all the DevOps processes involved
with it are huge roadblocks to people so
we've been working to build up this
application repository where people can
integrate containerization of dr.
ization of their their application codes
so they can share those and run those in
a very reproducible way using agavia is
kind of an execution mechanism and what
that's allowed them to do is as a
researcher you can develop your code
locally you can develop it in
collaboration over a distributed source
control management solution and then you
can run it locally you can run it on
your local university systems in the
cloud in your local data center and a
private data center on all of these
commercial providers with a single
interface in a single way so that when
you have to go back and you have to
reference your your discovery you can
reference not only the the the the code
that you use in terms of a source code
you can actually reference a
reproducible docker image that someone
can pull down and it's a it's an answer
box right so it's just black box where
if you give it the same data it'll give
you the same answer and you can validate
the results they got were accurate and
that's been hugely helpful for us but
I'm going to run out of time here so I
just want to say if you need more
information here's some links and these
slides should be available on that
website
okay so yeah my name is LaShawn Nelson I
work for Sun and it's often assumed or
sonus but for those who don't know it's
the European Nuclear Research Center in
Geneva Switzerland we have a very large
research infrastructure that has been
running for nearly 60 years now and
basically we go here that's quite a lot
of ways to lose your research data
here's just one example of a lost laptop
with crucial scientific dates and many
years of research work inside I have
more examples for those who want to see
it so basically what we're trying to do
with the nodal is make it as easy as
possible to get your research data into
a proper digital archive and avoid a
faith like this that's the cool part of
it and one way that we are trying to do
that is collaborating with github I'm
making it as easy as possible to
snapshot your software and get up and
give it a DUI and make sure that it is
available in the future so it works
pretty simple you sign in with your with
your github account you flip a switch
and your source code repository and then
you go to github start making releases
and every single time you make a release
we automatically track down a snapshot
you don't even have to worry anymore
about about getting it and you can even
using our DUI patches you can then
advertise that you actually have a DUI
and that you should cite this piece of
software if you're using it and not only
can we then wrap the software and get it
into Sonora we also export the software
again the one example is that we have a
community for high-energy physics where
we then grab software from github we
export it again to the high energy
physics repository called inspire and
they are capable of actually linking
this software together with with the
paper that is citing this piece of
software it's also just one example of
how this workflow can be made super easy
for for researchers so they don't really
have to think too much about what
what's happening in the background and
that's basically it so i'm jon lees
miller i'm one of the co-founders head
overly so it overly were basically
building Google Docs or maybe I should
say office online for scientific papers
so it's online collaborative editing but
with a focus on features that scientists
need so we're now up to about a hundred
and fifty thousand users all over the
world and they've written over 1.5
million documents now on overleaf but
overleaf actually started as a much
smaller project it was basically
something that I wrote when I was a PhD
student just to make it easier for me
and my colleagues to write papers
together so we were we were using this
tool called etherpad which was like a
really basic sort of precursor to Google
Docs it was basically just an editable
text file in the cloud you could all go
in and you could write at least a draft
of your paper but it didn't really it
solved the collaboration problem really
well but it didn't do things like
figures or references or equations and
you couldn't really see the results of
what you were writing you know how it
would look in the end so so basically I
always sort of incremental II wrote
extensions to etherpad that would kind
of help solve these problems and it's
slightly embarrassing to show you what
the first version of overleaf looked
like in about twenty twelve it was very
basic that's what it looked like it was
basically an ether pad on the left there
you could write your source code so we
were all mathematicians so we would
write in latex that's what we like to
use you could upload figures in the
files menu there and there was also a
real-time preview of the final pipes at
output you could finally see what it was
going to look like we've done so it was
very basic but it was sort of minimum
viable product as they say got it out
there was on the internet people started
using it they invited their
collaborators and that's what really
could have kicked off the growth that
we've seen so fast forwarding to today
the product has come on a lot but you
can still still see it's got the same
sort of idea I'm you're right in this
sort of rich text manuscript view so
you don't have to know latex anymore to
use it it's it's all sort of hidden away
from you so you know if you write a blog
in wordpress you can either edit the
HTML directly or you can switch on rich
text mode and not have to worry about
the HTML we do basically the same thing
with latex underneath and you can switch
it off if you want to see the source
underneath other things that we've been
working on are around really making it
easy for people to manage different
versions so our phone had a great slide
that was pretty much how we use to
manage things except instead of dot docx
you with tech but you know final final
v1 final so now you can take your right
latex project you can compare any two
versions there's an integrated
commenting systems you can have a
discussion in line in your document and
sort of manage those changes and see
who's changed what and then when you're
finished with your paper you can then
publish it to one of our publishing
partners we've now got about a dozen
people on board so for example if you're
going to submit to life sciences publish
your app 1000 research you can just
click a button and we send all the files
and all the metadata and all that stuff
over in the background so you don't have
to worry about it and we're sort of
building these integrations up now so
that with f1000 research in particular
and when you submit that sort of back
and forth between their editorial staff
and you the author happens now on
overleaf so you don't have to send a
bunch of files around by email so that
makes everything just a little bit
faster a little bit nicer and that's
really an important part of the
direction that we see for overleaf which
is the new name for right latex which is
our original name it's all about one
collaborative editing it's about the
rich text modes you don't have to know
latex to use it and it's about bringing
more of the scientific process off of
people's laptops and out into the cloud
because I think that if you make that
process easy you then have a lot of
options for how you make it easy for
people to to then make things open and
make things much more transparent and
that's a really powerful idea so thanks
Rover leaf
hi everyone I'm rob seagull I'm the
founder of publicize and essentially
what publicize is is it's a science
communication platform to essentially
provide and help researchers formulate
the research into terms at any one can
understand so that we can start
disseminating research to different
audiences so I like to think of research
dissemination being broken down to three
different audiences first there's the
intra disciplinary audience and this is
kind of scientist to scientist of the
same field communication this is journal
articles and for obvious reasons this is
kind of what everyone this is basically
how everyone this is essentially the
most attention is paid towards this
audience and we can kind of see that
here today everyone's kind of talking
about how can we help researchers out
better communicate with other
researchers but there are two other
audiences that receive very little
attention and that's the
interdisciplinary audience and the
public and as a result because these are
audiences that don't have the
terminology they haven't gained
experience for so many years and all the
terminology you have to reduce the
complexity and reduce the jargon and
this is a very difficult task and this
is something that's often overlooked so
in this in these two audiences the
interdisciplinary and the public this is
where really great things can happen
this is often where implementation
actually occurs when a researcher puts
out there all the information to someone
in the private sector who's not active
in research they can actually take this
knowledge and implement it there's lots
of obviously Crossfield collaboration
this is where people say from biology
can interact with someone from
atmospheric science to look at some
different research project and this
often doesn't happen when you know for
example I'm an atmospheric scientist I
don't go and read biology journal
articles so how is it that i can
actually discover the latest research in
a different field and then there's also
the obviously innovation this is when
different minds of different background
can actually bring new things to the
table so that we can innovate faster and
then policy also is extremely important
and that is a very very difficult
challenge how do we get this information
from us to people of the different
audience so that we can implement and
make change there are other examples as
well so this is kind of where publicized
set publicise essentially the main goal
is to disseminate research in terms that
everyone can understand so we can take
all of this great knowledge that we have
and actually bring it to different
audiences so I've created a few months
ago I've created a kind of a Minimum
Viable Product and this is essentially a
website where scientists can go up and
they can essentially rewrite their
research article in about three to four
hundred words and there's guidance to
help the scientists formulate for a
different audience so they go up there
and there's kind of a back-and-forth
process so we essentially act as the
editor so that we can make sure that the
information is not only understandable
by the layperson also scientifically
accurate so that we don't have
miscommunication so we essentially have
this back and forth process where
publicise helped and then what you get
are these is this website with articles
written by the scientist that can be
systema nated on it throughout social
networks and anywhere else throughout
the internet and I'll leave it with that
a quick overview of all our panelists so
I guess we'll go ahead and open it up
for discussion questions from the
audience how do you prevent lock down
into your platforms like we talked
before was portability as one solution I
would like to hear you know how to
prevent somebody working your platform
and then cannot take this away
oh I can go first if you like and so
with whatever leaf everything is still
stored in latex and lay tech is an open
source technologies been around for a
long time you can always download
everything is one click and then compile
it locally or wherever else you want to
do it so we definitely know a lot of
people in with riffin first of all all
of the design files will be exportable
to an open standard called animal anim l
which is an ASTM supported standard so
it's a container you can push it out its
text-based so if you don't have software
you can still read it or you can write
your own software for it well also we're
planning to make the entire driver
technology for data acquisition open
source as well our our platform is is
totally open source right so you can get
clone it and then you can you can just
do a docker build he'll deploy the
entire thing all your data is exportable
and the systems and science that it
enables run on systems that we don't
know so you know you own your stuff you
you have access to it so get is
distributed technology by sort of
definition so github role is a
collaboration point around something
where anybody could host that
collaboration point I guess is probably
metadata associated with the
repositories that is not in the get data
but that can be exported there's a rich
API the people use so yeah sure
so the question was if if I cut afraid
how you can how you can win the login
prevent login yeah yeah prevent login so
at the sunoco the entire platform is
open-source GPL license on top of that
all the metered acc 0 license you can
take it away the actual data files has a
license attached to it if you own that
data there's nothing preventing you from
taking it out and putting it somewhere
else in with publicise I mean the whole
point is to get the information out to
everyone so it's inherently kind of open
source but essentially the way that it
works is the scientists on the content
so they're free to do whatever they want
and it's an open source and they're
simply licensing lights licensing it out
to me so that I can publish it on
publicise but completely owned by the
scientist yeah and at the OSF it's also
completely open source anything that you
put up there you can take down at any
time you can download files that you put
up there and we also have a
sustainability fund in place so if
something were to happen to us the whole
system would be frozen at that point in
time and you would always be able to get
to anything you put up and download it
at any point in the future yeah go ahead
yeah and then all our questions repeat
myself worried so each of these products
are all a certain step in the kind of
life cycle of research from gap from
getting the files off your machine to
the point where you're disseminating it
to a wider audience through publicized
so but this is already six different
things and I just wonder if her people
comment on the idea that one solution
fits all my personal thing thinking is
it shouldn't but you know elsevier do a
lot of that what that you have to they
can do everything but it's a it's a lot
of stuff but otherwise we're expecting
everybody to sign up for italy
six accounts for things and then and
kind of where is the balance between
those things because yes some people
think one size fits all some people
think six different products is great
how do we link them all together should
I start okay so in terms of senato so
one is I think we need infrastructure
like all kids so we support the login
with orchid I think that's you know
everything most of the tools here should
just support that then we have one
account that we can all use and I really
don't believe in one tool for for doing
everything I think you have to do one
thing really well and then do the
integration as you say between the two
like for instance the gate of
integration that we both have I wouldn't
know to be honest I mean the problem i
have in my roller covers that the
majority of users of github and not
academic users so the idea of an orchid
ID is sort of confusing yeah you can't
log in with your Facebook account or
your Twitter account to get help so I
would argue they would properly come
first before orchid that said if we
solve one then you know it's a standard
um as to so your question kind of gets
to what I was thinking about I i would
just reinforce what laws of saying i
think we like I think products are best
when they focus on solving one thing
well and get hubs role and it's been
kind of repurposed and academics very
good at hacking systems I think to do
what they want gabs trying to build the
best possible tool for building software
with other people just turns out the
lots of academic formats are versioned
well in gear and by github and so I
don't know I I think yeah I think it's a
potentially a problem having all these
products but I would rather see people
solve problems really well and then
expose their data and allow people to
build around that product I think that's
the way the web works yeah so I got this
kind of a low level piece you can think
of it like a platform so it provides a
federated out
authentication and authorization
framework so you can plug directly into
whatever you're already using so it
actually means you have one less account
that you need to use but in terms of you
know integrating with other applications
and building the entire stack on top of
that you know whether it be a center for
open science building you know execution
into their their framework then you most
of the time people don't know where
underneath right we power hundreds of
applications and no one knows yeah sure
side I'll echo the sentiment that
probably we're not going to find a
single tool that does everything that
every scientist wants to do just because
scientists do so many different things
certainly at overleaf we've had quite a
lot of success sort of doing API
integrations I think open API is
well-documented api's are very good
things so we integrate with fig share
you can link your right latex overleaf
account to fig share and we also now
integrate with men delays you can link
your mendeley account in your overleaf
account so you know I think that having
this sort of system where we r things
apart but can all interoperate is a much
more powerful idea than just trying to
build one monolithic tool yeah and I
kind of agree with that model as well
publicised is dramatically different and
get out for example you know so that's
going to be pretty difficult to be able
to do both of them really well but but
yeah so publicized is still in its very
early stage so we don't have anything
you know kind of fancy sign-in methods
but but that is definitely in the future
I agree with everything everyone said
and I think people are just
fundamentally to creative to try to
constrain them to a single company or
person or organizations view of how
everything should be done so you need to
give them the ability to to gain
advantage from the tool you provide but
the flexibility creative freedom to take
it whatever direction they want and I
also think there is something to be said
for allowing users to still use the
tools that they're used to in their
comfortable with but add on to that some
additional benefit so you know if you
really like you
dataverse but it can't do some things
you want allow you to easily connect
that up with other things so rather than
having to overhaul your entire workflow
which is going to be harder for people
to do an implement allowing them to make
small changes that connect all of those
things up together so that everything is
still together and you can make it open
so I want to follow up on marks question
and actually one of my favorite quotes
from mark and a talk and talk to given
is if you build it researchers will do
whatever the hell they want so on that
theme can you talk about how we reach
out your audience the audience you've
got your products for and sort of as a
follow on to that what happens when
people that you were not advertising to
start using your product using your
services for things you didn't
anticipate and you pivot do you focus on
your core speak a little bit about
reaching out to your audience howdy how
do they discover you and then what
happens when people start using your
product in unexpected ways
ok so i guess with with overleaf for as
it was known right lay tech that was a
very clear community of people that used
latex and so we built up connections in
the end of that communities you could
open late echt m plates and things in
red latex really easily we also do a lot
of work on social media and other sort
of fairly cheap ways of reaching people
so I guess pretty much right at the
start people started using oral a tech
for things that I didn't think they were
going to like one of the first documents
on where they tech was actually a
wedding invitation as far as I know it's
the only one but you know people use it
for everything right so I think
definitely wasting a lot of growth in
the sort of interdisciplinary science is
so if you have computational biologists
working with mathematicians or or
physicists and biologists you know
there's there's sort of an impedance
mismatch between the tools that each
each of these people use and trying to
provide a platform that kind of does the
enough for both of them that they can
both come together and use it is I think
a very powerful idea and one that I'm
quite excited about seeing it with
overleaf now so with publicize this was
actually it's an interesting question
this is was my biggest concern was
starting to publicize I didn't want
anyone just going writing any article in
there it's actually not published
research so with publicize their is
essentially to even be a scientist user
you have to get approved that you have
been an author on a published scientific
paper so that kind of eliminates that
problem a little bit but I think that
what that actually has done is kind of
created a little bit more closed of an
environment and I think that it probably
would be more beneficial to allow a
little bit more freedom not just
published research to be publicized
essentially but yeah that is that's
definitely kind of a concern because
this is you know I'm trying to build
this brand that this is reputable
information so it is extremely important
to make sure that the information that's
posted is legitimate so yes I didn't
address that question so what I the the
best way is actually
listservs in academia those are really
powerful so listservs are really great I
got an article in inside higher ed that
was extremely helpful with the
universities and I've been active on
social media although I'm not very good
at it but but yeah that's been I've been
trying to be as lean as possible
designing our product to be sensible we
want people to use it in unexpected ways
so it's not at all a problem to help
with that the core architecture spill to
be kind of a visual programming language
and the it will be will have api's
export import as many possible ways to
end up using it in unexpected ways and
for reaching people part of reaching
people is to create a tool that is so
extensible that people just have fun
with it and share it with each other but
shareability in the core architecture is
critical so the design files are
essentially documents that can be
collaborative like Google Docs or shared
as a flat file export which everybody
wants by remarketing that's not so easy
to achieve so we hope to achieve some
level of that but we don't expect it to
sell itself so it will be marketing
components as well so I can't really
speak for how github again that was sort
of 2007 I know we did a lot of work to
get call communities on the platen so
you know we you know getting high
profile open source projects onto github
was very very significant in its early
days I think that's a transferable thing
bringing a community along I think so
thinking about kind of people who are
significant kind of in a particular
network of academia and getting them
onto your platform using your tools
would be a good strategy so but it's a
speed to sort of how people are using
github that I've seen the weirdest stuff
in the last year there's libraries who
have upload
a hundred thousand bucks to get hub who
unless they're all open source don't pay
a single dollar Jeff was saying
something about having your revenue
model aligned with your your mission
maybe I'm paraphrasing like you know our
mission we you know we people pay for
privacy on github people as people don't
realize how we make money we make money
for on those repositories that people
choose to not make open source so if you
come along and upload 200,000
repositories tomorrow in an open-source
fashion we won't charge you a single
then and so I've seen our libraries
upload huge amounts of data that's
actually tested infrastructure at times
I've seen academics shard genome
sequences and put them in repositories
again like things but usually usually
expect the unexpected I think that
happens a lot and so that isn't
necessarily affected how we present the
product but it does affect sometimes it
affects technology decisions about the
way that you go forward like academics
are being amongst the most sort of
abusive of our platform in the nicest
possible way so I would actually say in
terms of outreach we're not actually
very good at it at sonora and as an
international organization as well it's
definitely something we hope to warm up
what we do is that we we do try to
spread the word to a lot of people that
can multiply it we do engage when people
then come to come to us we do engage
heavily in them and make sure that they
are happy with what with the features so
that they can spread the word and in
terms of unexpected uses I think a lot
of the use we have I've completely in
live with what's in all of us I think
the most unusual ones are the people who
say hey can I say install a copy of
sonoda at my local institution and in
those respects I think it goes up a
little bit against this infrastructure
principle that Jeffrey was was talking
about as well but we're happy to help
them actually for coughs a note of which
fork of the underlying software menu and
actually help them build up their own
data repository network yeah enough USF
you know we purposely build it to be
very flexible you
blow to whatever you want to it I
haven't seen anything too bizarre yet
I'm sure at some point somebody will
start uploading cat pictures because
it's the internet and cats are
everywhere but you know that's it's
really fine with us we built it or
scientist so those are our audience and
we do try and you know always check in
with them and say hey how is this
working for you what can we do better
but it is open and free to everybody so
if you want to upload pictures of cats
you're welcome to do that and in terms
of restoring our audience we've started
doing a lot of outreach so going around
to universities interacting with grad
students postdocs researchers doing
training events about you know open and
reproducible practices some of which are
just about general workflow some of it's
about you know how to integrate the OSF
practically and to what they do and we
also in terms of outreach are always
looking around to see hey are there
people out there who are kind of doing
similar things to what we're doing or
thinking I'm starting similar things and
maybe they don't have a home for it yet
can we find a way to collaborate with
them on their project to help grow both
projects yeah oh sorry much more
questions okay oh I was just wanting to
put so we heard a little bit about some
of some sort of relationship that's some
of these have with libraries so it seems
like you know they love its product to
end user and user being the researcher
but where do you see libraries spitting
in here it all and just wondering lots
or any relationship see what that was
flattery's do you mean physical
libraries so first we work with a text
digital library and we work with a lot
of supposed non non traditional larger
so you know we we see a lot of people
that they come to us and say hey I have
you know I
you know five or six petabytes of data
that I need to offload the reference
connect their reference collections
there there are archived manuscripts
there every book that's been you know
written electronic theses dissertations
all that stuff right so we kind of need
to we've been working with them trying
to figure out as part of a larger data
initiative of how we can keep that stuff
available for for long periods of time
in in dark storage how we can keep it
available in in terms of the metadata
and discovery and what search means in
in context like that so I've been
involved with the National Digital
stewardship allowance for a while in my
previous role and still sometimes this
now um I guess my main relationship or
get main relationship is probably
through personal connections with people
like preserved in here in Hobbiton and
Lars no do I mean I worry about the fact
that you can go to get haven't delete
all your stuff this does happen by
accident usually when people are trying
to turn off email notifications and
somebody made them an admin by mistake
and they just delete their whole
company's profile and lucky we can get
that back for you really easily if you
do that but it's a real problem
especially for archiving of I think
software especially there's a longevity
thing that actually isn't kind of built
into what we do so more formal than that
not really but conversations happening
for sure so I would actually say that
libraries are one of our end users we've
been working ever live with with Chris
at mother at Harvard CFA for instance we
also have a lot of smaller libraries
that are interested in using sonoda as a
platform and I see that it's actually
the the bigger libraries that are not
really interested in using external
platforms where all the smaller ones see
the benefit of not having to run their
own infrastructure anymore when we rely
on a common place um for us we're not
really targeting libraries but we are
trying to integrate with publishers and
some of the new generation of publishers
fig share or or factory 1000 that
our publishing figures methods research
objects and so our protocols and
processes would be able to get a digital
object identifier and then one kick
click publishing of a complete
experimental record including what you
did and all the data associated with it
in a in a Mynah bowei so that ultimately
will make it to a library but not
directly sure I guess that overly if we
kind of work with libraries in two ways
first I know some libraries have taken a
sort of leading role in procuring
software for researchers to use and sort
of a research informations perspective
so we sometimes deal with them to sell
both licenses of over they for to look
at sort of trials and things like that
and then second I know we're working
with some universities to handle thesis
submissions that go through the
library's so on over leave it's quite
easy to make sort of templated documents
so if you have a standard thesis
template and you get all your students
writing their thesis on of relief then
everything comes in in the right format
and that's been of interest to number of
libraries and for publicise I haven't
really made any strong effort to work
with libraries but I would like to I
think libraries are a really good
resource especially to connect with the
researchers at the universities I plan
to implement the DOI so each one of
these lay articles can be actually cited
by the UI ultimately my big vision is to
have kind of like a mouse-over effect or
something on a title where you can see
the title in its full form but then kind
of mouse over and then see the late
title I think that would be the most
efficient for anyone so that's kind of
the ultimate goal and it's going to be a
long road to get there and at the center
Brooklyn science we kind of work with
libraries in two different ways because
libraries at many institutions are the
ones who do a lot of work and training
and outreach on data management and data
curation for the researchers at that
institution we generally talk to
libraries about how we can support them
in the training of those practices and
you know the new tools that are out
there unavailable to research
and we're also working on the share
notification system with the ARL the
American research librarians yeah I'm
terrible thank you I'm terrible with
acronyms it's really bad oh so the share
notification system which is a system
whereby universities and institutions
can get notifications and researchers at
those universities publish articles and
the code and data sets that are open to
the university can better track what is
being put out there by the researchers
who are working with them yes sorry
really odd I was struck by mr. Smith
what you said the end of your
presentation about reproducibility being
a workflow and workflow um cultural and
not a technology problem and that really
resonated with me so as interested to
hear any more discussion or commentary
that the panel wants to have on that I
can comment further I mean it ah yeah so
we touched a bid on it already i mean my
my my i'm i'm always kind of skeptical
of reproducibility as a goal in itself I
think it's obviously you can't argue
against it but at the same time it's I
think we should be reaching for there
like let me star get there are so many
people when I go and talk on a campus
about github who have no idea what
version control is there were a very
very long way away I think from kind of
executable papers and turnkey kind of
kind of research packages that can just
be shared and forward and whatever and I
think I would love to see us there but I
think we're often I would like to see us
focus more on some of the kind of
earlier steps towards that goal and I
think if you use tools like a lot of us
develop and work on then reproducibility
is a kind of a byproduct of using better
tools and I don't so yeah that's my so I
I'm slightly I am nervous and skeptical
about lots of resources going into
platforms that solve this wonderful
problem that we all understand because i
think it mrs. i think we end up focusing
on
reproducibility goals / kind of product
goals which can be making great tools
that people enjoy using and so if you
can do them both then great but most of
these project projects are run on
relatively small budgets and I think the
amount of money that you would need to
do it well it's in all so anyway I've
told you I was going to shoot myself in
the foot by I fundamentally agree right
so reproducibility is a byproduct of
good research all right so we we build
it into a gob a platform because we got
really tired of watching tens honestly
hundreds of millions of dollars go into
reinventing the wheel in academic
software over and over and over and
people not fundamentally understanding
the difference that research software is
different than commercial software and
the effort it takes to go from one to
the other is more than the effort it
take to come up with a research software
so we bake it in right I think it's
sometimes confusing when we start
talking in this context that we we
forget that there are a lot of different
kinds of users all right so the the
target audience for for our platform are
developers people that are actually
building tools right you know see very
often a n scientists come in and say oh
you know i love what agave did for me i
love you know did this man i really like
the API ooh hypermedia yay they just
they don't value those kind of things
what they value is hey I i was using
this app the other day and I was able to
share this you know three petabyte data
set right with a single click I can get
a URL for anything and I don't have to
authenticate again right I can share
anything from anywhere right I could
publish my paper I have a DOI for this
whole experiment when people went to
review my work they could rerun the
entire the entire thing end and
invalidate the output that I got that's
what they get excited about right but
those are different end users and you
kind of got to keep those in mind and I
don't I think that there is value in
building these platforms and I am in my
humble but accurate opinion there's
Paris value in building these platforms
because they're really stinking hard to
do and
people aren't going to pull them off and
as our keynote pointed out we've tried
it over and over and over and over again
and when you when you try to get it and
infrastructure is a byproduct of
research you're you're sure you're
you're aiming at nothing and hitting it
every time right because what you need
is infrastructure you don't need
research so I think that you need to buy
into that and you need to invest in the
infrastructure so that the
reproducibility is just taken for
granted right that it just be it's just
something that's there just like when I
look I'm going to hand off the mic but
when when I open my laptop in here I
started getting flooded with
notifications because I've been in four
time zones in two days right so
microsoft online thinks that my account
got hacked because I'm you know I'm
logging in from all these different
places in a short period of time
security is a byproduct of using that
platform right I think reproducibility
should be as well yeah that's a very
interesting anecdote actually and I was
also gonna do an anecdote so I don't
disagree with with any of this but I
think it's maybe a little bit a little
bit negative like I think we've got such
a long way to go between from where we
are now to like perfect reproducibility
that there's a lot of progress that we
could make so like for example when I
was an undergraduate I was assigned a
task to implement an algorithm for
variational notions segmentation or
something and this this was described
over the course of like three or four
papers in hard to find journals and the
key bit of it was actually in like an
unpublished technical report in Japanese
that I had to go and like dig up from
library inter loan services so like
that's that's kind of where we are now
with reproducible research I think that
using tools like github or any of the
tools we talked about today would
already be such a huge improvement on
that that I think there's a long way to
go we shouldn't be should be too
negative about things that we can do to
improve reducibility I agree completely
with the statement about research
reproducibility essentially it's a
problem of the workflow but but I guess
from the publicized perspective I look
at reproducibility from a different
perspective in that I think a lot of
research
is being reproduced unnecessarily and
because there's a lack of communication
between fields so from my perspective
actually I want to reduce the
reproducibility of research and
replication yeah or reproducing so yeah
so essentially i think that it would be
very useful if we can get all of these
research projects in terms that other
people can understand so that we can see
what has actually happened in different
in different fields because there's a
lot of overlap especially with methods
and algorithms between all these fields
as especially as we keep advancing in
computers so i think that yeah i come in
from a very different perspective so
there were there's really two questions
that were being answered the question of
workflow I so wholeheartedly believe and
agree with that that started a company
riffin to make workflow a part of the
process and explicit part of the process
not an afterthought or oh I'm going to
document it as metadata or some sort of
side project so i think workflow is
critical and i think it's critical to
start that at the very beginning as
upstream as you can go in the research
undertaking and that's what we're trying
to do the second question was about
reproducibility and i have to say i
totally disagree with the idea that
reproducibility is a byproduct that's
like saying that airline safety is a
byproduct of running airlines if you
don't focus on safety with a hundred
percent of your effort it will not be
safe we get to experience it as a
byproduct because as users that's not
our our primary objective but the people
who are at that airplane at those
airlines take safety with absolute
seriousness and manufacturers take
quality with absolute focus and until
the rd industry takes quality with
absolute seriousness it will not be
quality and so what we're trying to do
is make it easy at riffin to take
quality seriously not make it a huge
drain on your research
it's on I think I agree with a lot of
that things that have been set here it's
definitely that you have to get the
reproduces reducibility worked into the
tools so that it's really a no-brainer
for a researcher to do the right thing I
think it's about the usability of these
of doing it the right thing that's
important and I think that research
could actually learn quite a lot from
software development eyes when you look
at the lot of the packages and on github
they can actually be downloaded
installed and tested in a fully
automated way most software developers
don't have to think too much they just
have to follow the short guide that is
actually on the front page which is like
three lines of codes they have to do
when if more research tools were like
this then I think you wouldn't have to
think so much about the reproducibility
yeah and I mean I agree with a lot of
what's been said but there are different
types of reproducibility right depending
on what field you're in that word can be
used very differently there's
reproducibility in the sunset if you
take some of these data and the code and
you rerun it you should reproduce the
same numbers but there's also the
question of you know if i take the
methods and the material is used and i
go and do your experiment again will i
actually get the same results and I
think workflow can help with both of
those right if I have really well
documented data and code then it's and I
made that open source it's more likely
that somebody can download that or we
run and get the right numbers and if I
you know provide all my material is
online it's probably more likely that
somebody can at least try to replicate
my experiment because they at least know
what I've done but in terms of you know
replicating the statistical findings if
you redo the whole paper there is a
large component of that that comes down
to really you know having a good
statistical workflow that's something we
didn't talk about a lot but I think that
is something that can be done in an
open-source way but it's something that
really has to start even before
project has been done and so I think it
is having the goal of reproducibility is
important it does often come out of
having goals of openness and
transparency and a well-documented
workflow but I think it's important to
keep both in mind ok so I'm William gun
with a min delay and it's been really
interesting but I know we're coming up
to the through the end so i'll try to be
precise it seems to be a lot what you
guys are talking about is your things
that are on the top of that sort of
Maslow's hierarchy of needs
reproducibility as this ultimate in goal
you know pie in the sky sort of thing
but there's a lot of basic stuff you
know infrastructure is kind of stuff
that needs to be there in order to get
to there so I was kind of inspired by
some of the stuff riffin was saying with
instrumenting the actual lab equipment
you know and getting that stuff in there
so that you don't have variability from
how people record stuff that seems to be
kind of one of those lower down on the
on the pyramid what are some other
things that you know that you guys with
your platforms could do to make the
metadata attached datasets better so
that for example data search works
better our discovery or something works
better so we're pretty late in the in
the research data life cycle of
irrigated will write down at the
publishing process and actually the best
place to start collecting all your meter
data is by using tools that does it for
you so it's already when you start
planning your your your data collection
that you should be wrapping this data
out you should be using tools like for
instance the lab notebooks it's a good
example where you can then go with a
barcode scanner scan and say hey I use
this slice of the mouth spray and I use
this plasmid I use this from this drawer
I think we need to develop the tools
that really support you in doing the
things in the right way and then all the
later stages can actually depend on
although all this metadata this B can be
ingested into the files so I would love
to see people versioning their desktop
or whatever whatever they're working
with whatever file formats they're
working with it any point in time one of
the not sure there's quite answers your
question but one of the differences I
see between software development and
academic collaboration sometimes around
software to is a large astronomy project
is currently looking at moving lots of
their software to get hub and they have
a fundamental difference in the way that
they use for example apart the product
like comments on a line like review
comments a typical comment from a
colleague from on my co to get BB hey
why space fix you know two spaces here
please whatever is like code formatting
sort of problems or sometimes hey
actually that isn't the syntactic style
we like here in this other project
they'll be actually I don't agree with
your version of gravity here and then
they'll have this huge discussion that
actually is crucial in terms of like the
decisions that were made around how the
software was put together or even maybe
how the paper was put together but it's
a fundamentally different type of
discussion that's happening and so um we
don't capture that very well or it isn't
kind of front and center when you go and
check in on the work again in a few
years time so I think I don't know I'm
yeah so I mean I think versioning is
just kind of sensible lots of people
aren't doing it I would love to you know
so I consider a pretty low level
activity but then exposing the decisions
that were made to make a change at ism I
think a harder problem because often
that's kind of hidden away and buried in
weird places so my wife and I hate
making our bed right we have like a
bunch of sheets and comforters and
pillows and stuff you can matter we hate
making our bed and we were we were
traveling back we were looking one of
the SkyMall catalogs and in there there
was this there was this product and it
was it was this set of sheets right that
they they had a lot of flack the top
sheet was like really really huge but it
it buttoned on to the the corners of the
bed
right so you could get in get out you
can move it but your bed never got messy
and we SAT there and we looked like we
just found fire and we were like
Prometheus hello this is awesome right
it was a game changer for us and I think
that when you wouldn't you know we as
tool builders sometimes engage new
audiences that they look at these tools
a lot it in the same way wow I didn't
even know that was possible well I can I
can link stuff and and I like what
you're doing because you you know you oh
it's it's it's another step in the
process of automating the delivery of
software to to an end user right and it
just it takes the people out of the
middle and I think that that's where it
really needs to start is you know what
you want to really minate
reproducibility well you have to
communicate what's been done first and
let people know it's available so I it's
a hard problem but I think we kind of
need to start there just engaging more
and more people yeah that's very
interesting um I'd say again overleaf is
kind of a bit later in the research life
cycle but a lot of people do use it just
as a sort of electronic lab notebook as
a way of just capturing stuff as you're
going forward so it's not automatic but
it is very flexible so I think anything
that just helps you capture things and
version them is a very good step um I
kind of I guess want to repeat what
Arvind said about commenting I think
that that was kind of his main point in
that I think comments are actually
probably encode or basically the details
associated with the decision-making
process of your research that's actually
what's most crucial and and the vast
majority of researchers don't put those
details in the paper because I mean that
would be a horrible paper to read so one
of the big challenges of reproducibility
is actually communicating every single
decision and every single basically
of code that where you made some kind of
decision especially when researchers use
different languages they use different
tools that's a fundamentally difficult
that's a very difficult problem and I
think that better communication is the
key riff on our ultimate vision and
mission is to get to the point where
quality provenance shareability of
research isn't and oh yeah let's do that
after i'm done with my research it
actually is the research it is the way
you do research just the same way that
you would start a mechanical design
process with a computer-aided design
file or architectural project with a
blueprint you would never do that after
the fact you do that as part of the
process and that's what we're trying to
do go upstream so it's not a separate
thing it is the process and and that I
hope will dress at the OSF you know part
of what we do is we try and get journals
to adopt that are open and reproducible
practices because a lot of times
researchers will say you know okay I see
the point but that's one more thing I
have to do but if it's something where
you know the journal says hey we suggest
this or we require this you can get a
lot more movement from people so one of
the things that we suggest and that some
journals are starting to implement our
pre-registrations so you know before you
run an experiment saying what you're
going to do what hypothesis is
statistical analyses you're going to do
and so that thinking about the workflow
and the versioning really does have to
start happening way before like anything
has ever been run but part of that is
just because the community came together
and said we now care about this so like
in cognitive psychology you see a lot
more detail about the computer systems
that are used recorded because people
kind of came together and said wait this
really does matter for a research we
figured out that you know the refresh
rate of the computer is actually
something that is very important for our
research in social psychology you don't
see that detail recorded us as often I
think it's detailed that is really
important but I think
something that the community will have
to at some point come to a realization
about hey these are important details
for us maybe you don't include them in a
paper but they are you logged in version
somewhere CSV files there uh pleasure
excel files but no one but the person
who originally did the experiment can
make head or tails of it when it comes
up someone finds it later yeah as a part
of the training we you is to teach
people about Leah what a code book is
and what a well-curated excel file is so
that you know the the osf is never going
to be one of those really well-curated
and it's never trying to be data
repositories like icpsr where you know
when your data set comes in one guy is
literally assigned to go through your
data set and make it available we kind
of see ourselves as the middle ground
where you know that data is going to
have to live somewhere before it maybe
eventually moves on to repository if it
does ever move on tour posit Ori so you
know we would love for it to be hosted
somewhere where it is login versions and
open hopefully you upload it in hope it
that other people can understand it and
we will help that's through training but
it's not a requirement like it is and
one of those really really well-curated
for posit aureus break for coffee so
she's holding you up there we said this
discussion reminds me a little bit of my
research group meeting last week those
of you don't know me I'm an astronomer
and I do have an astronomy research
group that's my job but anyway um some
students and postdocs we're having this
bizarre conversation where they were
fighting about whether there really is a
workflow and whether you can get a paper
done by having a plan in advance taking
some data doing what you're supposed to
do a published paper go on to the next
one or whether screwing around was more
productive and I always experiment and
so when you said a minute ago there's no
you know you would never do blah blah
blah without a blueprint yes you would
okay and so I think there's a lot of
science that gets done where
we'll take some data for one reason and
I just like mess around with it and then
they mess around some more and they
don't really know in advance you know
what their process is and so it's really
hard in some fields to sort of back that
out and I think that the reason that
these workflow systems get used more in
genomics and fields like that is because
there is more of a process and in labs
there is more of a precedence more
important to have a process but it feels
like astronomy where nobody's life
depends on this there's a lot of messing
around and the most creative results
come from that so I'm not saying that we
should give up but I agree with our fun
that that actual reproducibility is
usually not our goal it's sort of
reusability of what somebody did and so
we have a very different set of
standards and goals and so I'm just
going to say that I know that Jeff told
us that you shouldn't think about
discipline specific things but I do
think that in disciplines where you know
people's lives depend on it there's a
whole different story around
reproducibility then in fields where
they don't each year microsoft research
helps hundreds of influential speakers
from around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>