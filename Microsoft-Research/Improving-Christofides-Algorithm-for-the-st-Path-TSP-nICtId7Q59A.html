<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Improving Christofides' Algorithm for the s-t Path TSP | Coder Coacher - Coaching Coders</title><meta content="Improving Christofides' Algorithm for the s-t Path TSP - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Improving Christofides' Algorithm for the s-t Path TSP</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/nICtId7Q59A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright so we're very delighted to have
him chan and from our lands which going
to tell us about improving the stapedius
is our organization thank you
okay so thank you ah yes it is supposed
to be and to be more forceful with this
rowdy audience okay well thank you I'm
in turn on from Cornell University and
I'm interested in investigating some of
the most fundamental open problems in
approximation algorithms and today i'll
be presenting some recent progress in
the Traveling Salesman problem namely
improving christofias algorithm for the
st path tsp this is joint work with
Bobby Kleinberg individuals the
Traveling Salesman problem is perhaps
the most well-studied problem in
combinatorial optimization and it has
also driven the research of algorithms
for optimization problems in both
theoretical and empirical domains such
as worst-case analysis of approximation
algorithms probabilistic analysis
integer programming and related
theoretical and computational techniques
for example so in fact in this this
particular figure has been the starting
point of the modern integer programming
where 49 cities in the United States are
shown here and this is the shortest way
to visit every city exactly once and
come back to where you started so okay
so I'm going to now formally define what
the Traveling Salesman problem is so
everyone I assume knows what graph is so
given a rayleigh graph we want to find
the minimum Hamiltonian circuit where
that is a circuit that visits every
vertex exactly once and because it is a
circuit come back to where you started
so everyone happy with the definition so
in the metric version of the problem
where we either assume the triangle
inequality or allow multiple visits to
the same vertex these two are equivalent
the problem is known to be np-hard and
crystal feed escape of three halves
approximation algorithm for it so the
three halves approximation algorithm
means it is a polynomial time algorithm
and produces a solution whose cause this
no more
three halves compared to the optimum
even though Chris defeatist gave this
three-halves approximation algorithm in
1976 this approximation ratio still it
remains the best known for the problem
and improving upon this has been one of
the most celebrated problems in
combinatorial optimization we are going
to consider the st patty TSP where the
objective is now instead of finding a
Hamiltonian circuit we want to find the
minimum Hamiltonian path between the two
given endpoints so for example in the
previous example instead of returning to
where it started we need to start from
Boston and end at Washington and we want
to make sure that we visit every city
exactly once so for this problem still
the problem is also known to be np-hard
and Hoffman has shown that Christofias
algorithm when applied to this problem
is the 5s there is approximation
algorithm and that they spawned this
type sorry when I see this ah yes well I
mean was Lee's Boston silly yes it is
worse so that is actually one of the
interesting thing of these variants
because hope fain actually in his paper
showed that depending on how many of the
endpoints are a surface by the
approximation ratios are different when
you apply Chris the Vedas algorithm and
this actually is the only variant where
problem gets more difficult so the other
variants would be you only specified
that you need to start from Boston but
you can end at any cities for example
not a circuit but you started from s
that would be there will be a 3 halves
approximation algorithm that was derived
from Christofias so the main results we
are going to say today is that
Christofias algorithm can be improved
for st path tsp to give a deterministic
the approximation algorithm for an
arbitrary metric where fee is the golden
ratio so I'm going to first make see a
brief review of Chris
the feed is algorithm and because our
algorithm is going to be based on a
linear programming I will show what the
linear program relaxation exists for
these problems and also show on LP based
analysis of Christofias algorithm that
is due to Z then I will show what our
algorithm is and then give progressively
improving analysis so first of all I
will show why our algorithm is another
factor is approximation algorithm and
then shall progress the refinement of
the same analysis yes recently have been
able works that I guess bit Kristeva
this algorithm for other variants of
this problem are you go yes so yes I'm
going to mention them and those results
were actually so following the break the
result of a base currents are very
insane those results were all dealing
with the special case of unit weight
graphical metric case that I'm going to
define very soon the problem also
you
yeah so this current siberian sing dealt
with the circuit tsp so they gave an
improvement over three halves for when
considering the unit weight graph
cometary blumpkins vinson consider both
circuit and path problem and gave an
improvement over three halves and 53
each yeah all four vertical metric the
problem harder but you get better result
than we're known for this heart of mine
but but of course I have to start from
530 now because so the bridge is best
technique for that okay okay so let me
first just remind you how Christofias
algorithm works so in general the input
to the metric TSP is given as paralyzed
distance between nodes but in this
particular example we are going to
assume that the distances are given as
just Euclidean distance on the 2d plane
the algorithm first finds the minimum
spanning tree and our eventual goal will
be finding an Euler in circuit that
includes the spanning tree we're all
learning circuit is a circuit that
visits every edge exactly once now this
famous theorem which was which was also
the beginning point of the graph theory
is that a graph has an Euler in circuit
if and only if the graph is connected
and the degree of every vertex is even
so in that sense these four vertices
that has odd degree can be thought of as
having the wrong parity of degree so we
are going to identify the set of these
vertices and call it t now in order to
fix this wrong parities we are going to
find the minimum T join where T join is
the set of edges under which the set of
odd degree vertices is exactly T so note
that this definition is parametrized in
the sense that T here is a variable so
for example this is a tea joint because
well 40 defined as these four vertices
this is a tea join because
these only these four vertices have odd
degree where is the other vertices all
have either 0 or 2 degree same for this
one or this one and this one in
particular among all the T joins has the
minimum cost are everyone happy with the
definition of teaching because this is
going to be repeated for the entire talk
so the entire set of businesses is a
teacher is a teacher but you want to
find obviously smaller one no so T is a
variable that we defined in the previous
step of the algorithm as you put
negativity resulting to you will be no
movie opt for every vertex in G end even
even for every other vertex yes so it's
a so it has to be exactly p the set of
all degree vertices and it's actually
not in the original graph but it's a
subgraph vijay yes but well that
definition becomes a little bit less
clear because in the metric TSP because
we are assuming triangle inequality we
basically have the complete graph so the
only problem is that some of the edges
may be quite expensive you are all using
solution
like support but intellect there is
nothing very preventing you from using
edge that were not
because those are you think about the
gravity is that so yes well I mean in
this example in general you're going to
a strip one in the one he just showed us
this is a yes are you kidding but you
could define a tee join obviously in the
metric case yeah Wow okay so by taking
the union of the minimum spanning tree
and T join now we can make sure that all
the degrees are even so we can find on
oil in circuit on it and we can do this
in polynomial time even though the
definition of the older in circuit and
the Hamiltonian circuit looks quite
similar both of the learning circuit and
minimum spanning tree can be found very
efficiently but Hamiltonian circuit is
np-hard problem so once you find an
order in circuit we can see that in
general some of the vertices such as the
one in the center here is visited by the
circuit more than once so in order to
obtain a Hamiltonian circuit we are
going to follow these vertices one by
one and when we visit the same vertex
more than once we're just going to go
directly over to the next vertex this
operation is called circling operation
and you obtain a Hamiltonian circuit
using district reading operation and
from the triangle inequality this
operation will not increase the cost of
the circuit so what does this algorithm
become when it is applied to the path
problem a similar theorem says that
there is an sto learning path in the
graph when graph is connected and the
set of odd degree vertices is exactly
SNT so all the other vertices still have
even degree is just SNT that has to have
of an odd degree so that will change the
meaning of the wrong parity here but
that's the only difference of the
algorithm we just identified as these
set of vertices T then find an Euler in
path and then we ensure cut it to obtain
a Hamiltonian path in the same example
where these two vertices are designated
as the endpoints now these four vertices
will have the wrong parity of degree
find the minimum T join we can find the
sto lariam path then
hamiltonian path using this recording
operation its algorithm clear okay so
hawk fan has shown that this is the vice
there is approximation algorithm and
that is bound is tight in order to see
that fact let's consider the so-called
unit weight graphical metric that is the
distance between any two nodes will now
be given as the shortest path length in
this underlying unit weight graph yeah
for this specific algorithm the analysis
is tight okay well obviously because we
claim that there is a better
approximation algorithm so so for
example the distance between this and
that node is going to be too because the
shortest path in this on the line graph
is too so in general given given this
particular input any minimum spanning
tree in the underlying graph will be any
spanning tree in this on the line unit
weight graph will be a minimum spanning
tree and suppose that algorithm has
chosen this particular minimum spanning
tree as the initial tree then this
shaded vertices will become the vertices
with the wrong purity of degree and we
can find the minimum teej rain like this
so the algorithm will produce five
thirds times the number of vertices
minus some constant whereas the optimal
solution was the number of has the cost
of number of vertices minus one you run
through this again okay okay so first of
all the optimal solution has to be just
this thread path so that has to have
caused number of vertices minus some
constant but the algorithm chose this
particular minimum spanning tree as the
initial tree well of course if you're
not familiar with I mean if you're not
happy with the fact that the algorithm
chose this one then we can make this the
unique minimum spanning tree by like
giving introducing some perturbation of
course but the bottom line is the
algorithm chose the wrong minimum
spanning tree
it is unique oh so this really is the
underlying graph so i'm using the same
figure for both of the things that is
going to add the join then i guess you
can see that to get to the next today
when step you're going to need to take
like right but let's not add the joint
first let's make sure everybody
understands that the reason he got this
thing it's just the algorithm pick this
minimum spanning tree so when you
analyze it this thing you think it'd
make up think we can the boss spying to
eat that boy doesn't specify which one
yes might as well video yes so and the
last comment that I made was if you're
not happy with that then I can introduce
the perturbation so that this will be
the unique minimum spanning tree but
that's a different story yes by making
those top ones just slightly cheaper
than this is the unique right spanning
tree okay it looks weird of course is a
spanning tree but you're right so I
think that that was what confused a lot
of us okay this is not the one we would
have thought so that's good yeah so this
is a minimum spanning tree and this is a
minimum t going so the algorithm
produces five-thirds optimum of course
minus some constant oh because now when
you just basically think of this plot
you have used to cause five because
these edges didn't exist in the
underlying graph and the shortest path
is length too okay
you have yes right you go for five steps
to give three steps okay so well this is
these are the papers you talked about so
there were very recent improvements very
exciting improvements for the unit
biographical metric case so a vase
garance a berry and singing in their
breakthrough paper gave an improvement
over three halves for the circuit ESP
for the unit weight graphical metric
case Lincoln's Vincent consider both
circuit and path problem and gave
different approximation algorithms using
a very different set of techniques so
our algorithm for the st pat tsp will be
the first improvement of recrystallize
elgar itam for an arbitrary metric o n
in the algorithmic perspective our
algorithm well one of the versions of
our algorithm that you are going to see
in the later part of the talk so you
have an arbitrary graph and then you do
a shortest path weight like on yes for
example that will be the equivalent way
of defining just any match yeah so any
metric is fine because it really is the
same I don't know about the question is
is it just a weighted graph or is the
distance between two vertices the
shortest path distances on this weighted
graph oh I say so the univ a graphical
thing was all of these things and then
what you're considering here is just a
general metric
I mean it just may take a metric space
you can make a complete graph and put
the distance in each end oh and the
shortest path yes okay so in the
algorithmic perspective our algorithm
one of the versions of our algorithms
resembles the the eventual algorithm
database gardens are very interesting
wanted to analyze so in that sense we
are algorithm is in the same spirit as
the result but for any of you who try to
read of a scar on adult paper it was a
real technical tour de force so in fact
one of the nice things about our result
is that the announces are quite simple
so I'm actually hoping today that I can
show practically all the details of the
analysis another reason why this is
interesting is because when you think of
the recent improvements for the unit
weight graphical metric case mumkin
svensson already thought about both
paths and circuit problem and we have
all we have shown that of a scholar and
a does result can also be extended to
the path case even though their
techniques were quite different so given
these successful other patients of both
techniques to the both variants a very
natural question to ask would be whether
our techniques that was used to obtain
this V approximation algorithm can be
also extended to the circuit TSP there
by answering the long-standing of
concussion so linear programming has
been one of the very useful techniques
in the design of approximation
algorithms and that was the case for all
of these recent improvements as well and
in fact even though Christofias
algorithm as we have seen before it's
not directly related to the linear
programming there is a linear
programming based analysis of the same
algorithm due to all Z so this is for
the circuit case the original
Christofias algorithm and our algorithm
will also be based on a linear
programming as well so we will naturally
take a look at the Uzis analysis first
but before we do that we will just
introduce some piece of notations that
I'm going to use throughout the talk so
for a vertex a tes the 12 s denotes the
set of edges in the cut
by S&amp;amp;S compliment for two vectors x and
y defined over the edges x of y denotes
their inner product and for some edge
that F X of F is the sum of X values
defined on the edges in F and finally
the instance vector of F is the zero
vector that indicates whether each edge
is in F or not x and y are just set of
values defined over the edges right
ok so how copy relaxation is a
relaxation for the circuit TSP but let's
first consider the following integer
programming so this integer programming
is the formulation for the instance
vectors of Hamiltonian circuits so
obviously the degree of every vertex has
to be too and when we consider any cut
that is non-trivial there has to be at
least two edges on it because the
circuit has to leave this part of the
cut at least once and then eventually
have to come back at least once so this
will exactly formulate the instance
vectors of Hamiltonian circuits now we
are going to relax this last constraint
to make this a linear program and
because we have only relaxed some of the
constraints now the feasible region is
strictly larger compared to the integer
program so when we consider the optimal
solution to this LP is cost will be no
greater than the cost of the real
optimum so when you analyze our
algorithm if we if we prove that our
algorithm produces a solution whose
cause this no more than rho times the lp
optimum then we have proven that our
algorithm is a row approximation
algorithm one useful observation is that
any feasible solution to this LP when
its scale by n minus 1 over n is in the
spanning tree pollito that is the convex
hull of the instance vectors of spanning
trees and because when you opt when you
optimize a linear function over this
spanning tree polytope without loss of
generality we will get an integral
spanning tree so that means when you
take the minimum spanning tree this
costs will be bounded by the scaled
health care solution which is in turn
bounded by the health care solution
calls itself you're saying if you scale
down
then you know that what you will get is
a condo so venetian trees yes and then
you say that you can always find them
because this is just a feasible point in
the spanning tree pollito but when you
optimize over the polytope you will get
this minimum spanning tree up to someone
say something ok so that's say you're
pulling out one tree from the
no it's just if you wanted a little and
for the few one v12 then you can think
of it in that way as well so just two
different explanation so so there I like
the only the only difference between
that and the linear program for the
spanning trees like the some middies
should be any of the edges you be yes
right it is fine so the proof really
comes from verifying all the constraints
in the admins characterization of
teammate troy but ok so we have a radio
good bound for the minimum spanning tree
but with what we don't have is the bound
for the minimum t join if you want to
analyze the crista fides algorithm so
we're going to take a look of a
polyhedral characterization of T joints
so let's consider this LP relaxation for
any cut that has odd number of vertices
in T on one side from the parity
argument you can see that there has to
be at least one edge that crosses the
cut so this is a LP relaxation and it
turns out that it actually well more or
less exactly characterizes the T joints
so using a very similar argument as
before when we call a feasible solution
to this LP of fractional key doing its
cost will upper bound the cost of the
minimum TJ
so this is a house payment solution
why this cost abounding well so it is a
non-trivial fact so you have to
basically what need to prove is that
this LP is not just the relaxation but
it's actually the dominant of the convex
hull of the instance vectors of T joins
but I was just hiding it because this is
all we are going to use but so this is
basically in the same spirit as what we
used to bound the minimum spanning tree
costs because yes so so this is like
almost integral so when you optimize
over this LP you will obtain an integral
T join and we are just giving a feasible
solution to the LP so its cost has to be
no smaller than the actual optimum for
the LP which is integral rational it'll
be is actually in the gun yes right you
shall not necessarily optimal of course
you can only go down yep okay that
Mozilla suppose we could think of is
equal but okay so you're using something
weaker than is okay so how do we know
yes right optima but that's just the
Edmonds and Johnson's theorem I'm not
going to prove that today but it's not
trivial actually find a DJ oh so
actually okay that is another thing that
I was trying to hide but I have to
confess so increasingly Christofias
algorithm is described as not finding a
minimum t going but you consider the
subgraph induced by T and then find the
minimum perfect matching on it that's
because you can actually without loss of
generality say that the minimum T join
when the triangle inequality holds
because it's a metric to SP problem
these are just the perfect matching in
the induced sub graph so what you really
do in the actual implementation of the
algorithm would be considered the
subgraph induced by t run Edmonds
algorithm for example to find the
minimum perfect matching
there is a way that we know that perfect
matchings always have half it is a
solution but if all in louisa even their
august integer solution so is that such
as the same see are you asking about the
cardinality of tea or but I just I
happen to know that he's trying it
related to something he already knows
instead of something that some other
classical result but it's not a lot that
college well this is perfect matches are
integer but anyhow it's probably it's
probably similar similarly not hard
let's go on so why are using teacher
I'll just call it perfect match it
though well because I was basically
using this this observation so this
doesn't really hold for matching so if I
decided to choose more details in my
talk then I could have actually used
them in matching as well but ok so now
we are ready to see the now you're ready
to see all this true ok ok so the we
have already seen the cost of the
minimum spanning tree is bounded by the
lp optimum and I claim that half the how
card solution is a fractional to join
that can be seen from this LP
formulation so T join LP says that for
any cut that is odd with respect to T
there has to be at least one edge on the
cut where is the hub solution just
simply say that for all the cuts there
has to be at least two edges so if you
take any feasible solution to this LP
scale it by one half it has to be
feasible for this LP so this means the
cost of the minimum T joint is bounded
by the cost of the half the health care
solution so the cost of the Hamiltonian
circuit which is bounded in turn by the
minimum spanning tree and the minimum TJ
is bounded three halves LP optimum which
is bounded by three halves the actual
optimum so this is aloose is proof that
Christopher disease or three halves
approximation algorithm
so given that we are going to use these
LP formulations it makes sense to see
how strong these LP relaxation czar in
particular into a little gap as defined
by the worst-case ratio of the integral
optimum and fractional optimum for the
health care bill extension the lower
bound is known to be four thirds and
there is an upper bound established by
this losses analysis three halves and is
actually conjectured to be four thirds
I'm going to soon introduce a path
variant of health care bill extension
and the lower bound known for this
relaxation is three halves and our
analysis will establish the upper bound
of the golden ratio and given the
conjecture in the circuit case it will
be natural question to ask whether it
actually is just three half the distance
lady me like if the health valve
relaxation is for parents does it also
then basically you get it over the
approximation algorithm so what it means
is that if you are going to analyze our
algorithm purely in comparison to the lp
optimum then we cannot hope anything
better than four thirds because there
really is an example where LP does
better than I p by the factor of four
thirds the best you can do using an LP
yes in the sense well not always because
there are results that still uses the LP
but somehow introduces the optimal
solution back there for like beat the
interval interval T gap but in general
that's the case so for that health care
bill excision and then i'm going to
introduce the pathway in healthcare
relaxation if the conjecture is too
and it's for food so mathematically
there really is nothing preventing us
from achieving something better than
four thirds the only better the only
best known complexity inapproximability
result is something like half percent so
positive value
just doesn't mean as you found it too
okay okay value is a great position and
second value will is so you'll have a
four fellows approximation factor which
is not know but usually when it's proved
it's actually exactly where does he find
it so probably okay so so that there is
a construction that shows the lower
bounds so this is the LP relaxation that
you're going to use in our algorithm
this is basically the same as the
previous relaxation but obviously the
degree bound has to change for ad two
end points so that now their degree is 1
and for the cut capacities for the type
of cuts that is on this left side that
separates smt you can all you can only
say that there has to be at this one
edge but you can now say that there has
to be two edges because basically the
path doesn't have to come back so for
these cuts that i'm going to call st
cuts the lower bound we have is now as
small as one but for the other type of
cuts that does not separate SNT we can
still say that there has to be at least
two edges on it so the rest of the
constraint will look like this this is
another LP relaxation now for the
Hamiltonian paths this can be solved in
polynomial time and the visible region
of this LP is again contained in the
spanning tree pollito this time without
the scaling so that means given a
pathway and he'll curve solution we can
write it as a convex combination of
instance vectors of spanning trees and
we can in particular find such a
decomposition in polynomial time for
example using the results of grocery
lavas inscriber and that as a corollary
of that there will be only a
polynomially many of those spanning
trees that contribute to this particular
convex combination so our algorithm will
be simply trying each of these spanning
trees that is given as the convex
combination so here's our algorithm that
i'm going to call best of many
christofias algorithm the rest of the
algorithm is basically the same the only
difference is in
stead of using the minimum spanning tree
we are going to solve the pathway and
he'll capitalisation first rewrite it as
a convex combination of spanning trees
and try each of them well then it just
goes through and it output city of
translation that's it yeah t will be
empty the optimal is integral in this
case then it's actually yeah it was just
give out that and that that's it but
clarify why like leave the previous
example
so they even if it was a unique best
pint we like you're not going to use the
best that it doesn't need to only to use
the best planet win in the convex
combination of this beam right yes so
but for the notational convenience we
are actually going to analyze a
randomized algorithm which we call
sampling crystal videos the only
difference from best of many is now
instead of trying each of these spanning
trees we are going to choose one of them
using the probability given by the
convex combination coefficients now
obviously if you can show that the
expected performance of this algorithm
is Roy approximation then we can show
that this algorithm the deterministic
algorithm that we have already seen is
order approximation algorithm and the
marginal probability that on edge is
included in the sample spanning tree is
exactly equal to the help of solution
value that's because we have used the
convex combination coefficients here an
implication of that is the expected cost
of the sample spanning tree is exactly
equal to the hell crab optimum so now we
can focus on in the rest of our analysis
bounding the cost of the minimum t-joint
so the rest of the analysis will look
like something like this we have already
good bound on the cost of the sample
spanning tree you're going to bound the
cost of the minimum T going by something
times the health care solution then we
will obtain the proof that is one plus
star so as I have promised I'm going to
first show that why this is another
factor is approximation in order to do
that I'm just going to exhibit a
construction of a fractional to join
who's expected cost is no more than
two-thirds times the hell crap optimum
so for the moment let's go back to the
circuit case and consider the very well
known to approximation algorithm that
starts with the minimum spanning tree
duplicate all the edges and then obtain
a larian circuit on yet this algorithm
can be thought of as using the minimum
spanning tree itself as fractional TV
and we have already seen that kristef
Edie's algorithm uses half the health
care solution as a fractional T joint so
given these televisions it is
natural to consider whether the spanning
tree or your health club solution can be
used in our case as well to construct a
fractional to join so let's first ask if
the hacker solution scaled by some
constant better is a fractional TJ if
there were no esta cuz then the life
would have been simple we can just
follow the aussies analysis show that
half the health care solution is a
fractional t doing that's it but the
problem is now there are stickers of
course whose capacity is as small as one
so all we can do is now we can show that
the on scaled version is a helper
fractional T joint but we wouldn't be
able to do the same for any smaller
value better so this table actually
summarizes the observation so these cuts
were not a problem they already had the
capacity lower bound this to the problem
was the st cuts with capacity can be as
low as one so how about the spanning
trees so one nice thing about the
fractional teacher in LP is that it only
constrains the cut that is odd with
respect to T so we don't need to worry
about the other st cuts if they are not
out with respect to T and based on this
observation I claim that as T cults do
have some slack in this case that is
because as fist lemma says if an SD card
is odd with respect to T therefore it
exists in the fractional to join LP then
there has to be at least two three edges
on it so here's the proof this is from
the parity argument so you contains as
as given in the lemma contains odd
number of vertices in T and it has to
contain exactly one of the two end
points so that will sort of flip the
parity of the number of vertices that is
that has odd degree so for example in
this example there are three number
three vertices in T but it contains s
but s was not in t even though it has
our degree because it's the end point so
that means you has actually even number
of
our degree vertices now when you
consider the number of edges in the cut
it is given by the sum of the degrees on
the side of the cut minus twice the
number of edges within this side of the
cut because we have cognitive edges
exactly twice when you are taking the
sum so everything in this equation is
even so there has to be even number of
tree edges on the cut but on the other
hand there has to be some edge on the
cut because the tree is panning so there
has to be at least two edges on it but
the problem is now for the non
separating cut the parity argument works
the opposite way so again we end up with
the proof that this is another another
proof that this is two approximation
algorithm but now these are
complementary to each other's that we
are going to take a linear combination
of them so in particular if we take both
alpha and beta equal to one thurs this
gives a proof that this algorithm is
another five there is approximation
algorithm and actually if you verify
carefully then this analysis also works
for the original path train Christofias
algorithm as well and it is something
interesting because original hoffman's
analysis compared the output of the
algorithm to the interval optimum so it
didn't have any implication on the
interval t gap of health care bill
excision but now this gives the first
proof that the interval t gap of the
pattern health care relaxation is
something no more than five thirds no he
didn't
okay now we need to get some improvement
over five thirds so we are going to
perturb I'll find better a little bit in
particular we are going to decrease
alpha by 2 epsilon and increase better
by epsilon and we are going to actually
choose later alpha equals point three
and better equals point three five this
will decrease the expected cost of the
perturb linear combination by epsilon
times the health care solution but of
course all of these things comes at the
expense of potentially violating some of
the cuts that is not violated in the
fractional t1 LP but note that alpha
plus 2 beta was unchanged because the
particular way we introduce the
perturbation so not separating codes
will never be violated even after
perturbation it is only the st cuts that
may be violated and even if they are
violated because we have made a small
perturbation we still have a pretty good
lower bound on their capacity in the
fracture perturb linear combination so
even if they're violated they will be
violated by at most point zero five and
you're going to call this maximum
deficiency d now if an SD card had a
large capacity in the helper solution I
claimed their slave that is because this
bound was basically obtained assuming
that the capacity in the help of
solution was as low as one but if the
capacity was something already large
enough then you do be enough to survive
the small perturbation everyone happy
with that ok so this definition actually
captures that intuition so a town narrow
cut is defined as an SD card whose
capacity is smaller than 1 plus tau
where the threshold tau is going to be
chosen so that exactly 1 plus how is the
threshold where an SD card has large
enough capacity to survive the
perturbation and in our particular
choice of parameters how is going to be
one seventh ok
now let's consider the other extreme so
what if st cult had the smallest
possible capacity namely one and i claim
they are safe as well that is because an
SD card that has capacity exactly one
will never be odd with respect to T
therefore will never even exist in this
fractional teacher in LP proof is quite
simple so the expected number of three
edges in the cut is exactly equal to the
help absolution capacity from the
previous observation that the marginal
edge probability was equal to the hell
curve solution value everyone buying
that so the expected number of three
edges on the cut is one but on the other
hand there always has to be one tree
edge on the code so that the tree can be
spinning so the number of tree edges on
the code will identically be one but on
the other hand we have already proven
that if the cut is odd with respect to T
then there has to be at these two edges
on it so they will never be odd with
respect to T so they're safe in general
for any power narrow cut the probability
that they will they may be potentially
violated because they exist in the
fractional t1 LP is bounded by power
proof is very similar there has to be at
least 13 edge on it so that the tree can
be spanning if it is art and there has
to be another tree edge but the expected
number of three edges is smaller than 1
plus tau so the probability cannot be
something greater than Tom everyone
happy with so far or ok so these are the
observations we have made so far non
separating cuts and st cuz with high
capacities are safe we don't need to be
worried about them the only cuz we need
to be worried about is how narrow cuts
but even if they're violated their
maximum deficiency will be bounded by d
and the probability that they may be
violated is bounded by tau so suppose
for the moment even though this is not
going to be true that the edge sets of
town error codes were disjoint
and then for each tile narrow cut we are
going to define correction vector F sub
you as defined as the health care
solution restricted to the cut and all
the other edges have value zero now I'm
going to take the perturb linear
combination here and try to fix each of
the violated cut so for all the cut they
may potentially be violated if they
actually exist in the hub fractional key
join LP I'm going to take the correction
vector corresponding to the cult whose
capacity has to be at least one from the
health care bill excision scale it by
the maximum deficiency possible and add
it to the perturbed linear combination
so this has to be feasible fractional to
join
everyone buying that we're just being
confused too so sorry oh because so far
nothing prevents the feasibility is only
about bounding the expected cost so now
I'm going to use the assumption so when
you think of the expected cost of this
last correctional term each of the
correction vector was used with
probability at most ow and they were
used with the scaling by D and the sum
of the cost of these correction vectors
is bounded by the cost of the entire
health care solution because exactly
they were disjoint so if these are
disjoint then we would have obtained the
1 plus alpha + beta + v power
approximation algorithm if tall narrow
cuts were disjoint ok but that's not the
case but I claim that they are almost
disjoint and here is the key lemma
improving that so town area codes will
do not cross that means for any power
narrow cuts if to donate un WR to town
error codes with the s on you NW then
one of them has to be the subset of the
other that means tall narrow cuts will
constitute a nested structure this
follows from some sort of standard non
crossing uncrossing lemma but I'm going
to skip it given that I'm running out of
time so as a corollary of that now we
can obtain a partition of the entire
vertex set that looks like this so here
the helper solution on the health care
solution is shown the actual numbers are
not of course important the first layer
will be the singleton ave s the last
layer of singleton t when we take the
union of any frisk a contiguous layers
this will be of how narrow cut and these
are all the power narrow cuts that exist
in the helper solution we can find such
a partition from the previous lemma
okay now i'm going to take a
representative edge set for each town
arrow cut so that if each edge will
represent at most one cut in particular
for example for this town arrow cut i'm
going to take the representative edges
as all the edges that leaves from the
immediately preceding layer and ends at
any of the following layers so for
example this edge is even though it is
in the pound arrow cut it is not chosen
as the representative because it doesn't
leave from the immediately preceding
layer now from the construction we can
see that these representatives are
disjoint and the representatives are
chosen as the subset of the edges in the
cut and then claimed that they have
large capacity as well so this is what I
mean by they are almost disjoint so
here's the lemma that bounds the
capacity of the representative edge sets
you can throw away only a small fraction
of edges in the air
no large fraction of them and then they
are destroyed so for each town arrow cut
we have sufficiently large
representative edge set so that these
representatives are disjoint to each
other sorry okay no I'm not throwing
away any of the edges because every Edge
has to be contained in any of the
tornado cut but okay so this is a panel
so consider this town arrow cut then the
rapid total representative it's the
capacity will be corresponding B which
is defined as the aggregated capacity of
all the edges that leaves from the
iplayer and ends at any of the following
layers right let a be the total capacity
of the edges that leaves from the any of
the preceding layers and ends at the ice
layer CB row total capacity of the edges
that basically skips over the ID layer
then we can see that B plus a has to be
at least 2 because this aight layer does
not contain either S or T so this is a
non separating cut from the health care
bill extinction the cut capacity which
is equal to a plus B has to be at least
2 B plus C has to be at least one
because this is an SD card again from
the hell capitalization a plus C cannot
be greater than 1 plus tau because this
is a tall narrow cut this all together
we get a bound that B is at least 1
minus 2 over 2 so here are the
observations we have made so far again
tall narrow cuts are the only cuz that
we ever need to be worried about and
even if they are violated they will be
violated at most by D and then the
probability that they're violated is at
most ow and for each of these tall
narrow cuts we can choose representative
edge set that has quite a large capacity
so we are going to redefine the
correction vector now restricted to the
representative edge that instead of the
entire cut and then our construction of
the fractional t joiner be slight
different so that we can take the
correction vector normalizes capacity by
dividing it by the lower bound we have
proven then the rest of the construction
is the same this will show that our
algorithm is 1 plus alpha plus beta plus
B tau over 1 minus however two
approximation algorithm and this is 1.6
577 jail or not this I've it was if you
instead you hear of 1 minus tau over to
you had 1-5 tau it wouldn't matter what
do you mean by I'm still beat my thirds
right oh so well if you're asking about
why this parameter should work out then
the reason is because the maximum
efficiency is in the order of epsilon
where the epsilon is the amount of
perturbation we have introduced the
maximum probabilities is also order
epsilon it's about epsilon square yes so
exactly the correction term is about
order of epsilon skirt cost that you are
incurring in addition to the perturbed
linear combination but we are earning
order epsilon here so there has to be
some epsilon value that works out so
yeah so in particular if it wasn't if
you didn't prove 1 minus tau over to but
you proved half you could still be fine
yes right sometimes you're going to
explain to us why d equals point 05
because you just pull that out of the
air oh so well way back there
well it is just given as well minus 12 4
plus better and because the omentum what
did you optimize at some point later did
you optimize to find the right oh oh I
see no so this is almost optimal but it
is actually not quite optimal because
this is anyway not going to be the last
theorem that I'm going to prove this is
just to show that it works out so alpha
and beta is some nice value rather than
yes okay so okay so we can observe that
in the previous analysis the maximum
deficiency and the maximum probability
was separately bounded but that didn't
have to be the case because the maximum
efficiency is achieved when the cut has
the smallest capacity where is the
maximum probability is achieved when the
cartels largest capacity so we can write
them as a function of the capacity and
simultaneous optimize them and also
given that we are doing this anyway we
can rewrite the lower bound of the
representative answer capacities in
terms of the cut capacity then we obtain
a 9 minus square root of 33 over two
approximation algorithm now you know to
push this tour is the golden ratio we
need to add a small piece of extra idea
to the analysis so what are the key
properties of the correction vectors we
used in the previous analysis first of
all we have used that they are
non-negative because when we add try to
correct some of the violated cuts we
didn't want to violate the cuts that was
already safe and in basically in this
last inequality we have used the fact
that some of the correction vectors is
bounded by the health care solution
that's the second property and then we
had a nice lower bound on the capacities
of Representative headsets or correction
vectors so where do you actually use the
disjoint nice of Representative edge
stats it wasn't used only to enforce the
second property but we didn't have to
enforce the second property directly
especially because as a side effect this
Jonas also enforces a single edge to be
used
I only at most one correction vector
which was not a useful property in our
analysis anyway so we are going to
ensure the second property directly we
are going to call this fractional
disjoin it and this lemma claims that by
relaxing the disjoint is into a
fractional disjoint ish we cannot prove
a bit improve lower bound on the
capacities of correction vectors which
is now one all of these constraints are
linear so the existence proof has to be
something that follows from the LP
duality theorem and it actually turns
out that there is an auxiliary full
network but I'm now going to have the
time to talk about this obviously so
just believe me it works out so this
gives the final theorem that best of
mini christofias algorithm is a golden
ratio approximation algorithm for DST
PAP TSP for an arbitrary metric now let
me discuss some of the possible future
directions from this work so one of the
nice things of this result is that it
seems to work out with d many of the
recent exciting improvements in
different optimization problems so first
of all the unit of a graphical metric
case so even though the tall narrow cuts
or the correction vectors were purely
analytic purposes in the sense that they
were actually not computed by the
algorithm so for that reason we can
actually think of it is conceivable that
if we can come up with a different
construction of these fractional
t-joints it might be very possible to
improve the analysis of the same
algorithm without changing the algorithm
at all but anyway the power narrow cuts
were purely for analytical purposes in
our previous analysis but they are they
can actually be computed in polynomial
time so we give on different algorithm
for the unit weight graphical metric
case that works that makes an
algorithmic use of that power narrow
cuts and when this is run in connection
with the other previous algorithms it
gives the best performance guarantee
known for the problem also another
application is in price collecting a
steep path problem where the problem is
finding a we are given a metric cost and
the vertex price defined on every vertex
now we don't have to find
spanning st pat but in case we determine
not to include any of the vertices our
objective function will be penalized by
the vertex price we have missed for this
problem there has been very reason
exciting improvement and we have shown
that our result our techniques can be
combined with the previous result again
to show an improved performance
guarantee for this problem now one of
the first token question would be
whether the analysis can be improved as
I have pointed out we can think of a
different construction of a fractional
TJ and such an exhibition will already
give an improvement over the algorithm
but the bigger question of course is
whether these techniques that was used
to obtain this fee approximation
algorithm for an arbitrary metric can be
extended to the circuit case to get an
improvement over three halves answering
the long-standing go concussion now the
final open question is the asymmetric
TSP for this problem there is no
constant approximation algorithm is
known this may not be directly related
to the problem but in my thesis I have
also considered the bottleneck
asymmetric TSP and we have gave some we
have given some general framework to
solve the problem where the problem
objective function is now instead of
minimizing the total cost of the
Hamiltonian circuit we want to just
minimize the maximum edge costs and we
have some open question or if you want
to put it that way conjecture that may
be the health card feasibility will play
an important role in unpacking the
bottleneck asymmetric TSP which I can
talk about later if you're interested
but let me finish it here and thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>