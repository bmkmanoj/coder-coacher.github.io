<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Modeling and Inspecting the Question-Asking Process in Educational Dialogues | Coder Coacher - Coaching Coders</title><meta content="Modeling and Inspecting the Question-Asking Process in Educational Dialogues - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Modeling and Inspecting the Question-Asking Process in Educational Dialogues</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QaDypJzrdzg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so hi everyone I am really happy and to
have Lee Becker here for forgiving as
you know a really interesting talk on
what he's been working on last few years
Lee has a has a really interesting
history so he's been very passionate
about education for I think his whole
life actually spent a year in Indonesia
teaching high school students over there
which I think led to some of his kind of
inspiration to work on this stuff you
know on the technology sphere before
that he actually worked as a software
developer you know at Intel and HP
making various kinds of tools but but
since then you know being at the
University of Colorado he's doing a dual
PhD in CS and CS computer science and
cognitive science for one is it two for
one that's not that and he's been
focusing mostly on looking at how
dialogue can be used in educational
systems and how improving the nature of
dialogue and different kinds of things
in dialogue can actually improve the
educational experience the tutoring
experience so he's going to talk about
some of that work here today and looking
forward to it cool thanks for the
awesome introduction so I won't talk too
much about this i'm mainly going to be
talking about asking questions within
the context of tutorial or educational
dialogues before i get too far into it i
wanted to flesh out a little bit about
my research focus and and i work in a
field that maybe sometimes is called
learning science or sometimes it's
called AI and EDD artificial
intelligence and education and it's
where we try to take all the cool stuff
that's coming out of AI and LP a machine
learning and use it to automate the
process of education or also use it to
help us understand more about education
and like submit said over the past few
years i've been working in something
more specific in the intelligent
tutoring systems domain where this is a
screenshot from our tutoring system
where a student interacts through
dialogue siri-like dialogue and and they
see a floating head who's there Tudor
and various multimedia visuals and what
I really find exciting about having
these kinds of systems and in actually
getting to deploy these systems on real
students is that with
enough of it going to a broad enough
audience we can start to investigate the
phenomenon underlying learning and start
to not only improve how well these
systems how well these systems actually
perform in doing the teaching but
actually tear apart the process and so
with learning gains we can start to
understand maybe what concepts are
important what might eat a student to
that yes aha moment versus a more
frustrated moment and and also start to
learn a bit about the tutoring
strategies that underlie things higher
level overview like I said over the past
few years I've been working in
intelligent tutoring systems and in the
dialogue space and trying to understand
like how can we improve the dialogue or
what do we need to do to really
understand what's going on in it and
tangential to this area it's brought me
into an interest in question generation
and I've been involved in the community
and the workshops related to that and
last summer we have enough coming pay
for Lucy and submit mentored me and we
have a paper on generating automatic
fill-in-the-blank questions or
automatically generating
fill-in-the-blank questions another area
because I do work in NLP and I've been
working this past year on doing relation
discovery and different information
extraction from clinical notes and
trying to drive more towards improving
the the whole process of understanding
what's going on with patients so to give
you a task right away imagine you're a
tutor and you're trying to teach a
student some material in this case we're
going to be talking about basic circuits
pretend the student is maybe in grades 3
through 5 so about eight to eleven years
old and we're going to use this visual
to drive the conversation so you see
there's a battery a light bulb some
wires and a circuit board and this is
actually something that they had played
with previously in class and so as a
tutor your job is to kind of lead them
through a conversation about about this
and amongst other topics and so you have
this history this dialogue history roll
over the D cell in this picture what can
you tell me about this so there's a
tutor the student the student responds
the D cell is the source of power so
tutor says let's talk about wires what's
up with those student why are
able to take energy from the dsl and
attach it to the light bulb now imagine
we were to pause and come in right in
this conversation and you as the tutor
have to pick what's next so if you're
given a list of candidate questions what
what is the next best question or what
is a good appropriate question to ask at
this point in time and so I just want to
take kind of a quiz or poll amongst the
audience and see what what the rest of
you think so we have what about the
light bulb tell me about that component
to you mentioned that the wires attached
the dsl to the light bulb talk to me a
minute abort a bit more about that you
mentioned that the wires attached to the
D cell what parts of the dsl do they
attach to so this is kind of a location
you said that the wires take electricity
to the light bulb how did the wires do
that and so the wires connect the
battery to the light bulb what happens
when all the components are connected
together so quick poll how many for
question one none to got a couple there
three for three about the same for not
that and five so it's kind of split all
over the place and I don't know if
there's a right answer but the human
tutors that I had that that were experts
in this domain and experts in teaching
this picked number five and yeah good
job those you pick number five you too
could be a tutor and so you might wonder
well why is that take a sip of water
what factors are going into that and
what do we actually need to know to to
make this decision and and there's a lot
of things going on under the hood it
might be that the if you pics of certain
things you might be partial to certain
keywords or certain types of vocabulary
maybe if you're like really simple you
just think oh this one has a lot of
words this is good there might be other
factors into if you take into the count
the dialogue history and and look at
what the students doing if we look
through here we see that the student is
pretty good at giving a response they
they ask a question and the student
gives this function right away and and
then the tutor asks another question and
there's good uptake there's good
engagement in response from the student
and so I'm thinking that the rationale
behind why the tutors picked question
number five has to do more with they see
that the student is on this and they
don't want to maybe grind on a single
point but maybe use them the momentum to
carry them forward and so to model this
I think you really need to understand
not just what are the words and what's
going on here at a low level but what is
the actual action taken by the dialogue
above and by the questions that are
being asked so the outline for the rest
of the talk I'm going to give you a bit
of background just briefly about
tutoring and intelligent tutoring
systems and dialogue in these and talk a
little bit about the tutoring system
that we've built over the past few years
as the context for for doing these
explorations into this process of asking
questions and ranking questions I'll
talk to you more about this dialogue
modeling with disgust so discusses a
dialogue act or dialogue move
representation that I've created that
helps us to understand what is going on
under the hood with with the action of
the dialogue and then we'll apply it to
this task of actually ranking questions
in context and then we'll close with
some closing thoughts well of course
we'd close with closing thoughts anyway
onto some background so you might think
oh why do we care about tutoring what's
important about that and and I think
part of it is there are probably a lot
of frustrated students out there and
it's not just education is great rah rah
there's there's actually a problem when
when we look at recent studies they're
like thirty-four percent of fourth
graders and like a fifth of 12th graders
only show proficiency in science which
if you think about like all the jobs we
do we need more than proficiency and if
you look at the advanced level that's
really small um I think there's like
poor proficient like it's kind of Bend
into left of the median median and dry
to the meteor mission-based you're after
advanced I don't believe there is so
this is like this is the top tier this
is like passing and so like and maybe
things have changed in the past three
years and we've radically fixed
education in that time but I'm
speculating that things are probably
about the same
employment about sixty-five percent of
fourth graders are not even proficient
yes exactly is the opposite of late
we'll go yeah not often you get a um
very home companion in these talks but
but there is some hope and there have
been some studies in the past this is an
often-cited study where if we maybe
focus more on being able to tutor and
have this kind of more focused kind of
remediation or most more focused
interaction that we can get as much as a
2 sigma gain and the two sigma gain
means that they may be going up two
letter grades from a sea to an A or
something along those lines so you think
okay tutoring is good but why do we need
machines why do we need a strap a kid
into a room with a computer in like
solve education that way I don't think
maybe alone solving this isn't the key
alone to solving education but it's
definitely a useful tool and I think the
big argument amongst anything else
really for for intelligent tutoring
systems and all of these educational
software and different types of online
learning is that we want to get towards
with what the CRA is calling a teacher
for every student there's a scalability
that we get here that you can't get with
human tutors there aren't enough experts
out there to sit and have one-on-one
conversations with every student in
every classroom and so if you could
imagine bringing it out to like web
scale anyone could learn and do they
have an opportunity to work not just
what they do in classroom but maybe to
address what their problems are and past
studies show that intelligent tutoring
systems are an effective means of
educating students we get the one Sigma
so there's still room for improvement
may be getting up to the mythical tooth
Sigma that we hope to achieve I miss
taste
it's usually a letter grade so so if a
student's getting a C a 1 Sigma would
bring them to a B level of like on their
final test or whatnot and so okay
intelligent tutoring systems that seems
scalable why dialogue why should we care
about doing this why can't we just like
give them a bunch of problems online and
I think the interesting thing that we
get with dialogue that that you don't
get maybe with other modes of
interaction especially with young
children that that aren't able to type
and do things like that yet is you have
an opportunity for self-expression and
and there's what we call the interaction
hypothesis in that getting to interact
and think about what you're saying
reinforces your your understanding in a
more CS or computer science point of
view intelligent tutoring systems is
really a fertile test bed for a lot of
the AI we do yeah Matt you go back a
slide yeah so the idea this is already
exists already given 1 Sigma games there
oh yeah that's what's saying is like at
least for these incarnations when they
tested them on their students and then
they took post-test they saw one sigma
gain with that other reason we don't see
those in my quite deployment I mean once
team is already really good right is
there something else um you actually do
see a lot of these systems in wide
deployment and these aren't necessarily
all to dialogue based systems but
they're often tied to a particular
curriculum or these people like some of
these studies were done on maybe physics
students at this particular University
and so the tutors kind of customized
there is one company Carnegie learning
that has what they call a cognitive
tutor that's not dialogue based but does
math tutoring and that's widely deployed
in like like all of Pittsburgh and
Pennsylvania and all throughout the US
or general system give as good or games
they claim to I need to double-check the
citation on that but I think they they
say that it gives some sort of positive
learning effect so like I was saying
this is this area not only is like feel
good we're helping education it also
lets us investigate the things that we
think are cool and fun to work on I'm
focused more on dialogue and planning
but you imagine there's a lot of issues
with natural language understanding so
not
semantic similarity but is a student
right or wrong and what might they have
backwards and so there's more subtle
problems there I think in terms of like
maybe working towards equipping these
systems you might have a lot to explore
in concept myth and misconception
discovery so knowing like well if I have
a body of text what are the important
concepts or what are they also the
concepts that my people might get
confused or wrong because these things
are often customized I think there's
also incredible opportunities for domain
adaptation can we take a tutor that
we've learned behaviors for in chemistry
and then make a biology tutor or physics
tutor and then after the fact once we
have all of this there's really great
opportunities for educational data
mining to really understand what our
tutors what our students doing right and
wrong what questions might they be
missing what behaviors are useful and
and really tease apart the learning
process so like I said before this is
our tutor or a screenshot from our tutor
and it's called my science tutor missed
and we've been working on it for the
past few years and over in the
right-hand corners Marnie and she's not
too bad in the uncanny valley she still
scares me a little bit but uh students
interact with her they wear headphones
and have a microphone piece and interact
through automatic speech recognition
when it's the full system and the tutor
presents series of multimedia visuals
and also using pre-recorded text or
synthesized text depending on on the
version interact with the students and
give them prompts and try to encourage
self explanation and so the purpose of
this it's not to bring about some
singularity in education it's really to
supplement in class instruction and it's
not that we want to replace teachers but
we want to give students who are maybe
struggling in class other venues that
they can continue to refine their
understanding and the idea is not to
test or assess so it's not just giving
them a bunch of questions and oh they
only got a 50-percent they need to do
more it's really just providing them a
comfortable environment to discuss and
reflect on what they've learned in class
and the educational approach we use is
called questioning the author and it's a
pedagogy created by Becky McCune where
it's originally used for reading
comprehension trying to get the students
to ask well what is the author trying to
say here in this venue we've turned it
into more questioning the science or
questioning the data what is it that
they're observing that tells them what
they understand and the curriculum
driving all this is the full option
science system which is a system widely
deployed throughout California Colorado
and in the rest of us mmm and so you
think okay well people have been working
on dialogue for a long time what's
special about this and if you compare a
tutorial dialogue to maybe a more
standard flavor that's actually deployed
like IVR systems or airline reservation
or hotel reservations you have kind of
inherent differences in the audience and
how you would go about approaching this
with the task oriented dialogue like a
reservation system the user like the
point is to get the user to complete a
task or as in the tutorial dialogue it's
not that the user is trying to get
something done they're trying to both
like it's some students may just want to
survive the 15 minutes that they're
subjected to others may actually want to
do learning and so the point is like
maybe not so much what the user cares
about but this process of bringing about
understanding and so like I said there's
different motivations the person trying
to complete a task has an intrinsic
motivation that says I want to get my
hotel and airline reservations I'm not
going to give up until that's done
whereas the student could easily get
bored or they might really want to go
with it and you kind of have to balance
for both and I would argue that there's
a more concrete measure of success with
with these more straightforward systems
if you got it done in 30 seconds that's
pretty good if you've got the task done
at all that's probably also a good
measure of whether the system is working
you could also do polls of user
satisfaction or decide well we needed to
get human in the loop the system's
obviously not working compare it to the
tutorial dialogue really the the long
goal is probably learning gains if we
even trust those tests to some extent
and then is it do we just do what
they've done before and after the
session is it what they retain over long
term is you just user satisfaction
meaningful even if the students said I
had a great time did they really learn
anything or maybe its coverage
cereal but is that are we covering the
right material and so there's kind of
interesting evaluation going on there
and similarly I would argue that the
penalty for poor behaviors is high in in
the tutoring system whereas poor
behavior because the users motivated
they might be just motivated enough to
continue staying with it I think the big
challenge for intelligent tutoring
systems and you alluded to this earlier
is why aren't these more widely deployed
it has to do a lot with scalability well
and and so that's this middle bullet
here it takes a lot of effort to kind of
curate what knowledge you want to do and
to author dialogues and and to create
all the behaviors for this system and
and right now like it may take a few
weeks for one lesson how are we going to
scale up to an entire text books worth
of lessons let's top bullet you also
need to be robust to a lot of different
users you're going to have people of
varying skill levels of different
motivations and so you're going to have
to be able to be personalized and
adaptive and I also think that that
after the fact there's not really a
clear way to look and compare it
strategies we might see this end goal
but can we really look at what's going
on and be able to tell what's one
session why is one session better than
another and so to give you a flavor of
what might go on in and how here's some
dialogue so here's a tutor and they
asked what do you think the paperclip is
made of to be attracted to the magnet
and the student gives response magnetic
magnetic force attracts the paperclip
tutor think about the kinds of things
that attract two magnets how do you they
connect two paper clips student it's
tracted to the magnet because it's iron
steel so throughout this thing
throughout this dialogue or the snippet
here the tutor really is trying to to
get at this notion of iron or steel and
so this is maybe an easier or less
adversarial there's good uptake in this
point in this conversation the tutor
gives question and the student is pretty
responsive and and the student is kind
of giving them what they want whether
that's good or bad that's still kinda
remains or to be told but um you can see
that there's kind of a good level
engagement here a challenge for other
students is
here's a tutor that asked a question and
the student just says I don't know I
don't understand and I don't know and so
the question is well do you just like
say alright move on or maybe there's
some strategy maybe what this tutor has
to do is they have to keep pushing and
say here's another question and the
students this I don't know and so it's a
matter of maybe backing off for more
open-ended questions to maybe a more
specific question where it's like here
look at this what happened and at this
point the student gets uptake which then
allows us to maybe as a tutor to move
the conversation forward is like now we
have something to talk about here's what
we can do and so maybe even if the
students not giving you the answers you
want there's still something that you
can do to give them a good learning
experience of course there are others
that are just out there and in this case
I think this may be a problem that the
student and tutor and these actually
came from Wizard of Oz experiments where
there's a human in the loop it's not
just the the computer not understanding
this is a human who's struggling with
this problem and so they asked him a
question and the student answers and
then the student had asked him a
question you already asked me that and
then the tutors like well the tutor
really wants him to talk about this
point for some reason and so they ask it
again and soon so yeah I already said
that yeah and so the tutor is like all
right I'm not backing off just answer
and so you might think there's something
going on the hood that differentiates
these and and if we're to make systems
that are robust like this it takes a lot
of work so back to the authoring side of
this most of these systems out there
have what we call a finite state machine
under the hood it's just a graph of
here's what we're trying to ask them
about and if they say this we go down
this path if they say this we go down
this path and it's very manual maybe
they have a good natural language
understanding that they can say well if
we have this much confidence we go down
this path but as you can see as the
lesson expands and the range of possible
things grows it gets to be a lot of work
to really author curate tune and change
these behaviors and so this this kind of
approach is pretty common in a lot of
these different tutors our approach in
mist is
similar when you when you break it apart
but instead of having like a rigid
finite state machine we use the frames
and slots approach which is we have the
information we're trying to fill so in a
hotel domain it might be like time
location etc this is we've broken down a
learning concept into sub parts that
we're trying to entail and these parts
have prompts associated with them that
you would ask the student to you would
continue asking if they didn't say
anything about flow you might continue
down that and we have different rules so
if they get things backwards like in
this case we're trying to get the
student to really understand that
electricity flows from the negative
terminal to the positive terminal if
they have that switched we might have to
say well hey check it out look again do
you think it's really doing that but
like with the other thing they're like
gravity pulls the electricity from
native to our systems pretty dumb and it
just kind of keeps going down and
usually the way it's organized is we'll
ask them a no overview we don't tend to
acknowledge they said anything totally
wrong so it's very easy for a student to
what they do is or what they call game
the system so they could just say yes no
and then just kind of exhaust the system
um we've been fortunate enough that the
students seem to think that this system
smart enough and they don't try to game
it I think if we had middle schoolers
instead of elementary school students
we'd have to put in more robust
mechanisms to say like oh you know the
the speak trade is this faster there
there are other factors going on there
beside so let me spoil this custom Oh
reinforcement learning or something that
that's right we we don't do too much
with we don't do anything with
reinforcement learning there are other
tutoring systems i'll talk about that
try to use the reinforcement learning to
maximize some final gold but this is
kind of the simplest thing that because
we have these very open-ended dialogues
we just kind of go down and exhaust and
then if we exhaust a frame we recap and
say okay it's good enough the student
understands or doesn't understand but
we're going to give them enough to come
away with something and so the broad
research questions that I think that we
get when we look at all this authoring
and these two
your systems is we really need to
understand what are the mechanisms
needed to support may be more
intelligent behavior if we want to have
more responsive and robust dialogue
management or if we want to actually
induce behaviors from corporal what are
we going to need and how can we drive
towards getting more personalized or
more human-like interaction and and and
then if after the fact how could we
possibly do like analysis of these
tutoring sessions afterwards and what
I'm going to argue is that the
representation the underlying linguistic
representation at the dialogue level is
what's going to really be able to enable
us to do more interesting things and so
now i'll talk about modeling dialogue
with discuss and so like much of what we
do in NLP you need a linguistic
representation that you can possibly
learn or or use to to abstract certain
actions so I want something that
abstracts kind of the function or the
the action the function and the content
so the high-level dialogue action what
is going on the function how is it being
spoken about in the content and not like
specifically the words but how is it
that they're talking about the concepts
in a specific domain and kind of the in
searching for a taxonomy I had kind of
these requirements in mind I wanted
something that was interpretive all
without words so if I took away the
words the dialogue could I still look at
the the annotation or the representation
and get it just for okay this is um they
seem to be responding to one another or
this is going down some different paths
and so I wanted something that would
allow post tutorial analysis and I also
wanted it to be useful enough that it
wasn't just like going to be a corpus
linguistics study but allow me to use
them as features for some sort of
behavior or learning some sort of
behavior and and i also had it in mind
that well maybe if we could go to the
next step this representation could
serve as an intermediate representation
to allow fully automatic question
generation so when i'm looking for these
dialogue acts i started on a literature
view of all the different literature or
works related to dialogue acts tutorial
moves and i find that most everything
seems to cover in this course space and
i'll explain a little more
about that and and so they kind of get
at the action at some high level there's
some with the this rhetorical form so
some taxonomy is have a bit about the
function and discount I drew a lot of
inspiration because that's also a
learning oriented one as well as these
question taxonomy 'he's the question
taxonomy is the drawback is there less
focused on dialogue and just on
classifying different types of questions
and so and as I'm going through this I
started thinking well I certainly just
can't use the words and of themselves if
I look at this I don't see the action
but if i use the high-level dialogue
acts the problem is that i can't tell
what's going on if i have to tutoring
sessions it's like question answer
question answer it's like oh that's a
good session i can't do that and so so
my approach to this was to use what I
call discuss the dialogue schema
unifying speech and semantics and it's
kind of a long name but the original
name was distressed and my advisor said
that's too negative come back and do
something else and distress was supposed
to be a response to damsel which is a
famous dialogue act but anyway and so to
drive it what I was saying the action
the function and the content i have
three dimensions the dialogue act
dimension so you do see still ask and
answer but also maybe more tutorial
specific moves things like Revis reev
voice is something used in questioning
the author but could be used in any
variety of tutoring modes where you're
summarizing what the student says to
kind of move the conversation forward
whereas a mark is a similar act but
you're highlighting key word so a revo
would be oh it sounds like you're saying
electricity flows from the negative side
and then ask a question whereas marks
would be more direct would be oh you
said electricity let's talk about that
and so these are kind of grounding acts
that that help the tutor bring show that
they're receptive to what the student is
saying in the middle layer is the
rhetorical form and this is like kind of
refines the the action here when it's
appropriate so it might be a question
that's asking to describe or question
asking define it's like what is the
question really trying to achieve what
is the function of this question and
then getting at the contents the
predicate type
and so it might be that they're talking
about some cause-and-effect relationship
or a function in a process or an
observation and so these these acts were
inspired partially by going through the
dialogues and seeing what we actually
had come up and and also by what I saw
in the literature and so to give you an
idea of how this actually looks here's a
dialogue and well if you just look at
the words it's going to get cumbersome
but let's imagine we just jump straight
to the dialogue act representation we
can kind of just what's going on here
and so at this point number1tutor saying
okay list an entity so what's what do
you see here and the student lists some
entities that that they see in the
visual and then the tutor gives some
sort of positive feedback and then they
describe the entities a little more and
now they're really trying to get them to
talk about what is the function of this
thing you're looking at so it might be a
circuit or a switch or a battery or
something and then the student just
responds with an attribute like
batteries are red or something like that
and so then the tutor oh wait I jumped
ahead so but in the same case the
student just like lists what they see
and they list some attributes so then
the tutor maybe backs off a little bit
and talks about the entities and then
students still talks about at attributes
so then they think okay i'm going to try
function and so you can kind of see
going back and forth is the students
stuck on attributes the tutors moving
forward with functions here um what I
think motivation behind this is if we
look at this across different lesson
domains we can kind of get the same
words different contents so here's a
bunch of different question and answers
and you can see that we don't just have
a single tuple per question it's like it
exhibits different properties in this
case it has a mark as well as ask an
elaborate process but this is for
circuits but now if we change it to
magnets I didn't change the labels but
now we have different different actions
there are different utterances that
actually manifest themselves in the
lesson and so we can kind of start to
see well maybe there are strategies that
are generalizable across both both
domains of course like a representation
alone without data is not any use
so we endeavored to have some linguists
help me out and I hired to linguists and
we annotated 122 transcripts these were
from Wizard of Oz sessions so they
weren't the the actual system this was a
human tutor controlling our system and a
student talking into into the microphone
and then we had manually transcribed
speech for this case and we coded it up
for 10 different units in magnetism
electricity tunes and measurement got
close to six thousand turns annotated
totally in total and fifteen percent of
it was double annotated just to give us
an idea of how difficult this task is
and so the kappa here it shows modest to
fair agreement them you can see that as
we go down the hierarchy it gets harder
and like so dialogue act it's pretty
easy to see this is asking a question or
it's answering question the difficulty
might come in is are they doing a
reverse are they doing a mark what other
things are they doing besides asking a
question and as we go down farther it
gets more ambiguous is this really
asking for a description or definition
where those things might seem a little
close going down to the predicate type
it gets even more ambiguous because well
in some cases it might not be clear
whether they're talking about a process
and observation or a causal relation and
so that's part of the difficulty and for
some of these kappas going down this
were to linguist and so like fifteen
percent of those well it was like
fifteen percent of the dialogues were
selected and yeah this approach how big
can it go in terms of defining the
schema
for example to Tory algebra is it to be
oh it's do you know never have a
specific I think algebra might be a
stretch because you don't have the same
kind of conceptual knowledge but I
imagine for a lot of a lot of types of
science where you do have processes and
observations and things that you see in
class related to these labs I think it
generalizes in that sense and um and
whereas like I think with math you might
need a different vocabulary like axioms
and theorems and and like and the
actions that you would take to solve
step I think it gets this is probably
more useful for conceptual knowledge and
and trying to maybe supplement reading
in some way and so I kind of talked
about these before but these are really
the motivations for discusses I want to
be able to discriminate one utterance
from another and I wanted to explore
like what granularity can I get it like
the speaker intent and what is the
content and and how can I use it for
something useful and and so I'm mainly
talking about learning the decision
making today but I'm also currently
looking at characterizing these
interactions as a whole and so now on to
the task of ranking questions in context
so back to what we did at the beginning
of the lecture or talk or whatnot we
have this picture again and you already
saw these things and and so I want to go
into more detail about how we use Disqus
and other features to actually go about
ranking these questions and so given a
set of candidate questions where do we
go next as a follow-up question and like
I said at the beginning there might be a
lot of factors influencing the tutors
decision you might be you might have
biases or opinions about certain words
and phrasings like oh I really don't
like that kind of vocabulary or that's
really odd syntax for to talk to a third
grade ER and there might also be
preferences about what you talked about
as far as subject matter it's like oh
this is less important let's focus on
this there are factors that come in from
the dialogue context so we have this
history certain things might be more
appropriate and of course even when we
have tutors who are trained in the same
area they may have different pedagogue
Circle philosophy some like might really
be keen on using the visuals as much as
possible some might like more directed
questions versus open-ended questions
and so that could influence and and of
course the student understanding always
plays a role is like is the student not
answering anything or are they getting
it and you might ask different questions
depending on what you get there so the
driving questions as far as ranking and
choosing these follow-up questions or
well I'll get into this in a second but
how might we go about learning this can
we use preference data so after the fact
can we use some sort of ratings and what
features are actually needed so we
talked about those potential factors so
how can we extract that from the words
as well as from a representation and
what can this tell us about tutoring and
about our tutors as we go through this
process so for that I want to talk about
a little bit about related works in
tutorial move and summing dialogue move
selection and so someone asked earlier
about reinforcement learning and there
has been work where they've looked at
trying to optimize tutoring behavior for
learning gains using reinforcement
learning but the the decisions they were
looking at were very miniscule and
didn't really get it what are the full
range of questions you can get at they
achieve was looking at like should I
illicit or should I tell so it's
basically saying should I stay on this
point or should I tell them and move on
and so you you can see where
reinforcement learning would be useful
in that sense but if you start to like
say should I ask him about a definition
or a description should I talk about
this aspect of the learning goal or that
aspect of the learning goal the
state-space explodes pretty large
similarly you would see the similar
behavior with the hmm and and Christy
Boyer did work in in having a dialogue
act taxonomy and trying to predict what
dialogue acts but again she was using
pretty coarse dialogue acts so might be
giving feedback asking and answering and
not really driving it what kinds of
questions are we asking at a specific
point in time this work kind of draws
from the tradition of what's called
sentence planning in the natural
language generation community where the
point is in a dialogue you're trying to
generate a representation which would
you then use to create the surface for
more the actual words and mm the instead
of doing that in my approach
think more of how did the
representations inform the features that
we can then use to rank but you could
imagine I could also ranked
representations at some point so the
approach is pretty pretty not surprising
it's pretty straightforward we're going
to treat question ranking as a
supervised machine learning task which
we means we need training data and
labels and in this case the training
data are going to be given a context a
dialogue history we want a set of
questions and we're going to then
extract features from these questions
and and then we're going to pair them
with some sort of scores whether it's
ranking or raw scores and then we're
going to learn different models I have
what we call a general model where we
average the scores across all Raiders or
average rating rankings across all
Raiders or we have the individual model
where we learn what are the preferences
for an individual and so the data again
we have the 122 transcripts that we use
so we use that corpus for for building
dialogue models but specifically we look
at 205 context extracted from these
transcripts and so set of 30 transcripts
in particular and we had mmm does it say
well what we did was we had manually
authored questions for these contexts as
well as when appropriate we used a
question extracted if it wasn't some
like meta statement or if it seemed like
it was a follow-up question and and then
we took these questions and we annotated
them with the discuss representation and
then we put these questions in the full
dialogue history which I'll show in
front of Raiders so these Raiders are
trained expert tutors that had
previously worked on on the on our
project and then we do that so it means
that I have the original dialogue and so
I pause it and so I take that next turn
out and just use that if it seems like
it's a question and then and then you
might so you might extract one and then
you would author like five other
candidate questions because I didn't
have a good way of like making a like
without writing my own awesome question
generation system from scratch I didn't
have a way of permuting like the
discussed space and dialogues face
it's a little more about the authoring
and the approach i hired a linguist we
hired a lot of linguists in Colorado and
I trained them in questioning the author
and amidst and and in the Foss and the
kinds of questions that we see in the
kind of lessons and I said okay you're
free to write any question but take my
guidelines into consideration and really
think about how might you change the
tactics would you want to add a reverse
at this point would you want to mark
would you ask them to elaborate and like
think about the learning goals do I want
to focus on this aspect of the learning
goal or a different aspect or maybe a
different learning goal entirely and and
then also because it's a linguist you go
ahead and do some variation on lexical
and syntactic structure but mainly take
into account discuss so maybe you might
switch from asking a definition question
about a causal relation to a definition
question about a process or a
description of a process and in kind of
permuting that space and so we went with
one author just to be more consistent as
opposed to just having tutors write
authors and ending up with like 10 very
similar questions and like I said before
when appropriate we extracted questions
from the original dialogue context so
this is what the author saw and they had
their learning so the author the this is
the question author saw the learning
goals so they knew what was it that we
were trying to elicit from the student
in this lesson we also see the dialogue
history up until this question asking
point and then following the guidelines
he was free to write what questions he
thought was appropriate as far as rating
we hired for tutors that had preserved
as Wizards when we were doing a wizard
of oz studies early on in the
development to mist and and we asked him
to to make these decisions as far as
rating questions in this context and we
gave him a similar setup so again they
saw the learning goals they saw the
dialogue history we asked him to rate
them simultaneously and part of this is
we wanted to not have them have like
some sort of drift just rating things in
isolation and the other thing was it
allowed them to kind of see oh this is
obviously better than another and I gave
him a wide range of 1 through 10 and
allowed him to pick
heÃ­s if they thought like I can't
really decide between these two these
are equally good i could ask either one
i didn't feel like it was necessary to
force a strict ranking in this case and
so to assess agreement we use a measure
often used in information retrieval
called Kendall's tau and it's a
statistic that ranges from negative 1
like perfect disagreement to one perfect
agreement and probabilistic
interpretation if you take tau you get
the probability of concordance 'as like
times they agree on individual pairs
versus how much they disagree on
individual pairs and so you might think
well why ranking why not just learn the
scores directly and I think part of it
is that different raters have different
scales someone might be a 7 through 10
person someone might be a 1 through 10
person and and so I'm really more
interested in which question would you
pick over another question and so the
mechanism we're going to use is we're
going to convert their scores into a
ranked list and then and then assess
agreement in that sense and so here's a
table of like how the different Raiders
agree and this bottom table is a couple
months after they did their rating I had
them go back in and redo ratings on it
on a small set and see how well they
agreed even with themselves and so
obviously they agree with themselves
more than than anyone else and what you
see here is like it really is kind of
dependent on who the Raider is paired
with and it tells me that different
people are keying and on different
things no less I took an average across
all of it and so this is our kind of
this is what taking all people and all
rankings this is where we get is like
point 1 48 which is positive agreement
it's not huge but it kind of shows the
limits of how well people did you have a
question John okay agree with one
another so the actual to actually learn
and to actually do question ranking
approaches we use a pretty standard
approach of learning a preference
function and we're going to take a
feature vector that we extract from a
question and possibly its context and
another question take the Delta and then
train a binary classifier to tell me
this question is better than another
question and we're going to run it both
ways and we're going to build just a win
table and
and the the results of this wins gets us
the canonical ranking as far as that
goes and so what actually goes into this
what features actually or what
representation with we're actually going
to plug something into a classifier do
we actually need so at the lowest level
we need the surface form features with
things that people might you in on or
what we speculate that different tutors
might think are important and so a
question like that something is overly
verbose or over liters maybe that has an
influence we also look at like WH
questions maybe some tutors really like
what questions versus which questions
and of course it takes on a little
different meaning and questioning the
author because the you'll see in a
second the wording is different and we
also wanted to take into account maybe
some syntactic variation with the part
of speech tags and so here's like a
question in the feature vector we would
get out of that single question and and
so you would see like what's up with
that we naively just take the wh or like
and put that as a binary but then we
also take the bag of part of speech tags
and just low-level commonly used
features in NLP going maybe a little
more complex we think that there's a
process in in conversation and in
dialogue called entrainment where as two
people talk more with one another they
tend to use more similar words and
constructs and and if if they're really
engaged with each other they might have
more of these words overlapping and so
we wanted to capture that in a feature
just a basic feature called lexical
similarity and so we look at both the
bag of words and the part of speech tags
and what kind of overlap and so you
could take a similarity between the
previous students turn and the question
that you're trying to evaluate and see
what kind of overlap you get or you
could also look at how does this relate
to the learning goals if we want to see
okay are they talking about the learning
goal we're currently talking about or is
this question about something else which
may be indicates if it has a strong
similarity that it might mean that the
preference for that would mean you want
to move on and so how this might look is
here's a question here's previous
student turn and and when I mean by
current learning goal is this is the
description or in an ideal case if a
student said this
we might think that the student has an
understanding of that concept and so if
I just look at the words like Oh
brighter and brighter or dimmer and
dimmer we can start to calculate just
simple overlaps and and throw that into
our vector for features getting more
into the more complex behavior we have
the discussed features and and so we
have these turns yeah that previous one
so if you're going to learn wait on
feature unique especially if you use by
graham features do you have trendy dated
to do that different kinds of conditions
dialogue states so I don't actually
extract word by grams because that's
going to be too sparse and so I only did
like diagram overlap so what percentage
of the by grams in this overlap the
percentage of my grams and that because
I think like you said it's too sparse to
actually it's too sparse to actually do
that but but given our domain the
vocabulary is regular enough that we
expect that the questions and the
students responses they're going to be
talking about batteries and wires and so
if the questions talking about batteries
and wires and the students talking about
batteries and wires you'll see a high
overlap there the student just repeat
the question yeah I mean will happen in
our system yeah so you ask a question
and they say the exact same thing it
might actually fill in a lot of the
keywords depending because we use a
phoenix semantic grammar that that
parses what they say and then it fills
in the slots and so I think if the
student was savvy enough they might be
able to but if you look at some of the
questions like they might only get the
simple things they might get light bulb
and dimmer but they might not get the
relationship that we're trying to say
that like that this gets dimmer when
this happens or true gets
which which feature identifies these
relationships um well get into I don't
think there's a feature that identifies
that but we do have a feature that takes
into account what slots they filled in
the dialogue and and then contextualize
that into a probability but uh we don't
do any like straight i don't use any of
the like the natural language
understanding for that and so I don't
say like is this they do they have they
triggered like a misconception or
anything and I think that would be like
if I had if I was to do follow-up study
I would probably add in more of these
features saying like how why or how
wrong are they and how would that
influence the behavior but because our
system is less about assessment we have
very loose definition of what's right
and wrong like I was saying we for
discuss we extract kind of the bag of
disgust features so these questions have
associated discussed labels and tuples
and we also have give an illustration of
this we can look at how closely like the
rhetorical form and the predicate type
match between this turn and the students
turn and I'm just kind of illustrate
here's a question and here's its
associated discuss act we see that has a
reverse and ask elaborate and we see a
student turn and so if we look we can
see okay we gotta reverse binary one ask
one a predicate type configuration one
so those are the kind of straightforward
to extract the other one is we want to
see maybe how in step they are and this
is just a very coarse feature that oh
the students previous response was about
observation in this question is about
configuration so that's not a match
there to maybe get a little more
sophisticated behavior we actually look
at the probabilities and compute kind of
just discuss transition probabilities
over our corpus and we can see what is
the probability of a question having
this kind of discussed tuple given the
previous students turn having this
discussed tuple we can back off from
having the full tuple to maybe just the
dialogue act in rhetorical form or maybe
we just want to look at the predicate
type and you can imagine this would get
it what is the sequence that you might
talk about a certain concept you might
start with a visual move to an
observation grind a bit about asking
about some attribute
then finally talk about the process and
then getting it this natural language
understanding component we have a
measure of what slots are filled for a
given point in the dialogue so if we
were asking electricity flows from
negative to positive and the student
said electricity and flows and the other
two parts that are left out is negative
and positive this half here this
probability would be like given a
50-percent fill of the current frame
what is the probability of asking this
kind of discuss feature at that point in
time so evaluation we're going to use a
lot of measures probably the main one is
kendall's tau which is the same one we
use to agree measure agreement between
the tutors and we train the system using
cross-validation where we hold out three
transcripts / fold and and each fold is
a different lesson so it might be this
is magnetism electricity unit one this
is going to be the evaluation and the
and we're going to train on the rest hmm
and so this is the general model this is
when we took all the rankings from all
the tutors and just tried to create one
model and the big takeaway here is that
if we go from the baseline features
which are the surface form and the
lexical similarity features and start to
add more of the discussed features we
get a bump and improvement and it's
significant from here to here I don't
have all the significant TSA's in
between there um and and you see that
for most of these measures and and you
see it at a level that's like if you
recall that all the tutors agreeing with
each other it was like point one four
eight and so the mean kendall's tau the
best system was 0 point 191 so it's
roughly kind of like how the tutor goes
and we can look at the distribution this
was for something right I actually did
some work with some other classifiers
and different tuning features but we see
very similar curves is we see that the
the mean distribution moves right and
that we have fewer the things that are
getting absolutely wrong with these
Kendall towels and moving the
distribution over and if we look at mean
reciprocal rank is how often are we
getting like the number one item we can
see that we're getting more the number
ones right when we throw in our bag of
features versus the spaceline system
yeah there a question oh no and and that
we're getting more of the ones that were
totally wrong on we're decreasing that
number
pushing it over but you're like it
doesn't make a lot of sense to just
train on a general model and I think
what we might be dealing with this
bimodal distributions we have mmm you
might have some tutors that think
question one is great and others think
question five is great and and so when
you average it out you might just get a
mediocre rating overall and like i said
before different tutors even within the
same educational setting might have very
different pedagogical beliefs and so it
might be more interesting to train
individual models and then we can start
to see well what do these tutors
actually key in on and maybe you could
imagine the next step would be to create
a more personalized environment where
student needs this kind of tutor and
they would get that kind of behavior so
I trained the individual models and we
also took the best general model and
added the features and what we start to
see here is the best performing model in
bold tends to be when we add more of
these discussed features so it shows to
me that discuss for the most part except
for maybe rate or see is useful but even
she got a bump when you added the course
level dialogue acts but different tutors
keen on different levels of complexity
when they're when they're doing this
ranking task and when they're trying to
evaluate the quality of questions and so
as we add more we see oh yeah the this
tutor really keys in on all these things
whereas this tutor maybe doesn't need
all of those features for the model
these are Kendall's town numbers again
yes seems like the computer business
agreements you had between yeah and and
so yeah if you look at the the agreement
these are like when we had that table of
agreement it looks pretty similar in
that sense yeah and so taking these
results and maybe getting a little more
qualitative about what do they mean and
what does it mean to train a model I
asked our project so our system we have
a lead tutor who manages the other
tutors and I said based on your
experience working with this tutor
observing them out out in the classrooms
actually conducting tutors and looking
at her transcripts what do you think
their style is or how would you give me
a one-line summary and so she said well
radar a focuses more on the student than
the lesson reiter be focuses more on the
lesson objectives see tries to get the
student to relate to what they see or do
some visuals and radar d likes to add
more to the lesson that was done in
class so she does something very
different and if i just take say the top
20 weighted features and i just look at
it as first level of like well what's
going on with the features we see that
it's kind of corresponds like radar a is
like focuses more on the student than
the lesson and so to really focus on the
student you need to have an
understanding of what the students
actually saying and so you really need
these dialogue axe Raider be who this
her description said she focuses more on
the learning goals and so you see these
baseline features where the lexical
similarity played a big role she really
keyed in on that and and maybe to a
lesser degree but it doesn't say
anything about the magnitude here but to
a lesser degree the the actual ax and
the types of questions were less
important versus how closely they
aligned with the learning goals radar
see who was tries to get the student to
relate what they do if you really want
to see how a student relates you're
going to have to know they're talking
about a visual or how they're talking
about a visual and so you see that
distribution and radar d she's kind of
out there she I mean she looking at her
dialogue she really like sometimes
they'll talk about things they're just
not on task and so you can see that
maybe we have to account for or maybe
the discuss doesn't model as much and we
get more with the baseline features in
her case because she yeah
using just aggression yes differences
between the pairs possible okay so some
of those numbers are very small like you
might have 13 verse approach weights
input features are pointing to other
ones a very big like yeah happens in
length of questions and so I didn't
normalize somewhere in the sort of do
Tom 20 yeah they're going to be all over
the place and so yeah most of them most
of them are binary to a percentage but
then yeah so this is kind of like maybe
just the first level past it what we're
getting at I think mmm what's more
interesting is if we start to look at
the weights individually in the story
they tell so rater a focus is more on
the student than the lesson and so what
you said about the actual weights is
still valid but you see that she gets a
negative weight to the assertion
dialogue act and so she's focused more
on the student and a question is giving
too much information she tends to have
this negative reactions like don't give
it away let the student do it rader be
focuses on the lesson objectives so
larger wait to semantic overlap features
like I said Raider see tries to get the
student to relate what they do and so we
saw this predicate type we saw more
weight towards like observation and
function or process versus different
dialogue acts and and so you can see she
really wanted to get him to talk about
what they saw vs. what are the concepts
that are driving this Raider d likes to
add more to the lesson that was done in
class and unlike any of the other
Raiders she really had a high wait for
meta statements in the questions that
are like oh yeah this is interesting
what's going on here and and and then
also because maybe she was trying to do
more the actual contextual probability
so we had the discussed tuple
conditioned on another tuple played more
weight with her model than anyone else
so well I didn't normalize the features
we can still do a cosine similarity
between the model for one tutor and a
model for another tutor and we start to
see okay this is how they agree and
while the numbers aren't going to be the
same is when we actually do the
Kendall's tau we can see that Oh radar a
agreed with rater be the most and and
and so that happens both with their
weight features from their models as
well as with the actual agreement there
and and so it gives me some confidence
that
that the model we're learning correlates
with what the tutors are actually keying
in on when they snake these decisions
and so just to get into little more air
analysis i looked at the things where my
system wasn't doing well and wasn't
agreeing with the tutors and i was lucky
in some cases when I was collecting
their ratings i had a dialog box that
said please give me any feedback you
might want to give in some cases they
just put n/a because they were just
wanting to click like a mechanical turk
er um but in other cases they were kind
enough to give me things like oh I would
never use these words in this situation
and so it kind of led me to identify
three categories of errors you have
questioning authoring question authoring
errors which where the ratings come from
how it's like I said the tutor might not
like the syntax or maybe the
construction was just grammatically
weird or the vocabulary was
inappropriate for for a third grader and
so they got a negative rating and it's
something that my model couldn't account
for on its own there are also instances
where I saw the linguistic annotators
giving the Disqus representation to the
the questions were wrong and so if like
some questions look very similar in the
discussed space and then one is very
different it might get rated much lower
much higher when whereas they might be
much closer and then there are just um
mmm other models where I didn't account
for different features so back to
closing plots we had these driving
questions behind how do we go about
doing this question ranking task and
what does it mean and so can we use the
preference data to use that and I think
yeah we can use this after the fact and
and I think Oh what features are needed
to model tutors behaviors and and I'd
say well maybe discuss isn't the only
thing but it certainly drives it what is
the action in the function and what's
going on in and so I think to do this
you need something like discuss or some
deeper level dialogue act annotation to
actually do this task and what can we
learn about tutoring through these
models well I think we learned that the
preferences aren't uniform and that
tutors really do key in on different
things and going the next step if we
started to look at learning gains paired
with this we could start to see okay
what tutoring Styles may be more
effective than others so the
contribution
our well first I just developed this
discuss taxonomy and the representation
and I think it's useful representation
for tutorial dialogue analysis and and
for this question ranking task and I
showed that it was useful for for like I
said actual human decision-making and
maybe not introducing the methodology
and machine learning but in terms of
this intelligent tutoring and question
selection modes I've introduced this
methodology for ranking questions and I
think I've just find a set of features
that really drive it what is going on in
this question process yes yeah of the
top you're getting in fact that in
addition to being good
those movements these consistent also
present the opportunity to run larger
scale experiment even ugly I'm just
wondering what's an example of
experiment that you
that gets at what's important in
learning specially yet figure out to
model the cotton wells about dialogue
based systems has so I think given
enough data and like enough pre and post
learning gains I can start to like
extract discuss features and look at
well what are the sequencing is there
certain kind of scaffolds or and and
even looking at similarity between
sequences that that are maybe current
dollar-based who you describe is that
based on is there somewhere in some of
these tutoring systems have sort of
simple cognitive models of st. memory
and help control the spacing and so on
examples nothing is there something like
that behind no we don't have any
cognitive modeling we're basically just
trying to follow the questioning the
author pedagogy and what a question
that's still open for us is well even if
we're in pedagogy in this questioning
the author pedagogy like can we maybe
try to find like a more direct strategy
versus a more open-ended strategy and
and I think given enough data and given
these labels we can see like okay do you
ever move from asking these open-ended
questions about observing or do you or
do you really need to with struggling
students have to ask a direct question
to get at that and so I think that's
kind of where I'm driving up with those
and I'm starting to look at we have we
have a collection it's not huge set of
data but we have learning gains for the
standalone system and I can look at the
discussed labels and see what I get
there oh and just like the final thing
that I wanted to add as far as a
contribution is that I think it was
short of having to create and run this
tutor on millions of students and
permute little things to learn an
optimal function we can start to create
behaviors from third-party rankings so
we can collect dialogues get people to
like mark this up and learn a behavior
and then you could imagine bringing that
back into the tutor and saying oh you
know we're going to have the tutor
raider a tutor and see what learning
gains we get with them versus the radar
d tutor and see like oh those are
negative and that's not so good so just
one final closing thought it's like
where do I take this to the logical next
step or what am I really excited about
working on into me I think with NLP and
machine learning we have great
opportunity to really make
sets of all this information out on the
world whether they're chapters in the
textbook wikipedia and and I'm really
interested in maybe like can we induce
these taxonomy xand and get at this
conceptual learning in concept maps and
and there's already work in that but can
can we then take it and actually create
interactive processes like so use that
and then do automatic question
generation so we can ask students like
um and hold them accountable I'm calling
something like more a more mode of more
active reading where we're instead of
just reading this text you might be able
to ask them questions but I think
there's also opportunities to maybe
create more generalizable models a
dialogue if you want to talk about these
concepts you can start to discover what
kinds of actions correspond with what
kinds of or what kind of dialogue
interactions correspond with what kind
of ontologies or underlying knowledge
driving it and then I think if you you
quit the system correctly you can start
to get an automated assessment you see
who gets what right and what questions
are actually useful and I think a big
open area that is we have all these
tools and we can use them to extract
things but can we expose these models
that we spend so much time creating to
the user and some sort of nicer HC where
they can maybe explore the concepts and
explore things on their own in a
different way and so fat I just want to
thank like my advisors colleagues
smitten Lucy for hosting me and close it
out and open it for any questions you
may have thank you he do this one
so I haven't heard anything about it so
we don't do anything wildly ponding like
um but I think they like the animations
they have these so I didn't say that
these animations are often interactive
and so it gives them an opportunity like
I know when I was a kid and I'd go in
class and you have to do lab and you
didn't know why you were hooking things
up and what they were doing and often
them equipment was broken and light bulb
was burned out and so this gives them
another opportunity to go back and try
it and actually see the experiments work
how they're supposed to and allow them
and so I think like for a student just
that added interaction
is fun I think they're also just looking
at some of the logs they're just
impressed sometimes by text to speech no
wow that's so cool I mean I know it's
kind of old nowadays but they think the
kids like when we were doing Wizard of
Oz the kids would be like can you make
her say this and so there might be more
things like that yeah yeah sure
discusses
extractable extractable at all i think
so i've done some initial experiments
and continuing to refine that I've built
some classifiers that do that I don't
think you can extract the tuple as a
whole but like kind of binary decision I
think it I think it's going to get
closer to those kappa values about a
year ago when i had different categories
it was maybe like five to ten percent
worse depending on what it was and and i
think part of the issue is both training
data and and the lexical features don't
carry as much weight with with how much
we have but I think it I think aspects
of it are automated I think the other
useful area is that if you're thinking
of a dialogue system you can start with
the representation and then you would
need to get it for the student but you
don't necessarily need to have the you
don't need to automatically label the
the tutors turn in that case oh sorry
should be drawing from yeah because you
might be drawing from a pool of behavior
or pre-selected full of prompts and and
then and then I think and really the the
utility at least for this application is
more tied to the question like to the
question representation and students I
think getting more towards more
sophisticated natural language
understanding you might want to then say
okay they seem to say something similar
but are they talking about in the right
way are they getting it like the battery
is the source of electricity versus the
battery electricity but not Matt so I
had a two-part question but John stolen
okay yes so the discuss ontology said
that some of the parts especially like
the product is
there are some things that are easily
confusable even by the human annotators
did you find that those differentiations
actually provided value when you were
when I to this features or with
collapsing them into a single concept to
be just as useful I think I think you
might like I think collapsing some of
those ones that were confused if I look
at a confusion matrix might actually
help in that case or previously when I
had really wild disagreements I use
those disagreements to collapse them
into the set that I have now was like I
found my annotators for some reason
couldn't seem to differentiate cause
effect in relation and so it's like all
right causal relation and and so I think
if I if it was annotated correctly I
think you would get more bang out of out
of the discrimination like saying oh at
this point we really want to ask about
cause and at this point we really want
to ask about effect but the annotation
is what it is sorry go ahead just
wearing it the tutors themselves can't
even really tell I'm wondering how
important that distinction so the tutors
oh you mean it so the tutors aren't
exposed to the discuss representation
but linguistic annotators are and is
that what you're getting at oh yeah I
mean your instruments yeah
I don't know what to use the boatman it
means I've left some very obvious
questions you gotta take something
engineer panels mislite about about yeah
kind of generalizing dialogue Jim moves
maybe beyond texting what are your good
to save some more about that so I mean
to me dialogue isn't necessarily just
what's spoken but it's the action you
take and so I think it might be that we
could generalize to well what questions
do we present but what material do we
present at a given point in time so it
might be oh you know we really want to
go from this concept and traverse over
to here and here in this order and so
it's not just specifically so it's a
combination of how do i packaged up
information but what information do i
give and how do i give it maybe it's
more important to give a visual at this
point in time than to actually give the
speech and so that's one way i'm
thinking of it the other way is i think
there are probably certain strategies
with certain classes of concepts that
that might you might want to traverse
down in a specific way like maybe you
need to with this concept really start
bottom up and and go with very detailed
questions and generalize whereas others
you might start with more open-ended
questions and drive down any other
questions
alright thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>