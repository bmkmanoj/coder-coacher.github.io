<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TechFest Workshop - Theory Day - Session 4 | Coder Coacher - Coaching Coders</title><meta content="TechFest Workshop - Theory Day - Session 4 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TechFest Workshop - Theory Day - Session 4</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xYe_BPNyp44" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so we're starting the next talk I was
once in a lecture by a Qi Qi Lu and we
explained that at least when we talked
to the outside world we shouldn't talk
about exploration exploitation but about
learning earned and similarly instead of
greedy algorithms they should be locally
optimizing algorithms and the same
spirit we'll just a next we'll hear a
talk from Mickey Roger will talk about
sequence assembly from perturbed bow and
arrow reads I see well my mom really
loves this new title so i'll be talking
about joint work with chi shen dugan
julie and alka and muscle and so the
motivation is DNA sequencing DNA
sequencing has really revolutionized the
biotech industry in the past couple of
decades because we the DNA sequences of
organisms contain so much information
about them and we can there are tons of
applications unfortunately we cannot
just read the DNA sequence of an
individual from left to right that would
be great but the current technology is
what they allow us to do is to get a
bunch of short or not so short
substrings of the long sequence that
you're interested in okay so X is the
DNA sequence and so this is just a
sequence composed of essays C's GS and
T's and what you get is a bunch of short
substrings which are called weeds so the
problem we are facing is to reconstruct
this original sequence X from the reads
are ok so there are a bunch of
sequencing technologies that have been
developed in the past couple of decades
and basically what we ideally we would
like our long ways that are error-free
or have very few errors however this is
hard to cheat hard to achieve so
typically the
types of technology the technology try
to trade off these two desirable and in
the Indies to and quantities so really
there was so original II Sanger had
developed a type of sequencing which was
unfortunately very expensive so what
really brought DNA sequencing to wise
produced with the development of
next-generation next-generation
sequencing methods such as alumina but
about a decade or so ago so this allowed
to get high throughput data really
cheaply unfortunately in order to get
really low error reads this was
restricted to having very short read so
on the order of maybe a hot length 100
when you figure very are you it's the
percent of wrong simple or yes yes and
are assuming different uniform spread
yeah so kind of the point is that these
different sequence ignatow just have
different type of error error error
profiles so you know there's some noise
involved but there also you know these
are some biochemical things going on so
there are some kind of systematic errors
that could go wrong if not properly or
depending on on how it's done so then so
because these the these next-generation
sequencing methods only produce short
reads it led to highly in complete
assemblies and they were really
fragmented because there are big part
chunks of the genome that you couldn't
connect properly and so partially in
order to get around this problem there
the new kind of technologies that are
emerging are ones that allow that get
much longer read so over ten thousand
base pairs but unfortunately the current
sager so these still have high error
rates so upwards of ten percent so
examples are the two main examples are
packed by a single molecule real-time
sequencing and the Oxford nanopore
techno
this but Sir what we see is there this
mode multitude of technologies and they
have different air raids different their
profiles and soup so any except so the
current assembly algorithms typically
are tailored towards the particular
technology that is used to produce the
reeds and of course this has a good side
right because if you know if you're
using a particular particular technology
you want to really and you're what you
want your algorithm to exploit what's
going on there but on the other hand
these technologies are evolving at a
rapid rate and so you know in 10 years
from now we're probably going to have
different technologies and the question
is will this same algorithms be good and
you know how much of the tailoring to
one particular technology will make it
unsuitable for other types of
technologies so we we'd like to
understand what are the type of general
you know what are the type of general
and robust reconstruction algorithms
that can work well with respect to
different sequencing technologies so in
order to study this what we're going to
do is not commit to one particular error
profile but instead we'll study an
adversary adversarial corruption or
error model for the reeds okay so what
we assume is that instead of getting a
true true read our what you get is a
corrupted read or what you bout what was
your phrase I forget already perturbed
yeah you got a perturbed read so the
types of errors that that happen are
deletions insertions and substitutions
so here in this example these two A's
and Red's got deleted this G this yellow
G turned into an A and this see in green
was inserted in between the GNA ok so
these are the typical typical type of
errors that happen
and so the edit distance is the distance
that quantifies how much of this error
errors happen so that a distance between
two sequences is the minimum number of
insertions deletions and substitutions
required to take one sequence to the
other so the only thing we're going to
assume is that we know that the edit
distance of the perturbed read is at
most something from the true read okay
so in particular we're going to assume
that the Edit instance is at most
epsilon times the length of the true
read which I'll denote by capital L okay
so this means that an epsilon fraction
of the read can be arbitrarily perturbed
corrupted okay so given this air error
model here's the approximate
reconstruction problem so we're going to
model the our sequence of interest X as
a uniformly random sequence from this
four-letter alphabet of length n so of
course this is not realistic but this
makes things simpler and one there are
you know you can study this problem for
arbitrary sequences and so I'll mention
some thoughts along those lines later
but for simplicity let's sit let's stick
to the Simple setting so then once you
have this sequence X you draw read
capital and many reads so what this
means is that you just take uniformly
random positions along the sequence and
then you look at a substring sub string
of length L there and then you you know
there's some adversary that can apply
any perturbation they want up to a
fraction of epsilon of the real length
and then we're given the set of
corrupted reads and our goal is then to
approximately reconstruct
the original sequence X okay so the so
the our algorithm will output some
sequence X hat not necessarily of the
same length and because we don't even
necessarily know what that is and what
we wanted to satisfy is that it have
closed at a distance to the original
sequence so because of this adversarial
error model you cannot really hope to
get smaller than linear in in epsilon n
right because for instance what the
adversary could do is so here's your
sequence and you chop it up into length
L parts and then it says that I will
never give you this information so here
these are blank l and this is a blank
epsilon now ok so then an epsilon
fraction of the whole sequence is just
not given to so you cannot really am too
much better so what we want is some
algorithm that gives you a small
constant factor approximation ok any
questions about setup thank you yeah so
if the errors are if you just have ID
noise then there there are results that
say that then you can average them and
you can do well now i'll get i'll refer
to that a little bit a bit later I mean
it's somewhat realistic that the arrows
might be not just iid right because it
sort of depends on the sequence yeah
what goes wrong yes
okay so so this problem I mean not this
this particular problem but the general
problem of reconstruction from Reed's
has been studied a lot over the past
several decades and so the two main
obstructions to reach instruction are
very well known so the first is that if
your reads are too short then this will
lead to repeat and then this will lead
to ambiguity in reconstruction so let me
explain in more detail what I mean by
this to suppose you have a read a
substring a here that repeats in the
sequence and also a substring be here
that repeats and that your reads are
shorter than the length of a and B okay
then when you suppose you had all the
reads even then you wouldn't be able to
distinguish between the sequence at the
top where Y is on the left and Z is on
the right and the sequence and at the
bottom where Z is on the left and why is
on the right when you get the reasons no
ordering where they come from no no no
they're just you know they're just in
the bag s so somehow the technology that
gives you this is that now you you
create a bunch of replicas of the DNA
sequence and then you put it into this
big soup and you blow it up and that you
get out these reeds that's it roughly
how it goes okay so your reads have to
be long enough and the other main
instruction is that you have to have
enough of them to be to cover the
sequence so again if you there's some
part of the sequence that you have no
information of then you have no way of
reconstruction with there and also you
don't know if even if you could recruit
you construct everything on the left and
everything on the right you don't know
whether you know which is on which side
okay what are you doing them great for
ya so this is essentially a coupon
collector problem but okay in this set
they were the one who did this but okay
they also you know applied it you know
they applied it to rio's sequences and
computed these various quantities and
things like that but yeah so this is a
coupon collector problem this is the
number of reads you need in order to
cover the sequence with probability at
least one minus data I must have missed
this on this I behavior model beads are
selected from rim uniformly random
questions yes yeah the adversary only
temper but they am sorry your only
interest one yeah yeah yes so this first
obstruction goes back to Conan and this
goes back okay so wherever it goes back
yeah the coupon collector so yeah and
this is often referred to as the repeat
limited regime and this is referred to
as the coverage limited regime ok ok so
if epsilon is equal to 0 so you have
error for your reads then this problem
is the same as you want to reconstruct
the sequence exactly and so this has
been studied and in various settings in
particular in this exact setting where
you have shotgun sequencing and a random
string this was studied by recently by
motihari Breslin Shay who showed that
these are the only obstructions to
reconstruction okay so more precisely
back to the random sequence it's ok they
do more than that it's more general but
let's just stick to this simple setting
and the reads are logarithmic in n so if
you have a random sequence of length n
then the longest repeats will be on the
order of log n ok and let's suppose the
error probability that you I mean the
probability that the algorithm is
correct you want that to be a greater
than half so then if the reads are
shorter than this threshold so that you
do have repeats in your random sequence
of this length
then exact reconstruction is impossible
because of the aforementioned fact and
if you're above this threshold so you
don't have repeats then basically the
not you know if you have enough reads to
cover the the sequence then you're good
and you can reconstruct so the ratio of
the minimum number of reads you need and
the minimum number for reconstruction
and the minimum number of reads you need
for coverage goes to one okay and so
they looked at also more general models
so the sequence can come from a Markov
chain for instance and of course for the
real life application you also are
interested in arbitrary sequences and
Farber cherry sequences and so bresser
bluster and Shay study this problem and
they showed threshold based on the
repeat statistics of the sequence so
that's it's very natural right you know
for a random sequence you know what what
the repeat statistics are so you can get
explicit thresholds in this way okay so
in an approximate reconstruction so
basically the result is that you can do
approximate reconstruction if you have
enough reads and if the read lengths are
long enough so the reads are long enough
so more precisely so this is a bit of a
mouthful but basically you can get an
approximation factor of anything greater
than three if so if epsilon is small and
the read length the reads are long
enough again on on this logarithmic
scale and you have you have enough reads
okay okay
let me make some comments so I'll show
in a second that the simple sequential
algorithm works right and that's good
because that's kind of the most natural
thing you you might expect to do you
just patch the reeds one by one so here
in this statement I have some dependence
on epsilon of the required read length
then the number of read the number of
reads so this is not necessary if you
just want the finite approximation
factor but I won't get into this one one
thing I should mention is that so in the
previous picture when epsilon is equal
to zero then there's this very nice
picture of clear sharp threshold and so
this was made easier by the fact that in
that case there is just you know I you
either reconstructed the sequence
exactly or you didn't so it's a it's a
binary thing here you're you the measure
of success depends on this approximation
factor so it's it's not something that
is binary so you know it might be the
case that the best achievable
approximation factor depends on how many
how many secrets how many reads you're
given and how long they are okay so
there might not be such a nice picture
so in Perth we would like to understand
this picture better but then okay let me
just mention related work so people have
looked at various noise and error models
so in particular mata Hari Ram Chandra
and Shay and ma looked at exactly this
setup of just adding iid noise and then
you can imagine that that averaging out
this noise so you can average out this
noise because of you know because of the
coupon collector fact that once you have
coverage most places are actually
covered log in many times so you have
many reads covering each each coordinate
so if you have some amount to noise then
you can still deal with that and show
Maroni quit that then she looked at an
adversarial model but it's a somewhat we
weak adverse adversarial models so I
want I can explain more offline if you
just wait them constant multiple of
recovery time and everything is
comfortable times right yeah okay so so
before just showing you the algorithm
very briefly at let me say that so in
order to analyze algorithm what so the
only assumption we're making is how the
edit distance can change so what really
need to understand is you know what is
that a distance of two reads that don't
overlap and what is the at a distance of
reads that do overlap and how much how
it depends on how much they overlap by
right because that versuri can change
things in at a distance so this is
something we really need to understand
so the picture is following so if you
take two independent sequences of blank
em then that is there at a distance will
be linear in am this is this is just
this just falls because of the sub
additive erotic theorem so there's going
to be some limiting constant here and
it's a hard problem to determine this
constant explicitly but you know
empirically you can simulate this and
find what the in particular when you
have four symbols this constant is about
2.5 1 and using a volume argument you
can give a lower bound of point 33 so
this means that if you have two reads
that don't overlap then they're pretty
far apart in a distance so if the the
adversary can only change that the
distance by a little bit then no they
will still be far apart the other end of
the picture is when you have two reads
that really overlap by a lot so then so
let's look at this picture here so that
it is it if they were lab by a lot then
that a distance is at most twice the
shift between the two reads because
you can get from this read at the top to
the one at the bottom by deleting the
blue part on the blue part on the left
and adding the red part on the right
okay and for random sequences the so it
turns out that this is exactly the at a
distance you know you can't do better
than this because of the randomness of
the sequences and this is true up until
you know a constant fraction of a shift
between the two sequences and this
exactly you know empirically it's true
exactly until half of this constant here
and then that a distance just just
becomes as if they were completely
independent okay and so okay we cannot
prove this the this curve but we can
prove note that this is true until some
point here and then we have a lower
bound of that form and that tells us
that ok if two guys are close then the
they overlap by a lot then they're
closed so you know that the adversary
cannot make them really far apart at the
profiling has this a tomb just two lines
no
okay so i'm almost out of time so let me
just very briefly say what the algorithm
is so you take a read and then you look
at an appropriate length suffix and then
you look into your bag of Ruiz and try
to find the a read that has a prefix of
that length that is really close in at a
distance and so there are a couple of
things you have to guarantee you have to
guarantee it okay so this is you know
larger than 2 epsilon al because
otherwise you know you can get rid of
the overlap you also have to make sure
that this is larger than the the length
of the longest repeat so there are a
couple of things you have to take care
of and that's why we have the various
assumptions on the read length and the
number of reads but then you basically
you make at each step you make again
that's linear in l and in particular if
absolutely small then it's almost l and
you only make an error of about 3
epsilon now okay so even computing
editors
computing at a distance standard squared
okay so let me just conclude that so
here in we've introduced an adversarial
model for approximate for for the read
errors and we showed that approximate
reconstructing possible using a very
simple algorithm and there are
challenges so we would like to determine
what are the really the fundamental
limits of this approximate
reconstruction also we would like
results for arbitrary sequences and they
would be roughly of the form of saying
that well if you know the reads are long
enough so that nah no wrapping reads
have larger the distance and overlapping
grades have small at a distance then
you'll be able to do it so this is the
type of result that should be true more
generally I feel like you know of course
the models where you just have pure
noise those are not realistic but this
is also a bit going overboard because of
course you know nature is not
necessarily adversarial so I think
there's there's a space for models in
between previous models and and this
current one I'm trying to find a good
model in between and so in particular we
can talk about heterogenous error rates
for instance and various other things so
would that let me just conclude thank
you d questions of river
I have a really stupid question okay and
it is DNA directional I mean can you
tell which end of your fingers which
yeah okay so i'm not an expert in this
but yeah yeah yeah yeah the occasional
eat small pieces get reversed then there
is there's a like there's it should
always have to deploy directions but
people you just have one of this seems
like now you know whatever ah you do
know if I religious Oh nobody believed
when you get there meet you know like
you know which direction oh I see if I
just gave you a sequence wouldn't know
but they're secretly to go to my
understanding that stuff but I've
invited my understanding that the two
strands and regulate going opposite
directions so when you get on a night
you it's a biggest whether it's forward
from the left strand or backward from
right strip okay where the battery base
paired thing right strong but that's
maybe ok any other questions maybe I
have one can you go back once I'm you
said the edit in exactly two players
here were you surprising a little
additive error there no I'm sorry Sarge
aggressive so listen Rita was too thick
because I mean less than or equal to K
follows from this construction but it
must be development it's a
yeah with probability at least one minus
hey any other questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>