<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>IMS-Microsoft Research Workshop: Foundations of Data Science - Opening Remarks and Morning Session I | Coder Coacher - Coaching Coders</title><meta content="IMS-Microsoft Research Workshop: Foundations of Data Science - Opening Remarks and Morning Session I - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>IMS-Microsoft Research Workshop: Foundations of Data Science - Opening Remarks and Morning Session I</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HYb2K-UUKeg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
Thanks 10 I'm here primarily
representing ims but in particular I'm
subbing forbid you to get intended to
come couldn't make it personal some
personal issues and which she sent me
were some slides that were based on her
presidential address from ims last year
that she delivered and in Sydney and the
title of her dress was lettuce own data
science I thought was let's own data
science but I think she uncontracted let
in us and us I think he represents
statistics it was a it was an address to
the Institute of mathematical statistics
so in the audience were statisticians
and improv lists and this is not a group
that you really needed to convince about
ownership of data science it's kind of a
sensitive issue in terms of the
terminology there the address is
described in the ims bulletin so you can
have a look at that if you wish some
point but in her slides she goes through
these different connections of bridging
computer science with math and sat and
the main site part on knowledge I don't
want to spend too much time going
through first slides I want to really
get to what I wanted to say this thing
but I feel obligated since I'm subbing
for her at least present her slides and
get she did want to thank thank Jennifer
Shays and especially thanks to the
conference committee David and sham who
helped who helped organize this she
mentioned a couple people in her
presentation and I was more interested
in how she crafted this presentation
because I have to give the president's
address next year and so I I like the
way she did it so she started talking
about the sky Carver Carver was the
first editor of the annals of statistics
probably in the nineteen nineteen thirty
some time and he there's a quote from
from carver about
upgrading from logarithms to computing
tabulating machines which is kind of a
nice one Margaret ins must be considered
now as a tool of the past this is hard
to believe right okay present-day
commercial institutions almost without
exception use computing machines rather
than logarithms in the conduct of their
business and interests of efficiency in
both time and labor she also mentioned
the Hollerith pavel tabulating machine
aged HTM and I hadn't realized that this
guy started a company he was the founder
of the tabulating machine company which
eventually became IBM and the first
supercomputer it delivered to a
university I didn't know the cedar was
to Columbia in 1931 and that's at the
time when I used the words maybe the
first time in a newspaper super
computing which is also an interesting
twist on it the other person that she
mentioned was was Helen Turner so this
was a address given in sydney and helen
was the first president of the
Australian Statistical Association and
she also did very kind of broad research
in experimental scientist she did
methods of reading and she was a good
communicator so these were all kind of
components that might go into what makes
up a data data scientist so she had a
Turner and Carver together and called
this the kind of prototype of a data
scientist and putting these traits
together she had these five traits
statistics the main science knowledge
computing collaboration and
communication communication to outsiders
and then this apart I didn't get it all
actually is there something I'm missing
here she said data science equals the
SDC cube
I got that but I thought there was some
other deeper meaning and that this
really meant something special but I I
guess you read it the same way I do
anyway and then and she wanted you to
enjoy the conference which I do too as
well but I wanted to get to the main
point which was the net is the next
slide so I'm going a little bit off off
with the format she wanted me to to to
adhere tube and to be more embracing the
society to data science they don't fit
so naturally necessarily coming up
working in the data
you
we're out there just may be purchased
for discussion and later time that some
things just to think about many of you
are already considering these these
aspects it was ims has a provision for
having a sub groups under the auspices
and right now there's only two subgroups
one is in finance and this is finance
group is really a little bit maybe a
little bit like data science that it
doesn't is not completely under the
umbrella of ims a lot of the finance
people are in probability and
probability sometimes follows honor
honor honor mathematics may be more
comfortable mathematics but there is
this finance group and they organized a
conference every year under the ims
auspices so this is something I think
would be a good idea I think it once you
have a data science group within ims it
gives it a bit more visibility and they
could interact with also junior members
and and create sort of an identity with
under under ims then the next one is we
should plan for the next I am at state
of science meeting and question is what
how should this evolved maybe I'm s plus
blank I wasn't sure who would be if
Microsoft would would be permanently in
there or would be someone else as well
but we should think about the the next
one and i think this also maybe
coincides with this formula data science
for me a data science group that this
could be a group that sort of organizes
this annual meeting so i think this is a
something we should consider i'm happy
to do this in new york next here and i
think there's some industries that in
New York including Microsoft that we
could collaborate with but I think
there's also an opportunity to bring
bring together universities and in data
science and industry so New York is a
good place for put your other
departments besides Colombian in New
York it could be Duke Carnegie Mellon
Chicago of course the west coast in a
bay in the berry
area so I think this could be sort of a
prototype that we ought to think about
doing every year on the annual basis one
of the sensitive issues I think as I
understand it is is this one I don't
know if ya is this data science
established data science publication not
lets an IMS and data science moves
quickly they'd like to do abstract short
papers whatever and these are not always
well received in the ims journals so
what do we do about this so I think we
ought to really think hard about duty
doing this one isn't you know the annals
of applied static that area editor's
possibly that just handle data science
but I don't think that's just that's
that doesn't do everything right that's
not enough and should we think about you
know what are the other possibilities
I'd want to propose another journal
whatever but maybe that is something we
could we could consider we need to think
about this and I think this is sort of
an important issue but you also have to
understand the the other side of it to
from the probability in statistics folks
the theory and the knee applied people
where they have to be kind of on board
as well with that so this is something
that we could discuss here but we should
have a group thinks about it put a
proposal forward to to ims I think bin
and I are very supportive of trying to
figure out something and there's only a
short window when bin and I have maybe
some influence and I am I ms so let's
not lose that opportunity and then just
other other ideas are very much welcome
to how we can incorporate data science
as a is a group instant in in under the
umbrella of ims i think i am s a great
organization if you're not familiar with
it it's really one of the largest
professional societies were probability
and statistics in in the world and
whenever I ms does something like start
a new journal it
instantly becomes the best journal in
the field it doesn't take long there's
no there's no lag really just they have
very very good people they put in
senators associate editors and quality
becomes instantly top-notch so it's a
good I hope this is a win-win it's good
for ims to broaden its reach and it's
also good for people working in data
science to be part of this organization
and and there are many things that I
mess can do do for data science as well
so oh and I'll end there I've 24 seconds
left i'm over by 24 it's red so thank is
that they share some very interesting
statistical and computational challenges
if you have large pnm you look at on
modern-day web search engine there are
literally trillions of documents and
millions of queries and users per day
the data is incredibly sparse most words
not occur in those documents and social
networks most people not connected to
other people and all of the both
representations and interactions
iid words are not independent we're
restraints are not uniform over time so
just about every imaginable assumption
that are different a reasonable
statistical perspective this program
what are our focus on today however are
put the speed is going to focus on today
however it to additional unique
challenges I think brought on by the
fact that both certain social media have
become over the last decade incredibly
pervasive in people's lives how many
views search in the last 24 hours how
many of you have checked Twitter or
Facebook or some other or email even is
the kind of social media mom he's are
really becoming core fabrics of people's
lives and so I think two of the
interesting consequences of that are
first of all that we now more than ever
need to take into account the fact that
people are interacting with these
systems and a whole other dimension of
variability that we need to represent
them to think about and the second is
because these cert these are large-scale
web services we can do experimentation
and a scale and speed that have not been
possible before so the first two talks
in this session I'm going to focus on
more core information retrieval problems
change eyes and a leadoff and talk about
how he's reformulating information
retrieval is really a kind of joint
optimization between utility for people
and efficiency of operations for
retrieval systems and Africa shahab is
going to talk about how we can use
information provision the process of
sending
essentially connecting the dots between
seemingly unconnected objects the last
two talks are really going to be about
experimental design leoma to who wasn't
Microsoft in this now Facebook is going
to talk about designing efficient
experiments that enable us to make
causal inferences from data and johanna
condors and then talk about the
challenges in doing randomized
randomized experiments in the case of
something like a social network where
they're huge spillover effects so will
first talk about some of the core
retrieval algorithms and that about some
of the really interesting and
challenging formal occasions so change
without from your date take a look okay
well I soon the issue it I got to use
this this what hope have we hold it for
years lined up
so it's easy okay good okay very good ah
thanks for the opportunity it's my great
pleasure to be here to share my thought
and my work with all of you and I'm
looking to looking forward to all the
interactions discussions and your
presentations so what am I going to talk
about today is just some thought about
what future search engines might look
like in my opinion and this view also is
more general than just looking at search
engines it might generally include all
kinds of intelligence systems that fear
with a lot of data okay so there's no
need to read this long title let me just
proceed with the presentation the
motivation is obviously how do I harness
big tax data which i think is a problem
or that your are very familiar with but
I want to emphasize that text data is
actually quite unique because it's
produced by humans and it's meant to be
consumed by humans so this is very
different from the data collected from
sensors in some way we can think about
the humans as subjective senses that
would look after the word and then
report some information and that's in
the form of text right so so in that
sense we could put all the data together
obviously text data is very important
for many and big data problems now
because it's produced by humans it has
included our knowledge and I think about
literature and we have a lot of
knowledge encode there and it also
includes our subjective opinions so it
has a lot of information about what we
think about the entity like a person or
product right so this means it's a very
unique source for discovering some
knowledge that we may not be easy to
discover from other data sources of
course in general we should combine more
kind of data the second point is that
because it's been to be digested by
humans then with it has two consequences
one is that because there's so much data
that no single person can possibly
digest order there are not even a small
fraction of it
we need tools to help us to digest the
data that's why many hands were raised
when to ask the question whether you
searched on Google being right and now
the second consequence is that the
humans must be in the loop in mining big
tax data because humans are the most
intelligent systems in some sense to
digest text there are machines can help
humans but we can't just completely rely
on machines or not yet so since I'm
going to talk more about the information
to and then this whole session is about
information retrieval so I want to
emphasize that information retrieval
plays a very important role in the big
texted applications in general so this
shows a rough pipeline or logic pipeline
of mining big text data you start with a
lot of raw data and then you try to zoom
into the small amount of very relevant
texts that are that it's actually needed
for a particular problem so we have this
process of reducing the size of the data
this is the most effective way of
solving the scalability problem and then
we're going to use techniques that we
often go to text mining to further
analyze a small amount of text data to
to get the knowledge out to support the
decision making support a lot of
applications so we're going to turn the
data into actionable knowledge right now
as I said that users are very important
for any of these applications and in
fact the users are generally involved in
all these stages of course what I'm
going to talk about is more about search
but one important the point which was
also mentioned is using introduction is
that we need to optimize the combination
of humans and machines so it's a a
overall global optimization problem and
in contrast I think today we have paid a
lot of nanjing to asking machines to do
as much as it can this is good but then
we also need to think about
opportunities of engaging humans
effectively to solve the problem and
that set up turns out to also raise a
lot of interesting questions for
interactions between status changes and
machinery researchers and computer
science and many others as you will see
later okay so I had can skip this
have you already know that but perhaps
you don't know that we sometimes
research for even small they're like
desktop search which is the big for
particular person now here are mention
that this was pioneered by Sue and her
colleague as in Microsoft is that that's
a very useful service that a lot of
people are using right and the second
point is such accuracy matters now I
meant to ask you to guess how many
queries and these search engines
received but that's not actually the
point it's a lot and the point here is
that if you can save even one second or
a few second or a minute for these
queries on then you can save a lot of
time and obviously there are many
application expected so i have to say
that i really would like to put being
here and I know being is getting a lot
of queries unfortunately I couldn't find
the data point so i have to say that
it's not because I you know just yes
it's somewhere here right so we have
come an amazing way in five years yeah
yeah so find the source I couldn't find
the number of queries thing is receiving
any way so that the central question
that I'm gonna dress like this Hawk is
how can we optimize all these search
engines in a general way because if we
can do that even if it's a small amount
then the benefit is huge but this
question is really your defined because
we have not really defined what is
exactly search engine although in our
mind we know what the second it looks
like right but if you think about it the
more you may discover that perhaps it's
not so simple and also of course what is
the optimal search engine and how do we
find or developing such as so genuine so
this started with current search engine
and this is overly simplified view of
the current search engines you have a
query and then the system the search
engine would match query with the
documents and then return a rank the
list pie here and inside the engine
typically you use some retriever models
we generate a lot of features hotels
which kokkonen alike is likely relevant
and then we use pretty minimal
NLT although as you imagine we want to
actually use more than to go beyond the
current state of that because
understanding the text content is
obvious very important I think definite
it's going to talk a little bit about
that but overall we're going to use the
machine only as an umbrella to put
everything together or statistical
learning and then this will give us an
optimal scoring function that can
generate the score for each document and
then we're going to rank and based on
that so if you look at this picture our
definition is basically the search
engine is to return a ranked list with
hemp rulings typically and then
basically our goal is to optimize this
scoring function and our objective
function is typically based on the
errors or quality of ranking on some
training data set that we clap now the
question being raised here is is this
really a good definition or this is our
best definition now actually there are
many problems with this definition
because documents actually depend on
each other the utility of document
depends on other documents if a user has
already seen the same document obviously
the next one which is exactly the same
which will also have higher angle score
would not be very useful sometimes
pieces of information can be put
together to answer your question that
collective relevance and we can't really
do this so well this is the easy to fix
let's just optimize the whole ranked
list and people indeed did that and they
have used learning rank to optimize the
whole ranked list of course the the
complexity is much higher now but this
does help solve these problems but we
can see ask the question is this
definition our best definition
unfortunately it's not because here we
have not really considered a lot of
context of the users when the user types
in here it's not just a single query
there are past queries history contacts
are a lot of information about the user
and we have to model the user in more
enhancing are in order to serve the user
better without consider serving such
information is very hard to model this
whole user right and also we can
optimize the performance over the entire
session which is more important
right and that's why I have game 0 in
the title and that's him for thinking
about this holding as a game and the
task users task is really the ultimate
goal and we need to optimize the whole
thing but people realize these problems
so they have done a lot of work try to
fix these problems and is another
complete list of all the existing work
at just a suggestion of some ways to fix
the problem so for example what about
the context of users particular past
history etc then people started
impressive feedback personalized search
in fact again microsoft research has a
lot work there and many other
researchers did that as well and Sue and
I think Jamie and some people have done
work that I also listed here now what
about users well this has been some work
mostly again industrial apps and Yahoo
lab school I think Microsoft again we
tried to model these users in hand so
task to some extent it can be also infer
what about the optimization or
performance over the entire session and
there has been work that started to
address the problem for example active
vida back where we sacrifice the
performance temporarily in hope of
learning more about the user to optimize
the overall return fine by exploiting
machine learning and exploitation
exploration trade-off is a problem here
and recently people have also used
partially observable markov decision
process from db2 model session search
and these are all a great effort and
that bring us more toward ideal
situation where we model the users
accurately and try to serve the users
optimally but the question that I raised
here is can we address these problems or
model this problem frame this probably
in a unified way and here the solution
is I think a cooperative game framework
so this is not a zero-sum game it's not
a competition the users and the machines
are collaborating with each other so
there is a common objective here so the
process of retrieval can be regarded as
a cooperative game playing and the
players obviously the search engine
systems and users let's think about
Oh case where we have just one user and
one search engine right so they make
moves and they take turns and depending
on application if such application
typically the user initiates the first
of all the user types in the query but
there are also cases where recommended
system can make the first move or queer
Ellis such as it has against you did is
the example using contacts to initiate
search and all these can be regarded as
basically having users and systems to
interact with each other and and I
should also say in recommender systems
they should be also follow up
explanation of the item and this is very
similar to search okay so and then for
each move of the user the system would
respond with some some move but if you
look at this the current system in this
way and it's playing a very simple game
yeah I sooo think about what moves the
user that has today it's just mostly
type in a query click on a document or
scrolling that right so pretty much
limited to a few choices as seemingly
the system also doesn't do a lot of
other moves even though in research
people have proposed the for example
clustering certain results there are
alternative ways of displaying the
results but the practical systems are
they play a very simple game here and
and this limits the utility of the
current system at one point that I want
to make is we can think in this way by
designing more moves based on data
mining operators machine learning
algorithms or other functions that we
can develop and bring all these
functions together make them available
to the user and especially provide a
task specific support for user right so
that so that what's objective of this
game well the objective here is to
optimize multiple factors one is of
course it will help the user finish the
task and as I said a multiple times
finishing the task or finding the
information is the ultimate ago all
right so the ranking accuracy for
particular query is only part of the
game I so want to satisfy users
information leader or in general help to
use a
task then we want to also minimize two
other factors one is the overall effort
from the user that could be measured by
the time by how easy the new it is reuse
the system is it the cognitively very
demanding etc right but there is another
fact that that's the system side which
can be measured by the system
performance requirement or resource
requirement right and but all you can
also measure this by the budget that you
have because you can invest in other
ways to improve the system right so but
and you get the point right so we can
have varying variants of formulating
this problem so for example one
realistic set up set up could be given a
constant effort of user user has just a
few minutes to find the information
right subject to the constraint of
system resources we only have so much
computing power that can be allocated
for this user now how can we maximize
the utility of delivery information to
the user in general these factors must
be brought together and that's the main
point yeah so there are some important
benefits of framing the search problem
in this way the first is we naturally
optimize performance on my entire
session instead of on a single query and
this is like to optimizing the chance of
winning hurricane now if you play chess
then you will realize sometimes you want
to sacrifice a piece right and from a
local viewpoint that this is not good
that you're losing a queen that's not
good that's not the game but if you look
at the whole game plan it helps you win
the game so in search it turns out that
we need to do something similar and it's
possible to do something similar and let
me give you it one example so sometimes
the user's query is ambiguous let's say
Jaguar could be a car could be an animal
now if the user doesn't find the
information the system does not perform
well for such a query instead of asking
the users repeatedly reform user query
and keeping the amputee you could have
asked that assuming jaguar by car or
animal now in such a case the effort
from the user side is not that much the
user would just click on one of them but
it would help with the system
tremendously and but note that in this
case the utility
we deliver to the user is almost zero
because we did not deliver any relevant
information it's probably worse than if
you just guess what it Yoga means and
you would deliver something for me so in
this sense it's a little bit like
sacrificing a piece but as we learn from
the user more than we were the benefit
will come in the later stages of
interaction just like a winning a game
right the second point is that we want
to optimize it now it suggests the
optimization of the collaboration of the
two parties that uses and the system and
this is this is to leverage the
intelligence of both and right so for
example a user no way about what's
important what's useful but the user
doesn't know what information exists in
the information space the system is in
opposite direction this is some knows
very well about what data we have but
the system doesn't know what you are
looking for so a natural solution would
be to preview what information is
related to your query and lets user
guide you the code to the right
direction in the information space right
so this is a long nap direction and this
kind of optimization can be addressed by
using such a way to think about the
search problem and finally it removes
the boundary between a search system and
a task support system and as you will
see more clearly when I present some
more formal right along this direction I
that that is because when we think about
query as one action taken by the user or
screwing the down or click on your
document as one action then we can
generalize this to all other actions
clicking on anybody or making any
requests and this so that's why this is
more general so let's look at the
currents are changing this framework
right so this shows a search process
that we are having today we can think of
this as a dialogue between the user and
the search engine the user enters query
that's the first remove a one and the
system would respond with some decision
so which information items represent how
to present etc now I have to say the
current search engines only optimize the
ranking of the list they did not intend
to optimize the display for example for
information why temporally
not five why some items cannot have a
larger space to display the information
adds cost of adding items how do you
optimize this right would miss some
optimization point here right
opportunity and then the system will
decide to display some results for the
user to to look at and then the user
would then check and then and the system
will go on now this is within 25 minutes
is that right okay so hydro because I
somehow registered as the amount of time
left for talk so I have to skip some of
the points and the slides are available
so what people can look at that let me
just proceed to how to formalize this
this problem right so to solve the
problem this way we can formalize this
problem so we have these actions taken
by the users the response is taken by
the system so far and then the question
is what's the next response right so
this is all very general and we'll put
the contacts here and document and then
we kept you all these in as history of
what happened in the past that context
gives an information about the current
and then the problem of the scene here
is given all the observed information
how can we choose the best response
right again sorry I have to apply skip
some of the slides and I intentionally
include more slides just for companies
and also reference for discussion so you
see I I skipped some of these right so I
skip something non-essential information
so to solve the problem we can then use
bayesian decisions and theory to frame
the problem right so the key is to
introduce a formal variable m that
stands for user model this captures
everything that we want to know about
the user for our decision problem
obviously this depends on the problems
here we are interested in finding
information so one essential element is
the information leader we have to have a
model for what the user is looking for
and we also should keep track of what
user has already seen and reading level
and a lot of other information how much
time do you think the user currently has
right and
and we introduce a loss function to
capture our objective and then we just
choose optimal response okay and this is
a standard a bayesian decision theoretic
framework so here we see we have
observed data I'm going further use the
model and then we minimize the space
risk now this of course composition is
very complex so there are challenges in
scalability one simple way to simplify
this is to take a mode of the posterior
as operation of this integral and then
we're not going to do basic and
basically and then this would lead to a
two-step procedure for solving the
problem essentially we don't consider
that certainty of models so given a user
action and then win for the model of the
user and then we choose the right action
and then the user would take another
action and we ideally it would also
model what the user would do for our
results right so this is something that
we turn it on too and we infer another
model etc now this framework is very
general because we have model actions at
different levels if you define the
action as the keystroke then you have
query accomplishing as the best of
service in responding to such a actually
but you can also define actions at high
level like this search session as one
unit then you have more of the users
tasks user is traveling perhaps right
and so we can further generalize this
obviously 22 analysis operators and
these are all moves or task request so
the key here is to have a user model
here that can be regarded as a state of
a mark of the gene process if you see
the whole process so that's why palm DP
is very environment and reinforcement
learning is very relevant because we
won't observe these states yet we want
to learn that so we have to interact and
learn these rules here so the key
questions here perhaps the most
important research question will be how
to define them and how to infer em now
this will probably be a very important
side to unite a lot of interests here
and here i show a lot of aspects about
the user that we want to infer and we
observe two kinds of data from the user
one
content one is the behavior data in such
a lot so there are two kinds of big data
and then we want to generally use
generative models to model that they
don't recover some of the information
about users now I have some example work
I'm going to skip all these all the way
to the end we can talk about this later
using them regression model to uncover
users letting the preferences and
interesting reviews okay so the general
question suggests by this framework
would be first how should we design that
game what are the moves right and how do
we compute the optimal strategy and how
is this related to game theory so does
Nash equilibriums there matter here it
is based on a lot of assumptions that
may not hold for our problem how do you
evaluate such a system is big problem
and I'm glad that there would be other
talks to address this problem right so I
want to talk about one specific problem
that clearly and ties these two together
I know you need to stop me the f does
not eat just one picture okay and so so
this problem is the following so if you
don't shoe leather shoe a lowly ranked
the document to the user then you would
never know whether users would like that
so the question is how do you shoot this
rock man and and where do the experiment
and that I'm sure will be addressed
later in some talks so I'm skipping this
something I just promised you to share
one slide and that's to say that in
order to build such a system we need
collaborations from all of us so we have
an interactive services system and that
looks like a typical search engine with
response to users and then we'll collect
a lot of user interaction log and it
will have also include a lot of big data
from other places the park users and
documents and then we obviously need a
traditional retrieve all we need a game
theory with in machine learning to
analyze the data and there'll be
understanding text and calm hand and
then human-computer interaction even
psychology don't understand the users
but at the core I think it's a
statistical modeling the probability
modern statistical answer and
optimization and this will be related to
all these fields it has already been
using all these different fielding and
and in machine learning I think
definitely it's probably going to talk
about this um also and then in other
talks you might see some of the things I
think with that I just stopped looking
forward to collaborations thank you
sorry for leaving just a 42 seconds by
the clock few questions and why don't
you set up your plot give a few
questions sir yeah yeah so how do you
actually measure it I kill you I mean
yet experiments could you just go with a
measure that utility yes I'm so much
more complicated than Jessica yes did
you get there i dint ever answer the
question is remove some thought and one
approach is we use a system that can be
application that's easy to measure that
for example MOOC massive online
education you can measure the grades of
students or learning performance to
assess the improvement of your system
did you teach the students more
effectively by doing so I think I'm all
the holes later where guess is far away
that baby you Incubus usually imasu of
the task whether the user has solved the
problem whether the user is satisfied
was this how much time the you that has
spent I saw this and how much resource
the system has has used to stop using
use anywhere you have a problem and it's
an interactive yes studying whether
they're trying to solve the problem with
queries or something yeah I'm going to
mess all the three factors and then
maybe depending on vacations we might
emphasize some factors more than others
okay thanks Ryan it'll be great to
continue these discussions during the
next two days each year microsoft
research helps hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>