<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The deterministic user-level replay of concurrent programs | Coder Coacher - Coaching Coders</title><meta content="The deterministic user-level replay of concurrent programs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The deterministic user-level replay of concurrent programs</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MSb2eLKUQZc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay I'm tomball and it's my pleasure to
welcome charged Charles Jang here he's a
professor in the Department of Computer
Science and Engineering at the Hong Kong
University of Science and Technology and
his major area of work is in this area
of software engineering he's been
focusing lately on debugging of
concurrent systems and is a PhD MSC and
BSC with honors all from the University
of Toronto so welcome Charles thank you
thank you very much all right so I'd
like to thank Tom first for have given
me this opportunity to talk about my
work so I'm very very happy to be here
to be the home of chess to talk about
debugging concurrent concurrent programs
we're happy that shares came to give us
some opinions so before I start talk
about research itself let me just first
to introduce where I come from there's
some old friends know where I come from
but there are many new so so I come from
a small University in Hong Kong it's
located right here on the shore of the
ocean it's quite small it's God in total
about 7,000 students so it's but it's
quite specialized so this where it comes
from on a map and my research group is
called prism research group it's
basically established in 2009 I joined
the university in 2008 so we're pretty
young research group that's why we're
happy to be here to learn from the
experts well I have for PhD students in
a group so so the research focus of the
artistic group is too we like program
analysis and we want to use it to help
programmers debug develop large systems
our current focus is concurrent systems
as tom has already
so we have a few research major research
projects the topic of the talk today is
one of them it's determinist replay of
concurrent sulfur so I'll talk about
that of course for for this talk and
other than that we also work on
automatic fix of concurrency bugs we
have two papers there we also work on
causal analysis or people call it
predictive analysis / chases and have
few interesting techniques there we also
work on something much lower on program
analysis itself we have some technique
that computes pointers more accurately
and we have you that it's been adopted
by suit and we also work on some
database approach for program analysis
that's our ongoing work okay so this is
overview of the type of research will we
do in in a group of course today I want
to talk about a specific area that we
have made a few interesting contribution
to it's called determines user level
replay of concurrent programs it's a
joint work with Jeff who is also here
and together with pretty much everybody
in the group so this is something that
everybody in the group has invest
invested some amount of time ok I want
to give you an outline of the talk for
experts I guess I don't have to explain
what replay is but for people who not
are not very familiar with replay I want
to define it in a very simple manner so
that we know what we're talking about
and then I want to use a very simple
example to illustrate some of the main
challenges of performing user level
determinants to replay then I'll talk
about some prior art to allow you to
better understand the contribution of
our our techniques and i'll talk about
these are techniques specifically
specifically the three techniques leave
stri
and clap so leap was present in the FSC
ten strides in XE this year and clap was
presented in pldi a student research
competition so we know that probably the
fsd and eggs he probably are self
engineering center conferences so I'd
like to even more welcome the opinions
in this audience on the work that we did
then I'll make some conclusions so to
begin I like to first define what would
we mean by replay first of all when I
talk about replay in this talk I want to
talk about programs that use threads on
a multiprocessor platform and
communicates through shared memory so
this is a kind of very common kind of
threaded programs that we deal with so
I'm not talking about functional
programming parallel programs like
Haskell so this is a shared memory
multistrada programs so this is the kind
of program we want to replay so I like
to offer a definition I like to point
out that this is by no means a very
authoritative definition of what we
players this is our working definition
so that we can have a easier way to to
position our contribution so i define it
to be a technique that repeat a
previously exercised execution according
to some kind of diagnostic criteria so
that means that sometimes we replayed
the program to be able to time travel so
that we can go back to any point in a
program execution and start to execute
from that point so we we want to replay
for full execution and some other in
some other areas we want to just browse
the computed values of a previous
execution but we do not care how the
values are computed okay so in some
other some other scenarios we replay for
getting the computed values
and a third category which I argue that
most are replete technique we fall into
is for bug reproduction is for producing
a particular failure okay so so these
are the two just to show you some
different purposes or different criteria
that each replay technique will try to
achieve the basic mechanism replay so
the biggest the month denominator
despite the purpose the glow of the
replay technique itself is that you
always want to try to monitor the
application produce some log and we use
the log to try to reconstruct a earlier
execution so this is probably the basic
mechanism for replay technique in terms
of the research replay has been active
for for many years so the earliest paper
we can find we're not claiming this is
the earliest paper the earliest paper we
can find is the talks paper oops I guess
Microsoft is checking on me alright so
the earliest paper we can find the talks
paper in 1986 okay and we also all the
way to this year 64 our replay work so
it has been it's just the exemplary it
4444 showing that this research has
beginning of good has been going on for
many many years and the publication of
replay works spend in many different
areas for all the way from course of
engineering compasses conferences to
hardware conferences like mac like micro
or vee the good news is that if we
conduct research in this area we can
have many different venues that we can
publish papers of course the venues is
that we have to read the papers from all
these all these conferences first to
understand the state of steve the art so
so has been a long a very poor laundry
search area active in many different
areas so
replay technique can be implemented from
these conferences we probably can
already sense that it can be implemented
in hardware such as modifying some
hardware cache coherence messages or it
can be implemented in software at the
user level from a program
instrumentation or at the system level
where we modify the virtual machine to
enable logging of the low-level system
events right so it can be implemented in
hardware it can be implemented in
software a replay technique is called is
what we call deterministic if a
guarantees to reproduce a early run so
we call it a deterministic role play we
call it a probabilistic replay if it
only tries to reproduce or earlier run
with the best effort okay with high
probability so there's just some common
terminologies that we use in this area
our focus in our in our research group
is what I call deterministic a user
level replay for reproduction that's
rules there are some terms here so let
me just explain it a little bit better
um we thought we liked deterministic
replay because we think that it helps
the diagnostic process more effectively
and in addition many sort of a client
analysis required determining to replace
as cyclic debugging fault localization
of a concurrent programs or bought
classification where we have to run a
concurrent program again and again okay
so in that case determinism is a very
very good thing to have and also we like
user level replay because we think that
we believe it's very easy to use is very
accessible so what user level replay is
a program and take the Ripley technique
and take a regular user program
instrumented or transform it and just
run it right so the replay is going the
technique is going to monitor the
application produce a log and replay it
so
this would not affect any other
application and this will not require
any OS level system level or hardware
modification so it's very easy to deploy
so we like this characteristic as well
and we like a bug reproduction we think
that's probably the most common use of a
replay the reason why we replay is try
to troubleshoot try to find bugs and in
particular we focus on reproducing or
producing the order of race right so
we're going to illustrate that that's
basically the one of the major reasons
for concurrency bugs so we we focus on
producing an order of race so that
programmer can have an easier time to
diagnostic to diagnose the bug and it by
saying that we we can relax on
reproducing the original schedule or
even the computed values right so we
focus on the race order and we relax on
reproducing the schedule and the
computed values so this is a sort of the
focus of our technique so you can tell
me if this is more appropriately asked
somewhere else but it seems like those
goals are a little bit kind of against
each other right like if you do it in
the software there's a lot of benefits
to that but you're kind of getting into
the world of the program like if you
truly want to be deterministic you know
it seemed to me that you need to remain
outside of the world that the program
lives in so it just kind of seems like
software is really good but it kind of
encourages probabilistic deterministic
is really good but it kind of encouraged
you know
it encourages other other decisions that
are made so yeah I think this uh well
illustrate later that the software
approaches have some problems but it's
good for producing many many different
concurrency bugs it has this shortcoming
but it depends on how you define the
goal it right because it's practical
right I mean deterministic you always
want to German a stick but you'll settle
for probability if it's practical right
uh you have a point so I oh you missed
you later on for the challenge is
probably okay answer a question after
that okay
alright so so before I actually talk
about the details are techniques I just
want to want us all together to go
through a replay exercise so that we can
get familiar with some of the challenges
and also some of the terminologies that
we are going to use later on so our
ripley exercise actually is very simple
it's probably the simplest simplest
concurrent programs you ever see so have
two threads that both reading from a
global variable G and incremental
locally and assign it back to the global
variable G ok so these are the two
threads and if we execute the threads
following this order meaning that we
execute entire computation of t2 after
chi 1 we will compute a two for the
global variable G at the end ok so G is
too but if for some reason a statement
for is executed before statement three
due to a different kind of scheduling
will have g equals to one at the end ok
so this is a very simple example and I
want to illustrate that so for a four or
concurrent program the order of the race
or whether G whether stemming for is
executed before steam and three or after
sliema three is the key to 22
determinants to replay right so we have
to restore a particular risk order to be
able to produce the same program output
ok so this is a so this is the sort of
essence of determinants replay that we
need to catch or need to restore the
order of race as illustrated by this
example otherwise the computation
results would be different all right so
let me just illustrate a solution the
first solution is a very intuitive
solution is that we can just record
order for a star
rectly right so if the wrist the order
is important let's just record the rate
that the order so here suppose that the
order is that students for happens
before steam three and since we're doing
user level recording what is in store
some instrumentation code and try to
record this Reese order so buttery
bye-bye sort of inserting this
instrumentation we hope to produce a log
of 4 3 right so we read order is that
for executed first the followed by three
but again since we're doing user level
instrumentation our instrument our
instrumentation code also suffers from
the perturbation of the scheduling right
so that our instrumentation code can be
executed later than the other
instrumentation cone thread on t1 and
thread one this will produce a log of 3
4 right so if we use that log to
reproduce to replay this whole program
we we know that as shown by earlier my
earlier illustration that we're going to
produce a different result okay so this
is very simple illustration of the
problem with user level instrumentation
so common in the common practice is we
have to somehow make the instrumentation
at actual statement to execute
atomically or have to use some kind of
synchronization and for people who know
about concurrent programming we know
that adding additional synchronization
is really really bad here I want to
illustrate another solution that solve
the problem is that we do not use any
synchronization but instead i'm going to
record the values that we read or write
for each of the shared variables okay so
in this case we can record that t1 reads
g and the value is 0 and writes 2g the
value is 1 so from these values with a
sort of
reason that that the the first statement
with t1 cannot have an after this last
statement of t2 because the value is 0
otherwise the value would be one right
so is this very simple example to
illustrate that it's possible for us to
find a schedule given a threadlocal low
store value ah just by searching right
so just make sure we find a schedule
that is correct for example sequentially
consistent given that all has improve as
proved as many years ago that this
problem is in pc okay so we can do it to
it but it's an MPC problem so let me
summarize what the example trying to say
is that the example shows you a order
based of solution where we try to record
the thread access orders we explicitly
track all the rewrite dependencies are
and we can guarantee to replay the
execution but we need to use logs a lot
of them okay so this is really really
bad or we can try the search based
solution we can infer the rewrite
dependencies through the low store
values require no use of locks but it's
an MPC problem which means it doesn't
scale means that we cannot always
produce the reasonable schedule so it's
we're losing the determinism well it's a
it's a it's a it's it's not so given so
as I showed as I stated here given a
threadlocal no store value trace like
the ones that I show here to decide if
if if there is a schedule that
sequentially consistent is np-complete
problem so this is shown in siem paper
or 356 that's the yeah so you feel
assign a schedule order which one that
that executes the first if you want to
sign a total order to represent a
schedule for these statements is an MPC
problem if you do if you only have the
value trace okay ah so I illustrated
order based solution Illustrated a
search based solution and the prior art
for user level determinants replay is
primarily order based okay and the
representative techniques is called deja
vu and rec play and the let me just
briefly give you some information about
these really the work so that you can
understand our contribution a little bit
better so to talk about the related work
and also our contribution I'm going to
use a slightly more sophisticated
example as is the one here that we that
involves two branches and only so what's
interesting about this example is that
by only following the schedule we can
lead to evaluating both branches to be
true okay so that's the only schedule
that we can follow this is just shows
that we need to precisely reproduce the
schedule to compute the same result so
this is the example we're going to use
and the first sort of representative
work for user level replay it's called
deja vu it's a developer JD Choi which
is also a well-known name in concurrency
work so this proposal is is very similar
to the first order based example that I
gave earlier which is simply if we can
identify all the locations in the
program where the assured access a
shared variable or shared object is
involved in a computation we can
actually record the exact order of the
threads the access or exercise these
shared computations right so we can
record all of them in the global log so
we can record a global sequence of the
thread schedule that that compute that
the shared variable States so in this
proposal obviously works right but it's
pretty inefficient because it involves
synchronizing all the threads onto a
global log so in this simple example to
produce this log involves six global
things eventually these logs to lot to
log into a global log we essentially tie
all the threads together using a global
lock which is in current I'm overhead so
to improve upon that rag play is another
representative approach presented in
2003 talks is to use a LAN ports clock
right so from distributed computing to
main we know that LAN ports clock is a
pretty efficient way of clocking
distribute events so we model each
thread as a distributed process and we
model objects as the sources of
distributed messages right so if we if
you know about lamport's clock this is
pretty straightforward mapping from that
problem to this problem so what they do
is that they associate each thread and
each synchronized object with a
certificate with a distinctive clock and
this is the algorithm standard lamport's
clock algorithm for updating these these
counters or these clocks so for our
example well the details how we arrive
the two to this these counters how do we
compute these counters is not important
but the basic the technique is to
associate each share variable age thread
with a different clock with the
different
counter and at the end each thread would
maintain a local history of all the
counter values for all the shared
accesses to the shared variables ok so
um so in this way the thread only
so the it we call it the locals think so
the three only needs to synchronize the
monitor or the synchronize the
observation or synchronized logging if
the threat involves a particular share
the variable so there's no need to
synchronize across all the threats so in
this way we call it local
synchronization so reg play involves in
this example involves six local
synchronizations plus six compare an
update for updating the lan ports Clark
counter so our contribution compared to
the the prior art is to still try to
still try to lower the logging overhead
while staying deterministic okay and we
want also want to simplify the replaying
process and let me just talk about our
core techniques now in in detail so I'm
still going to use the same example that
only following this path lets the
schedule that we can produce this error
so I want to first talk about leap is
our a very simple idea that improves
upon the direct play work so the idea is
very simple instead of associating each
a thread with a clock we associate each
shared variable with a sort of access
vector so as the program executes we
just record the sequence of threads that
each share the variable seized during
the execution ok so we maintain access
vector for each of the shared variables
so here similar same to direct play we
require local things so each share the
variable is required to synchronize
against the threads that will only
synchronize with the threads that
involves the computation involved in the
computation or race against that
variable do not need to synchronize all
the threads so still its same
six local sinks in this example so the
way to replay is to actually you can
think of these logs as stacks and we're
just going to read the logs one by one
or pop the item one by one and use that
value to direct a user-level scheduler
so our user level scheduler can check
start to check if it's a if it is the
threads turn to read or write to that
variable by checking the top of the
stack so in here we just check if it's X
is T ones turn to to execute and the
next is that we check the top of stack
for y and shows its t2 so we switch to t
2 and continue to execute and then are
we continuously to check the log and in
this way it's very simple fashion in
this way we can when we consume all the
logs we can guarantee that the our user
scheduler will be follow the same
execution paths as the recorded run and
finally to produce this error okay this
is a yeah I have two questions first how
do you like my shirt variable we use
yeah we use the static analysis prior to
the to the to the run so there's a phase
of static analysis for identifying the
shell variables yeah we do it pretty can
we do it conservatively yeah and the
thing is um the main reason why you're
like a recording phase is faster than
the global
you are basically allowing parallel like
a recording that right that's right
that's right that's right oh it's a very
simple idea we wonder why anybody has in
sort of earlier but but none of the list
it's a state-of-the-art order based
determination a play technique it's more
lightweight compared to existing
approaches and we use static analysis
and biotransformation to actually
achieve all the like the questions that
you just asked we have a formal proof of
replay correctness which I haven't found
in any of any of the earlier papers and
we we contribute the first automated
tool available to the public for replay
which is very surprising we couldn't
find any other automated tool for
replaying but r2 is public available for
download and weaknesses of this approach
is also apparent there are too many
still too many synchronizations we have
six synchronizations although their
local ones and essentially when we try
to log these leads access vectors we
essentially eliminated all these
low-level data races even though many of
them are very benign or intentional
essentially we're forcing a sequentially
consistent execution of our program so
so these are the weaknesses yeah would
you do anything to try to optimize away
conditionals like because you talked
about how to execute a statement and
then do you know if I should keep going
then execute next statement is there
anything you do to try to you know say
oh I should just do the next five of the
stack you mean for the replay part or
thought that way
really part of we just we just execute
for whenever when we reach a shared
variable we will actually check the log
and to check if it's my turn to execute
so I just as I illustrated each time
yeah you know you haven't found the need
to put optimization like different
tricks in there yeah it's pretty well in
other words it's it's pretty slow so we
just we just force actually each each
each computation we had to check the the
log to replay yeah yeah we haven't done
any any optimization on it but our roof
Solar paper actually does some kind of
organization on it but I probably don't
have time to talk about it um so given
all these weaknesses of leap we have
improved upon it and and we propose to
use a hybrid approach to address some of
the weaknesses so this is approach that
we require the log the recorder to
synchronize on the rights but not on the
reeds so this is the main contribution
of this technique destroyed I call it
hybrid approach because it is order
based where we record right orders
similar was actually the same to the
approach of sleep and we match the
values of reads a recorded read sorry
it's order based where we have to record
the right order it's search based where
we'll record the values read and we
match those values with the rights
during the replay okay so this is a sort
of research element in the algorithm as
well and we use the right order to bound
the research found the search complexity
so we don't have this NPC problem it
actually it's a polynomial time okay so
the total number of steps to search
is bounded by KN where K is number
threats and is the total number of
operations so it's a polynomial search
so let me just give you some details of
how strike works still the same example
first of all the difference is that we
record sort of access vector for rights
only right so for the variables sure
we're both x and y we record the
sequence of threats on that involved in
that in rights in rights to this
variables at the same time we'll record
two values for each reads right so so
I'm going to zoom in on the on this
particular thing later on but right now
this is a sort of the log that produced
by stride compared to leap the right
logs is identical to leap and we have a
sort of two values logged for each read
so we call it a double log so let me
just zoom in on this double lock feature
of stride so this is actually the key
contribution of stride is that suppose
that we have different instances of
rights on a shape on the same variable
so in my example the series of rights
produce sort of writing a series of
prime numbers on a particular variable
and our reads actually for example in in
a recorded execution the reason actually
reads a second right which is the value
3 as i show you earlier if we want to
wreak lure a record exact order of race
we need to make sure the recorder and
actually the actual operation happened
atomically using lock and i'll show you
showing you that this lock is actually a
bad idea right we have to insert a lot
of block to do this in stride the big
version is that we do not need this lock
anymore instead i'm going to read twice
the first read is going to read the
actual value that that that committed by
the remote right and the second read is
going to read the about the sort of
diversion that when this this vide
commits it's going to return whatever
the version this particular does the
second reid returns we call this one is
the bound so how do we use those value
to to to to to restore the reefs order
so our purpose is to sort of restore the
order of race right so it turns out that
our bound number four gives us a search
found that it can we can only need to we
only need to match all the values
written committed by rights before the
version 4 ok so this bounds our search
so that's why we're polynomial and the
rest is very simple we just scan from
the bound backwards and find the match
by the value because we have the value
of reads recorded so if you well it's
very apparent that it's possible that ok
is for its established a very different
rewrite link than the original one it's
possible and we prove that this does not
affect the replay correctness are you
ready to find that more we prove this is
not affect replay correctness Lee yeah
the full proof is in the paper but I
probably I can give you more information
if the idea basically that it has to
read the same value yeah if it's from a
different right yeah he returns the same
violent even it's from even if it's from
a different right target but if the
users debugging the code that's still
going to kind of bring I mean I just
think about this from
tactical standpoint if they're debugging
the code and they're trying to find the
line in their source code it's causing
the problem if it's still going to bring
him there I consider the proof correct
right I'm just practically so before you
tell me that's the case I'm happy so
this is failure so this guarantee is to
reproduce the failure but our focus is
try to restore the exact tree sorter
that so that your programmer can
actually understand how that failure
happened and this in theory does not
guarantee the original original order
but give you one of the orders that can
actually leads to the same failure okay
so at least it gives them sounded yeah
give you give you a list and for example
another possible order that leads to the
same feeling yeah so so it does not
guarantee to give you the original
original order so let me summarize that
compared to leap on this particular
example we only need to perform for
synchronizations and we need to log to
actual values and two versions so the
big change is that so by recording with
bob i wo geng we do not require to
synchronize right so we have to where we
only need four locks instead of six so
this doesn't seem to be a lot of
improvement compared to compared to leap
a compared to reg play but in practice
this has a huge performance improvement
so it's very intuitive that so what we
found is that in practice improving in
in all the benchmarks we evaluated a
large majority of the share variable
accesses are reads so that's that's so
so so for example in in some of the
benchmarks such as Derby spec gbb more
than eighty percent of the shared
variable accesses or reads ok so think
about the number of the degree of log
reduction that
we can achieve using using stride
compared to Lee and the rights to shared
variables in our experience our are
mostly already carefully protected by
programmers because there are more
conscious about writing to a share
variable so our experiment our
investigation reviews that for example
in a benchmark called Derby more than
ninety five percent of the accesses a
potentially incur some kind of race
however if we only count the right right
race it's only fifteen percent meaning
many of the rights to the variables all
right already protected by programmer
this means that we do not need to insert
additional locks for these rights we can
already leverage so in the night in that
the performance penalty is very limited
because programmer already has a lock
for their rights we can just insert
instrumentation inside lock region
without inserting additional locks
another amazing finding we-well probably
very uh uh also others have already
observed the same thing is that the
contact switch between those two double
logs actually is not that frequent so
remember we do not require a log to
synchronize those two reads so in our
experiments more than ninety percent of
the reeds can be solved in the first
comparison that means there's no
contacts which even if I read the value
twice there's no context switching
between only 58 out of 400 million reads
in our experiments require for
comparisons which means there are four
different versions of the value that
inserted in between those two reads and
those numbers are based on those facts
those are
those numbers based on the subjects that
we evaluated so we can now say this
could generalize to any any program but
intuitively I think it's not that that's
surprising ok so the contacts which is
not that frequent for for each for any
for the excesses so for so we do log
extra values so the value logs are
separate from the version log which
means that we can take vantage of the
locality so there long long continues
array of the same value so it's very
friendly for compression so in our
experiments we don't find we generate a
lot of logs as well so this is actually
a summary of the one of these
expectations we did for leap and for
stride on the left side is about is
array of popular Java multi-threaded
java programs and the second column
actually shows the percentage of wreaths
of all the traces that we collected so a
large portion of them of these of these
operations are reads so that's where the
technique stroyed can actually help a
lot so the first the third column shows
the overhead of of leap compared to the
original execution so in some of the
subjects such as Derby you can see that
the leap already has only ten percent
overhead for recording and the last
column shows the overhead of a stride
and a you can observe that it's
significantly faster or significantly as
significantly lowered the recording
overhead compared to leap okay in
particular in this in this in this
subject Modine leap were encouraged 100%
a hundred times over head where stride
can really drive it down to 1.5
okay so this shows that to relax on the
synchronization all the reads actually
has a huge performance impact on the
recording overhead sort of the last
technique I want to talk about is called
clap it's a solver based approach which
we go a step further to drive down the
recording overhead in this approach we
do not require any synchronization okay
and we record only the branch choices in
other words we do the past profile and
we can choose schedule by solving
constraints so this is ongoing work i do
not have full-blown detail and our
evaluation might be still premature but
the idea the core idea is presented at
the prd I student research competition
and actually won the first place so the
basic idea of clap is not to use any
synchronization at all so let's just
record threadlocal pass at one time
that's all we record is the local path
and then we can construct the execution
constraints on all the share variable
computations using symbolic execution on
the path and we use SMT solvers to
compute the schedule ok and in in more
specifically we have passed constraints
we have program order constraints
partial order constraints rewrite
constraints and we feed it to a
constraint solver to compute a global
order of shareable excesses and the good
news is a power passed from filing for
is pretty lightweight it's a it's a it's
a classic technique that people really
work hard to optimize okay for example
the boris profiling is only thirty
percent
so let me just give you some basic
high-level steps of how we approach
recording in clap so same same example
we first record all the branch decisions
okay so in this case we record branch
decisions and we collect the execution
path for for each thread and we next
step is that we try to encode the
constraints based on this path we have
different kinds of variables we have
very symbolic variable for shared
variables instances for all different
instances of share variable accesses we
have s variable that symbolically
represent the value returned by remote
read and have order variables represent
correspond to each of the sheer variable
instance to represent a position in the
global schedule its corresponding
position in a global schedule okay so
bottom I'm showing how we construct the
constraints the first order country is
just program execution order it's very
straightforward and the rewrite
constraints basically saying that I'm
trying to match the symbolic variable
that represents a remote read and when
I'm trying to match it with actual
rights okay but there are possible
instances to match to for example this
one that when I circled can be
potentially matched to its local right
or to a remote right okay so it depends
on the actual pairing I can construct a
different order constraint for the other
variables so if you don't do not bother
with the detail this basically says if
that variable correspond to the local
right
these rights are d xdd program the the
the computation of the other thread must
happen either before completely before
that first right or completely after the
actual read okay the only differences in
the programs that you're observing or
whether or not the conditionals
evaluating true or false right right so
then you can actually have so okay so
there are certain executions in which
for example y is equal to one on the
right hand side and so I so you're
saying but observing the control flow
you are getting constraints on the inter
thread execution because if so this
example 6 executed and then 7 executed
then you know something about why
changing and so that would require some
sort of race it's on the right hand side
so we use the control we use the control
flow to compute I thought this example
doesn't doesn't show that it's
explicitly actually computes the are the
constraints for each share variables to
be executed first but you're not local
companies are recording the values of
variables not recorded so the problem is
if you don't branch on if you don't
branch on some shared variables value
how will you be able to reproduce the
race we use probably you castle is right
but we use a low store well maybe I just
understand it that you do have orderings
of the shared variables here is that
what you want to compete you don't have
so the purpose of computation is to
compute smellies for these oles for
these orders to assign a global array of
integers to these days but these
variables it's ok i guess my point is if
you just have straight line code no
conditions then there's only one pair of
each side so what do you do in that case
then we don't have the past condition we
only have all the confidence and you
mean right off it so services then
actually so in that case you basically
say any interleaving is possible like in
that case you just observe these two
threads executing but you don't but
actually all the newly things are
possible in that case basically you have
you have min Wallander Liam's that are
consistent that are consistent with the
values example you you have have a back
property right so schedule have to
satisfy his back property then you have
another constant here
right i'm just saying that that that in
the case we just have straight line no
conditionals yes and just a bunch of
assignments to share variables and then
leads you're a lot of possibilities
right sometimes is sort of a predicate
okay straight assume there's some
predicate okay some predicate you have
is embodying execute that form other
constraints and and so is there so
there's at least one predicate that
tells you so yeah there's one predicate
yeah yeah that's right so very purpose i
think this is a simplified
representation of what we did but this
is the core idea is to encode different
constraints symbolically and while on
the top i'm giving all the constraints
for this particular example and we fit
it to the solver and then the end the
solver will return a integer assignment
to all the older variables to represent
a position of a particular access to a
share variable in the in a global
schedule so this would be the order
variable and we will just use this
variable and a user-level scheduler to
to to to replay this program
so let me just summarize the
characteristics of clap so we think the
most important contribution we make is
to reduce multiprocessor replay to
solving two well-known problems one is
the thread local profiling and the other
is automatic they're improving which are
really a very developed areas or very
developed techniques and we have also
formal proof of why the replay is
correct so that the schedule computed by
club is guaranteed to reproduce the bug
depends on wrenching then it's not right
for example if you have like a null
dereferencing you too late erases then
since you have not recorded any like a
values then I think you work you your
schedule does not say peach order has
enough hurtful because that's about two
yummy that's a neutral yellow bug under
song so much sugar but what I mean
generally I think you're also pushing
off alias analysis to your constraint
solver because in your simple case with
scalars it was great but when you have
pointers in direction since you're not
recording values you can't use value
difference to disambiguate pointers
generally there's a rule that if star p
is not equal to strike you and P and Q
dumped alias like which you can that's
used to your advantage when you're
recording values but you don't even have
that so you're also going to have to put
all the aliasing are not a lacing
constraint sign into your improve your
to ask it to also resolve potential
alias yeah that's that's true chance so
you're pushing off a lot you're making
your runtime cheap but you're pushing a
lot of problems out there the third
movement which is not bad but but I just
sort of wonder I mean it's not just
about the you're going to have to have
some memory model but to reason
aliasing is like in his case you may or
may not get the error depending on
whether some alias occurred or didn't
occur earlier yeah the aliasing is
definitely a problem and I think CLE
gives us a lot of symbolic
representation of the pointer values but
well but there are some problems with
with the race it's stuff like that and
yeah doubt that we admit it's a problem
for us to buy including those are all
over by having those order variable
another advantage of our approach is
that we can represent different relaxed
memory models very easily for example
TSO tso models and we just sing quote a
different order constraints into our
constraint solver to be able to address
the box in these relax memory models
another interesting characteristic is
that same as the work of chess we can
include to bound the search or bound the
to give easier time for the constraints
our we use a context switch bound
preemption bound to reduce the search
space basically because we can provide a
constraint on the sum of the Delta of
the thread local consecutive order
variables so that we can some of them
and and put that as a constraint into
the to the constraint solver so that we
can ask the concerns our only two to
give us a schedule within a certain
number of preemption bounce so this is
another way for us to to be able to make
computation tractable this is a
preliminary evaluation result for cloth
and these are the some of the subjects
that we used and the clap is completely
implemented on llvm so C programs
different from our my earlier subjects
okay so it's all C programs will observe
is that recording overhead ranges from
10 percent to around two hundred sixty
nine percent so we also implement the
very for evaluation
this is the version of leaf on a la vm
as well and will preserve some
significant reduction which is as
expected all right so I guess uh let me
just make some conclusions I want to I
hope I I sort of highlight the
challenges of user level determinists
replay is that we want to reduce the
recording overhead I want to avoid some
Heisenberg effect where the
instrumentation make certain type of bug
disappear we want to also reduce replay
complexity although in this talk I
didn't have time to talk about and I
present three techniques leave stride
and clap and a future work we'd like to
focus on things like aventurine programs
we will very much want to address how to
reply long-running systems and also how
to relate this tribute a bug in the dish
view systems okay so um so thank you
very much and thanks a lot for your time
and attention for more information about
our research this is my homepage and
maybe I I think I took a little bit long
but thank you very much maybe from clear
bags and suggestions I'm curious about
your plans for future work can you say a
little bit more about what you're
planning to do with event-driven
programs I mean what kind of programs
are you referring to when you say
event-driven programs so uh so I think
about to type of aventurine programs one
is the low level you mentoring programs
the most famous one is the linux kernel
things like that and and for my bright
background I'm more interested in
addressing event-driven middle earth
systems for example all these messaging
systems where debugging them is very
very difficult so I have some
preliminary ideas but my surprise is
that there's maybe I don't know yet but
I don't know of any replay work that
address this kind
system so so that's why I think it's
worth investigating I think that one
challenge here I have sometimes thought
about this problem is that in the when
when when we start looking at you know
multi-threaded systems there there were
standard libraries that programmers
could use to express multi-threaded
computation send the open source or the
UNIX phone we had this P threads right
on windows there is the win32 library
and Java and C sharp they all have the
standard API but with these event driven
in this event driven world it seems to
me that there's just a huge variety of
of primitives and libraries so it's kind
of hard to imagine which one should you
target can you see anything well we
start with well there there there there
I think the world is not completely
chaotic for example there they are they
also well defined type systems type
based messaging so that we can have some
kind of information about the semantics
of the messages it's it's not an N and
there's also standards like Java
messaging system it's a standard so so I
think we have some ground to start it's
not really completely chaotic but but
unfortunately i don't have further
experience in life I just feel it's a
great need to have that
you have not shared the elected actual
like analyst time for be all flying how
was that I mean was it really like I
scalable two weeks salty it's scheduled
problems so the complexity its name is
chess it's exponential to number of
threats to enumerate like understand da
like the complexity in a serious but I'm
just asking in your practice have you
can really like the Rex acute and we
play the prickly the execution in a like
a reasonable amount of time yeah for all
these subjects I list here we can
actually yeah so I think I want to race
against the time so I didn't explain it
so the first the second column is
actually the the time taken to reproduce
the pot to trigger the error for for
these subjects including my analysis oh
no this is only the plugins are carding
overhead yeah and the time taken we have
a table but I don't I should put it on a
backup slide for the firsts when you
free posted six programs maybe finish it
within one hour
and for the last 12 days
what are the last ones they like run
overnight it'll be difficult to mini
connects bitches need to explore that is
like really like a special benchmark
that one to us i call it does yeah oh it
doesn't it's just kind of like a
strength testing whether like every
place into that your works or not which
one is that that is racy the last one
it's so worse than its it's basically a
race with all the talking so for that I
think it's a special well that's the
only benchmark that we are unable to
produce the schedule but hopefully in
rural programs none of the race
condition is like that real application
so all these subjects are small but they
are carefully constructed to to to
produce a concurrency error so in terms
of replay difficulty I don't think
they're more easier than the real were
larger benchmarks but we're still
working on larger benchmarks you said
you're using please yeah so you're
actually do using plea them to do
exhaustive enumeration to find the path
so you're not going to be truly doing
symbolic we modify clean now to
duplicate the states because we have the
past we just use it as a engine to give
us the constraints along the path right
this is Suzy so you're using pleating at
ulah intra thread path constraints yeah
but then to that you have to add all
these other constraints right so then
those are being added in right
I see so you're going to you're going to
likely execute to some point or you just
I don't quite understand so you're going
to just take the all of you have the
separate thread traces you're just going
to make one pass with cleon each to do
to get formula per thread right and
anyway one big hole to the solver or
basically will after we collect the
pasco students or a stress right and
then we conjunction them and then we
encode all the other extreme cautious so
there's one big old definitely want
there's one big club right okay and I
call if it comes back we'll give you a
model for the word variables credit
interesting sue so that actually so that
trace then so unlike the YouTube a
typical use of clean our sage is that
you let go until the first branch and
then you say can I go a different way
you're not using one's legit right he's
having a normal prosecution and I just
want the path constraint a trail that's
what the whole time and furthermore
furthermore that's why you get into this
issue of symbolic pointers to because
CLE is not doing everything symbolically
you would like it to make more things
symbolic probably cetera but basically
we need to mock and she'll get a note
loads tradition body but because CLE is
clear I mean as i understand it will say
to you you sort of Mark some bit of
status of all is that correct but then
there's all this other stuff that you
want actually to be symbolic that if
clear just to treated is default way it
would not be simple we're going to be
different you because if we don't great
yeah we have to address
to sit pallet embody address public so
you need you need to make more things
simple cleaners essentially like
scissors trying to find changes to the
input bytes spring that will pull us the
sequential program to go a different way
right but in that case they have all
these global memory accesses who's like
for a single thread it's it's just like
a function of the district leaders extra
data because then analyzing each thread
separately there's this extra data they
want any sense about it here okay is
that correct so could he has its own
symbolic memory representation yeah
actually emulates the sort of the memory
assignments yes right as well so so it
gives us it gives us some kind of idiots
information but not for all the
variables yes it doesn't interest yeah
it doesn't solve one race you definitely
want to do partial I mean you definitely
want to do reduction on this on this
trace so that you don't like look at all
the possible so that points4 am sure
there's the research group at NEC labs
yeah they do stuff like this way I was
telling them about the I mean like month
malayan a yatch omelets and chow and
gabby's damage they don't have this
bloke there they're doing something
different because of the local stuff
generally there what happens is you
record a partial order of a parallel
execution then you have you search for
other schedules that that obey the same
constraints but might find above I said
right ok so as I have this alert is he
open it's different it's a different
thing
definitely a lot of room for
optimization but the key idea is to to
pass for falling and then do a small
execution on that pass and solve the
constraints and all the path profiling
though I mean it's you're really doing a
full instruction trace well pass I mean
go party over the past I think that is
the path decisions right goodness right
yeah I would not don't I wouldn't i
would talk about description cookout
okay cool thanks again thanks a lot</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>