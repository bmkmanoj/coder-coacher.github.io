<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sensing without Sensors | Coder Coacher - Coaching Coders</title><meta content="Sensing without Sensors - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sensing without Sensors</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/tsTi6oR34Bk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi all thanks for coming um it's my
pleasure to introduce John Candy today
from Berkeley he's a professor of
computer science and his research is
near and dear to our heart because he
marries HCI with machine learning with
signal processing and even big data and
he's focusing these days on health and
education primarily he'll be talking to
us about those topics today and some
news about Berkeley John's participating
in sponsoring the creation of a Jacob's
Design Institute which is supposed to
open next year twenty four twenty i said
yeah i did say next year 2015 2016 sorry
that's kind of cool that that's
happening soon so welcome John thanks
Mary and thanks for the chance to talk
to folks so today I was going to talk
about some work we've been doing for a
few years on the opportunities of
sensing with without sensors or at least
without things that we normally
recognize as sensors and most of the
work has been directed at sensing some
sort of effect most of our work has
actually been on stress we did a little
work a little bit of work on pain and
some work that had a focus on depression
and mental illness the signals though
are quite similar that we end up being
able to detect and we're currently
starting to move from the sensing and
detection into interventions based on
what we find in a sensor data so to
quickly review stress stress is a very
important and very global regulatory
mechanism in human beings that helps us
function at enhanced performance when we
need to that's how we pull all-nighters
and make conference deadlines but it has
negative effects obviously as well if we
leave it on too long because basically
our our stress mechanism is a trade-off
between fight and flight ability our
ability to respond accurately and sort
of it exceed our average pretend
chill briefly and all of the important
regenerative and repair functions that
we need to do as well so we have it's a
complex system but roughly there are
fast and slow components of the stress
response the first one is the adrenaline
or epinephrine response which is when we
get excited our pupils dilate we are
ready to spring into action and it
happens very fast for obvious reasons
you're going to fight or flight you
probably should do it soon and then
there's a slower response which is to do
not well largely with shutting down or a
sort of toning down the rest and digest
functions and and so this mechanism is
is perhaps the one we should be most
concerned about because when that kicks
in over long periods of time that's when
we start have trouble okay so two
different physiological responses and
they tend to have two different types of
signals that you can observe in the body
in response to them and I'll just
clarify for those of you that know is in
both cases I'm talking about parts of
the sympathetic nervous system the so
both of these parts are enhancing fight
and flight and reducing rest and digest
there's a complementary system that
helps with your regenerative functions
but we're still we're only talking about
the negative side or the stress Siyad I
guess on this slide all right so we have
these fast chemical mechanisms and then
the signs that you see in the in the
body are heart rate increasing with the
with fast stress response and breathing
speeds up pupils dilate we improve
memory retention and some types of
recognition and our emotions are
typically intensified amplified and then
the slow mechanism interestingly the
heart rate variability this sort of
variance in heart rate changes with the
slow stress response we get galvanic
galvanic skin response changes little
pulses effectively of changes in skin
resistance with perspiration breathing
becomes more eccentric often and we have
muscle tension so when we say we feel
tense because of stress that's a that's
not just a kind of an illusion we really
are tense many muscles in the body
become tensor in response to stress so
heart rate variability although we're
not primarily trying to measure it this
is the the gold standard that we do in
the sensorless work so I just to quickly
review what it is when we talk about
heart rate variability we're typically
talking about different measures of
variation of the inter beat interval so
and this is a very complex topic there's
lots of different measures the simplest
one to understand is just the variance
or standard deviation in that actual
number from a suitably measured peak in
the heart waveform and the others are
quite quite a bit more difficult to
explain low frequency high frequency
ratio which requires us to Fourier
transform the interval signal but anyway
this one the first one is easier to
measure but it's it's harder typically
for to provide physiological
justification for and biological
arguments have been made that this more
complicated measure it directly measures
the ratio of the sympathetic or stress
response to the parasympathetic or rest
digest response so yeah and so I'm
bringing it up we will say more about it
later it is a measurement that we made
as part of our study of sensorless
sensing
and the hard way we use is a is an older
project called the tricorder or Berkeley
tricorder and that was a custom sense so
that we started building I think about
eight years ago and can probably see
some dates on here this is a 2008
version it recorded all of these vital
signs so in particular we had a heart
waveform signal and it would both store
the data on a flash card or also stream
it out on bluetooth and it recorded a
lot of other measures that we we didn't
use for this study okay so having done
the work on the tricorder by the way we
we became quite quite enamored of the
idea of not using Hardware sensing
however sensing is obviously hard to to
do it's challenging there are lots of
adoption challenges even with fairly
simple technologies like wristwatches
and so on so we really started to focus
on measurements that we could make him
implicitly from people using existing
electronic devices in the way that they
would normally use them so we did some
work that i will describe on monitoring
of voice on a cell phone typically
during phone calls and we also have a
sensor in our lab which i won't talk
about but we have the ability to also do
both location analysis and also affect
analysis on voice signals of people in
the lab at berkeley and the most
interesting stuff which is current work
is looking at motion sensing from the
mouse from people using a mouse on a
desktop potentially using a trackpad on
a laptop which we haven't done yet and
another similar kind of signal which we
we do have measurements of in which
we're analyzing right now is the
accelerometer on a phone the phone is
quite rich and it includes study use of
the phone we're interested both in the
passive signal of somebody just holding
the phone in front of them are looking
at something the
tapping signals from interacting with
the screen widgets dragging and so on
all of these produce a signal that is
can be analyzed in a similar way to the
mouse signal and finally there's a lot
of opportunities we're not pursuing this
but a number of other people actually
one of my former students has been
recently looking at camera sensing on
cell phones for pulse measurements for
stress also there's a lot of opportunity
today we're not currently following that
though okay so speech speech encodes
stress in an interesting way it's
without I'm not an expert but as I
understand it part of our response to
stress is for the vocal cords to pull
away and basically open up the the
breathing passages so we can suck down
more air rapidly so those stress-related
muscles actually pull on the vocal cords
and change the shape of the glottal
pulses when we speak so and this
particular signal happens to be very
accurate at predicting stress we got
about a ninety-five percent accuracy and
what we were measuring was a controlled
experiment where we deliberately
stressed the subjects and had them in an
unstressed state and then we looked at
the accuracy of this signal in
predicting which state they're in so so
it would be nice it's desirable to do
analysis of that signal on the phone but
it turns out to be computationally
challenging because it has an an inverse
a fairly complex inverse problem to
solve because we're interested in this
signal which is the vocal cords
basically flick flickering I suppose
that's the signal that produces our
speech but before we hear it it goes
through the vocal tract and basically a
complex filter is applied by the way we
shape and make phonetic sounds so what
comes out
is a lot more complex than the little
pulses more or less isolated pulses that
are going in so at the task to do this
analysis on a cell phone is to model and
invert this transpose so notice that we
don't know what the filter function is
because it's varying as the shape of the
vocal tract varies so we have to both
estimate it and then try to undo it yeah
yeah I mean stress that we were able to
induce with math problems yeah short
term stress well you know I okay to be
to be a little bit clearer d there is
there are both kind of probable add a
probable adrenaline probable coral
flower responses in the stress response
that we measure so it's not purely
short-term and in fact the experiments a
lot of the experiments we don't have
have had more than a five minute lag
between the stress or in their
measurements so they're more likely to
be from the slower response yeah well
this is more detail than I need but but
there are a lot of features that
contribute to stress analysis the one
that works really well though is the one
that's not on this page which are the
the glottal features those are the ones
that are d convolving so to remind you
we those tend to be more than all of the
other ones on the other screen combines
so we basically did some work on
accelerating so that we have an
architecture for doing general speech
analysis with all of those features but
the the features on that list were
fairly easy to implement because we use
the existing tool kit called open smile
yeah the kind of classification feature
so you're looking at
recognition well them so some of them
are essentially it's a broader set I
mean speech recognition tends to be
built on hmm models on there mfc CSM
FCC's are the more or less the standard
features at the front end of a speech
recognizer the other ones tend to be you
know pitch per se is considered more of
an effect signal than a speech
recognition signal the lot of these
things are the people at speech
recognition people try to avoid because
this this is highly variable between
male and female speakers and children
and so on so speech people try to you
know in a sense speech recognizers try
to factor out those effects but we're
very interested in them from an
effective point of view but for pure
speech these are basically sort of
filter banks nonlinear filter banks and
then they go through HMMs to basically
track the little trajectories of
phonetic cessation of speech when we do
recognition we're actually using these
more as like static features so again
getting more at this kind of general
average shape of the vocal tract which
is probably a better cue to effect than
dynamics but there there are some
dynamic features that we so my student
did a course project one of the things
that he was trying to measure was using
the speech features and a simpler hmm
basically measuring speech rapidity so
the number of phones per minute and also
the durations of pauses because pauses
are also a sign of stroke diminution of
pauses as the strain of stress as well
so yeah there is a little bit of stuff
that you can get from higher levels
phonetic analysis of speech but we
didn't do much of that and we didn't do
any analysis of the content of
recognized speech either which could be
a good could have also been a good
signal yeah
stress you you also have a normal term
of off switch
then you try you use this sort of as
enough
yes yes so when I yeah ninety percent
I'm saying the experiment would Inc was
a counterbalanced experiment where
people die to start off or they'd rather
be sort of pressured into a stress state
and then relaxed or they go the other
way around and so we were comparing the
two signals for each speak I'm sorry
actually no the ninety percent is a
speaker independent measure so it's
actually a very very strong measure I
need to keep the experiment straight so
that was a remarkable thing about our
work and the work before which is the
the stress measurements are actually a
speaker independent so they're
surprisingly strong the work I'm going
to talk about later is is / a train /
subject but the the vocal speech
features are robust and and you can get
those accuracies in a speaker
independent way surprisingly yeah no
it's not it's yes so that's not yes so
so the point is that almost all the
recognitions based on that or the most
of the accuracy comes from that the the
glottal features which are more much
more speaker independent that the
changes in them and more speaker
independent so but yeah so those there's
a good questions so here's the the
framework that we built onto a phone
platform mmm these again most of the
features came from a the open smart tool
kit which is an open source speech
processing tool kit and our
classification was just simple was
linear SVM's built on those features and
the toolkit I think we have the accuracy
figures with a let's see where are we
yeah this is so these figures by the way
for recognizing a discrete set of
emotions rather than stress
the numbers are lower but also their
their multi-way classifications so you'd
expect them to be lower the numbers for
the stress and figures down here are
with and without those global features
it's a bit misleading because you see
only a one-point increase the point is
though that that's a very large increase
at that level of accuracy and also when
you look at this recognizer it's using
mostly those those features so they do
contribute a lot to recognition but it's
still worth pointing out that that the
distress features actually remarkably
strong compared to say recognition of
emotion recognizing stress is relatively
easy and for it certainly for machines
probably for people to I suspect if you
really ask people a lot of people I no
claim that they can tell certainly
relatives claim they can tell when I'm
stressed so okay so that was mm so what
we did earlier on now recognition of
stress from voice and I should point out
that there was related work by others at
Georgia Tech honor actually
discriminating depressed and
nondepressed patients from very similar
signals and they also attained
accuracies in the 90s for detecting
depression chronic but their population
was they had a control group in a
clinically depressed group and the
signals were very strong between those
two yeah question I certainly feel like
my stress levels
yes do these do these signals are pretty
nursing yeah so yeah so all of the
measurements are going to be
quantitative measures so I'm quoting
accuracies in order to get together well
actually I'm these accuracy measures
here are you know assuming some sort of
thresholds being set Rock area is kind
of a measure that is the set is
capturing the accuracy as you vary the
threshold so rock area is normally used
for a quantitative measure of some some
kind of feature and it it it tells you
that that this should work over a range
of different values so it is a useful
quantitative predictor okay so so the
most recent work we did was on motion
sensing because the voice work is
interesting but there's a number of
issues with it requires somebody to
speak at regular intervals if you want
to track stress it can potentially well
it suffers from the usual challenges of
speech which because people will often
do it in a noisy environment in fact
people will deliberately avoid often
quiet environments like their office so
they don't disturb people and on the
other hand things like computer
keyboards and mice are tremendous
potential tools for sensing because
people use them so much and they're
using them also in a context where their
potential stresses are actually hitting
them at the same time so so we started
looking at phone sensing and gas jumia
Mouse sensing and phone sensing so we
have a system called Mouse stress which
looks at the stress induced increases in
muscle tension and as I mentioned there
there has been work documenting stress
certainly in the neck and shoulders but
also in the arms and people specifically
looked at stress during computer work so
there's a very large literature on
this is just a couple of references that
have kind of told us the obvious that
yes people do have muscle tension when
they're stressed and it's measurable so
so when good ground for trying to do
this and so then to the study our goal
was to see if we could measure stress by
looking at fairly typical mouse
movements such as moving and clicking
dragging and steering steering maybe is
less common one but does show up
steering kind of mechanically it's one
of the best ones for making the
measurement it's not as common but it
would include things like tracing your
way through kind of nested pop-up menus
so we have not yet done a naturalistic
study on real interfaces we did it more
I suppose rates theoretical study where
we had controlled tasks with varying
distances for people to move and varying
size targets and so those had similar
dimensions similar geometries for the
direct for the clicking task and for a
dragging task where the idea is to move
that target on to that one and the
steering tasks look like this these are
also common tasks that people have used
often in other studies of mouse
performance so our target sizes were in
factors of two across a fairly large
range of this is pixels the big fraction
of the screen perhaps a fraction of an
inch to several inches for the movements
and I guess there were five different
values for distance and for different
values for width again more or less very
similar to what people do in other cut
types of mouse study so when we want to
analyze the mechanics of mouse movement
we adopt a sip very simple but
nevertheless fairly widely used
mechanical model which is a spring mass
damper so in biomechanics is fairly
common to concern
muscles more as adjustable springs
rather than electric than some kind of
motor that supplying controlled force it
does seem like muscles when we activate
them that we typically activate them in
pairs with a set point and there's some
biological damping that causes the
muscles not to oscillate when we do that
so it's a simple system it's
characterized by a second order
differential equation which means it
basically rings with a diminishing sine
wave so that's all we need to do we want
to though infer those model somehow from
the data and the data is going to look
like this these are some recordings from
in one dimension from those mouse
movements it's interesting you can see
people very visibly hunting and making
several different adjustments most of
the time but the the dynamics of the
models are encoded in the curvatures of
these little segments here and we use
LPC which is a standard signal
processing technique in order to infer a
second order models that match those
trajectories yeah for different types of
Congress
with the files well we because we're
trying to model the the arm itself
intuitively it should work if with any
sort of position sensor or velocity
sensor or acceleration sensor and
because it's really the mechanics of the
the arm rather than their but if you
yeah but if the if somehow it's a I see
what you're saying yeah if it's some the
tracking device that doesn't involve
perhaps movement of the arm then yeah
that's yes we have to look at that the
hope would be that because the muscle
tension seems to be a fairly global kind
of an effect it would might also apply
to fingers but it's yeah that would be
worth checking because it's not obvious
that would work so from this and we fit
the second order model so LPC as a model
it's commonly used to fit second order
differential models to signals that it's
very efficient you basically just need
to extract a few local correlation
coefficients from these signals and that
gives you a second order LPC model which
has very simple relationship to the
parameters of spring mass models so
these are parameters that you can get
from the LPC model and then those
translate directly into stiffness and
effective mass of the mass model though
it's we can observe our trajectory
generate the second-order LPC model
coefficients find some roots and then
derive mass spring damper parameters and
none of this is expensive to do
computationally so it's easily done as a
little background process on a PC so we
designed an experiment to try to
quantify the the accuracy of this and
it's a it was a counterbalance design
our goal was to have for each subject
because we didn't know whether we how
strong the signal would be we wanted to
have some measurement periods for each
subject where they were in a stress
state and an unstressed state but
because it was a one hour experiment the
was rather compressed so people would
enter the experiment and have a calming
phase to try to get everybody to a
similar state and then we they had to do
a challenging math task which was
stressful for most people then we did
the first Mouse measurement where they
were given these pointing and clicking
tasks pointing a dragon tasks then there
was some kind of calming exercise given
to them for five minutes and finally
there was the second mouse measurement
phase and and the final exit coming
required by our IRB so that's the the
first condition for subjects and half of
the subjects were in the counterbalance
condition where they were given an
effective karma first then given the
mouse task and then finally the stressor
in the second phase so one thing to note
about this design is it's not it wasn't
ideal in terms of giving us the best
stress signal to measure with the mouse
because we actually had separate phases
of the stressor itself from the mouse
task so the measurement in the stress
won't actually concurrent and that was a
choice we made in order to make sure
that we had a very good sort of robust
stress signal here we basically used the
task where people were concentrating on
the math problem that was similar to
what people used before in other stress
studies so we could have tried to give
them a mouse task at the same time but
the concern was that might have
distracted them maybe they weren't
really stressed we thought it was safer
to produce real stress which we could
validate with self-report and HIV
measurements which we did and then see
what we could get from the mouth
analysis later so we we expected a
certain amount of decay and in fact
there was some decay of the stress
signal during the mouse measurement
phase but it was nevertheless strong
enough for us to get to get reasonable
results in fact was considerably better
than we had expected
so I think this is all just saying what
I just said so yeah so we wanted you
know again to have a valid validation
that the stress the stressors were
really working so subjects were given
self-report questionnaires at a
beginning and ending of each phases it's
important to point out that was sort of
her practical reasons we had to give
them the service when they were
transitioning from one behavior to
another those were very reliably
significant and you can see that
although there's a label here saying
this dress and the surveys were taken at
stress and calm stages what actually
those numbers represent are the averages
of their questionnaire sorry those are
actually the average of the
questionnaire responses at the beginning
and end so we called we called the the
stress questionnaire response the value
average between here and here so it was
supposed to be something in the middle
here similarly the the M stress signal
was an average of the readings before
and after the phase alright so what we
observed was that the the difference in
stress was higher during the active
stress phase relative to the calming
phase so about twice as the difference
is about twice as big there as it was
here about roughly a 2-point difference
versus a 1-point difference oh so in
fact there was some decay of the stress
signal you know over time once the
stress or was removed so heart rate
variability we were measuring
continuously all of the subjects were
hooked up to our tricorder instrument
and we measured heart rate variability
and basically the results of sort of all
the math we we worked hard to get them
to be a bit cleaner than this but a
reality of heart rate variability is
it's a very difficult signal to get
consistent answers out of every
reference we've seen on that on the
particular instrument has similar
results the best result was actually for
the fast response the the basic heart
rate difference was the strongest signal
not the variability at all yeah there
was a huge difference in the two
measurements so we actually went over
the data a number of times to check that
and it's actually it's a very strong
signal and it's really there
realistically none of the other measures
i would say reliably reportable although
we have some significant results here
we've got a we took seven different
measures and if you really want to have
a significance of point 05 when you're
taking multiple measures you need to
correct and the thresholds would drop
below you really should be working at
point O 5/7 so these effects you know
aren't really strong enough to be
reported you're having too many chances
to succeed I would argue the other
rather disturbing thing is that these
signals were arguably you know that
marginally significant maybe is one way
to say it there were some others over
here though which were especially this
one and there's one up there too which
are actually about as strong and they're
in the wrong direction so heart rate
seems to be saying people were more
stressed in the calm face and again we
went over this data a lot and while
there is some outliers a lot of it is
coming from a little bit of motion
artifacts which we weren't able to sort
of reliably eliminate that is we
couldn't we couldn't define criteria
that said we
can throw this data out and keep the
other data so I the high order messages
that we tried our best to get good HIV
results for this data set and we got one
which was actually a fast stress
response all of the other sites they are
not credible and the lasting says that
when people do heart rate analysis there
all of the formal work does involve hand
clean up so it involves trying to
eliminate the worst phases of non signal
and the worst outliers of of these
values and in spite of doing that we
still didn't get a reliable signal in
heart rate variability so yeah so there
were several measures but if you
actually factor in bonferroni correction
they were they were less strong in the
a.m stress but none of them I think
we're reliably reported and some of them
were actually in the wrong direction so
not a good result all right so now to
the the measures that were derived from
the dynamic measurements from the mass
spring model here we got much more
credible results and just to remind you
these measurements were made in the
aftermath periods em stress and M comes
which are actually the inter was right
after this dresser or the calming
influence the the absolute values of the
signals are pretty small but you'll see
on the graphs that those are actually
they're the parameters that cells are
clustered around those values and when
you see differences like that they're
actually quite good so we do get a
reliable difference and a nice strong p
value and then they go in the right
direction in other words people are more
tense when they're stressed and these
are just simply some different
parameters these are the actual
frequencies of the damped response these
are the damping
parameters was less clear where the
damping parameter should be smaller or
larger when people are stressed and our
results were not really very conclusive
on that and as a reality check you you
might expect people to be a little bit
faster when they're stressed but we
didn't get a robust signal endorsing
that in fact we got virtually no signal
okay so um and that what I just showed
you was the aggregate across all of the
pointing dragging and steering tasks it
didn't matter if you broke them down
they are individually significant in all
of the cases as long as you use the
frequency features so yeah so it seems
like there's a real signal there we
didn't get a single from from time
surprisingly all right so let's look at
the signals a little bit more one really
nice feature of that we noticed of the
stress signal as a function of task is
that it had a visible and significant
sensitivity to the distance of the task
so just to recall what the tasks where
we had we had in all 20 tasks five
different distances and four different
widths in powers of two and they're
shown along here this is the ah five
different distances these are the
distance distances here and these are
the width of the targets along here and
you can see that there's a clear
dependence on the distance and close to
zero sensitivity on the width so quite
different from a fit slow kind of a
sensitivity and what that allowed us to
do but you can also see a nice
separation between stress and no stress
but you can also see that it would be
important to model the sensitivity to
the task if you want to really
distinguish these things they're not
there's no separation if you confound
for task
I
well I mean we could because the the the
Fitz lawyer index of difficulty well
you'll see in a second the time follows
exactly the index of difficulty but no
the index of difficulty what is
basically the the distance divided by
the width so that's a sawtooth it's a
sawtooth going like that and basically
it's it's it's only half right it has
the right sensitivity to the distance
but the wrong completely wrong
sensitivity to width so it just argues
for a different model different in
simpler model and that's what we built
and we found similar results for a point
for dragging the dragon curves look like
this again virtually no sensitivity may
be a very slight slope we actually
didn't model that we just modeled their
the distance sensitivity and there's a
good reason for that and let's see
finally yeah so we we turn this
observation into a model where basically
we extracted a we fitted a parameter
alpha based on the log of distance so
the other thing to observe here is these
steps are constant in size and the
target distance is varying exponentially
so it argues that the right model is
alpha times the log of the distance
similar to fits a little bit again
without the width sensitivity and from
that it's very easy to derive what alpha
should be and in fact we use an alpha
that's the independent of the of the
subjects so I'm sorry actually I didn't
quite I was out of sync so this is the
dragging task here the other ones were
still for the pointing task but you can
see it's the same kind of shape the
steering task though it was more like a
fitts law type of sensitivities so this
one did show sensitivity to the target
with as well as the distance again
though
with a log apparently logarithmic
dependence so we did analyze the
steering task using this more complex
model that had both width and distance
parameters and finally time looks like
this and if you work it out this these
values are just proportional to the
index of difficulty from the numbers
below but here it's also kind of obvious
that there's very little or no
separation in the time signals which was
a bit of a surprise all right so now we
have something a very simple model but
nevertheless a model that's a easy to
compute which is we can take those raw
readings and basically subtract off the
stair effect which in the case of
pointing and and dragging was or
clicking and dragging was a sorry
independent of W just depending on D and
the numbers that you get out a sort of
then normalized and you can simply apply
a classifier between them so making
sense so we basically removed the
staircase dependence so now if we had
any observation as long as we know what
the distance of the movement was we
could produce the kind of a canonical
measurement which should be different
for the stressed in stress case so we
from that data we finally run run some
kind of a classifier and derive some
accuracy results and here is the result
of that we tried a few different ways of
classifying the simplest one is just
taking the stressed and non-stressed
points taking the mean of them these
measurements like that HIV measurements
still have a lot of outlier problems so
taking mean values is a very bad model
we instead used a or is it max accuracy
classifier which simply means we took
the threshold it's a one dimensional
signal now so we took the threshold
which gave us the highest accuracy which
would be equivalent to doing a support
vector machine on one dimension but it's
just
simply to take the highest accuracy
threshold so that's what the blue curve
is here the red curve is taking a
simpler threshold which is just simply
the mean of the two sets so taking a
sort of an average midpoint between
stressed and non-stressed populations of
data both of those are using the stair
model if you take the stair model away
you get this accuracy here and to be
more specific I think it says it here
but the measurements are made by taking
our experimental data randomly taking a
sample of some of the points as the test
set and then training the model meaning
just setting the threshold on the other
points and finally using the Train
threshold to classify the held out
points so along this axis here is the
number of held out points the number of
sampled points there were only a hundred
points in total so the accuracy is
generally increasing as the sample gets
bigger but at some point it tapers off
because you don't have enough data from
the model the model is the other points
but anyway we get about accuracy of
about 70 this is per user so given let's
say a few hundred points of data for a
user you can generate assuming it's
labeled as through stressed and
unstressed or perhaps it might be
labeled as neutral you can learn a
threshold and then from about 10
observations subsequent observations you
should be able to classify stressed and
unstressed to about seventy percent
accuracy again to remind you the data
that we were using was based on the the
state of the subjects in the M stress
and M calm state where they had perhaps
fairly modest levels of stress perhaps
the self-report and their HIV data
roughly half as much stress as during
the fall stress or so yeah and the
data for the clicking and steering task
is here we get similar results overall
this one's a bit lower that one's about
the same so around seventy percent
accuracy again so you know it seems good
enough for for practical use and the key
a key advantage of the models the
staircase models for clicking and
dragging other they don't require
knowledge of D that's extremely useful
because if you build a very simple
logger that's application oblivious
that's just running at low level looking
at mouths activity all the logger has to
do is recognize the start in the end of
a mouse movement let's see with a time
window it doesn't need to know what the
target size was in order to figure out
the stair correction because it's only
depending on the distance you only need
the distance value presumably because it
has that really nice logarithmic
dependence on the the values that we
able we were able to take you should get
a fairly accurate measurement by taking
the log of some distance which wasn't
one of the ones we did so we are
actually in the process of doing a
subsequent study with more realistic
Mouse tasks where we simulate angry
messages from people supervisors coming
in in email to produce the stress in an
actual GUI contact so we can get more
realistic movements but still the
there's pretty good evidence from the
study that that should work so yeah so
we are building this revised logger
which will take which will run as an
independent process won't need to be
linked to applications which has some
privacy advantages as well but from
simply by looking at the lengths of
mouse movements that should be able to
report a value this an estimate kind of
real time estimate of stress so our
original goal of this was sort of health
lifestyle related how can we help people
monitor stress but it does suggest that
perhaps we could generalize a little bit
in our in our goals and look at things
like people's levels of frustration or
perhaps
anxiety about user interfaces or
applications in the absence of measures
of of what peop stressors are in
people's lives if we simply look at
these stress levels as a function of
time and if we were able to get a little
bit of information about which app
people are running then we can use this
kind of measurement as a kind of an
implicit usability measure which I think
would be pretty interesting so you know
it's simple enough we could get masses
of data and depending on how you
crosscut that day you can isolate
factors such as the application that
people are running in and get perhaps
this implicit usability information
alright so that's the summary we're just
going to wrap up there we we have
generalized to a cell phone we've
collected some data for from a very
similar study with the cell phone the
only difference in the cell phone is the
tasks or both more diverse and less
controlled meaning we do we did do some
pointing and dragging tasks on the cell
phone on the other hand though we
observed and we have video of the
experiments that people's use of the
cell phone was a lot more diverse than
the use of the mouse and that people
sometimes would use would rest a hand on
the table which sometimes hold the phone
up in some cases would be holding the
phone in two hands and doing tasks so in
terms of the dynamics it's a lot more
complex and most likely we'll have to do
some at least attempt to recognize the
distinct mechanical states that people
are in when they're using the phone
nevertheless there's some signs that
certain types of feature the basic
tapping on the screen seems to have a
really nice dynamic ringing signal that
that seems to be related to hand tension
so alright so so that's the work in
progress hope to have that soon alright
so so to summarize we've been working
for a while on senseless sensing which
is you know trying to leverage existing
technologies some of which seem to have
remarkably strong signals around affect
generally but especially
stress so we described recent
measurements on mouth stress which is a
ubiquitous low cost hopefully reliable
source of stress data in the real world
from ordinary Mouse use we'd like to see
if we can get similar measurements from
cell phone use and this we think would
have advantages over the voice based
cell phone use in that there would be
applicable to people holding the phone
which they arguably spend a lot of time
doing and we'll have to see if the
environmental vibrations and so on are
tractable or not so yes and of course
work that my student Pablo is is doing
and Mary's group is doing is looking at
interventions and trying to tie some of
these measurements back and deliver
appropriate timely and effective
interventions for relieving stress and
improving mental health yeah yes yeah
I don't currently have a student who
would is is oriented towards that I
think it's a great source my former
student qingdao who's that university of
pittsburgh has been doing some work
using the camera but you know contact
mode so he's built a small video game
that involves a lot of movements of
their of the thumbs over the camera
sensor and so he gets a simple pulse
signal from that data but the face you
might know there's been work at MIT and
elsewhere on recognizing pulse from
changes in facial color there's enough
blushing of the face during red red
blood I guess what's the word it
infiltration that's not the word but
there's enough signal from the flashing
of the face that you can detect the
pulse and so get at least you know a
pulse signal a fast dress signal
directly from face and of course I
there's so much emotion in the face and
there are a number of toolkits
unfortunately a lot of them are
perceived to be proprietary right now
there's a little bit of open source work
in the open sea be toolkit open computer
vision toolkit that that does at least
face isolation and a little bit of
future recognition but anyway the part
of the trouble is that there's a fairly
significant technical on-ramp for doing
vision analysis so right now we're
interested a little bit more in some
related topics we are doing some work in
deep neural networks for general image
recognition might be applicable to this
but for right now no we're not doing not
doing vision tracking do you know of
work yeah
I would love to do I would love to do
yeah well pupil dilation is a very
important q and I would love to do that
but I don't have the resources right now
yeah I think I think people bit
especially because it's supposed rescue
but also an attention Q and I think a
lot of the work on stress is focusing on
these rather macroscopic effects that
there are very important effects to do
with attention and interest that are
more on the positive side like you like
to know when people are being
effectively engaged and having an
appropriate level of engagement not
becoming sort of obsessed or you know
that they're staring this so they in a
sense are they in the sort of zone of
ideal behavior that is there sort of
attending to things without being
distracted I think gays patterns and
pupil dilation you want the right
combination where people are you know
transitioning from one stimulus to the
other without being haphazard a prying
appropriate focus I mean that's really
about detecting whether people are in
the zone that's sort of ideally we'd
like to move from remediating stress to
actually helping people get into their
the right cognitive and affective zone I
think so yes that would be a great topic
but we aren't really there yeah okay
thank you lots of mouse position
function
gasps for your second order model yeah
it didn't really look like a second
order model to Silas asymptote yes well
tell ya I'll tell you a little secret
which is no I mean I I don't know the
detail is that we sort of knew we didn't
expect to see really the second order
behavior in the gross behavior and the
truth is we don't actually it's not
strictly second order we it's a it's a
fourth order it's to second orders
stacked because the gross movement is
really not very interested in we're
interested on the little second order
wiggling that's on the top of it that's
at a different frequency so the truth is
we we actually do a fourth order model
and throw away the lower the lower
frequency poles and only take the
high-frequency ones which turn out to be
in the right frequency range for you
know the system that we're trying to
detect so you're very astute that that's
not exactly what we're doing but it
works to essentially filter out the
other component the male semen piece
we're just making a new set point for
well again again the it's it's it's not
exactly a fourth order system what we
understand is when people do a gross
motion it's not that the spring damper
is supposed to be a sort of a little
open-loop system that doesn't have a big
input when you actually move you really
have this other system with a big force
input that's responding to that input so
you again don't expect that and if you
look at those poles they're just not
robust they're all over the place the
the dominant poles so I'm not sure I'm
going to answer the question but yeah so
I'm sorry what was the cracks of the
question I was just wondering if the
model of a motion yeah it's kind of like
just making a good set point from way um
so the the the the simplest
biomechanical models i like that is
basically changing the set point of the
system so yeah we did try a variety of
things that that intuitively might have
helped such as trying to only run the
analysis during a what appears to be a
passive phase you can define passive as
energy coming out of the system and it
turns out I was simple formula in terms
of the direction of derivatives first
and second derivatives so we did it in
passive phase it was not as good we also
looked the active phase and so I I don't
know I mean yeah we tried to do the
things that might have helped but they
didn't really help yeah
I mean cuz I uh any experiment to make
them somewhat stressed over just yes
probably greater difference it really
yeah you know what I I honestly don't
recall so and you know it's a research
question which which interventions work
best for I think it might have been a
breathing exercise but i don't i'm not
completely sure but yeah from the work
that Pablo's been doing and mary has
been doing they're clearly different
interventions have different effects on
different people so it would be great to
have a better understanding of that in
the context of this experiment i'm sure
you can can't we get so many anomalies
because some people don't get calmed at
all in the calm phase and some people
aren't getting very stressed in the
stress phase so so there's all these
outliers which make the data you know a
lot less clean that we like it to be and
yeah perhaps better you know machine
learning and modeling so that we you're
giving people perhaps the best one would
would probably help this data quite a
bit first press inside the voice its do
you think there's a different type of
change in the voice during the high
speed version of the stress versus the
low speed version the cortisol versus
the adrenaline type of stress because if
you didn't know we realize you don't
know when the services so if you could
distinguish between the two of us to
figure out when what's the students that
caused them to be stressed well so I I
do know that it that it's a chronic
signal so you know it's the same signal
they find in depression so it's got to
be whatever it is it's in its most
likely cortisol because it's basically
permanent for depressed people there
might also be used yeah you would you
think that somehow that it might also be
the same effect but but stronger in a
short-term situation so I don't know if
anyone's measured that yes yes uh-huh no
that's certainly true yeah I know I mean
it's the voice is really a wonderful
signal and they're like breathing with
the good thing about the work we did
earlier is that there are so many
untapped signals in vital signs if
you're able to get them it's just that
it is really hard to get them there's
definitely a lot more in breathing that
people haven't tapped yet and it would
be great to be able to do that we just
decided this is going to it's much
easier to do the work and do the
experiments and have impact with the
implicit signals but the signals are
often a whole lot more ambiguous</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>