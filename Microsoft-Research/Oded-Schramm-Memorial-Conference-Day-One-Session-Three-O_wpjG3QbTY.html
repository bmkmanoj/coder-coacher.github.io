<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oded Schramm Memorial Conference: Day One, Session Three | Coder Coacher - Coaching Coders</title><meta content="Oded Schramm Memorial Conference: Day One, Session Three - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Oded Schramm Memorial Conference: Day One, Session Three</b></h2><h5 class="post__date">2016-07-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/O_wpjG3QbTY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome back welcome back to the
afternoon session I am Prasad Natalie I
was asked to introduce the next two
speakers it's a real honor and a
pleasure for me to be here and I want to
thank the theory group at microsoft
research particularly Jennifer and
Christian for having me visit several
times without which i think i wouldn't
have gotten to know that swamp I didn't
know him all that well except for
playing soccer with him several times at
lunch time and so I guess I'm i know
that groupie in some ways is why I'm
here one of the first times I met him he
told me about a result of mine on
hitting times using electrical
resistance is that he had used and so I
was pleased to hear that but after
hearing everything this morning I'm
regretting not having asked him for his
proof of my tiara and that I did work
with him just briefly for a couple of
days on a problem that he'd asked me
about and I asked him why he was
interested in that because it was
something I had thought about and he
said Mike Friedman emailed him mom and
he said you know I like to help Mike and
give his characteristic smile so I think
Mike will talk about some related work
tomorrow let me it's a pleasure for me
to introduce Ola hagstrom from Chalmers
University he's going to speak about
percolation thank you
but is the title of my talk percolation
mass transport and cluster
indistinguishability so wendelin hinted
in his talk at the crucial importance
that eat i had in recruiting Oded to
probability theory and this is the first
page of one of the first papers that
came out of that collaboration it's a
1996 paper in the electronic
communications in probability
percolation beyond ZD many questions and
a few answers by benjamini and SRAM this
turned out the very influential paper
and they it's sort of a rough outline of
a research program with many very
interesting questions and conjectures
also some some really nice results but
it's it's the conjectures that get us
going here's a list of further just just
a selection of other papers by Oded and
co-authors in this field shortly after
the benjamin SRAM paper they joined
forces with reliance and Yuval paris
these two papers or is part of the
outcome and there are further papers and
the one that I will be focusing most on
in this talk it's a result from the
Lions SRAM paper on indistinguishability
of percolation clusters so I will try
towards the end of the talk to prove
that result to you or at least outline
the proof and then finally there
this manuscript by myself which surveys
much of the work did by done by Oded and
his co-authors in this field so so this
is about percolation beyond ZD but just
for context we need to pick up something
about what happens on on GD so we're
talking here about iid bond percolation
meaning that you take every edge of the
lattice throw it out with probability 1
minus P keep it with probability P
independently of all others and you look
at the connectivity structure of what
you have and and one of the central
results is that in this setting you get
almost surely no more than one infinite
cluster for D equals to this goes back
to harrys 1960 and I see my cast and a
Newman first proved this for high
dimensions in 87 shortly after the eyes
amicus the Newman paper Burton and keen
gave a different proof of uniqueness of
the infinite cluster and it's a very
nice proof and I convinced that they
found the proof that is up there in what
erudis referred to as the book
containing all the right all the best
proofs of mathematical results and and
I'll say very briefly how how their
proof goes about its a proof by
contradiction general ergodic
theoretical considerations show that the
number of infinite clusters is an almost
sure constant for a given P and this
constant in fact has to be 0 1 or
infinity because if it were anything
else like seven you could easily connect
a couple or three or more maybe of these
clusters and you get fewer infinite
clusters just by local modification
that contradicts the almost your
constants so the only case you have to
rule out is having infinitely many
infinite clusters and if you have
infinitely many infant clusters or in
fact three or more suffice asst then you
can find some box which is with positive
probability intersected by three of
these infinite clusters and you can
locally modify the configuration to show
that this picture also has positive
probability namely these three infinite
clusters connected to each other by
perhaps in such a way that there's a
single vertex in the middle which we
call an encounter point it has the
property that if you remove it you'll
disconnect these pieces from each other
so provided that uniqueness fails there
will exist encounter points and so I'm
having some technical problems here my
slides are are too big yeah okay the
picture works anyway thank you yeah so
so when you have encounter points there
will be a positive density of them and
they're connected to each other in the
kind of binary tree structure because
you can't have cycles in their
interconnections because that
contradicts the notion of an encounter
point and binary trees have boundaries
of the same order of magnitude as
they're inside and that means that since
the number of encounter points inside
the box grow as the volume the number of
points and infinite clusters on the
boundary also have to grow like at the
volume like n to the D but the boundary
itself grows only like n to the D minus
1 which is the contradiction so you
can't have infinitely many infinite
clusters this idea is going to turn out
to be useful also beyond the CD setting
so when we go beyond CD we still have to
make some
assumptions on the graphs in order to
prove pretty much anything so one class
of graphs emphasized by by Benjamin
ashram or the transitive graphs so a
graph is transitive if for any two
vertices there's graph or amorphous and
mapping one vertex on the other so the
graph looks the same from every single
vertex and there's this natural
generalization of course the transitive
graphs which means basically that you
have only a finite number of kinds of
vertices so examples include ZD of
course regular trees have been much
studied various stylings of the
hyperbolic planes and so on and so on
once you have examples of transitive
graphs you can take the Cartesian
products and and get other examples and
so on I'll show a picture here of there
are many many hyperbolic tilings so this
one oh you I guess you can't see it here
here's its plain urdu also this is the
planar dual of the regular tiling of
hepa gonz and i think ken Steve Assange
showed the corresponding circle packing
in in his talk so so these hyperbolic
pilings are examples of so-called non
amenable graphs so what what's a mean
ability well first we have to define the
isoparametric constant of the graph and
that's defined as this ratio where s is
any finite vertex set in the graph d s
is the exterior boundary of this vertex
set and we're counting the number of
vertices in these things so this is a
kind of surface to volume ratio and let
me take the infimum over all finite s
of this ratio and that's the
isoparametric constant so that's in the
sense the smallest or the surface to
volume ratio that that it's achievable
or the infimum of such ratios take over
all finite subsets of the graph and the
graph is said to be amenable if if this
as a paramedic constant is zero as in
the CD lattice just witnessed by taking
bigger and bigger cubes and it's not
amenable if this constant is positive as
happens for the regular tree case and
also hyperbolic colonies and many other
examples and if we go back to the Burton
keen argument it's if you look at it
it's clear that it goes through for the
case when G is quasi transitive and
amenable and the Benjamin Ian SRAM paper
i talked about contain contains the
conjecture of a kind of converse so to
this so so what what they suspected and
which is probably true is that for
whenever a graph is quasi transitive and
non amenable there's you can find some
peace producing infinitely many infinite
clusters and their conjecture is a
little bit stronger than that so to that
then we can define two different
critical values pc is the usual critical
value for the onset of infinite clusters
and PU is the smallest the infimum
overall p such that we get almost surely
a unique infinite cluster and the
conjecture of ETA and Oded is that
whenever g is cause a transitive and
unwinnable PC strictly less than
PU so this has been established in many
cases but the full conjecture is still
open so having such such a regime with
infinitely many infinite clusters gives
rise to several questions that are not
there in the CD case and and this is
what brings much of the excitement to
the this field of percolation on these
more exotic graph structures so the one
result that I want to focus on here is a
cluster indistinguishability and this is
from the paper by Russ and Odette so we
focus on on graphs having this
non-uniqueness face and when you have
many infinite clusters you can ask are
they all of the same kind or can they
can there be infant clusters of
different kinds so here clearly we need
to make precise what we mean by
different kinds so obviously one
property of infant clusters that can be
different for different ones is the
property of containing some pre
specified given vertex so that's not the
kind of property that we're interested
in but but the natural property to look
at are the so-called invariant
properties so a property of infinite
Custer's we can identify it with a Borel
measurable subset of 012 the edge set
and we call a property invariant if it's
invariant under actions of the what a
morphism group meaning that if we have
an infant cluster in a percolation
configuration and then we move the
entire percolation configuration by
means of this graph falta morphism then
the moved cluster still has still has
the same property
and the the Lions and SRAM theorem says
that for any such invariant property and
we do I ID bond percolation on a non
amenable unimodular transitive graph
I'll explain to you in a moment but you
know modularity means and any invariant
property a then almost surely either all
infant clusters have this property or
all of them don't so that's the
indistinguishability of of infinite
clusters and to explain how the proof of
this result goes about we have to
backtrack little bit to the first of the
Benjamin in Lyons pairs SRAM papers that
I mentioned in this in this list they
considered a setting broader than the
iid setting that I've been talking about
so far namely autumn morphism invariant
percolation so the distribution of what
happens on a part of the graph doesn't
matter doesn't depend on where in the
graph you're so invariant under graph
automorphisms and and it turns out that
there's this condition of Union
modularity that is relevant for the
study of such percolation processes so
what is uni modularity here's here's the
definition so first of all the
stabilizer of the vertex in this graph
is the set of all the more films that
fix this particular vertex and the graph
is said to be unimodular if for any two
vertices this yeah any two vertices in
the same orbit of the autumn or fission
group we have that if we take one of the
vertices apply it stabilizer than the
other vertex maps on a number of
vertices which is the same number as if
we
in to change the roles between you and
be here so this is the kind of symmetry
this this tends to hold you know
modularity tends to hold for all
reasonable examples including all kala
graphs that you try to think of unless
you specifically try to construct grafts
which are not unimodular this is my
experience anyway so but but there are
non-union modular example so here's
here's a basic example consider the
binary tree with fix an end going off to
infinity a path going off to infinity in
this tree and we add an edge from every
vertex of the tree to its Xin parent and
the resulting graph is transitive but
it's not unimodular and the reason is
that in this construction every vertex
has two children but one one parent so
that asymmetry is the reason for the
non-union modularity so a basic
technique introduced in this benjamin
alliance peers Tramp paper they were
consistently very generous in quoting an
earlier paper of mine for inspiration
but it's really they who understood
what's going on is this mass transport
technique so the idea is that you take
some a function here the non-negative
function of three variables two vertices
and a percolation configuration and this
should be invariant under the diagonal
action of the automorphism group we
should think of this function as an
amount of mass transported from one
vertex to another given the percolation
configuration so every vertex looks
around at the percolation configuration
and deciding how much mass to send to
each other vertex depending on what they
see and the rule has to be autumn or
fizzle invariant and the mass transport
principle which is formulated here
says that if the graph is unimodular
then the amount the expected amount of
mass received at the vertex equals the
expected mass sent away and the reason
why you need to see that you need Union
modularity or some condition you can
look at trophy MOS graph and consider
the mass transport where every vertex
sends unit mass to each of its two
children then every vertex ends mass to
but receives only mass one but on
unimodular graphs mass is preserved in
this way the proof of the mass transport
principle here is the Kayla graft case
just to show you that it it's not more
than a free line calculation and and in
the general case you need a little bit
more but it's still not particularly
complicated yeah yeah okay so here's a
toy example to show you that the how the
power of the mass transport mess method
2 i'm calling an infant cluster slim if
it consists just of a single naked
infinite branch infant path so there's
no branches on it it has a single vertex
which begins and then it goes off to
infinity and the question is is it
possible to construct an invariant
percolation on G which contains slim
infinite clusters and on ZD I'll do this
rotation again the answer is no and it's
because of this picture that's basically
part of the Burton keen argument if you
have slim infant clusters then these end
points will appear with positive density
and for each end point there will be
some point on the boundary that it
connects to and different endpoints give
rise to different infant clusters so so
again we get this contradiction between
volume and and surface so this argument
works
on non amenable graphs but I'm sorry on
a minimal graphs but in the non amenable
case you have to think about something
else and in fact if we go to the trophy
mob examples slim infinite clusters can
occur and what you do to construct such
a thing is that each vertex toss this
coin to decide whether to have a link to
its left child or to its right child and
this produces a percolation
configuration consisting entirely of
slim infinite clusters so the question
is here okay maybe we can't do anything
in the in the non amenable setting but
in fact if you restrict to unimodular
graphs existence of slim infinity
clusters has probability zero and it's
very easy to prove to prove if you know
the mass transport method so here's how
it goes about so what you do is you
define a mass transport where every
vertex sitting in a slim infinite
cluster sends unit mass to the end point
of this cluster no other vertex ends
anything it's only those vertices
sitting in slim infinite cluster that
sent unit mass to the end point so
clearly the expected mass sent from a
vertex here isn't most one now if there
do exist slim infinite clusters then
some vertices namely the endpoints will
receive infinite mass meaning that the
expected mass is going to expect the
mass received is going to be infinite
and we get this strict inequality
between expected mass sent and expected
mass received contradicting the mass
transport principle so that that was the
warm-up example no yeah
you proved that you wouldn't have
probability I showed that with with
probability 1 there won't be any slim
infinite clusters
I mean it seems that it's limited the
clusters extremely unlikely likely
Brandon
because I'll well it seems very unlikely
branch every point along for some chance
no no no no because here i can define
the percolation process in such a way
that there is no no branching going on
was that this was not I ID percolation
because I just required the percolation
to be autumn or face and invariant so
just some publisher on functions
yeah what a more ordered morphism
invariant system okay so now for the
real thing cluster indistinguishability
from the lions and SRAM paper and i
organized how many minutes do I have I
think I started five minutes late isn't
it yeah yeah okay so I've there's a lot
of ground to cover here and and and I've
organized it in five steps here might go
right onto the first step which is the
existence of what I call or what they
call pivotal edges and that what's a
pivotal edge in the percolation
configuration it's it's an edge which is
closed it's it's it's tough but with a
property that if you would turn it on it
would change the status of an infinite
cluster so regarding this invariant
property that we're looking at so we're
fixing and invariant property a we're
assuming for contradiction that there
that infinite clusters with property a
and its negation coexist and claim that
if this is the case then there's also
going to be pivotal edges sitting around
and in the case where there exists
infinite clusters will probably be a and
a compliment sitting within unit
distance from each other then it's good
clear that including this edge is going
to change the status of one of these
infinite clusters because they're going
to merge become a single cluster and in
the general case these clusters are
going to sit at some distance some
finite distance from each other and then
you can do the same thing via a local
modification argument
that's the first step then there's
something called delayed random walk on
the infinite cluster which is a crucial
tool here so what we do is that we
define a random walk starting at the
given vertex and it moves only along
edges that are present in the
percolation configuration and it's
almost simple random walk exactly that
it has some holding probability so it
stays put with a probability equal to
the proportion of edges in the graph
that our neighboring edges in the graph
that are closed so one way to describe
this is its pick it picks a G neighbor
uniformly it moves to that neighbor if
if the edge to it is open otherwise it
stays put and the crucial Emma here is
that the percolation configuration as
seen from the random walk is stationary
the way that the percolation looks from
from the point of view of the vertex
where the random Walker stands is
stationary so so I'm not going to
formalize prove this I'll just mention
that it it says it's a simple mass
transport argument to show this and I'll
move move on to the next step which is
the existence of encounter points and
plenty of encounter points in in the
percolation configuration in this
setting so so so the it's the same
notion as in the Burton King proof the
vertex with three separate paths to
infinity that would fall in different
components if we remove the vertex and
if we consider the mass transport in
which every vertex sitting in an
infinite
with encounter points sends unit mass to
the closest encounter point with some
tiebreaking rule or maybe just equity
distribution in case of in case of a tie
that's that's the mass transport and
this first shows that any infinite
cluster with encounter points has to
have infinitely many encounter points
because otherwise one or more the
encounter points would receive infinite
mass while all vertices has had sent on
the unit mass so that gives the usual
contradiction to the mass transport
principle so once you have encounter
points you have to have in the cluster
you have to have infinitely many and if
you combine this with local modification
you get that any infinite cluster have
to have infinitely many encounter points
and and the idea here is that let's say
this is an infinite cluster that has
only that has no encounter point then by
local modification we can get this
picture and the mass transport that I
just described will send infinite mass
from this part of the cluster to this
point so every infinite cluster as
infinitely many encounter points the
main reason for doing this is that once
you have this abundance of encounter
points in the graph you're the random
walk the delayed random walk on this
cluster intuitively it's clear that this
this should be transient because of this
sort of tree like structure that the
encounter points creates you can in fact
deterministically construct non
invariant percolation processes which
have these encounter points and which
make the random walk recurrent but
because of the invariance here there are
ways to to demonstrate that the the walk
becomes transient and and there are
various ways to do this and
met the details be happy to describe it
on in one-on-one sessions to anyone
interested or you can turn to rest if
you want to hear the full story and then
finally we have all the ingredients and
want to put things together so we apply
local modification to a pivotal edge so
what I'm going to do is or what they do
is that they run a simple sorry delayed
random walk starting at the point
here and what I forgot to mention about
this delayed random walk is that you can
extend it to negative x by running two
copies of it one going forwards in time
and one going backwards and if we have
these two different infinite clusters
and then this pivotal edge me with using
local modification we're allowed to turn
that edge on and get something that
still happens with a positive
probability we can get them with
positive probability random walks
trajectories we're in positive time it
runs off in this direction and a
negative time it runs off in the other
direction so that gives if we look at we
get a stationary process in time to
indicate whether the random walk seized
property a or property a compliment and
when you take time average going
backwards in time you converge to
something and we take time average going
forward you see something else and that
basically gothic figure II tells you
that this is this is impossible I'm
cheating here as some of you may have
seen because when I introduce this edge
I'm going to change the property of one
of these infant clusters so it looks
here like the argument doesn't work but
if you replace property a by some finite
range property as seen from the random
Walker look this gives you an
approximation argument that that that
works so this argument in fact shows
that
you do get this decide contradiction
from the coexistence of the infinite
Custer's and different type I should
finally mention that the result of
Rossano dead was was formulated in
greater generality if you inspect the
proof that we sketched here it works
under various modifications so for
instance iid percolation which I
insisted on here can be weakened to
having autumn or facing variant
percolation with the extra property of
insertion tolerance also known as
positive finite energy meaning that an
edge has always has positive conditional
probability of being present given what
you see on the configuration on the set
of all other edges also whether we look
at bond or side percolation turns out to
be relevant and transitivity of the
graph can be weakened to YC transitivity
so that that concludes my presentation I
thank you for your attention
well I decided to come and I think
little is much too modest describing his
own role first he was the one who
introduced not on the mass transport
technique in the percolation but also
the technique of using delayed simple
random walk in the percolation and also
he and you all had earlier proof partial
resulted in distinguishing ability with
an additional hypothesis of one
ethnicity
into the non unibody Lopez yes and you
give an example but indistinguishability
fails the iron a polite yes the trophy
more example in fact works but yes
because every infinite cluster if you do
I a deep percolation in trophy MOS
example is going to have an uppermost
vertex and you can look at the degree in
the cluster of this vertex that's an
invariant problem Mike jr. Tigers think
about the Kelly brown resolve geometry
you know which is an example where the
growth is exponential but it's stolen
available room vahagn see it seems to me
that what I was wondering whether the
hypothesis is not amenable is really
important one or whether
it seems like the proteins argument is
destroyed no in fact I mean abilities is
the crucial property for it you just
have to pick the you don't have to look
at balls growing balls but you have to
pick some sequence of sets that witness
the amenability and their argument
go ahead with the next talk the next
speaker is one of the organizers and
manager of the theory group developer
ass and he's going to talk about a an
unpublished jam
like some time
connectivity probability in critical
percolation
so good afternoon turn this on good
afternoon I'm I'm tell you about a
theorem which truly ulema but it's one
of the really striking ideas I heard
from Oded he never published it because
he felt he had the lemma had great
promise and he wanted to actually
realize that promise before he you know
released the lemma into the world but he
told the some of us about it and and to
share that with you there already some
nice applications of dilemma so the
setup is the setup that allah described
in his talk so of so g is here nanami no
balls and
the Scimitar kaylee graph so you have an
underlying discrete group and with a
finite set of generators and you connect
two elements of the group whose ratio is
a generator or you can think of the more
general setup that all a described of
more generally the transitive unimodular
case everything works in both so
whichever set up and for those you know
who haven't worked in that setting it's
good to focus on some examples so think
of either those hyperbolic tessellations
that we showed in his talk or you know
one concrete example that we can all
visualizes think of a product of a tree
as a regular tree and the integer so
that you can think of the tree existing
in each airplane and every tree in a
plane connected to the trees above and
below it so that's tweet me so that's
one concrete example
and this aim this lemma Foday this coin
is related to the open question open in
general whether gene on a mini ball and
well any g as as on the left implies
that a pc the critical parameter for
having an infinite cluster is less than
P you the critical parameter for having
a unique infinite cluster so this is
still open and there are various cases
that is known so in fact before this
theory existed before the time no dates
paper there was a paper by a Grimm at
the newman who showed you know the
notions of pc and p you were not
formally defined that they did show in
effect this for a certain trees times e
Beeny mini SRAM extended it and also
proved pc less than P you for planar
nanami noble graphs and
the paper by by Igor packin energy benda
where they where they prove it in a
powers of so given any non amiable graph
you can pass to a certain power of that
graph so you connect things that are
distance k in the original graph by
passing to large enough power you will
get pc less than P you so this a uses
some insights from this in a mini from
paper but the conjecture is still open
and to me one of the most promising
avenues is the following lemma that oded
found so if we used to add criticality
at mythicality we're used to from
statistical mechanics that signature of
criticality is having polynomial decay
rather than exponential decay of a
connectivity probabilities but if we
think of a if we think of the kind of
degenerate example of a tree so consider
consider for a moment percolation on T
on the tree so on the tree PU is just
one so it's kind of a degenerate example
for this for this theory so in these in
these interesting examples p u is less
than one but on a tree tu is less than
one but you also see on the tree that
for all you know for all p less than one
you have connectivity probabilities
decay exponentially so although if
you're working see on the three regular
tree and then three regular tree pc so
here p c equals one half but at pc or
even above pc you don't have polynomial
decay you have still exponential decay
if you have two vertices and ask what's
the chance they are connected the
probability decays exponentially in the
so the idea is that this is a signature
of the fact that pc is not the right
critical parameter for connectivity it's
PU which is the right parameter for that
so remember pc is defined as the
critical parameter for having infinite
clusters but infinite testers can only
explore a small part of the space
sometimes and that's why I'm here you
have connectivity probabilities decay
exponentially and no Dead's so so so a
dead lemma that I want to tell you about
is that for for such G so non a minie
ball candy graph or transitive you know
modular we have the following kind of
exponential decay so we look at the
probability of connecting from a vertex
X 0 to a vertex X K in pc and this
probability decays exponentially less
than lambda to the K with lambda less
than 1 and lambda is in fact identify it
for you in a moment now what are these
points x 0 and x k so these are not just
any two points but x so x 0 you can fix
a to be the identity of the group or any
fixed vertex but xk is actually simple
random walk on the Cayley graph ok so
you consider you consider simple random
walk on this graph and this probability
stay with is in a joint probability
space so we run a we do critical
percolation with parameter p see on the
graph exactly the critical parameter for
having infinite clusters and we also
independently run a random walk we run
the random walk for K step so here is X
0 here is XK it's some distance at most
K but in fact on these graphs we know
that the random walk escapes at linear
speed so at some distance linear and K
and we ask for these two points what's
the chance that they're in the same PC
cluster the answer is d
exponentially this is pretty good
indication though not yet the proof that
pc is less than P you so there's you
know something still missing and this
was the motivation for or dead to prove
this was to get to the PC lesson PU he
never published it I think because you
know the last step was still missing to
go from this to pcl S&amp;amp;P you but the the
proof of this he sent actually sent a
few of us by email and this one
literally made me fall off my chair so
when I when I read it was a very short
very short paragraph because you know we
knew all the tools involved but it was
just such a stunning combination of
these tools so let me tell you these
tools some of them you've seen in ullas
talk so so no no me noble graphs are
defined as all I told you by having this
isoparametric consent or expansion
concept the ratio of surface to volume
being bounded below but for probably
there's a useful equivalent definition
which is cast and theorem so i'll write
this for the case of groups it's more
general test and proved it for the case
of group so for 4g which is a kala graph
actually okay since k system is more
general than what our state but i'll
just do this version if you look at gene
on amenable is equivalent is equivalent
to the spectral radius which is defined
to be the lymph soup of the probability
of returning to the starting point
but I mean I can just define for any for
any g it doesn't matter what GI fix here
so this we take this probability of
returning reaching in n steps starting
from some fixed point 0 the probability
of reaching some vertex G we take this
to the take the nth root of that so
basically we're asking is there
exponential decay or law not and lambda
is less than 1 if and only if G is not
amenable so again it's the correlation
this is equivalent not to exponential
growth the exponential decay of the
return policy cover not at financial
growth back to nanami nobility ok so
that's it yes and that theorem works
with the same lambda ok but here there
is no here there is no calculation that
all this is just a fact about random
walk going back to nineteen fifty-nine
basically testing species
okay so that's one tool that comes in a
second tool is a theorem already quoted
in newly stock film from the paper by
eat I rust Lions type in the mini rust
lines myself and Oded which is the
theorem that in ng as above so say
kaylee non- ball we have theta of pc
equals 0 so theta is the probability
that the vertex specific vertex is in an
infinite cluster this probability is
zero in other words if you work in pc
almost surely no infinite cluster of
open edges so we're doing bond
percolation here at the critical
parameter pc and this is a famous open
problem whether it's true in a CD for
intermediate values of d or in any
transitive graph but this is one case
class of cases where it's known all the
kaylene on the mineral graphs or more
generally known am enabled a transitive
unimodal or graphs fate of pc is 0 I
won't give you know I won't recall the
proof of this just going to use this as
a tool because again when the dead scent
is email this was after we had proved
this without and the third tool that
comes in it actually goes back further
it's hula hedstrom's theorem which was
one of the earliest uses of mass
transport in percolation in his paper on
involving a prism invariant percolation
on trees and oles theorem he had several
theorems in this paper the one I need
here
is the fact that for aim a so for
invariant and here i mean invariant
under all automorphisms a percolation
this is remember our statement here is
about independent percolation but as a
tool we use a result about more general
environments so these are just measures
on random subgraphs no independence
assumption but invariance under optimism
so invariant percolation on a regular
tree regular treaty so let's give this
inventor collation a name say Omega if
we know that almost surely there are no
infinite clusters so almost surely no
infinite clusters in this percolation
then that forces the expected degree in
the percolation of a vertex and since
I'm assuming the graph is transitive it
doesn't matter which vertex I put here
the expected degree of a vertex in this
percolation is at most two okay so
so any way you build percolation on a
tree it has to be autumn officium
invariant so here again in trophy moves
if you take so here is the
counterexample to the theorem but first
it doesn't satisfy one of the hypothesis
which is true if you take if you just
take a take a binary tree with a
distinguished end so a three regular
tree with a distinguished end and and
you just so you have this notion of
levels of the tree right because you
have a distinguishing now you just
remove every level with probability one
in a thousand independently of each
other and so this will be a process it
will cut the graph into finite clusters
but the degree will be close to three
here but that's again a non-union model
or example so if you stick to unimodular
examples and do percolation on on trees
which is optimism invariant under all
automorphisms then the finite clusters
force the expected degree to be too okay
so that's a student let me just show you
the proof because it's yet another cool
application and they say one of the
earliest ones of mass transport so so
here's the proof I am so then we're
assuming all the clusters are finite so
so aim okay each vertex
and takes its degree each each vertex X
sends its degree ad Omega of X a out to
its cluster and it divides it uniformly
so a so so the mass transport em X Y is
the random mass transport so it depends
on X Y and Omega will be a degree of x
over the size of the cluster of X if Y
is in the cluster of X and 0 otherwise
ok so that's that's the mass transport
and
and if you look at the MX y which is the
expectation of the mass transport then
right then the total mass sent out from
a vertex is just it's expected degree
because when we add overall the cluster
the denominator here cancels we get the
degree and then we take an expectation
so we'll just get the expected degree
and this is the expected mass coming out
but what's the expected mass coming in
to a vertex
okay well for every vertex the they
let's first look what is the mass that
can come in so the mass that can come
into a vertex is at most the sum of the
degrees in the cluster divided by the
sum of the cluster this is going to be a
actually the expectation of the sum of
the degrees which is twice the number of
edges in the cluster / the size of the
cluster so I'm summing over Y so here
the mass is sent from Y to X okay sorry
switch to keep you awake so so we're
looking at this ratio but because we're
in a tree in any finite tree the number
of edges is that most of the number of
vertices so this ratio is at most two
take the ratio inside the expedition is
at most two so by mass transport we get
because these quantities are equal we
get the expected degree is at most two
and you saw that we need you know the
module arity for that it fails in
Trofimov example then yes
again what you do is you remove every
level of this with with probability
epsilon that is autumn or is an
invariant when you only restrict to
automatisms that keep the level but
that's so so that's not the for now so
okay so so this okay I'll um right
that's good point but this you know so
so so let's let's do this intro form of
example connect you know we will connect
every vertex we connect to the
grandparent so we add we can add those
we can add those extra edges so okay so
all right so so proved for you this tool
and now okay so so the last thing I want
to do is just tell you how these I get
put together so all of these are tools
that you know that we in the business
knew very well but then how does this
give this statement so here is okay so
and have to erase this but keep okay so
now that proof was just a one paragraph
email given these tools but still you
know finding that paragraph to something
so he he says the following let's draw a
tree this is going to be a regular tree
but it's going to be of high degree it's
actually the degree fix the number cake
the degree of this tree is going to be a
lambda to the minus K say integer part
so every vertex has lambda to the minus
K neighbors the regular tree okay and
we're going to define so too again we're
the set of proving this lemma we're
going to define an invariant percolation
on this tree so and we're going to do it
using a tree indexed random walk on the
group so fix here is the root of the
tree say they call it also m and this is
going to be mapped to a point X 0 which
you can think of as the identity of the
group and then for every vertex V we're
going to have a variable X B but the way
is it it is obtained is by running k
steps of the random walk so aim if so if
X V so if actually if VW our neighbors
xw is obtained from XV by running k
steps of simple random walk on the group
g so here we have the tree and we're
kind of mapping we're defining a random
mapping from G to the group using this
random walk so if you're going to trace
any path in this tree you're just going
to see a simple random walk every edge
of the tree corresponds to K steps of
the walk ok but the walk if
here I have the walk as it branches from
from this vertex V the walk going here
and the walk going here is we're going
to walk independently okay so think of
every edge in the tree corresponds to a
path of length K and all these paths are
glued together independently to define
around the mapping from the tree to the
group now what is the percolation so we
define v and w VW are open this edge VW
is open in the tree so here is here is
Vee here is w so VW is open in in this
percolation Omega if and only if these
points XV + xw are connected at level pc
in g right so remember our key object is
percolation in the group independent
progression in the group so FX v + xw
are connected in the same PC cluster
then VW is open this defines a
percolation on the tree and it's easy to
see that this is a automorphism
invariant percolation on the tree ok now
this all right now why did we define
this degree in the tree because this is
the basically the largest degree we
could take to make this a transient
three indexed walk because if you want
to see what's the expected number of
visits from this walk to a specific
vertex G might want to sum over all
vertices the probability that this walk
will in visit g XV is this tree indexed
walk well you can obtain this just from
simple random walk by summing over n the
number of vertices at level n of the
tree ok well this is the same let me
still inequality number of vertices at
level end of the tree times the
probability for simple random walk now
xn is back to random of nature is the
probability that xn will equal G you
know all started from this fixed vertex
and
and this we can a we can certainly bound
the growth of the tree is lambda to the
minus k minus 1 that's the number of
children at each level the first level
is a little difference or throwing this
two for safety and then I have to take
this to the ends power so that course
counts the size of the ends level with
this factor of two and then this
probability we know from so here we have
to put x NK because n level end of the
tree corresponds to n K steps of the
walk so we get lambda to the power n K
right and because of this one we know
that this is finite so the expected
number of visits of this tree indexed
walk to any vertex is finite so the walk
is transient it will exit a compact set
along any path after finite time ok so
what does that tell us that tells us
that this invariant percolation has only
finite clusters because think about what
would an infinite cluster me it would
mean a sequence of vertices all
connected in pc and the sequence of
vertices are going off to infinity but
that would give us an infinite pc
cluster that we know doesn't exist so so
it follows hear that
take more then omega has only finite
clusters okay so that's the key point
combining the transience of this walk
with the finiteness of the clusters in
pc if the walk if you had an infinite
cluster and omega an infinite so in
infinite paths of open edges in this
omega it will yield for you and infinite
collection of vertices here all of whose
images are connected in the pc cluster
but these are going off to infinity so
you'd get an infinite pc cluster in g
but we know those those exist so in
omega there are only finite clusters but
now recall bullets theorem that I prove
to you before this means that the
expected degree in omega of any vertex
is at most two but but what this
expected degree we can easily calculate
that this expected degree is exactly the
branching of the tree so integer part of
lambda is minus K times this probability
that x 0 and x k are connected right if
you go to this definition what's the
expected degree of a verdict is exactly
this product of the number of edges in
the tree that I expect the degree number
of edges x times this probability so so
getting right so this tells you that
this probability is at most 2 over
lambda 2 minus K which is already
exponential decay so the you know in the
very last half minute I want to get the
actual statement there so a 0 dead left
this last step of his email because it
was too obvious but let me include it
here anyway how do we get to the nice
exponential decay furnace we just use a
some multiple multiplicative et property
so the probability that if we look at
the probability that X 0 is connected to
XK and take that and take that
probability
to the power l this this probability is
at most the probability that X 0 is
connected to xk el
so so so to connect from X 0 to X scale
you need to connect from X 0 to X k then
from xk to x 2k and so on and using the
fkg inequality you have this a this
inequality but then but then this
argument applied to KL tells you that
this is at most 2 / in lambda to the
minus KL all of that integer part and
now if you take health roots of both of
these and take L to infinity you'll get
the desired statement thanks for your
attention
you need something obvious but so why is
it this doesn't imply the pc must impede
you well maybe it does but what the
problem okay the problem is that we
don't know anything about the length of
the paths that connect so so what's the
natural natural approach to go here to
say that you know suppose I suppose p c
equals p you then you could get a you
can get very far away points the
probability of connecting would stay
stay positive and then you change the
probability a little bit the problem is
that we don't have good control in
supercritical percolation of what's the
length of the paths connecting so even
though you know you look at the point
points that are a distance k it's
possible that the only connections are
extremely long and then the trivial
argument me if go ahead if you had a
unique cluster then you take x 0 and x k
they each have a positive chance to
begin de cluster right ought to be
correlated so there's a positive chance
they're both in the unique cluster right
so how come that doesn't already
contradict exponential decay again
remember that we already know that at pc
itself there is no infinite cluster
certainly not even the not unique and
knowing so the problem is you have to
change the piece right okay so so well
maybe you know think a little more and
maybe you'll I said that this it looks
at very personally we haven't been able
to complete it for the original purpose
but recently Gaddy Kozma has some new
applications of the idea in this proof
to actually derive mean field exponents
in various new graphs but I won't you
know get get into that
so DK for any point of this bouquet then
then he was known that
No okay that's come community starts to
do the break
we convene at 32</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>