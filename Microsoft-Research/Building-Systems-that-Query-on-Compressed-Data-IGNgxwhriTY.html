<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Systems that Query on Compressed Data | Coder Coacher - Coaching Coders</title><meta content="Building Systems that Query on Compressed Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building Systems that Query on Compressed Data</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/IGNgxwhriTY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
agarwal here today once it is not a post
up at UC Berkeley were agreeing with the
instructor he did his you I his PhD at
UIUC I was Breton God for you and
Richard works on distributed data
intensive systems in particular these
storage systems that can answer very
sophisticated and cool queries even over
a compressed data which we're going to
hear about today the thing I like the
most about Richard is that he publishes
both in systems conferences like honesty
I and theory conferences as well like so
does so he really is a bridging force
between the systems and theory
communities and he's also received
several awards for his research and I'm
looking forward to hearing started a
perfect thanks thanks said then thanks
for having me here thank you all for
coming to the talk I'm very happy to be
here so my research yes likes it said a
lot of interesting stuff happens at the
intersection of systems in theory and
hopefully I'll give you some picture
about the theory side but this talk is
is going to be slightly more on the
system side because I think some of the
interesting stuff here might actually
excite you and so I started my postdoc
at UC Berkeley two years ago and at that
time we were trying to understand kind
of what are the trends that are coming
out of hardware and applications that
people want to run today and one of the
trends that is really stood out and that
we have been hearing more and more over
last couple of years is Moore's law you
know hardware designs not being able to
compete or keep up with the Moore's law
and on the application side there's a
very different trend which is the data
sizes are becoming larger and larger and
in particular data sizes are growing
faster than Moore's law so there was
this mismatch between what people were
trying to do over the kind of data size
that people were trying to deal with and
with the hardware that that people use
today and that's how this project
succinct came up and I will talk more
about motivation but the main goal in
this project was to understand is it
possible to take a server with say 64
gigabytes of RAM and push up you know
half a terabyte of data or 128 gigabytes
or 256 gigabytes of data in the main RAM
and do computations as if we do today
and and the basic question was
formulated as a compression question
that I'll talk more about but the
overall talk is going to focus on
so-called interactive Corey systems and
I will define what interactivity means
but for now think about when you
interact with the Facebook or Twitter
you know the kind of interaction you are
having between you as a user and the web
service that's what I'm going to call
interactive systems and the first the
first realization was that these these
trends that I'm going to talk more about
lead to this problem that query
interactivity is getting really really
hard to achieve even trace systems and
that there are two main reasons for that
the first one is scale last few years we
have seen that the rise of social media
has given us access to this tremendously
large amounts of data then people are
trying to exploit in many many
interesting ways in particular you know
terabytes of semi-structured data is now
quite a bit of norm actually if you talk
to any small company as well in the Bay
Area they talk about tens of terabytes
of data right large companies are
talking about hundreds of terabytes of
petabytes of data but the important
thing like i said is that data is
growing faster than a Moore's law okay
so people are really trying to do very
very interesting things on this massive
amounts of data it's not just a scale of
the data that has increased people still
want to do complex queries for example
here I have a collection of tweets
Twitter last year announced that now you
can actually go and search across all
these set of twists so each to eat has
some user ID sometimes time when the
tweet was created in some text and
people may want to search for tweets @
mentions are in the space of our certain
name right similarly a succinct and it's
also had one initial interesting
question about that gave us with one of
the large publishers that we we work
with which is that they had this large
collection of documents and they wanted
to do very fast regular expression
queries on this massive collection of
documents hundreds of terabytes of
documents and the use these regular
expressions in an interesting way right
so these are user facing queries when
the users go to this publishers website
day they actually run these regular
expressions in the back
Brown and then every time you go to
facebook facebook internally does
something which is called a range query
and I'll define this as well and
essentially what it says tell me all the
posts that have been generated or all
the lights that have been generated
within certain to right time ranges so
it's a range query so people are trying
to do all these complex queries on this
large scale of data right but it's not
just a scale and the complexity one
thing that has remained unchanged over
last tens of you know over last few
years is that the definition of
interactivity as a user if anything we
are growing more impatient right we we
close up a website if doesn't load up in
a few hundreds of milliseconds so the
definition of interactivity that I'm
going to use in this talk which is which
is slightly vague but basically what I'm
going to say is that we need low latency
so tens of milliseconds essentially and
as long as that latency is less than a
certain bound we are going to want high
throughput which is the number of
queries that can be answered by the
system per second okay okay so the three
challenges now scale complex queries are
interactivity and there's been a lot of
work at the intersection for looking at
these challenges either in pair or in in
isolation and of course scale is you
know we have we have studied a scalable
algorithms for a long time how do you do
complex queries and things like that but
if you look at the intersection of these
three we have this new bunch of very
interesting problems that some people
refer to as interactive big data
problems that are both high impact and
very very challenging and I'll talk
about the challenges my research
essentially focuses at this intersection
of these three constraints this is space
of the intersection of these three
constraints is also a space where
existing system start to fail so let me
start with a very simple very simple
experiment and show you some numbers so
suppose I have these search queries on
this collection offer so the conway was
one of the companies that generates
these video logs so this serves online
videos and
every time a customer comes to the
website they generate this kind of log
where each record has a record ide who
is the user when it the user starts in
the video when the video ended and some
of the tax for the videos and I'm going
to run these search queries on these
columns so each of the search query is
essentially a query on one of the
columns and I'm going to use a single
amazon ec2 server with a single core and
some 60 gigabyte ram so let's look at
what happens on the x-axis what I'm
going to do is I'm going to increase the
amount of data that I'm going to push on
the server right so wedding from one
gigabyte 128 gigabytes on the y-axis I
have the number of queries so such
throughput that is the number of queries
that is answered by these something I'm
going to look at these three
state-of-the-art systems for this space
so for elastic search as we scale up the
data sizes this is what the performance
looks like ok so when for small data
sizes the performance more or less
stable at roughly 200 queries per second
which is roughly speaking 5 milliseconds
and then suddenly the performance drops
beyond 16 gigabytes of data ok and this
is not just lost six search if we look
at MongoDB we see a very similar trend
right and with Cassandra very similar
trend so um as soon as you look at this
result to you you actually one asked you
know what is happening in this space I
have 60 gigabyte rhyme and I can't do
anything more than 16 gigabytes anything
interesting more than 60 gigabytes right
so what is actually happening in this
space any guesses swapping exactly so
what happens is the things to start
running out of memory right and i'll
talk more about why it's happening at 16
gigabytes but essentially a lot of
people have realizes that if you want to
achieve query interactivity you have to
do queries in memory right in memory
query execution is the key in particular
if you look at hardware trends today
secondary storage region SSDs is 100x
slower than main memory and very simple
calculation shows that even if ten
percent of your queries go to secondary
storage your system answers 10x fewer
queries actually 11 x few queries in
fact even if one percent of your queries
go to secondary storage your system
answers to X fear course yes SSD backed
yeah so hard drives are thousands of
mine slower than main memory so these
numbers would look even worse so and
nobody's using hard drives today so
secondary storage SSD backed this is
this is what your performance numbers
would look like even if ten percent of
the queries were going to secondary
storage you will see 11x performance
degradation which is essentially what is
happening here yes yeah right now we are
not doing any approximation is that
search queries all range queries here
okay so the question is what do we do
about this essentially this is what my
research focuses on my research in
particular looks at bridging the gap
between the memory capacities that we
have in today's systems and the data
sizes for which we can interactively
query these using these memory
capacities in particular the
functionality that we focus on we say
that okay we want to get the
state-of-the-art functionality of the
state-of-the-art no sequel stores and we
want to bridge the gap so coming back to
this curve what we are essentially
looking for is whether there exists a
system that can achieve a performance
like this let me try and explain this
more what we want is we don't want to we
say that okay when when the data sizes
are small of course we are getting close
to optimal are close to good performance
but we want to maintain the performance
for much larger range of input data
sizes at some point your system will run
out of memory and your performance will
drop but this is the range that you want
to get gains for and x axis log scale
here so we are actually asking for a lot
ok question is whether this exists a
system that can achieve this new car if
possible clearly the gains will come out
of the fact that we can do in memory
code execution for larger fraction of
quarries and if you look at the
performance at scale we get to multiple
orders of mind you'd faster performance
ok the question is that system exists so
this particular project succinct is
essentially trying to solve this problem
it's a distributed data store which
means is storing data
across multiple servers essentially what
it does is suppose this is your input
data and I've color encoded I'm going to
use this example throughout the talk I
have the color encoded the the file here
each of the blocks here could be a term
or could be a substring it will be a
collection of characters right now think
of it as an ASCII file set okay and then
I have multiple blocks in the file what
such thing does it takes your input file
and it is stores transforms this file
into suit of data structures okay that
the two interesting things here the
first thing is that the suit of data
structures are compressed representation
of your input file which means if you
you know these students structures will
have sighs no more than your input file
size this is guaranteed right and the
second important thing is that such
thing does not store the input file all
sucks and restores is this compressed
suit of data representation okay but now
that you have this suit of data
structures you can execute so basically
it's a compressed data store but once
you have this suit of data structures
succinct allowed to execute a law of
powerful queries directly on this
compressed data set okay so question is
what happens to the three problems that
i started the talk with the first thing
is that sucks ink allows you to do a
very complex queries directly on this
compressed representation in particular
you can actually search on the file
without scanning the entire file so you
can actually provide you the
functionality of indexes you can do
range queries you can do random access
and actually you can even execute
regular expression core is directly on
this compressed data okay on the other
two sides since your your data
structures that sucks into stores is no
larger than the input data size you have
now that the amount of data in memory is
at least as large as the memory capacity
but usually the real world data is very
compressible so you get a lot of kids
there okay and finally sexting does not
require doing data decompression or data
scans so we get interactivity okay so in
this space we have we have had a lot of
interesting work done over the last two
years we wrote this original succinct
paper we showed how to do queries
uncompressed data in n STI 2015 this
year we showed that the ability to be
able to do queries uncompressed it
actually allows you to look at a lot of
classical systems problems in up with a
new perspective and you get a lot of
interesting new solutions this was the
paper Ennis yeah this year we have a
paper information where we showed how to
do regular expression core is from
compressed data and more recently I have
gotten very interested in the security
side and we are trying to understand if
we can do corazon compressor encrypted
data i'll talk more about it later but
very preliminary paper that we wrote it
actually allows you to build a key value
store or it doesn't support complex
queries but now you get compression and
corruption while we were doing this
academic work we did not shy away from
real-world impact succinct is already
being used in in real world production
clusters for for large-scale web
services today that I think everybody
every one of us interacts with every day
in particular elsevier and one of the
large publishers starting to use such
thing and succinct is also into the main
code of two startups which is data rates
in backyard so this is what we have been
working on for last two years today I'm
going to focus on the first two projects
because I think they really show up my
approach to my usual approach to solving
problems which is and when you say it's
no more than one worse than it was so
I'll get more into that the second
question the first one yes is lossless
everything I'm going to talk about his
exact solutions so it's lossless
compression the second one is imagine
that we take the input file and suppose
the input file is not compressible right
so then you get no compression but
essentially what will happen is you
still get the functionality of so-called
indexes
at which people today use in addition to
your input data right so if you fix the
functionality you get a huge compression
of shell you're not compressing the
input file but you get huge compression
right if you fix yeah it's lossless
everything is lossless it's random acts
all the functionalities that talked
about you get it on on data sizes no
larger than your input data size in
terms of you're gonna have to require a
little bit of extra beyond that it's
slightly non-intuitive but yes you're
right there there are some little low n
terms but in practice yeah it could be
an epsilon but as you increase the data
sizes I think that epsilon is just gonna
vanish away in practice however if you
think about the facebook data or google
data right we see very very high
compressibility so even the numbers
today that i'm going to show you later
in the target they are very therefore
very conservative data sets where we get
a little over a little compression well
there is well we get 3x 4x compression
easily but you get the functionality of
indexes which are usually 4x larger than
than putting aside so it's um I mean
compression items actually build an
index like levels it build an engine
isn't running yeah so what I'm going to
show you today is a different way of
doing compression I'm not going to work
with lemon bishop I think there has been
some follow-up work on how to extend
membership to do our kind of analysis as
well in last year or two years ago but
yes today I'm going to show you a
different way of thinking about
compression completely okay so usually
my approach to solving these problems is
to force the first one is most of the
times the problems that I have worked on
during my PhD theses and during my
postdoc I have always been motivated by
real word problems but it's not just the
problems you know I also focus a lot on
the system resources
on what kind of constraints arise from
today's hardware so looking at these two
from from two perspectives the first one
is taking these problems and there's
some resources and designing scalable
gardens and techniques that is usually
the first step in my research once we
have a scalable gardens and techniques
then I build these techniques into
scalable systems and I really want to
emphasize this factor which is which is
I think different about my research is I
truly believe that it is very important
to look at these two perspectives to
solve these problems that we are facing
today we want to focus only on system
side then we will fail to leverage the
structure in these very specific kind of
problems that we are trying to solve on
the other hand if you were to focus only
in a large engine techniques and I have
done that in the past we are going to
ignore some of the advances that comes
out of system design so I truly believe
that it is very important to look at
this problem space from both systems and
algorithms perspective coming back to
back to researcher I want to start now
dive a little deeper and actually look
at this problem that I initially talked
about and try to give you some idea
whether this is actually fundamental
problem or is it just that these systems
are poorly designed because if it's this
problem is not fundamental it's not
probably what's alright so how do people
do today how do people do such today
where is that curve coming from so they
are essentially let's look at the same
example suppose I have this file and I
want to search for the green blocks okay
then essentially two techniques that are
known today to do this problem and to
solve this problem the first one is so
called data scans the nice thing is in
terms of data scans you store your input
data in memory right hopefully and when
equity comes in you actually scan the
entire file it's not just animation the
the data scans are actually that slow
okay so but the nice thing is that you
have to store only your input data and
hence you have low storage but since you
have to scan the entire file for each
and every query you get low throughput
right under the hand the people in the
database community have done this very
large amount of work or last decade
or two decades where they have built
so-called indexes so how do those work
you store your input data for random
access in addition you preprocess your
input data to create suit of data
structures right here I'm showing a
standard inverted index where for each
of the colored objects or the possible
queries you have already pre computed
that is also installed them right what
is the nice thing the nice thing is
whenever coy comes in you do a binary
search on on your index and you get your
result right what is the bad thing the
bad thing is that you have to store
these data structures in addition to
your input file and sometimes they can
be large so you have high storage okay
so that curve dropping thing was
happening because of this heist Roy
let's see how so the same the same plug
plot where I have data files increasing
on the x-axis and such throughput Andara
on the y-axis this is what the data scan
performance looks like for one of the
state-of-the-art databases that do very
fast data scans essentially what is
happening is you have data in memory but
your scan latency is increasing linearly
as the data sizes increase right at some
point you run out of memory and things
look bad so scans and faster slower and
slower storage and this is the curve
originally that I showed you with toxic
search what is happening over here is
when indexes are in foster story you get
really good performance but since
indexes have some high storage overhead
they start running out of memory after
16 gigabytes of data and you start
seeing this performance dropped okay so
this is actually a fundamental problem
yes
oh yes absolutely so the way I was
thirsting was that you have to store
some data structures in addition to your
input data so be trees will you know as
we know about be trees p trees have
storage footprint riches 1 plus some
alpha in terms of your input file size
right so i was talking about that there
has to be this 1 plus alpha part while
succinct is trying to do you know no
more than one okay so this is what you
pay for executing quarries of slower
storage so what's axing does like i said
earlier it takes your file it compresses
it down to this suit of data structures
and now you can execute queries directly
on this compressed data and what i want
to convince you basically essentially is
that you can get low storage and
high-throughput okay for a lot of
interesting workloads and why is this
interesting because such thing does not
have to use secondary indexes which are
actually a pain for different reasons as
well but without using succinct without
succinct using secondary indexes 16
actually gives you the performance of
indexes so essentially the data
structures that i'm going to talk about
in next few slides going to show how we
actually embed the indexing information
within the compressed representation
okay so we don't have to rate a scans
unless you actually want to read your
original data or do data access we don't
have to date a decompression okay so
getting back to this curve here's what
16 performance looks like this is the
real the real analysis now the left part
is not fundamental okay sexing does not
have some it's a very early stage system
so it does not have some of the
overheads that other systems have plus
it's written in c plus plus plus we have
spent a lot of time optimizing it so
that part is not fundamental but this
part is actually fundamental ok so we
roughly get 8x larger data sizes in
memory compared to today's systems and
usually much much more and in fact on a
60 gigabyte ram server we are able to
push more than 128 gigabytes of data and
execute everything in sub milliseconds
okay so we are actually getting giving
you more than the server capacity an
illusion of having much more ram than
what is available today yeah i'll show
you the later on yes yeah it's slightly
non-intuitive but i'll show you why it's
happening at 236 okay good so now let me
dive a little deeper and show you what
Saxon can actually do and what is the
data model and functionality so when we
started building succinct we had a big
question in front of us what kind of
traitor models did we want to support
did we want to work with documents or
small key value pairs large key value
pairs and we decided that we were going
to support only flat unstructured files
and this is that this is the 15-year
taking a step back and going into how we
used to do things 15 years ago but I'm
going to show you some very nice simple
result later on why this flat files is
such a powerful interface for today's
systems but once you have this flat
files which is on the left hand on the
right hand section compares compute
these data structures and now you can
execute the following queries so like I
said you can search so search query will
tell you the corresponding offsets in in
the flat file okay you can actually one
of the important things i think i should
mention is that the search is not term
aligned you can search for arbitrary
strings in succinct okay so essentially
you can take any arbitrary part of the
file including the arts or any any of
the delimiters and actually searched it
no such thing you can do random access
so it's starting at any arbitrary offset
in the file you can read as many bytes
as you want you can do counts you can do
append new data so Vijay suction
currently does not support in place
update so very efficiently but you can
append and delete data and then you can
do range queries and I'll like I said
you can do regular expression queries
okay so trade-offs so sexting does not
require secondary indexes it has
compression so it can keep all data in
memory and we don't have to do data
decompression
there must be something that we are
missing right it's a systems work
there's no free cake so suxing does make
some very interesting trade-offs that I
want to outline very very clearly so
what do we lose I'm going to tell you to
kind of trade-off such such thing makes
one is more on the fundamental side and
the other one is more that we haven't
reached that stage of maturity but from
the fundamental side sexing has to spend
some time pre processing the data
compressing the data right so in
compared to data scans that can answer
the queries as soon as you upload the
data sexing has to spend some time pre
processing the data so there's that I'm
lost when you want to do data axis we
have to spend some extra CPU cycles and
compare essential systems that do not do
data compression obviously such thing
works with bodies that have more random
access kind of format so search and n
random accident range queries it's not
very useful for systems like mapreduce
currently where you want to do read
massive amounts of data like hundreds of
megabytes or even gigabytes of data so
sequential scan throughput is low in
sexing and like I said in place updates
right now are supported by a delete
followed by an append so we know what
support in PlayStation efficiently on
the current limitation side we have we
have a couple of interesting projects
going on where we are looking on
supporting transactions and having
stronger consistency guarantees on on
top of 660 think does not provide strong
consistency guarantees right now okay so
these are the negative sides of such
thing okay so now let me spend next ten
minutes trying to show you how sexing
works okay and this is going to be
slightly tricky actually this crowd this
might be easier to show but but one
thing I want to take you good take away
I want you to take away from this is
that although sexting looks complicated
the underlying techniques are really
really simple okay at least the basic
part of it and i want to show you how
how sexing does this compression and
allows queries on compressed data using
such simple techniques so essentially it
builds up on some of the very old theory
work that was done in context off for
suffix arrays and FM
texts that i will talk about later on 16
has this new data structures that
actually allow you to use these data
struc in the old data structures in a
very efficient way and of course new
coral gardens that allow you to do these
powerful queries uncompressed data and
I'll talk about these algorithms later
on but let me start with this very
simple data structure that we have known
for many many years in computer science
research I think 45 years now which is
called Suffolk series okay so this is my
flat file 16 takes input as a flat file
and the numbers on the top of the file
are just showing the index into the file
so my character at the fourth index is
why okay so how do these Ephixa day's
work the first step in this file in this
construction of Suffolk series is to
actually construct all the suffixes in
the file so since it's a suffix the
entire file becomes the first suffix
then you remove the first character and
you get the next suffix and so on okay
suffix arrays then sort these suffixes
lecture graphically okay so you take
your all the suffixes and you actually
sort them lecture graphically okay now
for each of the suffix that we have in
sorted order you store the suffix
location in the input file so for the
first suffix for example it starts at
location 1 which is right here and you
store that location the second subjects
starts at location 0 and so on okay so
this part is called the suffix array in
traditional literature I am just going
to abuse the notation and just call this
as suffix race okay now in original
literature of course as you would
imagine you don't have to store this
because you can just throw the input
file I'm going to store the suffix the
set of suffixes along with the original
Suffolk learning and just represent them
here okay so it's the same thing
location of suffixes in sorted order
so while these two arrays interesting
because when I want to do a search for
example I can do arbitrary substring
search by binary search so suppose I
want to search for ppy I will do two
binary searches to find the first
occurrence and the last occurrence of
ppy right and the lower array will give
me the corresponding locations in the
input file okay so I have these two
these two areas that provide me the
search functionality what is the problem
the problem is that the topmost array
requires roughly n squared bits right
and the lowermost array requires roughly
n log n bits because this is essentially
a pointer into the input file which is n
characters so you require login bits
okay while your input file on the other
hand if it's an ASCII file is just a 10
bits so these two areas are much much
larger than your input file so let's see
what we can do let's focus on the first
so how do we reduce the space so let's
focus on the first two here ok and I'm
going to make one simple observation
here the first one in the observation
here is that this suffix is obtained by
removing the first character of this
suffix ok suppose I can store this
pointer it tells me where is the next
suffix is stored ok so this tells me
that the next suffix store at location 0
in this suffix in this array if I can
store this pointer the nice thing is
that I don't have to store this ain't a
suffix I could just store the first
character and then reconstruct the full
suffix on the fly but this pointer is
interesting from another reason as well
see these are the locations of suffixes
in the input file since I have removed
only one character my value increases by
one exactly one right which means this
point also tells me where is the next
larger integer in this array stored ok
so I don't even have to store one of
these values I can just show one of the
values and compute the other one on the
fly ok and I can recur sis over the
entire set
of excess okay so what I am left with is
one character for this N squared bits
that i had some sample values here on
the suffix array and some set of
pointers stop me if this is not clear
okay and i can compute everything on the
fly but since these characters are
sorted i don't even have to store 1 / 5
1 per occurrence i can just show the
first occurrence of all the characters
and recompute everything on the fly okay
so I've taken any squad birds and
converted into less than 1 kilobyte of
data for ASCII file sets some sample
values and the pointer values and these
sample values i can choose a sampling
rate such that the size is much much
smaller than the input file i'm left
with this array we on the same page okay
good so this is what's exciting to store
saxing stores these two some sample
values and some of the so the characters
and one set of pointers that allow you
to compute the unsampled values on the
fly yes yes go ahead give me one second
and then I'll show you so how to compete
on sample values like I said if you want
to compute on sample values I have this
notion that my pointer tells me where is
the next larger value stored so I start
with one of the unsampled values and
keep looking at pointers every look up
increases my value y1 which means i have
the simple formula where once i find one
of the sample values i subtract the
number of pointers i have looked up and
I get my own sample values okay so i can
compute the Sun sample values on the fly
so i'm left with this essentially the
set of pointers now i must have really
joked with you because what I did was I
took this massive array with n log n
bits and replace it by another array
which is n log n bits because
essentially this is a pointer into an
array of length n right so each of the
pointer values is still requires login
bits but look at look at this nice
structure in the set of pointers if I
look at all the values all these
pointers that is start with the same
character they increase they they
actually constitute an increasing
sequence
teachers okay and this is an easy proof
to show so essentially while my suffix
array is to start with did not have any
nice structure that allowed me to do
compression I took those suffix arrays
stored a collection of pointers that
allow me to recompute those suffix array
at any at any value and these new set of
pointers have a very beautiful
mathematical structure because these are
increasing sequence of integers I can
use traditional encoding techniques like
Delta encoding or run and according to
actually compress this so I'd look this
problem which was a completely
text-based problem and reduce it down to
a compression algorithm that we have
studied for many many many years it
which is run landed coding at Delta
encoding okay so this can be compressed
efficiently and those what succinct
estores as well a compressor
presentation of this set of pointers
these are very very small in practice so
Eckstein takes another step actually so
now this is more on the practical side
sixteen transforms this point right into
a two-dimensional representation
essentially what we can guarantee is
that each row is not just increasing
sequence of integers but actually
contiguous sequence of integers so you
get much better performance but more
than that this two-dimensional
presentation allows us to remember when
we were doing the binary search on the
original array we still had to do one
research on the entire array and binary
searches are not unknown to be not being
cash efficient so in this
two-dimensional presentation we show
that you can actually do binary search
on a very very very small subset of the
entire array using some very few bits
and hence you get very fast queries okay
so we get a lot of benefits from that
the transformation cost in terms of yeah
we have to spend more pre processing
time yeah in terms of space you actually
gain in practice but theoretical bounds
do not change okay so and sexing the
stores another array like this another
sampled array for for random access so
till now I just talked about search but
you also have to do this for all I know
Max's okay okay so this is all sexting
to stores literally this is just the
entire 16 technique really except for
some videos okay so if i look at the
storage versus throughput curve we
started at this point indexes had very
high storage but also very high
throughput scans were somewhere here
where you had lower storage and but also
low throughput and we have a better
point than scans now that we have
succinct okay so coming back to is the
same results that i showed you earlier
basically but now with slight more
intuition all these systems if i start
doing it for for these data set sizes
beyond 16 all of these systems run out
of memory and hence you were seeing that
drop right flexing goes all the way into
128 where things can be kept in memory
the interesting thing here is that we
can completely back up the numbers
performance numbers that we see in
particular at 64 gigabyte ram sizes this
system elasticsearch is actually
executing forty-four percent of the
queries in memory that's it right so you
would expect a performance degradation
of roughly fifty five percent
fifty-seven percent 57 x and this is
what we see essentially in the numbers
here that you see roughly 57 x
performance degradation and your queries
get down to one query per second okay so
we can literally back up the performance
of these systems using a very simple
analysis in terms of how much how many
queries are actually going to assist
ease and this is what sexting
performance looks like at 256 such thing
does run out of memory on this server
and in the performance drops
okay sorry uh there's not much dropping
me yeah it's an order of magnitude
roughly speaking yeah uh I would have
expected to perhaps even worse than a
scan because st is recently good
compared to random access yeah i think
my reason is that we we still under two
forty four gigabytes we were still in
memory i think so we had ten ten percent
of the quarry is going to SSDs and
that's how you see that much time off so
yeah but if you completely exceed ran
then we are gonna fall off yeah but it's
just that you can't go below zero which
other systems have already reached so
but yeah yeah i think over here these
just stop on saying it takes tens of
seconds to answer these quarries but yes
you're right that there is a certain
data set size where i can make other
systems that are doing scans work faster
than succinct if i were to be in memory
and disk the the gains that you get are
really for this range until saxing
completely runs out of memory okay so we
see very similar patterns for random
access as well it's just that the drop
for other systems is is much lower
because you don't have to do binary
search on SSDs anymore you have to just
go once to assess you then hence the
drop is much less significant and you
see roughly similar performance and
succinct but again the performance drop
is much lower so how do we take this
technique and turn it into a distributed
data store like i said you have to think
about multiple things in terms of data
model how do we do sharding and
replication how do we do updates how do
we handle skewed workloads try again
failures and so on so i'm going to focus
more on these three which is what data
model suxing supports and the skewed
were closed and drawing in previous
because that's where i think one of the
cool things about sexing kiss let's be
start with the data model so existing
systems essentially make very hard
trade-off of supporting one of the
written data models there so either the
support unstructured data key value
stores documents or tables in such thing
we decide that we want to go with flat
and structured files and it
turns out that using these fair and
structured files we can actually build a
unified interface to support
unstructured data and key value stores
and document stores and tables so we can
actually support and actually some more
recently so we can actually support all
these different data models using one
single system and let me show you how do
we do that so this is succinct interface
the user works with the system as if
they were working with any other system
that supports their interested data
model for example here I have a table
that has four columns okay so user
submits the table to succinct as if it
was submitting a table succinct
internally take this table and assigns
each column a you need delimiter okay
and then it writes a doll into a flat
file for example for the first column it
takes each of the values and appends the
delimiter and writes it down into a flat
file okay and then it does the same for
each of the columns and once I have this
flat file I construct sexing data
structures on top of it okay oh so the
green column in the green object in the
first column and the corresponding
delimiter is the first left on the top
left yes actually it doesn't matter but
yes all that matters is the value
followed by the delimiter so you but yes
you can read left to right column yes
the interesting thing is that once have
written down this table as a flat file
if a query comes in and says finding all
the green blocks in column one
internally succinct transforms the story
into the green block followed by the
corresponding delimiter of column one
and it is very easy to see that the
results will be collant for the two
queries because the delimiters and since
I can do tables i can do key value
stores i can do documents i can do
multiple jason's and everything right
using the simple transformation and flat
files okay so let me now us to talk a
little bit about the two different kind
of workloads skewed were closed and
transient failures and I think this is
one of the cool things I want to show
you what
saying so suctioned other side store for
this input file second source some small
number of bytes another small array and
then to sample Dirks okay so these are
really small and other two sample arrays
actually decide on saxing storage in
particular if I use some sampling rate X
then storage is roughly defined as to n
log n because each of those arrays had n
log and space requirements / the number
of samples that you are showing sampling
rate and once you want to compute
unsampled values then you have to take
those many pointer lookups so latency
roughly grows linearly with the sampling
rate okay so so can I can I build
something nice or other than just doing
replication and doing some things which
people use today so let's see how do we
use store these sampled arrays and this
part of the talk is motivated by
something that we did long long ago in
in video encoding literatures which is
called multi-layer encoding okay in
particular suppose I have the sampled
array where I am storing every second
value okay rather than storing the
sample layer as a collection of every
second value what suxing does is
actually stores this as a collection of
different layers okay let me describe
what each layer is doing so for example
for this example case of sampling rate
beam to the topmost layer here is
storing r88 so every eight sample value
the second layer is storing values of
rate for so every fourth sample value
except for those that were stored in the
top layer right and then right to every
second value except for those that were
stored in the upper layers so I have
taken a sampled array and stored it at
long multiple layers right why is this
interesting the interesting thing here
is that suppose I want to delete a layer
suppose I delete layer with rate to
write if i delete this layer sudden we
have changed my sampling rate from two
to four yes it's very simple just as
memory de-allocation I've changed my
sampling rate from two to four I have
lower storage but higher latency okay
suppose I want to add layer now remember
succinct is computing unsampled
values on the fly it's a lossless
compression technique right suppose I
want to change my sampling rate from
four to two I add a new layer so my
sampling rate changes from four to two
but I these are the these are the system
that answering user queries so I don't
want to spend extra resources filling in
values in this newly added layer but
succinct its computing these values some
of these these unsampled values on the
fly so I can opportunistically use some
of the values that are computed to fill
in this a new layer okay so I
essentially get a very low cost low
overhead way to populate these new
layers and changing the rates on the fly
so coming back to in fact just throwing
a few extra bits i can actually
guarantee that the layer addition and
deletion is independent of existing
layers in the system naturally query
execution is also independent of
existing layers so why is this
interesting interesting thing is that
remember this plot I showed you with the
indexes and succinct what this trade-off
what this layer addition and deletion
allows you to do is rather than
achieving one single point on this curve
you can actually achieve any of the
points so it actually allows you to
achieve something that we have never
been able to achieve in distributed
systems which is a smooth trade-off
between storage in performance in fact
by adding and deleting these layers on
the fly succinct actually allows you to
move along the straight off curve in a
very efficient manner okay because now
you can add and delete a storage and
depending on the performance you can
actually change your storage on the
performance requirements okay actually
better than scans you can always do
better than scans and such thing unless
everything is happening on SSDs because
you know you're paired optimal read the
scans right so but yes we do reach point
where you meet indexes the skin
as so if you have an incompressible file
then all the extra data structures that
you require are just extra ram usage yes
which would be very small yes it will be
small but it will be just extra and then
you would do which presumably would not
be able to be with this year Oh for most
of the queries you will still be able to
because still it's an index kind of
structure right so for most of the
quarries you will still be able to
answer queries of memory that extra
space might actually go to secondary
storage but that will be very small
fraction so when is it just load the
file and download the file then you
would not be able to yes yeah we're
gonna search again right right right all
right now Maxis if you want to read in
that file yeah sure leaders can be
faster okay so essentially what this
adding and deleting layers and sixteenth
allows you to do is take a system like
this where I have one server I have
three shots or three partitions on the
server and suppose the first shard has a
lot of requests second child has very
few requests and third one and somewhere
in the middle but succinct this
different layers allow you to do is
actually transform the system state into
another system state where the heavily
loaded shots can have higher storage and
hence higher performance and lower
loaded shots can have lower story to
hence lower performance okay and hence
you can have very balanced state okay
let's apply this idea actually okay so
essentially what sexting allows you to
do is increase and decrease the storage
fractionally okay and just enough to
meet the performance goals but this
raises a lot of interesting questions
that given the load how should share how
should different short share available
cash on a server and across servers how
should you schedule queries the Cross
charter because and so on right in this
industry a paper we had the simple cute
result where we showed that empirically
speaking shots are able to share the
cash proportional to the respective load
which is ideal scenario right the the
available system cache but more
interestingly you can do it without any
explicit coordination okay so the system
did not require
to explicitly coordinate between
machines to be able to achieve this very
nice property and the intuition is that
we use a back pressure stylist
scheduling mechanism that actually
allows you to schedule queries while
achieving this load balancing problem
but an interesting problem this space at
least I'm trying to understand is if we
can build any a little understanding of
whether it's actually just an
experimental artifact or you can
actually prove things about about this
cache partial to respectables because if
all the furniture for one of your end
files then either one part that one foul
sitting on one server right you can have
replicas in this case you can have
charger cliquez so those replicas on
different machines will really grow
larger yeah so some this yeah I did not
have time to talk about we are doing a
standard replication yeah right you can
have replicas multiple replica studying
on SSDs and load balancer would take
care of fish replicas need to in memory
and how much is storage they need to
have or how much cash space they need to
use know right now we have not yes right
now we are not implemented on demand
application okay but I want to show you
the application of this idea into two
cases where the first case you know like
I said people people talk about this all
the time in systems literature where
suppose you have multiple shots so on
the x-axis I have the shard IDs on the
y-axis I'm showing the load on the
charge right the state-of-the-art
solution today is so called selective
replication where what people do is
create as many replicas for the shard as
the load demands okay essentially what
what this idea gives you is a coarse
grained control over the throughput that
the chart can support so you can create
one egg national replica and you will
get 1x throughput increase but succinct
allows you to do is move along the
straight off curve and get fractional
increase so intuitively it actually
allows you to increase and decrease the
storage rather than always in 1x
granularity what actually allows you to
ink
and decrease that storage fractionally
and this is what you would assume we
would get is the we can even in the
worst case scenario what we have seen is
1.5 x higher throughput then selectively
replication so this fifty percent cash
space is is saved but more interestingly
what we have seen is that in across all
our experiments we were with an eleven
percent of the optimal throughput that
the system could support so we are very
very close to optimality and we dug
deeper into why we are sometimes this
much far away it turns out that we were
not doing intelligent placement for the
shots so if you can place the data
charts carefully across your servers you
can actually get rid of this this
placement thing but we are sharing the
cache very efficiently the case of
transgene failures is also very
interesting here one of the problems
here is that Facebook people told us
that ninety percent of their failures
were actually transient so machines will
go away it disappear but they will come
back right and to avoid unnecessary data
traffic they actually delay their
replica creation by 15 minutes Facebook
people but what is happening during
these 15 minutes is that I have three
replicas one replica goes away so all
the queries are now going to the
remaining two replicas so the load on
these replicas increases tremendously
and we applied succinct to this problem
and we showed that navigating along the
straight off curve upon loaded spikes
actually provides you a very efficient
way by adding and deleting layers to
increase the system throughput and
basically even for three x lo de spikes
so the load on one of the replicas
increases by three hundred percent by
two hundred percent suxing can add a new
layer within five minutes for uniform
boat loads by in fact for a skewed were
closed sexing can do it within a minute
as you would imagine because some of the
values in the new layer that have been
filled our can be used we used very
frequently so for a skewed workloads
that actually performs much much better
okay so I'm going to skip this finally
last two minutes i have i'm going to
talk about two or three interesting
problems to give you a flavor of what
kind of problems in trust me in general
but i think it's a great time to be
solving these problems in particular we
are working with larger and larger
scales of data
users are more and more insatiable which
has led to new challenges and
opportunities in the space of
distribution systems one interesting
thing that has gotten a lot of my
attention in last few months is security
and data confidentiality and i think i'm
planning to do a lot more work in this
space in particular the cloud has given
us access to cheap infrastructure but
then we have to upload our data onto the
cloud and customers want some kind of
data confidentiality properties and I
don't know what the reason is but in
last one here we have seen more Hardware
more new hardware announcements than our
in particular about this new memory
technologies new hardware and clave sand
and the entire data center that Facebook
design which is called the resource
disaggregated in a center so let me
drive deeper but looking at a 23 year
plan one of the things that I want to
work on is apply some of the succinct
ideas to to graph quarries and graph
problems other one is this problem about
ways to inquiries uncompressed an
encrypted data and finally this resource
aggregation data center so let me talk
about each of one graph store so a long
web services today they exploit user
information or user show social network
information to actually provide
personalized square e responses Howard
this is a very hard problem think about
this simple query which is finds all
friends absurd who live in Berkeley okay
the two ways today to do that a subset
of the systems the way they would do it
is they'll find all friends of said and
they'll find all people in Berkeley and
they will do a complex join right now
joins to the problem that we have not
resolved so far it's it's an efficiently
it's a completely inefficient solution
especially if said have a lot of friends
which is true and there are a lot of
people in Berkeley she's also true as
well right another way to avoid this
complex join is you look at each friends
offset and check if they live in
Berkeley okay what is the problem here
the problem here is that said might be
hard data so to say right but Friends of
sets of the friends have said in in the
social network case might actually be
cold data
right so so to say so to say but some of
the friends or so it might actually
correspond to the cold data in the
system right which means that even one
of these square is going to secondary
storage would lead to significant
through port degradation essentially
this is one of the known problems in
graph queries that they exhibit very
little or no locality right so there's a
locality problem in graphs and the
intuitions that compression should help
okay so the second problem is
compression and encryption so there's
been a lot of work on interactive
queries on compressed data succinct and
on an encrypted data for example crib DB
and some of the work from Microsoft
folks as well so I think this is both
important and challenging people want to
achieve the benefits of compression but
they also want to achieve data
confidentiality how it's extremely
non-trivial problem if you think about
it if you encrypt the data first and
then compress clearly encryption has
pseudo-random properties so you are not
going to get enough compression but if
you compress the rate of a sin then
encrypt server loses the ability to to
query compress data so it's unclear that
how how can we even design a system that
can do queries on compressed and
encrypted data right so are we stuck
with using only one of these either
getting benefits of compression or
getting the properties of encryption or
can we do something interesting in this
space and we have made some some very
interesting progress in this but I think
we need fundamentally new techniques to
to be able to solve this problem and
finally a resource disaggregation data
centers we have been building these
servers for for many many years that
tightly integrate the small amount of
resources and recently industry has
moved to this new architecture where
they're proposing a disaggregated
architecture essentially what this is
that we will build a blade of CPUs
blades of memory and then we'll connect
these different blades using a network
fabric as you would imagine this new
architecture completely alters the many
many fundamental assumptions that we
made in design of distributes
assumptions in particular we don't have
high CPU to memory bandwidth or low
latency and what does the failure models
look like
we exploited a locality if we don't have
cpu and memory next to each other right
and i think there will be a lot of
interesting new challenges in this space
so resources high-grade data centers is
one of the big things from the industry
side that is happening at least from
facebook i didn't oh and and academics
are just starting to look into this
space okay so what I talk to you about
today was a the suxing project which
spent most of my time with what I did
not get a chance to talk to you about
today was this resource aggregation some
of the recent work that we did in
resources hydration and in particular
about understanding what the network
requirements and systems requirements
are in this disaggregated or
architecture we actually built a system
that you can take today and go to Amazon
ec2 and actually emulate resource
disaggregated hardware using Amazon ec2
servers I did my PhD thesis on on graph
Corey sir I did not get a chance to talk
about some of the results there what we
should hear in my PhD thesis was that
using approximation and using graph
sparsity as the only assumption we can
actually get significantly better
results in in the set of a design and
build some interesting data structures
and algorithms foreign strings on a
specific set of course on graphs and we
have been doing some follow-up work
recently on this into transforming these
into real systems working with linkedin
and i i i also was involved in the one
of the early works on network debugging
which started this whole new area about
data plane debugging in networks and i
didn't follow much until recently and we
have started doing some more work
because i think the area has gotten too
complex and we can build simpler schemes
but this was my work dreama PhDs well
and i did some of the works and scalable
routing and some coding informations
here you work when I used to be younger
and I think this this kind of summarizes
the kind of research flavor I have and
none of this work would have been
possible without all the awesome
collaborators that I have worked with
over last 23 years and
some of the older works in the past so
thanks all for coming and thanks to all
the collaborators that's all I say I
could take more questions now swapping
presumably also applies when you go from
like the l2 cache to feel 3d l3 to the
Rams of where have you seen that ya know
we we haven't actually so we have seen
while building the system on how to
optimize with the l2 l3 crashes but we
haven't seen at essentially what we were
working with the data was hundreds of
gigabytes of data right so in that space
just looking at l1 l2 l3 cache wasn't
very interesting if you put in the
system operators oh yeah oh yeah
absolutely that over there the gains are
much much faster because today going to
l1 l2 l3 cache would be roughly 30 x
faster than main memory right so your
drop would be actually even more
significant because OS has also do a lot
of optimizations in terms of refitting
and all but for the kind of workloads
that we were working with which is Rida
Max's and search indexing style of
workloads so you really don't see much
benefit file1 l2 l3 cache anyways
because you are doing a lot of random
lookups or some data structures even in
binary search for example of an index
right it's it's known to be not unless
unless you actually build algorithm so
our data structures that are very cash
efficient and there's a lot of work in
that space but my hunch is that the
gains there are less significant so to
say yeah
perfect okay thank you can tell</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>