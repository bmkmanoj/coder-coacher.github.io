<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Edge of Artificial Intelligence - Human Level AI - Katja Hofmann | Coder Coacher - Coaching Coders</title><meta content="The Edge of Artificial Intelligence - Human Level AI - Katja Hofmann - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Edge of Artificial Intelligence - Human Level AI - Katja Hofmann</b></h2><h5 class="post__date">2016-08-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4SSaPyqaQho" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
I want to start by thanking Eric for
this fantastic engaging talk where he
outlined the enormous progress we as a
research community have made over the
past decades and also looked at the
challenges that are still ahead of us
especially as we develop AI technology
that will drive collaborative system of
the future where humans and AI can
really work together to solve the really
hard problems that we have in the world
today in the next talk I want to look at
project Mamo and this is one of the
initiatives that we take to enable that
research moving forward
I want to argue that a lot of this
research can happen first in virtual
environments and before we start to push
towards solutions that can deal with the
complexity and unpredictability of the
real world
project Malmo is such a virtual platform
it's based on the game Minecraft and we
have released this as open source for
all researchers to use over the coming
years we're very excited to put be
putting this out into the world and
we're very excited to see what people
will come up with so let me start by
just giving a very brief overview of
what motivated project mammal the
starting point was the dramatic progress
we have seen in AI over the past couple
of years as you have seen there have
been dramatic progress especially by
progress in the area called deep
learning for example today we have
speech recognition systems of human
level accuracy that drive already
important applications such as Skype
translators where people can go in and
use real-time speech recognition and
machine translation to communicate with
someone who doesn't speak their language
so we're already starting to use
technology to break down barriers
between people you already saw the
exciting work on image captioning and
how that can enable assistive technology
for example helping the visually
impaired community to move around in
real spaces so looking at some of those
dramatic advances some people are
starting to speculate and say well we're
so close to solving AI it's really
just a matter of staining things out
enough and if you really look closely
that is not true at all and I just want
to very briefly give a sense of what the
challenges are that are still ahead of
us and one specific challenge that I
would like to point out is that the
systems that we have developed so far
are all very custom targeted at a very
narrow application so we can use huge
amount of human ingenuity and
engineering resources to develop AI
systems that address a single narrow
task and in those single narrow tasks
those systems can become very very
sophisticated and very very useful such
as in the applications that you already
see but when we talk about artificial
intelligence what really what we would
really like to see is something that can
much more broadly meaningfully interact
with the real world if you think about
the intelligence beauty in nature you
think about a newborn child what
distinguishes their cognitive ability
from what we have in in artificial
systems today there there's just no
comparison it's a completely different
thing so it's not even clear to me that
we should be talking about intelligent
systems at all but if you look at it try
it over the course of the lifetime they
can learn to do a huge variety of tasks
they can learn the language of their
parents and the community around them
they learn to meaningfully interact with
with people around them and they learn
over time to do hundreds and hundreds of
different things that they need to
survive and meaningfully relate to the
real world around them in terms of
technology we are very very far away
from this but we are hoping that over
the next years or decades we can start
to address some of those challenges and
the dressing this would allow us to
develop systems that more genuinely
interact with the real world that aren't
hood off that don't break when they come
into an unpredictable situation such as
Eric's Tesla for example and that can
more genuinely adapt to the world around
them so just to highlight two of the key
open AI challenges that that have
motivated our work here the first that I
would like to highlight is this ability
to flexibly
learn across tasks to learn something
new as you come along and as you
encounter challenges in in some complex
environment so the goal here is really
or that the limitation at the moment
here is that current AI technology can
perform at a very high level of
sophistication but only at very specific
very on our tasks for example only at a
very narrowly defined aspect of object
recognition now the research challenges
how do we develop AI systems that learn
to perform a wide range of tasks and
I've already mentioned that reusing the
game Minecraft as as an environment for
pushing technology in this direction so
you could think about how to develop
agents that learn how to navigate around
obstacles and avoid falling into lava or
encountering other dangerous situations
you could look at how to navigate some
complex environmental climbing hiss or
how to construct new things how to use
the resources in the environment to
craft for some of the crafting table in
the game which would allow you to make
more sophisticated items like pickaxe s
and other items that you might need to
construct something in this in this
particular environment another premier
challenge is learning to collaborate so
if you are in a complex environment with
with other agents and ideally in the
long term we want to work towards
environments where AI and humans can
genuinely collaborate with each other
and complement each other then you need
some shared understanding of the space
current AI has very little understanding
or very little genuine understanding of
the human users their goals and how the
AI system could go in and support the
users goals so challenge here is to
understand how we could develop AI that
understands the users goals what they're
trying to do and how they could have
come in and really make a contribution
to the task that the human user is
trying to achieve so in the example over
here there's a mock-up of how an AI
agent could help to for example collect
resources to help a human construct a
house in Minecraft now what are we do
to kind of start even think about how we
can address those challenges I would
like to introduce the memo platform for
AI experimentation that we have
developed and that we think can really
enable some of this research in pushing
forward fundamental AI research why have
we chosen minecraft as the foundation
for this platform let me see who in the
room here has played minecraft before
just to give me a sense of what we have
here that is slightly less than half so
if you are not familiar with Minecraft
oh yeah it's a very good one whose kids
have played Minecraft roughly this it's
there's there's some over enough but
there so okay so that looks like roughly
half of the people here kind of know
what the game is about so let me just
very briefly give you an idea for those
who aren't very familiar with it so
what's appealing to kids about Minecraft
is that it's this completely open-ended
world you can go in there and have
adventurous with your friends it's very
social and collaborative so here for
example there's a Minecraft player just
exploring this world and trying to see
what is what is out there and if you if
we talk to a thousand minecraft players
they come up with a thousand different
ways of playing the game and that to me
makes them very useful for the kind of
AI research that we want to enable
because in Minecraft at the game there
is no way of winning the game there's no
sense of oh I just want to reach this
maximum score so this opens up the
possibility of focusing on research that
can help us develop agents that flexibly
learn new tasks as they go along and to
ideally push this towards technology
that can do lifelong learning and pick
up new skills as they interact with the
world
so first what minecraft enables is this
infinite variety of tasks that we can
put in front of AI agents the worlds in
Minecraft are procedurally generated 3d
worlds that both human and the air
players would experience from a
first-person perspective very similar to
how we experience the real world but in
of course a simplified form
and I think this combination of just
simplifying the program enough to start
to get a handle on it together with this
huge flexibility it's a really
interesting space for experimentation
that can really push the state of the
art for now what what have we done with
the mammal platform mama platform is the
mammal platform consists of a mod so a
plugin into the Minecraft game that
exposes the internal state of the game
to our platform and through that to the
AI researcher and it also allows agents
to be hooked into the game to send
commands to this environment so we are
providing the smart and intuitive API
for getting agents to interact with this
environment and a set of tools that is
designed to make it easy for researchers
to go in and focus on implementing their
AI agents and setting up experiments as
quickly as possible so researchers can
now easily experiment with existing
tasks or define their own using a simple
XML format or script to generate a wide
variety of tasks for their agents it's
possible to overclock the game so people
can collect data at a much faster rate
than would be impossible in a real life
system and we see here in this video
just an example of an agent interacting
with the environment and the data coming
into the system in real time this can
include different kinds of observations
including just the pixel observation of
what the agent can see as well as
internals of the the state of the world
where the player is in the world etc the
agents are embodied so they reinstalled
in a way that is much more like a real
world experience than something that
first sample just has a top-down view of
a 2d scene the environment is very
complex and dynamic and we're very
exciting to now have this ability to
also support multiple agents within
within the same environment so this
really starts to allow us to develop
systems where an AI agent and the human
user would need to collaborate within
this
to address complex tasks and this allows
us to focus on this line of work where
agents human agents and AI agents
interact with each other we have the
ability to collect human training data
and this also allows us to learn from
interaction with RIF mere human players
just as one example of how a human and
Dane and in the AI agent could be
interacting within the same environment
so here we have the AI agent view on the
Left it's trying to navigate to this red
goal there in the back and the human
with the view on the right can help the
agent to to navigate to the goal and of
course in the long run we want to also
have AI that can help humans to achieve
whatever goal it is that they are trying
to achieve just to give you a very brief
overview of what the platform is and Tim
will later on give you much more
detailed ideas of how easy it is to go
into the platform implement an agent and
run a first set of experiments but just
as a brief overview to get you started
we hook our mod into the game minecraft
as I already mentioned and the smart
runs within the Minecraft process and
exposes the state of the world through
observations and rewards and it listens
to commands that are sent from the agent
so on the agent site you really you
essentially implement this loop where
you get some observation from the
environment you may get some reward
signal that tells the agent whether it's
doing well or not so well whether it
needs to improve its performance and
then it sends back some comments to
interact with the world and have some
effect on the environment I'm very
pleased to announce that project Mamo
has been open sourced just a week ago we
are already seeing a very enthusiastic
community spring up around the platform
it's open available on github so if
you're interested to go and try it out
today I don't know how much time I have
left 15 minutes okay so that gives me a
little bit of time to just give you one
intuition or one kind of approach that
I'm very
excited about working with business
platform so very generally I've talked a
lot about AI in general and there are
different many different kinds of
approaches that people have worked with
one type of approach that is very
promising is called reinforcement
learning and reinforcement learning is
really about learning from interaction
with the environment so learning from
trial and error and learning about the
environment as you go along and
reinforcement learning interactive
learning is as I mentioned model as
learning from trial and error so it's
simply simplified viewest
of an agent that interacts with with
some environment it can observe some
stage that the environment is in can
take some action in response to the
state of the world and then it observes
some rewards observe that it is trying
to optimize this kind of approach very
naturally fits in with the mo
experimentation platform so for example
in some of our work and some of the
examples that are also provided with the
platform we show how reinforcement
learning can be used to train agents to
for example navigate to a goal in
Minecraft so for example if you look at
an arena top-down view you could have an
agent that starts down here it has to
navigate some obstacles and it has to
get to the goal without being told ahead
of time what it is supposed to do so it
really has to go out interact with the
world and figure out what it is that it
needs to do
a typical approaches for this are based
on for example temporal difference
methods where the agent estimates the
state of the or the the value of the
state that it is currently in and the
value of taking some actions in that
state and this can be done by
propagating backwards in time the
experience that the agent is collecting
just to illustrate this I want to show
one demo that that is an example that we
provide together with the platform and
this is just implementing a classic
approach to reinforcement learning that
is called tabular pure learning so in
case you're not familiar with this let
me just see if this is amazed that the
agent can actually Sophia in case you're
not familiar with reinforcement learning
and
in particular tabular pure learning in
this particular example we can see a
representation of the world as the agent
sees it so all the agent observes us the
number of the state that it is currently
in and it knows that it has four actions
available so moving north east west or
south and it has to learn from trial and
error what the consequences are of
taking a certain action in that
particular part of the world and so you
can see over time as it goes along
the green kind of areas here indicate
that the agent has found that taking
this action in the state is either
neutral or a positive or recently
positive experience and when you see
those red ones over here an observed
negative reward
so it has learned that taking this
particular action in that part of the
world and leads to negative consequences
over here you can just see the visual
representation of this which in this
case is just for us to get an
understanding of what exactly is going
on the goal is eventually to figure out
how to get to this blue square in the
back and only when the agent actually
reaches this it would observe this
positive signal hey something good
happened and then it can start to learn
how to propagate this back through its
state space to reliably get to the goal
of course the purchase like tabular
q-learning are very basic classic
examples of how reinforcement learning
works but we have seen in the recent
literature that this concept of learning
from trial and error when coupled with
for example deep learning so
automatically learning a representation
of what's going on in a visual scene can
together create very very powerful
approaches for learning interactively in
interaction with the real world and
making sense of someone's environment in
examples here I'm showing two videos of
agents that we have trained through a
combination of imitation and deeper
enforcement learning the idea here is
that if the agent has to just learn from
trial and error without knowing anything
ahead of time about the the task that
it's trying to do it requires a lot of
exploration so you have seen that in the
tabular qur'anic example the agent has
to move randomly a lot before it can get
some idea of what it is that it that it
needs to achieve in order to get
positive reward instead we can bootstrap
agent an agent from observing someone
else's behavior for example observing
how a human player would navigate to the
goal and then starting from there the
agents can learn much more quickly of
how they need to adapt their behavior to
the particular task ahead of them so
these types of approaches are very
promising and we're looking forward to
having more research that is inspired by
putting this platform out there I just
want to end with noting a few
opportunities for interdisciplinary
research so there is a lot of research
activity now in core a ID in scaling up
reinforcement learning and machine
learning methods to deal with complex
scenarios but I think there's a lot of
research potential for that for work
that needs to happen in order to finally
develop systems that are scalable and
robust and meaningfully work in the real
world for example there's a lot of space
for interaction between hardware
designers and AI researchers for example
to understand what computer platforms we
need to build to deal
with the the complexity of the learning
mechanisms that we eventually want to
put out in the world there's a lot of
space for systems and networking
research in inter in collaboration with
AI research for example to understand
how to manage complex air architectures
and pushing through the huge amounts of
data that we eventually want those
systems to deal with they're very
exciting challenges in the area of AI n
programming languages and looking at how
we will code how we will develop the AI
agents of the future and finally there's
some very exciting challenges and in
terms of user experience so how will we
define AI systems that can meaningfully
interact with us human users how can we
design systems that can take feedback
from people and that any person can
teach to do what it is that they want to
achieve rather than having someone or
rather than requiring someone who is an
expert in machine learning to get those
agents to do what they want because
we're in such an interdisciplinary kind
of workshop today it would be great to
have some more discussion on those
particular aspects in understanding how
different disciplines can contribute to
push research forward to summarize I
have given a very brief overview of some
recent advances in machine learning and
outstanding challenges in AI research
that have motivated our work on project
mammal we have Richard a proud to
announce that we have a developed
project mammal as an AI experimentation
platform on top of the game minecraft
we're very excited about the research
that this will enable and we're looking
forward to hearing back from you about
the platform and have you tried out
thank you so much for your attention
thank you
there questions comments okay so what
what aspects better work let the real
world do you think that you are able to
capture usefully in in Minecraft and
what aspects do you feel you're really
not able to model thank you let me start
with the limitations so project mama is
not designed to be obviously every
placement for for the real world there
is a coherent physics and minecraft
there's a lot of complexity but it's
nowhere near the nowhere near what
real-world physics would be like it's
nowhere near the complexity of the real
world so we think that by just pushing
on the complexity and realism in the
right direction we're hoping to create
this spot between what we can do using
current kind of evaluation platforms and
eventually moving to the railroad so the
hope is that by making it very quick and
very easy to do experiments here we can
make progress on the for example
learning mechanisms that would be
required to deal with complexity and
unpredictability once we get new
insights there we can then push those
out and have to of course fine-tune them
for realistic scenarios in the real
world
my name is a deaf a lot of a woo from
university Florida it's very good talk
so regarding the more generally I am
questioned about this fundamental
problem that is can we develop a
computer that is able to create a
methods of a methods which was that
we're not looking at a specific task
we're looking at whatever probably give
me I first to create a general method
and then the general method were
tailored down to a specific way to solve
specific problem so so humor has that
capability that that is able to so when
I learn mathematics I learn how to solve
mathematical and then later I use the
same strategy to solve physics problem
so this kind of a seems to me it's not I
interpret that as relating to the
ability to abstract to form more for
more general solutions to a variety of
problems that someone has encountered in
the past it's very much an open program
in the AI or learning community how to
achieve this and we are seeing some
interesting insights into for example
how to transfer knowledge from one from
one task to another how to learn
reusable skills or in reinforcement
learning there's something called
options that could be applied to many
different scenarios so people are
starting to look at this ability to
automatically learn abstractions from
interaction in complex tasks but I think
that in the past a lot of that has to be
put to those learning systems were not
quite complex in afront quite coherent
enough didn't require enough
common-sense knowledge as you will to
really push the system's in that
direction so I'm very excited about the
opportunities that we have with
providing those more complex tasks in
this environment and hopefully make some
progress in this ability of Aging's to
to form as fractions and and generalize
to new tasks hi I'm Adam alphabet my
team my questions kind of more of our
technical details so you mentioned that
you could speed up the game 50x to more
rapidly acquire experience for trading
models etc
in your experience is that is that
sufficient for things like dqn
approaches where you require an order of
like tens of thousands of episodes 3d
start learning something interesting
platform or fast enough to enable the
kind of method very good question it's
it depends a lot on the back of the
envelope calculations of how much data
your approach is going to need it's
certainly enough to really have pushed
us already in the direction where the
amount of data that we can collect this
is interesting enough and it's
substantial enough to address tasks
what's interesting to note here is that
because researchers can create tasks at
exactly the scale and complexity that
they need to understand specific
questions in terms of their AI approach
you can kind of work out how complex the
task needs to be how much data you
require and you can reason back to
understand what exactly the experimental
setup should be so it's very flexible in
this way and it's a very powerful way to
quickly iterate on a specific method I'm
gonna try a slightly more nuanced
version my question which is there's
been a history I mean you showed a
reinforcement learning task and I think
you know back to one piece world which
is maybe before you were born but there
there's been a history of these these
you know sick game simulation things
from Wampus world - Unreal Engine 2
various things with the Sims and
civilization now minecraft and so maybe
I'll put the question like this in this
history of I'll call them gaming
environments mm-hmm what advanced does
this gaming environment for running my
AI reinforcement learning or other tasks
have over previous existing ones mm-hmm
all right let me try again and see if I
can answer the question better I think
throughout the history of AI there as
you mentioned have been a lot of
examples of game environments and other
abstract scenarios that allow
researchers to really push on specific
questions so you mentioned civilization
something like this
can really be used to push for example
on planning approaches so that requires
some some information about what the
state of the world is and then you can
do planning there same chess go
backgammon
they all have done they have provided a
fantastic platform for pushing the state
of the earth in very specific directions
what I think is new here is this
flexibility that you can create
arbitrary new tasks within the same
coherent world virtual environment so we
can now create tasks that require to
work an agent from A to B we let's say
develop an approach that we speculate
can generalize to other tasks in rather
a flexible manner then as a researcher
we can come come up with a new set of
tasks 20 that require the agent to do
some kind of building that puts it into
a completely different part of the world
that looks very different from what I've
seen before and then we can start to
test whether we have correctly developed
a system that can generalize to new
unexpected situations I think in the
past what it was often possible to
optimize for one specific type of task
and it's pushed or it's it's held
approaches kind of focused on the narrow
AI scenarios and you're hoping that with
this with for example the crowdsourcing
huge variety of different tasks for the
agents to do we can push towards this
greater flexibility but if you're not
satisfied with that answer I'm very
happy to take it offline and can take
the last last question where I you take
it's rather thanks Ron Parr Duke
University again um so I want to maybe
this is a better question for later but
I was curious about what the state looks
like to the learning agent and and mr.
related to that I was wondering is it
depending upon how your answer that
question I'd ask is it really a pom DP
and and then also are you are you
creating a very difficult perception
problem that's maybe more difficult than
it needs to be because you picked
minecraft that's a fantastic set of
questions so let me start from the
observations the platform we have built
very flexible in the way that you can
plug and play the the kinds of
observations that you want the agent to
receive as well as the action space so
depending on the approaches that you
want to work on you could provide a more
symbolic representation of the world at
least locally you know what what is the
proc structure that exactly is is a
runty agent what items are there and
this would allow you to do for example
look at a purchase that do planning
using a reasonably known model of the
environment you could provide something
that is representative or for example
robotic sensors for example we provide
deft images of the environment as well
as just the pixel image of what would a
camera mounted on top of the robot MC in
this environment so you can work both
with individual sensors or with
combinations of those and because the
platform is extensible we're also
inviting people to put in other forms of
observations that they think would be
useful to request in that particular
environment and this again creates some
very interesting opportunities for
figuring out what sensors might be
needed to work in something you know
that eventually moves towards the real
world the prom DP there's a lot of
partial observability there depending on
how you construct the observations it
may or may not be an MVP we have already
noticed that the assumptions of for
something discrete time steps breaks
down quite quickly when you try to
address the full program of navigating
in Minecraft there are a lot of things
that the abstractions that we typically
use don't capture quite well and I'm
very happy to follow up on that online I
all right all right well thank you very
much and I'm sure we'll have more
discussions on the details here but just
before I let you go Katya so what would
you say today the audience's for project
manager we have professors for both
researchers educators do you have to be
an expert in around yeah I mean you know
for what it today fantastic question
we did
the platform with AI researchers in mind
but the moment we put it out and made it
publicly available we noticed that it
was also appealing to different
audiences all the way to for example
enthusiastic high school students who
know a little bit of coding have maybe
done a few coding exercises in Python
but they're very excited about Minecraft
and they were able to come and go
through our tutorials and get started
and playing around with some of the
agents that we have here so the barrier
to entry is actually very low so invite
everyone to go and play with it of
course the opportunities are quite wide
open in terms of the sort
sophistications of the agents that you
can eventually develop there all right
thank you very much gotcha
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>