<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Authenticated Data Structures, Generically | Coder Coacher - Coaching Coders</title><meta content="Authenticated Data Structures, Generically - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Authenticated Data Structures, Generically</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/srbzojREi4I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
Oh sleep I pass so it may swell their
kickoff so it's great pleasure to
welcome Mike Higgs for Maryland and who
says sort of passing through and so I
think he's going to give us a sneak
preview of his latest and greatest pop
wallpaper so like thank you very much
always fun to come by so this is joint
work with Andrew Miller who's a grad
student at the University of Maryland
and then also my colleagues Elaine she
and jonathan katz so this talk is about
authenticated data structures so many of
you might wonder what is that the idea
of an authenticated data structure can
be illustrated by this example which as
we'll find out toward the end is what's
called a Merkel tree the idea is that
the server is going to maintain some
amount of data say has a tree and at the
client you'll maintain some much smaller
amount of data a hash that is used to
spearhead queries to the server and your
goal as a client is to be able to submit
queries to the server for example a
fetch query and get an answer back and
be able to confirm after receiving the
answer that it's actually authentic that
the server did not lie about the answer
that it's giving you and it's going to
do this by recomputing some
cryptographic hashes so I haven't
explained what the data structure on the
left is doing each of the nodes in this
complete tree has hashes stored at it as
you can see and the leaves of the tree
have strings so you can think of this as
implementing a random access array where
the fetch to query is basically you can
read that as a bunch of bits where it
will follow the path down the tree
that's bolded there to get index to
inside of this array to return the
result now the proof that sent back
these three little ovals here on the
right include hashes that were gathered
along the path to returning the result
and these hashes are then used by the
client to confirm that the result makes
sense so the first is the string itself
that's the returned result and that can
be combined with the second thing h7 in
order to confirm the hash h3 in the tree
so in other words what the verifier will
do what the client will do is that he
will take the hash of stir to and he
will take h7 and he will concatenate
them together and reproduce for himself
h3 which is the blue node there in the
tree having being having Rida terminate
to which is the node on the other side
of the tree which is provided in the
truth in the proof concatenate those
together compute the hash and therefore
reproduce h1 which is the root of the
tree now remember he started with h1
which is there on the right and so of
all of these hashes work out the client
has now confirmed that the the server
actually did the right thing assuming
that it would be very difficult for the
server to have reconstructed these
hashes in some other way that is to have
found a hash collision yeah I think old
it seems that you've proved is the
server follows the trade that's right
that's that's the goal okay we just want
to make sure that the server did
actually if if the tree that I have the
hash for h1 there in the upper right
represents the tree that the server
really has and I say to the server
please give me the second element in the
tree I can confirm the server didn't
give me the third element in the tree
instead what it did was the server had
to have followed that path and had to
have given me the actual results stir to
there at the end is it true whose
hatcheries age one that's right that's
right so you can you can ask you can
wonder well so what might you use this
for why don't I tell you what you can
use it for and then you'll sit down the
tree the server could have yes if I be
handed back all life is hanging off the
path right except following the
different paths would have given you the
wrong answer and because the bottom here
i'm taking the hash of the answer stir
to and therefore if the server took a
different path but returned stir to well
what do I care if
took a different path and returned stir
one then the hashes wouldn't match up
return the age four and h3 on this path
every just returned ashes that you just
throw down different set of hashes in
the green and the blue boxes the
ordering and the hash function matters
yes the Canton concatenation here is
left right when you're when you're
computing the hash of these two things
if you've gone the other way then the
hashes wouldn't a matched up oh the
older of this hash brown okay since mess
find the path for the Trinity okay so
what does the clients asked for
specifically it's the true number the
client is asking for whatever is that
this this location fetch to so this is
this to hear just represents in binary
notation the path through the tree left
left is 0 right is one this for one bout
you da belief and it gets a hopeful that
big yes that's right okay so as I was
saying this is this is a Merkel tree so
this was invented quite a while ago and
why might you want to use one of these
things well here's one example trust
worry trustworthy mirroring and
duplication suppose that you have a list
you have a set of things that are
important for example all the tour relay
servers and you want to be able to
mirror that list so that people can get
the answer to their queries what's the
nearest tour relay server to me from any
server rather than the one trusted
server that's known to maintain the
correct list so right now there is one
trusted list that NRL maintains of all
of the tour relays which is a pain
because now everybody in the world has
to contact NRL to find out what the
closest relays to to them might be so if
we use authenticated data structures
what we can do is the trusted list can
publish the hash of the root of its data
structure all the clients will have the
hash of the trusted data structure and
then they can go to all of these
untrusted servers to confirm that
they're actually getting the proper
answers to their queries right so they
can have confirmed confirmed answers and
you can imagine this sort of trustworthy
mirroring working in other cases to like
with public key servers or for
distributed file system so that's what
the tahoe la FS beautiful file system is
for right anytime that you want to have
server store things for you and answer
queries for you where you don't
necessarily trust the server but you
have a root of trust from something that
you do trust for example this trusted
server that's being mirrored then you
can use an authenticated data structure
to do that mirroring reliably another
place where this happens is bitcoin I'm
sure everyone is heard of Bitcoin before
Bitcoin uses a form of authenticated
data structure to confirm that
transactions over the global ledger of
Bitcoin transactions are authentic and
that's because it's a peer-to-peer
distributed system and we don't want to
go to one centralized place to be able
to confirm whether a transaction is
valid or not and so instead we can use
authenticated data structures to do that
so I'll show you an example of how
Bitcoin works in terms of the language
I'm about to introduce to you at the end
of the talk you say oh lots of our
traffic sounds can happen real a
directory will publish the habits hash
and if anybody wants to access it they
say to an untrusted cloud give me the
direction it gives you the whole
directory and the hash and now you can
verify and what you're doing here
there's oh no you don't have to hand
over the whole to actually we can hand
over just a little piece in a poof
that's right okay so thank you thank you
good explanation okay so it turns out
that as I said this is an old idea this
authenticated data structures idea and
there have been many variants of
authenticated data structures developed
over time so merkel trees was the first
but since then people have developed
authenticated skip lists and
authenticated red black trees and
authenticated be trees and each one of
these new authenticated data structures
has warranted a new top tier paper in
some crypto conference and why is that
well it's because every one of them
developed the whole idea from scratch
they designed the data structure the
representation that designed all of the
methods the the queries and so on for
that data structure and then in a heroic
effort they constructed a proof to say
why all of these methods are going to
give you the answer that you expect so
our observation was well why do we keep
doing that we we have programming
languages for a reason can we not
develop a programming language in which
we could code up these data structures
so that by virtue of coding it up in our
language we'll get this authenticity
property in the way that we want and of
course I'm here so the answer is yes
so the language that we develop we call
lambda off it's a purely functional ml
like programming language as you'll see
in one slide it's a very small extension
to support coating up authenticated data
structures the idea is that we will take
a source program that very much
resembles the normal code that you would
write in ml for a data structure and
then we will compile from that two
versions of that code one that runs on
the server which we call the prover the
other that runs on the client which we
call the verifier and what we can do is
we can prove that by virtue of the
program the original program being type
correct the authenticated versions the
verifier and provers versions when they
participate in this protocol it will be
both correct that is if they follow the
protocol they'll get the right answer
and secure that is if the prove our
attempts to subvert the protocol and lie
by going down the wrong path in the tree
then the client is going to discover
that it with very high probability and
we have an implementation of this idea
we made a small extension to the o camel
compiler and we have used it to code up
as far as we know all existing
authenticated data structures plus many
interesting variations okay so how does
it work so this is the main idea so you
have a purely purely functional
programming language so and all the
standard features that you would expect
with data types and recursive types and
recursive functions and base types and
so on but it's purely functional so no
Refs we'll see why in a little while why
refs would be problematic and then we're
going to add a new type called off T for
authenticated of T and we have two
constructors to coercion zeeeee one that
inch that introduces authenticated types
from their regular variants and another
which unauthentic a 10 which turns them
back into regular type so that we can
compute on them as we expect then we'll
have a different we'll have two
different evaluation modes one for the
prover one for the verifier the prover
is going to produce this proof that i
showed you before this list of these
little objects that it's going to send
back and the verifier is going to
consume this proof and what we'll be
able to show is that in an ideal mode
that is a mode in which we can ignore
what authenticated types are doing we're
going to be able to relate both of these
results back to that mode to
that we've got the correct answer so let
me just make abundantly clear what ideal
mode is ideal mode is the identity that
is in the ideal mode authenticated types
are just regular types and author none
author the no op coercion and so when
you write code in our language it looks
just like the code you would write for a
regular binary search tree and o camel
except for the appearance of these off
and uh naught and the both the types and
the coercion so what is this what is
this type so the binary search tree is
just nothing at the leaf and then bin is
is a regular node where it stores some
value and then of course it has a left
child in a right child and in our case
the left child in the right child are
going to be authenticated so you can
think of it as this is where we're going
to be storing these cryptographic hashes
so I'll make that clear on the next
slide we're going to when we compute
over this thing you'll match over the
unauthenticated version of the tree so
you have to do uh naw thought on tree
because tree is an authenticated tight
so we coerce it back to its normal tree
and then we can pattern match on it and
then do the standard thing in order to
look up membership in the tree the
integer is not authenticated that's
right so it's going to be by virtue of
how this all works so hold on to that
thought and we'll see okay so now let's
look at how the prover and verify our
modes work these are going to do
something interesting with authenticated
types and they actually have two
different views of how authentic ated
types are represented and so these two
views are shown here on the right-hand
side the first that's stored at the
server and our initial example is just
the tree with all of these little hashes
the the Diamonds stored at various nodes
and then on the client it's just the
hash itself so let's make that a little
more specific at the prover a value of
type off T is a pair where V has type T
and D is a cryptographic hash of what we
call these shallow projection which we
write s POV pictorially we write these
little diamonds for for the hashes the
idea with the shallow projection is that
we're going to
serialize the data up to but not past
any nested authenticated types and then
we'll take the hash of all of that so
for example here in this tree the
shallow projection of the root is just
going to be this node okay so we'll go
down one level we're at that bin node
the bin node has three elements a left
tree and a right tree those are both
authenticated so we stop computing the
shallow projection there and then we
just have the integer so we have the
value at the node and we have the two
hashes and then we'll serialize that up
into some linear representation and
we'll take the hash of the whole thing
so you can see the analogy with the
Merkel trees that we saw before that
each of those nodes had the interior
nodes had the left tree and the right
tree the two hashes next to each other
and then we took the hash of those
things for the next level up we're doing
the same sort of thing here except in
our data structure we have the the
integer stored at each node rather than
only at the leaves as if it being a
parent to Jersey to see allows that
there's a tree of integers with no
education soon as all of that exactly ok
exactly right ok and at the verifier a
authenticated type and off T value is
just the cryptographic hash ok and so
that you can see here that the
relationship between these two things
the prover mode in the verifier node the
verifier mode is giving you this
compression I don't have to see all the
data to maintain the tree myself I just
maintain the hash where is it the
proofer I get the entire the entire tree
ok so now let's look at the
representation the semantics of the
different coercion the author none auth
coercion so the auth coercion auth V is
going to return this pair DV where d is
the cryptographic hash and the way we
just described it's the hash of the
shallow projection of V and the verifier
is just going to return the hash because
the verifiers representation is only the
hash and not the value ok so the
interesting part is the UH north of
comes into play the verification object
is a list of shallow projections of
authenticated values and how is that
list produced well at the prover we're
going to do uh naught in an
authenticated type at the prove are
authenticated types RDV pairs so what
we'll do is we'll compute the shallow
projection of V and stick it on to the
verification object and then just return
V so that we can subsequently pattern
matching over it just as we
showed a moment ago at the verifier at
the corresponding position you're going
to do a nun off what uh knopf d will do
is it will pull off from the head of the
verification object the current shallow
projection and it will confirm that the
hash of that shallow projection is in
fact the hash that it currently has in
its hands is an operational semantics
noise language that has a global
verification object and a certain
evaluation order these calls that's
correct i'm going to show you the
operational semantics in two slides
least offer than that's the food right
that's what's happening so you can think
of it as the prover is producing each of
these elements right we saw them the
little list that's these shallow
projections and the verifier is
basically running the same code right
it's the same code in two modes except
off and unauthorized one of these
elements from the from the list the
verifier pulls it off and confirms the
hash that it has corresponds to the hash
of the thing that was on the list so so
let me show you the operational
semantics and that'll make it abundantly
clear so it's just a small extension to
call by value simply typed lambda
calculus semantics we'll see that we use
a normal form just to keep things simple
and instead of actually doing
compilation in the formalization we just
have three different evaluation modes
where the semantics of off and on off
and so on are different depending on
which mode you're in and we've proved to
the correctness and security properties
and i'll show you formally with those
mean so this is the syntax and semantics
of the language or sorry the syntax and
some of the type rules for the language
so all of this stuff is standard except
for these things function type some
types product types recursive types all
the standard stuff that you would expect
plus these two additional forms and the
type rules correspond to the the typing
that I showed you earlier ok so now
let's look at the semantics so there's
basically three modes you start with
that program that we showed before the
membership
is a syntactic foam you say map although
for something and I mean in other words
well have it no it's it's an it isn't
it's syntactic also in the
implementation I'll show you why lamb do
actual facts yes you you you could
that's right you could do that I'll be
totally fine so any fact that that first
but it personally do so so yes but hold
that thought and I'll tell you where
some complications come in okay so so
yeah so that we have the source program
and we're going to think of these three
variants of the program we're not going
to really compile it but in our
implementation we will so we'll think
that we have the ideal version the
provers version and the verifiers
version and in all three modes of
evaluation of our source term the
semantics is going to be sort of the
standard thing so this is just showing
the rules for case expressions over some
types and also projections over product
types and our judgment is just going to
take a pair a configuration where pi is
the is the verification object and the
term right next to it is the value that
we're reducing and that's going to take
one step to the new verification object
whatever that happens to be and the
one-step reduction of the original
source term so we can see is that for
all the standard terms in the language
the proof stream their pie right it
doesn't change I have pie here I have
pie here so doing a case or a projection
or a application or whatever it doesn't
change anything and this is true in all
three modes in the ideal mode as I
already mentioned to you before off V is
just the no op unauthentic to the proof
stream okay so the idea is that when we
look at our code and we think about sort
of morally what it would do if we didn't
split it out into this proved her and
verify her part we should be thinking
about this ideal mode we're just going
to sort of run normal binary search
trees as usual we're going to ignore
these silly no op koers and that's what
the semantics is making clear okay so
now let's look at the semantics for the
prover and the verifier modes on the
left here is the semantics of shallow
projection so we write it as this
whatever this little function and
shallow projection is just a congruence
where the congruence quits when it hits
one of these authenticated values so an
authenticated value is a hash
followed by value and that's an
unfortunate notational difference right
so it's the same as d which I was
showing you before so i have this pair
which is the hash and the value when i'm
doing a shallow projection I stopped
when I get there and I just returned the
hash and then otherwise I just
recursively descend into the term as you
might expect all of you is not a value
know so why we got a case for it is we
just have values inside these show no no
we don't we because we're gonna descend
into lambda terms too oh I see to go
with it's a whole bunch of other black
case and so forth yeah they're all
congruences that's what I just said oh I
could show you all of them but they
would be telling you the same thing
thing which are you previously said it
was something to do with you serialize
the data's Jochum producer hash no after
you going to serialize code to we are
potentially going to serialize code we
can make anything authenticated into
including closures it's not scary code
is just data and data is just code right
come on okay so here are the rules for
off for the prover in the verifier so
notice little index here which says
which what the modes are so for the
prover off is going to take the shallow
projection according to these rules and
then it's going to compute the hash of
it and it will couple it with the value
so just what I said before now here it
is formally and then interestingly here
I'm not taking the shallow projection
because as it turns out you might have
already observed this the relationship
between the representation of data on
the prover in the verifier nodes modes
is that at the verifier the value is the
shallow projection of what it was at the
prover right so remember the proofer had
the entire tree and the verifier has
just the hash of the tree well just the
hash of the of that tree that that is
the hash of the shallow projection of
something of type dot tree is just the
hash right according to this definition
right up here so this already is in some
sense the shallow projection and so we
just have to take the hash of it okay so
now the interesting part is uh naw for
the value that it's
that it's working with and stick it on
the end of the verification object and
then just return the value itself so
again this value is an authenticated
value on the prover that's a pair of H
and T so what we'll do is the
verification object is as I said a list
of these shallow projections there we go
we take the shallow projection we stick
it on the list we return V and and carry
on now on the verifier we're going to be
doing consuming this verification object
in the same way so now we're going to be
taking off whatever is at the front of
this list we're going to compute the
hash of it and make sure that it matches
the hash that we think that we should
have on the verifier side if this hatch
matches then this step is allowed to
proceed and we're basically and dq'ing
the thing from the verification list yep
why is there a transition p of v in the
verifier and why is there this
transition no no no indeed appear in the
this one this one yes because often on
earth have semantics in both cases so
let me actually here I'll show you just
a second you were a it's a fair question
okay so we already saw this this query
here's where you need off on the
verifier this is that well this is eight
remember there's just code right and we
can run it in Barrow fire mode or prove
or mode so if you ever would use off you
need an interpretation of it at the
verifier but you might rightfully ask
look we didn't even use off anywhere in
this query why do you need off ever and
the answer is for insertions if you ever
construct authenticated data you need to
authenticate it so here I'm inserting
something into a tree so I have to do
off of all of these things and at the
verifier I'm going to have to add this
new node to the tree so I'm going to
have to compute the shallow projection
in the hash and so on to make these new
nodes so that's where this will happen I
should say that this is one way in which
our language improves on what people
have done before a lot of the time when
people make authenticated data
structures they only do queries for them
they just assume there's some
out-of-band process by which a trusted
person makes the the modifications to
the data structure and you're only
authenticating the queries we can
authenticate whatever you want to
yeah so this anyway so what would happen
here this is returning a new tree so
what would happen is the server would
actually return a new hash that the
verifier would now start using is the
new root of the tree okay what the
things on the verification object are
those s do is what type today they have
his or late they are they it's hard to
say what their type is they are they are
shallow well see the problem is that
they're sort of in between these two
modes so they're shallow projections
where I guess basically they're they're
the verifiers representation of
something of of the type that you did uh
naw thought if that makes any sense so
in other words if if I had something of
off T and I called uh naw thought it on
the prover then what will be on the
verification object will be as something
of type T from the verifiers point of
view so something of type T from the
verifiers point of view has everything
of authenticated type as being just the
hash and that's basically what a shallow
projection is something is it just this
tube is no it is a regular I mean see
what's happening here is I'm taking this
thing off and it's now I'm now computing
on it so I mean it is a regular term
it's just the verifiers representation
of the term that's all yeah absolutely
it's the verifiers representation of
something of type T where the
unauthentic was operating on type of T
we pushed on the line above was square
brackets of shallow projection of V
let's go back to such as the list
element yeah that's right I see in the
shallow projection thing is that's right
so if this whole thing was of type T
then this thing here is going to be the
verifiers version of something of type T
Silla term I was misled by you said it
was 70 with civilization so you has been
ordered in practice in order to hash it
you
to serialize it you're not hashing
structural terms right yeah laughing
takes place on that a dopey line the
hashing takes place designs above two
lines up there this is where I happen
right where things are being such a
shallow projection so that moment you
like to about it but this got the guy
that says the second the second rule
from the bottom this one here yeah
that's right right there's no serious
there's no hashing happening here we're
just pushing the shallow projections the
hashing is being confirmed here so
sweetie step you as much as the vaunted
value will know exactly what's the type
of the value of the app I didn't go
hiding that's right but it changes all
the time yeah that's right yeah so so
right so the key here is that we're
running the same code on both sides
right and all we're doing is
interpreting off and on off differently
so as you said in the very beginning
there's an assumption of evaluation
order and so on so that when the
verifier reaches an done off its the set
corresponding uh naw that the prover
used to produce the particular element
in the stream that it's now going to get
to compute on okay so so let me show you
what the security theorem says what it
says first of all is correctness if the
prover does the right thing if we if the
prover is is not trying to lie to us
then the verifier will get the right
answer and that's to say that the prover
and verifiers final results will agree
and I'll formalize what agree means in a
minute security says if the verifier
gets an incorrect answer so I got three
instead of four then the only way that
that was possible is if the prover was
able to discover a hash collision which
we're going to assume is computationally
difficult because we're going to use a
collision resistant hash function for
our hash function and the nice thing is
that this is a constructive proof that
is I can actually show you the hash
collision in the proof it's not sort of
a conceptual thing it's now here's the
hash collision that they must have found
in order for this wrong answer to have
occurred so let me formalize for you
what agree means so intuitively you can
think agree is the same right so if I do
a query at the prove or and it produces
it says oh you the this element is three
then at the verify riedel all
so get three okay that's fine the only
problem is that well what if the query
that returns something that is itself
authenticated if the query returns an
int well then agreement means syntactic
identity but if instead on the proofer
you would return something that's
authenticated like for our insertion
example that I just showed you the
computation is going to return an
authenticated tree well on the client
and the the prover and the verifier that
representation of these things are
actually different they're not going to
be syntactically the same so we have to
do is we have to formalize what we mean
by agree as being sort of morally the
same so all of these rules just say I
can relate all three of these terms the
ideal version the verifiers version and
the provers version and for everything
all the standard term forms in the
language it's just it's the same the
interesting case is that is this case
where we have these three different
representations so when I have a value
that's of type of T on the ideal mode
when we pretend we're not doing
authenticated stuff it's just something
of type T that is it savvy if it's on
the prover side it's the hash and some
value and if it's the verifier side it's
just the hash so first of all we can see
that for these values to agree these two
hashes have to be the same it's
certainly not going to be the case that
if you have an authenticated value if
the prover would have come up with one
hash the correct prover and the verifier
comes up with a different hash well then
these terms clearly can't agree the
other part that's interesting as well
how does v relate to vp so you might
immediately think oh v and vp ought to
be syntactically the same but we have
the same problem because vp might be a
recursive type that itself contains a
bunch of authenticated things so
therefore what we need to do is we need
to recursively make sure that all of
these things agree one level down and
agreement needs to be on the shallow
projection of VP since again the
verifiers representation of something at
the prover side is always it's shallow
projection so then we just make sure
these agree and we make sure that this
hash of the shallow projection is in
fact the hash H that we have so all of
the invariants that I have been saying
all the way up through this talk are
expressed in this one rule and say the
terms will agree if all of these
invariants are satisfied yeah the
Malaysian isn't this
function also liked because hash is mine
uh no actually it is it is functional
thick so you could just go up functional
relation that's a good point to what
welcome one somatic so another well
there are three so well click on what's
magic so another one to another from the
real dude yeah you can do it that way
it's a fair point idea was from the
ideal to all right yeah so I mean we're
always talking about all three things at
once so sorry movies new game until play
I'm just old yes yes so that's important
because I'm glad you brought that up we
don't want any free variables showing up
inside of these terms because if there
were free variables and they could be
substituted differently and that would
be bad so the lack of the gamma make
sure that values are actually closed
which in a call-by-value semantics you
should be only starting with executing
of clothes terms anyway and these gammas
are only here for descending into lambda
terms when we're doing agreement part is
part of the congruence so it's just
saying the values yep the value that
values of type T as opposed to terms
that might be off of something that have
type off T values should always be
closed and values will never show up in
source programs only show up as a result
of evaluation correct absolutely
excellent observation yeah hi different
strategies on the boy outside like
you're keeping your a shove everything
look at it at any place but in principle
you can only compute them on the fly
yeah but what so you're oh I see what
you're saying and this this is well for
one strategy where you click on control
the ashes on the cool side that's that's
a good point so our semantics doesn't do
that we have a couple of optimizations
that do things differently than I'm
describing here that's not one of them
but that would be a fine optimization
that you could implement because the
point is that you would still morally be
implementing the semantics you just be
lazy about the computation of hashes
but I'll show well actually I don't have
slides for a bit assuming we have time I
can tell you about what the
optimizations do okay so now let's
formalize the security theorem so the
security theorem says let's say we start
our evaluation with these three terms in
agreement to begin with so at the very
beginning when no evaluation has taken
place at all right I just had this query
in the tree well then they're obviously
going to be an agreement because they're
actually literally the same term on the
other hand as I'm evaluating I want to
say that I preserve agreement and so
hence i'm going to have these three
identify these three different terms
that are all related so correctness says
well if the ideal mode and I've now I
haven't shown you this but I now have a
new version of the semantics a
multi-step version of the semantics
which is the obvious you know
application of the transitive closure to
these rules where I is the number of
steps that are actually taken so what
this says is that if in ideal mode I
start with E and I take I steps to get
to e prime then if we run the prover the
same number of steps and we give its
output to the verifier we're going to
get the correct answer okay and one
thing that's important about this is
that we're relying on our language being
sensible because we're assuming that it
can take n steps right if you if you
immediately start thinking of type
soundness as an analogy of what we're
doing here we don't prove progress for
this correctness theorem because we
assume that the ideal language is
already a sound language that is our
ideal interpretation you're never going
to get stuck with a type error because
you'll have a type correct program and
therefore we can always assume that the
ideal mode can take as many steps as as
it wants to up into the point that it's
a value so in that assumption we can say
that will get the right output if the
verification stream that the proofer
produced is the one that the verifier
actually consumes we're going to get the
right answer now securities says well
suppose we had a malicious prover why do
we why do we have the little I here
because it's the same I and so that's
used really useful to reason about say
asymptotic complexity so because it once
dead then yeah obviously one step that
was fine yes that's right so so oh I
just I don't know just because I mean
why do people when they prove type sound
is
prove it for the transitive closure
version just because I mean yes in order
to prove this we have a bunch of lemmas
that work in the one-step case and one
step it would be vacuumed immediately
true further and I steps but by
induction and I yeah yeah absolutely
that's right soon what exactly there's
nothing complicated there's nothing
complicated because so you see it's like
to two more premises so art so if an
idea about the egos requirement and the
kruger produces a pee and the verifier
consumes it's not exactly that it's
saying if it's an ideal mode then the
legitimate proofer will also be able to
take I steps and produce approve and
assuming that it does that the
verification will be consumed the proof
and produce the result so with the vereb
the only premise really is this one if
it can take as many steps then the rest
follows okay so security is saying let's
suppose the wheat wheat some malicious
prove er produce this pie a instead
where they made some random verification
stream to try to trick the verifier into
doing the wrong thing so what this says
is that well either it's correct so this
is basically restating this but slightly
differently so ignore that for a second
the more interesting case is this one
which says that if we get an answer such
that they don't agree then there was
somewhere along the way for some J
that's less than or equal to I so you
know if I took five steps then somewhere
before that at two or three or four or
maybe five I I came up to a point where
my stream contained the legitimate
prover would have produced a stream that
had this s here at the end but the
adversary stream had while having the
same prefix pi zero now has this s
dagger and S&amp;amp;S dagger are not the same
shallow projection but they have the
same hash okay so the point is the only
way we end up with an incorrect answer
is if you could fool me into believing
that the hash was correct even though
you didn't actually provide the correct
shallow projection okay in other words
you had to find a hash collision and
that's it there's a hash collision right
there alternatively if you did give me
this pie which is the same pie that the
prover would have produced
and maybe you gave me a bunch of extra
stuff that I don't care about well then
everything's good and we're going to end
up with an agreement stuff okay so this
is the key right somewhere along the way
you found the bad guy found hash
collision and so the security of our
whole system now boils down to the
standard cryptographic notion of
security which is it's hard to find hash
collisions and in the paper we we go
into more detail to relate sort of the
crypto people's view of proving these
things to how this security theorem is
basically the linchpin argument in a
bunch of other standard steps to proving
security for authenticated data
structures yeah the same program go I
mean if you try to relax the assumption
does everything fall apart or is it just
sort of convenient to to make the
argument formally in this way so when
you say the server and the prover those
are normally the same role yes right
we're in the verifier it's critical they
have to run the same program they have
to agree on the way that they're doing
the computation and if they if I mean up
to that up to the level of abstraction
of this operational semantics I mean
sort of what Cedric was saying you could
certainly imagine computing things
differently for optimization purposes as
long as we agree on the way that we're
communicating this stream of
verification objects with the verifier
just always say no pretty much yet but
that would be okay as long as the bear
fire doesn't say yes when actually
that's right this exactly but but that
argument would isn't isn't made by this
proof this proof is basically just
saying that well it is sort of being
made by it this proof is just saying
that if the prove our runs the right
code then if I consume their
verification stream I'm good otherwise
what it says is that the malicious
proofer can do whatever it wants any
prove it can do whatever it wants to
produce some other stream and we won't
say anything about how it produced that
stream it could run the wrong code it
could flip coins who cares it's going to
produce that thing the only way I'm
going to end up with the right answer is
if it morally would have done what the
normal proofer would have done and if
it's somehow I don't I don't get stuck I
managed to get to the end and and think
that things are okay the only reason
that's going to be true is if
a that process produced a hash collision
so you'd only get you'd be lucky if or
very very clever if you ran the wrong
code and you still got everything to
work out okay okay so I I don't have
that much time but i'll give you a
flavor of how the implementation works
so we extended o camel while in our
formalism we can handle authenticated
closures and there are actually some
really nifty examples of using
authenticated closures for example
compiling programs at UC PS it's
actually difficult to do it for a
statically typed language because in
order for it to work you have to know
what the type of all of the values in a
closures environment are you have to
know whether they're authenticated or
not and in general if you have a
function from T to T prime you don't
have any idea of what the type of its
claw of its environment is so at the
moment we just say no you can't have
authenticated closures in our
implementation one easy relaxation to
this would be to say we only allow
closures that have empty environments
and you could make a special type for
those and say those can be authenticated
because then I don't have to actually I
know that they're following the
invariant Simon that you pointed out I
know that there aren't any authenticated
values that are in this closures in this
yeah this closures code because the only
way I could have authenticated values
they showed up in the environment but if
the environments empty then I know it
can't have any of them so we could do
things that way and but in any case we
don't so we've implemented a whole bunch
of 80s is so you've already seen a
binary search trees but we have a bunch
of other ones okay I guess I'll show you
the code so it's cool this is the whole
implementation it's one slot okay so
what's uh what's an authenticated value
well it's a we sort of did you'll see
why in a second so there's this is the
the verifiers representation is the
digest of the string and the prefers
representation is again the hash and the
value so off at the prover is auth
proved ER and here's where we had to
modify the compiler so in order to
compute the shallow projection we need
to have a function that computes the
shallow projection for the value of type
if we were implementing this in scheme
we could just run code that ran through
any arbitrary term and figured out how
to compute a child projection at runtime
because we're doing in a statically
typed language we can't do that so we
have to act compile-time generate the
shallow projection functions for
whatever types were interested in so our
generic implementation takes the shallow
projection function as an argument along
with the type and there are little
preprocessor and search the shallow
projection function every place at the
prover you do one of these off calls
right so polymorphism and closures are
where this strategy falls down but
otherwise this implementation is just
matching the semantics rules right it's
computing the shallow projection and
making these little values and in this
case it's uh naw thiking it on this
channel which is the verification stream
whereas for the verifier it's pulling it
off the channel and then it's doing the
assertion and returning the result okay
so this is just Oh camel code for the
semantics that I already showed you and
for the text that i showed you before
that so there's a default shallow
projection for authenticated values
right that was the one rule that i
circled on the math that if i have an hv
well then the shallow projection of that
is just the digest itself it's just the
age part the shallow projections for
everything else are going to be
automatically generated by our compiler
so this is just suppose we have this
user code then these would be the two
shallow projection functions that would
be produced I'm just going to gloss over
it for time purposes we also have these
so basically this shallow projection is
operating on the entire BST type and
then it will also compute the shallow
projection of this guy which is is
computed right down here and then we
have all thin unauthorized that will be
stuck in at that point in the code right
so every place we see auth of something
of type T will generate a shallow
projection function 40 and will plop it
in there on the on the prover side
to channel this also needs to actually
it has to be polymorphic yeah 70 but if
you have actually has to serialize
things that's that's right yes that's
correct your caliber jet to the
supervisor right and the serializer o
camel is actually generic or whatever
with that you can give it anything of
type apnea that's right okay so we saw
binary search trees there you go so
here's some interesting performance
numbers so this is a the running time
for a hundred thousand insertions into
into a tree and the as the tree gets
bigger the time you know it takes longer
the ideal case is here at the bottom so
if we just made auth anon author nope
this is how long it would take and the
times up here are for the prover in the
verifier so you can see that the proof
the verifier is a little bit slower than
the prover and that's because the
verifier has to end up doing hashing
twice it has to do I think of why that
is it's because it's sorry the prover
know why is it oh yes right hashing
happens in both off and uh naught in the
verifier right it has to do a hash to
confirm the thing that comes off the
stream and it also has to do a hash on
off whereas for the verifier sorry for
the prover it only world or do hashing
on offs and never on an offspeed already
has the hash is sitting in its data
structure so that's why it's a little
bit slower and you can see that most of
the runtime overhead eighty-five percent
of what the code is doing is hashes and
see the serialization are hashing and
that's why it's 100 times slower than
the original oh camel stuff so if you
didn't we use 160 bit sha1 hashes you
can make smaller hashes but you know
you're you're reducing your security
guarantee you could also be you could
also be smarter about serialization so
we we use the default serializer you
could also just like we compute shallow
projection functions you can imagine
statically generating smarter
serialization functions and that would
save you a lot of time to
you know when the rest of it is going
this oh the extra fifteen percent know
if happens has only six times slower
yeah so does the hundred ninety-nine
percent way to do this then we done this
right right on the total oh that's um no
I haven't figured that I we haven't
looked into it I guess I make a good
point we should we should figure that
out okay right and here at the bottom
interestingly it also takes a whole
bunch of time to do garbage collection
because it's going to compute a lot of
stuff and throw it away whereas it it
won't on the on the verifier side so
over here it shows space usage so this
is where the rubber hits the road
there's the whole reason we're doing
authentication in the first place so
what this shows is that look as you add
more and more stuff to your tree right
your tree takes up more space that's
going to be true for both the prover and
the ideal case you can see for the
prover it's just a constant factor above
the ideal that's all these extra hashes
or I'll not quite constant factor but
really close all the hashes that is
maintaining at each node in the tree
whereas for the verifier it's roughly
constant which is exactly what you want
you don't want to be maintaining any
extra storage you just have that the
hash of the root of the tree we also
compared against hand-rolled merkel tree
so we did our version of merkel trees we
did a hand-rolled version and o camel
and we did a hand-rolled version in c or
basically our version is a factor of two
slower than the sea version the old
camel version is about thirty percent
slower and basically the well there's
there's several interesting distant
differences but mostly it's you know
overhead of a naive compiler okay so I
didn't the the optimizations that we use
our space-saving optimization where I
shouldn't even go into it i'll just wait
and you can you can ask me after if
you're really interested anyhow we have
two optimizations that dramatically
reduce space usage and they bring our
verification procedure closer to what
merkel tree is actually are doing ok so
just for kicks we modeled bitcoin in our
language so Bitcoin works by maintaining
a ledger that keeps track of all of the
bitcoins that are available and
transactions are either purchasing coins
they're taking them out of the ledger or
they're sticking them back in the
blockchain this guy here is basically a
list of
so you can think of this block chain is
starting off from you know there's just
the root there's however many coins that
were in the world and then people just
keep making transactions either add or
remove them from the ledger so each one
of these guys is just modifying by
adding or removing stuff things over
time so it turns out that in in Bitcoin
the ledger or sorry the block list that
list of transactions is an authenticated
data structure so it basically looks
like this is how you'd encode it in our
language there's the root of the list
and then each one of those blocks is a
pointer to the next block where that
pointer is authenticated and it's the
transaction itself that's the part that
was pointing down that says what things
you added or removed and the reason that
it's authenticated is that we in order
for each client in a decentralized way
to confirm that the overall system
hasn't lied about that you have an
up-to-date view of what the current
ledger is you don't want to maintain all
of this storage local yourself for every
transaction that's in the world so
there's this decentralized way that you
can go to any peers in the network in
order to get the parts of the
transaction chain you're missing and get
yourself up to date by doing these
authentic ated operations so the
interesting thing is that the Bitcoin
people left an opportunity for
optimization on the floor this ledger
here that I've written as an int set can
be pretty big right there's lots of
bitcoins in the world and in order for
you to verify that the transactions are
valid you the client have to actually
keep a copy of the current up-to-date
ledger so I think currently the ledger
is like two and a half megabytes of
storage well you don't need to do that
you can maintain we can modify the
ledger to instead of being implemented
it's just a normal set to be an
authenticated data structure like a bit
red black tree and then in the same way
that you get the authenticated stuff
from your peers you can also
authenticate to get just the elements of
the red black tree that are relevant for
the transactions that you're processing
and save space so my claim is that the
reason that that hasn't happened in the
past is that people always thought about
authenticated data structures as
building them from the ground up right
they just thought oh I want enough
dedicated blah and then they designed it
from scratch whereas if they had had a
higher level programming language where
you could see in your code well where's
authentication happening house my data
representation working you could
immediately start playing with these
trade-offs and you
experiment with it and you could figure
out what made the most sense so I didn't
show you this but you know you can make
versions of trees for example where
instead of authenticating at every level
you could have leaves nodes that had
authentic ated sub trees and notes that
don't have authenticated sub trees and
you could choose variously to
authenticate or not to make for a
spacetime trade off you could have trees
with multiple roots you know you could
do any of these things once you have a
programming language that allows you to
experiment so that's what we have
provided giving essentially three
semantics could you give a man attic
translation and then just change the
moment yeah okay so we did that
originally and we just felt like the
three semantics was clear to be because
it just boils down to these three
different rules the only the semantics
is the same everywhere else except for
those things but yeah you could do that
and Andrew the student has a monadic
semantics in agda that he's made some
progress of actually mechanizing the
proof of security shop i'm thinking you
could just use computation expressions
fair enough that's that's true you still
let you still have this issue with the
shallow projection operator though
although with yeah sure I guess cuz
you've got one ton support for see you
respect oh I see it'll be okay so maybe
we should maybe we should look at an
f-sharp implementation that sounds good
can they usually relation to mix in the
same program some who else in some
getting failure so do i need to add more
plugins and reuse them together open it
i guess you would have to you would you
would have to express if you had
different provers and verifiers you
probably want a family of all types
right so you have off types for one
prover and all types for a different
prover and then absolutely you could mix
them and the you know the verification
stream would have to tag which elements
of the verification streamer for which
proved ER versus a different program
because that we index that yeah and
that's what the media monkey I think
that that would work but the point is I
mean it back to joshs question the key
that you have to get the verifier in the
prover to agree so they just have to
know where they are in the process of
computing to know how they're going to
do this verification process so if you
want to use different provers and you
just have to the verifier two sets and
no thats know where it's gonna get get
the information yep object a question
but you the whole time legal talk is
authenticated data structures right but
is it really anything to do with data
structures was what you hand over to the
approver hands over it's some kind of
trail to the you know to their client
that says well that amounts to proof
that he executed the program that you
thought a nice sewer data structures is
it so the reason that has to do with
data structures is that it's about
storage of data structures so it well
because if I I still get all of the
proofs if I don't have any dots in my
types anywhere right if I just write
functions but then what will happen is
the prover in the verifier will actually
run the same code so you're doing
verification by re execution which is
not very interesting clear with some
dull so that's right that's why it's
about data structures because the dots
are saving you storage about the
representation that you're doing these
operations over and if you weren't
worried about sport storage savings then
you wouldn't care about this end if you
mutations have consistency oh right
there is no mutation we mutations are
all mutations are functional right so
the insertion function that I showed you
before is going to produce a new tree
that will share a whole lot with the old
tree the reason that mutations is bad
I'm sure you realize this which is why
you ask is that if you modified
something all of the hashes of the
things that eventually refer to it will
now be invalid so if you supported
mutation you'd have to be able to go
back and fix up all of those hashes but
in that case you might as well just in
code mutation however you like so that
you make sure that you and you fix up
all the hashes the way you expect so you
could you know you can encode mutation
with an index and a list and so on and
you can make sure in this purely
functional way that everything was
what's up today because we produce a new
tree for example whatever you'd I'll
tell you give it structure right how do
you authenticate that a mutation is
valid well the new trees value is given
that several clients were trying to
produce a new tree at the same because
you're assuming I see what you're saying
ok well let's assume for my
there's one server and the clients are
all just accessing the one server well
the server is going to serialize their
requests right so the so what would have
to happen is if your request came in
expecting to operate on treaty so you'd
provide your hash for the tree but some
other clients snuck in and modified the
tree and update it a task your hash in
the service hash wouldn't match anymore
and then you would say no no I can't
perform this because you have the wrong
tree and then the server would have to
send back the proper hash actually tells
different clients different hashes right
so in that case Lauren so you're asking
a higher level question which is how can
you use the prover and verify our
infrastructure to build sort of an
authorized data structure that might be
mirrored in a certain way so probably
what you want to do is you want to only
allow trusted parties to perform
insertions and so then what would happen
is the trusted parties would then have
to propagate the hash to the clients to
say look I just did this insertion
here's the new hash and that's the hash
that you should trust now this is work
and it is for Bitcoin as a legit force
all the time we already have this
problem right you it's the same issue in
Bitcoin with the transaction history the
way that you do it in bitcoin is you
look for consensus among the miners you
make you make sure that everybody agrees
on what they yeah right so the point is
we're just giving you this way of
separating the storage and then you're
going to you may have to build stuff on
top of it to make sure that things work
out the way you want</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>