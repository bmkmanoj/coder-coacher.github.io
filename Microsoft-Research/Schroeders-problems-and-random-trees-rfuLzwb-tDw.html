<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Schroeder's problems and random trees | Coder Coacher - Coaching Coders</title><meta content="Schroeder's problems and random trees - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Schroeder's problems and random trees</b></h2><h5 class="post__date">2016-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rfuLzwb-tDw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so our next speaker is dr. lazaar
rizzolo he just moved from San Francisco
to Seattle he got his PhD from UC
Berkeley and jim pitman he is now a NSF
host all and a research associate at
u-dub and he's going to talk about
shortest problems and the reigning trees
Thanks I like to thank the organizers
for inviting me and the NSF for funding
funding this work on any number of
grants and I'd like to thank ass off for
giving such a nice first talk though I
would appreciate it if the bar been set
lower so as the title suggests I'm going
to talk about rotors problems and random
trees search rotors problems are a class
of four problems that were introduced a
while ago by Schroder in the 1870s in a
paper that everybody sites but I've
never seen physical evidence of it
existing or even really of the
journalists been published in but
everybody propagates the story that it
was published in eighteen seventy so
I'll stick with that so it's four
problems about bracketing zuv words and
sets so the first is a very common
problem comes up in and a lot of
discrete math courses it's how many
binary bracketing czar there of a word
of length n so these are bracketing zuv
length for its they're pretty pretty
easy to get a hold of these are one of
the classical examples of things that
are counted by the cattle and numbers
okay so the second problem is what if
you remove the condition that the
bracketing is be binary what if you just
have arbitrary bracketing of words of
length n you require the bracketing is
to be non redundant and non empty just
so that they're only finitely many of
them and for these you can get a general
solution these have been sort of known
for a while this is just taken off via
online encyclopedia of integer sequences
they're all there you can search them by
name if you want to if you want to learn
more about them okay and so these first
two problems are problems of bracketing
words
the elements are ordered but you can ask
the same problem for bracketing zuv sets
so how many bracketing zuv a set of size
and are there your binary ones you can
again get a nice formula and the last
problem is what if you remove the binary
condition for brac things of sets you
can do this again you can get a much
less nice formula looking at this that
just from the formulas for them it's
pretty apparent that that doing
combinatorics for binary things is much
easier than the general case but you can
always get formulas whether or not
they're terribly helpful the difference
between public water publicly could use
ah yes so yes sorry stop me if I go too
fast at any point so in these there
you're bracketing sets so the elements
aren't ordered right so you can you can
sort of see a difference for example for
these again
here I've only shown five of the 15 oh
there were too many of them to list all
of them so if this sort of indicated so
you underhand Indian language these are
some of the bracketing of size 4 since
you could have won three in a session to
fall it isn't exactly so it's the the
basic change between problems 1 and 2
and problems 3 and 4 is your trading in
order structure for a labeling structure
and part of part of what jim pitman
who's my co-author and a lot of this
work you've done is sort of figure out
what's the relation between labeled
structures and ordered structures of
these types ok so what we're interested
in is interested in is what do these
look like if you pick one uniformly at
random for some large n ok and what
we're going to look at this is we're
going to cast it in the setting of
random trees which is a fairly well
studied field so the ejection we're
going to use with trees is in some sense
the obvious one although there are lots
of by actions between these problems and
various models of trees so for example
the first problem is going to correspond
to rooted ordered binary trees sort of
in the following in the following way
it's just there's an somewhat obvious
nesting structure that these bracketing
is have and those nestings become the
vertices and the leaves correspondingly
ok so these are what our trees look like
for for binary word bracketing and we
can do binary set bracketing Xand here
it's sort of clear that that now we have
labels and though you may not be able to
tell from the picture these trees aren't
ordered they are rooted ok and similarly
we can do this for for the fourth
problem and in this case you can see
that the only difference is that we are
letting allow in sort of arbitrary
degrees instead of just binary degrees
okay so to look at these what we're
going to do is to frame these as
problems of looking at condition galten
Watson trees and galten Watson trees
have been fairly well studied they've
come a bit although always in the
context of conditioning on the number of
vertices never in the context of the
number of leaves which is that what what
we have in this particular case so let's
recall it the definition of a galten
Watson tree is you just have some
offspring distribution and you take
distribution on trees that makes the out
degrees of the vertices as independent
as possible okay so that's you have this
product form over over to the degrees in
the tree okay and just sort of been
known for a while that a lot of
combinatorial models fit very nicely
into into the galten Watson tree
framework for example if the offspring
distribution is geometric and you take
AG Alton Watson tree with that offspring
distribution condition it to have n
vertices what you get is a uniform
random tree on n vertices and so our
hope was to be able to do something like
this with the trees appearing intruders
problems and in fact you can and jim
pitman and i did this along with Kurian
in korchevskiy at around the same time
was for the first two problems it's
fairly straightforward because the trees
are the trees intruders problems are
ordered and galten Watson trees are rude
order trees that are the same type and
you can just sort of go through it and
what you get are these two offspring
distributions so in the binary case you
get the only thing you can really have
which is uniform distribution on
vertices of out degree zero and out
degree 2 and in the general case you get
this somewhat strange or offspring
distribution where it's not necessarily
clear where it's coming from but the key
point is that for I greater than to you
have some number risen to the power i
minus 1 and the reason that's going to
be nice is just because if you sum over
internal vertices
of a tree of their out degree minus one
what you get is just something a formula
in terms of the number of leaves so let
me give a quick proof of this to show
how these things go if you look at the
trees appearing in rotors second problem
if you just take a gaunt and Watson tree
with that offspring distribution you
just get this product form and you can
compute the sum in the exponent of the
second one and you get a formula in
terms of the number of leaves what this
tells you is if you condition on the
number of leaves everything has the same
probability so it's uniform and that's
basically how that goes for the first
two problems now for the second two
problems it's a little more difficult
because you need something to you need a
way to get from rooted ordered trees
which all galten Watson trees are rooted
order trees to rooted labeled trees and
this is sort of a classical problem it's
been done in the case where you're
labeling vertices and in that case it
turns out to be a bit a bit easier but
you can also do it when you're labeling
leaves and the basic idea is the
following sort of transformation is if
you take some rooted order tree and just
an ordering of the number of leaves in
the tree you just label the leaves from
left to right it's one of the first
things you might try it wasn't one of
the first things we tried for some
reason I can't tell you why I and the
idea here is if you now take
so it okay it might not be clear from
the picture but the the tree on the
right hand side is unordered but labeled
alright so in this case you have you
know for binary trees it's the one and
only known critical galten Watson
offspring distribution on binary trees
and in the case of the fourth problem
you get this even stranger distribution
but it turns out if you take a galten
watson tree with with one of these
distributions and an independent
independent uniform ordering of the
numbers 1 through n and go through this
label the leaves from left to right by
this ordering and then forget the order
you get the trees appearing in the
second I mean in the third and fourth
problems respectively so this this
basically does is cast looking at
schroders problems as looking at random
galten Watson trees conditioned on their
number of leaves okay so looking at
galten Watson trees condition on their
number of leaves is sort of a recently
developed thing there are at this point
four or five distinct approaches to to
dealing with them when they're large I'm
going to to tell you about what I what I
think is mostly the right approach or
the the easiest and most intuitive
approach to dealing with conditioning
galten Watson trees on their number of
leaves okay so i should mention perhaps
where these have come up before the
trees appearing in the second problem
these are rooted ordered trees with with
no vertices about degree one these
recently came up in studying non
crossing arrangements in the plane and
looking at Brownian triangulations and
and things like that in work of carrion
in korchevskiy sort of where they came
at these from
okay so how do we how do we deal with
you what is there to say about galten
Watson trees conditioned on their number
of leaves so the way I'm going to
approach the problem or at least the way
we're going to approach it today is by
relating trees with an leaves two trees
with n vertices and something of a
non-obvious way it's the way we're going
to do it is we're going to start with a
rooted ordered tree with and leaves and
we're going to transform it into a tree
with n vertices by the following
procedure so we're just going to to
label the leaves from from left to right
just increasing order once once we've
done this we're going to label all of
the edges in the tree and the labeling
we're going to do is we're going to
label the edge by the index of the
smallest leaf in the tree above the edge
so if you were to remove the edge and
look at the tree above it the tree
further away from the root you look at
the smallest leaf and label the edge by
that and then the transformation is to
collapse along these spines to get a
tree okay so what's happening here is if
you look at the vertex labeled one
that's coming from the spine from the
leaf labeled one to the root and the
vertices attached to it are all of the
spines that touch the one labeled one so
we have the spine label to five and six
and you sort of repeat this procedure
and it collapses the tree into a tree
with n leaves I mean into a tree with n
vertices so it's worth noting this is
something of a classical transformation
this is one of the many known by jek
shins between binary trees with n leaves
and trees with n vertices so this is
something of a classical transformation
at least in the case of binary trees and
we're going to do it just sort of in
general and what's nice about this is
this transformation actually preserves
the
of galten Watson trees if you do this to
a galten Watson tree what you get out is
again a galten Watson tree so here's the
theorem basically says that if you if
you start with the galten Watson tree do
this transformation the result is again
of Alton Watson tree but with a
different offspring distribution and you
can write down explicitly what that got
what that offspring distribution is okay
and other nice properties if the tree
you started with is critical that is the
offspring distribution has mean one then
your new tree is also critical offspring
distribution has meet one and again if
you start with something that's finite
variance you end with something that's
finite variance and that can that last
statement can be extended that if you
start with something in the domain of
attraction of a stable law you get
something in the domain of attraction of
the same stable law okay so just to
repeat or sort of to say in a different
way that this is a bijection from binary
trees to general trees that if you take
the trees appearing intro ters first
problem and do this what you get is a
uniform tree on n vertices and that that
will mention that again as to something
interesting that comes out of this study
because of this the by jection okay yeah
so this this transformation you start
with right you just label you label the
leaves then you label the edges and if
you look at the spine now labeled one
you attached to it as vertices all the
spines that that touch it so two touches
it five touches it six touches it and
those become the children of one so you
get to five and six and similarly if you
look at the spine too that's touched by
the spines three and four so you get as
a child of two three and four in the
order that they're appearing as they
touch it and then
go through five and six their leaves and
that's that's the transformation in
general is no it's not a by jection on
general trees it's a but if you restrict
to binary trees you get a by jection
from binary trees to treat with n leaves
two trees with n vertices so this in
general is definitely not a bijection
but if you look at if you do this only
two binary trees then then it is a by
jection and and that that's because you
can basically just reverse the process
if you restrict if you require
everything to be binary you just sort of
expand each each vertex you take its
degree and you turn it into a path of
that length and attach things as
required the only way to make it binary
trees to go from Wilson trees yes and
for all golden lots of trees on the
right is the result of balsa tree over
there well would you get all such you
get all such goals and also she's out of
this I'm fairly sure the answer is no
you can sort of when you write down what
the distribution is of the tree on the
left what it is is it's I it's what I
would call a compound geometric
distribution right you're summing up
you're looking at a sequence of
independent things until you see the
first zero and then you're summing those
up and I quite frankly would be
surprised if you got everything from a
procedure like that but I don't actually
have a proof that you don't okay so are
there any other questions about about
this transformation okay
so one one thing this does is it gives
you right by this remark it gives you a
connection between binary trees with an
leaves and uniform and just regular
trees with n vertices and as a
consequence of what I'm going to say
what turns out that a uniform trees with
n vertices is almost a binary tree with
n leaves and there's a very explicit
coupling of the two that has such that
the the grommet house tour of distance
between them is small okay and the way
we're going to to get to something like
that is through the depth-first
processes of these trees one of the nice
things about ordered trees is you can
make use of the order structure to get
to get bye Jek shins with conditioned
random walks that's something you can't
really do as nicely with labeled trees
which is sort of why moving to the
galten watson framework is useful even
for dealing with the third and fourth
problems which are which are not
inherently late are not inherently
ordered okay so the the most one of the
basic depth-first processes is the depth
first walk this here's a formal
definition but the basic idea is you
start at the root then you go to the its
leftmost child from there you go to that
one's leftmost child unless it has no
more left most children that haven't
been visited at which point you go back
to the parent and you just sort of
proceed around the tree in this matter
okay and this gives a nice way to order
the vertices of the tree sort of the
depth first order and so this is the
order we're always going to be using if
I have a root ordered tree and I list
the vertices V 1 through VN these are
going to be listed in order of
appearance on this depth first walk so
once once we have that the easiest
depth-first process to deal with is the
depth first q let's do take a tree the
depth first q is at you know step n is
just sort of the random walk that sums
up the
degree of the vertex minus one as your
sort of going around i should mention
that degrees are always out degree here
so it's the number of the number of
vertices that are adjacent to it and
further from the root ok see you get
this as the depth-first q and the reason
this is easy to deal with ferg Alton
Watson trees is that it's a first
passage bridge from 0 to minus 1 so if
you have galten Watson tree with
Austrian distribution distribution see
then SN I said is a just first passage
bridge from 0 to minus 1 of a random
walk with the shifted a step
distribution so this is an example of a
of the depth-first queue of a random
binary tree with 11 leaves okay so the
reason for introducing these def first
queues are the first step is that the
transformation I was discussing before
has a fairly nice representation has a
fairly nice action on the depth first
ques so if you look at it what happens
is the following you take the death
first queue and suppose you only observe
it when it goes when it steps down you
only observe it after- steps okay and
you just take that walk that's the walk
that you have in red here okay and then
just sort of compress that right you
only just this is just a time shift of
the red walk on the previous slide this
again is a first passage bridge and it
is in fact the depth-first queue of the
transformed tree okay so that's a fairly
straightforward action on the
depth-first queues and it also shows you
that the two trees really aren't that
far apart in terms of the distance
between their depth first queue because
you're basically just waiting until you
have steps down and really how how much
could go wrong in between the steps down
of
of one of these walks answer is a lot
but but it turns out that it doesn't in
this case because things things are
pleasant okay so what we can get out of
this is sort of this theorem and I
apologize for having so much text on a
single slide but that was a no escaping
it so what this theorem says is that if
you take a galten Watson tree with
finite variance mean one offspring
distribution and you look at the
transformed tree right and you look at
their depth first ques this gives you a
coupling between the depth-first cues of
those trees and if you scale
appropriately the Joint Distribution of
the two processes converge to the same
Brownian excursion okay so what this is
saying is that the distance between and
it's so the thing to note on this is
that this is the same brownie excursion
here and here they're converging to the
same thing that's the Joint Distribution
of the two okay and the way the way to
prove something like this is well let me
remark before I remark on the proof mark
this holds under much weaker conditions
you can prove sort of the analogous
theorems for for offspring distribution
that are in the domain of attraction of
a stable law you can do this coupling
and make it work but it's considerably
more difficult to do so so the way we do
it is this sort of proposition of
showing that the uniform distance
between the two the two depth first ques
is not far apart and that basically
comes just by looking at the picture the
whole thing sort of comes down to you
look at the time change of how far apart
are the steps down not that far apart
you can basically scale the
and have them going to the identity and
then if you look at the distances
between the two walks well i mean the
the walks just aren't going to get far
apart they don't have they don't have
enough time to get far apart when you're
doing this and this sort of works out
because in the limit we're going to get
standard browning an excursion which is
continuous and basically the modulus of
continuity the distance between these
two walks is controlled by the modulus
of continuity and that's going to 0 so
so we can get this type of proposition
connecting them oh yeah this is not
nearly the strongest statement you can
have 0 in in general for finite variance
it might be in our cases we have
exponent we have some exponential
moments on the offspring distribution so
you can do a moderate deviations type
thing you can you can get I think I
think you can put an end to the
one-fourth plus epsilon and get decay of
order e to the minus alpha N to the
epsilon
this
you should be locker
yes Isis I'm I suspect it could be I I'm
gonna say i haven't actually i haven't
sort of looked into how how tight you
can get these tales assuming exponential
moments but sort of there is there's
obvious theory there that you could that
you can use to to try to work to try to
work that out so I mean existing
deviation theorems could give you rates
for for something like this
okay so once once we have that so that's
sort of the depth-first cute what its
convergence tells you about the
resulting tree isn't isn't that obvious
and it tells you some things but it
doesn't necessarily have sense it just
sort of gets you close to a result like
that to get the convergence of the tree
in a Grom of house tour of sense or as a
whole you need to take in you need to
look closer at the contour process so
the contour process is just the process
that goes along recording the distance
from each vertex to the root as you go
along the depth first walk so that's
what this definition tells you and the
nice thing about this is if you assume
exponential that you have some
exponential moments of your offspring
distribution you get these sorts of
moderate deviations for the distance
between the depth-first cue and the
contour process of a condition tree so
this theorem when TN is conditioned like
AG Alton Watson tree to have n vertices
is due to market and mocha dem in around
2003 and more recently to this was done
in the case when you have n vertices and
you can basically just reduce it I mean
in the case mint leaves and you can
basically just reduce it to their proof
so getting it for EM for trees condition
tap and leaves once you have and
vertices once you have it for trees with
n vertices isn't so bad for that though
so one thing I should mention those
since we have this for both what this
tells you is the distance between the
contour process of a uniform binary tree
with n leaves and the contour process of
a uniform tree with n vertices you can
couple them so that you so that they're
very close together you have these sorts
of moderate deviations for the distance
between them at at least as evolved was
mentioning you can probably do better
than this
but still this tells you that a uniform
binary truth and leaves is in a very
strong sense almost a uniform tree with
n vertices which i think is something of
an interesting coupling okay so once we
have convergence of the contour process
we still want to say something about the
tree itself especially for the third and
fourth problems which aren't naturally
ordered so convergys with the contour
process is nice but it's not really what
you're interested in in the first place
so the way the way to make rigorous
something about convergence of the whole
tree that we're going to do is Roma
house tour prokhorov convergence so
we're going to let MW be the set of
equivalence classes of compact metric
measure spaces that are pointed and
we're going to define the gromov house
tour Prokhorov distance between them as
usual as usual there's not really a
usual definition but this is the one I'm
using is you minimize over the distance
of the distance between the roots the
house tour distance between the sets and
the proper distance between the measures
over all metric spaces and isometric
embeddings of the two into a common
metric space I should mention that set
theoretically speaking this slide is
complete nonsense none of that actually
means anything in ZF or throwing choice
if you want your quantifying over all
metric spaces several times over you
just can't do that but there is a way to
formalize this in terms of classical
Zermelo Fraenkel set theory so I I
mentioned this because usually it
doesn't matter that you can't formalize
this but every now and again you'll find
people getting in trouble because of
that sort of mentioned that you can in
fact formalize this okay
and the nice thing is that this metric
the strong law house tour prokhorov
metric plays nicely with encoding trees
by things like their contour functions
and the interaction is sort of by you
can take the contour function to define
a metric to define a pseudo metric
rather on on the unit interval and then
when you sort of quotient out to make it
an honest metric you get a tree that's
sort of what this is doing is you're
defining sort of the pseudo distance
between two points by a function is just
some the values of the function subtract
the minimum between them and there's
nothing inherently natural about this
definition the first time you see it but
if you sort of write down what this
means for a tree for a finite tree
you'll see that this sort of gives you
the graph metric on the tree and you've
just sort of filled in the edges by unit
intervals ok so we take this this pseudo
metric we quotient out by it we get a
compact metric tree and we can push
forward any measure we want on to that
and nice thing is that this map that
takes continuous you know non-negative
continuous functions that start and end
at zero and measures two trees you
actually have a continuous function this
tells you sort of everything you want to
do in terms of composing them works
nicely I should mention that while this
lemma has certainly been in the folklore
since at least the early 90s as far as I
can tell it's only been written down in
the past several months so this is sort
of a the lemma that that lets us
actually do things with this procedure
of constructing metric trees and the
sort of universal object for this
setting is the Brownian continuum tree
which is what happens if you apply our
construction to standard browning
excursion and lebesgue measure this gets
you brownie and CRT
which is slightly different from the one
that all this originally defined where
he had twice brownie and excursion but
this has become the more standard
normalization okay and sort of coupling
this with the theorem about convergence
of the contour processes you get sort of
the following theorems for convergence
in distribution of the trees appearing
intruders problems with respect to this
drama hausdorff rocker of topology where
the measure we're putting on them is the
uniform probability distribution on the
leaves and you get sort of these
explicit formula for everything okay and
I think I think that's it so thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>