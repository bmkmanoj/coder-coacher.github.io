<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Laws of Programming with Concurrency | Coder Coacher - Coaching Coders</title><meta content="Laws of Programming with Concurrency - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Laws of Programming with Concurrency</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/r7i1mpAc-b0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
well it's a great pleasure to welcome
you all to this the third in our series
of distinguished lectures we had Leslie
Lamport back in May shortly after the
award of it he received his Turing award
and we had our Adar Z in November very
different kind of talk today we have
Tony about two more in a moment and in
May we have been out Chilcott coming who
just won the third Robin Milner award
which as you may know is the top award
for computer science in Europe but now
to Tony who is the the main subject of
the day you can see how long his CV is
and I can't possibly deliver all of this
I guess it may be well known that he
began studying classics I suppose at the
time he couldn't have studied computer
science if he'd wanted to because it
wasn't really there because he's done so
much actually to construct the subject
so that now that we can teach it so he
began as I said with classics and he
became an expert in in Russian in in the
Navy and his first his first job was
with Elliot's alley at 803 perhaps was
it no three way he first worked on on al
Ghul and his first academic job was at
Queen's University Belfast where he was
a professor eventually coming back to to
Oxford and from where Microsoft poached
him although there was a dispute about
that about whether Oxford says he
retired we say we poached him but you
know anyway we've enjoyed very much
having him here for the last 15 years he
he is so well known for from many things
that I household words in computer
science like quick salt CSP many others
and has a great list of honours and
wards there's his knighthood perhaps the
most rarified one is the Kyoto prize I
think that's rather rarer than the the
Turing award but you know this point
i'll i'll stop because there are so many
more pages to go and tony we're really
looking forward to the lecture so let's
get on with that thanks very much well
thank you very much for that kind
introduction and thank you for inviting
me to deliver this lecture two
distinguished academic and industrial
audience among you are many friends and
colleagues working with me and microsoft
research as well as members of the
cambridge university computing
laboratory of which i'm proud to be an
honorary member others others are
industrial visitors from the flourishing
computer and software industry which in
an around cambridge welcome to you all I
have spent as under described a bit less
than half my extended working career
employed in industry and a bit more than
a half as a university professor I
therefore really relish this opportunity
to talk to a mixed industrial and
academic your audience on a subject
which has been dear to my heart
throughout my varied career I hope in my
talk to interest my academic audience in
the idea that the laws of programming
are simple enough to be taught to
computer science undergraduates maybe in
their introductory courses and i hope to
interest my industrial audience in the
idea that the laws can be useful useful
to software developers particularly
those designing writing or debugging
concurrent programs
my original motivation for exploration
of the laws of programming was
scientific curiosity discovery of the
laws of nature has been adopted as the
primary goal of the Natural Sciences
ever since they broke away from other
branches of philosophy the foundations
of many well at established scientific
disciplines is now codified in the form
of elegant algebraic equations or
inequalities as illustrated by the
examples on this slide the laws of
nature are all plied pervasively in
engineering applications of those
branches of science they provide the
scientific justification for the
algorithms that are embedded in my in a
modern engineering design automation
system such a software system calculates
the consequences of the laws when
applied to particular designs products
and services of current concern to the
engineer who uses them I suggest that
the laws of programming provide a
foundation for the science of computing
in the same way as the laws of nature
for other branches of science and they
are already providing software
development engineers a range of
algorithms for the integrated
development environments like visual
studio and eclipse i shall present a
selection of simple laws from sources
shown on this slide how these sources
are familiar to many computer scientists
both of practical and theoretical
inclination but I won't assume from my
audience any familiarity with any of
them I will of course throughout the
lecture we paying special attention to
concurrency so my summary I will have
five headings the first will tell you
what are the laws of programming
the second one with concurrency the
third one will answer the question what
are they for the next one what's the
point and finally consider an argument
against so what are they the laws of
programming are a collection of
algebraic equations and inequalities
that hold between computer programs in
the same way as the laws of arithmetic
hold between numbers when they are
manipular when when arithmetic is done
on them so as my running example I will
choose the natural numbers just the
non-negative integers which you are
surely familiar with and my aim is to
show the broad overlap between the laws
of arithmetic which are taught to
schoolchildren and the laws of
programming which are not yet taught
even to undergraduates as an example I
will give the laws for natural numbers
and my arithmetic operators will be
compiled location and addition and my
only relation between the numbers will
be their numerical ordering in order of
magnitude when the same laws are applied
to computer programs the basic commands
of the programming language will serve
as constants of the algebra the
assignments the inputs the outputs and
the jumps and so on they obey many
elegant algebraic laws but I shall
ignore them completely except for two
basic commands named as they were as
they were on the previous slide so the
one and the zero the one stands or a
very pervasive command in programming
which is do nothing and zero stands for
a program which has no executions maybe
because the compiler has found
fault in them say a type mismatch which
means that they are inhibited from
reaching an execution there are three
basic operators that compose the basic
command the semicolon and the parallel
signs specify complete execution of both
their operands either sequentially or
concurrently the Union operator presents
a choice between its operands now the
criterion for the choice is left
entirely unspecified it must be there
for regarded by the programmer as a
completely non deterministic choice made
by the implementation perhaps at any
time for example at compile time or even
at runtime now the ordering relation
states that everything that the left
hand side PE can do can also be done by
the right hand side q If Q is being used
as a specification of the behavior of
the desired program then the ordering
relation means that P satisfies its
specification if P is nonzero another
use for a law and in equation is that if
P is nonzero a compiler is permitted to
or indeed a instruction pipeline is
permitted to replace q the more
determine in more non-deterministic one
by the more deterministic p the reason
for doing this is of course usually in
the hope that p will be the more
efficient thus the laws the INEC in
equation ax laws can be used as valid
transformations or indeed the equation
of laws for optimizing programs and
every programmer who uses an optimizing
compiler may hope
that the compiler is performing valid
optimizations according to the laws so
here are the laws for multiplication of
not natural numbers I will claim that
these the three laws i'm sure you're
familiar with and i will claim that they
also apply to the two forms of program
composition both parallel and the
sequential denoted by semicolon when you
substitute these two symbols for the
multiplication symbol in each formula
which i think i will do now on this
slide multiplication is substituted by
sequential composition of programs and
the explanation of the laws is still
quite intuitive first for the unit law
doing nothing either before or after
doing something is the same as doing
that same thing p the for the
associative law i reasoned that doing
three actions in sequence is the same as
doing the first one first followed by
the other two sequentially it is also
the same as doing the last one last
preceded by the other two performed
sequentially finally if a program has no
executions then so the same is true of
any program which contains that as a
subprogram this is because each of my
composition operators requires complete
execution of both its operands and if
one operand has no executions that can't
be done
our similar intuitive explanation
justifies the laws for concurrency last
law on this slide states that programs
executed concurrently may be written in
either order doing something at the same
time as something else is the same same
thing as doing something else at the
same time as something and finally the
laws for addition which will be similar
to laws for the non-deterministic choice
operator the first three laws are
remarkably similar to the ones we've
already seen except that 0 is the thoria
that 0 is the unit of addition the final
two laws on this slide are familiar
distributive laws they say that if you
are multiplying a sum this is the same
as taking the sum of the component wise
products and in fact what this
reinforces this is an instance of my
statement that non-deterministic choice
may be made at any time either before or
after doing the multiplication the first
two of these laws are obtained simply by
are the associative and commutative laws
for choice obviously offering choice
between P and Q is the same as offering
a choice between Q and P and offering a
choice between P and L and the choice
between qar is the same as doing the
other way around the third law says that
if one of the alternatives has no
executions
then the non-deterministic choice will
always select the one that has an
execution it can't do anything else this
is something like Henry Ford's famous
statement you can have any color I'm
sorry you can have any color except
sorry I've just misplaced that quotation
this excuse me as long as it's black
thank you that may be a description of
the next law at as well the final law is
one that does not is not true of
addition of numbers and really has quite
impressive consequences it's the
statement that the choice between P and
P is the same as P itself it is no
choice at all finally we have the
distribution laws which can be written
as saying that multiplication sorry that
either semicolon or concurrency
distributes through choice the choice
can be made before embarking on the
concurrent execution or during the
current concurrent execution as
necessary now the ordering relation can
be defined in terms of choice as shown
on the first slide of the first line of
this slide using this definition other
familiar properties of the arithmetic
ordering of numbers can be proved as
theorems the laws on the last line of
this slide says that if you increase the
determinacy of a component of a of a
program composition for example by
removing the alternative q that's
illness to remove the alternative q you
can only decrease
the that you increase indeterminacy of P
Union q decrease is non determinacy now
the final law final two laws say that
concurrency and sequential composition
are covariant in the sense that if you
increase the determinacy of one of the
components you will it you can only
increase the determinacy of the other
component or leave it the same this law
is true for both sequential composition
and concurrent composition and indeed
for multiplication if the or sign is
replaced by the sum
the most important properties of
ordering are described by proof rules
which can be proved in advance of using
them from the laws of the previous slide
each rule consists of one or more
antecedents which are written above the
line and one or more consequence which
are written below the line above and
below each rule says that the
consequence written below the line can
be proved simply by proving all the
antecedents above the line the advantage
of a proof rule is that it suggests a
tactic for the proof of the conclusion
for example the first rule of
transitivity shown here says that if you
want to prove that p is below Q if I got
P below if you want to prove that p is
below are then it may help to find an
intermediate formula Q which is above p
and below q and if you can do that you
already have made a proof that p is
below our
another advantage of the proof rule is
that your proof can then make explicit
reference to the rule which can make the
proof quite a bit shorter to the benefit
of both man and machine now the
covariance rule this one is a direct
consequence of the covariance law it
states that if the determinacy of either
of the are either of the operands of
fake you of a composition is decreased
the determinacy of the result remains
unchanged or it decreases this is the
rule that justifies an engineer in
replacing any component of a working
system by a component that has tighter
tolerances that it thereby reducing its
non determinacy making it more Don more
deterministic the resulting system with
the new component that at home come back
the resulting system with the new
component is some what have we got here
the new component p is still more
deterministic has tighter tolerances
than the original system with the
component that has been replaced and
that's a fundamental belief of every
engineer if it turns out that replacing
a component with one in which the
supplier has promised that it has
tighter tolerances if that actually
increases the non determinacy t of the
whole system then the claim that the
clerk that the tolerances were tighter
has been refuted you should return the
component with a root note
so now let's come to the fundamental law
that governs concurrency in a
programming it's called the exchange
axiom I call it the exchange axiom it's
been discovered many times independently
and everybody gives it a different name
name I'm afraid I'm not particularly
proud of my one this is the axiom that
justifies the interleaving of atomic
actions in the implement as an
implementation method for concurrency as
I will show the exchange log which I've
written as an axiom here says that the
concurrent composition of two sequential
compositions on the right hand side the
concurrent comp cannot can be made more
deterministic one of the ways of
implementing it is to compose two
concurrent compositions where the first
operand of the sequential composition
contains everything that is done up to
the semicolon by both the threads on the
right hand side and similarly the
concurrent composition after the
semicolon is the RV to obtained from the
two from the sequential composition of
the right hand side so the role of
concurrent composition and sequential
composition has been interchanged
between the right hand side and the left
hand side that's why I call it the
exchange law it's the shape of this
theorem is actually quite familiar to to
you and you and indeed to all
schoolchildren in Britain these days
because of the theorem that if you add
two products you get a now
now a number which is less than the
result of summing them and then
multiplying them together so multiplies
plays the role here of the concurrent
composition here's the axiom again with
another explanation the left-hand side
of the in equation here is an
interleaving implementation of the more
general concurrency on the right hand
side and what has happened is that the
two semi the implementation the
scheduler which schedules these
concurrent compositions has chosen the
these two semicolons as a sort of
barrier which the two threads must pass
simultaneously on the left-hand side
that is stated that when that semicolon
is reached there's single semicolon here
stands for passing both of these
semicolons on the right hand side so
they can be merged into one and the
before this semicolon there occur all
the actions of the first components of
the sequential compositions of each
thread and on the right hand side we
have the second component of each of the
threads the use of implication in this
law rather than equality is essential
because this also allows alternative
implementations of the right-hand side
and it's non-deterministic which of the
scheduling strategies will actually be
adopted in fact the laws do not preclude
a true concurrency which could occur if
there is synchronized execution of
events such as input and output between
the operators in a communicating process
framework
the exchange axiom has some simple and
extremely consequences called frame laws
I've written the axiom again at the top
of the slide the frame laws are easily
proved from the axiom using the fact
that one is the unit of both sequential
and concurrent X composition for example
if you replace the P dashed on both
sides of this equation by one then the
two ones are canceled with concurrent or
sequential composition and the result is
exactly what we have claimed to be the
first of the frame theorems this is an
alternative with q treated in the same
ways as P dash was and here we've done
it twice to get the basic laws that
sequential composition is more
deterministic that concurrent x
execution and similarly the other way
around those are the two if P and Q are
basic commands this is merely an
interleaving law for the implementation
of concurrent composition
of course it may happen that the
sequential composition here has no
executions at all for example if P is
the destination of a jump sorry perhaps
I'll just leave the example out and go
on to the next slide so I'll show you a
more extended example of how the
exchange law justifies the interleaving
of its operands so I'm going to consider
two strings ABCD written in red and XYZ
r w and i'll assume that these are
atomic operations in the in the program
and these two programs are executed
concurrent concurrently and i will show
you just one of the interleaving zuv
actions which the exchange law permits
at the top we've just written the
concurrent composition as it two strings
in the second line we choose the
semicolons to indicate the point at
which we're going to apply the exchange
law that's permitted because a
sequential composition is associative
and we can put that semicolon anywhere
here we apply the exchange law once we
take the first part of this second
operand and run it concurrently with the
first part of the first opera first
operand and similarly on the right hand
side of the semicolon and that is
actually equal to we make an arbitrary
choice of splitting the XY in the middle
and splitting the BCD as shown by this
semicolon finally at not finally an
application of the exchange law now
allows us to bring out sorry the frame
law allows us to bring out the Y to be
done after the concurrent execution of
the other two basic actions and
similarly on the right hand side and
finally applying the same frame law
twice we can get an example such as X 0
as shown here notice that the ordering
of the individual threads has been
preserved in the interleaving one of the
necessary conditions of the connect
correctness of enter leaving but these
choices of where to put the semicolon
and whether to commute the operands of
parallel composition in one way or
another these are made during the proof
and different different choices of
commuting the concurrent or selecting
the sequential compositions will give
you eventually all the different
leavings that you can get from these two
threads now this exchange law can be
presented instead of being an algebraic
law can be presented as a proof rule as
shown on this slide like the rules for
ordering the modularity rule provides a
strategy for structuring a proof of its
consequence into smaller and simpler
parts
each of the two antecedents of the rule
above the line is smaller than the
consequent because each of them contains
only three operands instead of six and
they're simpler because they involve
sequential composition rather than
concurrent it's surprisingly easy to
derive the exchange law and the modern
modularity rule from each other as I
will show on the next two slides first
here is a proof of one half of the
equivalence it starts with the
modularity rule which I've copied on the
top of this slide since it is a general
rule we can replace all occurrences of
each of its variables by anything we
like and we choose to replace our by P
semicolon q and r dashed semicolon what
P dashed semicolon q dashed because that
will turn the antecedents into merely
restatements of the reflexive
reflexivity rule for ordering the
conclusion applying the same
transformation is written by replacing
or r by p semicolon q and r dashed by
peter CEO and COO dashed and that is the
extensional so from the modularity rule
we have proved the exchange law the
other way around is a little bit more
difficult we assume the exchange law and
then we seen the antecedents of the
modularity rule I've copied the majority
rule into this box here just to remind
us as a result we can apply covariance
to the consequence of the modular sorry
we can apply covariance 20 in this
setting to replace the are here by P
semicolon Q and replace the are dashed
by P dash semicolon Q dashed but notice
now that this red left-hand side is
equal to the right hand side of the
exchange law itself so you comply the
exchange law and this line of the proof
news transitivity to derive the
conclusion that we want that this
expression is below live alone of blue
which one that one which I've written
here but that is the conclusion of the
modularity rule that's the most
difficult proof I will show you all
right so what are they for well there
are three distinct purposes for my
collection of laws of programming first
and obvious purpose is to validate the
program transformations needed for
optimization any program who uses an
optimizing compiler is there by
exploiting the rod the laws of
programming a second purpose is to show
how to execute a program step-by-step
thereby providing guidance for compiler
writers and into and those who design
interpreters for a programming language
any user of a compiler based on these
laws is thereby indirectly using the
laws and the third purpose is to provide
proof rules to ensure that all
executions of a program will exhibit
some desirable property finally we must
have insurers the consistency of the
execution rules and the proof rules and
that I will do I hope quite briefly and
what is followed first essential
requirement to proving the rules is to
define the primitive judgments of the
proof rules and the execution rules and
the peripherals I will explain in terms
of the whore triple and the definition
is given on this slide reading the
definition intuitively it says that P if
P describes what has happened so far and
Q is now started and executed to
completion and the trace of overall
execution of P and Q one after the other
will satisfy our which serves the
specification of with what we wanted the
program to do
for the describing the implementation
the compilers and interpreters we use
the milner transition and the purpose of
the middle of transmission is not to
prove the correctness of all executions
of the program but to prove but actually
obtain and present the results of a
single execution of the program the
milner notation for the transition is
shown as defined as q semicolon p is
below are an interpreted interpretation
this time is that our may be executed by
first executing q with p as a
continuation for later execution of
course there may be other ways of
executing our are we can check this
definition corresponds with the
intentions of milna by a simple
tautology by translating Milner's prefix
rule which he used for ccs one of the
basic rules of ccs and it's obtained
simply by replacing this transition by
its definition here and we get yet
another application of the reflexivity
law
no extraordinary thing is that these
three rules are identical by definition
they can be translated by into each
other by translating one of them first
into the modularity rule and then into
the transition rule and vice versa it is
by definition that the whore triple for
at least for concurrency the rule for
concurrency is just a translation of
Milnes of the same law the modular which
is the modularity rule but I have
already shown you some lengths that the
modularity rule is equivalent to the
exchange axiom it follows therefore that
both the separation logic and the
operational semantics can be derived
from the exchange axiom and the exchange
axiom can be derived from either of the
two proof rules so anybody's ever used
or believed in the validity of nola
semantics and whole semantics must agree
that the exchange lat axiom is actually
true true shows a true of what it's
intended to be true of true of the
programs which these rules and laws are
applied to now a similar relationship
can be established for sequential
composition in this case we can prove it
is easily is equivalent to a weaker form
of the law of associativity in which the
Equality is replaced by an inequality in
one direction but it's not possible to
prove the law in the other direction
from the hall rule of sequential
composition if we look at the mill
neural sequential composition we find
that it's equivalent to the other weak
form of associativity
very similar except that the sides of
the in equation are reversed by the anti
symmetry of ordering the conjunction of
the whore inequality with the minute
memory inequality gives the associative
equation at this point we have shown
that the algebraic laws provide a
foundation for each of the two standard
methods of reasoning about programs and
we have shown that the algebraic laws
for concurrency can be derived from a
combination of the of these two methods
this shows a strong mutual consistency
between theories that the algebraic laws
for concurrency a valid and should lead
to widespread agreement among theorists
its own thank you unfortunately this is
not always so as well as I will describe
to you by recounting my own personal
experience Robin Robin nila and I were
close personal friends but we regarded
each other as strong scientific rivals I
promoted the ideal of verification of
programs and my theories were designed
to make this look simple Robin's theory
was more realistic he wanted to describe
things as they actually are not as they
should be so he wanted his single theory
to be equally applicable to computing
and to the real world and in this he
succeeded his theory is the one that is
used and I were in biology he this
caused him to concentrate on the actual
behavior of a computer executing a
program written in CCS his put his
program process calculus in the 1990s
Robin and I collaborated on an extended
project funded by the European Union the
third principal investigator was
youngberg struck from
damn who promoted the algebraic
definition of a program of his calculus
which he called a CP and algebra for
computed communicating processes the
name of the EU project was concur and
his goal is to reach agreement among the
theorists on a unified theory of
concurrency after many years and many
millions of euros spent the project had
not got the views of its leading
theorists to agree or to concur as
suggested by the deliberately punning
title of the project and it's only after
20 years that I uncovered the essential
unity of the algebraic the operational
and the verification approach to
concurrency and indeed to programming
whenever I'm tempted feel proud of this
revelation I remember I should rather be
ashamed as he took me took me so long to
come to it 25 years any credit for the
discovery should I think be assigned to
what has been called the unreasonable
power of mathematics it tells you more
than you ever expected to know so what's
the point the laws of programming
provide the basis for the unification of
theories of programming a unification
our theory is a necessary condition for
technology transfer from science to
engineering it is also necessary for
consistent integration of tools in a
software development environment for a
stub and for establishment of the
subject on the academic curriculum of a
school or you know
versity so unifying theories my original
goal as I said in the beginning was a
scientific unification of theories is
recognized as an important intermediate
and ultimate goal for science for
example the story of Newton's apple
illustrates his realization that that
the same laws apply to falling apples
and to the planets in heaven quantum
theory is the closest that we have to a
grand theory of everything it had three
independent discoverers Heisenberg
Schrodinger and direct d Iraq and they
all put put put forward different
presentations of the same theory but
they were prevented from fighting each
other or at least competing with each
other shall we say by Dirac the Iraq
discovered that the theories were
mathematically identical and that made
it possible for him and Schrodinger and
Heisenberg to win the Nobel Prize in
1932 and 1933 because Nobel Prizes don't
go to discoveries which are disputed
among the experts
a unifying theories a benefit of
unification to the progress of science
is that all the evidence can look up
which has been collected separately for
each of the contributing theories
automatically supports the unified
theory which explains them all and
because all the separate theories are
derived from a unified theory each
separate theory inherits the support
given by all all the other theories this
is important because the separate
theories that have been unified do not
get superseded their value is known in
no way diminished by the unification
they may be farm are more easy to apply
to specific classes of problem and in
specific circumstances than the unified
theory and that I think is the case for
operational semantics and verification
semantics one of them is obviously used
for verification and the other one is
useful for execution both of them have a
place in guiding the design of an
integrated development environment for
software
no technology transfer if a practical
engineering countless two scientists who
come into his office and promote rival
theories both of them are sent packing
with the instruction please don't come
back until you have resolved your
differences it's happened to many
researchers in Microsoft Research when
they go and call on them develop her in
Redmond so I'm told the reason of course
is that their managers and investors in
would insist that they would only we
must reduce the risk of the engineering
project as much as possible in other
words it's just too risky to design a
project on the basis of a theory which
is not good does not obtain general
agreement from scientists the other
thing is if you base your product on an
immature theory next year a more mature
theory arrives your competitors will
catch up and over take over take you
very rapidly and your project product
will become obsolete now if you are
engaged on a collaborative endeavor for
example to engineer a tool set to be
used by software engineers you I better
all agree on the specification of what
it is that you are doing a unification
greatly reduces the risk of the
expensive programming error the most
expensive error a mismatch between the
tools across the interfaces through
which they communicate and collaborate
that is why modern took sets exchange
information in a common intermediate
format in intermediate code like
Microsoft's bougie which has been given
an agreed semantics
oops this lecture has shown how the laws
can be translated into rules of of the
kinds that are specifically useful to
the implementers of different tools and
yet be completely confident the
intermediate code is being given the
same algebraic interpretation on both
sides of the interface and if the
algebraic interpretation is all that is
required for the individual designers to
design a correct compiler or verifier
then there is no risk of any gap in that
interface I finally let's come to
education education in computational
thinking at secondary schools or an in
software engineering in professional and
education if the laws of the definition
of the language teaching the laws will
peep and other and have been used to
actually implement the tools in the
interfaces they can be used in the
interfaces between the programmer and
the tool and therefore well let's face
it the people who use to any of the
tools or software design injury actually
do know what the relevant basic laws are
which are common to the science and the
engineering anybody against well if you
wanted to choose your antagonist I don't
suppose you choose Isaac Newton but in
fact he was against it it's the whole
idea of using algebra here is a
quotation from a letter that he wrote to
rich Gregory which I have translated
into more modern English our specious
algebra is fit enough to find out but
entirely unfit to consign to writing and
commit to posture
it cannot and must not be published well
lie blitz was not so disparaging of his
discovery of the different and integral
calculus and maybe he deserves just a
little bit more credit for realizing how
valuable that particular mode of
reasoning is what Newton did was it that
he he did use the reasoning heuristic
alee but his actual proofs published in
in the foundation in the principia
mathematica where would your metric he
used the methods of Euclid to
demonstrate because that really carried
conviction and I think he had something
there one of the real troubles one of
the real glories of algebraic laws that
is that they can be applied easily
without thinking of what they mean
whereas the diagrams that you draw to
accompany a geometric proof the little
ellipses that he drew in the margin to
illustrate the path of the planet
actually mean something rather obvious
to anybody who looks at them and people
prefer he preferred to use a method of
reasoning that seemed more directly
related to the space-time reality that
his laws of motion were attempting to
describe how am i doing for time throw
clock summer
can I whip through a few slides good so
let us try to draw pictures of what we
mean by the variables that are used in
the algebraic laws I'm going to
concentrate on traces of execution of
the program rather than the program's
themselves because of a theorem proved
recently by a friend of mine the laws of
the traces carries straight through into
laws for the for the programs that can
give run whose execution is recorded in
the traces now what we're concerned with
is events that occur at in space and in
time so these can be drawn as dots
points on a two-dimensional plane just
just the one favored by euclid these
points are connected by vertical lines
threads and objects are represented by
these vertical lines and the line passes
from the top to the bottom earlier to
later through all the points in which
the thread or object engages an action
is is performed by a simultaneous or
possibly not simultaneous event of both
a thread and an object and these are
represented by connecting the event of
in the thread which triggered the action
and the point in the object which the
action which carries out the action
now in a message sequence chart which is
what I'm working towards the actions are
given labels to indicate what type of
action it is and here is a list of
possible actions that you might annotate
the events in one of these charts with
so here is what I've done a simple
example in which an allocation axe axe
is the one that is the first action of
the object allocated and here the
disposal is the last action of the
object allocated and in between we have
writes and reads now the arrows may also
be labeled by values which which are
passed from the tail to the head of the
arrow when that action takes place for
example writing the value for reading
the value for allocating a variable with
value well this is written in
hexadecimal obviously because it's the
address of the object concerned and
finally we get to what is often called a
message sequence chart which is already
well-known and widely used in the
communications protocols and distributed
system design I suggest that it should
be used in any tool which is attempting
to help you to see what is going on in
while testing a concurrent program now I
need to define operators on these
message sequence charts which correspond
to to making a message chart of the
sequential execution and the concurrent
execution of of the same program so
what I will do is I will draw two
message sequence charts one from one for
each operand on and then draw a red red
vertical line through the arrows which
separate the columns of the chart the
arrows which cross the line our arrows
simultaneously of the left hand side and
of the right hand side and they
represent the interface a dynamic
interface of communications which pass
between the two threads and when we do a
sequential composition we just compose
the two message sequence charts
vertically one above the other again the
arrows crossing the boundary represent
the system state the memory state that
is the final state for P and the initial
state for Q and these arrows belong to
both P and Q like that and of course
since we can make these splits
independently and again and again a
larger program such as the one shown
here will have a message sequence chart
of the fall of that particular form ah
I've forgotten something the unit one
here's a picture of the do-nothing
message sequence shot it contains no
vents no lines and no arrows and since I
have no time left I will only say it's a
good point to end my talk except I must
thank you for being so patient with
morrie exposition we've listened to many
of my strange ideas you've been
subjected to a mixture of detailed
proofs and speculative philosophical
musings
you've sampled a range of ideas which
are normally found in different guises
in different academic courses in
different books and in different
articles I will hope you will be
rewarded by finding a use for some of
the ideas in your own research and your
own teaching or in your own software
engineering practice but I hope you're
also stimulated now to ask any questions
on any of the or indeed raise any of the
points which I have wrongly emitted and
I'll thank you in advance for that too
thank you very much well thank you Tony
for such an elegant talk and now we do
have a little time for questions from
the audience you showed us some various
proofs which you constructed by hand but
I'm just wondering you know what is the
state of you know state of the art for
automating proofs of the kind that you
showed it's very good this kind of
algebraic proof really goes extremely
fast particularly using the proven ein
or or indeed Isabel and the proof like
the one the one I showed you which is
actually a serious matter mathematical
semantical proof that on which acres of
new general print has been expended
Moses what was timing and whenever I
have an intern I asked him to verify all
my truths which they usually manage to
do without any without any difficulty at
all as advantage of algebraic reasoning
is that it isn't too difficult for even
schoolchildren and but it's really very
easy for computers as well
all the questions Helen I wish it were
true that the things that you described
here I could directly teach to my
students as an engineer you know who
tries to empower some engineering wisdom
to computer science students and I
certainly talk about your work to them
but on troubles by your overall scheme
because of the fact that those walls of
science although elegant wonderful for
teaching in classrooms never proved to
be very useful in my life as an engineer
and users laws are good approximations
when you're trying to draw an
expectation of what might happen with a
physical system but open they're not a
precise accurate description of how any
physical system ever really behaves this
neighborhood is never possible to know
all the factors that influence the
motion so I would say that these rules
of science are useful as approximations
and as clustering theories but not
really for engineers and I'm wondering
if there's a variant of what you've told
us that is a useful engineering
approximation rather than a detailed
proof mechanism yeah I'm an idealist you
know the but I would dispute that you
never use the laws describe several ways
in which you use them indirectly if they
have inspired the writers of compilers
verification systems testing testing
environments then that that's quite good
enough because it's exactly what's
happened in all the other branches of
engineering they do not use the laws
directly they don't they don't
differentiate and integrate anymore they
get computers to do it and so do
software engineers so please I will try
to refute with us your initial
assumption that you don't use the laws
why shouldn't you admire them as well no
thank you another question
concern that your presentation of the
laws contains now account what is meant
by behavior which is presented on the on
the first slide this as but you could
say that what one properties our program
and are you confident that there that
the definitions that the constraints
you've placed on what behavior is by
your choice of these laws doesn't
exclude programs that people might find
interesting and useful um no there are
not so confident about practically but I
tried to make up this for this
deficiency in the last few minutes of my
talk when i introduced the message
sequence chart as the appropriate form
of a diagram which corresponds
intuitively closely to what the computer
actually does and i will support this
view by quoting the experience of those
working on relax memory systems who draw
just such diagrams they they call them
they call them for the calls hmm event
structures perhaps let mr. litt littless
tests and they draw these these pictures
with vertical lines and concrete nine
and if they choose to define their
memory model which is of course
absolutely essential feature of
concurrent programming by means of such
diagrams I'm very happy to take such
diagrams and truths that are on them
through the laws that constraints they
place in what behavior is must be the
same and so has there been any attempt
to explore what what implementations
what manifestations of behavior are
permitted
respect to these laws in which exclude
well there are quite a number of people
in the audience who know the answer to
that question much more reliably than I
do they actually working on on testing
hardware against the claims made often
by those who are making the hardware and
finding litmus tests that will
distinguish between what the designers
say that they have done and what their
hardware actually does comforting to
know that somebody's interested in that
and that problem it's very technical the
only reason I have succeeded in
entertaining you for an hour or so is
that I have ignored a very great deal of
detail all the details of reality are
contained in the definition of the basic
commands now i believe i think that the
essential properties of the basic
commands can very often be coded as
algebraic laws for examples which of
them commute with each other which of
them are consistent with each other and
which of them contain programming errors
can all be described algebraically and
this sort of table of algebraic laws
will convey a lot of information about
the semantics of the of the program and
of the programming language graphically
yes Andy
I'm seeing if I you know applicability
of these laws I mean I mean think we're
all very encouraged by your logic
iran-contra bae systems that have been
super successful in industry like the
sort of slam work of device drivers of
Microsoft Anna mentioned separation
logic the new exciting work that the
forks are basically doing using using
separation logic to improve obvious
biosystems I'm still giving you
experience I mean it's really exciting
that this being such a risk you know
such applications industry of these
tools over the last 10-15 years and you
mean a keen observer I mean what sort of
advice do you have for those people by
what further directions to go in where
to redouble the records um I I hesitate
to give advice people who've been
working in the field rear of the
coalface so long when I'm only working
in head office as it were I would
suggest that the place that one might
attempt to get a more scientific
approach to a more widely acceptable one
is to concentrate on program testing the
most successful tools produced by
Microsoft are all our tools that assist
with finding test cases that violate the
assumption of correctness and if we can
also give help if we can make sure that
any program that we fail to prove prove
has a counterexample generated which
serves as a test case and that's that's
the Holy Grail but any progress in that
direction would be I think not only
scientifically interesting and
interesting engineering challenge but
also welcomed by many programmers
throughout the world
I asked question about algebraic vs I
suppose you could say topological or
limiting I remember many years ago as a
young PhD student reading reports from
CP RG in frumpy Audrey in Oxford where I
discovered of course the mathematical
models were using programming aren't all
finite for example the factorial
function isn't something we ever
calculate but it's used as a denotation
of the values in that and so we have a
set of finite values that are described
by algebra but they then have a limiting
case at the end and I saw lots of
algebra here and I just wondered if
you'd looked at for example if you had a
loop round these things then some of the
limiting behavior may just take you a
little beyond algebra towards where you
have topological structures are going
and there's a wonderful article by
Dexter cozen all action algebras in
which he tackles this problem head on he
has found a complete algebraic
definition of the cleani star operator
in the case of recursion one can apply
task ease fixed point theorem to get the
limit do to get a formal definition of
the meaning of recursion as either the
greatest all the least or fixed point of
of a function but the proof methods that
you have to use are not strictly
algebraic because they are essentially
rules the the recursion induction rule
but apart from that the algebra seems to
bypass a lot of the questions that are
that were originally of great interest
to computer scientists such as whether a
function was computable or not the
algebra applies to one computer both
functions as well the algebra applies to
infinite executions as well
so there's nothing in algebra that says
that the execution of the message
sequence chart has to be finite on the
other hand we can independently describe
what it means to be a finite execution
and use that as part of the
specification of anything that we want
to prove terminates we've worked you
very hard Tony it's been a wonderful
lecture and a question time probably a
good time now to transition to informal
questioning lubricated by alcohol and
canapes outside and let's just end by
thanking you once again for one</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>