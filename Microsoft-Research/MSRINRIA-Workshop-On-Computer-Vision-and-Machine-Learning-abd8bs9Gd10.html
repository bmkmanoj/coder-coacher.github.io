<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MSR-INRIA Workshop On Computer Vision and Machine Learning | Coder Coacher - Coaching Coders</title><meta content="MSR-INRIA Workshop On Computer Vision and Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MSR-INRIA Workshop On Computer Vision and Machine Learning</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/abd8bs9Gd10" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
I would like to talk a bit for some here
to find it right so intrinsic image
decomposition I will talk about a bit
but I realized actually i'm only like
about 10 minutes i do some other stuff
as well which i'm going to start with so
just a bit of advertisement so with
sharam is here very small picture kind
of we had this idea of starting a new
virtual group in the which is a lot of
the vision people i involved and a lot
of the people from the CML group it's
like human-computer interaction group so
we thought about joining forces on some
on some topics to get bigger things done
like like like bigger sicker off papers
so some of the total things we work on
is so we look at cameras we look at time
of light camera and we look at various
other cameras building our new cameras
for yeah for various applications so the
applications are like relative remix
this one so that's like probably know
the Kinect fusion system and there's
actually this here is an extended
version of Kinect fusion where we
actually go outdoors so we build our own
steroid camera and we go out to and do
real-time 3d reconstruction and then you
can do a lot of augmented reality with
it come on the part I'm most excited
about and we'll talk a bit about today
is going with such rich input going
further and for instance to
decomposition into shading and shading
properties shading shadow properties and
material properties but also for
instance if you have some stereo setup
you can estimate 3d bounding boxes and
physical information from it and from
this physical information hopefully to
loop back to to see an understanding
with richer input and then that's a like
Jamie talked about this work mainly and
he's he's driving a lot of that but that
could be could potentially combined with
some reality remix is deformable objects
and that's a great body of work and like
here is like an image of an older sicker
of paper where I don't
forma belen video okay so before i start
with him with a main talk just like
another paper we had at last BBC which i
think is a quite interesting paper and I
mention it because we actually currently
work on a new submission for BBC again
to try to have a bit more theoretical
grounding on this work this is a very
simple algorithm are not sure how many
people have seen about the patch match
algorithm pitch network so so we used it
in the not traditional sense where most
the time patch measures used so in this
work here which was last BBC was so
typically what people do is stare a
matching they have to camera so it
should actually be two cameras down here
what people use is so the green is the
true surface and people typically have
these thrown two parallel depth so they
have discrete so sorry they have
discrete depth and also their support
windows when they do matching our front
to power windows so so this this green
surface here you could either have a
matching cost here at this particular
depth or at this particular depth right
so in this work here we said well we
would we would try to do a matching its
pure unary terms is just matching of
support windows which where the support
windows are orientated in 3d and have
continuous continuous depth and
obviously that will support the true
surface much better so this is the
reconstruction here with front apparel
and this is what what we get when we
align the windows and this is actually
there is no there no pairwise terms in
here and that's currently one of the
things we're looking into how to put in
Paris terms so now so the main challenge
is how to actually get these so these
these planes can be represented support
windows by 33 continuous vector3
continuous variables at each pixel how
do you optimize them so we use this this
patch match algorithm and the main idea
is that first of all quite often there
are like bigger planes in the image or
even a bit I mean if it's a bit curved
it might also still work but there are
larger regions which are supported by
one plane like this image here for
instance
and couldn't be the idea of the
algorithm is just to say if you have one
if you have one playing FF 1 pixel away
I've got the right guess you can
propagate that information and i will
come to the algorithm in a second so
that's the whole idea if you have three
correct guesses for this image here in
here and here and here you can actually
very quickly propagate it and get the
right solution out so the ibrehem is
extremely simple you randomly initialize
the plane parameters so there are three
parameters for the for the plane the
continuous parameters then there is a
propagation step and I will come to that
point in a second but it's kind of it
feels the ingredients are very similar
to belief propagation or particle belief
propagation which we currently look into
and we try to make exactly the
correspondence and see if there is
something to be gay when you actually
express it as a particle belief
propagation but anyway so what what this
margarita ms the patch match is simply
doing is it's doing propagation so it's
like it says it has a solution for
instance here we've got to actually
label both images with terms of depth we
have for instance a solution for this
picture here and for this pixel here now
we try to find the solution for this one
here so this is the random
initialization what we simply do is we
look at the neighbors and say is it a
better is it a lower value is it my
unary cost if I recomputed with that
particular ABC coordinates or these ones
are is it a lower energy or not and then
you take it or you if it's how you don't
take it in slower you take it and it'll
you simply propagate there are also some
more interesting propagations across
views when you've done you can actually
propagate into the other and also
temporal propagation for videos and then
there is a random sampling step in there
where you have the solution and then you
actually refine it or your samples
around around your current solution and
it's yes just kind of you think about a
Gaussian surrounding or localized on
your current solution and you sample
from that to refine it we totally do
three iterations and so as I said we
can't look into how is it actually can
be expressed as particle belief
propagation and pairwise terms
potentially could be put in and I think
it's going to be quite a interesting
hopefully good submission to BBC anyway
so here is the short video
running here right so random
initialization and then there's a simply
propagation of top left to bottom down
and you already see it's quite it's
quite good then it's going the other way
around up in between there refinements
which are not sure if they visualized
and then it's going down again and then
I think it's finished there are two most
quite standard steps of checking
left-right check and then filling in the
pixels which were didn't satisfy this
check and then this is the output so we
actually managed to put that on in real
time on several GPUs and we had these
results I showed them beginning on 3d
reconstructions in real time that was
actually done with this method so just
some results Callen so especially is
nice slanted surfaces and curved
surfaces are done pretty equities and
there are no Paris terms and here's just
purely human returns so here is just a
demonstration about if you were to use
integer then you get these steps which
you see here the next thing is is in
teacher but orientated surfaces and then
and the other one is continuous depth
and orientated surfaces and you clearly
see the improvement hmm we haven't tried
people no well no there's a video coming
a second but no I don't recall any
images with so you clearly see an
improvement in terms of depth estimation
yeah there's one here on the on stairway
video and we as we say we managed to put
that now into your in to real time with
with several GPUs okay so main topic of
the talk all right only seven minutes
okay so this is a nips paper which we
had last year so intrinsic image a
decomposition the goal is you have an
input image you try to separate one
image into two images one is only on the
material and the other one is on the all
the light effects which is
shading and shadow are very ill posed
problem and so currently now approach we
ignore specular highlights so so we
phrase it as in the following way so
there are three color channels for every
pixel index I we have to compose it into
the shading shadow which is a small s
because it's just a one-dimensional and
this is three-dimensional is there
reflectance for the for every pixel ok
so motivation is in general interesting
problem arm would be great if it works
perfectly would be great if as in piss
poor shape for shading recognition
potentially segmentation and so on so I
think it's quite interesting but
obviously it's a very hard problem I
mean if that's going to be my outlook
that's where currently look into back in
the Kinect fusion sense like if you have
some rough 3d reconstruction how much
better can you get but currently in this
work we do it with a single image we see
what what what how far you can get there
is one there was one paper for instance
at siggraph two years back frias back
which did interactive so you had some
scribbles additionally you get this
reflectance out there shading out here
they used the head they had color
shading image because there might have
been multiple different lights with
different colors they can then just do
this image editing with it of putting
some different texture on and they have
to let the texture as well I guess but
they put all of the shading shadow from
this image on ok so there there is a big
there is a certain database but the main
problem it's it's not very big this is
the database so people from from Freeman
from the yes they have done that with a
it's quite elaborate setup so they have
a table where they put an object on then
their photograph it and then they
actually move out the whole table with
the object on they spray it in white and
then move it back in and take another
picture I'm not sure about the alignment
how good that is so these are some of
the objects in there and these are the
decompositions which is the ground truth
they measure I have to say that I'm not
sure about the quality of the ground
truth you really soo mean I think
there's more noise than there should be
so these are some of the dick
physicians counter our formulation is a
so first of all we were yeah you can
reduce the problem to one unknown
perimeter because you have this equation
here which are three equation for each
color channel and four unknowns so the S
is 11 dimensional and three-dimensional
for our so forth poor unknowns per pixel
and three equations so you can rewrite
it in a in a small are so one scalar for
each pixel is the is the unknown
variable so basically if you this is an
artillery which can be pre computed and
this is the true reflectance multiplied
with an R and this is the shading this
is the norm of the intensity so if you
plug s I and RC in there you get out
that I is equal to I so satisfying the
equation okay so what we do is a
traditional random field with two
standard terms and one new term and then
we just see how it performs with this
new term so the two standard terms are
the shading and the the so-called color
right our next term here and this is our
new term called a clustering term so the
shading term sorry is is a very standard
term which is just a smoothness term you
have the shading here and you say
neighboring pixels should have the same
shading and it's just a quadratic norm
on that quadratic penalty so these are
crops of the real image here it's pretty
smooth but here is not very silly so
it's not always a very satisfied so this
is a new term what we have is the ideas
that the image is only composed of a few
reflectances so this is the reflectance
image and this is the input image so
these are all the colors you've
distributed from the image and this
year's from the reflectance image and
you see there are more clusters here so
this is the white cluster and these are
the different colors here there are some
in between colors that come from these
transitions here between the between the
strobes so the whole idea is to say that
image has typically
few number of reflectances so we try to
find out what are the reflectances what
are these clusters what are the color of
the clusters and how's the clustering
done and at the same time solve these
other parts of the energy so this is a
cluster energy which we try to find the
wave k clusters and I come to that in a
second we try to find the color of these
clusters and then we say the true
reflectance should not deviate too much
from the reflectance of the of the
clusters so this is the illustration
about the power of this kind of this
clustering so here is an input images to
do composition this is the clustering if
it were to be perfect if there is no
smoothness on the shading so this is
this this is just smoothness and the
clustering if there is no no wait on
this on the smoothness what you see is
that within a cluster you actually get
the perfect the perfect shading out
because within a cluster it has to
explain everything by the shading now
across the clusters you don't get a nice
result and then if you switch on just a
bit option of smoothness it basically
says between the glasses has to be
smooth and you get the nice result out n
so this then with a bit too much
smoothness you get over smoothing here
so the interesting bit is even if you
have a lot of over segmentation there
are only in this case probably 50
clusters you still get out in quite nice
result with a bit of smoothness because
these pixels are all constrained within
the cluster here it's getting out the
right result so as long as there as
there are some pixels which are the
which are clustered correctly you get
out within the cluster the right thing
and the rest is done by smoothing so the
last term is the standard term grading
consistency which is the basic thing of
color 18x what you do is you cluster you
first classify the edges if it's going
to be in reflectance of shading edge so
this is the clustering here where you
hopefully correctly classified it and
then you just say you know what the jump
is in the reflectance that's taken from
the image here and then you just put
that energy in that that in the final
result you want to have the same
in the reflectance so here is just for
the color red tunics an illustration
what you typically get out so you've got
these are these some cluster these
classification here this is black as is
a transition so you have these
transitions and you know what they would
be a strong the transition should be and
you can get these reflectance images out
and this is the shading image all right
run a bit out of time so this is the
algorithm is phasing to just iterating
between the reflectance computation and
the clustering so it's just like we
initialize the clustering k-means then
we also optimize the this r and then we
Clutton then we cluster again and we
optimize our so here is the results with
cross-validation just to show that that
it's actually improves when you have our
full model and these are comparison to
state-of-the-art so this is our model
and these are kind of like competitors
fierce competitors down when you've used
multiple images that's your vice method
it's they're still better but you have
to sleep one out cross-validation to
hear some results I think the main thing
to take out is when we use our full
model the results look much more on the
reflectance looked more realistic so
this is like color rednecks with our
global term it looks visually very
different to this one here and here's
another one those color rotten eggs and
this V the full model is like it's much
smoother result than the color red necks
okay so next steps we look at we might
look at different priors we look at
different input stereo connect fusion
applications interesting potential
recognition arm and where to get
training data from real world is
synthetic that's kind of another
interesting question okay thanks a lot
Andrew do you have a question oh you did
you see the tips of the paper when you
share the results still residual and
will find yourself sure it's like an
error you mean matching sure I mean like
like texture i think texture objects
with it which are highly textured fur
and things like that is very hard their
intellect insists all different
difficult things going on there I think
if you have a very simple object like a
whole same reflectance on the big
surface that's relatively simple if you
have a lot of like like here wood
material it's it's also not well it's
think that's okay but we we start to
sing a bit about different price for
reflectance like like field of expert
prior or things like that but we're him
trained up yet the thing is like the
student is a very good student lot of
like machine learning skills he kind of
sets the database is so small it's like
he could / fit it and then get but but
he doesn't want to overfit it's just
like a small training database I think
words have a big train database would be
good obviously it's not out there me
normal images you cannot really take so
where do you get data from it's a
problem you could think about just using
that I don't know um probably phone
photo since I was thinking because
there's some I don't know I had some
ideas to think about training data in a
like not as elaborate ways what they've
done but that's an open question yeah
yeah but we started to do a bit on
graphics but they didn't look realistic
enough the images yet and that as and
there are very much believe in graphics
I mean would do it jamie is done is is
this graphics but if you but only for
depth cameras you gave for real cameras
RGB cameras it's a thing that's an open
question is it realistic enough for RGB
images okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>