<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Asymptotic Behavior of the Eden Model with Positively Homogeneous Edge Weights | Coder Coacher - Coaching Coders</title><meta content="Asymptotic Behavior of the Eden Model with Positively Homogeneous Edge Weights - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Asymptotic Behavior of the Eden Model with Positively Homogeneous Edge Weights</b></h2><h5 class="post__date">2016-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zg73M7h3Nj8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so I'm very happy to introduce you
n green brilliant young probability MIT
working with Scott chefville who has
been an intern here this summer with
David in me and you will tell you about
our joint project on first passage
percolation right thanks um so today I'm
going to be talking about a very end of
the Eaton model equivalently first
passage percolation where edges are
weighted by a positively homogeneous
function and this is also called the
Polya aggregate model and the this is
based on a joint work with Sebastian
blue-black so I'm going to start by
introducing the unweighted eaten model
and the first passage percolation model
and then I'm going to talk about the
particular model that I'll consider in
this talk so the Eaton model is a random
growth model on ZD um it's important in
a variety of fields because it can be
used to describe things like the growth
of bacterial colonies lichens mineral
deposits on the diffusion of information
through network and so forth so to
define this model we start by sampling a
an edge uniformly at random from the set
of all edges of ZD which are incident to
the origin and we let a 1 tilde just be
the singleton SAT which consists of this
this one edge so just start with one
edge um then inductively if for some
positive integer n the set a n minus 1
tilde has been defined we sample an edge
en uniformly from the set of all edges
which are incident to the to the
boundary of a n of a n minus 1 tilde but
which are not actually contained in a n
minus 1 tilde and we let a n tilde bv
the union of a n minus 1 tilde and the
singleton set en so look this is what it
looks like that for two stages and then
after n stages we get you know a big
cluster of edges and then we we add one
more at each stage so first passage
percolation is another random growth
model which is can sometimes be viewed
as I can
this time Reaper amortization of the
eaten model so this model is a little
bit more complicated to describe but it
also is more tractable mathematically so
to define this model we start with a
collection X sub e for each en ZD of iid
X match for each edgy of ZD of iid
exponential random variables and for a
path ada in the integer lattice by which
will mean a connected sequence of edges
in the integer lattice we let the
passage time Veda which we call T aveda
be the sum over the sum of x e over all
of the edges e in in the path data and
for a vertex V of the integer lattice we
define T of 0 V the passage time from 0
to V B to be the minimum of T aveda over
all paths ADA which connect 0 to B and
then we define a growing family of sub
graphs of the integer lattice which we
call a tea as follows for each T we let
the vertex set of 80 be the set of all
vertices V and V V and ZD whose passage
time from 0 is less than or equal to T
and we let the edge side of 80 be the
set of all edges in ZD which are which
lie on paths started from zero whose
passage time is less than or equal to T
so this gives us a growing family of sub
graphs of the integer lattice parameter
eyes by the positive real numbers and it
turns out that first passage percolation
is equivalent to the Eden model in the
following sense so suppose that for each
positive integer n we let T sub and be
the smallest T for which a tea has at
least n edges um then this gives us
another another growing family of edge
sets um parameterised by the positive
integers and it has exactly the same law
as the Eden model clusters and this is
just an easy consequence of the
memoryless memoryless property of the
exponential distribution
sell the one of the most fundamental
theorems about yes this night they said
fine they invaded loaded a set of edges
that you always fall battery yes um no
they don't former taken four stations
right because you've been selecting
uniformly from the set of all edges that
are a Jay set to the current cluster
that you haven't selected yet so like in
um in this picture you know maybe maybe
here instead of selecting this red edge
we could select this edge here now we
would form a cycle okay so it's not the
edge the next to the other side no it
just has to be some edge which is not
which is not been hit yet okay so the
one of the most basic theorems about
first passage population is this
following result which was originally
proven by Richardson and various
strengthening xand generalizations
recruitment by Cox and direct and kasten
it says there is a deterministic compact
convex set Bowl day which is symmetric
about the origin such that the the first
message percolation clusters converge to
a tee in the following sense um for each
T it holds except on an event of
probability decaying faster than any
power of T which is what i mean by this
notation osim t infinity of T here um
that the vertex set of 80 is
approximately equal to t times bowl a
intersected with ZD modulo these these
polynomial order errors so although we
can get very strong convergent
statements about the the convergence of
the fpp clusters told toward bold a we
know almost nothing about the SAT Bowl
day itself beyond the fact that it's
compact convex and symmetric about zero
it's not even known for example whether
or not it's a Euclidean ball except in
dimension greater than or equal to 35 so
this is a very poorly understood object
um but it's it's not hard to simulate
the SAT Bowl day by just writing a
simulation of the even model
and so here's a here's such a simulation
which was generated by Sebastian using
math using matlab and as you can see the
limit shape appears to look like a
Euclidean ball but maybe it's off by a
little bit um so it's so it's
approximately a utility involve it's
conjecture that it's not not exactly a
equally involved so in this talk I'm
going to be interested in the following
natural variant of the Eden model um
which can be described as follows
suppose we have a weight function which
we call WT on the set of all edges of ZD
so each edges associated await WT of e
um and suppose that we do the standard
construction of the Eden model except
that at each stage instead of selecting
the next edge en uniformly we select
that edge with probability proportional
to the way to be from all of the edges
which are incident to the previous
cluster so as is the case for the
ordinary Eden model this this weighted
variant of the Eden model is equivalent
to a awaited variant of first passage
percolation where we have independent
exponential random variables at each
edge but instead of all having parameter
1 the parameter of each exponential
random variable is given by the weight
of the corresponding edge and again this
is just a consequence of the memoryless
property of a exponential distribution
so in in this talk I'm gonna focus on
the the weighted eaten model where the
edge weights are given by an alpha
positively homogeneous function for some
real number alpha so there's there's a
number of reasons for considering this
particular variant of the weighted Eden
model first is that it's just a it's a
natural generalization of the standard
even model on both because of just
intrinsic mathematical interest and
because in the in the situations that
the Eden model can be used to model
remember like the growth of mineral
deposits and the spread of information
and so forth it's it's natural to to
consider what happens if you allow the
growth rate to depend both on the
distance to the origin and the direction
in which you're growing additionally
it turns out that on diffusion limited
diffusion limited aggregation or DLA
which is another important random growth
model is actually equivalent to a
weighted variant of the Eden model on a
dierry tree where instead of having
edges which decay polynomially as we
move away from the origin or instead of
having weights which depend polynomially
on the decision origin we have weights
which depend exponentially on the
distance to the root and this model was
studied by Elvis and shields and by
barlow mantel and Perkins and finally
recently in the computer science
literature a variant of the weighted
Eden model with a with positively
homogeneous edge weights which is the
particular model that we're considering
this talk was proposed as a protocol for
spreading a message while obscuring its
source so these are these are some
reasons to be interested in the model
considered in this talk so now to
formally described the situation I'm
going to consider for the rest of the
talk fix a we fix some real number alpha
and we fix a function f 0 from the
euclidean unit sphere to the positive
real numbers which is Lipschitz
continuous and we let F be the function
which is given by the Euclidean norm of
Z to the alpha power times F 0 of 0 ver
absolute value Z so that F is locally
Lipchitz and positively homogeneous of
degree alpha for example we could have
that f of z is equal to the alpha power
of some norman rd be positively
homogeneous they saying because alpha
appears with that a minus sign the
definitely not thought must know I
positively homogeneous I mean that F of
constant times Z is equal to the
absolute value of the constant to the
alpha times F of Z a function was just
homogeneous would mean that if you took
like f of negative Z it would be equal
to negative f of Z that's not the case
here that would work Howard
right so wait we consider positively
homogeneous rather than but signed what
my genius is it okay so yeah but alpha
can be positive or negative and so in
this track we're going to consider the
weighted fpp model where the weight of
each edge E is given by the value of F
at the midpoint of that edge and we call
this model f weighted fpp and note that
in the case when F is identically equal
to one so that alpha is equal to zero we
just get the standard ftp model and in
the case where d is equal to one so
we're just working on the line and f of
z is equal to 1 over Z we get the Polya
Orton model so in some sense our model
can be viewed as kind of a vast
generalization of the Polya earn model
and this is the source of the name
apollyon aggregate so we'll introduce
yes sorry should be plus one here um so
now that we've introduced the model I
can state the main results of my project
with Sebastian so first in the case when
alpha is less than 1 for any choice of
the function f we get a deterministic
limit shape in the same sense as for
unweighted ftp um so we have some some
simulations in this case so if we take
alpha to be equal to negative 2 and F of
Z to be the l1 norm to the negative 2
power then our our limit shape kind of
looks like a slight rounding of the of
the l1 unit ball and if we hate alpha
equal to 0 and f of z to be the ratio of
the l1 norm to the euclidean norm to the
third power this means that the
restriction of F to the Euclidean unit
sphere which we call f0 is going to be
big on the diagonal directions but
smaller on the horizontal and vertical
directions then we get this kind of four
leaf clover shape all right so that's
what happens in the case when
is less than one in the case when alpha
is greater than or equal to 1 um thing
things are a bit more complicated and we
need to introduce a new notation to
describe our results in this case so if
alpha is sorry if alpha is strictly
greater than 1 they're almost surely
exists a finite t for which 80 is
infinite this should be strictly greater
not greater than or equal to um and we
call how infinity the the smallest such
team so cow infinity is in some sense
the time that it takes for the fbt
calstrs to get to infinity and this is
this is kind of easy to verify and will
be an easy consequence of some of the
estimates which I'll describe later in
the talk I'll be just a lot of line
sorry I'm just really feeling in finally
came along the straight line yes it's
it's it's it's a it's an easy estimate
improve so are our first main result in
the case when alpha is bigger than one
is the following so for each alpha
bigger than one there exists some norm
new which may depend on Alpha on our d
such that if we take our weight function
to be given by the alpha power of new
then um almost surely all but finally
many vertices of the time infinity
cluster a cow infinity are contained in
some euclidean cone of opening angle
less than pi so here's a simulation in
the regime where alpha is bigger than 1
so this is with alpha equal to 5 and f
of z given by the euclidean norm and
here as you can see we start here and we
just we go off to infinity in one
direction so this is very different than
the case when alpha is less than or
equal to 1 note that this this Euclidean
norm is not the action is not the norm
that we actually prove the result for on
the the purpose of this the purpose of
this picture is just came to illustrate
what happens in this case thank you yes
we do think it's true for the you clean
Norma it's not not the one that we can
actually prove it for a lot of others as
well yes but not for all norms as you'll
see from our our second theorem which
says that for for any choice of the
function f 0 to remember is the
restriction of app to the unit sphere
on there's some small positive constants
C which depends on at 0 such that for
any Alpha between 1 and 1 plus C almost
surely on ZB minus the vertex side of 8
how infinity is finite so all but
finally even many vertices of ZD are
emotionally hit and in particular it's
the the cluster is not contained in a
cone of opening angle less than PI so in
particular this tells us that in theorem
2 we cannot take the same norm new for
every value of alpha so for example if
we took the Euclidean norm there have to
be a an alpha slightly bigger than one
for which the the cone containment
result is not true so here we have a
simulation in in this regime where alpha
is slightly bigger than 1 so as you can
see it doesn't appear to have a
deterministic limit shape because it's
it's growing at different rates in
different directions um but on the other
hand it's it is growing at a at a
positive rate in every direction so it's
not going to be contained in some cone
all right so here's the summary of the
results and i just want to point out
here that in each of the three results
the corresponding object is a
deterministic functional of the of this
of the function f in a standard limit
fpp limit shapeable day so even though
we don't know bold a explicitly if we we
did know what bold a look like we could
given an explicit description of the
limit shape in the case when alpha is
less than 1 the the norm new in the case
when alpha is bigger than one and the
constant C on for a for a given f 0 so
now that we've stated the main results
we can proceed to the proof that's if
it's deeply derivative to the Alpha you
do know that for large enough all by ear
Oracle now we do not know that all this
is a remains an open problem to show
that to answer whether it's true that if
you fix in our new but it's almost
surely contained in a cone for large
enough alpha its flesh their results
again baby
all right somebody and let this finite
hopefully is going to be some places
where you just have the focus with it's
always true because it gets to infinity
in finite time so it's always true that
if you fix some some work some vertex
than with positive probability there's a
patch that vertex with passage time
which is less than the time to infinity
so you're you're never going to have
things can always fluctuate by a finite
amount okay so now for the for the
proofs of our results so the the main
idea of our proofs is that we're going
to approximate F waited a few key
passage times by a certain deterministic
metric which depends on F and on the
standard ftp limiting shape bolle so to
define this metric we first define a
norm u which is just the norm ird who is
closed unit ball is bowled a on this so
mu of Z is the smallest are four which
is e is contained at all arbol de and
this gives a norm because bull day is
compact convex and symmetric about zero
now if we're given a piecewise linear
path gamma um from some interval 0 T 2
r.d we say that gamma is parameterize by
new length if for each T in zero big t
the MU length the sum of the MU lengths
of the linear segments that gamma has
traced up to time T is just equal to T
ok so it travels T units of new length
into units of time and for for such a
path gamma we define the D length of
gamma to be the integral from 0 to t of
1 over f of gamma of T DT ok and 4.2 ZW
in our d minus 0 we define the you to
find d of ZW to be the infimum over all
paths gamma from all piecewise linear
paths gamma from z to
view of the of the D length of gamma so
this D is a metric on our d minus zero
and it's a metro extends to a metric on
all of our d if in fact alpha is less
than one and it has the following
scaling property for any Z and W in our
d and any are greater than zero the
distance from RZ two RW is equal to R to
the 1 minus alpha times the distance
from 0 W this is just an easy
consequence of the of this formula here
alright so the reason why we're
interested in this metric D is the
following lemma which is going to play a
crucial role in the proofs of our main
theorems so what this is is that we're
given any stopping time for the
filtration generated by the fpp clusters
and any positive integer M on then
except on an event of probability which
decays faster than any power of M it
holds for each vertex in ZD which is not
in the time tau cluster and has its
Euclidean norm proportional to M um it
holds that the the passage time from 0
to V minus tau is approximately equal to
the the D distance from V to a towel in
the following precise sense we get these
exponents which tell us how close the
approximation is then we have a error
which is a sub- power of M so now
suppose that we're given so too I'm not
going to give a fully detailed proof of
that lemma um because it's it's a bit
technical but I'm going to give a kind
of a hurry argument for why we should
expect it to be true so suppose we're
given a vertex you in the in the time
Cal cluster a towel and then we observe
that near you the our clusters grow like
on standard unweighted fpp scaled by F
of U and translated by you right and by
the limit shape result for standard ftp
on the limiting shape of of this
is going to be the the ball of radius f
of you centered at you in the norm mu
which is just F of you bowled a plus you
so for for each small epsilon greater
than zero um it holds with high
probability that a tau plus epsilon
minus a tau is approximately equal to
the the union over all vertices vertices
you na tao of the MU ball radius epsilon
f of you centered at you intersected
with ZD right because we just apply this
observation then we take the union over
polynomially many vertices because this
holds because the the limit shape result
holds except an inventive probability
decaying faster than any power of m and
we only have polynomial e many vertices
on with distance to the origin
proportional to M we get that this this
approximation holds with high
probability now if we're given a
positive number T we choose some small
epsilon and we break up the interval
from tau D tau plus T into increments of
size epsilon and then we use the
definition of the metric mu and we find
that in fact a tau plus t minus a tau is
approximately equal to the D ball of
radius T around the vertex set of eight
how intersected with ZD right because
we're just kind of averaging the
function f / / increments of which size
depending on mu and so if we're given
any vertex as in the statement of the
lemma we find that the time it takes to
get from a cow to V is approximately the
D distance from B to a towel and that's
that's why this lemma should be true
this kind of illustrates what's what's
happening here if the start with a set a
towel which is the site in blue um then
it's going to grow kind of like the the
that the fpp process after time tau is
going to grow kind of like the the D
balls centered at UM a towel so it's
going to grow so if alpha is bigger than
one which is the regime that's shown in
this picture then it's going to go
faster when we're further
from the origin and we're good and it's
going to grow slower when we're closer
to the origin okay um right so now that
we've got our main lemma we can move on
to the to the proofs of the main
theorems so first we're going to
consider the case where alpha is less
than 1 which as you may recall is where
we're claiming that there's that I
deterministic limit shape of the VP
clusters in this case so when when alpha
is less than 1 each point of our d lies
at finite distance from the origin in
the metric D so so we're going to we can
extend dito metric on all of our d so in
particular the the ball of radius one
centered at zero in the metric D which
we call bold be is well defined and by
by scaling we know that bold be is just
equal to R to the negative 1 over a
minus alpha times the the D ball of
radius R centered at 0 and it turns out
that in fact bold B is the limiting
shape of F weighted fbp in the following
sense so um we take these these
exponents Chi and Chi tilde which will
give us our our rates of convergence
then for any T it holds except an event
of probability decaying faster than any
power of T that um the vertex set of 80
is approximately equal to t to the 1
over 1 minus alpha bold be intersected
with ZD so this is essentially the same
as the limit shape result in the case of
unweighted fpp but just with with
somewhat different exponents all right
so so prove this theorem we proceed as
follows the order is just the exponents
um so that fluctuations here will
actually be of different order but the
exponents are probably not optimal um
the reason for this is that these
exponents come from the exponents in the
the limit shape result for standard fpp
and those fluctuation exponents are not
expected to be optimal so you think
videos aren't either hey do you think ok
so for for each positive integer n we
let tau n be the smallest t for which 80
is not contained in the d ball of radius
n centered at 0 ok so it's just so if
this guy here say is the dbol in blue
then in tau n is just the first time
that we're not contained in it um we
know that for for any n tilde greater
than n the D distance from the deep ball
of radius end would devolve radius n
tilde is equal to n tilde minus n
obviously and so by the by the D
approximation lemma um tau n tilde minus
tau n is going to be approximately equal
to n tilde minus n except an event of
probability decaying faster than any
power of n provided that angela is
proportional to n so as they enter lows
between 1 plus epsilon and and 1 over
epsilon n um so this means that with
high probability the vertex set of a tau
n tilde is going to contain everything
which is at d distance slightly less
than until the minus n of 80 in alright
so this means that if at time tau n are
our cluster 80 n contains most of the
things in the dbol of ready most of the
points of the d ball of radius n then
also at time tau n tilde our cluster is
going to contain most vertices of the d
ball of radius and Tilda ok so by
induction our proof will be complete
provided we can show that with high
probability there's some n0 for which a
Tau n0 is not too much different from
the D ball of radius n0 um and in fact
we can just use some some basic
estimates for exponential random
variables I can't essentially just you
know counting just fix some path between
two vertices and look at how long it
takes or the an estimate the sum of the
exponential random variables along that
path we can find some some epsilon
greater than 0 which does not depend on
n 0 such that um with high probability
um vertex set of a towel n 0 contains
everything contained each vertex of ZD
which is in the ball of radius epsilon
and 0 centered at the origin and such
that the time tau n 0 is between epsilon
and 0 and epsilon inverse and 0 so it's
things are off by most a constant factor
with high probability win when n 0 is
large um this should actually be an 0 n
0 infinity of n 0 because it's a it's a
probability so 0 and 0 of n 0 does
exactly make sense but um right so
because n0 is fixed this this error
epsilon inverse n 0 is just dominated by
n when n is large so it doesn't matter
where we started at because when we make
and large enough just the the error from
this the starting position just kind of
is dominated by n m and it turns out
that this is this is enough to prove the
to prove the theorem so this is how we
get the the limit shape result for alpha
less than 1 all right so next I'm going
to turn my attention to the to the
result which I called theorem 3 above on
because it's easier to prove then than
theorem to recall this one says that for
any fixed f 0 so f 0 is the restriction
of f to the unit sphere um if we take
alpha a little bit bigger than 1 then
almost surely a towel infinity contains
all but finally many vertices of ZD so
to prove this we first are going to
quantify how close to 1 alpha needs to
be so if we're given ZW z and w in the
boundary of the euclidean unit ball we
let gamma delta of ZW be the set of
piecewise linear paths from z to w who's
linear segments have length Delta and
which have endpoints in the the
euclidean units
we let lambda bv the D circumference of
the Euclidean unit sphere which is just
defined by by this formula so we we look
at the infimum of the so essentially
what we're doing is if we're given
points Z and W in the in the unit sphere
we wanted to find the distance from Z to
W considering only paths which are in
some sense contained in the euclidean
unit sphere but of course you can't have
a piecewise linear path contained in a
sphere so you have to take piecewise
linear paths which are almost contained
in the sphere and you take the infimum
of the the lengths of all of those this
gives you the distance within the sphere
from Z to W and then we look at the
maximal distance overall points in the
sphere of the the distance from Z to W
and we take the limb soup as Delta goes
to 0 this quantity is is that can be
interpreted as the D circumference of
the unit sphere all right this okay for
everybody these paths go in the ball
here well they're the endpoints of all
of the linear segments will be on the
sphere but and the linear segments will
be short that's anywhere um well they're
going to have to be contained in the
unit the Euclidean unit vault by
convexity involved okay yes and so this
looks kind of like a diameter instead of
Russia conferences um well the diameter
I would think of as the the D distance
between any two points without any
constraints on the paths but here we're
requiring the paths to be in the sphere
so it's really the distance around the
sphere nowadays is asking that seems to
this very you totus only the fashion all
on the day of questions right it doesn't
deserve it right these are very close
they're they're piecewise linear paths
and all of the segments have length less
than Delta and the endpoints are going
to income the end points of each segment
is in this year yes oh so it's the path
is very close game container on its
nature right this has to be piecewise
linear
as level so I get his house after
circumference arc happens around pretty
nice assuming alpha is strictly greater
than 1 yes but this it's like booing
this 5 title outside it's been 11 plus
okay yeah I can be equal to 1 it can it
can be equally and this make sense it's
just me it's greater than or equal to 1
gah um so um the important point about
this quantity is that it's it's positive
and it depends only on f 0 because the
function half is just identically equal
to f0 on the validity in unit sphere
okay um so now we're going to we're
going to prove that um now we're going
to prove that we're going to prove
theorem plea all right so um it's it's
not hard to show that the D distance
from the Euclidean ball of radius n to
infinity um is at least some small
constant times alpha minus 1 inverse
times n to the 1 minus alpha or hear the
small constant does not depend on alpha
but it may depend on bold a and F 0 for
each positive integer and we let Sigma N
and be the first time that 80 is not
contained in the Euclidean ball of
radius n so similar to the time to tau n
and the previous slide we're using your
hoodie involves which is alpha minus one
little one infiniti the so in the case
when alpha is equal to one the D
distance from anything to infinity is
infinity ok ok so where alpha is equal
to 1 it's kind of a trivial statement I
got it sorry it's hard to be precise
about all the little details when L was
exactly equal to one on there
other signs are it so by the weather the
approximation llama we get that
accepting the value of probability
decaying faster than any power of n tau
infinity minus sigma n is not too much
smaller than B times alpha minus 1
inverse times n to the 1 minus alpha all
right this is the adidas tense to
infinity so the time to infinity is
approximately the D distance to infinity
which is just the statement um so on the
other hand any two points which are in
the nhu points of the integer lattice
which are in the Euclidean ball three
days n plus 1 minus the Euclidean ball
of radius n lie within the distance
slightly more than lambda times n to the
1 minus alpha from each other follows
from the definition of lambda together
with a scaling property of the metric D
um so if lambda is less than B times
alpha minus 1 inverse then the time it
takes our clusters to get around the
boundary of the ball of radius n is
smaller than it the time it takes the
clusters to get to infinity and so this
means that with high probability it's
going to absorb every vertex in be n
plus 1 minus BN after time sigma n but
before time how infinity um so and this
holds accepted in fact decaying of
decaying faster than any power of n so
in particular the probability of the
complement of the event is summable and
so we can apply Borel Cantelli to get
that emotionally this is true for all
large enough n which implies that
emotionally the cluster a cow infinity
contains every vertex all by fine
animated vertices of ZD and that's what
we wanted ok so here's a picture we look
at the time that exits the euclidean
ball of radius and tire takes it to get
to infinity is BN to 1 minus alpha over
alpha minus 1 at least at the time it
takes it to get around the boundary of
the ball is lambda n to the 1 minus
alpha so if this guy is smaller than
this guy then it's going to hit
everything all the vertices of ZD near
the boundary of the
all before it gets to infinity okay so I
concludes the proof of theorems one and
three and now I'm going to turn my
attention to theorem 2 which says that
if alpha is bigger than 1 then there
exists norm new such that if we take f
of z equal to new to the Alpha then
almost surely all but finally many
various use of eight how infinity or
contained in a cone of opening angle
less than pi okay so note that by
theorem 3 we can't take an arbitrary
choice of norm there has to be some
dependence of this norm on Alpha at
least when alpha is close to one arm so
in order to define the particular norm
that we're going to consider we need to
introduce a couple more quantities which
depend on the standard fpp limiting
shape of bold a so first I let robar be
the smallest are for which bowl gay is
contained in the euclidean ball of
radius art and I like bold it's not
about absolutely nothing really well I
think there may be some very very
trivial bounds on it like its most like
as d goes to infinity grows at a rate
that's at most D over log B or something
like that and I think that's probably
the best that's available so this this
quantity is not very well understood at
all and likewise this let bold X be the
set of accessing the boundary of bold a
for which absolute value X is equal to
Rho bar so bold axes the set of these
blue points which are at maximal you
Polly in distance from the origin um
also there's there's almost nothing
known about this set bold x um but it's
a well defined quantity it may be the
entire boundary of the euclidean ball if
the ball day is actually equal to a
euclidean ball but probably it's not all
right maybe you can say that if we knew
more Oh Dixon yeah so if we knew more
about both acts than one would be able
to say what these we be able to say more
about the norm that we're going to
define shortly but I'll tell me you
could get
yeah let's yeah I guess is the main
obstacle in proving this for a for the
euclidean norm where the l1 norm or
something like that is really that we
don't know very much about boleh and
therefore we don't know very much about
the metric D and therefore we don't have
very good estimates for the for the FPC
passage times in in that case hold on so
now we're going to fix some X in bold x
um we're going to define three planes
first piece of X is the plane is the D
minus one hyper plane which is
perpendicular to X and passes through X
P minus X is the D minus one hyper plane
which is perpendicular to X and passes
through minus x + PX 0 is the plane
perpendicular to X passing through the
origin um and we know that because PX
intersects the you clean ball of radius
robar only get x it also intersects
bowled a only at x so here's an
illustration in the case when d is equal
to 2 so these hyper planes are just
lines and these these two on the ends
intersect bold i only at a single point
yeah so now we fix a set Q which is
contained in PX 0 um and so that Q is a
d-minus one-dimensional set and we're
gonna require that Q is come back
compact convex and symmetric about 0 and
that Q contains the the intersection of
the Euclidean ball of radius R 0 bar
with PX 0 okay and for a given a seller
greater than one we like script Q sub s
bv the s stretching of Q by which we
mean um the Sun obtained from the
following operation so say we start with
Q which is here depicted as a red line
because we're in dimension to so Q has
has dimension one arm then we stretch it
by s in the direction which is
perpendicular to X um and then we
stretch it by one in the direction which
is parallel to x and so this gives us a
d-dimensional sat which is kind of
a cylindrical shape okay which is kind
of tilted in the direction parallel to
tax and we call that set script cues of
us so it's it's easy to see that Q s the
script q s is compact convex and
symmetric about 0 so we can define a
norm new s whose closed unit ball is Q s
and this this norm us is the one that
I'm going to prove the statement of the
theorem for so in particular for each so
okay so for any X 1 has such an arm yes
okay right this is a norm for any choice
of Acts okay na yes in any ass in an EQ
look you guys haven't any come here
right this is a family of narrow so
actually you can you can get a family of
functions which are not norms also which
are defined in kind of a similar way but
I'm not going to talk about this in the
talk but it is it is in the paper you
will you get a slightly wider class of
choices of half than what i described
here oh so I'm the kind of more
quantitative version of theorem 2 is the
following for each alpha bigger than one
there exists an s greater than 1 which
depends on Alpha such that if we take F
of Z to be new s of Z to the Alpha for
this choice of s then and we light
script k be the Union overall our of the
of the intersection of Q s with the with
the with the plane PX so the such k is
contained in some new clean cone of
opening angle less than pi then it's
emotionally the case that either aight
how infinite either emotionally either
all but finitely many points of eight
how infinity are contained in k all but
finite on any purges of a talent finity
are contained in minus k okay so this is
this is kind of noteworthy for a couple
of reasons first we get a we do get an
explicit description of the cone
and you can see kind of see what it
looks like um from the from the norm
from the SEC script qsr it's just the
cone who's boundary lines pass through
the boundary of the intersection with Q
s of the plain piece of X and
furthermore there's the 80 infinity has
to go off to infinity in one of these
two directions it doesn't go it never
can go off to infinity in one of these
directions so the support of the the
center line of the cone is not the
entire set of possible lines it's only
it has to be in this direction or this
direction oh wait is there this
direction dependent on X right if you
but there could have been an X one of
those other places right the norm
depends on X so we're focusing in acts
and we define a norm all right it's this
norm for the enhancer only one is what
is right yes so um so the the reason why
we choose this particular norm is that
with this with this particular choice of
norm we can get sharp estimates for the
metric D even without knowing anything
at all about the set bowl a ok so in
particular we can show that for each
cube bigger than one the D distance from
the boundary of script qs2 little Q
times boundary of script q s is equal to
one minus Q to the 1 minus alpha over
alpha minus 1 and furthermore if we have
a point Z in the boundary of Q s and a
point W in Q times the boundary of Q s
which lie at minimal distance from each
other then it has to be the case that z
is 1 in one of those two planes PX or p
minus X and w is just equal to Z
translated by plus or minus Q minus 1 X
so here's a picture um if we've got a
point so that the inner box is Q s the
outer box is QQ s and um if we have a
point Z in the founder of the inner box
and appoint w in the boundary of the
outer box then Z has to be on one of
these two
lines by which are the intersections
with the planes p x and p minus x + + w
has to be the translation of Z in the
direction parallel to two acts under the
the red line and so I'm particular w has
to be on on one of the two red lines if
yes it's Z and W at minimal distance
from each other okay so the reason why
this is important is that if we we take
this picture and rescale everything by 1
over Q so that the the outer box is
mapped to the to the inner box then the
red lines will be mapped to proper
subsets of the green lines so if you
have a point on the boundary of Q script
us which lies at minimal distance from
from script us then and then you rescale
by Q inverse you end up with a point in
a boundary of script QSR which lies at
minimal distance from the boundary of Q
script us um so this is this is crucial
for our our proof of the theorem which
is going to be buying an induction
argument so to set up this this
induction argument we define for each
positive integer n we like tau n be the
smallest t for which 80 is not contained
in a script q s so for the first theorem
we use d balls the roof of the next
theorem we use Euclidean balls and proof
of this theorem we're using new sebass
balls okay and um so emotionally there's
a unique vertex u sub n um of a tau n
which is not in n script us um and we
let GN be the event that you n over the
US norm of U n is contained in one of
these two planes PX or P minus X so in
other words a tau n exits the the set n
script q s in at a point which is close
to one of these two green lines
um so now we have an n tilde which is a
little bit bigger than n and the event
GN occurs on then accept an event of
probability decaying faster than any
power of n and in fact this is
conditional probability given everything
up to time tau n um we have that talent
tilde minus tau n is at most n to the 1
minus alpha minus n tilde to the 1 minus
alpha over alpha minus 1 plus a small
error this just comes from the D
approximation lemma um because we know
the distance from the from the set
ending script us to the set until Louis
group us ok um so by a a second
application of the D approximation lemma
we get that each point which lies at d
distance bigger than this quantity from
nqs is not contained in a towel n tilde
um but we know from our deterministic
estimates for d that anything which is
not in in one of these two red lines
lies at bigger d distance from the site
nqs than the stuff that is it that is in
the red lines so that means that nothing
which is which is further than a little
bit a little error away from these two
red lines um is going to be contained in
a towel n tilde provided the event GN
occurs so this means that if GN occurs
then with high probability also G n
tilde occurs because we have to we have
to hit the next the boundary of the next
ball also at a point which is in one of
these were these two good faces ok um
this means that if GN 0 occurs for some
large n0 then with high probability also
GN occurs for all n a little bit bigger
than n 0 um so by by summing over an
appropriate sequence of ends tending to
infinity we get that with high
probability if GM 0 occurs then for each
n greater than or equal to 1 plus
epsilon n 0 we have that the time to
infinity minus tau n is at most n to the
1
is alpha over alpha minus 10 k plus a
plus the small error um now if we make s
big enough and q0 big enough depending
on alpha then we have for each queue
between q0 and to q0 we have that the
the distance of olive from the the part
of qn x the boundary of q s which is not
contained in one of the two planes to n
times boundary of Q s is bigger than
bigger than this plus Delta n to the 1
minus alpha for some fixed delta which
doesn't depend on n um so by the by the
d estimates by the d approximation lemma
we find that any point which is not any
point in in this part of the boundary of
qn script q s is never hit by eight how
infinity so that means so here's a
picture here's qn script us your Zen
script us so if GN 0 occurs for some for
some n 0 which is you know maybe much
less than n um then with with high
probability nothing and one of these two
red lines is ever going to be hit by by
eight how infinity um so this means that
if G NGO workers for some large and 0
and then in fact a towel infinity is
going to be contained in the union of
the SATs script k + minus ripped k
because this is this holds for every for
every large enough n all right so now
there's there's two pieces left first
one we need is to show that in fact gian
0 occurs with high probability when and
0 is large since the kind of a similar
situation to what we dealt with in the
alpha less than one proof but here in
order to deal with us we need to make
asks a little bit larger and in fact we
can arrange that by by making us big
enough we can arrange that in fact every
point in the boundary of Q s
is closer in the in the metric D 2 to
the part of Q star times the boundary of
Q s which it which is contained in the
two planes than it is to the part which
is not contained in the two planes so
then the the approximation lemma implies
that the GN z Ro was going to occur with
high probability even if GN 0 ver q star
do not occur so here's the here's the
picture um so if s is very big then
everything in the boundary of the inner
box is closer to the to the green part
of the outer box than it is to the blue
part of the outer box okay so that means
that no matter where we hit the the
inner box it's going to hold with high
probability that we hit the outer box
for the first time on one of the green
lines which means that g + 0 occurs um
so this shows that almost surely all but
finitely many vertices of a cow infinity
are contained in the union of script k
and- script k um but there is still one
problem left because it's possible that
or I guess we can we could worry that
maybe um al but finally ended vertices
of 80 infinity are contained in the
union of these two sets but there's
infinitely many in each so it's not
actually contained in one of the two
shots um so we still have to rule this
rule out this possibility that it goes
to infinity at the same time in both
directions okay so let's like EB the
event that that this happens um and
let's let Sigma plus respectively Sigma
minus be the first time that a
t-intersection script came actually a
t-intersection asst script k arm is
infinite that so on the on the event E
it's going to hold that Sigma plus is
equal to Sigma minus is equal to tau
infinity as it gets to infinity at the
at the same time in both directions and
furthermore for some large n it holds
that 80 infinity minus a tau n is um is
contained in the union of K and minus K
right because all what finally many
vertices
are contained in nine Union so let's let
en be the fact that this is the case for
for a given fixed integer n so if he
occurs with positive probability then
for some deterministic and the event yet
occurs with positive probability but on
the other hand the random variables
Sigma plus and Sigma minus are
conditionally independent even of kaolin
in the event en viously depend on
distinct collections of independent
exponential random variables um and so
if Sigma plus is equal to Sigma minus is
equal to tau infinity on the event en on
the conditional law of tau infinity
given F tau n has to have an atom with
positive probability um and it turns out
that this is this cannot possibly be the
case for for any stopping time tau um by
kind of a straightforward probabilistic
argument which I'm going to to skip for
the sake of time I can explain it
afterwards if people are interested um
and then I'm just going to end by by
mentioning some open problems which are
related to this model um so first um we
show that for each alpha bigger than one
there's some norm new for which we have
this this cone containment result but it
remains an open problem to classify for
a given F which choice for a given alpha
what choices of of F are such that a cow
infinity is emotionally contained in a
cone of opening angle less than PI so in
particular if we're given a large enough
or forgiving a fixed norm then does it
hold for large enough alpha that we have
the containment result with that that
particular choice of norm um and it's
possible you can do a little bit better
than than our result without knowing
anything about the with it without
knowing any more information about the
set bold a but I would expect that a
full solution of this problem would
require some more information about the
standard fpp limiting shape bold a um so
here's another interesting question is
it true that for any choice of F either
a Tau infinity is emotionally Canadian a
cone of opening angle less than PI or
almost surely
infinity contains I'll but finally many
vertices of ZD so we know that that both
cases are possible for some for some
choices of F or desire choices of F for
which neither of these are true for
example maybe there's some choices of F
for which 8 how infinity has a spiral
shape or a cow infinity is contained in
a cone with positive probability but not
emotionally so you didn't get to rule
out this kind of thing to answer this
problem um then in the case where alpha
is equal to 1 do we get do we ever get a
deterministic limit shape in this case
and if not do we ever get a random limit
shape um and then also what happens if
we take choice we take edge weights
which are not positively homogeneous for
example we could consider periodic edge
weights or edge weights which are large
in some spiral shaped region but small
in the complement of that region so we
try to like force their force the limit
shape to actually have a a spiral shape
or something like that then there are
many more open problems a total of
fifteen listed in the paper which will
be posted to the archive soon hopefully
so here's the list of our references and
that's
questions comments yes so you mentioned
and not much is known about this set
full day but I'm wondering if there any
conjectures about what it should be is
um so I don't think there's a conjecture
about exactly what bowl they should be
um one significant conjecture is that
bull day is strictly convex meaning that
doesn't have any corners or flat faces
um and yeah this is this is still not
known if you could prove that it would
be a very significant result about first
passage percolation does it make sense
to talk about what happens after time to
insanity um it does um it eventually
everything in ZD will be hit rice
because you know everything is connected
but to the origin by some path with when
I use a time right for that immediately
selfish yeah it's so cold conventional
cavity is whatever or any site will
eventually hit brother no time delivery
um I guess I think in the can in the
case when alpha is they're gonna wanna
can hit every doing environment right
you can't give it up your rebound right
I think it yeah i think if alpha is
bigger than one that almost surely
everything is hit in finite time you
could imagine you know at each time
greater than tau infinity there's a
array to infinity in certain directions
within your set but not the other
directions and that so you have a set of
directions which you can reach infinity
and this time expanding and eventually
it becomes all merchants I think maybe
that maybe you could never picture like
that um but the one kind of disadvantage
of considering what happens after talent
is ethan's that it has no relation to
the Eaton model anymore right so they're
about the model 1 &amp;amp; 2 billion
yeah fine it's so yeah it's their show
some interesting questions about what
happened after time talented not sure
why I say it's not very in battle cuz
they even model you're adding one at
your each step all right and so after
time Omega Omega plus maybe you could
come by that time so it's gonna be
pleased everything is filled by I don't
make sure there's no that don't hold up
signs no indeed mall itself indicates
where alpha is bigger than one hour not
even mobile itself oh yeah but this no
they have time relating comes to time
after time for unity hear it different
from time of dro meagan nothing left
after Omega a I was in the future we're
talking about this one right oh yeah so
just a basic thing about alpha equals
one and so I think my confusion was just
in case alpha equals 1 tau infinity is
infinity thoroughness and ate our
affinity is all TV yes yeah very weird
it'd be interesting and in the same vein
of this continuing beyond and finished
Eminem people just understand some basic
things like can there be a second
explosion time thing I thought thanks
but it out likely right anyone when you
explode an explosion time your time T
such that such that
infinitely many 14 but not the other gun
and all those 49ers I think after time
Cal identity every time as an explosion
time in that sense because you're always
going to be adding infinitely many
vertices in every increment of time
effort to find an explosion time as a
ray to the array from the origin to
infinity gets accessible that you know
it is not what have you are so it's
really not in the closure of what was I
give so before I mean so if you're you
start out at a time tau infinity you
have this this cone shape here right
right and then so does this like a ray
like that count how far away from the
home to happen d it has to be not in the
closure of which was accessible in
previous times mmm okay maybe maybe like
something interesting the b-side here
any other questions again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>