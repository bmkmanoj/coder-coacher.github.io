<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MSR-INRIA Workshop On Computer Vision and Machine Learning | Coder Coacher - Coaching Coders</title><meta content="MSR-INRIA Workshop On Computer Vision and Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MSR-INRIA Workshop On Computer Vision and Machine Learning</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Pn5kOMAEjeU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay we'd like to do some early vision
problems you know you know whatever the
vision problems are I want to take the
noisy image and get the clean image I
want to take the downsampled image and
get the up sampled image you know if you
can't see at the back that's what I want
to do I want you know I want to take an
image which has some maybe it's got some
missing color channels maybe it's got
some missing pixels maybe it's got some
noisy pixels and I'd like to recover
some representation of the image which
it seems to me obvious and I hope to
persuade you should be resolution
independent so it should be effectively
at infinite resolution that explains how
we got the samples this is not my baby
okay so normally you're used to this
story you have a choice of two ways to
do it you can write down some discrete
energy which has image values here I so
by and you're trying to find some you
values ieave some representations of
some latent image which matched the
image and maybe where the difference
between adjacent pairs is small and i
don't care how much you generalize that
i'll do that in a minute or you might
try to write down some more
mathematically sexy thing but of course
you can't do that right because you
don't have access to this thing this
continuous domain image this is a myth
okay so you don't have that so don't do
that let's carry on over here so we're
in the discrete phase right we can do
various things we can improve our
regular Iser to all sorts of fancy
things we can make our latent image to
use at some different resolution to the
input image so we can put pixel is maybe
some linear combination of latent image
pixels maybe we can do that nonlinear
are they ok so those are all fine you're
told that many many times ok you're told
some things like ooh discrete is bad
because you've got discretization
artifacts and education artifacts and
that's all bad and continuous is good
because you know it's not bad ok why is
it good this prior as written here is
rotationally invariant if you write it
in any
many of the known ways like this it's
not rotationally invariant and you have
to hack it to try to make it
rotationally invariant so in some sense
this story is true so this fire are
super rotationally invariant should be
great except we also know that in
practice the stuff you can do with total
variation and friends gives you
denoising results which are not as good
as the stuff you can do with patch price
things that look a little blocks of
pixels so so what's that all about and
finally anyway in all the cases that we
have properly explored and it's very
very difficult to do this for us you
take this thing you push it through all
of the ground you do some variation you
get some PDE then in one sentence in the
paper you say we discretize the PDE and
solve and for most of the
discretizations that we have examined we
can work it back to a discrete energy of
exactly of some clearly well-defined
form okay so having told you there was
two ways to do it I'm now saying there's
only one way to do it you always end up
down here somewhere somewhere like this
okay but all that other stuff is still
true okay so what do you really have
right what you really have is a list of
scalar real-valued samples at a bunch of
locations these pixels got three samples
right because their color so they have
the same location X I and these pixels
down here we only got one sample so this
image is this number of samples and
there's other stuff the way you've got
those discrete samples as you view the
world through a point spread function
and for these pictures you've you
through some spectral filter and maybe
you know what they are and maybe you
don't depends what camera you have okay
let's just stick with gray scale even
though it really doesn't simplify things
but let's simplify things by sticking to
grayscale and let's pretend the only
thing we don't know is the point spread
function okay so I want to know how I
got this pixel here image I at location
X I sorry intensity I at location X I
and I got that pixel there by looking at
the world through some point spread
function ok and I'm going to call the
put and now I'm going to make a big
simplification i'm going to say the
world is a flat world sort of just
outside the camera ok so i'm going to
look at the the optical reyes gibson
call
but some image just in front of the
camera continuous defined on the
continuous domain so there's scalar
intensity you as a function of 2d
location X and I'm going to say that's
what we want to recover okay and then
the point spread function for pixel I
I'm just going to call Kappa I which is
a function again to find on the
continuous domain X and sometimes if
you've been taught sampling theory and
engineering you'll think things like you
should do a convolution with a point
spread function kappa that's the same
everywhere but of course in most cameras
is not the same anywhere and anyway it's
not going to make any simplification to
treat it as a convolution right so each
pixel comes now with its location and in
fact we don't even need the location we
just have point spread function which
may or may not be known okay so this
tells us the the equation for how I got
the number of photons into bin I was Ike
involved or multiplied the world here
with a point spread function kappa and i
added up and then i added some noise
Etta so now it's very obvious how you
get the the world back given the
individual samples ok we still have a
functional and it's always sexy to say
functional so that's great and our
functional says minimize some difference
that's what these funny brackets mean
between your sample image I and what you
get if you convolve if you view the
world through the point spread function
Kappa I and of course it's an under
constraint problem so you might add some
regular Iser and again we could do some
funny stuff with the gradient because
we're still completely continuous it's a
continuous function you that we're
solving for R you can generalize this in
a number of obvious ways that's that's
straightforward yeah so my first claim
is that I've really tried hard I don't
think anybody has ever written this down
before with the explicit Kappa I it
exists lots of times with delta function
cap i but that's that's pointless
because when you have a delta function
you're not breaking the link between the
infinite resolution representation and
the very discreet finite resolution
image so you have to have the coppers in
their claim to is that this is the
correct thing to write down let's see if
that is in any way supportable five
minutes before quadrillion needs to go
okay so first time is it sensible at all
to talk about the world being continuous
is that you know that's obviously silly
at an atomic level it's obviously silly
if you're dealing with bits of hair or
feels obviously silly if you're dealing
with bits of hair is it at all sensible
okay well let's look if it's sensible so
here is a picture of a hat in front of a
mirror and this is the sharpest edge in
this image now I suggest that the hatch
is probably a little bit furry I don't
know I've never seen it probably a
little furry hat but when represented in
this image if we take samples from this
slice i'm leaving this down here just
because i hate it when people delete
equations that i haven't had a chance to
read so you can read this for the next
few slides if you like okay so there's
the hat and these red dots here are the
intensity samples across the half if I
were fitting a prior which encouraged
piecewise smooth I might fit a world
model U of X which is like this black
curve right a step age but it's not a
step edge right because clearly the Hat
takes two or three pixels to transition
from its bright to its dark because
there is some point spread function
viewing it so that's a bad prior if you
want to reconstruct that image however
if I say that the world is the step edge
and I convolve it with a point spread
function which looks like this then I
get this blue curve which indeed does
match lennar's hat so a better prior for
lenarz hat is not piecewise constant
world a piecewise step edge or whatever
you want to think of it but a piecewise
constant world convolved with a point
spread function even when you're not
doing up sampling and when you're not
doing anything if you just want to
interpret the image we can do that a
little more carefully right so here some
signal I've drawn from some types of
signals which is piecewise smooth to fit
it in the image they're mostly flat but
that doesn't matter I take the image I
convolve it with some point spread
function now I've got these samples of
the image and I draw some add some noise
to these samples to simulate what was
happening now I want to denoise this
image so my goal is to take this image
denoising and give that okay well the
obvious thing I can do is use some total
variation or some smoothness fire on the
reconstruction that's clearly not going
to work because it's going to give me
this piecewise steady r you can
struction which we know is wrong I could
try to learn the fields of experts fryer
right the problem is that the stuff the
interesting stuff that's happening is
not happening at adjacent pixels it's
happening over big patches of pixels
right three or four five in the case of
lemons hat so I could learn myself a
five wide fields of expert model still
not possible so I learned myself a nine
wide PH fields of expert marble and now
I've got a nice patch prior that
encapsulates the kind of stuff that was
going wrong or I could simply minimize
an energy like the one I told you and
I'll get the same reconstruction so I
don't need the complicated fields of
experts I simply do TV plus fine okay so
there's my energy how am I going to
minimize it and I will jump way to the
end no I want okay no I've got a minute
I'm simply going to write to my
continuous function as a product of some
basis functions right that's the only
thing we know how to do okay we knew in
order to other stuff but let's just do
that I'm going to do some flipping of
some integrals and I'm going to end up
with the basis functions looked at
through the point spread functions and
I'm just going to end up with some
system much like the ones we often know
and love okay when I choose basis
functions i can choose ones like little
boxes so my hike map is parameterizing
the height of these little boxes I could
choose little triangles fixed onto the
image like showing the moon at all i
could do by linear or i can maybe do
some wavelet basis where I just means
some basis functions or maybe I could
take a wavelet basis and outer product
it with some masking by the triangle so
now I can build quite complicated images
this is the one we do still no good
unless I'm going to move the vertices of
the triangles so I've got my image 3 by
3 image here triangle grid underneath it
and all I need to be able to do is
intersect the point spread function this
50p with a triangle compute some
derivative it's not that hard
and then you know hit optimize and now
I'm going to slowly this is sped up very
much but it's still very slow I'm going
to optimize my triangle mesh to match
the image is it a good idea well I don't
know here's an up something paper from
Fatah little so they can opt ample this
much we can have some pool this much
we've got a little bump here because
their optimizer still doesn't work very
well if UD noise we are worse than BM 3d
definitely worse than the levin and
nadler you know a hundred cpu RS on 100
machines or whatever it is but we should
really be comparing to total variation
because that's the kind of this is a
total variation prior which simply is
rotationally invariant which really is
rotationally invariant so rotationally
invariant TV much much much better than
TV around maybe the same as or maybe
similar PS and our 2pm 3d so you know
messy patchy thing incredibly simple
prior done right yeah you can do those
ok I'm basically done why did I do this
I do this because I want to do flow
properly and why do I want to do flow
properly because if I have a red square
moving from a green background to a blue
background brightness brightness
constancy is nonsense this yellow has to
match this purple ok you have to
represent at sub-pixel what's happening
and then deal with the fact that pixels
are massive and their massive therefore
they must be viewed through their point
spread functions thank you are there any
questions
Causton I mean the last one you can also
do with welcome right I'm not sure it
does it seems to me yes I could probably
think yeah we'd have to drift it and
yeah it just seems much easier to write
down what's actually happening yeah well
easier to write down fit on the
optimizations I mean you a set of all
the field of expertise sure it's much
more complex but I mean your
optimization might be yeah yeah and
we're not beating transfer edges let me
let me be clear if you make your patches
bigger than 32 by 32 I don't see how any
simple dead leaves like prior has any
chance so if you make your patches 512
by 512 then clearly patch priors are
going to win in all circumstances it's
just that no one is ever going to get
the training data for them so there are
certainly we hope simplifications of
this different ways of looking at this
you know we've picked a pretty ugly
brute force up representation which
yields a hard optimization problem you
know we've done everything sort of us as
agriculturally as possible so I hope
that there will be better some other
people will think of better ways to do
this oh sorry because I really want
sharp boundaries so with all the other
basis functions I have a mobile boundary
so when I sorry
yeah so you know here's my basis
functions and whether they're sharp or
smooth it doesn't it doesn't really
matter that's what they are to get sharp
edges in the image which I believe I
need then I need to be able to move
triangle boundaries so I need a simple
representation with sharp edges times
some richer representation I mean we
don't use anything even as rich as this
we use constant X ramp and why ramp as
our basis functions but I think
positioning the boundaries is what it's
all about even in this you know the no
sort of obvious sharp but I mean yes
there are obvious boundaries and the
peppers but we're not we're not finding
them recently just writing down a better
prior effectively who push me then so
I'll see anything yes sorry absolutely
constant known for these cases or you
know set as a tuning parameter I have
some examples not on this deck where we
can solve for parameters of points for
function you can do some stuff simply
linear combination of basis point spread
functions a bunch of other stuff most
importantly the point spread function is
not a Gaussian and there's nothing wrong
with that because real point spread
functions aren't gaussians I learned
from Karsten that they're most likely to
look like that 50p you can change the
point spread function right and so most
of the other denying algorithms not take
into account the point spread function
explicitly and you would think that you
might not need to just ready noising to
reconstruct the same pixels of the same
resolution yeah
your point of view and say they dissolve
the point spread function problem and
you have this elated representation of
the super solid resolution image right
then the question is how would this
solution is really look like okay so let
me give you a counter thought experiment
we're going to learn a patch par prior
over five by five okay you already know
the answer right take every patch ever
shot ever to be shot okay it's got to be
rotationally invariant it's going to be
translationally invariant mostly it's
going to be constant except where it's
not so I think the patch prior from five
by five is going to be dead leaves right
and it's going to be dead leaves with
objects not very much smaller than the
pixel right so really what what can it
turn out to be except something as
simple as you know total variation on on
boundaries between two smooth ish
regions agreed agreed that was five by
five it's not eight piecewise and ramp
but yes so I used to think that to deal
with textures we should add basis
functions like sine X sine 2x and 3x and
then they would pop up as
representations of texture on some
regions like suppose this is a real you
know this is actually the image then and
that may be true so maybe that I change
the basis functions to include some more
natural stuff or maybe / camera or I
mean something else i'm throwing away is
the fact that when you buy a camera if
it's not sold by the megapixel it's
probable that the anti-aliasing filter
and the optics and the pixel grid are
all sort of aligned in size so somehow a
pixel is a is a is a is not an arbitrary
size of 555 pixels might not even be an
arbitrary it's not scale invariant
that's what I'm saying so that's I'm
throwing that away and maybe I shouldn't
more questions and that concludes the
workshop</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>