<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probabilistic Programs as Spreadsheet Queries | Coder Coacher - Coaching Coders</title><meta content="Probabilistic Programs as Spreadsheet Queries - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Probabilistic Programs as Spreadsheet Queries</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2wzre05DBjo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hello everyone my name is marcin and I'm
a second year PhD student at the
University of Edinburgh and today I'm
going to talk about it about the new
additions to the probabilistic
programming language called tabular
developed here at Microsoft Research
which have been described in a recent
paper submitted accepted that the
Europeans imposing on programming this
work is partly based on my previous
internship at Microsoft Research from
nearly two years ago so because not
everyone here might be familiar with
tabular let me start with a quick recap
of of the language so tabular is a
schema driven probabilistic programming
language so it differs from other
similar systems in that every user
doesn't actually have to write a a
probabilistic program per se but rather
just annotate a database schema with
probabilistic expression which explain
which express how we how we believe the
data was generated so it the language is
a embedded in Excel so that both the
databases the database schemas with the
annotations are RF written in Excel
spreadsheets and also the inference
results are also are also displayed in
Excel but we could propose process them
and to perform some visualizations and
so on so improbably tabular programs
compiled two of two factor graph so that
we could perform inference on them using
the internet probabilistic inference
engine which has various various
inference algorithm such as
expectations' propagation so just to
give you an example of how it works here
is the tablets tabular code for the
trueskill model which is m which is a
probabilistic model for ranking players
in unlike online games it's used for
example by microsoft in in its xbox
games so in this model we have a schema
with two tables we the table of players
by default only has we player names and
this table of mattress has stores the
names of the two players which took part
in a given much as well as as well as
the outcome of the match what is which
player actually want and we went from
this data we want to infer V
with kills of the players so in order to
do that we we added an extra light and
column to the players table a column
which named skill and we assume that
it's prior is a Gaussian centered at 25
°c and we also also state that we win
one variable which which says whether
player one player on win won the game
was generated from from invest
expression which compares the
performances of the players on a given
day which are dependent on on the skills
and so as you can see here you can not
only not only infer the skills of the
players and the values of any
enlightened Collins but we can also also
predict the values for for unobserved
matches so now let me move on to the to
the new features of the language with
which are presented or in the paper so
first of all this paper describes
user-defined functions which actually
which abstract away some of the some of
the commonly used patterns in
probabilistic modeling for example
conjugate models which are will show in
a moment another another edition is is
the presence of user-defined queries
which can be used for for computing
deterministic data from inference
results this can be imperfect in
performing decision theory for instance
on the influence results also also also
show an example in a moment and the
final contribution is the is a dependent
type system with with array bounds with
RA sizes and integer bands which or it
might depend on previous columns
together with F with a lattice of levels
which separate the deterministic V
probabilistic and the query level
columns so let's let's start with with
with queries and Tulu straight however
how they work let's consider a true
school example again but this time we
want to decide whether it whether it's
worth placing a bet on one of the player
so participating in a given match given
given the odds for this for this player
but is the amount of money we get for
every pound we move out on that player
so so if in order to determine whether
about this but we worked
I think or not at all but we need to
know the probability of player 11
winning v match which can be can be
inferred for inferred from from previous
mulch data and we also need to know v.v
also fattest v amount of money will get
every player wins which which was also
which is known because it's an input so
in this example here if play if the odds
for player 1 winning are equal to 4 then
the expected utility which of placing a
bet what is the probability of the
player winning x times V also minus 1
because we normalize it by v minus bet
on the paper on the only player of x
times the probability of player 1 losing
the expected utility is positive in this
case which means that that is worth
placing even though we player is
actually unlikely to win the match
because the probability of winning is
only about thirty percent in VA in the
second example vote because we also are
only took only equal to to the expected
utility becomes negative and so wave and
so the V bet is not it's not worth
placing which means that we choose not
to do it so now let's move on to Toby
functions and to illustrate however how
they work let's consider be the data set
containing the data was the eruptions of
the Old Faithful geyser in VA lost on
national park this data this data set
contains which constrains the durations
of the eruptions at the time we have to
wait for them and as you can see from
this graph it ever took this Gator
Castle two kinds of eruptions some of
them are shorter but we also need to add
shorter for them and others others are
longer but a cure less frequently and we
want to let we want to a plaster visit
is eruptions into these two into these
two groups and also and also infer the
distributions of waiting times entered
and and durations 444 eruptions in both
groups so this can be done by writing
and at
a tabular program with with with
function applications which can be
combined combined with with indexing
which was explained in a previous paper
oh and now let me show you how how how
functions actually work so in this
example let's focus on just the eruption
duration for the moment and forget about
about about waiting time because it
works in the same way basically so here
you have a function which represents the
conjugate Gaussian model and then if we
if we assume that that the eruption
duration was drawn from this conjugate
Gaussian model then we can we can
represent it in a program by a single
line which is a call to vist to this
functions to this function and when we
call this function with without any any
parameters and the default V than the
default hyper parameters which are women
and precision ins and precision of the
avi of the Gaussian prior of office
quantitative are substituted in for with
variables and and then we we chopped out
the hyper parameters from the table and
substitute the and substitute the AV
output column width would be the body of
the function so it basically looks like
it looks like this in this in this way
we can expand it we can expand the the
function calls so and and reduce egg an
extended program written in the extended
language until 21 in court tabular which
which directly corresponds to a factor
graph I don't know if we can we can run
inference so another assault with as I
mentioned before a function function
calls it can be combined with with
indexing which was which was the index
before which was mentioned before and
let me show you let me show you how it
works out unless simple example so in
the so in this case if we actually want
to sir just just wanted to mention that
the investing simplified example we
actually we were not doing an indexing
because we
want to label the points we just wanted
to infer v.v distributions but was a
simplified example just adjustment to
show how function applications work and
if you actually want to label the data
then we need to combine this fan fest
cultivate conjugate Gaussian function
model with with indexing so what this
guy does is essentially it just creates
two copies of all these topic of all
these static columns in this function so
we have two mins and two precision to
accept one for it one for each cluster
and then the final outcome return to it
depends on this on this additional index
variable which is which is drawn from
another distribution so so in this case
we can have separate parameters for
visas for VC into clusters of variables
and and this is good and to never
country another contribution which was
was making this paper was the presence
of a of a dependent type system together
with us with a simple lattice of levels
which I will talk about shortly but for
now let's concentrate on V on the
dependent types so as I mentioned before
we can now have we can now have a race
of specified length I've specified
length which might depend on previous
columns as well of bandage off button as
well as bandage integers which are
always known to be always smaller than a
bonus certain quantity so as an example
consider we see this prolific conjugate
discrete model shown on this slide this
model has app has a parameter has two
inputs one of them is one of them is
it's the number of the bank of the
integer which is meant to be drawn from
this distribution and we say which is
also besides of the parameter vector
from which we were drawing an index and
the envy envy and TV ever r is the
variable representing v representing the
kinds of v data that is how much
confidence will have we have in in the
results so if
so if so if this so as you know this see
if notice with this we know both by
assigning a dependent activist to this
column we know that the variable drawn
from this distribution who always will
always be an array of n reals and the
output drawn from the discrete
distribution having this V as a
parameter will be an integer up to up to
n so if so in this is so because we
treated types object statically a user
user scan it can discover of some basic
errors without actually having to run
length the influence and and in that
case it it saves saves time on debugging
and allows for some common mistakes we
spotted respected spotted earlier in the
development process so moving going to
v2v lattice of levels as mentioned
before if this new version of tabular
introduces the query operator which
allows for which allows for the in
survey in fair operator which allows for
for deterministic arrival pseudo
deterministic quantities to be to be
deduced from from from distributions of
random variables so in so now we have
three types of columns who have
deterministic columns containing input
data or transformed into data you have
random colon suit which which which
which are assigned probabilistic
distributions and we have query level
columns which which contains post
processed data which depends on the on
the on the results of inference so we
say so we have a lattice of levels which
organizes it organizes a schema into
into this into these three levels and in
this lattice in we can use a
deterministic variable whenever a random
quantity is expected or a quick query
quantity but not the other way around
and we cannot make random and query
level variables and the only way for up
to pass information from from random
distributions to query level columns is
via this in fair in this example have a
this is an example of an of an error in
which we want we want to decide whether
to place a bet as in the previous
examples like this time
this time is drawing drawing the
decision randomly from a Bernoulli
variable but because of this piece that
determine it is like it's a random
variable and place that is a is a query
level variable we can't this doesn't
really work because this has to be
digitally to be determined by inference
and this has to be determined by it but
sorry I want to say that if this this
variable is depends on influence and
this the distribution of this should be
should be should be actually computed by
inference so so we can't have this kind
of dependency and hence the technical
frosted narrow so that just to show me
that the tabular can actually be
successfully in practice we have some
early adopters of the of the of the
language who used it for real life
modeling for you look at this example
shows a model a model used by Dylan
Hutchinson hackathon and Matthew snitch
in there in verse study of inverse study
concerning the recognition of of wild
and and artificially propagated plants
this visit this model written here in
tabular if it can be can be used to to
deduce whether were something suspicious
about about the plant for example
whether it whether it if it seems to be
to be to be collected in the wild even
for which it was declared to be to be
propagated at artificially as you can
see here with the results which are
which are the results of inference seem
to be fairly accurate this data was
obtained by by testing the classifier
using 55 fault cross-validation against
against against labels assigned by
experts so so what's actually in the
English new paper in the paper we have a
detailed syntax of the extended language
with fire function and queries we have
very you have a reduction system which
tree which reduces it tabular queries
into court tabular queries which have
straightforward factor graph semantics
we have dependent a dependent type
system and as I mentioned before we have
never fear based denotational semantics
semantics and an example application
based on Basin desert analysis and they
keep you are a theoretical results from
the papers are firstly better world
types the tabular schema reduces to a
well typed quarter bueller schema with
the same type and secondly that if a
core schema is well type and at the
input data rates confirms to it then it
went the output databases returned by V
semantics will also confirm to the into
the schema and the in future want to
concentrate on model criticism and
determining however how well compiled
models confirm to the data you want to
we want to compare the performance on of
tabular against systems of aimed at see
similar type target user group and we
want to conduct some usability studies
to determine whether whether the whether
if the new features of the driver
language are actually are actually
helpful and what else we can do to make
the to make the system more use a loop
and we're always looking for for new
above external and internal adopters of
tabular to receive any feedback we might
get thank you very much for your
attention so any questions so I have one
as an user if if I want to define a new
kind of distribution for example not
Gaussian but student e canna can I do so
by specifying the density or I don't
think I don't think his specifying
custom distributions is supported in the
current version of tabular however I
believe believe that the range of
distributions which are available at by
default this is fairly broad okay thanks
any more questions yeah if you should
see the Prince don't have the exact
results but as far as i remember it was
it was a comparable to be to the
efficiency of the infrared net system
itself and the cold is also much more
concise so versa there is a little bit
of performance deficit in comparison
with the internet but but it's not
really that significant it's less than V
even than the amount of conciseness we
get by by using tabular
ok Thank You Marcy</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>