<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Rationale Design of new Drugs Using Azure | Coder Coacher - Coaching Coders</title><meta content="Rationale Design of new Drugs Using Azure - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Rationale Design of new Drugs Using Azure</b></h2><h5 class="post__date">2016-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4XYlVCNPVqI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay we'll go ahead and get started
first of all thank you for coming for
all of you here and for all of you in
the television audience today we have ed
Addison from terror discoveries coming
to talk to us about using computers to
design drugs and he's been doing a lot
of work with Microsoft with Azure and
they have taken their work that they did
in the universities and they're now
making a company and the movement
forward has been 25 years working in
this industry terror discoveries as a
serial entrepreneur it sounds like and
we've worked with them for probably
three years I think since I first met
you here at Microsoft roughly three
years ago that you started doing
something that's quite close maybe 22
years and change okay so my time goes
way too slow for me apparently because
I'm having so much fun but it's been a
very interesting talking with them and
several times that I've met with it
before and we're gonna have a chance for
you guys to hear what I say about
rational design okay thank you very much
I'm going to talk to you today about
terror discoveries we're a small company
of 15 people some full-time some
part-time some contractors some
employees typical startup quasi virtual
we have a business incubator where we're
located on Davis Drive and in in
Research Triangle Park in North Carolina
before describing what we're doing let
me just take a minute or two to to the
state where we came from Terra
discoveries was a venture that wasn't
quite planned with the business plan it
evolved a little bit a colleague of mine
by the name of Lawrence music and i
founded terror discoveries we've been
working together for quite a number of
years through various ventures he is a
chemist and an intellectual property
attorney and I'm an engineer turned
entrepreneur spent most of my career of
doing business development and a few
years back I'm a graduate of Virginia
Tech so I'm a hokie in a few years back
the the Dean of engineering at Virginia
Tech reached out to me and
others who had venture experience asked
us to come in and take a look at some of
their technology they were doing a tech
transfer a push and at the time and this
is before Asher and before the cloud was
was overwhelming Virginia Tech had a
system called system X which was a 2200
node cluster with with a high-speed
network connecting a bunch of apple g5
servers together some of you may have
heard that they won some awards and they
were number three or number seven or
supercomputer in the world one year but
they gradually slipped because they
didn't that didn't go beyond that when I
saw that I asked the Dean what they were
doing to commercialize it and he said
nothing and I didn't really think we
were going to sell anything like that
but I suggested that the pharmaceutical
industry needed to start doing high
performance computing on an outsourced
basis and I had agreement about that
from a major pharmaceutical company whom
we did our first engagement with and
what we did is we formed the consulting
company it lasted a year or two and then
along the way I was making a
presentation at Duke University where I
was then approached by their tech
transfer director and said I have the
perfect piece of software for that big
machine you got well this was inverse
design which is a computationally
intensive drug design tool which I'm
going to talk about today and so we
ported inverse design to system X and it
worked at Duke University on a 16 node
cluster on system.exit worked ok had a
few memory problems but very quickly the
the cost was dropping on the cloud and
Amazon was where we went next we ported
to Amazon because the the big cluster
that we started out with was not really
being maintained in it in a commercial
way and
the cost even though it was an academic
price was higher than the cloud by a
factor of fifty percent or more and
after we were reporting to Amazon we had
an internal discussion and decided that
we're going to need a lot of computing
cycles not to do our software as a
service but we had a bigger vision and
that's that we wanted to preemptively
compute potential drugs for many
proteins from the protein data bank as a
way of shortening drug discovery so we
identified three sources of big cloud
computing that was Google Amazon and
Microsoft and the relationship that
stuck was Microsoft I met met Todd need
him a couple of years ago and we we
began this discussion and so our stuff
runs on Azure and we aren't using the
other clouds at this time you know we're
focusing I guess that's a compliment to
Microsoft so what do we do what what we
do is we use proprietary software and
cloud computing and design drugs now
that if you're a chemist that probably
does a little violence to you we don't
really design drugs we design drug
candidates because we don't do the
clinical research but it does it quite
well and we use a method called q mmm if
you're a scientist quantum mechanics and
molecular modeling you do a quantum
mechanical model of the small molecule
or the peptide and you do a molecular
model of the protein which makes it a
lot more accurate than older methods
specifically doc which did all molecular
modeling which was a crude and less
accurate approach even though faster it
didn't produce really good results well
that's not all there is to it that's
just the binding calculation the problem
is molecular spaces tend to this
65th big and so you don't want to
enumerate q mmm calculations which take
about eight hours using p dynamo on a
single node or you'd be waiting several
lifetimes or more for for the answer so
what we've done is we've built a and
designed a heuristic search algorithm
through molecular space we constrain the
space by the properties of the protein
that so that we can search a virtual
space including molecules that have
never been synthesized before and only
test some of them in order to do a hill
you know what a hill climbing search is
your Microsoft so so that's essentially
what it does if we describe inverse
design i've already I've already talked
about some of this but we're searching
and computing binding energy but we're
doing a lot more we're using additional
filters we model water which a lot of
the earlier in silico techniques just
modeled the molecules and paid no
attention to their properties in water
we look for a lock and key fit in other
words a very good binding score we and
will optimize that as we search through
space this is all based on a worldwide
exclusive license from Duke University
and our enhancements to inverse design
it now runs on a jour we're still
testing a few things but we have modeled
several proteins we've done the
calibrations where we're starting
production runs this month we have one
patent issued on the heuristic search as
applied to chemistry and we have more
intellectual property being filed so our
partnership with Microsoft is to use
ashore to we're we've done runs with 500
nodes and we're trying to up that now to
about 1,200 notes it could go even
higher than that but there is some
iteration in terms of the scores that
we're if we do too many then we might be
less efficient with the computing we
have to keep we might what we do is we
launch
say a 1200 q mmm calculations get the
1200 scores and use those scores to
determine which 1200 to do next based
upon the heuristic branch-and-bound
hill-climbing search and then we have to
do several dozen iterations so each one
is eight hours so several dozen you know
it's a few weeks for a given protein not
not running continuously for a few weeks
but it could run continuously but we
have the we go from long calculations
score update repeat and and so forth and
so a little bit of technical detail and
this is this is an illustration of the
idea that we we choose the best molecule
in a database but we don't calculate the
binding score for every molecule in the
database and we're looking for local
Maxima in the scores and so you might
have a surface this is a this is a
simplified illustration because the
dimensionality is really higher than
this but with inverse design it's an M
times n as opposed to enumeration which
is an M to the nth power computational
cost where m is the number of sites and
n is the number of groups per site and
so groups per site has to do with how
big the molecular space is a group is
you can make a small molecule by I guess
some of you maybe chemists and a group
if you put put an R group on a molecular
scaffold it's a group and you can put 10
20 30 of those on a scaffold that's
typical to a protein and then that
defines a rather huge space and then the
m is the number of sites which could be
you could think of it in simple terms as
a number of proteins but it's really but
each protein has multiple binding
pockets so it's really the number of
binding pockets so just to compare
inverse design with prior methods
you will often hear old-school
biochemists who are primarily wet lab
people say oh that stuff doesn't work
and what they're referring to primarily
is doc which is a system that has been
used which is only molecular dynamics no
quantum mechanics for many years and it
was used because Q mmm was too
computationally expensive and it still
is if you knew enumerated it but with
the cloud you've got one speed up with
the heuristic search you got a
substantial speed up and with Moore's
Law you got another speed up so compared
to just five years ago this really
wasn't wasn't practical so docking is
very fast but its accuracy is about
twenty percent but what that means is if
I get docked and scores for five
molecules one of them will be correct
and the other four may not be and so
you're the attitude of the chemist is
okay so I have to synthesize five
molecules to get one good one not so bad
compared to screening 10,000 except I'll
tell you why this isn't good enough even
though it is twenty percent in a moment
a free energy calculation is where you
do quantum according your wave equation
for the binding and you enumerate
instead of using this the smart methods
and the problem is it takes years to do
the calculation so with inverse design
we use the AI search and the cloud we
use we're accurate greater than eighty
percent demonstrated multiple times in
terms of binding prediction and the
search is in the we call it novel
because we're searching molecular space
typical drug discovery project in a
using robotic screening is screening
existing molecules and so you hear
stories like small molecules or all the
good ones are taken you may have heard
that if you talk to two chemists in the
drug discovery business it's all the
good ones are taken because they're only
look at the ones that they've already
built or that they've already
synthesized and they have in their
refrigerators or that or libraries that
are variations of that
but so we have a greater novelty greater
accuracy but let me give you an example
of why this accuracy is even more
important than it appears to be the in
other words the chemist story of all we
only have to synthesize five molecules
and we get a good one isn't quite where
we're at so suppose a protein that's
getting a lot of interest is jak 3
because it's indications of inflammation
and rheumatoid arthritis which are huge
markets and we're we're running inverse
design on jak 3 now but it's really not
good enough to just have a jak 3
inhibitor with good druggable properties
because there are other Jack's that
signaling proteins like jak1 and jak2
whom you do not want to inhibit even
though you're inhibiting jak 3 so the
the problem is more complicated you have
to be selective so we were asked by a
potential customer can you give me a jak
3 inhibitor that's selective against
jak1 and jak2 and we said we believe you
can and we've set out we're doing that
now but if you look at these accuracy c
scores to come up with a selective jak 3
again selectively against jak1 and jak2
you have to take the point eight or
point nine will use point eight to be
conservative and take it to the third
power because you have to run it against
three molecules three protein models not
just one so that says that fifty two
percent or just call a fifty percent of
our results should be accurate if I do
it with Doc twenty percent to third
powers less than one percent so you
can't design selective molecules with
docking because the selectivity will
kill you because of this low accuracy
figure yes if all you care about is
binding and that doesn't make up a drug
just binding any binding you need
selectivity you need good druggable
properties and you need low talks and
you know we're we're not a talk software
company but we use talk software filters
so that our output library eliminates
molecules that have really bad tox
scores and there's plenty of room for
improvement in that talk software but
it's getting better yes so you could
have it almost for free compared to what
you're doing can you combine the two
even though docking is a less accurate
score there are smart ways that you
could combine the two depending on what
you're trying to do that's a good
question and and i'm not sure we fully
exploited that yet but when we're
interested in selectivity because
inhibitors or agonists alone aren't
enough again to be a good molecule were
worthy of going through preclinical
research you need a you need an
inhibitor it's got to be selective it's
got to be low tox it's got to be
synthesizable and it also it also has to
have you no good druggable property so
we need to use filters to do that and
the medicinal chemists have to like it
in other words it has good clearance
properties it's not going to it's not
going to go in there and clear out right
away so that it is ineffective yes you
look at the correlation between the
hours of talking
to see if their mitts are completely
correlated then of course there's no
extra value using talking also if
they're completely uncorrelated that's a
really good question and personally I
don't know the answer are keen and our
chief scientist would probably know the
answer and I will follow up and and
respond to that because that that's a
very good point so this is how inverse
design is configured conceptually the
workhorse part is the the the binding
calculation which we're using p dynamo
for which is an open source software
very good open source software but our
value added is not not the computation
of the Schrodinger wave equation and P
dynamo its its selecting what molecules
to compute it on so the way this all
begins is we have we have a binding
affinity equation that's applied to a
target you start with a target the
target is an x-ray structure we build a
computer model from the x-ray structure
of the target which is a protein we the
step one is to calibrate the inverse
design algorithm based upon any
published data for any inhibitors
whatsoever for that target so this this
setup process is still a little bit
manual we're working we're building
automation to combination expert systems
and an automated algorithms to take the
person completely out of the loop this
here is completely automated on Azure
this setup process takes anywhere from a
couple days to a couple weeks per
protein but once it's fully automated
will be down to you know hours if less
the library design is a process in part
of we're not searching complete blind
molecular space because it's 10 to the
65th big but you can choose a smart
scaffold that fits the binding pockets
for that protein and we are in the
process of writing an automatic library
designer but it's still today's
based on mining the literature so all
this setup again takes a couple days to
a couple weeks per protein we expect to
shrink that down to hours we've we've
got materi Hobbs one of our computer
scientists working on that right now is
her main mission and as to by this time
next year to have that down to two hours
and not days property filters that's
where we use third-party software to
eliminate bad molecules that are bad for
other properties if they got predicted
predictively bad talks which is not our
core competency but other people do that
then why consider it solubility can be a
rather synthesized ability can be
estimated from properties and those
kinds of things go in these properties
and then then we do the the iterative
runs where you go and use up the X
molecules we said 1200 we were doing 500
but we're going up to 1200 I'm not sure
we got our limit raised to 1200 yet but
we'll find out soon you do a run on that
many simultaneously it's embarrassingly
parallel each one is running a Q mmm
process or qm process and giving the
scores back then it iterates we do it
again and again several dozen times and
we come back with a new chemical entity
or a small highly focused library of
several new chemical entity
possibilities and we can do this we're
doing this primarily for small molecules
today but we expect to do it also for
peptides short peptides you know not not
proteins but short peptides you know 10
to 20 positions not you get any bigger
than that and the computation gets gets
ridiculous because there's 20 amino
acids / position to consider whereas if
you're using small molecules you can
limit the number of our groups that you
vary in the number in each group set can
be substantially less than 20
so this came from Duke University it was
validated with H deck 8 which is the
protein that was done at Duke and a new
molecule was designed and synthesized
and literature data was used to validate
the binding scores and here is where we
got a result of about eighty percent
we've also done it since it was licensed
from Duke for jak1 jak2 and jak 3 and
the correlation to the literature is
good we're getting ready to do the big
production run on jak 3 that's going to
the Selective one and and so we expect
for that one we're going to hire out a
Cynthia out a chemist to synthesize the
results that we get so that we can get
some wet lab correlation validating even
further than what was validated at Duke
so I've already pointed this out
benefits as accuracy speed and speed
relative to free energy calculation not
speed relative to to doc and novelty and
novelty we think is really important
because for the reason I mentioned
earlier you still here sometimes the the
people in the industry saying well all
the good small molecules have been taken
well that with space 10 to the 65th big
how can that be true it's just that they
use the same ones all the time so hold
on
some of the business propositions that
that that we are experimenting with in
the market now are as follows one option
is and we're in early-stage companies
just you know primarily been in
development most of our revenue today in
fact all of our revenue today has been
consulting in services option one this
think of this as a customer's option we
do a single target discovery project
which may have a total price tag of a
you know 50k or higher depending upon
the complexity and we would ask for
royalty if it ever goes to market or
milestone fees but that are much smaller
than what a biotech typically asks for
for developing a single a single
molecule option two is to license
molecular libraries in our project with
Microsoft we are doing 25 targets that
we select developing small focused
libraries and library being maybe six to
12 molecules big of our best results and
making those available and if someone
wants to go forth with them they can buy
them or license them for license the
rights from us or we can be
collaborative with them and raise money
together for the project to take it
through the clinic on an outsourced
basis and this is what in our agreement
with Microsoft has been called the
speculative business because this is
where we choose the proteins in advance
and work on them and then look for
partners on for the results we have a
partner in Philadelphia called nimodo
enomoto technologies who has a database
you and it uses sequel the database
matches molecular assets to anyone in
the world who's interested in those
molecular assets either to license to
partner with to research with or or from
a market perspective so we're using that
as one of the ways that we're going to
find
partners for the work we're doing
together is through their database a
third option is an RD partnership if we
find a target that's of interest to a
big pharma company and we achieve early
results then we will seek a partnership
with them where we do you know they fund
preclinical development together or that
we pass that on to them depending upon
what their preferences are an option for
is is the license inverse design for
internal use we haven't done that yet I
think we are going to wait about 12
months till we get a bit more experience
with it ourselves and make it more
foolproof and then we make that as a
high-end as your application that will
train a company to use due to farmers
concerns about you know complete nutter
privacy it could be in a bit and if that
happens what what they're they're going
to want a private you're a sure how do I
say that it a sure both okay here now I
know I am schizophrenic with it so that
might be something that that is more in
in Microsoft's world what what happens
if a pharma company wants the cloud
internally how do you solve that problem
do you just sell them a monster machine
inside their firewall and if so then we
can port the software over there and do
a contract with them and give them a big
license to do all of their proteins or
one of their proteins or whatever they
want to do and so we're a little bit
we're a little bit opportunistic about
the business model i think there's
there's going to be some changing
dynamics in this market and we don't
claim to have a good enough crystal ball
to know what the stable business model
or which one of these is going to be the
driver so we're going to spread our bets
and be nimble and as the market evolves
and as this matures it may be that we
zero in on just one of these is our
primary business model but for now we're
we're
going with the flow and I don't think
anybody in the market knows what the
markets going to be as you know as the
blockbusters move toward personalized
medicine there's going to be lots of
changes so far for marketing we've been
the bio IT world in bio also Boston
biotech the Boston biotech CEO meeting I
went to we want to market inverse design
to large pharma companies and I these
are not customers I just put their names
down as examples of the kind of clients
we would like to have we would like to
partner with other microsoft partners I
named a couple here because their
software might be compatible for either
improving the speed of what we're doing
or being a high-end option for our
customers and we would like to market
the products when I say products I'm
speaking of molecular products that come
from the speculative business using one
of those business models that that I
mentioned and this will be a thrust of
ours going forward we have some other
bioinformatics capabilities that I would
like to mention and also like to talk a
little bit about some of the things
we're interested in pdb which is the
database of the National Institute of
Health and it's also its worldwide its
european molecular biology Institute
also hosts PDB has been ported to the
it's been important to Azure not to the
data marketplace yet but it will be soon
one of our developers has ported it it's
in sequel Azure so we can do full sequel
queries on pdb so we can do more
powerful queries than you can do on PDB
on the public site for instance you can
find molecules that that have certain
kinds of properties maybe you want a
molecule that has three zinc's close
together you can't find that in pdb the
public pdb now but if you have sequel
you can and we are going to provide you
with some queries that that we think
that are unique to the sequel as your
pdb as as a as a follow-up
about a hundred thousand proteins and
about 300 gigabytes in that in that
range our staff has both computational
chemists and bioinformatics people as
well as software folks and so our reason
for being interested in pdb is because
we can draw the x-ray structures from
that to feed into inverse design but
along those lines we're interested in
and and I had several discussions today
here we're interested in finding a
natural language or search capability
semantic search capability to complement
the platform because we would like to
compute upon finding adequate capital
all of the targets in pdb in advance of
anyone doing drug discovery on them just
so that we short we shorten the drug
discovery cycle for small molecules and
peptides at least but not all proteins
in pdb are suitable as targets many of
them would never be a target because
they're either not human or they're not
part of a pathway that's of
physiological relevance so by having a
literature extractor natural language
focused on biomedical literature we can
identify you know which ten percent of
the PDB or possible they might be
targets because they were found in
pathways that molecular biologists have
identified in their research so that's
one litter literature extraction problem
we have another semantic search problem
we have to do and that is as we produce
these molecules we need to do patent
searches and the patent searches are not
as simple as text searches because we
need to semantically model the
properties of chemistry in those queries
so that we can find whether there are
structures molecules or structures that
might that we might be in violation of
if we tried to sell these molecules and
we have to eliminate this so we need to
do and and that's not as good
is a IP attorney doing it but our you're
doing two-step IP the first is this sort
of automated filter in the second one is
we have an interested customer we have a
real IP attorney look at it and that way
we're not paying attorneys fees for
every Mott every molecule but only when
when there's a customer and it's been
filtered in advance so we have a need
for for semantic searching and
literature extracting in the biomedical
literature and we've already started
some discussions along these lines we're
exploring a search engine and we're one
of your staff is also looking at what
you're all doing in natural language to
see if there's a fit there and so let me
summarize where our status is the sequel
Azure pdb is ported not yet released on
the data marketplace we have some
product ization work to do such as a
user's manual privacy policy and a
license and that stuff as being worked
and we need to do a little testing but
we'll probably have it out there for
free for a little while maybe by Labor
Day inverse design is ported in debugged
although we found some new things that
we had to do this week and it does the
heavy lifting we need to do more
front-end automation before it's
released as a as a piece of software
that we can license without without
hand-holding but that's a goal and the
first six actually the first seven
targets have been identified three
calibrated Jack three productions ready
to run we're again 15 full and part time
folks quasi virtual we have incubator
office space but we half of our people
are not in North Carolina so obviously
we're not all there every day all day
but but we use the incubator as a place
to go for meetings to meet customers and
to have group meetings when needed if if
we're not doing it on online we're also
raising around the funding we have an
interested investor we're looking to add
to that
and we're expecting that that will come
to a conclusion in the next couple of
months so I have a chart that I call the
Holy Grail and this is I've already
alluded to this and that's the the Holy
Grail is we'd like to reduce drug
discovery to a simple sequel lookup or
search look up in other words now that
now that's that's a long way off but
there are significant steps toward that
that we can take so we precompute
inhibitors for all promising-looking
targets in NPDB that's the immediate
goal that's an expensive computational
proposition we're doing 25 right now and
we're shrinking the time and we're doing
trying to do as many smart things and
look at your suggestion about the
combining of docking with with to see if
we can get any savings there but
ultimately we're going to you take a
hundred thousand proteins in pdb and we
want to maybe choose five to ten
thousand of them that we want to
pre-compute this for in it you know we
set it on earlier slide a well that's
50k engagement well that includes profit
and markup and people that were cutting
out so it may really only be ten
thousand dollars worth of cloud time /
protein and that will come down as costs
come down however it's still a 15 or 20
million dollar proposition so we have to
raise money to do it and our intent is
to raise money for some of that to get
customers to pay for some of that and
maybe to get some of that from
government sponsorship and just over
time build up enough roll up enough
money there to to do this the first step
toward the Holy Grail where we'll take
the x-ray from pdb or wherever it comes
from if it's a private if it's a
proprietary protein we're working on
what we call the automatic scaffold
designer that has to be done before we
do this in volume that's the part that's
people in tents that were we're
automating
the methods to automate that have been
identified so it's not doesn't require a
scientific breakthrough it just requires
more work and what we want to do is
compute this big inhibitor library and
drug discovery then becomes you know one
of the things you'll do in drug
discovery is look up and see what what
inhibitors are already available and
then if a customer wants them we either
sell them to them or take a take a
royalty or whatever business model this
evolves to as part of our business so
thank you for your time and we can do
some questions if there are any yes you
spoke to which was not just for drug
discovery for material science as well
oh yes I should i neglected to mention
that this inverse design technique
originally came from material science in
the chemistry department of duke and
then it was they got a Duke got grants
to do it for drug discovery and shahar
Keenan who's our chief scientific
officer was at Duke at the time as a
postdoc and she did the original inverse
design for drug discovery but with some
changes we can use it to design
materials we haven't done that yet but
and I think that what we would do
initially is to do that as a service to
find if we find an interesting project
or a customer who's interested in doing
that that we can go back and optimize
the materials to certain properties what
inverse design does is it it maximizes
the score on a property in the case of
drug design that property is binding but
in the case of materials there are other
properties that people are interested in
and you have to change the property
equation and so there's some testing and
some changing of the scope and size of
the problem would have to be done but
but we would be interested in branching
out into material science as well
because we think it is has a different
risk profile from a business sense than
drugs
drugs are you know low probability of
success but big money when they succeed
whereas material science would probably
be a little bit more stable so it might
be good to compliment to businesses but
we're were small and and focused at the
moment but yes we would be interested in
that so if there if you know of others
interested in your community in that
problem we would certainly like to have
conversations any others so in the
transition to as you're from your
proprietary cluster to Amazon to assure
now as if it easy as it we weren't
really all that far we weren't really
all that far with Amazon we had only
done a couple of runs when I first came
in here and then we were given some as
your time it was a little bit
challenging for our folks at first
because they didn't have their mostly
Linux type you know C programmers that
didn't know the Microsoft platform all
that well but we recruited this a guy
from Florida the one who did the PDB
work it was a very strong database guy
good software engineer who who has had
experience with issuer and he basically
coached our staff on you know getting
through some of the we got some good
tips from Microsoft people too but they
they had to you know go through periods
of time have not known a bunch of things
until they and and and so it was a lack
of familiarity with the Microsoft
platform as a developer and so we
brought we brought Eric in who's done
the PDB work and he's helped the others
Terry and Bill and shahar you know
overcome the the we don't know the
Microsoft platform and and I think we're
past that hurdle mostly so other than
there's the learning career that you're
coming up on you think that capabilities
are you trying to accomplish
so you said embarrassing parallel and I
tend to use the term pleasingly parallel
because I'm not embarrass my girls well
I'm not either but that's the term that
the technical folks like to use for its
hour but I'd rather have it that way
yeah yeah then you don't have you cut
some costs down yeah but you're finding
it you've got access to everything you
need or their issues he's still having
the platform well it's taken me a while
to learn who to call it at Microsoft but
I've gotten more comfortable with that
now and and different people at
Microsoft have different ways that they
respond to messaging you know some will
respond to email and some you might need
a calendar appointment or somebody might
need a text you know so you have to kind
of figure out okay so but so that would
that was one challenge that's a non
technical challenge you know getting the
people train was a challenge and then
you know we've run into a couple of you
know technical barriers on Azure that
that your staff was very helpful with
also you know and you know we're working
to find the best data centers for these
big jobs you know we ran a job on a
Friday night once and it took a long
time to cue up not that long I once this
is being recorded I won't say the
numbers but I think it's gotten better
since
okay thank you
and we're going to follow up with having
some of our technical folks especially
on the PDB talk to your sequel Azure fix
any others how much need how much manual
effort does it take well here's the part
that's manual is once we choose a
protein you have to go get the x-ray
structure and set up a computing file
but and that's that doesn't take too
long but it's not fully automated but
the part that is a little more
challenging there's two of them one is
is calibration where we have to go to
the literature grab any data that's
available pull it out and run a
calibration run for that protein and if
we could do that with a literature
extractor we could largely take the
person out of the loop on that and then
the other one is the scaffold design the
scaffold is largely based upon the
binding pockets of the protein we don't
want to just do blind molecular space
it's too big so we have to you know are
we doing a peptide or we're doing a
small molecule there's no scaffold with
a peptide we just have to decide how
long it will be but for the for the
small molecule you may have some parts
that are going to be fixed and many
parts that are going to be varied and
you have to decide how big you want that
molecule to be and the literature can
give pointers to that chemists intuition
so this is the hardest one to automate
but we're working on it where it's going
to be part expert system and part
extraction and part part assembly
however those are not you know the
reason we're using Azure was for the QM
part which is the real number crunching
where we need a lot of parallel ISM this
automation is more along the lines of if
I want to queue up a lot of proteins I
want to get people out of the way so
that I can streamline them rather than
have a two-week delay for each one or
have multiple people in parallel for
each one you know cut that labour down
oh and also to release this as an
application to customers I think we
really have to keep that much simpler
than that setup is now it's not terrible
it's just not as automated as the rest
of it we focused on the heavy lifting
thing first so it's just where we are
it's I don't I don't see it and there's
some hard problems in there but there's
not impossible problems in there well
what literature should we search you
mean or do we search when we set it up
usually pubmed we want to know what what
biochemists and molecular biologists
have found when they've either done
binding experiments or they done pathway
analysis is depending on which problem
we're looking at the pathway is really
more to determine is this protein
potentially a target if we're doing
preemptive calculations we don't wait
for a validated target if we're doing a
service for a customer they'll bring us
a validated target so there are two
different models there and in the
project we're doing with Microsoft
that's the pre-emptive stuff we're not
the ones where handpicking initially are
validated targets that are coveted by
the industry but when we get to looking
at the bigger piece of the database we
have to have methods of selecting that
are smarter
could you tell you a little bit about
the calibration process that you do it
takes a set of binding data for anything
that has bind has has been bound to that
protein and uses it to tweak the
parameters in the algorithm ok so it's
an no but it's a point six that you
create gets mapped 1.75 know but there's
but there is a program that does it you
just have to find the inputs that you
want to use and if you want the detailed
science of that I'd have to set up a
call between you and shahar so she could
share you know what what what's in the
algorithm but but if the algorithm
exists it's a matter of finding the data
that we're going to put in it
and the same would be true we did
material science for instance we'd have
to to get we'd have to seed it with
anything that was known now it's
possible to do this without calibrating
but it takes a two step process in other
words you get you find a homologous
protein and get some of that data run
with that take the results and you have
to synthesize it get the binding data
and run it in again unless it you get
really lucky and it's good enough then
you don't have to run it again this
calibration effect the sort that you in
do afterwards so what finds strongest
Alliance weakness when you're talking
about you know you want something that
matches this and it doesn't match these
that now you really need calibration
because you have to be able to come no
that's selectivity the selectivity is
done by running the results at against
other protein models all the proteins
have to be calibrated
others so I want to thank you very much
thank you for the opportunity</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>