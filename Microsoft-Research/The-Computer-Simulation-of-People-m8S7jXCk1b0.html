<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Computer Simulation of People | Coder Coacher - Coaching Coders</title><meta content="The Computer Simulation of People - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Computer Simulation of People</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/m8S7jXCk1b0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">let's welcome professor Dmitri Tazawa
neiman how I'm delighted to be here
today I'm going to be speaking to you
about computer graphics which I i think
is a wonderful field one of the reasons
is because it brings together a whole
variety of the other fields there is no
field in science and art that is not
fair game for computer graphics to
incorporate into what we do and today
i'll be speaking about humans and how we
can use computers to simulate humans
people are the most complex natural
phenomenon in known to us in in the
known universe so you can think of this
as being a long term grand challenge
problem and what I'd like to do today is
show you some progress that we've been
making on this big and important problem
over the years the motivation for what
we do a large part of that motivation
comes from the entertainment industry
and as you know computer graphics has
been the engine that has been driving
the enter the multi-billion dollar
entertainment industry both the movie
industry and the interactive game
industry both on the software side and
also on the hardware side now when we go
to the movies these days we see virtual
humans and it's easy you know Hollywood
magic is basically giving us the
impression that these virtual humans on
the big screen are intelligent
characters and are doing things on their
own but it's important to realize I'm
sure many of you do that these are
characters that are not not only are
they not intelligent but they're also
not even autonomous it requires humans
to make them move and make them move in
a
a realistic way and here in on this
slide you see some examples of virtual
humans from landmark movies such as
final fantasy or Beowulf and many more
examples over the years showing you know
these kinds of characters also as I said
human characters are very important in
interactive games because we like
interacting people like interacting with
humans with one another and so we want
virtual characters in interactive games
that are at least autonomous that they
can do motion you know their own
movements just like real people can and
eventually also become intelligent so
what I'll be speaking about today part
of this is of course what we have on the
one hand is physics and simulation
biology computer science of course
because all of this has to be simulated
on a computer and of course animation is
just mathematics in motion and so and of
course there's a lot of art involved so
all of these things are coming together
in what I'll be showing you now those of
you who are familiar with how humans are
animated you know that the state of the
art these days is motion capture
technology which requires instrumenting
the human body with 3d tracking
reflectors infrared reflectors and then
having an actor recording the motion of
the body from the actor both the body
and the face of the actor and then
transferring that motion to a virtual
character to make that character move
such as Gollum here in The Lord of the
Rings trilogy but what we're trying to
do in our research is make virtual
humans that can move on their own let me
begin by talking about facial modeling
and animation the faces are probably the
most important thing about the human
body that we interact with
on a day to day basis and here you see
the progress in computer graphics facial
modeling in a 20 year span from the
early 80s to the new the new millennium
two thousand or so and you can see the
dramatic progress in facial modeling
this is a geometric model of the face on
the right and if you look at it it looks
almost as high-quality as a photograph
it's you have to look closely to see
that this is not actually a picture of a
real person but it's a 3d
three-dimensional model of a you know
virtual face and so visually this is
pretty good but to make a face like this
move in the realistic manner is very
difficult still and that's where some of
these movies fall into the uncanny
valley as it's known where the
appearance is great but the movement and
the behavior and the intelligence is not
at all great and so what we're trying to
do in our research is close the gap
between appearance and let's say
behavior so everything works well now
for the human face of course if we look
at facial Anatomy we see that the
anatomy of the skin the skin is not a
simple surface of course it involves
multiple biological tissue layers
epidermal layer dermis fatty tissue
embedded muscles and additional fatty
tissue or adipose tissue underneath and
the muscles themselves are highly
complicated there are many muscles even
in the human face as you can see here in
this picture they have Latin Latin names
and it's it's complicated these are just
artist renderings artist drawings here
so what we try to do is emulate this in
a computer model starting with the skin
we build a synthetic virtual skin which
is a multi-layer structure it is created
out of finite elements
simple finite elements here this is
intended to be a real-time simulation
model and then we take the many muscles
of the face and abstract them into a set
of facial actuators that are responsible
for facial expression then we embed
these actuators and the tissue we form
it in the form of a person's face so as
you see there and the geometry can be
captured by say a laser scanning device
as you see on the right there which
captures the shape of a particular
subjects face and what we have as a
result of this process is a face that
actually works a simulation model here
and here it's going through random
expressions of random intensities and as
we see when we bisect the model you can
see how it works in the back you see the
multi-layer tissue created out of these
finite elements and those lines back
there are the muscles the facial
actuators and when they are controlled
in a coordinated manner what we get is
tissue deformation the muscle actuators
produce forces that deform the tissue
and the deformations on the exterior are
recognizable expressions and then you
get all the nice phenomenon that we see
such as the nasal labial furrows and
natural types of deformations so i'll be
showing you many videos and images
throughout this talk there's a lot of
mathematics behind this but i'm not
going to show you any or many equations
there are many applications for this
type of work the model you just saw was
intended as a real-time system but we
can also use facial tissue models to
simulate facial surgery craniofacial
surgery so here's an example from the
work of FD he owes sifakas and his
collaborators where say you have a tumor
on the skin you excise the tumor and
then
the surgeon needs to close that defect
that is created but I excising the term
the tumor as you can see how the the
procedure works as it doesn't in real
life now let me talk a little bit about
muscles so there's muscles are
complicated as all these other
biological tissues are and here you can
see the hierarchical structure of the of
a particular muscle going going through
the various sub parts of it until we get
to the sarcomeres over here which
actually perform the contractions and
result in the forces that are that are
generated in the in the body so it's
very difficult to model even something
like this but we have the work of
Archibald hill from you know the early
earlier part of this century and he
actually won a nobel prize for
physiology and medicine for elucidating
how mechanical work is produced in in
muscles and he came up with this model
which is known as the hill muscle model
it's a combination of a contractile
element that's this one over here with a
Serie A Series passive elastic element
and a pack and a sorry series passive
elastic element and a parallel elastic
element over here and this is known as
the hill model this is what i'll be
using well this is what we used in the
face simulation that you saw before and
i'll be using it again in the models
that i'll show you to come let's go down
the human body the next important
structure is the neck and that has been
very much overlooked with you know
relative to the face but as you can see
here it's extremely complicated in terms
of the muscle structure and and the
geometries that are involved biology
seems to be that way biology isn't like
robotics in the real world you know you
have a physical robot
and compare it to a human being
roboticists like to minimize complexity
reducing the number of actuators and
joints if possible as much as possible
because these things are complicated and
they break down as mechanical parts but
biology evolution seems to go the
opposite way increasing complexity as
much as possible almost perversely so
one has to wonder why that is and I you
know based on our work I think it
actually helps in controlling these
systems it makes them more flexible of
course in terms of degrees of freedom
but also in terms of actuation it's
easier to control mechanical systems
that have lots of actuators as opposed
to few actuators so we bit we built a
model of the neck and here you see we
have the skeletal structure it's got 77
cervical vertebrae and a skull each
vertebra vertebra is connected to the
next one by three degree-of-freedom
joints ligaments and discs are modeled
as well this leads to equations of
motion here's a simple formula it's just
Newton's laws of motion it's basically
saying that the mass of the system times
the acceleration is equal to force F is
equal to Ma Newton's second law and we
see all the forces that are involved
here gravity Coriolis and passive
elastic forces if you turn on gravity
you what this is expected the mass of
the head collapses on top of this
flexible neck so of course there are
muscles there to prevent this from
happening by producing forces
contractions so this leads to moment are
matrices and the active muscle forces
that are produced by the actuators in
the neck and what drives this whole
system in in us is neural inputs coming
in from the motor system of the brain
and so we're modeling all of this in
this particular model we have 72
anatomically based muscle
actuators and three layers 48 deep
muscles 12 intermediate muscles and 12
more superficial long superficial
muscles the challenge here is a big one
how to actuate and control this model
the way our brain controls it by the way
here's a drawing from Leonardo da Vinci
from a long time ago and one might
wonder what he would think of something
like this hat if you were to see it now
I'd like to play this short video it's a
it's a humorous piece that explains how
our model work it was produced for the
annual computer graphics conference
siggraph so let's see if I once upon a
time there lived in expressive face
named Pat one day Pat found seven
vertebrae and a skull that fit nicely I
should now be able to turn my head Pat
thought but gravity prevailed as the
blood rushed the pats head Pat became
introspective that's it Pat realized I
can control my head using muscles
attaching 72 neck muscles activated by
trained neural networks Pat could now
turn at will this changed Pat's life
pack could enjoy riding a wagon playing
soccer and even talking to friends and
they all lived happily ever after
Thank You muscles in the body come in
pairs and you have coactivation Co
contraction of muscles enables one to
increase the stiffness of the physical
the actuated physical system so this is
illustrated here by co contracting pairs
of muscles and opposing pairs the system
becomes stiffer so here you see one of
those wobbly head dolls on the wagon and
you can see as the wagon perturbs the
system the head wobbles a lot but as we
increase the stiffness of the system by
co activating muscles in pairs on either
side of the neck it becomes much stiffer
it's not as much wobble and now it
increases again ok so this just compares
the two I'll move on in the interest of
time and here's another demonstration of
that with with the soccer ball with low
coactivation the deflection of the head
is quite large and if we increase the
stiffness of the system the deflection
is much less so in addition to
controlling pose of the head the
position of the head we also need to
control the head stiffness and so if you
heard the video it mentioned neural
networks let me illustrate this as a
system diagram what's happening here
this is our neural muscular skeletal
system model of the neck as you see we
have the biomechanical face model over
here the skeletal system the muscles and
two sets of controllers a low level
reflex controller and a high level
voluntary controller the control the
muscles in the system there's
proprioceptive feedback in the system
and the feed forward and set point
signals go to the reflex controller
while the voluntary controller
is based high-level thing that the head
decides what to do and the low level one
controls the muscles the muscles then
produce contraction forces which
actuates the skeletal system and the
whole thing is situated in a physical
assimilated physical environment so with
gravity and external forces and the head
of course has the biomechanical face
attached to it which is capable of
facial expression and what I'd like to
talk about next is the neural network
the neural muscular controller that
controls the muscles these are
conventional neural networks and what
I'll describe first which are
perceptrons essentially and we all know
what neural networks are so let me move
on now here's the problem we want to
build a control model that is biomimetic
that it shouldn't need to know anything
about physics it doesn't know anything
about mathematics F equals MA Newton's
laws nothing like that but it should
work in a physically correct manner so
it seems that the only way possible to
do something like this is not through
optimal control and the things that
robotics people really you know
traditionally used to think about but
rather to use machine learning methods
to do something like this so let's
suppose we have our our head over here
and it has to look at that visual target
that the little doll so let's set that
random target pose then we can use
inverse kinematics to determine so if we
rotate the head to that orientation we
know what the muscle lengths have to be
but remember the head is has weight so
it'll fall in gravity unless the muscles
contract so using inverse dynamics we
can figure out what the muscle forces
have to be to keep the head in that
position against the pull of gravity so
this creates basically a set of a
training data pair the input is the
desired head pose the output is the
activation signal that gets sent the
activation signals that get sent to the
72 muscles in this system
and to create additional training pairs
we can do thousands and thousands of
them here's like 2012 illustrating
20,000 random samples with putting the
doll in random positions in the visual
field and so we can synthesize through
the biomechanical model an infinite
variety of training data and then we
feed that training data to our neural
network using back propagation learning
the neural network learns and basically
what it does is regression in a high
dimensional space this is the power of
regression basically on training data
nonlinear regression in a high
dimensional space and if it's done
correctly the model can then the
neuromuscular controller can generalize
so it can go in between things that seen
the training data and generalize and do
continuous tracking of the visual target
and hear the expression is just a simple
thing that relates to how that the
visual target is moving so this is an
illustration of applying machine
learning to train to control
biomechanical models for use in computer
graphics and animation and you saw this
earlier which is early attempts at
putting together some amount of social
behavior as well so when you're in a
group of people you want to look at
someone but not exclusively at that
person you want to gay you know glance
at the other person as you're talking so
these characters here are just doing
facial expressions and mimicking each
other's facial expressions but they're
doing it in a socially aware manner so
that's the next level up where we're
doing behavioral modeling nowadays we're
using deep learning to do this kind of
thing because we have more situations
the train over and vastly more
quantities of data so the conventional
neural networks are not sufficient for
that so we use auto encoder stacks and
so on to to push this line of research
forward let me move on to whole body
biomechanics here we see the
traditional way of doing physics based
modeling and computer graphics you have
a skeletal system and you put joint
motors at each of the joints which
produce torques and then of course
there's ground reaction forces gravity
and so on and you have to control the
system to do to make it do certain
things so I mean clearly this is not
motion capture because this is very
dangerous to do if you're going to do
motion capture but as a simulated system
it's not a problem so the way this works
is through post control where you set up
a set of key poses and then use the
physics to interpolate between those
post positions and external inputs such
as you know touching the chair and so on
and the character is able to do this so
this is just a start because the
biomechanical model is very simple there
are no muscles in this model just joint
torques but nevertheless it could do
some interesting things as one once it
falls then it could actually get back up
again and this is a challenging control
task in itself how you know here you
could see the strategy of rolling over
into a prone position and then getting
up on all fours and remember there's
gravity here so it has to control its
balance as it's doing this task and not
fall over and of course if the the
actuators were suddenly not working you
just collapse so it gets back up but you
know that's a start and what we want
what we've been trying to do is build a
much more high fidelity model of the
human body that involves muscles rather
than motors and so are simulated motors
so here we have a comprehensive
realistic biomechanical modeling of the
human body that includes 75 bones or 165
degrees of freedom and a large number of
muscle actuators this one includes 846
muscle actuators in it in addition we
have a volumetric finite element soft
tissue or flesh in the body which is
three hundred thousand or so
he drill finite elements and let me go
very quickly through this model here's
the skeleton all the various bones if
you look at the again the anatomy of the
situation you see lots of muscles in the
torso there are hundreds of muscles in
the torso that control the spine
movement and all of that at the at the
deep layers and more superficial layer
muscles and what we try to do is emulate
this complexity by putting in these hell
type muscle actuators into into our
model so here you see the deeper muscles
in the back and bigger muscles are
simulated by cooking up smaller
actuators see we have broad muscles here
again this is done with smaller
additional actuators now you can see
here how many actuators are in the upper
body area here's the lower body as well
forward backward and here we have the
muscle geometries that come along with
this and here you can see the muscles
individual geometric muscles stripped
away on the right side so you can see
the deeper layers underneath them and
finally there's a skin on top of the
model so creating the soft tissue
simulation mesh is actual challenge in
itself let's say we start with the skin
geometry here of our virtual character
we create a lump of flesh which is
modeled using finite elements this is a
tetrahedral lattice seven millimeter
resolution throughout the body we cut
out the stuff that's on outside of the
skin and that leaves us with about four
million tetrahedral elements which is
too many to actually simulate so we do
corseting to create coarser elements in
the interior and this reduces the
complexity by an order of magnitude then
we have the lump of flesh underneath and
the geometry on top and we simply embed
the geometry into the soft tissue and I
can't go into the details of how we do
this but this is a pretty good
compromise
is between performance and fidelity that
doesn't require modeling individual
muscles as three-dimensional objects so
that gets kind of technical so I don't
want to get into that with too much
detail but here you can see the result
of this which is a model that actually
works and here he's doing his exercises
and if we look on the inside we can see
that the muscle actuators are actually
producing forces between the bones that
they attach to and then the bones move
and the form and of course the muscles
deform the flesh which is deformable
here you see a shoulder view where you
could see the flesh deformation over the
arms much more clearly so I talked about
coke attraction of opposing muscles
earlier and here you could see it again
where this is an isometric exercise
where a virtual character holds his arm
out and then flexes and let's see
releases flex release so you can see the
tissue deformations that result from
this so we've got zero co-contraction on
the left and the high co-contraction on
the right and so it looks quite natural
so we wanted to do interesting things
with this model even though you know
it's very complicated and takes yeah you
know quite a bit of time to simulate
these various components but we got very
ambitious with it and decided well we're
going to put it into a fluid and then
we're going to try to simulate human
swimming and control the muscles large
number of muscles in this virtual human
to produce swimming so we start with our
comprehensive biomechanical body model
which I talked about already and then we
immerse that in a simulated
navier-stokes fluid simulation so this
is you know a field onto itself in in
applied math and then we try to do some
again biomimetic muscle actuator control
and in this case because we're dealing
with swimming
in rhythmic motions this is
characteristic of locomotion in general
that the body produces rhythmic motions
we use what's known as central pattern
generators or CPGs that control muscles
in these are recurrent neural nets at
the spinal level that produce rhythmic
patterns and these rhythmic patterns
contract muscles in a repetitive
rhythmic fashion so here's a close-up of
our swimmer you can see the skin here
the internal muscles the bones and let's
see and the fluid so here's a system
diagram of what's going on the swimmer
has the ability to perceive its in its
environment it's simulated physical
environment the brain enables the
swimmer the high level controller
enables the swimmer to produce different
swimming strokes like crawl butterfly
freestyle you know those sorts of
swimming strokes and then at the CPG at
the spinal level the CPG networks
produce the rhythmic active activation
signals that go into the muscle into the
muscles to make them contract in
rhythmic patterns so this simulation
here you can actually see front crawl
and then we can compare something like
this with real footage in fact we can
have the character learn from the real
footage how how to reproduce that
particular pattern in the timing that's
shown in the video and so this
particular swimmer actually mimics what
the real person is doing in the video
and then the network's themselves can
transition quite easily so here we start
a slow swim and then it speeds up
or oops I'm sorry I shouldn't I should
not have done that I'm gonna have to
play this back up here so I have to play
this one again because I want to show
you the second part of this
demonstration with a style transition
where the characters here doing a
butterfly and then transitions quite
naturally into the front crawl stroke
and these networks are able to do this
sort of thing quite naturally by just
switching them and they do the switch
continuously smoothly and of course
physics interpolates quite nicely as
well so what we have here is a highly
complicated multiphysics simulation
system where we have three different
types of simulators across three
different regimes we have the rigid and
articulated body simulation which is
using multi body dynamics multiple rigid
bodies for the bones then we have the
deformable body simulation for the flesh
which is using lagrangian finite element
models and finally we have the fluid
simulation for the water which is an OL
aryan fluid simulator with
particle-based level set methods so
these are all quite complicated
technically but they it's it's hard to
build a single monolithic simulator that
can do all of this these are specialized
similares simulators and it can
communicate with each other each other
through forces and it happens in an
interleaved manner where the muscles
control the bones the bones you know
move the flesh and of course the flesh
is embedded in the fluid and so there
are forces between the fluid in the
flesh which produce movement to I mean
the propulsion to move the body forward
through the water and finally let's just
look at this video here which
illustrates well first the actuators and
the geometric muscles and finally with
the fluid added splashing effects and so
and you have the whole system working
together now let me move on to the topic
of artificial life I mentioned that AI
comes into our work in a very heavy
manner fact we go beyond artificial
intelligence to artificial life where
the intelligence system the intelligence
of the model sort of cooperates with the
biology in some sense and the
biomechanics at the lower level so
here's the artificial life modeling
pyramid the way I see it an animal which
of course as we humans are is a physical
agent that situated in the physics
physical world so we simulate physics at
the lowest level and in particular for
animals and humans we are interested in
biomechanics which is the physics of
biological tissues both hard tissues and
soft tissues and the use of biomechanics
to produce locomotion and other task
based movements now an a physical agent
in a dynamic world needs perception so
we have to build perception models
including computer vision as part of
this overall artificial life system
perception and behavior and locomotion
and action are linked together through
behavior so we get into the biome you
know the biological study of behavior
known as ethology in order to do this
animals of and humans are of course
capable of learning from their actions
so we kind of saw learning already in
what I showed you so we come learning
theory and machine learning comes to
play in our in our models and finally at
the apex of this artificial life pyramid
we have cognition where the agent can
finally have a representation of itself
and its environment within its head and
can use this representation to and
knowledge to reason and plan its actions
into the future which we think of as
being thinking so too
span this entire pyramid is kind of
daunting but we have been able to do
this sort of thing we need to do it as a
matter of fact for simulating multiple
humans working together in a virtual
environment so I'd like to show you next
autonomous pedestrians you see here it's
a train station you'll see a little bit
better you know in a few moments you can
see multiple virtual characters in this
in turn indoor urban environment here
the train station itself is a large
space it's a geometric reconstruction of
the original Pennsylvania train station
in New York City the one that was
demolished to make you know to where
they put the new penn station and as you
can see was a classic neoclassical
building over here and here the
historical for photos from the interior
and this is just the geometric
reconstruction of that station you see
the train platforms over here the
concourse area here the main waiting
room and a shopping arcade and the
little the little autonomous pedestrians
in here top-down view and some close-ups
of our simulated humans and here you see
a bunch of commuters and other people in
the train station simulated people
moving around they don't collide with
one another they go about their business
doing things that they need to do such
as purchase tickets over here talk to
one another purchase drinks and food
from vending machines and and they you
know the captured you know catch trains
and so on in this in this environment
they get tired they want to sit and so
on the activity in the train station is
kind of characteristic of human a Clark
scale human multi human activity it's
this kind of ordered chaos that you see
that we see around us all the time the
system is intended to be real time so of
course we're not
simulating physics in order to do these
this this is just inverse kinematics
with game characters doing a physics
simulation would be too expensive when
you're doing thousands of people but you
can see that these characters have
perception in their environment they can
move around and avoid colliding with
objects and so on so I don't have time
to explain all the details of this but
let me show you some interesting things
here here you see it two groups of
people coming together in the arcade and
these these two crowds pass through each
other this is a bit strange because no
one here wants to pass on the left they
all pass each other on the right which
of course is not realistic but with
changing parameters of the system here
let's see we can have them prefer to
pass on the right but but they could
also pass on the left when needed and
what you could see here is the formation
of lanes of traffic opposing lanes of
traffic in this simulated environment
and that's quite natural then these
characters are able to plan their
actions so here we want to get to the
chair and if the character knows how it
is where it is then it can walk around
and come and finally navigate in a large
scale and sit down so these characters
as commuters in the train station they
would enter the station and then go and
purchase tickets and then board trains
so let me see if I have time to play
this one where we followed yeah we
follow the male subject bounded by the
rectangle on the stairway close to the
entrance or subject another pedestrian
her to stay to the right in order to
avoid oncoming traffic after our subject
enters the station he proceeds toward
the ticket booths to obtain a ticket our
subject joins the line of pedestrians
waiting for the available ticket booth
luckily he does not have to wait for
long notice how the pedestrians avoid
colliding with each other as they
proceed to purchase tickets after he
gets a ticket our subject proceeds to
the portal leading the main waiting room
to the concourses he manages to overtake
the lady in green and tries to stay out
of the way of oncoming traffic
nope help pedestrians avoid oncoming
traffic in the narrow portal now our
subject feels thirsty when you spot the
vending machine in the concourse he
walks towards it the weights firm has
turned to get a drink
at the same time not far away Destry ins
are gathering around a group of girls
dancing to music
feeling a bit tired our subject finds an
available seat for seizing towards it
and sits down
the clock chimes the hour and it's time
to proceed downstairs to the train
platform our subject passes through a
somewhat congested area by following
turning and stopping as necessary in
order to avoid bumping into the other
investigators the girls are still
dancing and are attracting interest from
other pedestrians but our subject
apparently has no time to watch the
performance so as you can see these
characters are intelligent characters
and you can go in and look at them close
up and they do smart things so it's not
just simple crowd simulation as you may
have seen in games these days we're
actually modeling the artificial life
pyramid to do this in a bottom-up manner
there are many applications for this
kind of work we've worked with
archaeologists to do simulations of
activity in ancient reconstructions of
ancient sites this is with collaboration
with Brown University one interesting
application is using these kinds of
human simulators in computer vision
research and very quickly to motivate
this surveillance that's becoming
ubiquitous in today's world there are
many cameras out there in cities these
days and of course human operators can't
possibly look at all of the video feeds
that were coming in that are coming in
from thousands of cameras so what's
needed is autonomous networks of smart
cameras like the ones shown here which
have onboard processing and
communications from one another perhaps
in even wirelessly the problem is to do
research with these kinds of systems in
the real world is very difficult or
actually impossible for most people you
can't go into an airport and say I want
to do research with the camera system
that's over here they'll tell you go to
your lab in the lab it's very difficult
to set up big multi camera systems
networks to do this kind of work but
there's no constraint to do this in the
virtual world and so we have our train
station we put we put virtual cameras
down there that capture virtual video
and then we use machine vision
algorithms to do tracking recognition of
people and so on and finally high-level
camera control and the cameras
themselves are modeled you know
reasonably accurately so this allows us
to do this kind of research at the high
level of how to control cameras in
without constraint and of course these
virtual humans don't mind being watched
as they go about doing their their
business so just to illustrate this
quickly here you see our simulated multi
camera system tracking a virtual
pedestrian the operator has said this is
the person I want to track and then the
cameras communicate with one another
through a network that's simulated a
wireless network that simulated and the
cameras can actually use the signature
of the uniform the color signature of
the person's uniform to track her in
with multiple cameras as she moves
around so this is automatic persistent
multi-camera observation of a person
moving through a large space so one of
the several examples applications of
these kinds of human simulators most
recently we've been looking at human
simulation at the social level just as
an example of what we can do let's take
door in doorway etiquette holding doors
for others door manipulation and dynamic
decision-making in the doorway
environment which we actually do using
Bayesian network decision models so
situations such as this where this is at
UCLA and one of the buildings and you
can see how people interact socially
holding the doors for one another and
and so on you're all very familiar with
this kind of behavior and so what we try
to do is emulate this by building a
social model on top of the autonomous
pedestrians that I showed you earlier
let me just quickly we introduced a
real-time simulation framework that is
capable of emulating human social
behaviors around a variety of doors and
in doorways including the common
behavior holding the door open for
others to pass through our novel human
simulation system can synthesize various
types of door holding behaviors
while maintaining coordinated order as
autonomous pedestrians passing through
doorways so this is proper social
etiquette there and based and it defines
the roles of the door holder and the
follower a holder may continuously hold
the door for two followers to pass
through first if a follower takes over
the door from the door opener the
follower will become the new door holder
and we'll assess the next follower
before deciding on the appropriate door
holding policy integrated with our door
etiquette framework a post opposed
procedural motion model generates
motions by defining several key poses
with possible transitions from holder to
follower to synthesize a variety of
natural behaviors our model takes into
account both internal and environmental
factors and employs a Beijing network to
choose between different door holding
behaviors additionally the rush factor
influences the walking speed in the
doorway so I'm out of time and I'd like
to our approach can synthesize a long
sequence of pedestrians approaching the
door from one side the inset video shows
more hurried and less kind characters
so this gets kind of complicated
sometimes that's fringe of protein from
opposite sides as one side takes over
the doorway the opposing side will queue
up and wait for the doorway to clear the
inset video shows interleave passage due
to a similar arrival time on both sides
our door interaction model includes the
ability to catch a closing door our door
and doorway etiquette framework can
support different types of doors such as
the revolving door by modifying the door
interaction model the autonomous
pedestrians are continuously able to
push and pass through the revolving door
in an efficient manner hesitation and
ketchup behaviors are observed as a
consequence of a moving door here we see
simultaneous passing through the
revolving door from both sides
our system can also simulate social
etiquette around double doors with more
complex drawer where conditions the
autonomous pedestrians normally prefer
to stay to the right and pass through
the right-hand door but this is by no
means mandatory in a dynamic situation a
pedestrian may take advantage of a door
that is being held open even if it is
not the right hand door moreover as one
side gets crowded subsequent pedestrians
will prefer to use the less crowded side
regardless of whether it is the left or
right door ok so this I will not play
that let me just wrap up this talk by
talking by discussing some future
challenges as we as we've seen the
computer simulation of humans is a
difficult problem spanning many levels
of detailed and abstraction from the
physics level all the way up to the
social level and while virtual humans
are of course becoming increasingly
useful not just in entertainment but
also in science engineering in the
humanities and really there are many
even though progress has been made there
are many open engineering and scientific
problems still to be addressed and
tackled for example how can we close the
gap between biomechanics and
intelligence for large-scale multi human
simulation this is a grand challenge
problem and it's a high-performance
computing problem you can imagine if we
did a full biomechanical simulation as
in the case of our swimmer for each of
the hundreds or thousands of characters
in our autonomous pedestrian simulation
how much compute power that would
require and you know if that were
feasible then we can populate
reconstructed models of entire cities
such as the virtual Los Angeles model
here where the buildings are all
modelled but as you can see there are no
humans in in this space and wouldn't it
be great if we can actually put
biomechanically simulated in intelligent
virtual humans
in this type of environment and have it
and have it actually work in you know in
feasible computer time that's a very
difficult in a challenging problem that
spans multiple levels of computer
science and also tackling the the
massive data driven high dimensional
real time learning our machine learning
problems that have to be done for
neuromuscular control is a very
important challenge as well that I'm
personally very interested in these days
the nice thing about virtual
environments though is that we can
simply synthesize unlimited amounts of
training data from the simulation itself
in the real world we have to actually
measure training data from real people
which is a little bit more complex and
challenging to do but in the virtual
environment we have all the ground truth
information and can simulate the data in
real time so I think much more research
is actually required to understand
people and then reverse engineer people
in a sense so we can make them into
fully functional virtual people and of
course all of this work is done by my
former PhD students for Chinese students
in in this list and a former postdoc so
this is in the order in the order in
which the work was presented and I'm
very grateful for having all of these
very smart intelligent students working
with me it's all due to them thank you
very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>