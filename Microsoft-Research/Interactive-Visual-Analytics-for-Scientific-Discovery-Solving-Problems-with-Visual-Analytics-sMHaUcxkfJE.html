<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Interactive Visual Analytics for Scientific Discovery - Solving Problems with Visual Analytics | Coder Coacher - Coaching Coders</title><meta content="Interactive Visual Analytics for Scientific Discovery - Solving Problems with Visual Analytics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Interactive Visual Analytics for Scientific Discovery - Solving Problems with Visual Analytics</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sMHaUcxkfJE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by microsoft
corporation may be used for internal
review analysis or research only any
editing reproduction publication
reproduction internet or public display
is forbidden and may violate copyright
law
good afternoon everyone welcome to the
video analytics workshop the major goal
of this workshop are threefold first we
want to bring together the rug needs a
leader in this area to share their
successful stories and rich experience
in designing effective visual analytics
systems to to the insincerity the
applications second we want to
demonstrate the typical use cases to
facilitate the scientific discovery and
the decision-making and the finally we
want to provide guidance and a
suggestion to the future work so we
include three talks in this workshop the
first talk is given by professor
professor Daniel camp and he will talk
about how to solve real-world problems
of video with visual analytics
technology and that its role in big data
analytics and the technical talk is
given by professor Klaus murah here we
are talk about video analytics of the
high dimensional data and the last talk
is given by Professor 1-1 we will talk
about visual analytics of social medias
first weigh-in white and welcome
professor than you can to give his talk
yes thank you very much for the
introduction it's a pleasure for me to
be here and speak about the topic
solving problems with visual analytics
the role of visualization analytics in
exploring big data and if I'm talking to
people what is solving problems so that
does it mean what kind of problems if I
talk to my son the who is 19 years old
the main problem that he has is about
soccer he wants his favorite soccer club
to win but we won't be talking about
these types of problems here maybe a
more serious problem is earthquakes and
this is actually a very interesting and
very nice example not talking that much
about Big Data yet but if you look at
the recent earthquake in in Japan and
just plot all the earthquakes that
happened before the big one that we had
in Fukushima and you saw and color it
the more darkest in in red the higher
the the scoreboards and you see that it
wasn't that unlikely that where this
little crosses that this earthquake
happened at this position so it wasn't
really unlikely if you just look at it
and if you visualize what is affected by
by an earthquake at that position you
see the coastline that is affected and
you can even simulate how it distributes
over the Pacific Ocean so you see where
the impact is biggest and so on and so
forth so we see already how
visualization can help us to understand
these problems but this is some of it is
not really big data so what are the
Grand Challenge problems and I found
this page from the National Academy of
Engineering and they mentioned all the
big problems of the world the Grand
Challenge problems and if you look at
these things then you immediately
recognize that all these problems and
you see there's everything out there
that that is a big problem financial
ecology then you have energy water
cyberspace all these things and they are
all related if you look at them all
related to big and calm
Lex datasets and this is the first
important thing to note we need to deal
with big data sets in order to make any
solution now the topic of my talk is
about what can visualization and
analytics healthier and the
visualization of big data is difficult
that's actually bad news we have about a
million maybe 10 million pixels on our
screens so if you deal with really big
data like hundreds of billions of
records we can't really visualize it all
at least there is no simple easy
solution to it and that's actually kind
of a problem and if we try to scale it
and we have developed a number of
visualizations like here's a big tree
map of network data you don't see the
important data in here there is some red
dots in here that are hard to perceive
and you can put this up on power walls
and this is like again network security
data and then you see like this is now
the 100 most important ports where we
had a text on our network and you can
basically look at them it's one week of
data and reports out of 65,000 ports
there's plenty of other data that we
can't show even if you have the big
screen and and what you see here is
basically like if i zoom in you see this
development and they are interesting
things that you can see like this is a
backup process over the weekend that
happens here these are interesting
things that happen in the middle of the
week there's something that running in
the beginning of the week and this is
kind of normal traffic here where you
have basically doing the day more
traffic than at night so this is
actually a nice example of a scalable
visualization but it doesn't scale to
the extent that we needed to so I do
have some good news after that bad news
about the visual part automated analysis
of big data works and it's usually
scalable at least most of it so you can
deal with billions of Records that's
fine and then should we use it I think
we should use it whenever possible
whenever you can use automated noises
it's a good idea to do and the question
is why of course because it's cheaper
faster more
scalable and less Irenaeus if you put
humans in the loop it usually causes
errors that computers don't do so am I
really telling you that we should get
rid of the user must be some other thing
that is coming and if you look closely
in any of these problems that I
mentioned in the beginning it's actually
I have to restrict this good news the
automated analysis of big data only
works under certain preconditions and
what are these preconditions I get to
that in a second the bad news is
actually for automated noises that these
preconditions are really rarely met in
real-world applications what are these
preconditions the preconditions are the
data must be clearly structured the
semantics must be well-defined the data
must be complete correct and not
changing over time and if you think of
any of the data sets that I mentioned
it's usually not the case take molecular
biology or the data is not clearly
structured the semantics is not clearly
defined data is incomplete correct and
it's changing over time so it's all
these parameters are not given and one
more point that is even more important
the problem is not very defined we don't
know what we are looking for if we knew
then it may be easy if you know what the
virus that you want to detect you can
write an eye goes in the desert if you
don't know the virus how should you how
can you write an and there is no
algorithm that it takes a new virus that
that you don't know how it's defined how
it's working and this is what people are
doing at some are taken other companies
they are updating the virus definitions
every day that's why we download the new
definitions every day maybe you don't
recognize it but your computer if your
virus program installed is downloading
new definitions every day because they
detect new viruses and tell your
computer how to find them but somebody
has to detect it and distinguish between
a new computer game and the virus so
this is kind of the problem where they
find is really a problem and this is
true for many applications molecular
biology you don't know what you are
looking for
if you knew the reason for the illness
you are done right the main part is to
define the problem and well-defined
problems are often not the case if we
know how things work together for
climate change then we are done but this
is not very fun we have to discover this
and discovering can't be done by
automated methods alone and this is
basically all the cases when automated
analysis is not enough it's basically
the inverse to the preconditions that I
just mentioned i already mentioned some
examples let me briefly go through a few
of them network security the data is IP
flows and if you wanted to take novel
viruses as I already mentioned there is
no way to do it fully automatically you
can have systems that give you
interesting data like effects that that
are sticking out that are new you can
have algorithms doing that but deciding
on a virus or not can't be done fully
automatically you need the human because
the problem is not well defined fraud
detection credit card or phone call data
I personally have work with phone call
data and phone and credit card data both
and the thing is the same you can have
algorithms that highlight changes you
can have I wisdoms that help you detect
potential fraud but you can't decide on
it without having a human involved
otherwise you shut down systems before
you need to and have unpleasant
situations happening for your customers
so the detection of fraud is still
something where you need the human
finally making the decision business
analytics customer feedback data and I
get back to that later if I have time
it's a real time problem detection what
is kind of happening in real time you
get all this customer feedback from your
customers and you have to retake new
things not the things that you already
know and deciding these is again a
problem that you need the human to be
involved to prioritize and help
molecular biology already mentioned it
if you have patient DNA records and want
to find out about the root
cause causes for an illness this is
something where you again need automated
analysis are lots of automated noses but
you need the human with the human
knowledge and intuition so what is
visualization needed for it's needed for
interactive problem specification so the
human puts in the problem in the process
of dealing with the visualization and of
course for interactive data exploration
and understanding but in addition and
you need steering the steering the
automated algorithm to head the I wisdom
do this thing in the best possible way
that you needed to do it and you need to
communicate the results so we have
different uses of visualization and this
is basically motivating what visual
analytics is and I've found a nice code
which is attributed to a very well-known
person who probably never said it it's
attributed to Albert Einstein but I
don't think he ever said it but who
cares everybody attributed to him
computers are incredibly fast awkward
and stupid humans are incredibly slow in
equity and brilliant together they are
powerful beyond imagination and this is
the motivation and I would say even the
best definition of what visual analytics
is all about very nice sentence and I
don't think he said it because computers
run that fast when he left and then was
saying this supposedly so I guess
somebody attributed it to him so what is
visual analytics it's a tight
integration of visual and automated data
analysis methods for information
exploration and decision support and
what you see down here is a very
simplified version you have the data on
one side and knowledge on the other side
and you see you can go from data to
visualizations from data to models by
automated analysis and the important
part is you can iterate between the two
you can go back and forth between the
two until you find what you need and we
rarely see that these days but we need
it urgently for many applications and
basically the whole motivation is you
want to bring in the abilities of humans
and computers where humans are go
and computers are good and this picture
is actually quite old I found it in a
book about 20 years ago and it's almost
still correct I put in the arrows this
wasn't in there and it's non linear
scale of course computing power is
incredibly fast now for computers data
storage is beyond imagination but if we
look down here modeling general
knowledge on the computer is still
something that we we are struggling with
real general knowledge of a 15 year old
child bringing that to the computer it's
really hard and you see that even with
all the success that IBM Watson had some
of these answers are really bad of
course some of it was great but but some
of it was was quite bad and everybody
knew in the audience that the computer
was doing because they don't know they
don't have general knowledge they do
statistics basically perception we are
still better and creativity I have no
idea how computers how even to define
what creativity of a computer means like
inventing relativity theory by computer
something we couldn't imagine writing
music that bar or other magician did I
don't think we can imagine computers
doing similar things of that degree or
paintings or whatever defining what
creativity means is even a problem so I
believe we should combine these two
things and if you want to know more
about what visual analytics is we have
in the I've coordinated a European
program with big program and this was
the outcome this was a roadmap for
visual analytics outcome of this master
project if you want to download the book
just go to this web page and have a look
you can download it from there and it's
outlining the challenges of this
emerging and quite important field and
how to bring visualization and analytics
together for solving the real problems
of the world at least some of them and I
brought you a little video clip that we
also generated that is motivating
analytics and play a little bit of it
and this was also an outcome of the VIS
master project
biologists every day collect knowledge
what music data from web lab experiments
trooper genome sequences
in business internship during those of
the work consists in managing order news
data
the real-time Lance's towards the state
competition and survey the print
cartridge
they have to protect and proves
effective your team to write them but
also within the ranks your money and i
spencified the case of enemies closer
the large amounts of data from seven
supports experts have to deal with
multiple sources of information huge
number of entrants inch and waste time
to cross combine them because of lack of
support and their way to query the data
efficiently with one of these examples
have in common all these people
encounter the same problems they have to
deal with masses of time
they want to answer a lot of questions
sometimes unclear questions that require
exploration a need for the computational
analysis and interactive visualization
we need to export easy-to-understand
representations of their results for
communication it's now imagining the
epidemiologists with visual analytics
capabilities if you have an epidemic the
touchy strong countries with a coma
hospital admission
or people in the same sentence they can
share their own database of hospitals
concern by disease and visualize them on
a map it looks like is not contagious
the experts in further exploration to
identify the causes and the nature of
the acrylic after hospitals and you want
to share it visualize the vocalization
of people concerned by the disease
looking in the propagation of the
dullness we can see that the pattern
doesn't form of communication access or
several ways this is a specific pattern
that has grown and start the duckling
experts therefore conclude that it is
not the contagious disease the most
probably of food poisoning Tonetta
neurologists decide to investigate what
time the products all the patients are
ingested and look
math last thing to do
identify the fruits
is closest to reach people
this is a supermarket among people
beauty
this time
is too broad and the immediately know
that they have to try something else
try again in the new suppliers I think
it's top here and if you want to see the
rest of the video and it's going on for
a few more minutes it's on YouTube just
type in this master and you'll find it
so this is kind of just motivating me
visual analytics and I hope you have now
seen that this is an example fictitious
example of how visual analytics may work
this is not work operational and this is
true for many reasons this is the case
for many reasons because you don't have
the data sources for such an example
ready from multiple countries and so on
and so forth but people also don't have
the tools to explore that data analyze
and visualize it what I'm going to do
now is after explaining a little bit
about the role of visualization
analytics I will probably provide a few
examples how visual analytics may help
and I start with network security and I
won't make it so all fake for examples
but I give you a few examples of how
this can be used operationally in some
some interesting cases so let's start
with network security and what we did
here is kind of trying to take the best
that is out there in the analytics
domain take commercial intrusion
detection systems and connect them back
to the raw data to allow people to make
better decisions so the basic framework
is here we have an intrusion detection
system on this side and we have the
NetFlow data which is the wrong network
data a little aggregated net flows are
aggregates of the draw IP packet data
and this is basically now coming from
the University and it's basically
connecting to the global internet and so
here from the gateway you get this
NetFlow data and here you get the
intrusion detection dealers alerts and
our system is now in between connecting
up this output of the automated
algorithms back to the raw data and is
helping you to understand these
intrusion detection alerts better so
what are the components
and of course you have to do kind of a
number of things here to make this work
because this is very big pipe of data
coming in here it's billions of records
per day so you can't easily process it
so you have to be aware that you need IP
packet stream processing netflow record
aggregation on the fly so you need
special technology even to do that and
you can increase the effectiveness of
the intrusion detection alerts by adding
something in here and we are part of a
connector of a network of honey pots if
you've never heard about honey pots it's
basically computers in the network that
you put up just for the purpose of
getting bad traffic they have no other
purpose so there is no valid traffic
going to these machines so everybody
accessing these machines is a bad guy
and you can collect information of what
they are trying to do so there is no
reason you just put them out there
simulates something and open environment
and then people who connect there are
usually bad guys that try to infect
these machines try to capture them and
there's a network all over the world of
these honey pots that we collect data
from together with somatic so now having
all the data what do we do we can do
netflow summaries which is basically on
the right hand side the raw data you can
see what ports have unusual traffic what
is the time development and so on you
can visualize the IDS on or EC intrusion
detection summaries and now we put both
together in our system that I'm showing
you in a second and then of course you
can drill down to the raw data the host
details like every computer net flow
details to do the detailed analysis to
confirm what you have found so now just
to show you a little example here what
is happening here this is now a complex
system for an expert user so if you
don't understand it it's perfectly
normal because this is the expert at
user at the administrators level who is
usually dealing with the IDS system so
he is really knowing about IP addresses
subsys sub IP addresses and so on and
many of the features here are for the
expert user
but what I want to explain to you is
just the major view here and you all
start with your intrusion detection
alarms and this list is usually too long
so they always work up work on the top
of that list because you get more alarms
all the time and there are hundreds and
thousands of alarms coming in every
minute so you have to basically
prioritize what you work on and that's
in general true for intrusion detection
systems so what we can do here is we can
now take any part of that list of alarms
and then look at the raw data what is
the raw data to eat doing to my network
and what you see here is basically in
the background a tree map of your
internal network this is my internal my
company's Network University Network
whatever you are looking at and these
are external IP addresses every these
little circles is one external IP
address that is accessing my internal
network and it's somehow suspicious and
then we have automated algorithm studies
that are clustering these nodes
according to what they do to my network
the behavior of the traffic that you
that they generate and you see there's a
lot of nodes doing very similar stuff to
my internal network and you see that by
this edge bundling that they really
access a few computers so guess what
this is this is an distributed attack
that is happening every day at least on
the University Network so you have large
number of external machines that are
trying to hack one of these machines
because they have some open ports they
are seem to be viable in a room and this
is what you can easily see by such a
visualization you can drill down and see
whether these computers if in fact it or
not so they are using this at the
network administration level to use it
and of course you have multiple views
then to do it down this little timeline
views and these are now IP addresses and
imports so you get the time behavior in
this little clocks and you have other
representations that help you to go into
your network structure and visualize
that and that's the dynamic system where
you can zoom in and out and see certain
behavior you see here you have this
whole subnet and then you see here the
details of the subnet
out having some interesting traffic at
one particular time spot and this whole
thing is set up in an operation control
center where you have basically all the
visualizations and these are high
resolution LCD monitors each of them
having a resolution of 10 megapixel with
the touch table surface down here that
you can control the whole thing so this
is kind of an operational system where
you can do this visual analytics in
practice and note it's combining
analytics the best analytics you can get
intrusion detection system commercial
systems but connected back to the raw
data and visualize the connected data in
a way that you can make sense out of it
and this is big data this is billions of
records that you can access in real time
on your backbone and you need a lot of
technology to make it work but this is
one example where really big data is
explored by visual analytics meet second
example customer feedback analysis and
have no time to go into all the details
so the process of generating the of
processing the data is quite a detailed
process model you get basically the
input data is commercial data from a big
company all the customer feedbacks
millions of these little feedback nodes
such customers right when they have some
problem and I'm sure you had this happen
to you you bought something with some
store and they put up this little book
do you want to give us some feedback and
probably most of the time you click no
but some cases you may click yes and say
this was really bad whatever I didn't
like you put in there so processing this
is basically now the idea here and know
the big company doesn't have the stuff
to read it all maybe here in China but
in like the US and Germany they don't
have the stuff to read all these notes
that you write they want to get it
aggregated they want to find the
important stuff out of this and this of
course they want to find in real time so
this is a idea here so what happened
what do you have to do and as you can
tell you I'm not going to explain this
because otherwise my
time is gone and what you have to do in
order to process it there's lots of NLP
that you need to do like part of pitched
speech tagging whatever sentiment
analysis of these course and so on and
so forth so this is the whole pipeline
model of what you have to do assume that
you can do this with a reasonable
quality now how can the intro actresses
and this is what I'm going to show to
you now the point is these events even
if you can cluster them aggregate them
happen very at very unusual arrival
rates if you have a problem you have a
big peak coming up of some problem and
you want to detect them and that's why
we come up with a new visual model like
if you take the raw data and this is
just an artificial example now here it
would arrive in certain at certain
positions in time and here you see I
have multiple events occurring at the
same time spot if you linearize them
like just plot all the five events that
we had here and this is artificial what
we do then down here is a density curve
this is a density over time these two
events were kind of dense in time and
then there was a gap that's why it's
going down and then you the highly dense
event coming up here and so on and you
can calculate the time density and I
don't have time to go into the details
but I want to show you some real
examples is now will I have no 27
documents for certain topic complaining
about whatever topic and then you have
down here now each of the events
happening and red means bad sentiment
green means good sentiment score so it's
quite bad that people were complaining
about something but what you see in the
density track they were highly
concentrated at some point in time right
so you have the linear arrival here
which is not giving you the time but
this is giving you the time and what you
are interested is not the absolute time
but the relative time whether it was
dense in time or not so the big gaps you
don't see then it's going down to zero
right if it's a big gap but if it's
dense in time so the something happened
around this time right something really
bad happened and now we can go in with
really
samples and this on our wheel examples
from a real customer feedback stream and
you see here we had some problem
happening here very bad sentiments very
concentrated in time we have some bad
events happening here and what the
system is doing its proposing all the
topics whether were clusters with
interesting co-occurrences of terms that
were unusually compared to the past so
you have some values that you know these
things always come customers are always
explaining about certain topics and what
you can do then is also kind of
attributed back to the time line this is
not real time line those lines give you
back the real time line and you see
these kind of terms that go with these
events and you then can click on every
single event and read it if you are not
sure what was happening here and we
exploit this the scene experts that
we're doing these analysis and they are
more used to it this is now a timeline
where you have all the events happening
over time and you can relate it back you
see every serious problem happening down
here so just two more examples packing
list example there was a promise a
packing list something went wrong here
and you were able to see that custom
something went wrong with customs rarely
happens but it did happen and so we now
evaluated this with real people and we
found all the events that they knew were
in that data set and there was a year
worth of data of the customer feedback
data and the interesting the more
interesting part is we shot the more
events and they evaluated whether they
were real events and they found that be
detected more events than they were
aware of so they would love to have
known it but they didn't so our
technique was actually able to help them
find more events than they were able to
discover with their manual and and their
means that they had beforehand and
that's a big company doing this and of
course you can rate related back to
geography positive negative feedback
overlaid on a map and you see now here
customer feedback overlap shipping seems
a big topic always and you see it's
always mixed
negative and positive is mixed you see
here tax-exempt was just in some regions
the problem and it's negative you had
some problems due to rain in some
regions which were mostly here we have
some problem that was related to traffic
in some regions and so on and so forth
so you can really do kind of interesting
analysis even over the geo spatial
domain so this is kind of an example in
that domain and I guess I'm now skipping
over the next one because we hear more
about high dimension in the next talk
and briefly go into a completely
different domain namely molecular
biology before I conclude and I think I
have few more two more minutes I guess
in order to do that so let's go into the
domain of molecular biology and you may
have heard about overlapping genes you
may not have heard about it this is
something that is quite new so you have
and this just to give you a refresh to
understand what I'm talking about DNA
you've heard about in school I hope so
these are normally in a strings and you
have these letters here and three of
them make up one amino acid and so you
can start at any position to come up
with the decoding and any of them is
good so reading frame one is this one if
I start reading one level one one letter
later I get different amino acid
completely different amino acids and I
have six reading frames sweet in the
forward Direction sweet in the backward
direction if you read backwards you get
different DNA Strix Rite decoding it in
the back Direction gives you different
rooms so this is standard right this is
sign of knowledge what is the assumption
currently and most of the DNA analysis
is done about you are taking the most
probable of these reading friends
because biology can take any right
reading you can do backward forward and
you can start anywhere you want so you
take the one that is most likely to code
a gene or
ecology so what biologists have found
that in some cases you have something
that is sitting in the forward direction
this is the coding a gene and on top of
it and this is now the interesting thing
on top of it you have something in the
backward direction it would be like in a
computer program you code something and
on top of it you have another message
coded which is never happening in
computers because there won't be any
message you can't coach another program
up on top of the other or another even
ASCII text it's impossible to have
another ask you take text on top of
another of an existing one you can try
there will be never anything more than a
sui letter word coming out of it in
biology they found this to be
operational which means these are long
sequences that are sitting on top of
each other and both of them are
functional and this is very surprising
and our project was now dealing
detecting that there's a lot more of
this happening than the biology sought
bears and we developed a system that is
now helping them to decide which are the
candidates of potentially overlapping
genes that we haven't known about and so
we developed a quite complex system
which is decoding and encoding lots of
automated analysis results and I can't
explain it all it's just to steer your
interest in it that is helping you to
decide where there may be additional
overlapping genes and this is expression
data that you get and you see here known
genes and you see potential and this is
a start codon stop codon frames that you
can automatically compute and then you
can basically help them understand where
there is maybe another gene that is
overlapping with existing genes that you
know about the most interesting part is
here we have found that even for the
most examined saying the e heck by
bacteria like the heffa bacteria there
is about thirty percent additional genes
that are most likely to be overlapping
to existing known genes
with their function being not yet known
this is for the most examined bacteria
so there is a lot of additional
information encoded here and the
biologist even have more of a problem
with our result because it's very hard
to explain how this could come in to be
how this could come you can easily
explain how overlapping goes two
non-overlapping you get deemed
application and then you knock out one
of the genes and this thing is
functional but how you get on top of
each other even for computers we
wouldn't know how to do it well it's an
NP hard problem to put two strings on
top of each other and coding and it's in
medica is not possible here we have it
happening almost everywhere and we don't
know how this could be encoded so this
is kind of a problem they have no models
yet they actually biologists have a
problem luckily I don't have the problem
they have to find the solution here but
the results are very surprising to them
so there is quite some resistance in the
biology domain some people say that
can't be true they simply but it's all
made on out they basically on based on
these automated analysis and our
biologists do wet lab experiments to
confirm that they are functional so they
have shown for some of them and this is
difficult to do of course but it's
possible these days with all their kind
of creating stop codons into sequences
and so on and so forth so they can
really prove that some of them are
functional so it is there it is true it
everything is confirmed so far as we can
tell but it's an interesting result okay
we said I would like to conclude what
are the perspectives and I could go on
we need a lot of additional things we
need a methodology to define what
original analytics problems we need to
understand what the data and the task is
including all the big data parameters
like volume variety velocity veracity
and so on then we have to decide in
going about to solve the visual
analytics problem can be solved the prom
fully automatically it may be possible
then it's not a visual analytics problem
if you can solve it fully automatically
I would propose to you use the automated
message to do it there is no need to
bring the human n but if it's not we
have to decide what can be done was must
be done automatically and we kind of
need to provide the best support to the
user to solve his tasks we need to
define the workflow of analytics and
visualization and then we have to decide
on how to visualize it and how to do it
best and of course in the end we have to
implement it so if you follow these
steps that's actually the steps that I
proposed to my PhD students when they
have to deal with a real world problem
in kind of deciding how to do it and
when they find out here it's a yes then
they stop I tell them don't go further
it doesn't make sense right and they
have to basically go through all this
process to do it so they are interesting
aspects how to do it the implementation
and they are commercial systems out
there that help you and you they range
from a loose coupling to a tight
coupling and I could name now the
companies that go with it but there is
very little on the tight integration
level there is basic none of the
products that you can buy it's doing a
tight integration so there is lots of
room for research to help to do here
better in this domain we need this tight
integration to solve the problems and of
course we want an a high flexibility
with the least possible programming
effort and there's no systems there's no
system currently out there that does it
so we said I would like to conclude and
thank you for your attention are there
any questions
Thank You professor Kim and and very
interesting talk and I like to ask about
the question about site cyber security
which analytics as we already have a lot
of the automatic method for detecting
the network vents so what which part do
you think is most needed or critical for
we generalities to for the cyber
security so let the automatically cannot
be done individually so like we are
working in a new project together with
somatic and other companies that kind of
are really working on this so what we
what we have learned is they can do
great stuff in creating alerts potential
events that may be suspicious but they
can't decide finally between a new
computer game causing that traffic or a
new virus causing the traffic this
decision is still up to the human
because it involves general knowledge
that the computer doesn't have you can't
explain to him you can't have the
computer check automatically whether
it's a game or not so these things are
very hard to do automatically and that's
just one case and in case of all these
fraud things there is a human
intelligence on the other side and you
never know what the human intelligence
is putting in because they try to
basically get around everything you do
in your automated system they exactly
counterbalance that like if you put
thresholds on the number of accesses to
a computer like for distributor tech put
that special 250 you would see the next
day all these distributed text go in
with 48 or something right if you change
it to 445 your threshold they come in
the next day with 43 so there's some
game right it's a game going on between
intelligent humans and you can't compete
with a computer you can't do it without
the computer i'm not saying you should
get rid of the computer but you need the
computer and the human to make these
decisions on what to do and this is
where i see the need because there's
intelligence on the other side there's
human intelligence
and you can't counterbalances just by
computers there's always a human making
the final decision also in fourth the
same thing behind I'm to town from
taking University your talk is nice and
I want to and I'm actually doing with
diuretics and I like the idea of titling
cooperating computational analysis and
interactive visualization but I find
latency and speed is always a problem
for example for visualization if it's
low you can always aggregate or analysis
and you visualize the result but if the
analysis is slow especially for big data
what is the solution thank you yeah so
um scalability is of course a problem
especially in the network domain it is
certainly from but in many other cases
as well and of course there is not a
simple answer to this question you need
to take many of the currently available
methods and like techniques like Hadoop
classism whatever you need to take that
into account so we have a like the
student actually worked a year on the
data side before he did any visual
exploration of the data just to load the
data this NetFlow data into into our
database system and do all the pre
aggregations and he was getting it down
to five minute intervals so real time in
that case meet means five minutes after
the fact that's what we were able to get
of course you could can do better if you
put more resources or outright but but
it's a challenge because the data is
increasing right and there are methods
out there stream processing methods and
so on and so forth that you need to
build in otherwise you have no chance
but I think this is orthogonal to a
certain extent to what we do right there
is some some people in the database
domain working on this like 80 people
have worked on scalable aggregation to
risk our guarantees so you do basically
not fully correct aggregation but you
have gone T's on your aggregation so
they can do it at any time frame
with the best possible error rate so we
probably have to work and take some of
these technologies and incorporate them
good afternoon I'm as the sides of the
room and I have two questions first is
that in this talk i heard that are
nearly each of your projects are heavily
involved with domain experts right and i
want to know that there some good
experience to share with us that how to
cooperate with domain actors or to
better involve them into our projects
yeah that's actually key to what we do
and if you want to like the title of my
talk was solving problems if you want to
solve real-world problems you have to
work with domain experts no way without
that and this may be taking quite some
investment of your time and energy and
in some cases it may not lead to
anything because some of these projects
they walk away they don't take the time
that would be needed so if you want to
do relevant work to some people you have
to be willing to start a year of work
without knowing any direct outcome is in
that year and that's I guess my
experience it worked quite nice in some
cases but I can guarantee you that you
will have some failures if you don't
want to take that risk spend down to it
then work on some Cerreta good problem
and then abstract is abstracted out but
if you want to have an impact and solve
real problems you have to be willing to
invest that you won't be otherwise the
relevant work to these people and solve
their problems right if you want to
solve a problem molecular biology you
have to become partly an expert and and
I have learned a lot myself I've learned
a lot about molecular biology my student
has learned even more she knows no
things that I don't know what network
security my students are expert on that
I'm learning myself a lot linguistics we
have worked loaded with linguists I'm
learning a lot about languages but my
student he is now sitting together every
day with these people and it's an expert
in linguistics now he's publishing more
in linguistics conferences these days so
it's
yeah so you have to be willing to do
that in order to have real impact i
believe and vision analytics is a highly
interdisciplinary field i don't think
we'll have an impact if you if you are
not willing to collaborate there is
that's a very simple story it takes an
investment but it makes your work very
much relevant and if you see people in
these domains using it all that makes it
a lot nicer right if you see that they
deploy it on an everyday basis and it
helps them in their work and solve new
problems or brings up new questions that
then have never thought of oh this is
fun I like it if they are puzzled and I
tell them something and they all this
takes our world right this is changing
our like I could have shown some
examples from from linguistics and these
people were kind of astonished that we
what the outcome were because we were
dealing with languages that we have
never I don't know anything about it we
were able to show something on vowel
harmony in these languages without
knowing anything about these languages
and they were confirming it after going
back to the library for a week and they
said oh you could do that without
knowing anything this is like showing
the potential of visual analytics and
making a very convincing case since they
discovered that they were very willing
to work with us but so it's like if you
have these successes but then these
people are very very open and then it's
a lot easier but it takes maybe a year
to start yeah so sorry no good news on
that side but it you have to be willing
to invest and then it may be very
beneficial for both sides do it with a
time limit that we do not pick up the
photo question I any interest their
audience could talk with Daniel of land
let's thank then you again for this
great talk
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>