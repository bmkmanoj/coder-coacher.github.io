<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Towards a Theory of Trust in Networks of Humans and Computers | Coder Coacher - Coaching Coders</title><meta content="Towards a Theory of Trust in Networks of Humans and Computers - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Towards a Theory of Trust in Networks of Humans and Computers</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cE8BsgmMbQY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'd like to first thank Microsoft
Research nan Chi University and qian jin
university for hosting this event so
thank you it's a real honor to be here
in this beautiful city of tengen or with
lovely weather today so i really am and
looking forward to giving mice talk to
all these eager energetic young students
in the audience to share my new ideas
and new questions i'm going to talk
about a theory of trust towards a theory
of trust in networks of humans and
computers and the talk i'm going to give
is going to ask more questions than
answer questions and this is i think
especially appropriate for this audience
it's going to point to new fundamental
questions insecurities that I think
challenge all of society today so let me
start I'm motivated by actually a
problem that men while Blum a Turing
award winner asked a couple of years ago
we have to recognize especially
appropriate in the theme of the 21st
century computing computing naturally we
have to recognize that the computer of
today is very different from the
computer of yesterday the computer of
today actually is made up of humans and
machines we have now networks of humans
and computers that are solving problems
solving problems that neither can solve
alone so this is the computer of today
and one could ask some deep scientific
questions in this context what is the
what is computable by such a hue of
network of humans and computers but I'm
going to focus on a different question
and this question is how can i as a
human being
trust the information that I read over
the Internet a very common situation is
we go to our machine we look something
up in Wikipedia and we read what is
displayed why should we trust what that
Wikipedia page says that's the question
I'm asking and in trying to disentangle
this question we will see in my talk
many questions that are unanswered many
problems in computer science that we
still have to answer but probably the
most important part of my talk is not is
that it's not just about computer
science the most important part of my
talk is that to answer this question we
have to bring in the social behavioral
and economic sciences to understand a
broader theory of trust in this context
so the insight is that computational
trust defines trust relations among
devices computers and networks
behavioral trust defines trust relations
among people and organizations and a
theory of trust for networks of humans
and commuters needs to include elements
from both so let me decompose the
question how can I as human trust the
information I read over the Internet let
me associate messages that I receive
over the Internet as information and let
me associate receiving messages as what
I read over the Internet and so we're in
a more familiar territory now when we're
talking about receiving messages and now
let me decompose the question into two
questions one is is the communication
channel over which I receive messages
secure
the second is how can I trust the sender
of the messages I receive or another way
to put this is how can I trust the
person who wrote that Wikipedia page why
should I trust the site that hosts that
page and so on let me start with a
simple communications model because this
will let me get rid of the first
question and put it aside so we have a
sender and a receiver sender will always
be on your right and the receiver will
but the will be Bob and he'll be on the
left we're going to assume that we have
secure private available channels we're
going to assume that we have the
computer science technology and the
computer science science to discharge
this assumption we're going to assume we
have a trusted pass between the
application or the user and her machine
and a trusted path between the receiver
and his machine and we're also going to
assume that between the computer and
devices that are communicating with each
other that there are penetration
resistant interfaces this means that I
basically have secure communication and
so I can gray out the first question of
is the communication channel over which
I receive messages secure because I'm
going to assume that I can implement all
those properties i just mentioned on my
previous slide that leaves the second
question how can I trust the center of
the messages I receive so that's what
I'm going to focus this talk on and
we'll see that this question the main
question boils down to the act of
trusting the sender where you should
think about the sender as some person or
some organization
okay why let's let's say I'm the
receiver um and why don't we even want
to ask this question the reason is there
must be some value for me as a receiver
to want to interact with some sender I
must be gaining something from this
interaction and be willing to risk some
costs for having this interaction
otherwise I can just not interact at all
with anyone and then I don't have to
trust anyone so there must be some value
gained by the receiver in interacting
with the sender and this value must
outweigh the costs so that's what this
slide is supposed to indicate the value
underline the act of trusting the sender
if the receiver trust the sender and the
sender's trustworthy then values gain
for both so I gain information and the
sender monetizes on my clique if the
receiver trust the sender and the sender
is untrustworthy then the value gained
must outweigh the cost to engage so the
receiver risks getting now where for
instance but I take that risk because I
think I'm going to get some good
information and finally if the receiver
suspects the center is untrustworthy
that I want to engage and then no value
is exchanged so these are the ways to
think about the axioms underlying this
theory of trust so let's first start
talking about computational trust how do
we build computation how do we build
trust in the computational elements in
in our system and then I'm going to talk
about behavioral trust because we'll see
that even if we could do the best job
possible for ensuring computational
trust we still need to rely on something
else to trust
the sender so the elements of
computational trust our isolation
correctness and recovery these are all
familiar kinds of properties that we
study as computer scientists and these
isolation is when a receiver could
isolate himself from any sender so
regardless of what the center is or who
the sender is or what message is
received we'd like to achieve that
because if you can achieve that then you
can trust anyone and you can trust any
input but we'll see it's hard to achieve
correctness means independent
verification of the code that the sender
might send some somehow parts of certain
messages might be code and we actually
want to want to verify properties that
the code and we know computer science
ways of doing that verification and the
third is recovery where it may be that
we receive a message and we get into a
bad state and we have some way of
recovering back into a good state and
again in computer science we have
techniques to do fault recovery and so
on so we'll see that all of these
elements are necessary for providing
computational trust but they're not
sufficient so let's just look at the
first one isolation from Thunder so we
have a we have one way to possibly
isolate ourselves from the sender is
verify every any input message that we
might receive and as I said if we can
verify any input message that we can
receive in terms of the properties in
the behavior of the the code that might
be in there then trust of the sender is
not needed however let's look at how
possible is isolation from any sender
can input always be verified well the
input might be anything from a piece of
text or took piece of code so no
arbitrary code cannot be verified I
might
the property for instance does this
piece of code that I just received halt
and we know we can't do that we can
answer that suppose the input can be
verified is verification always
efficient well no it might be that the
the message is a solution to some co NP
problem and we know that verifying the
solution will be inefficient suppose
input the input is we can verify it
efficiently is it always practical and
again there are a recent results on by
par no actually an ACM dissertation
award winner a from Carnegie Mellon who
is now at Microsoft Research who shows
that it may be possible to for instance
send a piece of encrypted code over to a
server say the Microsoft Bing that might
say do a search over a large database of
pages and send back a result that the
receiver can check really quickly so we
know we can do this however to do it is
not quite practical yet because these
kinds of techniques rely on a fully
homomorphic encryption which are that
technique is not quite practical yet but
it gives you a hint at what might come
in the future ok suppose input
verification is efficient its practical
and is it always scalable even hear the
answer is unfortunately no and we have
security models from decades ago the mid
and late 1970s that have come up with
ways for us to define how we can check
certain conditions on input messages
with respect to a particular security
model the problem is in the internet
today not all organizations and entities
and individuals buy into a single
security model so not one security model
fits all
okay so now we're in the situation
isolation from the Thunder is hard
suppose the sender can provide evidence
of trustworthiness so now we can't when
the receiver really needs to interact
with the sender and the sender is going
to promise to send over not just the
message but some evidence that what
isn't that message it should be trusted
by the receiver so this is a situation
and here the most the hardest example is
when the message contains a piece of
code and so we might want to ask about
how to verify that piece of code with
respect to certain properties and the
situation is if we have complete sender
trustworthiness no isolation is needed
and the input can always be accepted and
you'll see that we still can't do this
so for instance is it practical not
usually Co correctness proofs are not
scalable their first often limited to
small configurations or limited to a few
properties so I might for instance pass
a piece of evidence would be a would be
a proof that the code is correct with
respect to a specification so that I can
as a receiver check the proof but this
kind of proof carrying code is often
restricted to certain kinds of
properties another problem with scaling
this technique is that the techniques we
use to do the correctness proofs
themselves are often human intensive
they often require interactive simmer
improving so the real problem but even
if we could do full verification of code
and and provide a proof or evidence that
that code is correct is that that code
might still have some input parameters
uninst an she ate it so some where
someone or something is going to
instantiate those input parameters so we
still have some reliance on that someone
or some
thing so how do we do it today we rely
on reputation services third-party
recommendations outsourcing trust
relations to get a sense of whether the
human is trustworthy or not and I think
this should give you a hint as what's to
what is going to come in terms of the
behavioral trust we need so providing
complete or irrefutable evidence that
the sender is trustworthy is hard
suppose a receiver can detect and
recover from ascenders untrustworthiness
okay so in this case we get a an input
message we get ourselves into a bad
state and we figure out we detect that
we're in a bad state and then we need to
recover from this to get ourselves into
a good state again is this feasible
practical and scalable by the way all of
these seemingly challenges are great
questions research questions for you to
be thinking about so the answer is no
not usually it might be possible in
certain situations for instance a lot of
the work and fault-tolerant distributed
transactional databases have figured out
how to do this that's why we can go to
an ATM machine on and do transactions
online however there are situations
where it is impossible to undo the
effects on the standard example is in
fact when you go to the ATM machine you
withdraw money and then you can't undo
that you're hardly going to give the
money back so that's an example of i/o
where those effects cannot be undone
okay so we're in a situation where we
can't have isolation from the sender we
don't have sufficient ways to provide
trust worthy on this evidence we can't
always recover from that
input well suppose when we do get that
input we punish the sender so here what
we need is if if we want to have
deterrence we need punishment and for
punishment we need accountability so
what that means is if i do want to
punish the center sender i need to know
who to punish um and uh this is well
known this sort of implication the
necessity chain but we also need
sufficient punishment to deter and
sufficient accountability to punish so
this is actually a new idea okay is
deterrence always practical and scalable
and here no not always what deters human
behavior or what deters human
misbehavior is an outstanding question
that has been debated by the legal
community for centuries so let me just
summarize where we are in terms of the
act of trusting from a computational
point of view we don't have this
isolation from sender we don't have a
way to provide complete irrefutable
trustworthy this evidence we can't
always recover from that input we don't
have a complete of ways of deterring
from sending people deterring people
from sending that input so but this is
of course the Internet of today so is
there ever a way that we can ever be
safe to trust the sender and this is
where the new idea of combining elements
from behavioral trust from the social
behavioral and economics alliances come
in so let me just tell you right now in
terms of the theory trust so far in
terms of the computational elements
we've got cryptography
verification fault-tolerant computing
all of these have been studied for many</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>