<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Hardness of Robust Graph Isomorphism, Lasserre Gaps, and Asymmetry of Random Graphs | Coder Coacher - Coaching Coders</title><meta content="Hardness of Robust Graph Isomorphism, Lasserre Gaps, and Asymmetry of Random Graphs - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Hardness of Robust Graph Isomorphism, Lasserre Gaps, and Asymmetry of Random Graphs</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gAsQsEMgWU0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
it's a great pleasure to have you on Joe
here so Jana is a student at Carnegie
Mellon University on his greedy agent
this year you undone some excellent work
an approximation algorithms and today
hillel tell us about one of his recent
results thanks so yeah I'm going to talk
about the hardness of robusta graph
isomorphism the circus and the symmetry
of random graphs and this is a joint
work with Rio no John right and chungu
and most of the slides here are made by
Mike closer John right so like there are
three terminologies in the title is a
quite long title there so the robust
graph isomorphism the litter gaps and a
symmetry of random groups so I start
with the first the definition of the
first term the robust graph isomorphism
I'll motivate the definition with this
example say we are given this graph
which is yesterday's to facebook graph
so the nodes represents the users and
the edges represents the friend
relationship so here is me and here is
my courses all right and we are given
and here we are given another copy of
yesterday's facebook graph and somehow
we scramble it now if we put these two
graphs as input into a graph isomorphism
algorithm a so we expect such an
algorithm tell us that yes these two
graphs are the same graph and the
algorithm should also unscramble the
second graph right but let's look at
another example so we are still given
this first graph as yesterday's facebook
graph and here we are given today's
facebook graph we see that it's almost a
same graph except there are few
difference in SE like me and John became
friends and some other two users the
different each other so here are the
differences and now we
also a square both this second graph and
put them as inputs into the graph
isomorphism algorithm a now a will tell
us that no there are different graphs
and it just terminates so this is a good
it's like it is what we should expect
from a graph isomorphism algorithm but
it's a little unsatisfactory because
they're almost the same graphs so the
question now is can we detect this
almost isomorphism and if so like can we
a scramble the second graph right so
this motivates us to define the problem
of robusta graph isomorphism at a high
level it says that given to almost
isomorphism almost isomorphic graphs and
the goal is to find the best isomorphism
between them or like something pretty
close to it so I'm going to like to
define this more indeed even more
details but let's start with some basic
definitions such as isomorphisms so I
symbolism is just that by jection pie
between the vertex sets of two graphs VG
and vh we say pie is the isomorphism is
like for every edge using the geograph
after we apply the permutation of the x
direction pie the resulting edge is the
edge in the h graph and vice versa so
for example we have these two graphs and
we have this permutation pie we see that
so this edge is mapped to this edge and
so on and let's now modify the
definition a little bit so it is
equivalent to define that a pie is the
isomorphism like let's assume first the
two graphs has the same number of edges
then this pie is the isomorphism if and
only if the probability over this
uniform distribution of the edges of Chi
and then we choose this UV a random edge
and we apply
pi permutation and the resulting I GSA
edging H graph there's no that's it
different but now we can multi vases to
defy something like close to an
isomorphism so we save this pie is the
alpha as a buff ISM is this probability
is alpha okay so still like if this oh
yeah so we are so here we assume like
the to grass has the same number of
edges or like they are very close
network the numbers are very close
yeah because we really care about like
whether two graphs are very close so if
they are number of edges differ a lot
there already not very close so now we
look at still let's take a look at this
isomorphism pie we see it's chilly where
isomorphism and for a different mapping
say this pie is we can just do some
simple counting and see this is a
one-half isomorphism so a very simple
fact is that if the two graphs have a
beta isomorphisms in there are
isomorphic we offer is less related so
with this definition we can introduce
the problem of approximate graph
isomorphism that is say like we have two
constants C and s for secret Ernest we
want you so the cs approximate graph
isomorphism problem wants us to
distinguish whether is g and h RC
isomorphic or they're not as isomorphic
so the simple fact is that for this one
comma s I psalm of approximate GI so
graph isomorphism it's no harder than
the normal graph isomorphism because the
normal curve is over it's a 1 comma 1
approximately graphics on what we do and
but if like we make this completeness
factory like this number 1 to 1 minus
epsilon is now it is not very clear like
how hard this problem is and actually
this problem relates to the robust graph
isomorphism problem so for graphic
robust graph isomorphism problem we are
given to graph G and H which are like
very close to be isomorphic say y minus
epsilon isomorphic and we want the
algorithm to output a isomorphism which
is one minus of function R of epsilon
and this our ff7 goes to zero as epsilon
goes to 0 so this means that so if they
are really close to isomorphic to be
isomorphic we want to certify that they
are very cool
so this robustness of this algorithms
are like studied before like for the
constraint satisfaction problems so we
we propose before we propose a Kirk we
propose a conjecture that characterizes
all the constraint satisfaction problems
that have a robust algorithm and the it
was later confirmed by barton kazakh and
we also introduced this robust require
isomorphism in another paper and we gave
a robust as graph isomorphism algorithm
for trees so a very interesting question
is like for other class of graph such as
plant planar graphs that do they also
have robust qualify so my freedom
algorithms okay so uh also for the graph
isomorphism for the approximate this is
a brief history of the approximate graph
isomorphism problem so either it is it
was known that when the two graphs are
dense say like the number of edges is
omega n square then this problem can be
where approximated but in our talk we
are mostly interested in the sparse QWOP
say like the number of edges is renewing
a and the arvind the door they also show
some harding software approximation
results for this for some variants of
this approximate graph isomorphism but
they in their problem the vertices have
colors that is easier to show hardness
result so now with you always the grass
without colors and the for the graph
isomorphism problem it is same famously
it is not known to be whether impure NP
complete and there are some evidence
with that it is not NP complete so now
the question is whether what about the
robust graph isomorphism problem and so
this is one of our main results we prove
that assuming some the five years random
3x or hi Paula
is there is no Polly time algorithm for
robust graph isomorphism ok so in more
technically we show that there is a
constant epsilon 0 such that for every
positive constant epsilon there is no
party time algorithm can distinguish
between 1 minus epsilon isomorphic or
like not being 1 minus epsilon zero
isomorphic and so in other words this
your bus graph isomorphism problem is is
hard and actually like after we after
our pic we submitted our paper we also
got some better results like instead of
assuming the randoms 3x or our
hypothesis we just assume our P does not
equal to NP we get the same result and
so this is our first result and now let
me introduce our second result but
before that let's look at the past
algorithms for the normal graph
isomorphism problem so the first
algorithm is just brute force search it
takes into the factorial time and there
is there was this a pretty famous
algorithm framework or algorithmic
framework or with failure limit
algorithm it is there some lifted
algorithm for the color if I'm in a
rhythm so it also takes roughly order of
n factorial time but it is a quite
useful in the sense that later like bye
bye Anna looks they combine this
algorithm with some other group theory
techniques they were able to bring this
running time down to the two to the
square root n log n so this with failure
limit algorithm is pretty we are known
heuristic for the graph isomorphism
problem and it has a it actually has a
this a parameter K and it for a fixed
Kate groans tip
in time angel okay and 1k is bigger it
takes more time but also more powerful
and it is quite interesting to us as
like some somewhere in the optimized
optimization community this work they at
this recent work they show that this
with fail early May algorithm is
actually it is powering is actually
almost the same as the level K strata
Adams linear linear programming
relaxation so this is quite interesting
because while it issues that the tub l
and the shredder Adams there almost us
have almost the same power in terms of
graph isomorphism and force the shredder
items LPS usually like called the super
elf is like very strong and indeed yes
the face very problem so just write the
European see whether it is feeling
so indeed like even in on the other side
on the graph isomorphism community there
was once like it was speculated that
this wao whatever strata Adams algorithm
can consult could solve graph
isomorphism even for a very very small K
equals to logging other of logging but
this was later this conjecture was later
refuted by its high fever and a merman
they showed that for some graphs in
order to prove that these two graphs are
not isomorphic you actually need k to be
Omega of a 4 w or shred items okay so
but back to our strata atoms view social
items is a very strong LP relaxation but
still we can ask questions like can we
use some even stronger relaxation to
such as s dps what about lesser or sum
of squares which is like super duper stp
okay so let me first introduce our with
us so we in this work we show that using
like strong stp relaxation techniques it
actually does not help we show their it
exists some graph such that they're
actually they are very far away from
being isomorphic there's a point nine
nine nine they're not point nine
isomorphic but the lesser hierarchy the
linear run the hierarchy thinks they're
isomorphic okay so this is our second
result the condition of 1-2
I saw me oh it's just as like the so
they are not a there exists some
permutation of the vertices such that if
you permute the vertices of the first
graph and so let's say y minus epsilon
fraction of the edges in the first graph
overlap with the second graph and you
assume the two graphs has the same
number have the same number of edges did
you know at this epsilon zero in the
results how it's also other any
algorithmic sort of lower bounds on
epsilon zero did you know but it weather
like so you get maybe something like
quit your own that's very bad Nigel's a
year but the bit do you know that force
on force also something you can
distinguish one minus small epsilon than
that actually that's a very good
question i think i suspect that you can
even the true answer might be like one
comma delta 4 4 eva every constant Delta
but we don't know how to prove it yeah
so the way I mentioned that in it and
even one welcome Adele to you I before
for for lesser oh god harness is like
what myself silent come on down okay
I but you don't keep any hardness on
there any other condition so these are
not give any hardness essential that's
sorry this does not keep in your
hardness or graphics an orphan ah no no
this so our first result give harness on
your bus professional is the previous
one but this one only says that for this
lesser hierarchy you cannot not only the
fails to do the exact graph isomorphism
but it feels significantly so so in
terms of how do you prove it like so one
slide well it's like a wewe actually we
look at the the previous work by a few
moments they showed that the shredder
items cannot distinguish tune isomorphic
graphs so actually they are basically
their work is basically like a reduction
from the three XOR instance so we also
we use this observation and use the
random three XO are so things like it
was known before by shadow back that the
random three XO r is hard for lesser and
we use this reduction but there are
several new ideas we need to introduce
ok so you oh he goes random 3x
so the two results are basically uses
the same proof so so in a sense of that
let me just try to show the proof of the
our first theorem which is assuming
random three XO are there is no
polynomial time algorithm for a bus
professora okay the definition just
robots your bus graph isomorphism is
just to say that say you are given two
graphs they're really really close so
the algorithm algorithmic a task is to
find out a permutation to certify this
which more technically saying like if
they are why minus epsilon close the
output of your algorithm should be a
isomorphism which is one minus function
of epsilon f of epsilon such that this f
of epsilon goes to zero as epsilon goes
to do think of apps I iff epsilon being
with some square root epsilon or even
like well over a log when website
something that goes to zero as epsilon
which we do
I'm just give anything for the regular
club I supported on this reason
Draculaura let me see Charlie I got a
robot so thank you for that I say that
the graphite the one with name is hard
NP hard I'm not appear on how kind of
partisan Givens is rope
oh okay yeah dad probably should not sit
okay so yes else here is our reduction
um yeah one thing of type you're an MMA
is that actually there the gap there gap
is really really small like the air gap
is 1 comma 1 so there are two graphs
only differ by wedge we we need to make
it like constant apart so our reduction
is our proof is a reduction from the
three XO are so here is a 3x our
instance so we have all these linear
equations and each linear equation is a
modulo 2 and it only has access to three
variables okay and for every equation
they are there are three related three
variables has like four possible ways to
satisfy satisfy this equation right for
example this is the four ways and this
is a other four ways for the other
equation so and so forth so the goal is
to find out the assignment to satisfy as
many equations as possible and this is
easy one this instance is satisfiable we
can just use Gaussian elimination and
but it once it is almost to be in
satisfiable so 1 minus epsilon
satisfiable then a theorem by hostesses
that we cannot even find out the
solution that satisfies a hard plus
epsilon of the equations in other words
like we cannot distinguish whether this
instance is almost the satisfiable or
far from that it spins on its variable
and so we want to use this to prove that
for graph isomorphism it is also have
this style of hardens
okay so this is ideally we want this
reduction so that almost satisfiable the
3x for instance is reduced to a almost
to almost isomorphic graphs and though
if the instance is far from being I
satisfiable then we have like two graphs
that are far from being isomorphic so
the first step is quite usually quite
easy but there for the second step we
are we currently we don't know how to do
it we only know how to make this work
for most of the non satisfy both far
from satisfied with 3x are instances
which I mean the random instances so
this is the definition of a random three
XO are so say the randomest 3x are has a
variables and M equations and this M
equations are chosen uniformly from the
ancient reap ossible triples of of this
variables stay right we have the first
trip oving x1 x2 and x3 and the second
being X 3 X 5 and X 7 so on so forth and
now we write the equations like this but
we leave the right hand side blank now
to decide the right hand side we just
flip a coin for each flipper and biased
coin for each equation and to make sure
they are like a independent it is quite
easy to show that as long as the number
of equations is pretty largely much
bigger than a then with very high
probability every sign Minh Tran satisfy
the most of fifty plus a small number a
percent of the equations so the five
years random 3x of our hypothesis says
that there is no Polly time algorithm
that can distinguish between almost
satisfy over a 3x or instance and a
random 3x or instance that since the
randomest reacts our instance
is pretty far from being satisfiable
okay so this is a quite well believe in
the some standard complexity assumption
that is why they're using some other
results and the current best algorithm
for this problem takes time to to the
aim by logging it's a almost exponential
time so now we assume five years random
3x our hypothesis and we want to do a
reduction from a random 3x or instance
such that or from almost satisfy for
instance such that this almost satisfied
building since still goes to our sites
file almost isomorphic pairs of graphs
and the random a random 3x our instance
which are far from which are which is
still far from being satisfiable goes to
a pair of graphs that are far from being
isomorphic with hyper bit yes
so now we define our reduction so we
want to a at a high level we want to
define this reduction function graph to
map 3x or instance to a graph suppose
now we have such a function but now we
need actually we need to produce two
graphs what we do is we start from this
3x our instance I and we make another
copy of make a very similar copy of I we
quite a tie which is we just so we
preserve every equation but change the
right-hand side to all zeros we Corey
said I just because now said I is always
this instance it's always satisfiable by
the trivial assignment all 0 constant 0
assignment okay and the suppose we have
this reduction for single instance now
our pair of graphs is just the graph I
and the graphs at I gruffly is like I'll
define later is a reduction function I'm
modifying the next slide ok so now I'm
going to define this graph this graph
function I first define how some gadgets
which with which works for a single
equation so we call this zero guided
because it works for the equation with
right hand side 0 and for the right hand
side being 0 they have all these
assignments which satisfy this equation
in all these assignments they are even
number of ones right so now in my gadget
I have these six vertices in three
groups we call them just like say the
variable plops or variable clouds for x
and y and z ok and yeah each card they
are like two vertices when each one
represents the assignment for X say 0
and 1 and we also have this equation
religious they are four of them each one
corresponds to
a assignment as that is a satisfying
assignment to this equation there four
of them and now i connect edges that is
i I just connecting the obvious way I
connect every equation radix to the I
connect three edges out out from it to
the three one of each I ready variable
blobs with the corresponding assignment
okay so for this one because XYZ they
are or map two zeros i connect to x0 y0
and z0 and also for this way i connect
to x0 y1 and z1 and so on so first a
final final has some graph like this so
this is a little messy so i'm going to
write it abstract it in this way so this
so this cloud is represents the equation
reduces for this equation and this truth
three smaller clouds represents the
variable reduces okay and similarly i
define the equation one gadget which
work for the equations with right hand
sign one it's just very similar i define
this equation releases and variable
releases and connect to the
corresponding edges and i also a Strakka
dating this way so we see like both the
one gadget and the 0 gadget they
actually why I abstractly out zoomed out
they look the same the only difference
is like hi connects the edges between
this equation vertices to this to this
variable reduces so now finally I'm
ready to define this graph function so
in the resulting graph i will have
equation clouds for each equation that
is each cloud i have three four vertices
corresponding to the for satisfying
assignments no matter whether it is
right hand side 01 right and for the for
each variable
I introduce this variable cloud which
contains two variables and the obvious
use a very obvious way to apply the
gadget that is for each equation that is
0 equal with right hand side 0 I I put a
0 gadget here and for this one the
right-hand side is why i put the one
gadget here and so on so forth so
finally I got this graph and take a step
back our final reduction is that because
I will need to grass so we take both
this instance the original instance and
the instance the set site is set
instance and apply the graph function to
both of the instances I have the two
graphs gah so this defines our with the
reduction any questions and now we need
to show this company's case than the
soundest case ok so the company's case
is pretty easy so for we need to show
that for almost as follows 3x or
instance with the two graphs are almost
being isomorphic so for simplicity I
just show it for satisfy those 3x or
instance i'm going to show their
isomorphic so it's just we do it in the
obvious way that is that it so assume
that we have a assignment f which is a
satisfying assignment for the instance I
we let us use this F to construct an
isomorphism pi between G and H so this
is how we construct the isomorphism for
each variable blob the two vertices are
mapped to the corresponding two vertices
there if if if this variable if is
assigned to zero that is if it is a sign
to zero the pie maps x1 comma 0 red X to
the zero vertex here and when we're
vertex to the one vertex q
and if x2 is assigned to one we swept
the the the mapping that is I mapped the
zero radix to the web verdicts and I map
the web reading 20 projects and so on
and now how do you map the corresponding
we want to map the Chris the the the
equation where it is here to the
corresponding equation where this is
here how do we do it we need a simple we
need an observation that is so for the
right-hand side for for this graph we
all the gadgets so we apply our 0
gadgets because with zero out all the
right-hand sides so then we need to say
that if this equation is indeed with
right hand side 0 therefore here is a
also a 0 gadget then for every even
assignment because because f should
satisfy this a sign this equation so you
should be an even assignment there there
is an isomorphism between these vertices
to this realization given that the
bottom variable releases are fixed and
similarly if this if this is a one
gadget therefore every other assignments
there is an isomorphism so let me just
demonstrate it by a wine example say the
right hand side is the 0 gadget and here
we have a one gadget I'll say we have a
one equation we choose this assignment 2
x y&amp;amp;z so the pie maps 0 2012 14 X
because X is assigned to 0 and so is 4y
for this web so it maps 021 maps 120
because these assigned to one assigned
by one and now we we say there is this a
isomorphism for the for the equation
where it is
let let me just check it is because up I
only swear this dear is that you we can
check that for this 0 0 1 vertex on the
right hand side that we map in 2000 and
we see that all these three edges are
preserved and we can also check that for
this release to these verdicts all the
three edges are preserved and so on so
you can just trust me that there is
always a way to map the equation where
it is such that all the edges are
preserved so we can we can construct
such a pie which is indeed isomorphism
between G&amp;amp;H okay now we come to the Sun
is that is we want to show that for
random 3x or instance it is far from
being isomorphic and I'll cheat for most
of during most of the time so but what I
say might not be correct but they can be
corrected so we want to show that for
random 3x or instance with hyper video
in our reduction we got two graphs that
are far from being isomorphic so we
usually would do the contrapositive that
is whenever the two graphs are almost
isomorphic we can decode a MMA
assignment such that which almost
satisfies this instance I but now let's
see what must be true about pie so
indeed like most of the pies can go
crazy that is it can matter like some
equation vertex to some to some variable
vertically can map some variable
verdicts to some equation verdicts and
also like map some equation vertex to
some equation verdicts which is not
which not belong to the same equation
right we don't want this to happen and
you can believe me that we after doing
some tricks then if pi is very close to
being isomorphic then none of this will
happen what will we what we can
guarantee is almost like this up high
maps all the equation release in the
same blob to other equation reduces in
the same plum they might not that might
not be the same then might not be
corresponding to the same equation but
it must be like from one block to the to
the other plumber also for it's also
true for this variable blobs okay but
actually this this is what we dream for
this scenario that is not only what I
just said was true but also it indeed
maps the this blob from Equation 1 to
the to the blob to in equation 1 in the
in the in the autograph I mean you maps
the corresponding blobs so you you can't
believe me that if pi really looks like
this the rest of proof should go through
really easily we can just decode the
assignments for this X I spy like
whether they're map from 0 to 0 of 9
from 0 to 1 but sometimes this fails
what why does this feel so a simple
answer is that it fails when the
equation graph has lots of symmetry that
is taking this take this for the example
that is say like for the first equation
we have X 1 X 2 X X 3 and the second
equation has x3 x4 and x5 and third one
has x5 x6 and x7 in this case what does
G and H look like she looks like this so
at a high level that zoomed out level
they looked like the zits right and now
app I could just map
equation 12 equation 2 and y are mapping
this x 1 x 2 x 3 2 X 3 X 5 X x2 x3 x4 x5
now we see that all these edges some
maybe you can still be preserved to all
these edges and also for the equation to
you can be mapped to equation 3 by
making x 32 x 5 + x4 2x6 and so on so
you can imagine such case might happen a
while like pie is still almost
isomorphism or even exactly isomorphism
I in this case we don't want this case
because now I for a variables x3 is
mapped to x5 and we don't know how to
decode it alright so this is not what we
want it but since this graph is produced
randomly we we want to argue that random
graph usually don't have this kind of
symmetry so then we usually get our
dreams scenario and this is our dream
scenario and the proof go through so
this is a high level of the proof of the
soundness and now let me just say a
little bit about our last topic which is
robust asymmetry of random curves so a
symmetric graph is just a graph that you
can rearrange the vertices to get back
to the same graph so say like all these
are the same symmetric groves because
like you can it's just obviously the
symmetric growth and this is not
symmetric so formally we say a symmetric
graph is the graph with a non-trivial
autumn ilysm by autumn autism I mean is
just the isomorphism between a graph and
itself and the trivial alchemist
it's just the identity mapping so ass
image a symmetric graph is a graph which
has an automatic which is different from
the the trivial identity mapping so the
asymmetric property are a symmetry
property of random graphs are studied
like we're studying a long time ago from
or those aren t they showed that it's
GMP model in GNP model random graph is a
symmetric with hyper-v when this piece
bounded between a log n by n 2 1 minus
log in by day and it was also shown for
random d regular graphs but in our case
first is a random graph with exactly M
edges and actually they're hyper graph
but these are like some technical issues
we can deal with but indeed the main
problem is that we not only we want we
want something more than is a symmetric
prompt a symmetry property we want your
bus as symmetry because so now we define
a permutation pie to be I f F
automorphism just as we defined for the
offer isomorphism that is this
probability is alpha for G&amp;amp;G self ok
so now let let us ask does the random
graph G has a good advice isomorphism of
course because it everywhere has the
autumn one autumn of ism which is the
identity permutation so we cannot use
this definition just pick the same as
the previous reason so another
definition we might use is we ignore the
identity permutation test g have a good
I fav I automorphism but still this is
always true because we can always take
the identity permutation and just swept
the first two bridges we see that not
there are not many edges to be affected
in this way so it's still a very good
automorphism so our final definition is
we want G to have we asked whether G has
alpha automorphism which is far away
from the identity function or the
identity mapping so indeed now we have
our theorem which says that let g to be
a random graph that was hyper visit any
other morphism one any very good
animalism y minus epsilon autumn ilysm
4g is is epsilon close to the eye to the
identity function for any pretty large
for any pretty large epsilon this so
there are some restrictions on the
number of edges and this epsilon but it
is enough for our application ok so this
is a high-level proof and there are some
open questions so the first way is still
we assume we prove our harness assuming
our penal you go to NP so can we make it
just the MP company NP hardness proof
there we need to explicitly construct
the some graph that are robust
asymmetric a symmetry so currently we
know that random graphs are such graphs
with very high probability
but we don't know any great candidate
graphs I mean for deterring
deterministic construction once we get
that it will give us a NP hardness proof
for the robust require isomorphism
problem so the second problem just as
cost you asked before like can we
improve the harness gap for your bus
graph isomorphism so here is our theorem
we say like for every epsilon we cannot
distinguish whether it is 1 minus
epsilon isomorphic or 1 minus epsilon
zero not isomorphic but this is this
epsilon zero is really really bad it's
like 10 to the minus 14 your paper
although we didn't try to optimize it
but it still is really bad so I'm not
sure whether it is a worse or better
than the that constant in the Chris one
in PG PG room but in the PCV theorem you
can always use parallel repetition to
you can you always use parallel relation
to amplify the gap and but for hours the
question is there some procedure is
similar to the parallel repetition to
amplify this gap and well attempt is to
try the tensor product so given two
graphs that let us tickets tensor in
this way we know that the two graphs if
under some mild assumptions the two
graphs year if originally they are not
isomorphic then they're tensors are not
an isomorphic but what we really want to
know is whether given their a little far
from being isomorphic are there tensors
much farther from behind some of it this
is so this is our second open question
and that that's all what I'm going to
talk
questions so this you didn't talk much
for the gap
no what's up
both of them
oh so the integrated gap follows related
by the same proof so the B course the we
we use the channel box integrated gap
for random three XO are so the sum needs
which is the most technical parties both
the hardest part is the same we only
have to show the companies in the in the
lesser language but that is usually you
can expect it to be to be true
until unit this X or conjecture or fall
off air gap your epsilon 0 is equal to
an app or big because
so so so so so you have hard as a human
the turkey is not a good idea miss
Henderson your life ppm but for 44 44 x
or before if you assume the finest
conjecture that you they give you
then can you show coordinate where
episode here it is going to hop it's
hard to do to do to distinguish
instances capsule and 19 essential
buzz
so you're asking cash it is there a gap
like 1 minus epsilon come one half plus
a plan yes indeed
I don't think so so so I don't say why
like what Harvey is important for it's
like magic for graph isomorphism right
yeah but you're right like if you're
given like a one come over to gap you
usually only expect to show a bigger gap
but I think though yeah the the most
cost that does not come from this guy is
from some other procedure today for
inviting to conjecture isn't hard so
essentially you get hard part this is
half plus epsilon 1 minus s right or so
random lessness will be a professional
yes it is fun but there you can always
use some like extensions of that
construction like not not our much about
you you do your modulo Q somehow you can
always assume a very big gap still like
using that pickup I don't think we can
get something sickening I can just give
yourself in giving in your proof of
variables to say I mean why don't you
get the same to see why half the same
gap at is in the original sort of 0
because there are many ways to lose is
so we need to say we need to make sure
that the equation block goes to the
equation blob is like we need to act add
some extra edges and there we we already
lose a lot yeah
so yeah you use some averaging argument
that you easily easily lose a lot
no questions
but things are speaking here</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>