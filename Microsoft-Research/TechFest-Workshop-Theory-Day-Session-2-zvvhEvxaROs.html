<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TechFest Workshop - Theory Day - Session 2 | Coder Coacher - Coaching Coders</title><meta content="TechFest Workshop - Theory Day - Session 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TechFest Workshop - Theory Day - Session 2</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zvvhEvxaROs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
I'm actually pretty excited to be giving
this talk here today because the problem
that i'm going to be talking about is a
problem that i started thinking about
actually during the beginning of my PhD
and i had this problem and i really
really wanted to be able to present it
to my call committee during my
qualifying exam so I worked really hard
but you know I couldn't really get a
result so I said okay okay maybe it
won't happen for mike wall but maybe in
my dissertation at least I can say
something about it one year went by two
years went back dissertation Karen went
still no result and so finally now here
is a postdoc at emisora and working with
yuval and jion I'm able to say something
about the converse result here and so
I'll tell you about this long-term
problem that I've been thinking about so
before I get into details the problem
that i'm going to be talking about today
is really motivated by developments in
the Internet of Things and today we have
these control systems like package
delivering drones or self-driving cars
or you know autonomous home system that
sometimes cats right on that are
interacting physically with the real
world and control is a natural way of
trying to understand and model these
systems but when we're dealing with the
systems we might be controlling them or
observing them over unreliable or noisy
communication channels or the models
themselves might not be precise they
might be changing rapidly and so we need
to really be able to understand kind of
the fundamental limits on systems like
this so for example if we were to think
about a drone that we're trying to
control but maybe we only have some kind
of unreliable measurements about it
sexual position yet we want to have it
you know fly in a certain way how can we
understand systems like this so in
today's talk I'm going to be talking
about a very simplified model for
problems like this
and explore what we can say about this
model so the simplified model is going
to take the following form I'm going to
have a system whose state I'm going to
monitor and I'll make all of this
precise and this state will be given
maybe some noisy version of this will be
given to a controller and the controller
then wants to put an input back into the
system so as to stabilize the system or
have the system go according to the
trajectory that the controller wants it
to go in so to make this somewhat more
precise let's think of X being the state
of the system and n is a time index and
I really want to think of X as being
kind of the error from the desired
trajectory so we really want X to be
smaller you want it to be you know going
to 0 let's say we have some initial
state that's a random variable X naught
is just a normal 0 1 and this system
involves according to the following
equation that X at time n plus 1 is a
times X of n minus this control you open
so is a scalar all of the system
variables here are scalars is somehow
known to is known to us um and this
control you can basically be any
function of this Y which is what the
controller gets to observe about the
state X and you know you can be some you
can you can use memory it can be linear
nonlinear whatever so now the question
is really what is this observation and
how is this observation what is the kind
of thing we're going to consider so in
this setup in this problem I want to
consider this channel as being a
multiplicative noise channel so I want
to think of why as being Z n times X of
n where Zn is draw an iid each time from
let's say this normal one Sigma squared
distribution and Sigma squared is let's
say known to us and this kind of
multiplicative noise channels can model
synchronization errors and
stands or they can model quantization
errors for example or you know
particular kinds of communication that
is happening over for instance a fast
fading channel these are the kinds of
things that can be modeled and that
we're trying to capture in this kind of
system yeah xen is Xion Xion is
independent of all of the XS and they're
all iid over time yeah yes the additive
problem is very well understood that
comes down to basically being a common
filter and there's there's the the
additive noise problems actually have
been widely studied and are quite
understood but multiplicative problems
or problems where we don't have a
precise model are significantly more
challenging and this is some work that's
kind of moving in that direction so
finally with all of this what is our
goal our goal is going to be made to
make sure that our system error does not
grow too large so in fact in particular
we want to look at the second moment of
the system and we want to make sure that
this is always finite so this will be
our goal going forward so there has been
a lot of work thinking about problems
that are similar to this in the control
literature I don't have time to go
through all of this but I want to point
out for example the common filtering
work is you know obviously very relevant
which considers additive noises but the
one piece of work I do want to highlight
is the case where the system state X is
observed over a rate limited channel so
the controller gets a finite number are
bits about the system state and again
the system evolution is exactly the same
here we have a very nice and clean the
result that says that this system is
stabilizing that mean squared sense if
and only if the information transfer
across this channel is larger than log a
which is the growth of the system and
there's a nice intuition about this that
I can explain later if
if people are interested but with this
background I want to now move towards
the bulk of the talk I'll first talk
about a linear achievable strategy to
say you know how can we possibly stratus
stabilize the system and think about the
most simple thing we can do to do this
and then I'll move to the second part of
the talk which will be the converse
result which will be the kind of main
heft in the talk so let's try and
understand this problem and let's say
well what can a controller do and let's
consider the most simple linear strategy
by which the controller says well what
do i have i have y let me scale it
somehow appropriately and what's the
best i can do right let me not even try
and use memory nothing let's do the
simplest possible thing so let's see
let's evaluate this so we just
substitute this into our equation we get
the following evolution and now when we
think about this will very interested in
the second moment right so let's square
this when we square this we see that
what is really of interest is this
quantity the expected value of a minus d
x ZN squared and this we know exactly
how to calculate right we can just I can
just rewrite this as a minus d squared
plus d squared Sigma squared I want now
to have this system be stable so I want
this factor to be less than 1 and in
fact I wanted to be as small as possible
so what do i do I differentiate I can
find the optimal d right nothing
complicated simple stuff and I you know
solve the equation i find that d is
equal to the optimal d is a over 1 plus
Sigma squared great further I can say
well when is this factor less than 1
which will tell me when the system is
stabilized by using this strategy and I
get some condition like this this is
great but I want to actually rewrite
this condition in a different form and I
want to say that this system is mean
square stabilized abell if using this
linear strategy if and only if log a is
now smaller than half log 1 plus 2
squared and this formula is kind of cute
right it reminds us of the half log 1
plus snr formula from from information
theory so this is kind of nice and you
know this cuteness brings me to one of
the nicest pictures in the talk for
those of you who are wondering where the
title is coming from we're saying well
in this regime the system is definitely
not any kind of tiger it's actually kind
of cute and tame if log a is bounded in
this particular fashion so but now that
we have this I guess we can move to the
more ferocious part which is really the
converse so you know what kind of
converse would we want to have what
would we expect to have will be only
considered in the past achievability be
considered this you know memory less
linear simple strategy we can actually
improve that to show that actually this
particular linear strategy is the
optimal linear strategy memory doesn't
help in the linear case but we don't
know if that bound was coming from the
fact that all we're only looking at
linear strategies or if some kind of
nonlinear memory full strategy can do
much better so what we would really like
is something that says well oh if log a
or a is larger than a threshold then
your second moment must be unbounded it
had better explode to infinity turns out
I'm going to prove a slightly different
result it's actually a stronger result
that says that I'll give you a threshold
for which stability in any reasonable
sense is not possible and so the
statement of the result that we have is
the following is that if a is larger
than some threshold that depends on
Sigma then for any control strategy we
want to look at the probability of X
being bounded within the box and the
probability this probability of it being
bounded itself is going to go to 0 for
any box that you choose and so this
obviously implies that your second
moment is going to be exploding right
because you cannot even be within a
certain box if you're choosing so forget
anything about the second
which then brings me to the next nicest
picture in the talk this is not a system
you want to try and tame okay any
everyone with me till now okay so now
how do we go about proving this result
and that's what I'll be talking about
for the rest of the talk the first step
that I really want to do is I want to
think about a reduced system I want to
set I want to start ignoring this growth
factor a so I'm going to drop the a here
and consider the system with a equals 1
and for the rest of the talk I'll
explore only this particular system and
hear what we can see is that if I want
the original system to be bounded within
a box of size M I want this non growing
system to be to fit into an
exponentially shrinking box so I want to
instead look at this probability that xn
with this system is now in this box that
keeps shrinking by a factor a as as time
goes on so now that we're looking at
this modified system given that we have
all these past results on rate limited
channels and how to understand them it's
natural to think well you know you have
some kind of channel here and additive
noise is well understood that was as was
pointed out can't you build on some of
those techniques to get somewhere so the
channel that we have is really something
like you know y and z times X n so you
can say that log Y n has just log X n
plus log is ian and if we could bound
the rate of this channel that might give
us an approach but turns out that in our
particular problem the range of xn is
actually unbounded and we don't know
what this you can do to the distribution
of X right like it can change things in
any way and so getting a bound on this
the rate across this channel is going to
actually be like we can't we can't do
that so the standard approach of having
a rate limited channel is actually going
to be going to be hard and we can't
use this this this approach so yeah the
posterior distribution of X and it's
always gasps oh no you can't because
you're adding basically a correlated
random variable you and you you know
will be dependent on X and so like you
you don't know what the controller can
do distribution of xn given the entire
sequence of use the conditional
distribution of xn given the entire
sequence of yours will be golfing but
you take that mixture of ghetto sites in
your losses but yeah but you don't
actually have Gaussian Eddie and so you
can't actually say anything um okay so
what is the strategy that then we want
to look at and so this was one of the
key new ways of looking at the problem
and so the the approach this problem is
different from the way of control
theorists and information theorists have
been looking at this problem so far and
what the proof does is actually it looks
at this object which is the density of
the system state X at time n and you
know I'm just conditioning on basically
everything that the controller nose up
to time n and I'm looking at this object
and remember what do we want to do we
want to look at the probability that xn
is going to be in these intervals that
are shrinking exponentially so if we can
say that actually this density is upper
bounded and we can give some exponential
upper bound on this then we can say that
actually the controller cannot know with
this exponential precision where the
state is and if the controller doesn't
know where the state is it's not going
to be able to hit it and control it
right so this this is this is the
approach that we're going to take to
prove that the converse style result so
to do this we really want to understand
the effect of these observations because
that's what's going to make this density
become peaky so what what do we want to
really understand
really want to understand how does this
density change every time the controller
gets a new observation right because
that's how the controller can do better
so I really want to compare this pink
density which is basically the density
based on everything the controller new
at time n minus 1 to the black density
which is now with the new observation
included and I can just rewrite this as
in this form and now it's natural to
want to use Bayes rule to kind of
separate these effects out so when I use
Bayes rule I have this pink term which
is kind of the term that I want to
relate this to but then I have this
denominator right and it's like the
density of Y conditioned on all the past
and I don't really know how to deal with
this it's something complicated so we
say ok let's try and avoid getting into
this mess and note that here there's no
term X so the idea is to just say let's
take the ratio of densities and so that
this denominator term will just cancel
out because I like this I like the I
like being able to deal with this
recursive form at this term i'm going to
be able to deal with eventually so i
take the ratio to be able to remove this
denominator and so now i want to look at
the ratio of the densities of f of
little x given my observations / f of
little X at some w given my observations
and I'm just taking the logs here to
make just to make things a little bit
easier so now my denominators have
cancelled out and what I have here in
pink is this nice recursive term that I
want to recurse on to get my bound and
now there's this blue term here which is
basically the condensed conditional
density of Y given what exes but what do
we know about why why is just a Gaussian
times X and so if I know that xn is
equal to some little X the density of Y
is conditional
city is now just the conditional instead
of a Gaussian which is really easy for
me to handle and deal with so i can
actually explicitly write this thing out
and so it's like okay and you look like
this i can deal with this is recursive
we're excited right everyone's excited
we can almost solve this problem okay
but now what we need to do is we need to
bound this term and we have these things
in the denominator X is going towards 0
and now we have these things that are
getting small that are in the
denominator finding a bound is suddenly
going to be a bit of a problem so this
is where the second idea in the talk
comes in which is that we have a genie
that provides side information that
helps bound on this term in the
denominator and it'll it's interesting
how this works so let me make exactly
what is happening precise remember that
we're proving a converse bound so if
they give the controller some extra
information and prove that the
controller cannot do anything that's
always that's always fine you can always
give this extra information so what is
this site information we give the site
information is essentially a quantized
version of the log of X n so what we do
is we find xn and we localize it in a
binary interval between say two to the
minus KN and 2 to the minus KN plus 1 a
genie comes along and observes this and
hands this KN to the controller and
remember what was the channel that the
controller already had right it had log
Y n is log xn plus some logs en so it
already kind of had a noisy version off
the log effect so it's not like this
Genie is actually giving that much extra
information but the clever way in which
it's used allows us to actually get the
bound that we need
and the Y dependency the Y dependent on
Sigma and the Sigma will show up in the
bound I'm somewhat suppressing that
right now just to be able to give the
flavor of the proof but it the Sigma
Sigma does show up like these constants
will all depend on Sigma yeah yeah yeah
basically they look at the precision of
the observation will dictate the kick
the can yeah exactly but what this gives
us now is this bound on the magnitude of
xn and the way the proof is going to
proceed is going to use these cans in in
a key way because now remember what did
we want to do we wanted to measure how
fast xn was approaching 0 right and
these cans are basically exactly
measuring that so first they give us a
lower bound on xn which is what we
wanted but secondly what the problem is
now becoming is we want to measure
basically how the cans are proceeding
and if we want an exponential bound on X
what we really want is we want now a
linear bound on how the K ends our cans
are increasing and really what we will
be doing is will be using kind of the
properties of the density of xn to bound
KN and then we'll use KN to bound xn so
it's kind of this back and forth between
xn + k and that is going to let us get
to the conclusion that we want to but
now thanks to our nice and friendly
Genie we can go back to the proof that
where we were and actually have a bound
on this term this trouble has now gone
away and now with some algebra that I'm
really not going to talk about so much
we can have the kind of exponential
bound that we wanted which is to say
that okay the density of X can be
bounded basically by 2 to the K n and
there's some constant here and this
constant will actually depend on disease
and on the Sigma's
but now really the problem now still we
don't quite understand this right this
these kids are still random so the
question is now reduced to understanding
basically how do these k ends behave and
here I'll introduce the last lemma in
the talk which is that the cans will
actually grow at most linearly in fact
the precise statement that will be that
the probability that KN minus K naught
is larger than some constant times n
this probability has to go to zero and
the way that we are going to prove this
lemma is in fact to look at the
increments so we're going to look at K n
plus 1 minus KN and the probability that
this is very large so basically in one
step these kids grow by a lot will show
that this actually is kind of like a
geometric this has these exponentially
dying tales and once we have this we can
have that these can't grow at most
linearly if this is very precise and you
sort of know k anything ignore wife but
physically it's not precise enough to do
it um so much all the way anymore I mean
if I if I have to distribution okay and
it's possible yes okay so it's it's it's
yeah there's there's I'm I'm think these
constants are all not actually constant
there's there's a randomness there these
are these are random constants that
depend on the Z's and the wise so I'm
like Justin in the spirit of giving a
flavor of the proof I'm like hiding the
sack but there's a lot more work that
needs to go into actually showing that
these things work but yeah so we can't
actually completely ignore otherwise
because of that listen to you yeah but
just to give now again like a flavor of
how this how this proceeds is this is
the probably probability we want to look
at which is the probability that KN plus
1 minus KN is larger than L so what does
this mean right KN is basically looking
at the order of magnitude of xn
so this means if KN plus 1 minus cared
is very large it means that xn plus 1
must have been much smaller than xn
write xn plus 1 suddenly became much
closer to zero in fact it became it
closer to zero by this you know factor
of 2 to the K n plus L and how is closer
by true to deal and when is that going
to happen what does that mean that means
that basically at time n the controller
really hit it home right the controller
got really really close to xn so
basically this UN at time n was really
close to wine so this was also bounded
by 2 to the 2 minus K n minus L but now
let's look at this probability and this
is where all our work unbounding the
density of xn is going to come in handy
because you is now measurable by FN
right you would just depend on all of
the observations of the past and so this
probability I can just rewrite as an
integral of the density of X and this
integral is going to be over an interval
J that is basically around X and is off
this length around
you and this varying around xn you okay
yes oh yes okay so we're looking
basically at the ad this integral in
this small in the small interval and now
we have a bound on this density right
basically we know that this guy is
bounded by something like this we know
that the length of j is of this order
and so now we have this expression these
cans cancel and we get now that the
probability we want it is decaying as 2
to the minus up just like we watch it so
which gives us exactly the dilemma and
once we have this we have now proven
that the cans increase at most linearly
with this known rate which means that
the X ends can decay at most
exponentially and once we have that um
basically that gives the the Congress
result and so just you know this bound
is far from tight and there's still some
open questions but yeah if you can call
it answers my question I thought it an
early slide you presented an only here
for that linear strategy my name is Ben
if an only asked for linear strategies
so you don't know that linear is optimal
you know that it's proximately optimal
in the sense that you have converse I
don't even know that it's approximately
optimal I have I have other reasons to
believe that it's going to be that you
might not be able to do that much better
than linear but I don't have a proof for
it at all I don't know that it's optimal
it's like nonlinear controllers can can
improve by a little bit but I don't know
that they can improve by a lot I don't
yeah I don't know the answer to that
other questions fine hi phone requests
yes basically yeah any other questions
you're saying anything about the your
motivation you talk about model the
specification mhm in your bottle I would
interpret as something like the COS
today is not known but you know that it
belongs to subjective bola values uh
yeah so it can use anything about robust
control policies that stabilize the
tiger for Ranger so the thinking about
actually a not being known precisely is
very very challenging and there aren't
really any results that I know and there
I know if one classical result that
talks about a very limited case of that
I've tried thinking about it a lot but I
don't have a result here the model
misspecification motivation really comes
from for example if you think of the
standard Kalman filtering model you
assume that you know your Y is C times X
plus some may be additive noise and you
ever think if maybe the sea is unknown
this observation gain is unknown and I
have other results that talk about cases
where the gain on the controller might
be unknown so you have some distribution
on it but you don't know precisely what
it is it might be changing so in that
regime I also can talk about some robust
control notions I know you can tell you
about it offline at some point so take
other questions in the coffee break</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>