<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Micro-Policies: A Framework for Tag-Based Security Monitors | Coder Coacher - Coaching Coders</title><meta content="Micro-Policies: A Framework for Tag-Based Security Monitors - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Micro-Policies: A Framework for Tag-Based Security Monitors</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vHapsqhotIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so hello everyone as it's a
pleasure today to have Benjamin peers
from the University of Pennsylvania with
us measurement has worked on many topics
ranging from types and programming
languages to differential privacy to
testing to security information flow
enforcing and synchronization and
Benjamin plot your stuff thank you okay
thanks everybody for waking up and
coming I'd like to tell you as to meet
you said about work we're doing lately
at at Penn on I thing we call Micro
policies I won't spend long on
motivation because I don't think anybody
would disagree in this room that where
we are at the moment with respect to
security of software systems is not
where we want to be a more interesting
question is how we got there and of
course there are many answers but one
that I think is interesting is the the
fact that we're still in some ways
really living with legacy hardware and
software decisions that were made for
perfectly good reasons quite a long time
ago when hardware was extremely
expensive when our ability to to specify
in verify systems was very limited and
when frankly security really didn't
matter all that much and and the result
of those design decisions reasonable at
the time was was systems with very poor
hardware abstractions and a very high
cost to too isolating system components
and protecting them from each other but
in the meantime a lot has changed in the
world in particular security is a lot
more important and hardware is a lot
cheaper so we believe that it's time to
reconsider
or the the trade-off calculus and and
see if there isn't a way to spend some
of the abundant hardware resources that
we have now on getting better security
at the lowest levels of obsessed emits
unique to us but we have a particular
take on it which I'll tell you about
them so to be more specific what we'd
like is to find a way of making hardware
better at enforcing invariants of higher
levels of the system and of course to do
that we need a way of communicating
those invariants to the hardware one way
to communicate invariance to hardware is
to build them in but of course being a
programming language is kind of guy I
would rather have a more flexible
solution and so we work with an idea
called micro policies which sounds to
Simon very governmental but in fact is
is a fairly technical motion so what I
mean by micro policies is a fairly
diverse collection of instruction level
enforcement mechanisms of of policies
that can be phrased in terms of metadata
on the data that's flowing through the
system and and we have a particular
notion of a particular subset of those
that we know how to accelerate in
hardware and it will be those I'll be
telling you about so if we succeed in
doing this the wind of course is that we
now have programmable hardware that can
support a low level of enforcement of a
wide range of policies we're able to
experiment with using those policy
enforcement mechanisms to to harden and
protect the very lowest levels of
software in systems and we have and we
have opportunities for for safety
interlocks protection at at multiple
levels
so we have not built all of these micro
policies for experimenting with a few of
them but just to give you a sense of
what we believe might be the range of of
things that one could address in a micro
policy framework here are a bunch of
things that we think are are promising
things to experiment with and I and
we've we've actually experimented with
five or six of them and and I'll show
you those today so to tell you a little
bit about where this came from some of
you may know that that for the last
several years we had pen have been
engaged in a big DARPA project called
crash safe where the goal there was to
completely redesign the whole hardware
software stack was an extremely
ambitious kind of let's do something
impossible sort of project and and at
both hardware and software levels of the
system there were many interesting
innovations which I would love to tell
you about another time but what we're
doing now and the the goal of the
present effort is more focused it's to
take just one of those mechanisms this
particular way of of propagating and
checking metadata to extract that from
the crash safe design and to and to
transplant it into a more conventional
hardware software setting so so we're
thinking now of extending a conventional
instruction set and processor design and
and we're we're also generalizing at the
same time the information flow policy
that we concentrated on in the safe
project to a wider range of policies
including information flow among many
others so where are we now we're we're
kind of in the middle of all of this so
we don't have final results to show we
have I hope interesting and suggestive
intermediate results so what we have is
prototype implementations of several
micro policies including those plus
information flow we have simulation
experiments using a simulated alpha
processor plus
supporting hardware and software to get
some idea of the performance and energy
and area and power impact of these
extensions and we have a detailed
formalization of simplified versions of
some of these things that gives us a
sense of of what it means for it to work
so what I'd like to do today is swaying
lots of Intel that actually they should
use some of them any abundant
transistors to do something like this
that is what we would like to do that's
the only feasible path to impact yes
missed it but well fortunately not just
until they're there are a large handful
of of places that you might have impact
in that way but that arm so that but
that is the ultimate the ultimate goal
at the moment the the crash system runs
on fpgas so you could imagine just
disturbing it that way but for for a
really wide impact you would want to get
some big manufacturer interested we're a
couple of design generations off from
from that being an appropriate direct
target so here's the structure of the
talk and but I'm showing you this now so
that you can kind of think about which
part you're going to be most interested
in peppering me with questions about
Thank You Simon for breaking the ice and
we can really concentrate on whichever
of these interest people so let me tell
you a little bit about the the hardware
because this gives a kind of grounded in
the reality of of what sorts of policies
we can hope to accelerate effectively
and then look at the other policies
themselves so here's the here's the idea
we call it the pump the programmable
unit for metadata processing and what we
do is so we begin as I said with a
conventional is a like an alpha we add
to every word everywhere in the system
so in
registers in caches in memory the
program counter every place there's a
there's a word of data there will now
also be a word size bundle of of
metadata why word size because that's
big enough to hold a pointer and that
means that the that the size of of
metadata structures that you can
represent is effectively unbounded so as
far as the hardware is concerned at the
level of the acceleration mechanism
these tags are going to be just bits but
at the level of software when we when we
are instructing the the hardware what to
do we can choose any any interpretation
we like either encoding the information
that we have if it's if it's just a
little bit directly in the tag bits or
letting the tag be a pointer to some
larger structure in memory okay so we
add a lot of tag bits to each word of
course this is a conceptual model and in
the implementation we may play lots of
tricks but for for present purposes
let's think of it that way these tagged
words are are going to be indivisible
atoms in the in the users view of
operating the machine and at the at the
hardware level what's going to happen is
on each instruction dispatch we're going
to pull off the tags from all of the
relevant bits of the of the current
machine state so we're going to take the
the tag on the current instruction and
the tag on the program counter and the
tag on any any registers that are that
are being used and the tag on the memory
location that's being used if there is
one we're going to take all of those
tags and look them up in a in a hardware
rule cash that that will give us back if
the lookup succeeds will give us back
the next tag for the program counter and
the next tag for the result of the
operation if there was one in the
machine state that results from this
from this step it's not a question about
application or somewhere view of the
tangy yep biography of back or as far as
as far as user level software is
concerned the tags are completely opaque
and and not directly accessible as far
as the operating system is concerned
well it's there there's a there's a
question about to what extent you want
to consider the operating system to be I
above the tagging mechanism and to what
extent it needs to be in bed with the
tagging mechanism so there's a little
bit of a bop rating system code which
I'll show you in more detail in a few
slides that handles mrs. in the rule
cash and that of course needs direct
access to the tag so it uses some
privileged instructions that let it
directly read and write the tags but but
the intention is that nowhere else in
the system even in the lowest levels of
the rest of the operating system are the
tags directly accessible okay so this is
just pictorially what I just said so
here's a conventional processor diagram
and here it is extended with extra tag
stuff and everything gets pulled off as
the instruction gets decoded and stuff
through the we usually call it pumped
now but it used to be called tag
management unit stuff through that and
then the results are recombined as
things come back around out of the AO
you it probably should okay and I and
I'm not going to go into the
microarchitecture on beyond this slide
partly because it's not really what I
want to talk about today and partly
because it's really other people's
domain to figure that stuff out but but
the basic idea is that we need to add
just one pipeline stage so this is a
standard simple five stage pipeline and
we just add one stage at the end but
does the lookup in the
in the rule cash and and combines the
result with the results coming out of
the earlier stages sage it'll well while
the ALU is computing you're calculating
new tag yeah but we need okay now we get
to subtleties that I may not be able to
answer correctly but but we need
information from all of the previous
stages including potentially the the
memory that we're that we're writing
into is for example the destination
memory for things like information flow
where you need to be careful about
things like sensitive upgrades of a
memory that you're writing to yeah so
that yeah places are you concerned for
the fact that putting their power in
some cases you have to put the top of
the end because you have to read the
memories but in other cases maybe you
want to do the pump earlier so where
other performance issues is kind of you
know how how how often you have to kind
of flush your pipelines and how many
things you have to flush the pipeline if
you put the beginning undoubtedly so I
can't speak to them because it's I it's
not even my student it's my colleague
student that's actually doing that work
so if you are interested in that level
there is going to be a forthcoming paper
about about pipelining okay so here's a
simple example of how it might work so
up there is the soft whoops sorry up
there is the software down here is the
hardware this is the ALU not shown
because its standard and here is the
pump here's the rule cash and then down
there are some ground rules which I'm
not going to talk about right now but
i'll come back to later on so so let's
say we're enforcing a very very simple
information flow policy we have we have
just two tags secret and public and
the user code is doing some arithmetic
so so in the rule cash we have two rules
one says if you add a public thing to a
public thing the result is a public
thing and I'm suppressing some of the
fields of the of the rules in the in the
full system we would also take the tag
from the pc and return a new tag from
the pc as i said but this is a
simplified version so so it says if
we're adding two public things then the
result is a public thing and if we're
adding two secret things the result is a
secret thing so completely unsurprising
rules now what happens when we're
executing the first add instruction we
pull off those tags and send them over
to the pump while the AOL you is doing
its thing so in this case suppose the
both arguments were secret well then the
pump sends back sorry sends back the
result secret that gets recombined with
the with the added bits and stuck on to
register r3 another thing that can
happen is that we ask a question that
the the rule cash doesn't know the
answer to so we ask so suppose our one
is public and our four is secret well
well now we're going to we're going to
miss in the cache and and trap to a
software service routine whose job is to
consult a symbolic representation of the
policy which says when you're trying to
add two things two things labeled l1 and
l2 and those are symbolic labels then
the result the label of the result
should be the join of l1 and l2 so that
gets installed in the cash as a new rule
and we restart the instruction but
trapped now when we ask the question we
get back the answer directly from the
cash
okay and and of course as I said we need
to have a tag on the PC also to drag
implicit flows and and the fact that
we're using word size tags means that we
can represent much richer flavors of
label for example if we wanted to have
dynamically generated principles and
have tags be sets of principles that are
expressing an interest in the
confidentiality of the data then then we
would just make the tag be a pointer to
a data structure representing a set and
then at the symbolic level we would need
to do operations like set Union and
subset and so on but at the at the
concrete hardware level we're still just
comparing bit patterns short we run the
pc from being permanently painted I'm
sorry how can you prevent the pc from
being permanently tainted so this is a
question for the policy designer and and
may take us too far afield to answer it
in detail the one way to do it without
giving a full answer one way to do it is
to just let the pc drift up continually
and make sure that you fork a new
process for for doing computations where
you want the pc to go up without without
tainting the main computation so that's
what they do in the l io system for
example in the safe processor we use the
different thing where where we identify
merge points in the control flow graph
like returning from from subroutines and
allow the pc to go down then so there
are a variety of of policies that can
work for information flow at the
hardware level and the intention is that
this mechanism be able to encode all of
them
the devoted only to sort of triggering
some policy shift on the program counter
say with um many interesting
computational person no but I'll get to
this in a second we have we have two
ways of doing that so one is you can one
is that each micro policy comes along
with some some system services that can
be called from user programs so it has a
it has a sort of hardware facing part
that handles traps and it has a software
facing part that does things like in an
information flow policy please create me
a new principle can this flavor flow to
that one and so on so that's one way of
doing it another way of doing it is is
you can make up you can tag instructions
with special tags so for example you
could have a move instruction or indeed
a no-op instruction tagged with a
special tag but that means something to
the to the rule system and and if there
isn't a rule for it in the cache then
then you're just going to trap when you
see it and now you can do anything you
want okay let's look at a few more
details of micro policies so as I said
answering Simon a micro policy really
has three parts it has a set of tags
that we're going to use for labeling
things it has a set of rules for
propagating those labels and it has a
set of monitor services or system calls
that can be made from user code down
into the down into the micro policy for
performing more global operations
involving tags and we'll see examples of
all of those shortly when we write down
the the rules at the symbolic level we
often write them with notations like
this so a symbolic policy is is
convenient to represent as just a list
of rules of this form but basically just
match on the opcode and the tags of a
bunch of things and return new tags and
might have a movie an expression saying
saying when the operation is allowed if
it isn't allowed then of course the when
a trap happens the the trap service
routine is not going to install a new
rule instead it's going to inform the
scheduler that that this process needs
to be killed do you need to know sure
the location every time ah so so no and
the reason again is that we have is that
our tags can represent pointers to
anything so so in a multiprocessing
setting what we would probably do if we
if we wanted to have many processes with
different policies we might have one
policy enforced throughout the system
but if if different policies wanted to
if we wanted to enforce different
policies in different processes all we
need to do is is add a process ID is to
make the tag be a couple of the process
ID and and some tag relevant to the
policy that's being enforced by that
process
of course doing that increases the
pressure on the rule cash and and as you
might guess pressure on the rule cash is
the is the main thing that determines
the performance of the of the system
that you get okay so here's a really
simple policy dynamic ceiling so the
tags in this policy are there's a
there's an infinite collection of tags
or a really large collection of tags
there's data so data is the tag that we
use for most things then then we have
tags sealed k which means this is a data
value that's been sealed with a with a
key K and shouldn't be readable by
anyone anyone that doesn't possess that
key so it's a kind of linguistic
hardware accelerated cryptography if you
want oh and then the other kind of tag
is key K and we use this tag to
represent keys so so so a key K is
represented as a value that we don't
care about say zero tagged key of K and
now the the rules let's jump down here
the rules look like this the the
instructions that just move data around
like store are going to insist that the
pc not be a key or a sealed thing so the
pc has to be just data and the
instruction that we're executing has to
be just data but the the source register
can be tagged anything and and the the
result of the memory location that we
that we store into is going to be tagged
the same at the end of the operation
okay so data movement instructions just
preserve tags while data manipulation
instructions like jump through a value
are going to insist that that value is
also data
then for the monitor services we're
going to need something to generate a
key so it's so new key is a is a system
call a kernel call that can be made from
user code and it makes up a fresh key K
that no one has ever seen before and
return 0 tagged with key of k and then
seal takes two arguments in into
registers one tagged v not sealed and
the other tagged and the other we don't
care what the value is tagged tagged key
of k and a returns v tag sealed of k and
then unsealed just does the converse so
with this architecture allow it to a
cryptographic implementation the
architecture doesn't directly allow it
and doesn't need it but but of course if
you wanted you could add more monitor
services for converting between the the
sealed representation and a
cryptographically protected
representation and indeed you would want
that if you if you wanted to say put
these sealed things out on on external
storage but there's some there's some
system designed to do too I'm waving my
hands here it's it's to make that really
work would not be completely simple use
the combination of the hardware rules on
the monster service precisely so they're
monitoring service passivity and indeed
the full paddlers and you'll be all
operating and some other instruction set
that can do a lot of crazy stuff with
tags without any checking at all almost
so I have slides on this in a minute but
let me address it now so you might ask
yourself as Simon is what about all of
this all of this code that's
manipulating all of these tags directly
doesn't it have to be ultra super
trusted and the answer is yes it does
because if that code is wrong or goes
wrong then absolutely nothing else in
the system can be trusted so so it has
to be
right so how do we protect it two ways
first it's Ordinary code and in the
simple design that we have at the moment
we just have a flat address space with
no protection other than tags so so the
protection on that code like the
protection on everything else is just
tags so in a little bit more detail
there's a special distinguished tag
which we call Colonel and and it's it's
bit pattern is known and agreed on in
advance and unknown to the hardware so
when we take a trap because of a Miss in
the rule cash we set the tag of the pc
to zero which means colonel now we have
now we come back to these ground rules
that I mentioned at the beginning so so
in the rule cash at boot time or perhaps
at at hardware fab time we install a set
of rules involving the colonel tag which
are then never evicted there permanently
in the cache and and they say things
like if the pc says colonel and the
instruction that we're executing says
colonel then it's okay to execute it in
the pc stays colonel I we are very
careful very very careful not to put
rules in the cash let's say that say
things like if the pc is tagged
something other than colonel and the
instruction is tagged colonel then it
can proceed and here's the result so the
so the protection of kernel code and
data structures results from is a result
of our care not to put rules ever in the
cache that allow user code to do colonel
things and of course okay so so that's
the that's the mechanism now how are we
sure that the mechanism works we prove
it so that's a sufficiently critical
mechanism and a sufficiently small
amount of mechanism that really warrants
a proven we've done one
ok let's go on here's another policy
this one is a simple version of control
flow integrity so the idea here is that
we're going to use the tag on PC on the
pc and on instructions we're not really
going to tag data in an interesting way
to to track the progress of control flow
through the program so so that so the
tags are basically just addresses of
instructions or any other set of large
set of tags and the scheme is we we ask
the compiler to to please dump out the
control flow graph along with the binary
of the program and and while while
loading the process we tag control flow
endpoints with these unique identifiers
and we remember the correspondence
between those identifiers and edges in
the control flow graph ok so if you
think of those identifiers as addresses
then the control flow graph is pairs of
addresses that are allowed to branch
from X to Y and the tags on those
addresses say this is X or that's why
now the rules say on a on a branch
instruction on a control flow transfer
we take the tag on the current
instruction and put it in the PC put it
in the PC tag then on the next instruct
then we just execute the branch on the
next instruction we notice the rules
notice that the pc is tagged something
other than the default namely we just
branched from someplace and we check
that the tag on the current instruction
together with the tag on the pc is an
allowed pair in the control flow graph
so so the contents of the of the rule
cash are essentially the recently seen
subset
of the control flow graph edges indeed
indeed so the so this like other kinds
of control flow integrity this analysis
is only as good as the compilers control
flow graph control that might mean
legitimately not very good might be
legitimately not very good here's
another one we can we can do memory
protection using tags so the scheme is
every time you call Malik Malik
generates a fresh tag so Malik becomes
part of the policy so Malik generates a
fresh tag and tags all of the memory
locations in the block that it's
returning you and the pointer that it's
returning you with this tag now when
you're loading and storing you have to
check that the that the tag on the
pointer is the same as the tag on the
location that you're that you're loading
and storing I into or from there's one
tricky subtlety which I'll say before
George points it out which is that when
you store a pointer into memory it you
actually have two tags now one on the
memory location and one on the pointer
itself so in fact that the tags that we
use in this scheme are really pairs of
or the tags on memory rather our pairs
of the tag on the memory contents and
the tag on the memory location
conceptually a similar scheme can be
used to do compartmentalization so so
the idea here is that memory is divided
up into a set of compartments each
compartment has a tag which is chosen at
the moment that that compartment is is
created and and each compartment has a
set of addresses in other compartment
that it's allowed to jump to and another
set that it's allowed to write to so
this is this scheme is similar to the
design of the original software fault
isolation system except that of course
we're not doing it with binary rewriting
we're doing it in hardware and so the
the way it works is like this so at any
given moment the pc is tag to indicate
which compartment were in and each
memory location is tagged to represent
here's the interesting thing not the
compartment that it's in but the set of
compartments that are allowed to jump to
it and the set of compartments that are
allowed to write to it so the so these
jump and write tables are our kind of do
alized in the in the tag representation
now on each read and write sorry on each
right and one instruction after each
branch like in the in the cfi we we
compare the the pc tag with the tag on
the memory location that we're doing
something with and see if that's an okay
step and then for monitor services we of
course need a new compartment call that
splits the current compartment okay I've
already talked about this so let me skip
over it and tell you a little bit about
the the architecture of the proofs that
we've done so as I said at the beginning
we have a well we have many things in
various stages of completion for the
safe processor we have running running
hardware on fpgas for the alpha plus
pump we have we have instruction level
simulations and and performance
estimates and and for a simplified
version of each of those we have we have
quite a bit of proofs so so what do we
want to prove well first of all we want
to prove that this this kernel
protection
scheme that protects the that uses tags
to protect the tag hardware and software
is correct and then and then for each
micro policy we want to know that it's
correct in the sense that both it
preserves the invariants that are needed
by the kernel protection and that that
it correctly realizes whatever
specification we've we've decided it
should have so so the way we think about
it is this there's some there's some
generic parts and then there's some
policy specific parts on the on the
generic side we have of course the the
hardware itself we have a a generic part
of the of the the trap handler for rule
cache misses that that does the
low-level fiddling with hardware and
then invokes the the policy specific
part I and we also have a symbolic
machine which which is a middle layer of
abstraction between the the very most
concrete machine running a particular
policy and the very abstract machine
that we intend that policy to realize so
so okay in practice what do we do we
have an implementation of a policy which
is some machine code that the needs to
get run when services are called or or
when or when the rule cash traps we
install that on the concrete hardware
and now we want to what we what we would
like is that is that running user
programs on that machine with system
software installed behaves like a
machine that has say
compartmentalization built in so so way
up here there's an abstract
compartmentalization machine with a with
a primitive for compartment creation
that that you know divides up the memory
and what not and then in the middle to
make the to make thinking about it
easier we have this symbolic machine
which consists of a machine definition
whose whose execution model is executing
these symbolic rules that I showed you a
few slides ago and then on the on the
policy design side we provide not just
the machine code but also a symbolic
representation of the policy itself now
ultimately that machine code is going to
be generated from the from the symbolic
policy by a little compiler and for one
specific policy information flow we have
written that compiler but but for the
more interesting more general policy
language that we're dealing with now we
have not finished that step so so the
the monitor code here and the symbolic
policy are connected by a proof either a
one-off proof that you implemented the
policy correctly or a once and for all
correctness proof of the compiler that
takes these symbolic rules and generates
the code whichever you like then you
have for each policy your abstract
specification that says this is my
compartmentalization machine that that
that programmers are going to think in
terms of at the user level and what we
want is a proof that this concrete
machine running that concrete code
implements that policy and we've carried
out that proof we just submitted a paper
a few weeks ago to a conference that you
can probably guess we just to carrying
out that exercise for
compartmentalization memory safety
ceiling and cfi so for a range of micro
policies and that included quite a bit
of proof engineering to make as much as
possible of this and this refinement
proof generic
the general enforcement of the ultimate
example not certain what distinction
you're making yes again and this is with
you to generally tfcc finding the too
much for example the the main generic
bit of proof that we have is a is a is a
generic proof that the concrete machine
running any policy monitor satisfies the
corresponding symbolic machine under
some quite specific assumptions about
the relation between this code in this
code I think I've said this already yes
please sorry abstract machine that's a
contradiction in terms ok let me give
you an example one of the ways i might
specify a an abstract policy would be to
say it respects ownership of data by
threats so it doesn't have any no
references it doesn't overflow in your
buffers or other
that seems to be at the right at the
sort of level of abstraction that one
could say it was really abstract you are
you got any examples of that sort of so
this is something we've thought about
quite a bit in the in the process of
doing this this last round of
formalization experiments what is an
appropriate specification for some
policy it really depends a lot on the
policy so for example for memory safety
you can write down an abstract machine
and it really is a machine that is
self-evidently memory safe because its
memory model is segmented so every
single pointer has two parts a segment
part and an offset within the segment
and you just by construction can't run
off the end of a segment we've tried to
think about what would be an even higher
level specification of memory safety
than that and it's hard to come up with
one so so for memory safety that seems
like a perfectly good and adequate
specification of what memory safety is
you're just you're providing a machine
to the programmer where you
self-evidently can't overflow a buffer
for other policies like information flow
there are much higher level properties
that that you can enunciate and reason
about so so what we did in in that
experiment was to say okay here is an
information flow machine so we had an
abstract machine it had built in labels
information flow labels in the style of
information flow calculate that you've
seen but then we prove some properties
of that machine directly at the level of
that abstract machine we prove that that
it has a non-interference property or in
the case of the compartmentalization
machine we proved that the compartments
are isolated or in the case of the
control flow integrity policy we proved
that the the abstract machine that the
steps of the abstract machine
necessarily follow the the given control
flow graph and and then we need to check
that those properties are preserved by
the refinements all the way down the
stack so that they become properties of
the the code running on the concrete
machine okay let me tell you three
minutes about the most important at a
conceptual level open problem which is
the issue of composition and this is
what we're really struggling with right
now so so I've described a bunch of
individual policies and they are
probably individually quite useful but
but really you know one would like to
have memory safety and control flow
integrity and and yes let's have some
dynamic sailing too so for certain
combinations of policies just kind of
whacking them together and running them
in parallel is perfectly reasonable I
and so for example memory safety
together with control flow integrity you
don't really need to do anything you
just observe that that since tags can be
pointers two tuples of other tags you
can just say well the policy is the pair
of the the cfi and the memory safety
policy and you do everything point wise
and and when you're propagating tags you
just run the separate policies and when
you're checking whether an operation is
okay if either policy says no then you
say no and it's as simple as that so so
that kind of composition is is
straightforward and I and we've built
things like that and and measure them
and so on dyna super because
interesting correlation problems or or
or maybe you know merging the times or
something because you don't want be
paying costs no going on the direction
that has a pupil of the policies yeah
yeah that's true if it comes to making
really high performance versions then
right right at the at the conceptual
level it's easy to see what it's and
actually it's the conceptual level
that's the hardest because even when the
policies themselves are not orthogonal
you can still the the implementation
aspect of whacking them together is easy
you just you just have to ask yourself
what did that mean when I did that so
what's an example of non-orthogonal so
memory safety and compartmentalization
both deal both have have system calls
that need to deal with large large
blocks of memory so so the memories the
the memory safety policy has malik as a
system call that's part of the policy
and it has to tag the new memory with
its memory tag and then the
compartmentalization policy needs to
know what compartment that new memory is
in so it's going to need to put tags on
on the memory also so so if if you if
you just try to think of them as
completely separate things it just
doesn't work so what should you do we're
not sure but we have a couple of ideas
one possibility the the last point on
the slide is maybe instead of thinking
of composing things in parallel we
should think of composing them in series
somewhat in the style of haskell monad
transformers so so you don't just assume
that that you can with monads you just
don't assume that you can take to monads
and whack them together and and
everything is going to work one might
need to be wrapped around the other in a
way that the that the ordering matters
and indeed where the outer one might
need to know about the inner one and and
do things with its special primitives so
similarly here maybe memory allocation
is a really special thing and needs to
at the very bottom of a stack of of
policies that are organized in in layers
another possibility is what if at least
some operations were not part of
policies this is in a way an
instantiation of the same idea what if
operations like memory allocation were
not things that were provided by
policies but were provided by the policy
framework so we say well memory
allocation is a really special thing and
policies are going to are going to need
to deal with it as as part of their view
of the underlying machine and so rather
than programming the the monitor
services the system calls directly on
the hardware we program them on on an
abstraction of the hardware that
includes things like memory allocation
and am perhaps key allocation as
primitive okay so these are ideas that
we're experimenting with I don't know
which are going to work let me quickly
tell you a little bit about what we know
about what we can see at this point
about how this thing is going to perform
because obviously doing hardware
accelerated security is is only fun if
it's fast enough so so to get a sense of
that we we built a simulation of of an
alpha processor plus pump hardware and
low-level software and all that and and
tested it with the spec 2006 benchmark
suite using a an orthogonal composite so
a memory safety + c fi plus a simple
kind of tank tracking to see what would
happen so so here is the runtime
overhead and hear all the individual
policies broken down into where the time
is going and the interesting one is the
the geometric mean over there which is
around eight percent I think so so in
the in the
eight to ten percent range so this is
the amount of overhead that we're adding
to the runtime of these benchmarks quite
a bit of this overhead is fixed so so
even the null policy takes I forget
seven or eight percent overhead and this
is the extra pipeline stage and and
making various things slow down just a
tiny bit making the reducing the size of
the l1 and l2 caches because we need
some of it for the rule cash and so on
and and adding tag words everywhere for
energy again looking at the geometric
mean we're in the sixty percent or so
overhead range and this is after some
amount of pretty hard work on on
crunching things down but i think it's
far from all we can do so so this is
kind of 11 paper worth of of effort on
on optimizing the microarchitecture so
so this news is a little bit less good
than the than the performance but I
think I in the ballpark that we want it
and then the and then the absolute power
is actually not bad so so namely this
graph is showing the the white parts are
the baseline alpha architecture not
extended with the pump and then the
colored parts are the are the with pump
running all of these policies and you
can see that there are some where the
where the pump extended one is pretty
expensive in terms of power ceiling but
the but the the unexpended one was
pretty expensive too so the amount of
power that where that we're adding is is
reasonable in most cases area is the is
the place where we have not extensively
optimized in fact some of the
energy and runtime optimizations are our
bad for area and and so there were at
around one hundred and ten percent
overhead although again especially for
external memory there are lots of known
optimization techniques for for
crunching these things down okay so let
me finish up I don't think I want to
take your time to to go through all of
this in detail but at the hardware level
there are many competing attempts to to
do various sorts of tagging in hardware
ours is the only one where the number of
tag bits because we can indirect through
the tag is effectively unbounded and but
there are a lot of things that there are
a lot of previous systems that share
other properties with us and I'd be
happy to give you a draft paper that
talks about this in more detail what
mentioned explicitly that in addition to
using transistors you might arguably
available on the cpu also using double
the number of transistors in the memory
that yes every bite you store now is
another bite of tag is it yes so so in
the optimized microcar microarchitecture
it's not quite so bad so just thank you
memory but if you need to get two
gigabytes of memory before 94 is that is
that one so there's let me distinguish
between on chip and off chip member ok
so for off-chip memory I that's where
things like this Mondrian memory can
apply so so we have not yet investigated
optimizing off object memory but but
lots of people have experimented with
schemes where you can wear if ranges up
to the extent that ranges of memory are
tagged homogeneously you can you can
represent things very much more
compactly at some cost in in complexity
and
and performance which might not be the
case which might or might not be the
case depending on the policy and indeed
as I mentioned before the the really
quick critical question here that we're
just getting to the point of being able
to seriously answer is what are the
working set sizes for for the kind of
composite policies that we want to use
for real application programs and the
spec benchmarks give some indication
that that maybe we're in the right
ballpark but but I don't think I don't
think we should feel convinced yet he's
the one way you most i HEV skies exactly
there's an object with have pointed
still lots of emoji today all will have
different tax exactly memory safety is
the one that worries me the most so then
you'll leave your lunch it cash you're
level-1 level-2 now let's talk about on
 that way that they would be to
contain half as many other much data
that's right well unless you crunch them
down which we do so so that's the part
we where we have something done some
optimization and so one one observation
for example is that if your rule cash is
only four thousand entries then there's
not much point in having the tags in
that rule cash be longer than 12 bits so
we do some translation of tags between
the long form in the short form and
write change right away yeah right okay
i think i mentioned future work
sufficiently already we're defining more
policies building hardware and this one
thing i have mentioned which is one one
aspect that we're very interested in
that I that I briefly touched on the
beginning is once you have policy
enforcement in the hardware now you can
enforce policies of the operating system
so you don't need to think of the
operating system as this monolithic
thing that's providing security
abstractions to the above layers you can
actually think about compartmentalizing
it and and enforcing that
compartmentalization because the because
the enforcement is light enough weight
and that is something that we're very
interested in so my colleague Andre has
this slogan of he wants to build the
zero colonel operating system now one
has to be a little careful because of
course the cash management software is
is always going to be quite sensitive
and and need to be trusted but as we've
seen we can hope to do proofs about that
so so then the rest of the what's
usually Colonel one can think about
using those facilities for for
protecting it okay and that brings me to
the end thank you very much for your
attention and questions sees you could
either use the URL or you could do by
nelly lighting and so and the ogle that
would be his fault Sam police is a quite
embarrassing I wondering if you uh no
characterization without good policies
for the item matter but it is a trivial
way of hardware exam but other that
effective everything you have a
departure of you try to remove
everything that is complicating that
something that is yeah I don't have I
don't have a really good
characterization but but two things that
might make you lean toward a hardware
implementation are there are some
situations where binary rewriting
depends on static analysis of the binary
that's hard and there might be some
situations where your binaries are going
to be interacting with with unknown
binaries and so you want the you want
protection at a at a lower level so but
but these are just thoughts we don't
have really results about them I'm sorry
in forcing anyone to comply with the
body see any because it's not that the
actor okay just very related to this
question
couldn't go to the slide with the
performance perspective you perform
sorry beside the cpu performance results
for ya so do you have these numbers for
the same policies but excluding a time
tracking because time tracking think
only expensive thing you are being here
the rest you can be implemented
efficient wings on OS time appointed at
memory safety can be oh no sorry you
mean you mean they're efficient software
implementations yes we do have the the
numbers broken out i don't remember them
off the cuff yeah because I mean
recipients efie you'd get software
implementations that I'm better than
these yeah so I was going to be here for
the rest of the day so he has meeting
something two or three but after that I
think schedule is free soon she will
talk to him you're not scheduled already
he said you know thanks rose ok thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>