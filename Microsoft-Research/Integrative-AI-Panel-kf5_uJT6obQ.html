<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Integrative AI: Panel | Coder Coacher - Coaching Coders</title><meta content="Integrative AI: Panel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Integrative AI: Panel</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kf5_uJT6obQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
welcome to the integrity of AI panel
people are still trickling in but for
those of you that happen to not be here
in the room for the previous session the
this panel follows a plenary session
that had the same topic of integrity of
AI and we have a fabulous group of
researchers here from I guess your left
to right Eric orbits from MSR Charles
reach from WPI Manola veloso from
Carnegie Mellon lead on Joe from MSR and
Larry's is nick from ms our first I want
to thank them for agreeing to be in the
hot seat today I think on this what I
believe to be is a really really
interesting topic and before giving them
the floor I'm just going to spend one
minute on kind of setting up the topic a
little bit there's this big intriguing
title of integrity VI and we're all may
be struggling w what does that exactly
really mean and I like that term can I
think used yesterday which is organism
and I think I think we're on to
something this this idea of building
systems where we leverage different
kinds of we harness different bring
together different kinds of competencies
to create things that are more than the
sum of their parts is is I think an
interesting idea that that that marries
more thrust and exploration I was
looking actually this morning at the
definition at the dictionary definition
of water system is and apparently a
system is regularly interacting or
interdependent group of items that form
a unified whole and I think to Eric's
comments you know at the beginning of
the previous session over the years
there's been a lot of you know energy
and a lot of work spent into advancing
state of the art in these various
vertical feels like vision and speech
and language you know some parts of AI
but I think it's interesting to think
about how can we bring them together how
can we get more of this interdependence
going like Larry had a fabulous top
before on on you know vision and
language I think we all have intuitions
that there's potential big benefits here
you know multimodal fusion the
multimodal interaction community people
for years have you know worked and shown
how robustness can be increased and
created in these ways but I think
there's also really important challenges
and big challenges you know in creating
this kind of unification so the hope is
that with the panel today we'll discuss
some of these topics and get to some of
these intuitions and hear their
reflections and also maybe get some
educated guesses about directions we
should pursue more and where we should
push on the accelerator more as AI
researchers just the last word about
mechanics I would like this to make this
as interactive as possible so I'm going
to in a second give the floor to our
panelists to do a little sort of
introduction initial reflection and
after that I do have a list of topics
that I I consider would be interesting
perhaps go through but I would really
like to open up the floor to the
audience and get many questions from the
audience and and participation okay so
with that I think I'm going to pass it
on to you guys I don't know if we want
to start right to left or we can start
with Eric right here I think what would
be just to kick it off like maybe spend
I don't know somewhere between three and
five minutes just the first thing I
would like you to do though is in maybe
one minute kind of introduce because we
have a large diversity in terms of
research backgrounds on the panel kind
of introduce your research background in
the direction you're coming from to this
problem and then comment a bit or
reflect about what does integrative AI
mean to you and where do you think are
the things that we should chase are like
where we're we're the potential big
benefits here so maybe we'll start with
Eric so I'm Eric Horvath some and I've
been long passionate and curious about
the foundations of intelligence
computational foundation for which I
believe describe both natural
intelligence and the machines that we
build and
was always deeply interested in how
small simple systems perform well in
large-scale complex open universes and
machinery that enables these systems to
perceive and reflect and make decisions
and prosper potentially competitive
environments in the open world which
brings into play uncertainty motions of
utility actions and reflection or meta
reasoning it's been fabulous working in
the space of Integrative AI as somebody
who has been longing over the years to
understand all aspects of machine
intelligence and trying to keep track of
the best of innovations in each of the
fields subfields in a world where the
CDP our conference has 3,000 people
attending in triple-a I the general AI
conference or h KY maybe has 1500 you
have to sort of really know make sure
you're dipping into all the areas of
expertise and keeping track but back to
this idea of building larger systems
that actually have more of the skills
that we'd like to see for dreams of
building more human-like general
intelligences it's pretty clear that we
need to understand how to mesh weave
together multiple competencies and
modalities in ways that that again
create some sort of a symphony or
coordinated intelligence I've been
intrigued and looking at the cognitive
psychology literature and looking at
models of mind that psychologists have
been studying over the years including
the multiple resource theory of mind
which described mind as being not a
singular the singular kind of
intelligence we might experience as
individuals but really it being composed
of many experts and the ways of
coordinating among the expertise is so I
think to look at on the capital side at
a given time is having least three
different types of integrations one
ought to think about is fabric level I
often when mind think about it as
representational integration
where there's opportunities to build new
kinds of representations and reason over
them that bring together modalities that
aren't traditionally considered deeply
in a unitary you know homogenous
framework and a good example of this is
bringing together you know whether it be
a continuous representation or or
probably a graphical model fine-grained
distinctions about visual and the visual
world and language based semantics in
the same representation i think is lots
of opportunity to do weaves like this
that are quite deep in the architecture
of our systems called the fabric level
then there's a popping up a level this
idea of compositional integration but we
actually have components some of these
are black boxes we heard about in the
Latin last meeting a black box face
tracker spitting out features or
confidence is a speech recognition model
an object recognizer system that reasons
about availability we have systems that
we composed of these units and when we
do that we have to end up wrestling with
issues of that distributed systems
researchers work worried about
coordination timing but now subtleties
in timing affect deeply user experience
for example in a dialogue system then I
have worked on we ended up discovering
that we had to introduce a layer of
metairie of analysis will call right now
of how long it would take for a pipeline
to go from perception to reasoning to
reaction to understand how long it would
take from seeing something in a dialogue
setting with multi-party to reacting to
it and saying something relevant and
running this layer in real this this
integrative cross module analysis in
real time so the system would know to
not even attempt to say something you
would take too long and I'll just
disrupt the conversation just hang back
now understanding that the cost-benefit
analysis is a cross
component layer that we learned to
actually integrate into our systems or
another example is looking across a
pipeline of analysis and looking at all
the ways a system could be confused and
we had a project working with an intern
last year where the where we were avatar
an embodied agent we actually share
expressions in a natural way confusion
or acknowledgment or relief or surprise
where those kinds of natural status
reports about internal state were across
modules across many components and they
all have to share the same language
reporting on competence is such that the
system could have a kind of a natural
unitary singular sense for reporting on
internal state let's so I call us kind
of the data spec compositional and the
file Larry I like to think about it is I
call reflective and the prospect of
developing new machinery which treats
components as object level reasoner's
and the challenge is to reason at the
meta-level about how not just to
optimize how these components work
together but to even to create new
responses with by assembling in
automated ways in machine learning and
through combinatorial come tutorial
search maybe or simulation sampling new
approaches by automatically assembling
and tuning component tree and this kind
of thing I think it's getting more
interesting because it involves even the
idea that someday we would might put the
other set of components to a first pass
at task oriented problem solving and
then once we have a up and running
system have itself optimized with
lighting conditions changing or with
dropping a new sensor into the bucket
and having every for every decision
maker every learner can listen to the
reports from that sensor for example
opponents can actually decide what to
listen to by doing some value of
information analysis in the distributed
way it might be some central ideas as
well but there's a science there of meta
level reflection among about componentry
where we don't take it upon ourselves to
design these systems really by hand
anymore we take our first past and we
have this notion of higher-level
meta-level process is helping us to
integrate and create these integrative
models offline or in real time so I
think that those three types of
integration are very presence front and
central from me am I reflect about the
opportunities thank you well good
afternoon I have laryngitis but I guess
I speak like this people can hear me for
through the miracle sounds great of
microphones that's great so I started in
AI when what we call right now called
good old-fashioned AI was current AI and
I've been on both the academic side at
MIT at WPI and in the corporate research
side at mitsubishi electric's research
lab in Cambridge I think the reason I
was invited to this panel is because for
the past number of years together with
my colleague candy cider is sitting in
the audience we've been building systems
which have dialogue systems both verbal
and nonverbal sides of dialogue have a
computer vision and have manipulation
and have planning to kind of basically
the main components as I was sort of
thinking about this panel listening to
the presentations Eric you said in your
introduction that talk about sat
tripodal forces I think there's sort of
two categories of courses that are
driving the field you know in two
separated silos one is sort of
disciplinary vision people to talk to
language people don't talk to robotic
people and so on I think the other one
is sort of task specific focus so people
working on a particular task listen to
your presentation manuela which I
thought was really wonderful but I did
have the feeling that you were really
focusing on specific task and you're
making progress by being task specific
so my question for the panel the last
thing I want to say this at this point
is
you know it I was I was hoping I was
thinking I was thinking this was a panel
on generally I because you know there's
been as pendulum swing people sort of
regularly bemoaned the fact that no
one's working on general a i right and
now this is think integra today I and
I'm not entirely clear whether generally
I and a tegra today I are the same
research path of the same vision or the
same intuition so I'd like to come back
to that yeah love to hear the comments
of the panelists on on the on that topic
as well well maybe one of them can
provide a path to the other maybe not
that's what you're interested in I mean
I think some people may be interested in
what about the other I don't know yeah
my name is Little Joe um I want to start
with a confession that you know I'm not
one of those cool AI scientists like the
rest of the panelists I'm actually a
boring system guy try to blend in as a
you know into this group of people and
so the only thing that I can remember
you know doing before I talked to Dan
and Eric and the other AI researchers in
MSR it's probably gonna help my 10yo
with his robotics project that's the
only a I exposure that I had and so but
you know we do also acts differently
kind of cool projects are in systems so
mention you know two of them as you know
they're sort of related to the
discussion in this context you know when
before then I actually talked about some
AI problems that they were facing so I
was actually working on was with some of
the Prada teams on a large scale
streaming systems where you know we can
process petabytes of data daily and on
thousands of machines and the other
project we did too is you know we can do
you know graph processing you know when
Trillia age kind of graph on you know
only 64 machines within minutes so we
were pretty happy any systems that's
what we tend to focus on you know
scalability reliability and so on and
then you know by excellent you know
we're talking about some of the Desai
project that the van and Eric and others
have been working on initially so my
first reaction was great you know what
about you know offering you a powerful
system infrastructure that's you know
all this magnitude then what you have I
would that change your thinking right so
that's the typical way of you know
system trying to you know enable
disruptions in other fields um and and
then you know when we talk deeper about
doing some issues it just strikes me
that it's not really about the rocket
abilities that system provides it's
really about you know first of all
there's a gap between what system
provides and you know in terms of what
AI researchers need and there is also
very importantly you know the way of
thinking so in systems we also reach a
point where we're no longer able to
define precisely what the system is able
to do I mean we're dealing with you know
a very large scale system we're very
complicated set of components
interacting together I mean just like
when your own words was saying you know
it's very hard to know really what's
what's going on and in some sense we're
also looking for a different methodology
and you know different way of looking at
systems and how they can we have a teeny
bit with components and abstractions and
and so on but the methodology we've been
using you know try to precisely define
what system does is probably not going
to scale very well so this is why you
know I think putting a I and a system
together could actually potentially
bring disruptions in both fields this is
why you're not very excited I've been
working with dan and Eric on some
aspects of outside especially you know
introducing capabilities into systems
that were never available before all the
things that we tend to do is you know
essentially the AI researchers should
not spend a lot of time
dealing with infrastructure problems
right the infrastructure should provide
all the abstractions for them to look at
the data look at how system behave and
you know ask all the scientific
questions and come up with new theories
and I think this is going to be a very
exciting sort of collaboration I'm
actually looking forward to that and my
hope is you know in maybe this year it's
kind of strange to have a system person
on the panel you know AI topic but you
know a year or maybe a couple years
later it's natural to have system people
and they are people actually working
together so that's why I'm here good all
right I'm Larry sit Nick I guess as it
even in high school and as an undergrad
I remember just being fascinated by a
I'm reading like the pop science books
on AI just thinking about how cool it
was and then I got the grad school and
even though manuela was on my thesis
committee I kind of did what everybody
does in grad school and kind of narrowed
my focus and it became a hardcore
computer vision researcher working on
stereo vision and I'm going to solve
that problem and I think sometime after
my thesis is done i realized that who
cares about stereo is case solved by
lasers anyway so there's no point sorry
I didn't he didn't solve anybody so I
stopped working in that problem but it's
still desire to do something in a I
still was still there but something
happened I'd say four or five years ago
and it's amazing how like these
seemingly kind of small things can make
a big difference you know Mechanical
Turk you know it's just huge the fact
that people upload their photos two
billion or ten billion of them per day
is huge the you know the amount of data
we have on the web is huge you know it's
just all eating together then then deep
learning gets into the mix you know if
you see these transformations is coming
you know and it's just right now I don't
think there's been a more exciting time
to work in AI then right now and this is
just is like a kid in a candy store all
over again we can start thinking about
these higher level problems so that's
why I'm so excited right now now this
integrative AI just makes me like bust
up laughing I think it says more about
where we've been and where we're going
the fact that we need to put the word
integrated
in front of AI implies that before we
were not doing integrative AI which
seems really ludicrous because
intelligence by essence should be
integrative it should be general the
fact we had to put general in front of
AI as odd as well so you know I look at
that is more like yeah obviously we
should be doing it integrative but maybe
we should put more emphasis on it now
because now it's a time where we get to
come out of our silos you know going
forward well thanks thanks everyone for
these initial reflections I don't know
if anyone wants to ask a question right
now we're a couple couple comments and
there's some comments from the family I
mean I mean I think that there's
something different Larry from my point
of view in saying well of course it's
always been it should have been
integrated maybe it says something about
things being separate on the other hand
this the situation is one where we can
we can reflect pretty deeply about the
the interfaces and methodologies and the
nature of the integration itself as
something very explicit so in some ways
maybe there's a fortunate aspect of the
fact that there we have modules and
components that are sometimes segmented
by modality task or by type of
representation with some good
competencies and characterizations now
in themselves that there is an
opportunity to think clearly with that
kind of abstraction layer at what it
means to put things together in new
kinds of ways so it's not just the
coming back of what it should have been
but also the idea of the site this
notion that there's something about
science and and the engineering in terms
of how do you put things together with
how itself is part of the science I
think we originally wanted to well I
wasn't around but I was saying that if
boats back then they wanted to go there
and I think right now the fact that
things kind of work ish you know allows
us to finally start studying these
problems and the fact that why do we
want things to be integrated well we
need to have a deeper understanding of
them right and we don't have a deep
understanding of what these cons you
know what these semantic onsets mean
like I was talking about am I talk
without having is integrative
approach you know without going multi
modality that sort of thing but so I
think I hear people talking actually in
two different things part of when you
talk Eric and manuela when I hear a lot
if I what it would be like standards the
reason we can't put things together is
we don't have standards i mean it's it's
not fancy where mr. the assistant people
to all about standards that's that's how
things that put together and standards
are basically a following activity you
standard supposed to capture which we
already agrees on that then is support
from going further but it's it's a
following least common denominator kind
of thing that's nice I'm not vol.4
standards I'm submit that by the way
well but I think well but I think McCall
conceptual could conceptual interfaces
standards well it doesn't that's exactly
the thing but then on the other side of
your mouth here those side of the panel
which talks about deeper understanding
and conceptualist and those are leading
leading concepts we don't even read and
we don't even agree all of us I how to
think more deeply and so you know it's
sort of premature for example I'm so you
want to stick things together that are
black boxes or gray boxes or whatever
that's a software engineering it's the
standards issue and you know if you want
to have languages it supports certainty
and streams great idea a terrific idea
because that's so saying that it's at
least common dog everybody you know is
using uncertainty everybody you know is
using time sequences so for God's sakes
let's not reinvent that let's have a
standard one let's make it available to
everybody and that will help advance the
field no question about that it's a very
that but does give us a following kind
of vector I'm talking about dropping a
new camera into an operating syste
system that's operating doing stuff in
the real world and having features
stream to the right components and again
me to do that yeah but that's not the
same as what Larry's saying it because
he's asking a very general question
about what is understanding you know is
it cor-ai generally I kind of question
and so it's good that we have diversity
here but I really think that that one's
a leading topic and the others are
following topic I think if I may
interject in here I mean my like I one
question is is there really like an
opposition here or like a sort of good
stuff not in the sense that it's good or
bad but in the sense i'm wondering
whether one might provide the path to
the other we've all been striving for
general
I we have evidence from cognitive
science and so on that systems that do
these things existence proof that we
have the brain are tightly in the
greater than casual of course but it's a
different discussion entirely they put
in platforms and fabrics that are going
to stop us from wasting our time so they
can work more on the hard problems we
don't know how to do yet and not
everybody redo the things that pretty
much we all know how to do that's a
different discussion then how do we get
progress shared progress community
standards let me set you know share
databases all those kinds of things to
get us fundamentally forward it's not
just putting to me the problem is not
just putting together all the things
that people written papers about I think
we don't begin and how to do AI and
that's it let me let me get them they go
back to Larry again I was saying
fine-grained integrative AI talking
about bringing modalities that have not
been bought together clearly in the past
in some ways in new ways to understand I
was talking about us to a w3c standard I
meant we're asking a basic question here
we're looking at what's the innovative
aspects of this where I guess you might
say we're taking deep understandings
about wedges that have been largely a
modular and separate we're bringing them
together in the saying we have a real
interesting challenge problem of sub
table call understanding right now might
be described the intention of the humans
in this picture what's happened describe
what will happen next and we find this
is a really interesting hard problem
that we for which we can leverage
existing assets that weren't thought
about together before and it so happens
we're in a world where there's some
really great work that's been done
separately I haven't mentioned anything
what standards of fabrics are sharing
talking about a hard AI problem and
we're suggesting in this panel I think
in part and in the last session that we
can make a leap towards more powerful
systems along the lines of the basic
questions that that we've all been
asking through thinking integrative Lee
and then even thinking about what that
actually means and what the various kind
what's the ontology of integration we
can do and what we call it integration I
actually like Larry's comment when you
made the comment well boy it's like
we've always been building systems and
thinking about systems and interactions
components of modularity and
independence and what that means in
these in these complicated pipelines so
what does it mean to start thinking and
new with this new phrase and a track at
the faculty some online etiquette today
I I think it means some things and it
does reflect us to a little bit about
where we're coming from but it doesn't
mean we can't ask basic questions but
thinking I knew about for example what
does it mean to take two modules that
you do visual and the language
processing and without breaking them
open completely and rebuilding them have
them talk in a very exciting interesting
way where the talking itself is part of
the excitement in what might give us
more general principles of that in the
AI system well there's something that's
happening I think right now and there's
been a philosophical shift especially in
the computer vision community we're
thinking about things as separate
systems that we need to tie together is
very uncool you're you know like you
know especially the image captioning
right if you have a different module for
every single component if we're like
that's a pipeline system this isn't
that's you know that's just a bunch of
things taped together that's that's not
what we want to do what we want to do is
we want to do end-to-end learning you
know which is only been compatible you
know because of the you know the deep
learning kind of revolution right and
it's amazing that you can actually do
this and I think that's once you start
thinking about hey I'm not training
separate modules anymore I'm not
thinking about the problem like that
anymore I'm thinking about the problem
holistically I'm trying to think of a
function in which if I train to try to
produce these words will actually train
my visual receptors as well you're right
and it's the singles are going every
which way yeah you could break it up and
different things but the representations
become more opaque in a way which is
unfortunate but you still it's a
different way of thinking about things
and I don't think you know it's uh it's
it's just you know beginning to catch on
oh this interesting question oh good
doing oh yeah if we have questions do we
have questions right now Chris i quess
Chris bring a microphone there it's a
race so I want to kind of reinforce her
Larry's comment about not so much
stitching together the modules and
maintaining a pipeline but maybe better
coordinated because when i went to
trying to move from knowledge-based
understanding to memory based doors tied
into a learning system it was like
merging companies i attended having
firing a lot of modules that i had
because i needed to integrate the
operations that were happening into a
coordinated single system an algorithm
operating time on top of United
knowledge structures rather than these
separate silos of knowledge that were
then talking in some intelligent way to
each other so I think that I tend to
think when I think integrative AI I
think of at some point we've understand
what goes on now you realize when you
come together it's going to be one thing
doing it but catching a lot of the same
operations and functionality that was
done in separate ways before very
interesting classical respond and ask a
question back to the audience when is it
the case that even in the long term it
will make sense for the first system own
reflection about its operation to have
separate modules that are relatively
well characterized or learnable and and
then harnessed in a larger system that
one said it knows learns how to use them
as opposed to big innovations that solve
everything in one place you know
evolutionarily you might beat the
comment that you know there are
mechanisms and machinery in nervous
systems that have evolved in a long
history of a trail of innovation where
there was no way to go back and fix and
start over again but instead layer and
do control and optimization and so there
might be some things to be said about
about that kind of thing even though we
would want of course to have big grand
unifications unified representations a
unified inferential schemes just a
high-level comment on your reactive all
systems are not modular either it means
are you if they're quite modular
they're quite ugly layer your reptile
you got to you know the mammal brain on
top of layers as modules but well I
don't think so at all well take that the
dinner conversation I don't think so
that's a question it composable so so
building on on I think it's a mistake to
think about the problem right I mean the
whole point about intelligent systems is
like of it like Black Orchid organisms
have multiple problems they're
constantly doing a mix of things they're
constantly changing as Dan brought up in
the last session one of the big
important problems is longevity and
lifelong learning and so imagine a
system now where instead of most of what
it knows get started out with or was
done to explicit training most of what
it knows actually has come from its
experience with no one looking at its
internals that's something I don't think
we know how to build right now and
that's I think one of the next really
big key things we have to strive for
what one of the comment in response to
you can also increase and back to tuk is
that an example that Nuri Oliver and I
built matures with us at Microsoft
Research a system called sere which was
a multi-layered hmm system for
recognizing office activities and once
we built this system we recognize that
because of the layering we can retrain
it for different offices very quickly by
just retraining the bottom layer the
sensory layer and with a much smaller
parameter space than we would if we had
one big network so back this idea of
reflects ability in different
environments and lifelong goodness
through trials and tribulations there
are some architectures that might
decompose in a way where the hardness of
the problem is is simplified in
particular region and still giving the
overall architecture it you know the
sort of a good performance I want to
give Larry a chance to respond briefly
to that and then we have a couple of
questions hanging in yoga
so I good allowed to come it I'll be
really quick though no no no learn from
scratch some the pics of all one thing I
think it's important is we say
modularity as in the modularity has to
occur because it's done by hand we say
we should have a face detector we should
have a small detector that sort of thing
but you know a lot of times even believe
these neural networks a lot of times you
get modularity by it just happens you
know it just learned that this part of
the network does this this part of
network does that when they separated
the network into two GPUs he learned the
separate pathways one GPU sup you know
focused on black and white the other one
focused on color you know so this can
happen just automatically the the other
thing is you bring up this point of
generalizability one of the amazing
successes I think of recent is that our
datasets have gotten so complex and so
real world is that the features that
were you learning are actually they do
generalize I mean look at the number of
papers right now that take imagenet they
train this really super deep neural
network on image net and then they take
their own task and they just fine-tune
they just tweak the weights a little bit
with as much smaller data set and Wow
beats everything out there you know so
there is something that is learned there
is something that is general and we
should take advantage of that and it is
amazing what you can learn when you take
kind of a relatively weak signal and
your back propagated through so you know
let's take a couple quick question so
actually the first part of Larry's
comment sorry chris bishop at the back
here the first part of your comment
Larry just beautifully anticipated the
question that I've been waiting a couple
of minutes to ask which is really the
question the whole premise of this panel
that whether you should be talking about
integrative AI at all but rather think
about things back to front so so we know
the brain has these modular modularity
and different kinds of architectures but
they they're sort of historical in
nature I mean the most recently as
cortex and cortex seems to be the same
throughout whether it's doing sort of
motor or century or what particular and
sensory inputs are and and so really
shouldn't we be thinking about finding
out what that sort of general neural
goop is and then the modularity will the
the integrative part will happen
automatically the module and the modules
as you say will arise automatically I am
NOT a neuroscientist but my
understanding is that if even as
adult even if you say lose your eyesight
that that cortex that was previously
doing visual processing that some of it
can actually be repurposed to process
different kinds of signals so it's
somehow not only a single
general-purpose architecture but it's a
adaptive and plastic even during life so
maybe we don't need to worry about
integrative a i tole we need to find the
the general mural groups and all the
signals in at one end the outputs the
other end and it will organize itself
into the into the right kinds of modules
is that completely crazy it's it's great
it's great like I said about me so
conceptually great I think that is one
of the big challenges right now is what
is the structure which will allow some
of these things to arise and I think
there was a lot of hype for everybody
familiar with L STM's long long short
term memory that this you know can do
amazing things you know it can recurrent
neural network that can learn all these
different properties and I think right
now they're kind of overhyped and I
think in the image captioning space no
there's a lot of magic attributed to the
use of LSD ms but then when you actually
go and see what they're literally doing
it's not that impressive so I think we
still have a long way to go but I think
that is a viable and any good way of
thinking about the spot not that people
should do it other ways but you know I
doesn't there's a lot of a potential
there your spirit or some weight Magda
so as a starting point I don't know a i
I just I after yesterday's panel I want
to make sure I'm framing this question
is best i can not really knowing this
research space I am a systems person and
I built custom compute solutions for
challenging problems an AI seems like a
very good tool kit to be using for some
of these challenges is this microphone
on yes okay good I wasn't sure so where
my question is going is I do know
something about algorithms and one of
the things we would look at would be
looking at distributed learning so for
example distribute intelligence be as
things like that versus
well I'll go back to the dinosaurs two
different brains you know one to operate
the backend went operate the front end
for lack of a better way of putting it
and where I'm going with this is when I
think modular I tend to think more in
that sense and so I wonder how can that
can that actually grow into that space
or can your approaches and techniques
work within that kind of computing
physical framework in a good way and
grow to learn more in that sense and I
really hope that I didn't offend any way
in the way I tried to rid that question
it's great I mean maybe lead on you can
respond cuz you've been looking at some
of the AI techniques lately at your
assistance person so maybe you can write
so I'm try to understand the question
precisely basically you know I'm
assistant person and we're being should
also looking at you know distributed
algorithms and how we implement those
abstractions and so on so my
understanding is you're looking at the
problem from you know like swarm
intelligence kind of point of view where
you have a lot of you know small
components that are interact with each
other and then we r you know there's
emergency emergent behavior coming out
of it and you know I think so we
actually look at this domain a while
back one thing that you know always
puzzles me is the I guess from system
point we want to understand what
behavior will come out of those
interactions and it's very hard for us
to specify you know certain behavior and
figure out what the algorithm should be
in order to achieve that kind of
behavior and I think currently we're
actually looking at a very different
approach where we really want to
introduce kind of this kind of
distributed learning into even an
existing system where the idea of doing
in stress introspection in the systems
and you know introducing feedbacks in
the system and continuously learning and
adjusting
and see you know where this is going so
this approach because we know that what
the goal goes our and essentially it
says you know we have metrics that can
guide the learning process and that's
you know my understanding of you know
what we have been looking into so I
don't know whether the same approach can
be taken in you know swarm intelligence
kind of domain I don't know enough
actually to comment on that it's
interesting this notion of integration
right like I think Eric outline this
like three different levels of thinking
about it one being some sort of
representation all right where you fuse
representations and construct things
that maybe get us closer to coming up
with things that can support common
sense reasoning and you know aspects
like that the compositional integration
and the reflective which is what you're
talking about right like these systems
that reflect upon themselves upon their
own structure one question that I had is
whether whether there's other kinds of
integration or other kinds of achieving
you know this cumulative effects where
you might get you might get a benefit
where get a hole that's larger than the
sum of the parts for instance you know
someone brought the lifelong learning
like over time like you know how do we
build systems that that do that kind of
and over time and space like at web
scale right I I was reading recently
about robot libraries where they learn
tasks from each other you know are there
is there a space where we can think
about integration and sort of like but
that kind of scale like is that a I
don't know an interesting direction for
AI or
I have a comment a little bit often so
those grab it out okay yeah that one um
so first of all I want to say maybe I
sounded perhaps I was criticizing you
meant about which which I apologize
didn't mean to I I think that you know I
completely agree with you but part of
what integrative AI is about i think is
as much as possible we should no one
should go too far without actually
putting of the complete system it does
something actually in the world right i
mean if you do that just gives you
honest and I mean that if anybody
disagrees with that I don't know you
what to say them anymore because you
just gotta live in this world know that
how how helpful it is to build real
systems and have them out so I I don't
find that controversial at all thinking
about integration I just a little bit
the historical footnote just came to my
mind which is remember I don't know that
15 years ago maybe 25 years ago
blackboard systems now I think what
people first reduced blackboard systems
you were there I think they were saying
a lot of the same things that was a way
you made integrative a I was it wasn't
that the whole idea of blackboard
systems it's so so here we are again and
I don't have an answer as a question who
reflect back on that did it succeed what
can we learn from from from that run at
this goal let me flip it around you
should say why don't why don't we have
knowledge in a form that computers can
use it slightly another holiday that is
why can't robots use the knowledge
that's already in a form that humans can
use right and I think the reason why
computers have such a hard time
understanding this human form of
knowledge is that computers don't
abstract knowledge in the same way that
humans do they don't they can't deal
with abstraction they can't generalize
nearly as well if you look at what is
the Achilles heel of deep learning the
Achilles heel is that you need huge
amounts of data to do learning with it
that's also what you know we were
talking about lifelong learning that's
really like uh yeah I'd be really great
but it would learn something in about
two years and then we had you know it
would take so much data for it to redo
its processing to actually then change
its actions in the real world maybe you
know not a very smart robot so I think
that that's like a big challenge is how
do we take these you know the computers
which are good now at doing these
intuitive tasks and they
it'd be able to extract being able to
reason with the same sort of power that
humans has it that way we can so let me
mention one question to the audience
into our panel which is methodological
and maybe philosophical getting back to
what chris bishop was saying about
cortex and you know pursuing as a
methodology the singles the singular gap
for multi-layered units that are late to
do everything where the gap includes
some set of basic procedures for things
like a propagating signal and doing it
efficiently and we're done just get
there and so this 2 comments there one
is that it is the even if that was
possible and that's the peaceful
philosophic direction where things are
heading and they should head that way
I'm speculating let's say that was true
there's the pathway for getting there
the comprehensive bull pathway for
getting there first of all neural nets
are not that way complication are not
like brain units and we should start
thinking saying that you know I mean
roll out of it I mean there's a lot of
mystery about how the brain works do we
do not understand it's it might turn out
that the way to seek understanding is if
we do if that indeed is useful it could
be true things like computational neural
nets that that's the methodology want to
play with understand and I put some
analogous kinds of procedures and
processes that are useful to understand
for understanding richer deeper
intelligence of the form represented by
these naturally evolved nervous systems
but you know one of the big challenges
with the neural net research as we know
it today is expect ability clarity
comprehensibility understanding some
details such that such that when folks
like Matt zeiler and Rob Fergus came up
with some basic visualizations they made
some big strides along the same lines it
might turn out that the best way for us
to get game comprehension and to make
leaps to the next step would be to
taking modules we understand relatively
well this includes LST mms and
and and couple of doughnuts are various
kinds because I understand them at some
level and start pulling them together in
ways for example to do planning systems
to can you imagine trying on this to
South poker with with a deep neural net
the way that my bowling and others did
at alberta there's more going on with
thinking reasoning reflection that we
have no idea how to do with this gap so
i want to raise the question to the
academic community to our partners on
methodology with you know the is the
business is the short path to deep
intelligences of a form that the
founding fathers and mothers of a i
reflected about through solely through
really pushing hard on where we've seen
some recent gains and classification
technologies or not and if and if not
looking on if not why not and what role
does this approach to taking various
kinds of modules including strip style
logic that we understand and thinking
through building larger systems they can
do more kinds of tasks and generalizing
abstract so just a question i want to
ask everybody on it's given the fact
that we're kind of getting to a gap like
let's stop now state in this room yeah
so this question actually goes back to
something that that Manuela said at the
very beginning building complete agents
has been a theme in af from the from the
early days continuously people have
never stopped trying to do that and we I
think we need to ask ourselves why there
has been a lot more progress in
developing the individual you know
solving the little problems like
classification or stereo whatever then
inputting the elements together and I
think the number one reason is what you
know Henry cuts cause the complexity
monster right you have a lot of things
that work well individually and then
when you put them together they don't
this is what kills us and we can make
all the progress that we want on these
individual things if we don't solve that
problem we will never
have intelligent agents and I think
manuela to my mind at least give a hint
of an answer to this one she talked
about we need to make sure this is sort
of like we need to make sure that each
module or whatever or each capability
can do its thing with input from the
others well knowing as little as
possible about them but the problem is
that this can't be the whole answer
because you know that's what every
well-designed system does it's called
divide and conquer you know my procedure
has its internal state and in some sense
it seems that the real difficulty NYADA
has stumped us for 50 years is that
divide and conquer doesn't work for AI
because the interactions between the
modules are too broad and too deep so in
some sense maybe we need a new kind of
design paradigm that is different from
how we build our systems today and then
and I wonder what that would be and you
know what the panelists think about it
isn't present except maybe for Ken
forbus which is a whole group of a small
group of people in AI who work our two
called cognitive architectures it's not
very fashionable but in some sense
they're trying to do integrate and not
maybe we just think that they're just
never going to get anywhere and and they
do sometimes build complete antenna
systems but at least they're thinking
about the issue of what are the
architectural principles and variants
but they don't talk like software
engineer I'm a shock when you're
actually originally and they don't talk
about modules and api's and data
pipelines and so on they're mostly
talking about your shared
representations they're mostly talking
about sort of the you know the real time
loops and how many there are and so the
top and architecture something that any
systems person recognizes architecture
but they're you know influenced by human
architecture i'm going to take their
inspiration some some literally do fMRI
studies but a lot of all of them take
their inspiration from human what's
known about human cognitive architecture
and that's a part of AI which is not
represented on this panel and i think
very little represent in his room that I
think are trying to work on integrity of
AI at the architecture level then they
talk about very different number
over there ya know hey so I just wanna
speak me that nobody hurts me for that
debt contingent because I think it's
important but yes so that's actually one
of the things that I've learned you know
interacting with our researchers you
know your systems we tend to have you
know get to mystic in a modular kind of
design so every is every single suit
designs right you have interface that
you know you expect the other component
to do in a certain way and in AI domain
this is completely not true anymore so
this is why you know you really need to
design a system in as you said you know
in a completely different way and this
is you know what I think it's very
exciting also in a firm system point of
view the other thing that I want to
point out is you know I think the
capability of what systems can do
nowadays is also a major factor now
there's this potential for disruption
lynn previously you know if we only have
the capability to do one component at a
time and all the interactions requires a
lot of you know additional complete
human resources to handle and it's just
not possible to think about you know
integrative AI and those kind of things
so i think there's a timing issue as
well where you know we now have maybe
hopefully deeper understanding of you
know how those components work out of
the existing robotics work and coupled
with you know much more powerful you
know hardware and more data and so on so
this is where i think why we have
january general AI coming back again i
might be different i don't know what the
breadboard system did but timing has to
be right for those things to have a have
the right solution people question their
there's a question that we hanging for a
while and yeah it's not a question
really um so this might sound boring i'm
not really that interesting the
architecture the representation but what
I love about the work that the folks on
stage do is that you build systems that
do a task that I can kind of understand
or wrap my hands around it's a task that
seems like a sensible task it might be
an artificial task but it's still a task
that has some of the right properties
that we want an intelligent thing to be
able to do and I think that you know I
think when I look at men well is the
whole discussion you had about finding
flat surfaces and the vision system is
tuned to find
flat surfaces because you're navigating
an environment a built environment that
has a lot of flat surfaces and that's
kind of an input constraint that you're
aware of and the output constraint is
you don't want it to bump into the wall
so you have you have a lot you have a
pretty clear set of constraints there
but what I like about what you're doing
is you're aware of those constraints
they come from you you have a pretty
clear understanding of the environment
and what it's bringing and the task and
what it's bringing and you know I think
the question you know Eric you said
something like you know when we'll
categorization what if it's all just
categorization and i guess i would say
categorization of what for what and i
think that was really the thing about
all the work on image captioning and
larry i think you're a sweet guy but I
found your work very compelling partly
because to me it was just very clear
that in that work there was very little
understanding of the social constraints
on the input pictures that have been
garnered from the world and how
regularized they are and how non
generative that input is and actually
haonan generative the output is as well
that the that the captions are just so
you know darn simplified in some sense
and I mean raised the question of what
do people when they apply a caption to a
picture think they're doing but you know
most people doing that work I don't
think really worried about that very
much and that that's actually what makes
it a bad task for AI from my perspective
I'm not saying it's a bad task for
computer science or even really from AI
from an apply perspective or even from
pushing those tech particular
technologies forward but it's hard for
me to see how to generalize the results
of that into something that I can use
for in a more profound way what's your
favorite task telling stories of course
you know I actually I got little games a
little league baseball game I will say
don't actually I have a quick thing I
was talking to somebody who does this
kind of does a lot of work on
optimization for image things and I said
you know what I'm really excited about
is the idea eventually looking at a
picture and telling a story and this guy
said he said yeah we're doing that I
said really you know it's not just uh
it's not just um
you mean like label so you said no you
know we can look at a picture and say
its people its people sitting around a
table eating dinner and I said that's
not a story you know when we had a whole
and I actually ended up having to say to
him you think it would be strange if
you're trying to design a computer
program to have some kind of
characterization of what the output of
the program actually is supposed to be
and I found it strange to have to be
able to say something like that to a
computer scientist I'll be honest with
you a couple points want to make one is
I think the story generation once people
actually started hitting on it might not
be as AI complete as we hope and I think
it is a huge I mean if people care about
integrative AI and they want the field
to go in that direction I mean one of
the biggest challenges is coming up with
challenges that people want to solve and
it's not just coming up with the
challenges coming up with the data that
goes with that challenge and making sure
the data isn't built in such a way that
it buys it is it towards like deep
learning and that sort of thing so
there's so much thought that needs to go
into developing challenge the right data
you know with cocoa should we get a more
diverse set of images so that way we see
things generalize I mean all these
things are incredibly important one
comment I want to make this it touches
on a couple things you guys said but I
think having something be interpretive
all is it's completely oversold right I
think dan den and I argue about this all
the time you have these systems each box
seems exactly what each box does I don't
think that is necessary and I think it's
actually misguided and I think in
computer vision you can look at a test
you can look an example of this we for
decades try to make our features
interpretive or can we design them by
hand right and we said okay need edge
filters and we got to a certain point
because we can do introspection we can
kind of think what would be good then we
got you a certain point and we're like I
have no idea what to do from here well I
could look at parallel lines maybe or T
junctions or you know you add these
things that each one Davey does against
such a small little minor Delta that you
could never publish a paper on it right
and you just stuck you're stuck at this
one level and then we said I don't care
anymore and and basically you know let
the algorithm learn you can't million
turn we can kind of interpret what it's
doing but what it did is it just freed
us from having to interpret what it's
doing and it did something as more
intelligent than we were doing
by hand and I don't think this is just
limited to you know the you know v4v
three levels of the visual cortex I
think it's for true for all the
different levels and how they interact
with each other we need to let go of
this introverted ability we don't
understand how humans force but Larry
Larry we say something about this yours
if without interpretability of your
software of your algorithms what back
propagation does what it means you're
stuck you're stuck with where you are
and what you know and that's solving a
problem down here which fighting
features for you that was a great
problem to solve how about going beyond
that now it's not you know what your
albums are doing it's not a science is
it engineering but you need to handle
board make progress you need to continue
to be aware and I'll to reflect about
the actual problem no no I actually
completely agree i'm just what i meant
there is interpretability is actually
great for the science to really
understand what's going on by just
scientists well yeah we times it to get
a deeper understanding i think that's
important we should be doing that but i
think in this field will actually find
that the understanding will come after
the engineering part of it where we
actually design it and it works if you
have a direction they could potentially
go gineering though yep de do it when i
do you there knowing what you're going
when you do graduate student gradient
descent right then they just try and use
my great big fish yeah it's a big I know
they are but I think I'm afraid we're
like this has been a fascinating
discussion we will take one more quick
question and then I want to give
everyone a chance because we're getting
close to the end to reflecting the last
two minutes some final thoughts but ya
thank ya oh I would like the rich panel
to react to one concept a term which
probably I find is missing i mean we
discussed from deep learning to vision
to knowledge representation common sense
everything I want the panel to react to
one simple term called memory now from
architecture and system guys it's just
to look up tail because you just give an
address and the contents come out that's
what memories taught in basic computer
science but I'm sorry cognitive
psychologists say learning and memory
goes together and there are concepts of
short-term memory long-term memory which
I am not sure whether models have been
tried out to make intelligent systems
and maybe that's missing somewhere could
you can you react to that it's a very
good question any cognitive scientist it
doesn't matter what is just right well
so so mean that's just not in vogue at
the moment as I was trying to speak good
thing I guess people certainly are
trying to be inspired by cognitive
psychology and build computational
models that are inspired by that and and
you know it's they don't they're not
they're not coming up with the best
results to get on to the news at the
moment so i want to invite the other
members of the panel to kind of clothes
off with some parting thoughts and maybe
you know what do you won one direction
maybe to talk about what do you think we
should do more of maybe next before
proceeding this big dream so i can just
follow up to my nails point you know
from system point of view I'd seen that
you know we've been living in a digital
world where everything is sort of
precise and you know we have complete
knowledge and every sees toluca to
mystic and predictable we're certainly
going out of that world now and we're
seeing more uncertainty or even in a you
know individual world and of course you
know when we interact with the real
world this is going to significantly
change change you know how we build
systems and how we you know what kind of
capabilities we need to have is about
performance not about correctness and
you know not about being predictable and
so on and I think that is to me you know
a fundamental change in how we approach
systems and this is why I see a lot of
opportunities you know combining systems
and AI together and what other the core
presupposing systems that are still be
useful and applicable and what are the
concepts of AI that actually can be
integrating all the systems that we
build and I think that that you know it
really excites me I just want to comment
merely quick on the loan short term
memory thing I think the short-term
memory is one of the most exciting areas
right now and being able to take short
term memory reason on that
and then you know how do you how do you
bring this long-term memory concept and
put it in the short term memory how do
you remember what you've said previously
so all of that is just amazingly
fascinating right now and and if you
look at you know I know I've been
harping on that works too much but a lot
of people been thinking about this sort
of thing in that context and I think to
me it's incredibly exciting now going
forward you know if we really want to
you know push integrative a I and and
and where can it go I mean the data sets
we like we talked about before I think
are incredibly critical designing
datasets designing problems which are
really difficult to solve an H it's
really really hard to cheat right the
captioning task you can cheat the the
image classification task it's not
integrative right so that's one thing we
like about the visual cue way it was
well it'll be interesting people can
cheat and there's a way around it
without something to general a prime
people will do it you know and no matter
what you do even storytelling you know
people will figure out a way to do it
which cheats right but we can do our
best we and I think in designing data
sets and designing funds we could do our
best then finally I think for a lot of
this it's really interesting to think
about how do we scale right how can we
get how can we take our ideas with these
robots and make them and I think they're
doing this with a grasping where they're
having you know not just one more bottle
in lab learning how to grass but they're
doing it with cross robots all over you
know us learning how to grasp why don't
we take how can we like get more data
you know and maybe we can't do it with
real robots maybe we do need to do it
with some you know artificial you know
something or other but I think once they
start thinking about scaling and once we
start thinking about how to you know you
had a big then I think the field would
really see a lot of progress leave Eric
last word so I'll speak now if that's
all right it's actually I want to just
put another chip on your point marriott
as i think about what useful we could
say as opposed to all this sort of
philosophical be as we've been doing
I've been continually impressed more and
more so you're working with others with
the leverage that well-chosen challenge
problems shared problems that the
community buys into an well as we like
is that you then modified you discovered
that there was a cheat there's a there's
a exploit in anything and then you you
keep changing it and so I think that
that wouldn't want to advance and I go
to the I the most I mean other than
building plots the systems can you build
of course absolutely but I don't think
they're just choosing good applications
and then making them bigger and talk to
each other and so on I don't think that
by itself is going to get us there I
think that if you want to really pull
the field I put my vote on I'm thinking
about good challenge problems the
problem sense I just think that's the
most useful thing that could possibly
come out of this discussion yeah so my
one reflection I'll share is that we're
in it's an interesting time where we're
seeing some very exciting specific
capabilities and jumps and abilities
with lots of economic value that the
company's coming from a particular
methodology particularly the
convolutional neural net as its realized
reraised a renaissance of these of these
methodologies with more data and some
and some refinement on for example the
way we do optimization with them but and
I do agree that it would be wonderful
and one potential goal of our mission is
to come up with a parsimonious set of
principles that explain everything in a
set of n layers and some procedure for
ad for for walking over the and and
modifying the parameters in those models
I think we should continue along those
lines and look great carefully at those
successes but we're not ready to
collapse our research yet into one vein
or one line of reasoning and it's
important for people in this field to
really understand the diversity of
methods that have been tried even in
earlier forms just like neural Nets
where we tried again in the current era
to think deeply about sampling
simulation planning some of these core
search some of these core methodologies
we know will be important whether or not
their selves magically in a surprising
way by a simple representation in the
future so I think it's with it's nice to
see this healthy discussion we had just
now with them
waving our hands I would call it BS it
was very interesting and valuable I
think for sharing intuitions and then
thinking about interpreting people were
saying and reacting but it's it's uh
it's wide open right now as to how it's
going to go and I have lots of questions
of curiosities and certainly those
include curiosities about what we're
seeing with neural nets and how to
visualize better and understand them
better and to innovate with them their
links to rich probabilistic graphical
model representations we've had in the
past notions of how we do causal
inference lots of questions out there
and lots of directions to go in and also
the links what we're doing to to
cognition to human cognition and what we
know about minds whether yeah abstractly
so oh yeah they're all neural Nets I
think or in more detail here's what we
found in hippocampus and so I'll stop
there thank you thanks thing the panel</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>