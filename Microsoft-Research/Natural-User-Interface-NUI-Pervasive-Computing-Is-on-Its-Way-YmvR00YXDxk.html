<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Natural User Interface (NUI): Pervasive Computing Is on Its Way | Coder Coacher - Coaching Coders</title><meta content="Natural User Interface (NUI): Pervasive Computing Is on Its Way - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Natural User Interface (NUI): Pervasive Computing Is on Its Way</b></h2><h5 class="post__date">2012-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YmvR00YXDxk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">as we discuss natural user interface
nuit and the advent of pervasive
computing with me in studio our
professors at the hassle plattener
Institute in Germany Pat bowdish and the
director here at microsoft research
connections in redmond Stewart Ansley
also joining us via Skype a researcher
at Microsoft Research UK lab shahram is
buddy there is do we have you are you
there I'm here yeah Schramm's there and
I came here but I can tell he's there
let's start right here so where I want
start with you I asking a simple
question easy for me to say what is
newly what does no II mean cuz there I
know I know what it is but there might
be people who don't know what new he is
so give us the skinny but new if this
was really exciting to be with so it's a
one of the most exciting part research
areas to be working in today we're
already seen products in the marketplace
yeah we're gonna be talking about
research today a new he brings a more
more natural more intuitive way of
interacting with computers in a way that
that's helping to bring new sensing
technology together with new powerful
software to go with new expectations
that users have of their computer
systems so we'll be seeing how New
Year's illustrated through some of the
researchers talking today well we're
excited SRAM is joining us via Skype are
you there shrimp I am I use there is
we're doing well we can hear you I want
to hit you up next you have something to
add to that we're talking about nuit and
we're going to unravel all of this today
yeah I mean as Stewart says natural user
interfaces are a very interesting
exciting area of research it's a little
bit of an overloaded term it means a lot
of different things for different
researchers some people working on
multi-touch interface would say that's a
great example of a natural user
interface where you can directly
interact and touch gestures with digital
content others would say the Kinect
camera is a great example of a natural
user interface I actually think natural
user interaction means bringing
computing into a domain where it becomes
a lot more intuitive and easy to
interact with the digital domain and I
think ultimately it's about bringing
together
mashing together these different
modalities of interaction whether it's
gestures whether it's touch whether it's
speech and making computers interact
with us as if you know as if we're
interacting with another human being but
it's more than just creating the next
generation the next version of Connect
right yes certainly yeah I think I i
think what connectors demonstrated is
how the whole body can be used as an
input device and that is a really
exciting you know set of technologies
that are associated with that but I
think that's just the beginning I think
as I said natural user interfaces are
about bringing together lots of
different modalities of interaction it
might even be speech based it might be
gesture-based and let's not actually
forget the keyboard and mouse as well
you know this is this these paint hybrid
approaches are also also interesting
well it's a pretty impressive tackling
bridging the physical and virtual worlds
I it's it's powerful slogan I mean it's
hard to sort of explain what that means
right yeah I mean I think a lot of the
work that that we're doing and Microsoft
and it's happening within the the
research world especially in
human-computer interaction is about
bridging that the physical and the
digital but actually it is a larger term
it's a broader term I think it relates
to a lot of different areas whether it's
robotics where there is computer vision
computer graphics for example these are
all areas that really are about bringing
together the real and the virtual worlds
and I think ultimately that's where the
magic lies when the the virtual behaves
more like the physical and when the real
captures the capabilities of the virtual
that's where that that's an interest
interesting intersection I believe no
patents put you in the hot seat how do
you explain the project and how it sort
of fits into bridging the physical and
the virtual world so yeah we've been
working on a project called multi toe on
which was initially just a kind of
working title what we're doing is we're
taking the idea of multi-touch
and extending it to an entire room so as
SRAM was pointing out deity of natural
user interfaces means that we want to we
want to bring okay yeah he's a bit of a
video yeah you can see here's some
actually early footage just actually for
jackets yeah so it's if you think about
it this in a wider sense a bit like a
Microsoft Surface people are walking
across it we identify people based on
their shoe prints okay yeah here's some
footage en you can play some video games
on I think this was with a lot of
involve still have students actually so
this was a big hit I think interesting
element from the from the from the
system art that we kind of try to
capture the the simplicity of
multi-touch which is a very reduced and
simple way of doing computer vision and
we try to extract 3d information from it
so normally when you have you know like
the touchscreen device you have the in
front of you we reconstruct the position
of the fingers but it's not really
necessary beyond the position of the
touch but the concept itself when
applied to an entire room actually
allows us to reconstruct not just what
touches the surface but also things that
happen above the surface so we can for
example to find out where people are in
what direction they're leaning if
they're carrying any object and so on so
we're doing some interesting
reconstruction there we think this could
be interested in the longer sense for
things like assisted living for example
we're using a pretty complex prototype
right now we actually have two rooms on
top of each other with a 1.2 tons of
glass in between that people walk on its
eight square meters large is pretty big
insulation but we think we think of this
more as a placeholder technology as you
know interactive precious sense of foil
kind of evolves that you know one day we
might you know when you roll out a new a
carpet for example this might just be
the sensor that essentially covers all
the things happening in your home and we
are writing the algorithms today that
cover you know the the sensors and
extract the information that we need for
them this is fascinating stuff because
you know why as a child we're led to
believe through the movies and
everything that the ultimate the end
goal is gonna be fingerprint you're
gonna be able put your fingerprint on
something it's gonna know who you are it
sort of evolved beyond that to the point
where I never thought about what my
footprint that I could just walk into a
room and things can happen like you said
there's so many applications in are
obvious like assisted living in
and things like that so in order to put
this into it like a big scale like a
room I mean you just said I've have a
ton of cameras and a ton of microphones
well I mean that's kind of I mean that's
kind of the prototype is pretty yeah
yeah so well so i think the traditional
approach is as to use cameras and when
you think about it I mean that's exactly
what happens to the transition from
natural user interfaces from sorry from
like traditional you know graphical user
interface to newly is that cameras play
a much bigger role or at least sensors
that generate that type of data in the
you know essentially starting the
sixties when like Doug Engelbart
invented the mouse you know recently we
had the anniversary we got very little
input about users but that little input
we had was very liable right you knew
there was you know essentially from the
computers perspective a user was a
moving coordinate across all right right
and and today that's changing the same
way we perceive the computer as being a
high-resolution image like through
graphics computer start perceiving us
kind of in a similar way also as you
know as a video if you will and so the
algorithms are getting really
interesting for getting that information
out that we want and as a matter of fact
we have another project that's not quite
ready to be showing where we actually
look at extracting fingerprints from
from tablet computers and multi-touch
systems to identify people so I'm very
excited about that yeah well I mean as
we look forward to where you know nuit
is headed I mean I i I'm seeing even
people on Twitter which by the way you
can tweet us at any time during the
summit hashtag vac some fac su mmm you
can pose questions a lot of people
joking about that this is another
example of the robot takeover they've
got us right where they want is now
they'll know where we are what we're
holding which way we're leaning we're
not training how I found us Sam who are
you guys working for really oh is this
where you see new we heading I mean this
is very impressive of course they didn't
know what what the the amazing thing
about that news is such a rich area
every time you talk about a particular
type of sensing technology or a
particular modality of user interface a
particular user context it's always just
slices on what the overall field is
about I think shahram spoke very very
nicely to the synthesis since with its
and the combination of these things
really are showing the richness of this
this area the amazing amount of work
that there is to do in of research we're
only showing some some narrow examples
but sure ultimately robot takeover
that's where I'm going perfect all right
as long as we see it coming that's like
we didn't have we didn't told you SRAM
are joining us by the way via Skype and
you want to weigh in where do you see
things headed with newish Ram yeah
that's a great question I guess you know
one of the one of the kind of
motivations for us is to start thinking
about smart spaces and smart rooms where
we can combine a variety of different
sensors we can not only combine rich
input sensing but rich output as well
through projection or new types of
display technologies and the coupling of
input and output is a really rich area
of investigation I think in in future
you work for example sorry now go ahead
so with the kinect for example you know
ultimately the the output side of things
is still experience for your TV screen
and so what's next in terms of display
technologies is an interesting question
a lot of the new e based research has
focused on input and combining it
without put this is an interesting area
I know a lot of this were tiptoeing into
we don't want to reveal too much but
shahram do you have any other nui based
projects in the pipeline you can talk
about so yeah i mean the one that really
springs to mind is a complement to the
work that Patrick was was was describing
so so Pat's work is looking at sensing
interactions in a room using this novel
bottom-up approach for once of a better
term where he has cameras looking
underneath a or mented floor we have
what Pat described as a more traditional
approach where we have multiple cameras
in a room connect cameras where we can
actually get a 360 image of all the
interactions happening in the room we
can track objects we contract users and
we have a number of different projection
technologies and tablet technologies
which can be tracked to reveal
specs of the the virtual within the
physical space and so that's a that's a
really interesting complement to two
Pat's work and that's that's where we're
we're we're actually collaborating
directly on so that's one project and
then another project that we've invested
a lot of time in is a project called
Kinect fusion and some of you have heard
of this so the idea here is to sort of
almost reverse the setup of the the
typical Connect which typically sits
above your TV screen and you're
gesturing at the at the the Kinect
camera instead why don't we grab the
Kinect camera hold it in our hands and
rapidly scan in the environment around
us and actually one of the areas that
the work particularly interested in is
using these kinds of technologies for
augmented reality where the virtual can
be overlaid onto the onto the physical
and experienced in in in rich ways so
those are the main main projects that
with we're focusing on yeah i gotta say
connect fusion it's one of the coolest
names and i wasn't sure when i first
heard the term if it was a new project
or if it was a deodorant they sort of
all try to use the same words right but
it's this is like really exciting stuff
and a lot of people obviously are trying
to figure out what's next where is this
all going people weighing in on line on
twitter you can tweet us throughout the
summit as well just use the hashtag fact
some fac su mmm we'll see your tweets
you want to pose questions or just
comments somebody just tweeted says so I
guess I won't be interacting using my
mouse and keyboard for input anymore
finally breaking the 40 year old
paradigm so people saying is that stuff
out should I go Huck it I just throw it
away no on the contrary as Pat said it
may be that these are lot of these
technologies are complementary to what
we already have right a lot of what what
new is about is about personalizing the
experience you may you may use existing
contemporary user interfaces in a
particular context but there are other
times where when using other other
modalities might be more relevant so
making the user experience personal
adaptive helping the computer system try
to anticipate the user needs this is
what what new ease encompasses hmm what
from you guys with you know boots on the
ground developing this stuff seeing it
kind of unfold what are the biggest
challenges whatever
roadblocks I mean you're starting to see
some of the some of the fruits of the
labor here but what do you think are the
biggest challenges in seeing this
evolved literally you'd have boots on
the ground right now boots on the
surface right yeah I think
algorithmically it's it's an interesting
challenge the I think I think input
devices for a long time we're known to
be like simple and reliable right now
and I think techniques like computer
vision and machine learning which were
always kind of adjacent to human
computer interaction and now kind of
being you know really integrated into
human computer interaction starting with
the fact that like you know we teach
your undergrad students you know early
on how to familiarize themselves with
these with these technologies and i
think so i think in like 10 years in the
future that the that the that students
and researchers will work in this in
this area will have a very different
skill set from what they have today as a
result of nui a very different way of
processing this type of input in order
to learn more about users and kind of
conclude more you know there's more this
there's more data and it takes more
complicated algorithms to kind of
extract what users actually intending to
do now obviously at this point there
you're working between some sort of you
know kind of fun uses but the practical
is there any concerns I'm just wondering
in you know not so much privacy but
security threats you know I mean I know
the ideas of people talking about the
thumbprint technology and even people
exploring chips and all of that then it
became well wait so if I get your
thumbprint or if I get that chip out of
his thumb then I can open his house and
all that I mean there's any of that even
come into this you know if I swipe your
shoes I can just walk into your house
right it thinks it's you yeah so I think
the for shoe prints obviously we don't
go as far we're thinking of groups you
know that kind of you know 50 people
living in a house we would not use this
for security and authentication that
said the project we're doing right now
where we're building multitude surfaces
actually is using the fingerprint and I
think your concerns are actually well
taken not so much I think there's been
several attempts to kind of go forward
with biometrics and I mean the risky
thing is if you ever have a key card
system that gets compromised well you
have to withdraw the whole key card
system if your biometric data ever gets
compromised you have to wait a
generation
right you have to wait 50 years before i
can try again so obviously this is an
interesting challenge to get that right
and for that matter you know i mean you
know i recently had my email hacked
which was a whole lot of fun to get
resolved and we could that even could
that ever happen to where i mean even if
it's just it to you know i'm walking in
my house and all of a sudden music i
don't like his planning wait a minute
who's who's reconfigured my profile here
i think at the end of the day we are
doing science here we are doing research
and these are very important questions
but the the social impact and and and
things like the security and privacy
impact and so on on on technology within
technology is always there and a back of
minds we're in society as well we use
these technologies so we're conscious of
it and it's good that in the night ii
today these concerns are higher profile
than though perhaps might might would
have done but at the end of the day we
are doing research and exploring the
boundaries of what we're trying to do is
these guys are trying to break through
make breakthrough ideas innovate it's
it's hard and taking these things into
account is important it's there but it's
not a dominant factor in constraining
are thinking just about out of time here
but before we go to i'll give you the
first crack at it final words on this
cool kind of collaboration that's
happening here yes or the collaboration
with pat we're really excited about
we're calling a surface cubed there's a
whole bunch of different technical
challenges some of which mentioned i
guess the you know there's in terms of
the software challenges alone you know a
lot of the work that we're doing is
focusing around the camera which is a
really rich sensor especially you know
when you start to think about depth
cameras you know you you you even get
richer data than the 2d data and then it
becomes a process of trying to infer
from that Ridge signal what the user is
user is doing whether it's tracking the
user detecting things like gestures and
trying to interpret those for you know
natural interactions so that's so that's
a really challenging area but then
there's the whole device side of things
it's like how do we actually experience
this rich world where the physical and
the
you know being being kind of meshed
together in this interesting way and
there I think we're just really
scratching the surface no pun intended
in terms of what could be done in terms
of different display technologies and
different ways of revealing these kind
of hidden Wealth's to the to the user
Pat shahram buttered you up properly
there what do you think parting words
this is it ultimately it's a very cool
collaborations extraordinary technology
being developed but it you know it's
good old-fashioned teamwork yeah
absolutely yeah so working with with
people at MSR Cambridge has been a
fantastic experience SRAM Steve Hodges
everyone on the team and I mean
including the fact that that for like
I'm a comparable recent addition to the
to the faculty route being at having
been at Mike stuff myself at some point
in the past and it was great to actually
bring all the students out and and get
this collaboration going so everyone's
super excited about it and I think
especially the the perspective of us
coming you know from this kind of more
surface oriented perspective and and
adding the spatial component of the
Kinect experience that that the tramps
team has is really really full right now
and and so right now next steps will be
trying to do motion capture systems that
combine these different types of sensors
because it turns out that the types of
input we get from from connect based
system and the types of input we get
from a surface weight system are quite
different oh and make a wonderful
addition together so I'm very excited
and and to move this forward together
SRAM Stuart parting words well it's a
great privilege to be working this area
with such wonderful researchers not only
are we bridging the physical and virtual
worlds but we're bridging the academic
and industrial research worlds so I
couldn't ask for a better better
collaborators it's this is just one one
tiny piece of the entire field of new
we'll see a few more into presentations
coming up this afternoon Pat will be
speaking there and let's see some more
look look forward to showing showcasing
some more later looking forward to it
great stuff thank you too Stuart Pat and
shahram for this exciting preview into
the future a pervasive computing I'm
excited about this idea of ubiquitous
computing
you know I haven't devices understand
what I need without my conscious input
but can we make like the bathroom
off-limits no sensors in the bathroom
that's that's just one there are so many
tons in this field yeah I know still the
Chimaera day one of the 2012 microsoft
research faculty summit technology and
the fight against human trafficking and
internet governance at the crossroads
but first for those of you who might
have missed it here as an encore of Eric
Horvitz is summon opening keynote
predictions decisions and intelligence
in the open world take a look each year
microsoft research helps hundreds of
influential speakers from around the
world including leading scientists
renowned experts in technology book
authors and leading academics and makes
videos of these lectures freely
available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>