<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oral Session: Attractor Network Dynamics Enable Preplay and Rapid Path Planning | Coder Coacher - Coaching Coders</title><meta content="Oral Session: Attractor Network Dynamics Enable Preplay and Rapid Path Planning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Oral Session: Attractor Network Dynamics Enable Preplay and Rapid Path Planning</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BcbP5iPWGwE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so our next speaker is stained corneal
Dane is going to introduce his work on
attracting that attracted networks
enable pre-play and rapid path planning
inmates my maze like environments so
thank you for that introduction so the
basic idea that I'm considering here is
one of the cognitive map so we know that
rats like humans if they're given enough
time to explore and learn about an area
they can develop a fairly sophisticated
model of it such that for instance if
this experimenter introduces a new
reward site within this environment that
the right is familiar with the rack can
very quickly plan a path back to that
reward and it can also very rapidly
update its policy with changing reward
positions over time so the question here
is how can this rat develop a neural
representation or a cognitive map of
this space that allows it to plan a path
between different start and goal
positions within this environment so I'm
going to be looking today at one
potential model of a cognitive map that
can be applied to this path finding
problem and because it's a neural model
it's inspired by the dynamics that we
see in hippocampus during a path
planning task and finally I'll be using
a chapter network formulation and
looking at how an attractor network
might not only be useful for
representing space but also for planning
perspective trajectories through space
so if we look at the coding properties
in hippocampus during any sort of
spatial task what we see is this very
classic place cell phenomenon so these
are neurons or play cells that tend to
respond when the animal is within a
specific region of the environment
defined by its place field
with a firing rate that in open
environments is usually described with a
gaussian light colonel so the firing
rate falls off with distance from a
particular point called the place field
center and we also see that these place
fields exist along a variety of spatial
scales within the hippocampus from about
20 centimeters across up to 10 meters
across in very large environments so
what a network of these plays cells give
us if they all have slightly different
place fields is a population code for
the animals current position in space so
the set of neurons firing at any one
point in time could be decoded by a
downstream population in order to get an
estimate of the animals current position
now this population code usually
corresponds to the animals actual
position in space but what's been shown
is that during short bursts of activity
sometimes this code can trace out a
trajectory through space away from the
animals actual location so in particular
here pfeiffer and foster looked at this
activity when the animal was stationary
within an environment before it started
moving along a novel path towards an own
goal position and what they found was
that during these bursts of activity
before the animal started moving the
population code tended to represent a
trajectory through this environment that
approximated a path towards this goal
position and also did so in a way that
was predictive of the animals future
path through the environment so this
raises a question of whether the
hippocampus might not only be involved
in sort of a passive spatial
representation function but I'm also a
more active path planning process
so the basic model that I'm going to be
using to look at whether we can explain
both of these phenomena is a bump
attractor network so this is a very
common model of hippocampal activity and
the idea here again is that we have this
cell that responds within a specific
region of this environment defined by
its place field when the rap is within
that region and we can line up these
cells within the network according to
their place field centers and then apply
a feed-forward stimulus to this network
are corresponding to a given position in
space so in this case we get a bump in
firing rates where the neurons with
place peel centre is closest to the
center of this positional input fire the
most now in a bump attractor network we
have the specific profile of recurrent
connectivity such that neurons with
similar place field centers tend to
excite one another and they tend to
inhibit neurons with distant place field
centers and what this gives the network
is a sort of memory function such that
it can retain this bump and firing rates
for some time after this feed-forward
stimulus has been removed and this could
also act as a sort of intrinsic
denoising property of the hippocampus in
responding in response to this incoming
positional input to the circuit so I'm
going to be looking at first of all
basically generalizing this classical
bump attractor network model to more
complicated environments so I be doing
that first by looking at a way of
representing the topology of these
environments in a way that we can relate
to pathfinding and then generalizing
this bump attractor so that rather than
representing these sorts of artificial
infinite lines or rings they could be
placed within a 2d environment with
walls and obstacles and then finally
I'll be looking at whether the dynamic
these bump attractor networks could be
involved in long-distance pathfinding
specifically in the pace case of bump
attractor networks incorporating large
place filled neurons so the way in which
I'm considering this basically is that
we want to find some sort of algorithm
that allows a network to determine a
path from a given position within the
environment towards a given goal
position and I think of this here in
terms of a particular value or closeness
function induced by a goal position
within the environment that the animal
wants to ascend in order to get closer
to that goal position now if this
network for instance it were
representing positions and terms of x
and y coordinates this would be very
complicated to determine if there's any
sort of obstacles blocking the animals
direct path towards that goal so instead
I'm going to be using a topology of this
environment based on the specific
features of this maze and I'll be doing
that using the success representation so
this was a framework that was put
forward by Diane Peter Diane back in
1993 and it was used in a model of
hippocampal activity here at nips just
last year by statute fellow doll and
what we can get out of this success of
representation basically is the expected
occupancy of a given position with this
within this environment assuming that
the animal starts from other states or
positions within this environment and
performs a localized random walk running
forward into the future and useful
property of this is that if we use the
success of representation to represent
spatial environments we can come up with
a mapping of these states within the
environment into a new vector space
which I'll call the successor coordinate
space where this value or closeness
function is given by the scalar product
between the representation
one state or position and the
representation of the current goal so
the idea is to use a network that's
representing positions in terms of these
successor coordinates and the fact that
in this case this value gradient is
given by the representation of the goal
position itself and then look at moving
this network representation towards a
position that's closer to the goal so a
trajectory that the animal can follow in
order to move towards the goal position
so here I'm going to basically look at
reinterpreting this bumpa chapter
network I look I described before in
terms of the successor coordinate
representation so these coordinates
basically correspond to a weighted
version of the eigenvectors of this
environmental transition matrix based on
a localized random walk so what this
gives us is a set of functions of
increasing spatial frequency across this
environment and when we define the input
to the circuit in terms of the successor
coordinates and also the input weights
in terms of these successor coordinates
what this gives us is a resulting place
filled that in this case respects the
specific topology of the environment as
we see in experiments so for instance
here respects the walls within this maze
now in addition we can look at the
activity of a whole network of neurons
representing different points in this
environment so here I plotted them each
color pixel corresponds to the activity
of a given rate based neuron in response
to this input where its color indicates
its activity and what we get is a bump
in firing rates or round neurons with
place real centers similar to this
positional input
now from this we can come up with a
population decoding so a representation
based on how these neurons respond to
different inputs of the position
currently being represented by the
network and then using this attractive
network formulation by Elizabeth and
Henderson here I essentially project
this population representation back onto
the network itself through a set of
recurrent weights so this gives the
network a sort of integrator or memory
function that allows it to maintain this
bump of firing rates in this transformed
environment over time and we can look at
the temporal dynamics of this s wreck so
this successor coordinates represented
by the network and with match strength
and the input and recurrent weights this
can be seen as sort of a low-pass filter
with a long time constant tau so
essentially we're updating this position
over time with new sensory information
coming in through SN where this bump as
a result will follow the animals
movement through this environment now
secondly we can think of this in terms
of a pathfinding Network and in this
case I'm going to apply a position
representing a given goal within this
environment and now we can see these
dynamics in terms of s wreck or the
position represented by the network as
moving towards this goal position so a
sending this value gradient with the
addition of this slow leak that controls
the overall level of activities of the
neurons within the network and also
stabilizes the activity when this s rec
reaches the goal position see idea here
is to look at how the representation of
the position changes over time in
response to an input representing a goal
position in order to determine a
trajectory that the animal should follow
a local trajectory to move closer to the
goal now this integration basically
depends on how close this representation
is to actual positions in space so one
problem we can run into is that if these
positions the original position the goal
position are very far apart in space
instead of getting a smooth movement of
this population representation from one
to another we get a jump from one to the
next so here I've applied original
stimulus corresponding to the current
position and then a second stimulus
corresponding to a goal position and
this population representation or this
bump of activity basically bumps or
jumps from the original stimulus to the
goal position so in order to look at a
potential means of counteracting this
basically we're going to develop a set
of larger place fields that spread out
throughout a greater proportion of the
environment from a low dimensional
representation of these successor
coordinates so here I've removed these
less significant higher spatial
frequency successor coordinates from
this representation and this
approximation gives us a set of a larger
place fields that spread out throughout
the environment and also a large bump in
activity rates and as a result now when
we do the same thing so I start with
initial stimulus representing a given
position where the bump is now much
larger and spreads out to incorporate
more neurons within this network and
then apply a stimulus representing the
same goal there is a smooth movement in
this activity profile between the
initial stimulus and the
position giving our potential trajectory
that the animal car followed to move
towards the goal and in fact we can
decode this very initial movement of
this bump in order to determine how the
rat could move in order to get closer to
the goal position so here I basically
initialize the network with bumps at
different positions throughout this
environment and then the arrowhead
represents the initial movement of this
bump in response to a particular goal
position and we can think of this as the
movement of or the trajectory trace
start if the rat is at a given position
with a given bump of activity and there
is a feed-forward stimulus applied to
the network representing a goal position
and since this goal position is
represented within this P for stimulus
which can be updated on the fly
basically we can get different
trajectories throughout this environment
throughout the same environment by
applying different feed-forward stimuli
and looking at the resulting trajectory
trade start by the population
representation so what these successor
coordinates give us is a means of rapid
pathfinding between different positions
within a particular environment and also
a means of generalizing these sort of
classical bump attractors to more
complicated environments involving walls
and obstacles and then finally when we
develop this low dimensional truncation
resulting in these larger bump
attractors these crude implement a long
distance path finding process between
distant points within an environment
reflected in sequential activity as we
see in the hippocampal representation so
just in closing I'd like to thank my lab
in my funding source as well as my
supervisor professor Krishna
thank you very much are there questions
oh yeah and while we take the questions
the the presenters for the spotlights
could you please come to the front now
okay so in your you're setting if I
understand correctly you assume that you
have the map given from the beginning
the maze the yeah so these basis vectors
that I saw these eigen vectors which can
be used develop this map one possibility
is that these could come out of some
sort of learning process based on higher
costs low feature analysis so this is
something I talk about a bit more in the
paper but this is an active research
topic looking at how these types of
functions could explain place L
activities starting just from raw visual
input okay thank you
have you thought about the role of grid
cells in terms of path planning in terms
of you know integrating with the play
cells grid coordinate system there yeah
so this this paper that I briefly
mentioned last year taught or suggested
that grid cells in more complicated
environments might be doing something
like these non localized functions these
eigenvectors that I showed way back when
so this could act as a coordinate system
so here I use them as a coordinate
system to develop these place cells and
one possibility is if these grid cells
transform in more complicated
environments in accordance with these
types of functions that they that might
explain how it could be a basis for this
type of complicated place uh behavior
okay thank you very much
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>