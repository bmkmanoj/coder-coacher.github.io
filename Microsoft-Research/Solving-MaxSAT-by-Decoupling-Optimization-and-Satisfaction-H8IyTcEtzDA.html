<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Solving Max-SAT by Decoupling Optimization and Satisfaction | Coder Coacher - Coaching Coders</title><meta content="Solving Max-SAT by Decoupling Optimization and Satisfaction - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Solving Max-SAT by Decoupling Optimization and Satisfaction</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/H8IyTcEtzDA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so so it's my great pleasure to
introduce Jessica Davis who will be
talking on her max at solver which one
industrial categories in weighted max at
last year and so please go ahead so
sorry Jessica is visiting from
University of Toronto where she is
currently a postdoc and we'll be at ist
later this year thank you okay so thank
you very much for inviting me to speak
at Microsoft and to visit here for a
couple of days so this is work that I
did as part of my PhD thesis last year
and I'll be talking today about how to
solve Mac set by decoupling optimization
and satisfaction so first I'll just
define the max at problem
so it's an optimization version of the
set problem and the input to a Mac set
problem is just a propositional logic
formula in conjunctive normal form where
a formula is in conjunctive normal form
if it's a conjunction of clauses and
each clause is a disjunction of literals
which our variables are their negations
now in contrast to the set problem here
in max that we have for every clause in
the formula an Associated cost or weight
which is represents the cost of
falsifying that clause so in general in
a max at problem all of the clauses
can't be satisfied some of them must be
falsified and this is how the cost is
how important they are to satisfy so the
goal is to find a truth assignment that
has minimum cost which falsifies the
least weight of clauses so in this
example we have a max that formula the L
sub-1 sub-2 sub-3 are three different
boolean variables and the first four
clauses are soft clauses soft clauses
are ones whose cost is less than
infinity so here we have costs of three
four one and ten and finally we have a
clause which is called hard because it
has an infinite
cost that means that in the max at
solution it must be satisfied then for
every possible truth assignment like
shown in this truth table there's an
Associated cost for example if we assign
l1 l2 and l3 all to zero or false
then the first the first clause will be
satisfied incurring no cost the second
clause incurs a cost of four and the
fourth clause incurs a cost of ten so
for a total cost of fourteen so the max
at solution is just the truth assignment
that achieves the minimum cost in this
case it is this truth assignment l1 to
true l2 to true l3 false and it has cost
three so there are many applications
potentially of max add because max at is
complete for a complexity class FP to
the NP which it contains all functions
that are computable in polynomial time
with access to an NP Oracle so many
different problems that fall into this
class could be efficiently expressed as
max at and there are applications
currently in fields like bioinformatics
electronic design automation operations
research etc so now I'll turn our attend
my attention to solving max ad using
integer programming so it's very easy to
formulate a max at problem as an integer
program entry program is mathematical
programming where all of the constraints
are linear inequalities over integer
variables and the objective function is
to maximize or minimize a linear
constraint over the integer variables so
in this case we've got the max that
formula and all of the clauses here have
been encoded as linear inequalities
simple encoding which actually adds
these new fresh variables to every
Clause so the first the first linear
inequality there are states that either
l1 is assigned to 0 or b1 has to be
assigned to 1
now these fresh variables I'll call them
be vary
Bulls allow the different clauses of the
Mac set formula to be falsified or
relaxed and the goal is to minimize the
sum of the costs of the B variables
which are used so the we use these in
the objective function of the integer
program and the weights of those soft
clauses become the coefficients of the
objective function so a solution to this
integer program or a 0 1 in sugar
program will be a correspond to a
solution to the Mac set problem where
you just drop the assignment to the new
B variables so MIPS solvers are very
sophisticated technique to solve integer
programs for example they're implemented
in IBM's SEAPLEX
or Goro P solvers and they use an
algorithm called branch and cut so
branch and cut relies on solving a
linear relaxation of the integer program
a linear relaxation is obtained just by
relaxing the integrality constraints on
all the variables so instead of
requiring them to be value 0 or 1 we
allow the variables to take on any value
in the range 0 to 1 and if we solve the
linear relaxation for example using an
algorithm like cplex which usually runs
in polynomial time then the cost of the
solution to the linear relaxation will
be a lower bound on the true optimum of
the original integer program and in the
case where the solution to the linear
relaxation is integral all the variables
take on 0 or 1 then it's also a solution
to the original integer program so in
the branch and cut approach we at the
root node we solve the original linear
relaxation of the original problem and
if the solution to the linear relaxation
doesn't assign all the variables
integral values we can derive a cutting
plane which will exclude that solution
of the linear it lacks a ssin and then
resolve the relaxation and iterate
solving the linear relaxation adding a
cutting plane until either the solution
to the linear program is integral or we
just
we say ok this is taking too long and we
instead we decide to branch on a
particular setting of a variable so we
can set the variable to its two possible
values and that produces restricted by
those values we get two different
subproblems and all the different
subproblems that are generated in this
way are solved using a best first search
so how does a integer programming
actually work on instances of max at so
we we did some experiments with SEAPLEX
and we took all instances from the
previous max at evaluations so these are
international evaluations held every
year since 2006 and they have three
categories of problems random problems
have been randomly generated crafted and
industrial problems so we exclude the
random instances because they're usually
different techniques have to be used in
those cases and we just report the
performance on 3826 problems that are in
crafted industrial categories so this is
the total number of problems that were
solved within the resource bounds by
three state-of-the-art
max at solvers in comparison to SEAPLEX
and we can see that the total number of
homes that see Flexcon sold is as very
is very good in comparison to the
state-of-the-art in max when suplex
sauce the linear relaxation it gets two
values for the yes yes it's floating
point yeah but it's sound
there can be some numerical issues in
inside cplex for sure and there are some
tolerances and things so it's not being
exact it's not an exact you silver does
seep it's guaranteed no no it makes no
particular guarantee no no it has a has
some tolerances within which it can
guarantee that it is within that much
from the optimum but that that's all so
quickly place get wrong croissants I I
think that it would I honestly I don't I
don't know if there are any cases where
it will give you a wrong result but I
suppose depending on the the costs in
the objective function and there may be
but I'm not I'm not my background is
definitely not in like mathematical
programming yeah so I mean if see flex
does give you an incorrect answer I
don't know we're not too worried I've
never observed that River never ever
observed it to there's no wrong answer
no yeah yeah for practical purposes it's
very trustworthy I would yeah this legs
III yeah okay okay so I suppose you
could probably implement the branch and
cut algorithm in a way that under some
conditions gave you some guarantees but
I'm not interested so okay so there are
were some cases where C flex is
outperformed and can it basically times
out on problems that are easy for other
max at solvers to solve and those come
from applications like bioinformatics or
circuit debugging planning scheduling a
timetabling so on the other hand max at
is also very close
related to the SAP problem and we can
look at how would a Sat solver be able
to address max at problems and this is
just a one slide about house--at solvers
work just to remind you it's a conflict
directed clause learning algorithm
basically uses a depth-first search
rather than the Brent the breadth-first
or best for a search of a branch and cut
and in contrast to solving a linear
relaxation the form of inference that's
applied at every node is just very
lightweight binary constraint
propagation or unit propagation which
just assigns any literal appearing in a
unit clause to the value that will
satisfy that clause and as the search
progresses if a clause is falsified
that's called a conflict and we can
analyze how those Sat solver reach that
conflict in order to derive a learnt
clause which is soundly implied by the
Sat formula and the learnt clauses are
very important because they can be used
to both guide the search through the
adjusting the branching heuristic as
well as they enable the search space to
be pruned and ultimately a proof of
unsatisfiability to be generated so in
my work the goal is to really combine
myth and Sat technology in order to
solve the MaxEnt problem because both
myth and Sat solvers are very mature and
powerful techniques but they are
definitely known to have divergent
strengths so we're interested in
combining those strengths in order to
solve an optimization problem with
logical constraints in the approach that
we introduce is called max HS and it's a
hybrid approach which uses a mips silver
and a Sat solver as black boxes the MIPS
solver is going to be responsible for
the optimization while the Sat solver is
responsible for what is good at which is
reasoning about the logical constraints
and we this this max HS approach offers
a rich design space and we investigate
several different points in this space
and we can show that the max HS silver
results in one of the most robust
solvers for max at so first I'll just
make a couple of definitions which are
important to the max a chess approach in
a given a max app formula
a core is defined to be any subset of
the soft clauses which together with the
hard clauses is inconsistent so in this
example we have a core k1 which can is
comprised of the first two soft clauses
and you can see that when taken together
with the hard clause there they're
contradictory and if we have a
collection of course so on the left here
we've got three different cores the
first core contains three clauses C 1 C
3 and C 10 then we can define a hitting
set of this collection of course to be a
subset of the soft clauses that includes
at least one clause from each of those
cores so in this case a possible hitting
set would be C 3 and C 5 including those
two clauses and we are interested in the
cost of these possible hitting sets so
the cost of a hitting set is just the
sum of the cost of the clauses that
contains and in general we're going to
be interested in finding hitting sets of
minimum cost so we make a couple of
observations about the cores and the
hitting sets first of all if you
consider any truth assignment that
satisfies the hard clauses of the max at
formula then it must falsify at least
one clause in each of the course because
the core has no satisfying assignment
and this leads us directly to the
following theorem which is if we have
some collection of course and we have a
minimum cost hitting set of them then if
we remove that hitting set from the
entire max out formula f and there's a
satisfying assignment to the remaining
formula then that satisfying assignment
is actually a max at solution so based
on that intuition we could define the
max HS basic max HS algorithm in the
algorithm we start with two sets so
we've got the hitting set current
hitting set and a current collection of
known cores we ask what
/ if we exclude the current hitting set
from the formula is the remaining
formula satisfiable or not if it is
satisfiable then the satisfying
assignment is a max that solution by the
theorem on the previous slide otherwise
if the Sat solver refutes this formula
still then the solver is able to provide
a new core which can be added to the
collection of known course we must
update the hitting set to be a hitting
set given the addition of that new core
and then we repeat and check to see if
that if we exclude that hitting set will
the remainder of the formula be
satisfiable
so these iterations continue collecting
new cores adding them to the collection
resolving the hitting set problem until
we have a minimum hitting set which
leaves a satisfiable formula and then
the algorithm terminates to be the best
solution yes yes yeah because and so the
the cost of this solution is at most the
cost of the formula minus the cost of
the hitting set right because it can
only it can only falsify it satisfies
everything that's not in the hitting set
you start out with an empty hitting set
yeah the first time you go into that
diamond okay
HS is empty so you are finding a
satisfying assignment of the entire
problem oh yeah and then if you find it
you just output it right but it can't be
something completely a random satisfying
assignment it might not be the best well
satisfying assignment in that case so
you would just exit early well I guess
the one the one thing that might clarify
this is in general the F is going to be
unsatisfiable so when the hitting set is
empty the first time through this loop
it won't it won't be able to find the
Sat solver won't be able to find a
solution
you're right yeah yeah so the billion
managed to satisfy everything then
that's great
yeah yeah yeah and the max edge solution
has zero cost
yeah what's intriguing is that it
surprises to satisfy the minimum bidding
said with respect to the Senate protocol
known course yeah so that theorem that
you have in the previous slide yeah I I
mean I was trying to prove it but I
signed it off yes yeah yeah it's fun
yeah it's a very it's very sort of very
straightforward actually so it's based
on the fact that the so the cost of any
truth assignment has to be at least the
cost of a minimum cost hitting set of
the course because any truth assignment
has to falsify at least one clause in
every core which means its cost is at
least the cost of a hitting set minimum
hitting set so you can do no better than
that
and then the fact that there's a
satisfying assignment proves that you
don't have to do any worse than that so
in so you know that we've got a lower
bound on the max at solution and this
provides an upper bound so me yeah you'd
be write it down it's not it's not it's
not really complicated but yeah yeah
it's kind of it's kind of nice because
the really the thing that's nice about
it is that you it's clear it's easier to
prove that if you've got all cores then
a minimum cost hitting set of them is a
max at solution in this case we might be
able to get away with a much smaller
subset of course just a small number of
them not all of them okay so it's
correct if it terminates it's correct by
that theorem and then the argument that
it terminates is basically that every
core that you drive in every iteration
is different from all previous course
because it the hitting set
excludes all previous course so if you
take away the hitting set the the new
core has to be a subset of
formula without that de-annex n so since
do you get a different core in every
loop and there's a finite number of
possible cores the the loop eventually
terminates so we solve the Sat problem
the sat queries using a Sat solver we
were using mini sat and we solved the
minimum hitting set problem by encoding
it as a integer programming problem and
calling SEAPLEX so let's talk about the
behavior of this basic algorithm first
of all it's kind of nice because it's
incremental which means if you terminate
it at any time you do get a lower bound
and possibly an upper bound on the true
cost of the max that solution however
there's at least three different
possible sources of exponential behavior
within this algorithm first of all at
every iteration we're solving a Sat
problem that could take a long time
second of all we're solving a hitting
set problem at every iteration that's
also np-hard and third of all we might
need a very large number of cores or
this we might require many iterations
and in the worst case that is actually
an exponential number of courses needed
so we implemented this basic algorithm
using a mini sat and SEAPLEX and we
tried it on those instances from the
previous max at evaluations and in this
slide I'm just showing where is that
time spent between the SEAPLEX
and the Sat solver where is most of that
runtime being spent and splitting the
instances into the ones that were solved
and the ones that were unsolved during
the resource limits we are looking at
the percentage of time total run time
that was spent in SEAPLEX
and in both these solvent unsolved
instances the percentage of run time
spent in SEAPLEX is very high it's
frequently very high and in unsolved
instances in particular it looks like
most of the time is being spent solving
those minimum hitting set problems so
how can we how can we improve the
performance of max HS using this
intuition that the seafoot that the
minimum hitting
problems are are taking up most of the
runtime so we have three basic
approaches to improving the basic max HS
algorithm first of all perhaps we can
give better constraints to cplex
so see flex doesn't have all information
about the original max at formula it
only has the course that you give it so
maybe if we could inform SEAPLEX better
it would propose better hitting sets and
the the process would be more efficient
second of all perhaps we can generate
the constraints the cores more cheaply
because we're using a Sat solver at the
moment that could be expensive maybe
there's some information we can give to
SEAPLEX
in that we can derive in a more
efficient manner and third of all we
could try to give SEAPLEX multiple
constraints at a time in the algorithm I
showed you we give SEAPLEX a core and we
ask it to resolve its optimization
problem then we give it another core it
has to resolve and so maybe there's some
way to shove it like a whole collection
of cores at once and then we would have
to solve hitting set problem less
frequently so first of all how can we
give better constraints than these cores
to SEAPLEX
we can observe that we're getting a core
from the Sat solver and thus a solver
may include in that core clauses that
were irrelevant to the reason why the
core is unsatisfiable so instead of
keeping these irrelevant clauses around
we could try to minimize the cores and
make sure we only give minimal cores to
SEAPLEX so a minimal core is just one
who's any proper subset of it is no
longer a core so we can use we're just
using a simple greedy algorithm which
checks if each Clause of the core can be
removed by using an additional call to a
Sat solver and in this way we can make
sure that we're only sending minimal
cores to SEAPLEX
secondly we can observe that there are
many constraints on which clauses can be
falsified or satisfied together and
these are constraints that SEAPLEX
is unaware of because we're only giving
it some information so for example
if you have any any clauses that contain
conflicting literals like l1 and not l1
it's clearly they cannot be falsified at
the same time because any truth
assignment will satisfy at least one of
these clauses so there's no point for
cplex
to put both of these clauses in the
minimum hitting set because that hitting
set cannot possibly correspond to the
max at solution so we'd like to give
some of this information that suplex is
missing to SEAPLEX so it's better
informed however some of these
constraints are not in the form of
course so on the left hand side we have
to relax
soft causes that imply this constraint
yeah so the actually the problem that
you're giving to SEAPLEX is not even
aware of the boolean interpretation of
yeah yeah yes just the SEAPLEX only
knows about the B only knows about these
B variables it doesn't know anything
about the original constraints in the
max out formula so it's quite blind
doesn't have much information about what
it's doing okay yeah yeah so in this
case this is how we get a core the core
says that either this clause
corresponding to B 3 or this clause
corresponding to B 4 is going to be
falsified in this case we have a
constraint over the B variables which is
not core it doesn't correspond to a core
it says that you can't possibly falsify
this clause and this clause at the same
time because they contain the
conflicting literals so any any
constraint any causal constraint over B
variables that includes negations we
call a non-core constraint so we'd like
to be able to give derive some of these
constraints and give them to C plugs we
can do that actually by modifying the
formula that the Sat solver is solving
by setting up a strict equivalence
between these relaxation variables and
the negation of the soft clause that
they appear in so now the B variable if
you said assign it to true that enforces
that the
as it belongs to will be falsified so if
you add just these equivalence clauses
to the Sat solver then the solver will
be able to return non core constraints
and once we make this modification
SEAPLEX is obviously not solving a pure
hitting set problem anymore
but that's something that SEAPLEX is is
actually able to able to do because it's
not a true hitting set solver it's more
general than that
pure gating since I think it might it
might because it's the same as a set
cover problem and they might you might
be able to identify that perform because
it's a it's an important problem in
operations research that cover yeah so
it's set it's like set cover with some
side constraints and who knows at what
point you know suplex will see flexes
performance will degrade okay so that
was those are a couple different ways
that we can add better constraints to
SEAPLEX now is there some way that we
can drive more constraints in a cheaper
way than close to the Sat solver so I we
we proposed to instead of using sat call
to a Sat solver to find be variable
constraint to just use the cheaper forms
of inference like unit propagation
failed literal detection to derive
constraints over the B variables and
then seed the SEAPLEX model with the
collection of constraints derived in
that way prior to solving the max out
problem using the regular iterations of
max HS so there's two two ways that we
can derive some some constraints of the
B variables the first is called
equivalent seeding and this is just
based on the observation that if the
original max set formula had clauses
units off clauses containing on one only
one literal when we introduced this
equivalence between the B variable and
the original soft clause it implies that
original literal and an original literal
is actually equivalent to one of these
relaxation variables
so what we do is we scan through all of
the clauses of the max at formula and we
look for any clause that has contains
literals all of which are equivalent to
relaxation variables and then we can
just replace those literals with the
equivalent relaxation variables and that
way derive a constraint over only the B
variables that can be added to SEAPLEX
and so that way we give some of the
constraints of the original max out
formula to SEAPLEX
and they can also be the soft clauses
and going further than that we can spend
a little bit more time to drive
additional constraints and we do this by
doing something like a failed literal
detection where for each of the B
variables we perform a trial unit
propagation so we set that variable to
true and then we perform unit
propagation and we collect all of the
other B variables which have been
implied via unit propagation and if we
have these variables which are implied
by bi bi 1 2 bi k then it represents K
binary implication clauses which can be
compactly encoded as just one linear
constraint and given two cplex
so we could we could think of other ways
that we could project the original max
that formula over the B variables and
you know that might be an interesting
line for future research so let's see
how those ideas of driving better
constraints and driving them more
cheaply have affect the performance of
Max HS so in this this reports results
on all of those instances from the
previous max out evaluations that are
non-random and on the x-axis is just a
number of problems solved within the
resource bound and these versions of Max
HS are the following so the first
version here is the basic algorithm that
I showed you
it describes you first yeah yeah what
does it mean to solve an optimization
problem it means to find the optimum so
is the optimal known for these 4 moves
yes yes well as far as I knew like you
said earlier like the standard solvers
that are used just all these following
they provide no guarantees right so one
one find a they can say this is the
optimal solution what what is the basis
for believing that that is the optimal
solution is there something like an
Oracle that has been previously
enumerated all the possible solutions in
Act
we invented that this is the most arcane
solution well okay so theoretically you
could enumerate all of the different
there's a finite number of possible
solutions so you just enumerate them all
and calculating their cost is you can do
that without a numerical no but the way
that we believe that we have correct
results is that there are many different
max at solvers and they've all reported
the same the same value so this value is
achievable
we know that the fact that there's no
better value is basically these methods
are theoretically complete if they've
been implemented correctly they provide
a guarantee so it's relying on incorrect
implementation about some of these other
techniques are ya better nice yeah
better than there are other techniques
that provide some guarantees yeah okay
yeah so it they basically rely on a Sat
solver so it depends they would their
correctness would rely on the
correctness of a Sat solver if you feel
comfortable with that and you can probe
you can verify the output of a Sat
solver yep okay yeah so this is um this
is the baseline max HS this is in you
when you take minimal course you get a
big jump in performance this is when you
introduce the equivalence the strict
equivalence between B the relaxation
variables and the soft clauses so that
you can derive non core constraints and
then these are this is when you add the
seating where you derive a bunch of
constraints cheaply
using a unit propagation and you get
another gain in performance okay so now
the other major bottleneck of max HS we
observed was the time spent solving the
hitting set problems to optimality so a
natural question arises how could we use
a heuristic or an approximation to this
optimization problem and could we use
that within the max HS algorithm
so part of the problem is that we're
solving this resolving this hitting set
problem after an addition of one
constraint and so we're solving many
related problems and all those SEAPLEX
does allow you to do like a hot start so
that if it solves related problems
perhaps it can benefit from some of the
work it did in the previous iteration we
observed experimentally that SEAPLEX is
not perfectly incremental so we would
prefer not to have to call SEAPLEX so
many times on such closely related
problems and instead use some sort of
heuristic method to replace the exact
SEAPLEX computation so in when we use a
non optimal hitting sense we can use
just any sort of approximation to the
hitting set problem and this describes
how we can incorporate those into max HS
so it's very very similar idea we have a
collection of course and we can find a
hitting set of them appropriately using
an approximation algorithm and if that
hitting set when removed from the
formula is still unsatisfiable then we
do get a new core which we can add to
the current collection and iterate so we
can use this approximation of the
hitting set in order to get a new core
from the Sat solver but what happens if
when you take this approximate hitting
set away from the formula the Sat solver
is able to find a solution what happens
then well instead in contrast to our
previous in the case where we have an
exact minimum hitting set
we cannot terminate at this point
because it has this hitting set has
potentially relax more than necessary
and that might be the reason why the
formula is satisfiable so what we
propose to do is use a more expensive
form of approximation to potentially get
even smaller hitting set and this given
that we have this better hitting set we
ask the Sat solver again is there
is it satisfiable at this point since
the hitting set is smaller than it was
in the previous step there may be a core
that we can find and then if there is a
core we can find we go back to the top
and we start using the the first level
of approximation again we can have
multiple levels of approximation and
ultimately when we run out of levels of
approximation then we need to go to the
actual exact hitting set computation at
that point if the formula is satisfiable
with that optimal hitting set then we
can terminate so hopefully we only have
to call the exact hitting set
computation a lot less frequently yeah
and the best just once exactly exactly
okay so that's just a summary actually
of what I said on the previous and the
previous slide okay so we have different
ideas of how we can calculate an
approximate hitting set and these are
the ones that we tried so first of all
we can build the hitting set
incrementally every time we get a new
core you can just add any Clause from
that core to the hitting set so the
hitting set grows quite quickly as the
number of course increases and this has
the advantage that we can basically
build the hitting set to be much larger
than the optimal hitting set but this
forces the Sat solver to find cores that
perhaps it would not be likely to
produce otherwise so it can generate a
greater diversity of course the second
method is an obvious method you could
use a standard greedy heuristic to
calculate minimum um a small hitting set
and that just simply favors clauses that
hit the most cores for the least cost
and finally when we have non core
constraints it's difficult to use any
sort of greedy method to find
approximation or like a satisfying
assignment for them so at that point if
we have non core constraints then we can
use a Sat solver to find an arbitrary
solution to them which may not have a
minimum cost but we can use as an
approximate solution
so using the non-optimal hitting sets we
can again look at how what's the
percentage of total run time that was
spent in the solving see play like using
SEAPLEX to solve exact hitting set and
in stat solving so basically the picture
has changed significantly now in most
cases the percentage of time is spent in
optimal hitting set computation is as
low on this slide or comparing the
performance of this the best version of
Max a chess which incorporates all of
the optimizations that I've described
against other state-of-the-art max at
solvers and SEAPLEX when applied to the
max at problem so on the the solver that
solves the largest number of problems is
this version that we submitted to the
evaluation last year and SEAPLEX
is also a very very good max at solver
as we observed before and then these are
the other the other max at solvers
including the baseline of max HS which
was sort of in the middle of the pack
before the optimizations and these are
some of the results from the last max at
evaluation and this years whose results
were just announced last week
this is totaling up all of the number of
instances that were solved in the
crafted and industrial categories so
this is not the metric that is actually
used in the max out evaluation but it
was the metric that with which we sort
of developed this max at solver so the
B's we are looking for a robust
technique rather than focusing on any
particular type of problem so in 2013 we
were solving the largest number of
problems of any solver other than Isaac
Isaac is a portfolio so it incorporates
many of the other max at solvers and its
performance is you know understandably
better
in 2014 we also did very well but
there's a new solver this year also by
Fahim Bacchus and Nina narrowed iske at
University of Toronto called Eva 500 and
Eva the Eva solver actually did manage
to solve more problems than we did but
it's a yeah we think we think that we
can overcome that okay so one of the
advantages of max HS which has made it
attractive for other people who are
looking to solve an optimization problem
is that we allow in the input format for
there to be non integer weights so if
you have some real valued costs in your
problem that you don't want to scale up
and you know make into integers we can
as we can still accept that natively
because we use the SEAPLEX to perform
the optimization and so the max HS
solver has actually been applied to
these two applications in data
visualization and learning of bayesian
networks recently in 2014
yeah floating floating point yeah and
another so going back to my original
observation that SEAPLEX was a pretty
good max at solver but you couldn't
solve everything let's take a look at
some problems where these are real max
at problems but SEAPLEX see flex can't
really solve the original problems so
these are problems from the
international timetabling competition
yeah can you go back a couple slides to
where you are showing the results of the
competition yeah why isn't see clicks
mention here oh sorry it is actually
mentioned here it I've because in the
evaluation it was entered under the name
of ILP integer linear programming that's
a good question yeah these this is the
performance of C flex in the competition
so it looks like it's it was pretty much
ruling earlier and then starting to -
yeah Venis nowhere near the dock no no
there's some of the some of the issues
there I haven't analyzed all the data
because I just got it last week but
there's a different there's a different
subset there's a different set of
benchmarks used in
each year's evaluation and that can
really have a big effect on which silver
performs the best that for example this
silver is very strong on a particular
some particular problems which there
were many of because you know there's
many different types of problems then if
one family of problems has you know two
thousand instances and some others only
have fifty then it's biased except no
words yeah it runs the portfolio track
it doesn't have a separate track it's
not a different track it runs them right
against all the other soldiers so that's
why I like to point out that this is a
portfolio so of course that's all more
what is the reason for bending it people
who write solver as they hate black
because a portfolio software you don't
you just take all the previous year's
solvers and run them in parallel with
different heuristics I mean you don't
need to be an expert in satsang see
there's it's it's sort of very brittle
the icing on the cake it can always be
done you know that's great that it can
be to solve real problems give you many
insight I guess I get what it does me
that people really dig this thing about
winning the competition very seriously
yeah they do they do they do so I I want
to win next year definitely people being
very serious about but I'm not serious
for example some people are specializing
on particular benchmarks yeah particular
class of benchmarks and then if if there
are people who specialize max at then
the portfolio solver just you know has
the best chance in each of those some
categories right so it generalizes by
just doing a case split over a finite
set that was given before whereas what
you're trying to do is say hey what
techniques better than that that
improved across a wide set of benchmarks
and yeah I would say like you know it's
two different i mean one is a little bit
more than the scientific yeah one more
comment about your technique yeah so I
think another strength of your technique
is that it uses Sat as a black box so
the same algorithm can be used for max
SN T also yeah we're getting to that yes
it is really easily we could we could
really easily extend it too much is that
true that particular of these this
observation in the observation that I
just made is that true for any other
solver that you listed in that
competition I think any of the Sat based
solvers which is the other predominant
technique they could all exploit an SMT
solver as well
yeah they don't they tend to use SAS all
girls also as a black box yeah thank you
yep okay so I was I was talking about
the fact that these are problems that
SEAPLEX couldn't solve originally and in
the original max out formulation of
these problems they had very you know
ninety-three thousand variables five
hundred and sixty two thousand clauses
and SEAPLEX was timing out on those
we're very sort of they're pretty large
problems right now
when max HS on the other hand which can
solve these problems in you know a
pretty pretty good small amount of time
and it's interesting to look at the
final model that SEAPLEX has to solve so
in this case the the model that C flex
has to solve has you know many fewer
variables and a very small number of
constraints so these are problem this
all of a sudden becomes tractable for
SEAPLEX and basically you can sort of
think of it as reformulating the
original problem as a problem that can
be solved by SEAPLEX
the second third to last columns these
are the matrix for the heating sense
computation yeah yeah and this is
actually with the basic version of Mac's
HS so these are actually just strictly
cores yep okay and then there's some
relationships between Macs HS and other
existing work and some of these are very
really very strong relationships so in
operations research benders
decomposition is very old technique to
improve the ability of solvers to solve
integer programs and hooker john hooker
has introduced something called logic
based benders decomposition where his
idea is to exploit two different types
of technology to solve scheduling
problems so in the scheduling problem
you might have something like multiple
facilities and many tasks that can be
carried out on each of the facilities so
the assignment of tasks to a facility is
may be solvable using mips over an
integer programming solver but the
actual scheduling of the tasks once
they've been assigned to a facility that
scheduling is perhaps better done by a
constraint programming solver so logic
based benders was a way to combine those
two technologies in in a vendor's
decomposition basically the idea is that
all the variables of the optimization
problem are partitioned into set X and a
set Y and then the optimization problem
is just to minimize some linear function
of X f of X and Y subject to constraints
over x and y and the master probe the
so-called master problem assigns a value
to the variables X and then the problem
is called the inference tool which is to
infer the tightest possible lower bound
on the objective function that is
implied by the constraints subject to
this particular setting of the values of
the variables X
so in Yuka c-max HS as an instance of
logic based vendors decomposition where
the partitioning of the variables is
basically into the B variables and the
original variables the master problem of
the benders decomposition is the problem
that's being solved by C flex over the B
variables and subject to the solution to
the master problem the Sat solver is
used to solve the sub problem over the
original variables and in the case when
that sub problem is infeasible the
solver is able to produce core and
non-core constraint which actually is a
vendor's cut and that could be given
back to the master problem the max HS
approach is also very similar to
something called the implicit hitting
set problem which was introduced by
Chandrashekhar and carp in Murano
Centeno they this is basically a hitting
set problem where the sets that you need
to hit are not available there's
potentially an exponential number of
them and the only way you have access to
them is through an Oracle so given a
candidate hitting set you can ask the
Oracle is there any set that hasn't been
hit yet and if there if there is the
Oracle will return one of those unhip
sets and if there if the hitting set is
complete the Oracle is they have also
able to tell you that yes you've hit
everything so they've they implemented a
solver for the implicit hitting set
problem that also used SEAPLEX to handle
the hitting sets and they've showed that
it had very good performance on this
problem in bioinformatics called multi
genome alignment now in contrast to max
HS basically they have they assumed that
this Oracle that generates the sets to
hit is can run in polynomial time
whereas in our case we have we're using
a Sat solver as our our Oracle so in
future work some of the ideas that we
have to work on to improve max HS are to
incorporate ideas from the literature
like stratification so stratification is
basically the idea of solving a maxout
problem by taking
only the clauses over only the
constraints over only the clauses with
highest cost and solving that Mac set
problem to optimality and then adding
clauses of lower cost and six and
resolving the problem and then adding
clauses of even lower costs so basically
you find course only over clauses of
high cost and this allows you to make
progress quickly towards the optimum and
the other idea we we should probably
look at is better more sophisticated
techniques to get minimal cores because
there's a lot of a lot of work done on
minimal unsatisfiable subset computation
and finally I'd like to extend it to max
SMT one way that we could do this is to
: SMT solver from within the max HS
framework which would be basically using
a Mac sessom SMT solver as a black box
in place of the SAS holder so I think
that that's all and thank you very much
thank you very much for your attention
yeah great
the nigga are you aware of any users of
Naxos NT in the program analysis context
yes
Shivan who has I think stopped reacting
I mean a teacher
Laurie controversial should I say paper
and then peel the I this year on using
Mac's that or creating by unfolding
abstractions or finding abstractions on
demand for database punch to analysis so
you basically the idea is to limits the
context sensitivity by creating a very
rough abstraction and then one day when
the abstraction that gives the longer
source you set up an Excel problem to
find the least number of contexts you
need to unfold this is one an example of
a situation where even though the worst
case complexity is polynomial they get
somehow better results by making calls
to an Oracle there is theoretically
exponential because I mean it is
analysis etc in the worst cases all
polynomial but if they're using max
maybe you know there's some like
sensitivity factor and it gets
exponential and that sensitivity factor
maybe if the vanilla alias analysis is
all polynomial yeah
yeah attending my works anyway that was
another example okay okay program
analysis thank you thank you thank you
Thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>