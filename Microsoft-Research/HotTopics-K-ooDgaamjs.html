<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HotTopics | Coder Coacher - Coaching Coders</title><meta content="HotTopics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HotTopics</b></h2><h5 class="post__date">2016-07-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/K-ooDgaamjs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">please welcome Jeanette wing hello
everyone I'm back so thank you Peter for
that very nice talk about where computer
science is going and where it's been
this is the hot topics session and we're
going to hear from four different
researcher research projects and that
basically span the interest in breadth
of research at microsoft research from
AI machine learning to privacy and
security to systems and networking to
health care and biology and what i'm
going to do is let you hear from the
researchers themselves so i'm going to
call up one or two persons per project
and we'll have a little informal QA and
we get well we'll hear from them about
the research so I'd like to start with a
I of course you've heard and everyone
knows it's in the air that with the
advances in deep learning and
reinforcement learning and so on we've
really made tremendous progress in task
like speech in object recognition and so
on and I think this is emboldened the
entire community the research community
and industry to strive again for that
grand quest in AI to build an agent that
combines all the cognitive skills of
humans vision speech natural language
understanding even mobility so in our
first story we're going to hear about
the combination of vision and natural
language understanding and let me start
with a teaser whoops let's see there we
go look at this picture what is the
first question that comes to your mind
when you see this picture what's
happened to the right
what's happened was anyone hurt was the
motorcyclist injured now imagine trying
to get up computer to generate those
questions there isn't even a
motorcyclist in the picture for the
computer to talk about so this is not so
easy so what I'd like to do is call up
Lucy Vander Wende to join me on stage
and we'll talk about this visual
question generation task Lucy hydrant
you got you Thanks have a seat yes so
can you explain why would we want to get
computers to generate questions in the
first place what's the context and
motivation for this work well questions
are very interesting and in fact
questions are one way that we as people
demonstrate an understanding of the
situation so we don't walk around making
statements all day long that would be
very robotic we sometimes give
information but we also ask information
we ask questions and so to be natural we
want to train a computer to do both as
well ask questions and answer questions
now why photos photos are interesting
because imagine how many conversations
get started when you show a picture to a
friend they imagine how popular snapchat
and Instagram are in fact and sometimes
the conversation just says oh how cute
or oh that's terrible and the
conversation ends but sometimes you
might get a very you know somebody might
ask you a question and you really take
that opportunity to engage with that
person and to really get to know them
better and that's the kind of natural
question that we're after great so you
know as a human I don't think how is it
that i generate questions it just comes
naturally we just generate questions or
ask questions naturally so how is it
that you think about how to get a
machine to generate questions well how
we say what we're going to say as humans
is kind of a still a deeply
philosophical question and we really
don't know the answer
yet but for computers we can think of a
few models so one is to think of each
conversational turn as a translation
from what I hear to what I'm going to
say and in fact it's my colleagues bill
Dolan and Michelle Valley who have
pioneered this machine translation model
for conversation there's another model
which treats conversation like retrieval
what is the biggest chunk that something
that I've said before or heard before
that Matt best matches the input and
just output that without thinking like a
lookup table it's a lookup table the
thing that we're of course interested in
is the neural models we're given an
input what should the system pay
attention to and which words are
triggered by that input and we think
that this vest explains the questions
that we see for motorcycles the
motorcycle picture where the system
observes the collection of objects those
together evoke accident hurt injured and
then from that we generate a question
well I understand in all three of these
generative models they fell short of
human ability so how far did they fall
short and what can we as a community do
to make progress on this task so a human
evaluation tells us that a human
generated question scores 2.5 on average
for a scale of 1 to 3 for naturalness
the our best model the neural model
scores on average 1.75 so there's a gap
and the gap is largely explained by the
variety of questions that the computer
ants that can ask and there are two ways
that we were wanting that we want to
work on this one is through better
content selection so for this image for
sure you can say who is this but surely
there is something much more compelling
and interesting to ask about is that
really I don't know it is really good so
that's that's the thing it's it's as
people we zoom in on what's important
where is the cat the machine right now
the computer is still at the in the
stage of cataloging what are the objects
in
in the in the field in its field of
vision so question generation is
actually a really nice way to test
whether a computer can pay attention to
the right thing it can focus in on the
rest and another way to increase the
variety of questions will be better
common sense reasoning so for the
motorcycle accident picture in our data
set we have enough images of accident
but it knows to recognize an accident
and then to say did somebody get hurt
but for an image like this we don't yet
have enough samples in our data set so
how does it go from seeing that there's
a potato to knowing that there we could
ask a question what's for dinner that
would seem to require common sense as
people we think that this is common
sense but common sense may itself not
come as a component a standalone
component that we that the machine needs
right how to learn this common sense and
how to represent it are themselves
interesting research questions I
actually understand even for your PhD
thesis you are struggling with this term
vegetable market right now compounds
they're fascinating so what you know
what do you see as the the challenges
for our being able to use this kind of
question answer kind of system to build
truly conversational agents that we can
talk about our daily lives within a very
informal manner right so I think you
know I think right now we can use
conversational agents at the level of an
acquaintance we've told them some
information we're willing to share some
information and locally it might be
coherent I think the challenge is
sustained conversation over time so the
difference between acquaintance and a
friend is a friend remembers the
information that we've told it and uses
that information in really subtle ways
to demonstrate the bond that we have so
imagine that you've posted this picture
and that are not really my car if not
real
but a brand-new conversational agent
might say whose car is this and you
would let's pretend you're going to say
it's it's like it's your car everyone
know he's here I Drive on the autumn a
red one I had to take a stock picture
but then next week you post this picture
of the car but now on a highway scene
now Kim should the computer now say
whose car is that no it would break your
trust because you know this has already
been out it didn't remember they didn't
remember right so there are other
questions that are more natural given
our past history so I think those are
one of the challenges but another thing
I wanted to bring out about
conversational agents is this one a
great example where we've just finished
training a model that given the image
and given some limited amount of context
here I made a little treat for my
co-workers the machine now can generate
a new question and I was really
surprised when it generated where's mine
Wow right thanks that means half but I
then it also realized you know we need
to add some fun to our conversational
agents as well so in order to have that
sustained conversation it's not only
about the information it's also about
the experience in the engagement yes
thank you very much Lissy so that's
great just wanted to say on the topic
this on I enjoy working with all of my
collaborators and I just wanted to call
out especially nasara and most of us a
day who's been the main work person
who's been working on this project and
she's here in the audience i believe
yachty something great thank you very
much Lucy thank you
so the next story is about the marriage
between cryptography and machine
learning and so let me start with the
cartography side of the story in 2009
Craig Gentry published his breakthrough
results on fully homomorphic encryption
showing how we can actually compute over
encrypted data and this gave especially
the privacy advocates a hope that we
could actually entrust in cloud
providers private data and have the
cloud compute over the encrypted data
without seeing the data in plaintext and
so in this particular work we're going
to show how we are able to use
homomorphic encryption to build
prediction services and the work builds
on a simple encrypted arithmetic library
called seal that we implemented here at
Microsoft Research and released to the
public last November for download so
this is one of the building blocks that
we're providing all of you to work with
and that we use ourselves I'd like to
call Ronnie guillod Bachrach up on stage
and we will talk more about this
marriage between cryptography and
machine learning Ronnie how'd you know
nice seeing you here you go so before we
get into the technical details Ronnie
give us one example of motivating this
work yeah so imagine you had your DNA
sequence so obviously you may want to
use it to get some predictions or risk
factors you might have but if there was
a service providing these predictions
you might be reluctant to use it because
they might lick your information whether
intentionally or unintentionally and
once your DNA leaked it's much harder to
get the new one compared to just getting
a new credit card so so the question we
were asking is can we build such a
service that can make these predictions
but without leaking your information
that's great so you are a machine
learning expert not a cryptography
expert let alone homomorphic encryption
expert and yet you work with
cryptographers who are not machine
learning experts let alone deep neural
network expert so what was the aha that
you had to make this marriage work yeah
so you know when I was introduced to
this concept of homomorphic encryption I
was I was looking for the catch because
morally it should be impossible to
compute over encrypted data but but you
know after i looked at the math and you
know i came to realize yes it's it's
possible but i'm not at the level that I
can really modify it or tweak it I can
understand it and the aha moment was
when I was talking to my cryptographer
partners and realized that they see
machine learning in the same way they
see it as black magic that that works
they can understand it they can use it
but they cannot modify it in order to
solve a problem and and once we work
together we can actually open all these
black boxes and let me give you an
example for that so for example one of
the keys in neural networks is
activation function activation function
is just a nonlinear function typically
we use a sigmoid function or the
rectified linear function and the
problem is when you want to apply it to
data that is encrypted with homomorphic
encryption it's kind of hard people
tried it and without great success but
when I look at it as as a machine
learning researcher I know that there is
nothing sacred about this specific
functions right we use them out of
convenience they are very convenient for
use but we can use many others so now we
were talking and trying to understand
what are the limitations that we have
from cryptography the main limitation in
order to be practical that the function
that you want to apply have to be a
polynomial of low degree for machine
learning point of view with the main
limitation is that it has to be
nonlinear so now you put all these
limitations together you are looking for
a nonlinear function which is polynomial
of loading
it's x squared that's that was yaha yeah
and and so here's an example of how we
tweaked the machine learning part of it
to make things more practical but the
same thing happened when we used we
tweaked the cryptography part of it for
example in the same thing when you apply
to our network you have a lot of time
that you want to multiply your data by
some constants it turns out that you can
do this multiplication much faster when
you multiply a constant by a data then
multiplying two data points this is
something that I'm as a machine learning
researcher would not have come up with
but for the cryptographer this is kind
of oh yeah you can do that and once you
sit together you just see everything
opens up well that's that's that's
wonderful I when Ronnie first told me
about this work he he told this story in
the hon I'm so excited I was so
impressed and this really goes to show
how people in different disciplines
coming together can really make new
things happen um one of the things that
I I hear a lot is when when you mention
cryptography especially two systems
people they think Oh slow it's going to
slow my system down doesn't speed up its
performance is bad so but you actually
would this work have very good
performance and you can show that this
work actually applies to a range of
applications can you speak to that yeah
so you know a homo homo freak encryption
is treated in many cases as a nice
theoretical exercise of no practical use
and we wanted to try whether we can make
it practical so the first thing that we
tried is neon network we already talked
about it and and here we used a standard
benchmark in machine learning which is
the amnesty day to set you have
handwritten digit and you're trying to
recognize the digits we build a new
network that had an accuracy of
ninety-nine percent it's not this
state-of-the-art but it's it's a very
decent result for this data set and
we're able to make a prediction on a
single image in five minutes on a single
desktop and then our cryptographer
pulled another trick which allows
actually to batch the prediction so you
can make 4,000 predictions in
minutes and just to give you a sense of
the security that we have actually that
the service that provide the predictions
cannot tell the difference between
whether it's making a single prediction
or 4,000 predictions we even didn't have
to change a line of code in order to
allow that so here we can do it in five
minutes but then we went on and we did a
little hackathon in offices in New
England and we build two additional
applications one of them is a pneumonia
risk predictor so here you're getting
your medical record and you're trying to
compute the the risk from pneumonia and
this is using a special kind of machine
learning model which is called
interpretable models and here every
prediction takes about 40 seconds and
again you can stack them together and
get 4,000 predictions in this for 40
seconds and another application with
that we built with a genomic predictor
which takes up your DNA so 200,000 snips
200,000 variants of your DNA and makes a
prediction on your trades or risks and
this one takes two seconds to complete
that's impressive and and and when you
asked about whether it's practical or
not the way I like to think about it are
you willing to wait for two seconds when
you're trying to get a prediction on
your DNA and you're Riskin and trades in
order to make sure that it's secure if
you're willing to wait for two seconds I
think that homomorphic encryption zar
practical and can be used for medical
applications but other applications as
well such as finance for example cases
in which you care about your privacy I'm
willing to wait two seconds Thank You
Ronnie that was beautiful thanks very
much and I did
call out Ronnie's collaborators and also
this is the URL that tells you where you
can download the simple encrypted
arithmetic library that I mentioned
earlier so with our next story I we're
going to talk about security if security
is part of the bigger picture that I
mentioned in my opening remarks about
trust in this case trusting the Internet
you know we trust the internet today to
do all our daily transactions our
financial transactions and so on but we
use computer scientists know quite well
that the internet is insecure and quite
vulnerable to attack so in the Everest
expedition that just started a couple
months ago the team's goal is to within
four years deploy a verified secure
version of the entire HTTPS ecosystem
that's pretty ambitious so the team we
got together or they form themselves
actually is quite impressive also in
that it spans three different labs in
Bangalore Cambridge England of course
here in redmond and we have academic
partners in in RIA and other
universities now Cedric 4na is a key
person in this team but he couldn't be
here today but I we have Brian porno and
nick hill swami to join us to talk about
the Everest expedition so Nick Brian
thanks for joining us so so Brian I'll
start with you what is HTTPS and why is
it so important and can you give us an
example so some internet meltdowns
because HTTPS is so insecure sure so
https is critical infrastructure it's
the foundation on which internet
security is built so it includes not
just the HTTPS protocol itself but also
the underlying transport layer security
or TLS protocol the x.509 standard for
certificates and identity management so
numerous cryptographic
algorithms and it's used for internet
traffic every single day over half the
internet traffic is encrypted using
HTTPS and it's used not just for the web
but also for things like email voice
over IP VPNs and many other applications
so we use it without even our realizing
it yes and so unfortunately that means
because it's so ubiquitous if there's a
vulnerability in any of these components
then the entire world is at risk and
we've seen that with high-profile events
like heartbleed or the recent freak
attacks so what is ever is going to do
about this well so we're going to be
looking at all these different
vulnerabilities that we've seen
historically so there's been say 20
years of attacks on this ecosystem and
they've ranged all the way from
low-level buffer buffer overflows to
higher level things like lacks
certificate parsing or validation or
weak or encrypt cryptography to side
channels and even to design flaws in the
standards themselves and there's
actually been multiple academic survey
papers published just cataloging all the
different ways in which this ecosystem
has been broken and many of these
vulnerabilities are very subtle they're
not the kind of thing you're ever going
to find through simple bounds checking
or through randomized testing and so to
get rid of all these bugs that we've
seen all over the ecosystem and to avoid
ever having another heart bleed or a
freak attack we're actually going to
develop verified replacements for each
one of these components and we're going
to prove that each component as well as
the composition is secure that means
that we'll never have any of the
vulnerabilities that I showed you on the
previous slide and furthermore we're
going to be focusing on deployability as
well we want our code to be high
performance standards compliant and easy
to interoperate with existing clients
and servers and of course along the way
will be improving the tools that we're
using for to do this verification so
that others can use them in future
efforts good Nick what exactly are we
going to prove about our code and and
what tools are we going to use to do
those proofs right so so clearly we want
to want to prove that our code doesn't
have any of the vulnerabilities that
that that Brian mentioned but trying to
go about this by enumerated all those
vulnerabilities and trying to squash
each one of them individually is a lost
cause Christmas if there's too many and
there's some that we may just not even
anticipate so instead what we're doing
is identifying a simple high-level
security property
that we can provide our code from which
you can conclude that we are
invulnerable to all these attacks that
we know off and other classes that we
may not even know off yet so to give you
an example for TLS the protocol at the
core of this ecosystem what we prove is
that an attacker cannot tell the
difference between the concrete version
of TLS that's actually encrypting
secrets on the network and an idealized
version of TLS that's only exchanging
random bytes except for a negligible
probability subject to some
cryptographic assumptions so this is the
kind of property that a cryptographer
would prove about a protocol usually
about an idealized model of a protocol
and pencil and paper but what we are
doing is we're proving this kind of
property about the code that actually
implements the protocol with all its
optimizations down to the actual
implementations of the crypto primitives
so to actually do these it sounds like
that's like a by simulation argument
that's right it's a by simulation kind
of a probabilistic equivalence between
these two versions of the TLS so so we
need to actually analyze the code to do
these proofs and for that we make use of
several verification tools that have
been built at MSR one of them sort of
near and dear to my heart zip your
jacket and show off your t-shirt is f
star is a programming language and a
verification system that on the one hand
looks a bit like a proof assistant like
 and on the other it's it's based on
a higher order effect full typed
programming language like in the
tradition of standard ml and we use f
star to do the proofs of TLS and other
language that we use is Daphne which
looks a bit like C sharp it's an
imperative object-oriented language but
with a verification system that's based
on first order logic on first order for
logic underlying both these tools is is
z3 an automated theorem prover that's
very widely used both inside MSR in many
verification projects and outside MSR
I'm sure many of you out here have used
e34 for your projects and without z3
trying to scale our proves to the extent
to which we we do scale them would just
be unthinkable I think now lest I give
the impression that we're just going to
be completely bulletproof the what we're
aiming to do as Brian mentioned is to
deploy verified code inside the existing
software ecosystem so we're going to
have a deployment of ever stls inside
say Apache but we don't plan to verify
the rest of Apache or the operating
system on which it runs and so it is
possible that a vulnerability in the
operating system could just take down
the security of the entire stack and
having a verify to your lesson there is
you know a boot point but we still think
that being able to produce high
assurance components that have provable
security guarantees is really the only
way in which you can build very reliable
stacks and yeah and so we think so we
think what we do we'll have that I think
you know it is a four-year goal and it
is very ambitious to actually think
about doing a verified system with lots
and lots of complicated components that
interact with each other and then to do
it in a performant way that you're just
going to drop in what what makes you
think you can succeed so it's certainly
ambitious set of goals and we're helped
by the fact that in general the field of
software verification is advanced
tremendously in the last 10 years and in
particular are our team is bringing
together several lines of research that
have been working in this general area
and so we're benefiting from previous
results and experience so for example
the MSR iron cloud project has been
building a wide variety of
high-performance system software that's
been verified for both security and for
reliability and the distributed setting
the and we're able to get good
performance in part because we're using
verification languages that operated a
low imperative level all the way down to
the level of verified assembly code now
at the a higher level the meat ALS
project has shown that it's possible to
verify the security of real world
protocols so not just models but the
actual protocols are being used in the
real world and so they've shown that the
process of verification actually leads
to a better understanding of the
security of the system itself and
discovers vulnerabilities at both the
limitation and even the specification
level and these are vulnerabilities have
been lying there for years that nobody
found and of course we're building on
all these verification tools that Nick
mentioned and so there's been tremendous
progress there and we're benefiting from
that effort and yet if we look back at
the ecosystem that we're trying to
verify you can see that the amount of
work we've done so far really leaves a
lot left to be done and yet as Nick
alluded to I think the HTTPS ecosystem
is kind of a sweet spot for verification
it's clearly critical infrastructure and
it's demonstrably too large to get right
without verification and yet it's much
smaller than a traditional say operating
system or browser and so it seems within
reach of our tools and techniques that's
that's great so what's one less question
Nick what's suppose we do succeed in
achieving this goal how do you imagine
getting the community to actually adopt
this verified HTTPS ecosystem right yeah
that's a that's a difficult question
partly because it involves I think a lot
of intangibles and we have a few things
in mind that we think will help so the
first thing is that we're we're doing
everything in open-source both to
encourage as much scrutiny as possible
as well as to invite participation from
from the community so if any of you out
here are interested in the stuff get in
touch with us the second thing that
we're doing is something that Brian
mentioned earlier is to ease deployment
of our code although we're programming
and verifying in languages like capstar
and Daphne we're going to compile our
code and distribute it as C++ C and C++
which is which should make it possible
for people who are not quite familiar
with our exotic verification languages
to actually study our code and convince
themselves that it's a suitable
replacement for say openssl mm-hmm the
third thing which i think is maybe the
most important and and maybe also the
most relevant for this faculty summit is
I think education so I think it really
requires a long process of Education for
for people to appreciate the very
tangible benefits that that software
verification actually provides and what
we've noticed i think is that in the
last decade or so students emerging from
universities all around the world in
computer science are are coming out with
a better understanding better priests
for what formal methods is and what it
has to offer and it's only with this
trend continuing that I think Everest
will eventually succeed that's great to
hear I I know most of you know that only
I'm informal methods and I did not ask
him to say that in his answer but also I
know very well that many of you are
having your undergraduate curricula
courses that teach pre and post
conditions which are just the requires
and ensures clauses of daphne teach
functional programming which is really
in essence what f star is all about so
the the students that you are teaching
today will be armed with the right kinds
of approaches and techniques and skills
to do this kind of verification for the
future so let me thank you for that
thank you Brian excellent Thank You Nick
great okay our last story speaks to the
opening remarks I made when I talked
about tomorrow's computing machines that
might be made out of living matter in
particular i'm talkin about let's build
computers made out of DNA molecules and
we have a biological computation group
and with a bunch of collaborators in
microsoft research which aspires to be
able to write in a high-level
programming language a program that you
can then compile down into a machine
that's made up of just DNA molecules so
this is pretty ambitious um it's pretty
far out and what i like to do is call
Neil dash out to join me on stage and
we're going to talk about molecular
computing so thank you hard yeah good
before we get into the details what I
thought we should explain to the
audience or or what are some of the
building blocks for DNA computing and
one of them I know that you and your
collaborators have built is this thing
called a DNA
drown displacement tool so can you
explain what DNA strand displacement is
and and what's the largest program
you've written in this language yeah
sure thanks Jeanette so I'm going to use
an animation to help explain what DNA
strand displacement is so what's
unencrypted discovered the structure of
DNA some years ago now and the
complementarity rules where a binds to T
and C binds to G and what this animation
is going to show is a process known as
DNA strand displacement which is being
used now by a community of researchers
to be able to implement computation
using DNA molecules so what you see is
an input DNA strand that single-stranded
piece of DNA which is binding to a
complementary DNA molecule which
essentially plays the role of a logic
gate so the inputs around binds and it's
actually displacing another piece of
single-stranded DNA which plays the role
of an output molecule so what we
generated here is an input to output
relationship made purely from DNA now by
extending these DNA logic gates to be
able to take multiple inputs and then
through composition we're able to
actually dis design arbitrary logic
circuits so with some collaborators
actually here in Washington Georg seelix
lab we've worked very closely with them
over the last year's we have implemented
a DNA version of the so-called
approximate majority algorithm now this
is an algorithm that's used in
distributed computing to be able to
detect the consensus of a mixed
population of agents so in our case what
we wanted to do is apply this to a mixed
population of DNA agents so on the Left
you're seeing some input signals which
are pieces of DNA some are red and some
agreeing that's encoded in their DNA
sequence now we then can describe the
approximate majority algorithm by a
number of rules which is shown in the
right top right-hand corner of that
middlebury where's out there yeah and so
they're very simple rules but
theoretical analysis of these rules
enables us to conclude that the
consensus is efficiently computed by
this protocol so it remains to then
attempt to mimic the
behavior of these rules using our DNA
architecture which relies on that DNA
strand displacement process that I just
showed you and so when we measure this
DNA implementation in a test tube what
we find indeed is that the consensus is
efficiently computed well I say
efficiently actually it takes several
hours so actually over 15 hours it took
to compete the correct computation here
so I would say that this architecture is
not exactly going to rival silicon
anytime soon well one of my favorite
other examples of a DNA computer is one
that Shannon Winfrey at Caltech did that
when they published about in 2011 which
is a machine made out of 74 DNA DNA
molecules that computes the square root
of a four bit integer now so both in
that program and in this distributed
consensus program clearly scale and
speed are still a limitation to this
technique but what I understand is you
and your colleagues most recently are
using this notion of DNA origami to
address the speed and scalability
limitations of the prior approaches can
you explain what DNA origami is and and
what can you do with that yeah sure so
DNA origami is really fascinating it was
a technique that was pioneered by Paul
rothermund about ten years ago in a
seminal paper published in the journal
Nature and the idea is that you can
actually wind a long piece of
single-stranded DNA treating like a
scaffold into a desired shape by
designing shorter staple strands so
that's what you're seeing on the diagram
on the left there so the little colored
ones of these staple strands their
sequence has been designed suitably now
in this paper they showed that you could
actually design and realize a range of
different two-dimensional shapes so
simple shapes such as rectangles but
also more complex shapes such as a star
in a smiley face here now these are
really at the nanoscale we're talking
hundreds and Anna meters here so you
have to use atomic force microscopy to
be able to image them now more recently
we've done something fairly exciting
so we've actually built our own
experimental wet lab in MSR Cambridge
and one of the researchers in the in our
group called boy and Jordan oov has
actually used DNA origami as a template
to fix to it small proteins which as you
can see have been suitably chosen to
spell out MSR so this is great
advertising for MSR and I should also
acknowledged that the atomic force
microscopy imaging was done with our
collaborators at the University
Cambridge or kaisers lab now this raises
the possibility of using origamis as a
template for molecular circuits as well
so here we've attached proteins to the
tile but you could also of course
attached DNA logic gates like we saw in
the strand displacement circuits before
now by attaching them to a fixed base
you can take advantage of what we refer
to as a localization which is the idea
of basically removing the need for
molecular diffusion for mach 2 molecules
to find each other and then trigger a
reaction and so localization in theory
should speed up our molecular circuits
by orders of magnitude and our
theoretical analysis indeed has
suggested that you can go from circus
running over the course of hours right
down to minutes but then if you're
building these localized molecular
circuits out of these DNA origami tiles
then is there a limitation to the size
of the computation that you can perform
on on these tiles yeah of course the the
larger the tile is the the more
molecules you can fix to it so of course
you're always going to be limited by the
size of the tile so on the one hand you
could think about maybe making bigger
tiles of course but it also raises the
possibility that maybe you can
distribute computation over multiple
tiles nevertheless with a standard size
tile which again is about a hundred
nanometers big you can already fit on 16
DNA logic gates and in this particularly
compelling example here we've been able
to implement again in collaboration
revealed seelix lab a localized version
of an X North circuit which is
implemented using dual rail logic and
what you see on the right hand side is
that
experimental measurements compared with
the theory which shows that indeed these
circuits can run giving correct answer
within minutes that's that's pretty
impressive and this is this is new work
you see it's not even published yet so I
understand that stochasticity is is it
actually inherent to what it is you're
doing because after all they're just DNA
molecules interacting with each other
which is just chemical reactions yet you
use probabilistic model checking in some
way in your tool suite to assure that
the the program does the right thing how
do you actually use probabilistic model
checking yeah you're quite right Janette
so you know stochastic fluctuations are
going to become really important in
localized circuits because all of those
interactions are inherently at the
single-molecule level so if we want to
analyze for example how long does it
take for a given circuit to complete
then we must use a probabilistic
analysis to capture the effective that
those molecular fluctuations so what we
use is an equation called the chemical
master equation which essentially
describes the probability of a given
circuit being in a particular
configuration at some time T now we've
also developed some efficient algorithms
in our group in MSR that enable us to
provide numerical solutions to the
chemical master equation and those are
actually orders of magnitude faster than
industry standard tools wow that's
impressive so let me close with just a
final question of well this is all
sounds very like great science but what
are the applications that you imagine
our being able to actually build or do
with DNA circuits yeah so more recently
now that a lot of the technologies have
been developed people obviously started
looking applications and one of the some
of the cool things recently is actually
using molecular programs as biosensors
so for example you can design a DNA or
an RNA sequence that will bind to its
complementary sequence so that might be
used to for example detect a particular
RNA in a Cell so you could use up for
scientific research you know you have
your favorite RNA or maybe even protein
in a Cell you can use these bio sensors
to detect
it similarly groups have developed by
sensors that can detect even single
nucleotide mutations in in gene
sequences so that gives you a diagnostic
test for a mutation that might lead to a
cancer so what I think though is the is
the next possible application is to
combine detection with treatment if you
can have these detectives working in a
live cell then and then trigger off the
delivery of a treatment in a Cell then
you kind of can start to imagine these
smart drugs that could be used to treat
a whole range of different problems that
we face in the world today cancers viral
infections you name it so it's really
exciting times that's that's really
great a very inspirational I think so
thank you thank you very much for
joining us thank you everyone I hope
that gives you a taste of the the
breadth of research and the interest
that we have at Microsoft Research we
are going to close he took the clicker
but pretend i clicked it okay let me be
let me close by Ashley pausing to thank
everyone behind the scenes who have come
together to make this event possible so
that is of course the MSR outreach team
but us also the IT support team the
administrative assistants who are all
working behind the scenes to make this
event they have been working for months
planning for this event and weeks and
days and nights actually setting things
up I also want to thank Victor ball and
Harold Javed for organizing this event
and the agenda so thank you everyone</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>