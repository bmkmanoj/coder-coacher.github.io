<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Predictable and Dependable Low-power Wireless Networks | Coder Coacher - Coaching Coders</title><meta content="Predictable and Dependable Low-power Wireless Networks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Predictable and Dependable Low-power Wireless Networks</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_6zi5PVsApY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay I guess we can start good morning
everybody it's a great pleasure to have
marcotte Simon link with us today
Marco's time from ETH Zurich and he
started doing his PhD there he's going
to be graduating this summer june july
and he's going to talk to us about
predictability in low-power wireless
networks so markov sorry so as many of
you may know there are a number of
researchers working very hard to make
data center networks predictable and
dependable for various very good reasons
we would like to give guaranteed network
resources to tenants and in general
ensure that user facing services and
applications exhibited predictable
performance for very similar reasons we
would also like to make low-power
wireless networks predictable and
dependable because these networks form
the basis of a number of important
applications we would like to for
example retrofit old buildings with
wireless sensing an actor and technology
to reduce the energy footprint of on
these buildings I would like to network
drones to increase the yield and reduce
the waste of water red lines and
pesticides by putting these resources
only where and when they are most needed
and also we would like to extend
existing wireless infrastructures with
wireless devices or completely get rid
of wires to reduce costs and potentially
optimize the production processes
dependability did predictability in
these applications is extremely
important because they use feedback
loops to control physical processes and
these processes are governed by the laws
of nature which means that they evolve
over time and this is also inherent to
control theory this means that sensing
has to happen at specific moments in
time the sensor readings have to be
communicated to a controller that
Ulysses these sensor readings and the
model of the physical process
to compute control signals that have to
be transferred into a physical
activation at a specific moment in time
because the controller makes a singe
essentially a prediction of the state of
the physical process at some future
moment in time and if messages are not
meeting their deadlines it may be
impossible to guarantee guarantee the
stability of these control loops and
therefore message latency is not a
performance metric but it's really an
issue of performance in some of these
cyber physical applications
unfortunately existing multi of wireless
protocols cannot provide end-to-end
real-time guarantees so here in this
example the green node wants to send
messages to the retinoid subject to an
endo and deadlines and there are
approaches that adopt a fully localized
operation which means that nodes gather
information about their direct neighbors
within communication range such as link
qualities and fill level of packet
queues and using this this local
knowledge they also compute local
transmission schedules which each node
follows locally to exchange message with
their neighbors and since these nodes
are limited to only a log of view they
have no means to affect the global
system behavior such as the entrant
latency between the green and the red
node alternatively there are approaches
such as wireless heart that have a
centralized solution so there's a
network manager that has a global view
of the connectivity graph where the
vertices are the devices and the edges
are annotated with packet receptor age
rates link qualities and based on this
global view the network manager computes
schedules that are tailored for each
node in the network and communicated
distributed to orleans once these
schedules are in place we essentially
have a routing tree where packets are
routed along end-to-end pass however
since we are in a wireless environment
nodes may be mobile therefore links may
break completely because a node has
moved also it is very common that links
become really unreliable you do fading
interference and other environmental
effects and therefore
the schedules may quickly become
obsolete and messages are going to miss
their deadlines to repair this the
situation the change in the topology
first has to be detected it has to be
communicated to the central network
manager which has to update its
connectivity graph compute new schedules
and distribute new schedules to the
nodes and all of this takes time and
during this process measures messages
are going to miss their deadlines and
even or at the time the new schedules
are in place there could have been
further changes in the topology in the
meantime so it's extremely complex or
actually impossible to guarantee enter
in deadlines in the mighty upsetting
based on centralized routing in addition
to printed ability in terms of timing we
should also tolerate falls in
safety-critical cyber physical systems
so you should should be able to tolerate
fault of the controller for example a
common approach is to replicate the
controller across several physical
machines and then we are able to detect
a faulty controller and once the primary
controller fails a backup controller can
smoothly take over to do this for
example using this state machine
replication approach it has to be
ensured that all controllers the primary
one and the backup controllers receive
the same messages in the exact same
order only if this can be guaranteed we
can adopt the state machine approach for
fault tolerance however this is not
possible with existing multi wireless
protocols and it boils down to
complexity so here we again have our
three controllers in grey the primary
one and the two backup controllers and
to let them all receive the same
messages we have to construct routing
trees routed edge each of each of these
controllers so it is already extremely
complex to maintain one stable running
tree now we have to maintain three
running trees so there's a lot of
network stay to handle at each node in
addition there must be some point to
point coordination among the controllers
to agree on the set of messages
the order which they're going to process
and this is extremely complex if not
impossible when adopting a routing based
approach due to the changing topologies
unreliable wireless communication also
the bandwidth is limited using the
radios with the come usually with a data
rate of 250 kilo bits per second but due
to contention in collisions the
achievable rate is actually much lower
also these devices feature my
controllers that run only at a few
megahertz and have a limited amount of
memory and in some applications it is
important that these devices are going
to survive for several months or years
to be economically viable and useful so
given all these problems we have been
asking ourselves is it actually possible
to narrow this predictability and
dependability gap in low-power wireless
networks so is it possible to provide
predictable guarantees that are useful
for cyber physical applications on top
of resource constrained and unreliable
my job low-power wireless networks sure
for very critical again do you need to
be you know at what time scales do you
need to make sure that the system is
stable I think this depends very much on
the control application so in the
supervisory control we have updated
rates in the order of tens of seconds to
minutes so if there's a failure you
should should be able to do a failover
within these timescales for more
critical control with update rates on
below one second it becomes much much
more difficult therefore and therefore
researchers are mostly focusing on not
so critical control where I mean update
rates of in the order of several seconds
that means that basically the Lord get
hundreds of innocent ones if they've
kind of work at the levels remote
hundreds of lead and we may look at
classical embedded systems where that
we're also we have a lot of
safety-critical concerns and the system
should be dependable and predictable for
example in cars this bus us called
flexray and in the latest ml bus a380
there's a bus and it's called time
triggered protocol and so these are
wired buses we're all nodes are
synchronized they have become a notion
of time and they communicate according
to a global communication scale so
taking inspiration from these classical
embedded systems we built a wireless bus
we're also all nodes are synchronized
they share a common notion of time in
the exchange messages as if they were
connected to a shared bus to realize the
wireless bus we had to build a
completely new communication
architecture from the ground up first
one is the communication sorry
Communications substrate it's called a
protocol called glossy that provides one
to all communication and global time
synchronization the actual bus is
realized by a protocol called low-power
wireless bus that achieves this global
globally time seeing a time triggered
communication that is inherent to a bus
and on top of this bus abstraction we
build two prototype systems one of them
called blink that provides end-to-end
real-time guarantees and virtus that
provides virtual synchronous executions
and therefore enables designing
dependable cyber physical applications
glossy really provides the foundation of
this whole bus idea by providing two key
services in an integrated manner in the
first key service is one to our
communication also known as network
flooding or broadcasting so there's one
node that would like to send a message
to all other nodes in the network a
glossy does this by letting the
initiator transmit the message so all
nodes with
communication range will receive the
message at nearly the same time and
glossy now ensures that all nodes all
receivers also relay the message at the
same time so it forces packet collisions
on purpose and by by aligning these
concurrent transmissions such that they
really overlap notes further downstream
are also able to receive the message due
to a certain physical layer phenomena
such as capture effect and constructive
basement interference so notes other
nodes in the network are going to relay
the message in a blindly manner so what
do I mean with blindly there's no
explicit routing here nodes do not keep
any information about link qualities or
locations of nodes they essentially
oblivious of what is going on around
them and therefore glossy can tolerate
all kinds of changes in the network when
if few node links break or nodes are
moving glossy is unaffected by this
we've shown in many experiments on large
test beds with 300 nodes that typically
all nodes receive the message within a
few milliseconds so this is extremely
close to the theoretical lower latency
bound using the radios we have available
today and also all nodes receive the
message with a very high reliability
very close to one hundred percent so why
is it so reliable because there's
essentially a lot of diverse regions
easy during a glossy flood first one
that's what we call center diversity
because the same message is send over
different channels to the same node and
therefore it is rather unlikely that all
of these channels are suffering from
fading and other adverse effects at the
same time so essentially the importance
of individual links is diminished and it
becomes much more it becomes much more
likely that one of these channels is
going to lead to a successful reception
also during a glossy flood and now it
has several chances to receive the
packet so for example here the red node
has the first chance to receive the
packet directly from the initiator of
the flood in SD flood progresses it has
a second chance to receive the packet
now from a different set of
nodes that are also taking advantage of
sinner diversity and therefore glossy is
so robust and reliable in addition to
this one to our communication one can
also request glossy to time synchronize
the entire network s the flooding packet
propagates through the network at no
additional cost so how is this done a
message contains a certain fields called
the real accountancy that is initialized
to zero before the flood starts and
before reeling the message the nodes
increment this real account this means
by the end of the flood and looking at
there it is really count to see nodes
can infer how many times the message has
been relayed since the start of the
flood and also notes can locally
estimate how long it takes to relay a
message and by combining combining
knowledge of the relay counter and the
time it takes to relay they can all
nodes can compute a common reference
time which is the time when this flood
has started therefore synchronize to
each other we've shown that in networks
with more than eight hops the
synchronization error is typically below
one microsecond which is sufficient for
most applications sure deterministic can
there not be convention at a given node
on a given node we mask all interrupts
all other interrupts so we are only
going to accept sft so the this start of
frame delimiter interrupt when a packet
arrives so we ensure very deterministic
timing on each note that this was one of
the challenges we had to solve finglas
multiple s 15 drops at the same time no
can only be one so how can glossy help
us to build or to realize this idea of a
wireless bus well the answer is actually
provides simple we use glossy for
everything every message that has to be
communicated in the network is flooded
to every other node using glossy so
there's a it's really a broadcast on
communication and therefore we
essentially turn the mighty have
wireless network into this shared bus
infrastructure and it creates the
illusion of a virtual singlehop network
because glossy abstracts away from links
and route it doesn't keep any network
state and we get this singlehop
abstraction sure is this a low bandwidth
environment because in the graph above
there are lots of noise they can
communicate with their neighbors whereas
this is a very nice abstraction the
single bus but the effective bandwidth
that you'd be offering would be
significantly lower it could be
significantly lower but keep in mind it
to to really take advantage of diversity
like path diversity in the upper figure
you have to you have to ensure that
there's no contention and collisions and
due to this all this contention is
especially if we have a routing tree
there's a lot of contention towards the
root of the tree and this also limits a
lot your bandwidth so but you're right
for very specialized application that
really require very high bandwidth this
pass idea may not be the best approach
strength sure it in your scenarios or
not if we can tolerate mobility yes I
mean like in a typical usage we have
mobility of nodes all you have pretty
much a static network that depends on
your applications will on the
application we can tolerate mobile nodes
here we see no performance impact when
nodes are moving compared to a static
environment as long as the network stays
connected so when you're it's pretty
much static this seems to be a bit over
killing but I'm them just building up
like you know I prefer our routing
structure on top of that but still as I
will show later and in the torque once
we have this pass abstraction we're
actually able to reason about entering
timing properties which is in extremely
difficult if you have a routing based
approach because they are you depend on
the reliability and state of every
individual link along your path and here
we are abstracting all this complexity
away
extremely simple we are losing something
but we are gaining a lot unless i will
show also there is much more efficient
than most of the state-of-the-art
protocols in this space so to allow
multiple nodes to actually access this
Wireless pass we need some form of
scheduling this is done by a central
host known that uses information about
the current traffic demands in the
network to compute the global
communication schedule that is followed
by all nodes in the network and nodes
announced their traffic requirements in
the form of packet streams these are
characterized by an absolute start time
this is the release time of the first
packet and given period the nodes can
add new streams at runtime update
periods and also remove streams as they
wish and this leads to a globally time
triggered communication because all
nodes follow the same schedule so if you
look at the network from the outside
over time we can identify certain rounds
communication rounds where communication
is happening and between these rounds
nodes can go to a low-power mode and
save energy if we zoom into one of these
rounds we observe a sequence of
communication slots and the very first
slot is assigned assigned to this host
node to distribute the schedule and also
keep the nodes in sync and this schedule
specifies which node is going is allowed
to transmit its message in the following
data slots so there are a number of data
slots in a round and there's a dedicated
requests lot that is not allocated to
every node to any node and this is used
by the nodes to submit the very first
stream request to join the bus operation
afterwards the host computes the
schedule for the new round and also
sends the schedule at the very end of
the round and this is beneficial because
by the end of the round all nodes know
when the next round is going to start so
they can turn off the radios go to a
low-power mode and save energy and of
course each of these slots is mapped
onto a 12 all glossy flat
we as I've already said we evaluated the
bus across several test beds and in
mobile scenarios with interference Wi-Fi
interference and people are carrying the
nodes and moving around and we compared
it to several of the best protocols that
are have been designed for very specific
scenarios for low rate traffic for
mobile networks with mobile things and
so on and we found that in almost all of
these scenarios the bus outperformed the
state-of-the-art protocols and here i
would like to present one comparison
against the the state of the art for
many too many communication because this
is a traffic pattern that we need in
cyber physical systems when multiple
sensors are sending their readings to
multiple controllers so we conducted
this experiment on the testbed in Berlin
we have 90 notes spread across three
floors in the large office building and
we use eight nodes as receivers so there
are eight sinks in this test bed and we
are varying the number of senders from
18 up to 72 of senders and each of the
senders sends one message per minute and
we use two metrics one is data yield
this is the fraction of successfully
received packets at these things so it's
an indication of reliability and radio
duty cycles this is the fraction of time
nodes have the radio on and this is
using our field as a proxy for energy
efficiency to be able to compare
protocols that are running are installed
and running across different hardware
platforms so looking at the low-power
wireless bus we see that across all
numbers of senders it delivers a very
higher data yield very close to one
hundred percent and of course as we
increase the number of senders also the
traffic load increases the host has to
allocate more slots and we consuming our
consuming slightly more energy as we
increase the number of centers looking
at the results of moisture which is the
state of the art for many too many
communication we see that it delivers
consistently fewer packets and has a
much higher energy costs we
it creates a lot of overhead for
maintaining all these different trees
and it has it really suffers from
collisions and so on the other question
that he'll means just you don't lose the
package but you can be sending more
frequently right in in the other one you
don't see that here right the other
protocol does pair up retransmissions I
don't quite remember the setting but i
think it was ten retransmissions per
packet ten retrans protect you normalize
them in terms of duty and you don't I am
I right to say that we don't see a
throughput here it just impacted low
don't see see this also do normalize
them to throughput or have you compared
the tribute of the two like the big
train how many watts per second you can
transmit from essentially it's okay and
maybe I answered from so the when you
look at the data yet you actually have
an indication of the throughput so yeah
once you know the rate with which nodes
are sending packets and you have the
data you'd you can calculate what was
what book right right right the rates
are the same in both networks that in
your with your sister must increase the
size of the network the performance
should drop right because you need to
operate and last number of men so that
is not really captured in the graph haha
how come begin it is not a shit because
we are we are using the same network
that extends across four or five hops
and on this test bed but you're right as
we increase the diameter of the network
in terms of physical hops slots must be
longer because the flat needs longer to
reach or notes and we are losing
something that in those scenarios at
some point master for example we
eventually get better or well what do
you see market I realize that's hard to
predict but i would say that also
becomes much more difficult to maintain
all these routes in monster because it
also so it creates a very deep tree and
maintaining all these paths is not so
not so easy
there are also certain optimizations one
can do when coming into sort of pipeline
flooding so you don't have to wait until
a packet has reached all nodes in the
network you can already sent the next
packet when the first one is
sufficiently far away so it doesn't
interfere may be broadcast in the other
direction this one must be resolved by
it by the schedule of this is true yes
yes you occupying the open why this is
difficult to Monday know this old can't
you just create like a static like a
spanning tree and then they just use it
for all your entire lifetime because you
have like your night the point that you
have failure so you have mobility so
what does the cost of maintaining these
woods come from it comes from from the
fact that nodes have to send a lot of
beacons they have to you have to have to
have a way to estimate the quality of
links and therefore you have to observe
what is the reception probably from a
certain note if you can see over time it
changes the changes very often so we
have empirical studies in our field that
show that there can be several topology
changes permanent the coherence time of
these links this is on the order of a
few milliseconds so you have a lot of
changes here in these networks not in
not in all scenarios if you think about
deployment in the Swiss Alps which we
are also running there are links are
much more stable but if you are in an
office environment with microwaves and
elevators and interference from Wi-Fi
and so on you have a lot of changes in
the network and you too this overhead
which we don't have we are much more
efficient so this is one of the reasons
why we are more efficient and we can we
can globally schedule all the floods so
radios the nodes only have the radio on
when it's but when it is really needed
to actually communicate useful
application data
besides performance one may ask why is
this wireless bus idea a good foundation
to build into an guarantees on top and
there are four aspects to this first the
host makes global decisions based on a
global network view and the only time
varying Network state it has to keep is
the knowledge whether a node is part of
the network or not and by making global
decision that has the ability to affect
the global system behavior and provide
end-to-end guarantees also glossary
abstracts away or the complexity and
source of unpredictability that comes
from links and routes and by scheduling
non-overlapping slots we remove
unpredictability due to collisions
interference when multiple nodes would
like to send something so by removing
all these sources of unpredictability we
can provide robust guarantees or
predictable guarantees all nodes share a
common notion of time which is very
important to reason about entering
timing properties and the protocol is
also efficient and versatile so with the
same protocol logic we are able to
support many too many one too many all
kinds of traffic patterns in a very
efficient manner by building blink we
exploited this pass abstraction to
provide end-to-end real-time guarantees
which means that one can prove that any
message released by a by an admitted
stream is allocated a slot before its
deadline and also it minimizes the total
energy costs in the network if that is
required by the application and the
wireless bus helps us in solving this
real-time scheduling problem because
glossy abstracts away our links and
routes and provides us this singlehop
virtual singlehop abstraction and all
nodes follow the same schedule we can
abstract the entire network as a single
device that runs on a single clock so we
can map the real-time scheduling problem
to scheduling task on a beginner
processor even
though the underlying topology and
effects are much more complicated so we
can leverage 30 years of research on you
new processor task scheduling and this
problem is also much simpler than the
corresponding problem in tree based
systems where the real-time scheduling
problem has been shown to that can be
mapped to my processor task scheduling
and this is np-hard nevertheless we have
to tackle the three subproblems to
perform real-time scheduling on on the
bus first we have to decide when
communication rounds should start first
we would like to save energy so we would
like to defer the start time of the next
round as far as possible into the future
but also we should not miss any
deadlines and we have shown in the
corresponding paper that this is
possible to decide in an optimal way
once we have decided when around starts
we have to allocate the pending messages
to the available slots in a round and
here we use earliest deadline first so
messages with an earlier deadlines are
given higher priority and allocated
first and also shown in the paper we
should allocate as many packets as
possible to the available slots to be
energy optimum all of this only works if
we have a proper admission control so
whenever we want to accept or when
whenever a new extreme is requested we
have to check that the new set of
streams doesn't make the problem
infeasible this boils down to checking
that over any interval the requested
bandwidth does not exceed the available
bandwidth it can be shown that all of
these subproblems have a kind of closed
form analytical solution and this takes
form like here copied from from the
paper and I want to only illustrate that
this requires you to sum over all
streams from 1 to N and do a lot of
divisions and divisions are extremely
costly in resource-constrained on recess
contained devices that don't have a
hardware / hard
multiplier and even if you have this
hardware support it doesn't scale very
well so and this really prevented us
from from just taking this analytical
solution and implementing it on the
nodes that we had so this will take my
tea / seconds to actually compute the
schedule and this would blow up
completely the timing on the wireless
bus because the new schedule has to be
computed at the end of the round and it
should not take longer than a few tens
of milliseconds we exploit that one can
simulate the computations on a priority
queue so instead of doing all these
divisions we simulate the execution on
top of the priority queue of streams you
don't have to understand the whole
algorithm just to look at the redbox
there are certain operations carried out
on the priority queue so we are in this
loop iteratively we are visiting the
stream of the highest player with the
highest priority and doing very simple
arithmetic operations to compute the
starting of the next round TI plus 1 so
the efficiency of these algorithms
depends usually on the efficiency of the
underlying priority queue data structure
then we looked at the problem and found
that it's that we are able to use a very
simple one level bucket queue as the
data structure as the priority queue
data structure so here's an illustration
of a very simple scenario where we have
a bucket queue of 16 buckets in each
packet consists of it of a doubly linked
list and there are already a few streams
in in this queue streams a2g the and the
numbers are the absolute deadlines of
these streams so currently a stream e
has has the highest priority because it
has the earliest the smallest deadline
and now if you want to surf the stream
and it has been allocated a slot for
example we have to update its deadline
so we have to increase its deadline by
its period and this involves adding for
in this in this case for to its deadline
so it will be moved from back at 14 2 pi
to and computing the the target bucket
is a know of one operation because you
simply have to do a modulo operation and
this model o can ought to be efficiently
implemented or it is actually
transformed by the compiler and a very
simple end operation if we have to do
more to lower by a power of two then
again we may have to look for the stream
of the highest priority which means we
have to move this pointer L until we
find sorry until we find the next non
empty bucket in the worst case this may
take over n but as I will show later
this lease costs Emma ties over time
then B is the the next stream that we
found the stream of the highest priority
its deadline is updated by adding seven
to it so it's moved from back a tool to
back at nine and and so on and now if we
are looking for the stream of the
highest priority the find min operation
doesn't have to do anything because the
point are already points to a non empty
bucket there are also four other
operations that are supported by this
priority queue data structure and in
particular two of these operations are
not supported by most of the common
priority data structure such as binary T
binary tree and and so on it so it
really boils down to 20 that we had to
use a binary search tree data structure
such as a red black tree right for the
red black tree to support all these
operations but red black trees although
they are used in general purpose
computing a lot they are extremely
complex and we found that the packet Q
can support all these operations much
more efficiently to evaluate the
efficiency of the data structure we use
the notes that we had sure for a heap
you just didn't rewrite incident for a
heap you just need an array why would
you need the red black tree produces it
again any of you so okay so what we
there I have to explain what kinds of
operations we need you talk about five
min right yes also Fineman and decrease
clear are the typical operations and
they are
very very well well supported this is
true yes you just need an array but you
have to do comparison so you're limited
to this or login complexity whereas with
a bucket q even when especially when
it's rather small you can be much more
efficient because you don't have to do
any comparisons in addition we have we
need to support me visiting streams in a
order of deadline so we essentially need
an iterator that iterates that visits
each stream of increasing deadlines and
whenever we found a stream with a
pending packet we allocate a slot to it
and this so this essentially requires
that we update the priority queue and we
should not invalidate the iterator while
we are updating a stream and this is not
supported by a binary heap you will need
an external stack to stack all the all
the nodes on top of it and so this
becomes extremely complex with a binary
heap even your you're right you can do
it with a villain array and therefore a
binary search tree comparisons with a
heapin you just move elements in the
array or and you're saying you need
extra elements on the side extra memory
you need you need extra you need extra
bookkeeping your you need you need to so
if you are always only visiting the top
element of the binary heap this is
extremely simple decrease key fine
Medusa finding this is too simple but
now we have to traverse the tree and why
we traverse the tree in with decreasing
priorities or increasing deadline we
have to update this heap and we don't
want to start searching again from the
heap from the top of the heap we would
like to be able to smoothly continue
once we've updated a stream in the heap
restructure do that anyway but we can
take this Oakland there we can and we
can take this off my mac nevertheless we
did an experiment to see how how
efficient is data structure is we use
the these notes that we had and they are
featuring a 16-bit my controller and
running at four megahertz and since
these nodes only have 10k of RAM
could fit up to 200 streams in in the
memory of these nodes and then we used
certain optimization problems and solve
these problems to compute the worst-case
combination of periods and deadlines
that would trigger the the largest
execution execution time of our
scheduling algorithms and one important
dependency is the dependency on the
bandwidth demand of this stream set and
as we increase the bandwidth demand from
five to ninety five percent the
execution time increases as well but
it's always below what 80 milliseconds
and this is good news because now we can
we can use these algorithms to transform
the real time theory what what the
theory tells us into a feasible
implementation on only small small
devices and compute the schedule in a
few tens of milliseconds surely the
walls in software yes so this is like
Secord assembly code 0 so these chips
don't have things like priority encoders
because the one level bucket q just
seems to rely on what you should be able
to implement with a priority encoder and
if there is the priority encoder on the
chip itself the 80 milliseconds it seems
pretty high anyway again we can so we
can we'll have to do it on the board of
the clock cycle and yeah yeah but these
these are my controls are extremely
simple only the very recent arm cortex
and three platforms have a hardware
divide and so on so I don't know if they
features this in quarter your image but
i'm sure that ours did not and yeah this
is still the most vital widely used
platform in our field and then we also
did large-scale testbed experiments in
Belgium with almost 100 nodes many
streams over several hours and we found
that link meets ninety-nine point nine
seven percent of the deadlines and the
view the few misses we observe the only
due to packet loss over the wireless
channel and these losses are unavailable
unavoidable because you have a limited
time between the
release of a packet and the deadlines or
you you have only a limited number of
retries and since our channel is lossy
it's impossible to guarantee a hundred
percent delivery so our better finish
all more than 80 milliseconds right
because pratik say to me right so can
you talk a little bit about like the
average of these deadlines are jumping
again seconds how what kind of bad ones
are we talking about my other question
is wouldn't something else also meet
those deadlines like how do you cook
what do you compare this with Randall it
is there something else it could also
meet the deadlines as well is there is
going to be a graph where you compare
this it met the deadlines and then
something else didn't you mean a
comparison protocol kind of here and we
have been struggling a lot with this
problem because there's essentially no
solution out there that provides this
these kinds of guarantees we talked to
our contacts at abb then they have been
using wireless heart it's one of the
solutions for industrial automation and
they struggled a lot to actually get
wireless hard to work and they told us
that it takes minutes up to half an hour
to actually form a stable routing tree
and on top of this we also you also have
to compute the schedule and you have to
implement the scheduler and they did not
succeed after working on this for
several years so I it is it is seconds
the deadlines in periods yes few a few
seconds and a few hundreds of
milliseconds so with the current
solution depending on your on the size
of your network we can support deadlines
in the order of a few hundreds of
milliseconds yes then we also build
another prototype and that exploits this
Wireless pass abstraction to provide
virtual synchrony guarantees this means
that this prototype is called virtus
allows the application to form groups of
notes and notes exchange messages by
addressing them to other groups to the
same group or a different group and
virtus ensures that all nodes in the
group see the same events in the
same order this includes messages that
are delivered and no it's joining and
leaving the group so it really creates
the illusion of a globally synchronous
operation that is fault free so here in
this example the Blue Note addresses a
message to the group down there and it
ensures that either all nodes in the
group receive the message or none of
them which is known as atomic multicast
brothers also provides support for
different message orderings so first one
is total order we just have to ensure
that all receivers down there receive
the same set of messages in the same
order irrespective on off when they were
sent then what we call paranoid 50 so
it's ensured that nodes received the
message with respect to when they were
sent by specific notes or system-wide 54
across all nodes which could also be
useful for building dependable men
mechanisms on top of birders to support
all of this we had to extend the
wireless bus with two additional
distributed interactions first the host
informs all nodes of the current group
membership in this view slot and also
the receivers acknowledge the messages
they have been they have received and
this allows us to provide at atomic
multicast on top of the bus of course
there's a certain costs involved in
doing that in to quantify these costs we
again use this test bit in Berlin with
19 notes and there were two groups of
notes 45 senders and receivers and we
are varied the number of receivers from
25 10 up to 15 and we are again looking
at the ready duty cycle or a proxy for
energy consumption and you see there's a
there's a moderate cost involved in
providing virtual synchrony compared to
the basic low-power wireless bus
operation and you can also see that
there's no noticeable difference between
the different orderings because the
underlying glossy 120 communication is
extremely
reliable we have to return some messages
only rarely and therefore the cost is
limited if we now compare this to the
state-of-the-art many-to-many protocol
muster we see that has a orders of
magnitude higher energy costs and it
does not provide these delivery
guarantees so in summary we look back at
this now it is this communication
architecture that we have built we can
identify the the glossy as a as a data
plane is a very simple dump data plane
that can essentially only send a message
from one or two or others and a
centralized control plane physically
centralized at a host node we also have
have host failover policies to tolerate
failures of the host and this host
orchestrates the entire communication in
the network and therefore provides very
nice abstractions such as virtual single
op network or that we can treat the
entire network as a single device that
runs on a single clock that is useful in
providing sort of very specific
predictability and dependability
features in the form of blink and
burners and this involved extending or
modifying the control plane not the data
plane only in the control plane at a
single place so to achieve this we had
to challenge and I think you are to do
this in your research you have to
challenge the traditional networking
practice and in our field it was
considered yeah that collisions are a
bad thing and instead we are taking
advantage of them we are trying to make
them overlap as much as possible to
benefit from certain physical layer
effects we are also centralizing the
control and synchronizing or the node
which was also considered a bad thing
but by doing everything on a single node
and it is in the synchronized manner we
can be very efficient and achieve
end-to-end guarantees and also we try to
keep the system as simple as possible so
we use broadcast only communication we
try to not add any network state that is
no
needed and use periodic streams which
are the traffic patterns needed in cyber
physical systems and this also allowed
us to model the entire system very
precisely so in another piece of work we
did we could build models that can very
accurately predict the energy cost of a
node in the network and give
probabilistic end-to-end guarantees on
reliability which was not possible
before there are few ideas or many ideas
that are flying around for future work
some are more concerned with the with
the with the wireless and communication
among nodes and some are more global I
would just briefly go through them I
think we can talk afterwards about all
these ideas first of all I think there's
a still a lack of understanding of these
concurrent transmissions why do they
exact your work or what impacts their
performance and I would like to use
models and software-defined radios to
better understand all these mechanisms
and based on this inside come up with
new modulation schemes and physical
layers security mechanisms if possible
to make make them better and more
efficient also exploiting full-duplex
communication that is coming up or
Wireless cut through which means that a
node can send a message while it is
still receiving the message and if this
would be possible yeah we can speed up
the flooding even further also there's
this in triggering idea of flying around
that now we have all nodes synchronized
so we can treat them as a mighty course
in a magical system so is it possible to
build a distributed shared memory
abstraction where nodes do not exchange
messages through message passing but by
writing state to a shared address space
these ideas has also been around for
several years but I think now with the
bus it becomes possible to apply this
all these concepts to low-power wireless
networks which could potentially make it
easier for domain and experts to program
these networks and get their
applications to work
also I think that if we look 20 30 years
ahead and we have smart buildings with
thousands of sensors and actuators in
them we would like to run multiple
applications on this infrastructure so
there is some form of sharing needed
among different applications and this I
think requires thinking about the
network operating system for cyber
physical networks so there's there's
this vision that we some owner of the
house can just download a new app from
an app store to announce this a bit
automate a building automation system
and this of course requires negotiating
if applications are actually allowed to
access this infrastructure when they can
do this and so on so I think that can
one can leverage ideas from from general
purpose operating systems and so on and
also all these low-power wireless
networks are not living in isolation
this may be the case in factories and so
on but if we think about the Internet of
Things vision and smart cities I think
there's a need to integrate all this
knowledge all the sensing and for
example have control as a cloud servers
running in a data center and there I
think our new abstractions needed to
tackle all this complexity is it
possibility to real-time control
involving controllers running in the
cloud and a very interesting application
i think is platooning track platooning
where we want to get rid of all the
drivers and we are forming into the
tunes of tracks to save fuel and how can
we coordinate this how can we coordinate
tracks in a platoon in in a row how can
we coordinate them within the country
across country across countries and I
think there we have to build up a
hierarchy and think about new
abstractions to take this complexity so
with that I would like to conclude and
thank you for your attention
I guess you had a number of questions
during the talk but if there aren't any
more questions it's a quadrature phase
of organic phase a phase shift phase
shift keying it some from the 802 1504
standard frankly 2.4 gigahertz why can
you not build a centralized scheduler on
a PC or something much more powerful
because it's centralized so you can add
one note the network scheduling and be
really why we need to do all this this
is certainly possible in some settings
but if you think about a drone network
for example that is flying around the
country you should have the controller
on one of the drones so it's not
possible to do that I'm thinking about
adding many to one support in your
related plane seems like having 10,000
sensors reporting using broadcast and
work quite as well as having a hundred
sensors reportedly we thought about this
idea is we thought about doing that for
example form a sort of tunnel in the
network so we only are using a few notes
that propagate the flood on some point a
point and route let's say and turn off
all nodes on the outside we we didn't
follow up on these ideas because this
would require notes to maintain
additional network state and by doing
that we would lose this nice property
that we don't care about links and nodes
are moving and the topology changes so
making the data plane support these
scenarios more efficiently which has
been done in the meantime by our others
we lose certain nice benefits
Welding can aggregate messages instead
of just repeating them you mean the way
of doing many to one multiple nodes are
sending different packets at the same
time and then you can a great on the fly
this is very similar to another work
that we did yeah publish it census last
year the where yes all nodes are having
a certain piece of data that they want
to share with all others and then the
sort of OneNote starts this process and
receivers are combining the data they
have received with their own data and
then share it again with others and this
also works even though no no notes are
sending different packets at the same
time still you are going you lyri
sieving one of the packets and then this
chaos or a chaotic dissin this
dissemination can and can keep keep keep
going on so we did with you we did that
for all to all communication yes sure
because if you get the random stuff from
you know multiple directions and you
don't know what he's been combined you
cannot really guarantee correctness
right so much it is resetting that will
be much much you you have to know what
you want to compute exactly so there's
some kind of sort of how do we call it
some kind of aggregator function so how
you combine your own data with the
received data and in order to do that
you have to know what you want to
compute in here if I'm definitely the
factions only a subset of them that
would work well in your setting because
you need to keep track of what he's been
aggregated before you have your stuff
and then you reallocate exactly so we
are there's a sort of their packets have
two portions one is sort of flex
sequence of flags where one bit
indicates whether this node has
contributed to the aggregation or not
and the second portion is the actual
data that you are aggregating so in this
way we can compute
some are very efficiently maximum in the
network or agree on a new radio channel
and this kind of thing seems so this
kind of coordination is incorporated
into the protocol</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>