<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Algorithms Among Us - Nick Bostrom | Coder Coacher - Coaching Coders</title><meta content="Symposium: Algorithms Among Us - Nick Bostrom - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Algorithms Among Us - Nick Bostrom</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hNAJobqGdds" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hello everyone welcome back thanks
thanks for coming back to us after
dinner let me first just say that we'd
love people to provide questions and
also just to sign up for more
information so as a reminder if you have
any questions you can go to this first
website first website in yellow and send
questions which will go to the panel
later on or if you're just interested in
signing up to get more information
please go to the second website there
and put your information there or we
also have pages distributed around the
room and you can just write your email
address on those and we'll collect those
also in case anyone wants to ask
questions and is having difficulty doing
that because of web connections whatever
then it's okay just to write on a piece
of paper and if you bring them over to
the corner here either Victoria or Mike
will be happy to take those questions
will pass them through to the panel so
maybe I'll just give a quick recap of
what we've covered so far where the
start of our third session but just
remind you in our first session we
talked about near term issues have
focused on legal issues economic issues
and matters about data among other
things in the second session we talked
about if how and when we might be able
to achieve human-level artificial
intelligence and in this our third
session where we're going to talk about
the issue of well what if we succeed and
I think perhaps we can interpret that a
bit more broadly to mean what if we
continue to be able to keep improving
dramatically the level of intelligence
that were able to to create inside
machines and we're going to focus on
what research should we focus on today
in order to try to help ensure that we
get a beneficial outcome down the road
and thinking about that I was very
encouraged by a comment that Shane made
in the discussion last panel where he
described this as a good discussion to
have from time to time so this is a good
time for us to have that discussion the
format is going to be we'll have two
presentations and then another panel
discussion so let me just get started
with the next presentation which is
going to be from nick bostrom nick is
probably known to many of you he's a
professor of philosophy and also the
director of the future of humanity
instituted Oxford he's also the author
of the recent best-selling book super
intelligence
and please join me in welcoming him to
our to our group air
the moment of truth and there we are so
yeah thanks for organizing this this
exciting event so the this future of
humanity that we are a multidisciplinary
research institute with that
mathematicians computer scientists
philosophers trying to think carefully
about really big picture questions for
Humanity and one major focus is on the
future of AI which I think has a great
potential to benefit the world in the
short term and an enormous potential to
do so in the longer term and to realize
that potential we will need to confront
a variety of different issues we've
talked about some of them already today
so some of the nearer term issues are
familiar but what I'm really most
interested in is this question that
dimension what happens if we actually
succeed all along since the very
beginning of a I the ambition has not
just been to automate specific tasks but
it has been to produce true intelligence
the same powerful general learning and
reasoning ability that make us humans
smart so this looks to be that it could
have enormous ramifications enormous
consequences for the world there have
been a small number of previous major
transitions in human affairs the
Industrial Revolution springs to mind
where we figured out a way to mechanize
physical labor and that had made your
impacts not just on economy but on
society on culture on the human
condition itself I think that the
transition to the machine intelligence
era when we learn to mechanize also
thinking will be at least as momentous
as the Industrial Revolution and
probably perhaps better analogized to
the very rise of the human species in
the first place given that the potential
impacts are so enormous it seems very
worthwhile to start thinking hard about
this even if we are uncertain as to how
far away we are from this
even if we were not sure that this would
happen at all even if we just designed
some modest probability to this given
the enormous values at stake if there
were even some modest way that one might
contribute to increasing the prospects
of a good outcome by by devoting careful
thinking to this in advance that might
have a very high expected utility so I
don't think it is true that the case for
working on AI safety or for thinking
about impact rests on some assumption
that we have enough evidence to be
confident that this is just around the
corner like that just isn't part of the
reasoning of most people involved in
this that said we did a survey a couple
of years ago where we asked a number of
leading experts various different
questions one of which was by which year
do you think there is a fifty percent
probability that human level machine
intelligence will have been achieved and
for the purposes of this survey we
defined human level machine intelligence
as the ability to perform almost all
jobs at least as well as a typical human
and we also said conditional on there
being no global catastrophe that destroy
civilization and as you can see here the
median answer to the question by which
year do you think there is a fifty
percent probability that this human
level machine intelligence will have
been achieved was 2050 or 2040 depending
on precisely which group of experts we
asked so this is a relatively small
survey and that could be responsible as
I think it's the most scientific survey
that has been done to date in that it
wasn't just asking random people at a
conference who might be self selected
nevertheless not a very good server so
that needs to be more work but I think
the one conclusion one can draw from
this is that it's not a ridiculous
proposition to take seriously the idea
that we might have this kind of
technology within the lifetime of a lot
of people alive today like you might
disagree with that but if you're really
confident that this won't happen you are
actually departing from mainstream
expert opinion
so in order to get to that place we will
have to overcome a variety of different
difficult challenges so you'll be
familiar with some of these improvements
in the way we do transfer learning
concept learning now you might each have
your own slightly different list of sort
of favorite outstanding problems in
machine intelligence in parallel with
these technical problems that we need to
solve in order to make machine smart I
think there is a different set of
problems that we will need to solve in
order to ensure that the impacts of
smart machines will be positive a set of
problems perhaps no easier than the
problems in the left column I think
there is great uncertainty as to how
hard in the left column are we know that
they are not easy or they would already
been solved but whether they will take
20 years to solve or 100 years to solve
is not something we really can be sure
about there's maybe slightly more
uncertainty as to how hard the problems
on the right side are but certainly it
seems consistent with all we know that
some of these problems could turn out to
be really hard in which case the outcome
might depend on us starting to put in
solid research effort early on so that
we have enough time to work on them so
we have a solution in time I'm not going
to be able to go into great detail ID I
did write this book a a year ago which
some of you might have seen through kind
of represented or misrepresented through
kind of media summaries and commentaries
but but a few of the points that I tried
to make is a that AI has this enormous
potential it's not just one more cool
gadget one more cool technology it's
really a fundamental game changer once
once once you have the ability to
automate reasoning and in fact if you
think about it once you have machines
that are smarter than humans that's the
last invention we will ever need to make
it's not just progress in AI that then
translates into progress in all other
fields where human
calvin's currently is the bottleneck the
limiting factor all of that father
invention can then be done by these
smarter than human machines I argue that
super intelligence races unique
challenges we need to think about this
in its own right not just kind of copy
and paste some template that we have for
dealing with various other challenges
this raises some unique issues I argue
that their possible scenarios in which
super intelligent systems eventually
become very powerful not that we know
that this will happen but in some saurus
the super intelligent systems themselves
not just the humans operate them might
become very influential in shaping the
world and that there are sort of
superficially plausible ideas for how to
try to engineer such super intelligent
systems so that they would be safe and
friendly to humans superficially
plausible solutions to this control
problem that nevertheless turn out to
fail and in fact one type of progress
that has occurred in this field is
slightly the development of it slightly
better understanding of what the problem
is and how southern superficially
possible solutions actually don't work
so I also argue that by way of
recommendations that we need to
establish a field of inquiry to work on
foundational and technical issues
related to this control problem that
this is a suitable calling for some
small fraction of the world's most
mathematically talented people to go
into not all not most not even ten
percent but if say a few percent of the
resources that went into making machine
smarter also went into work with this
problem I think that would be good that
the people interested in these kinds of
issues want to make sure to build strong
research collaboration with the people
who are developing machine intelligence
and for many different reasons one
obviously is that ultimately whatever
ideas and solutions are produced will be
need to be implemented by the people
actually building systems but also
because I think there's just a huge
amount to be learned in both directions
that insofar as one is concerned with
long-term
outcomes for Humanity one should factor
in the possibility that we might have
machine super intelligence if you are if
you are concerned about global warming
let us say and the reason for being
concerned about that is that you think a
hundred years from now there might be a
certain effect of that then you should
also be thinking about all the other
things that might happen in this hundred
year window and AI might be one of those
and I make a lot of other points but
also that we it might be a good idea to
try to embed from an early point in time
like the present time the notion that if
we ever do develop this genuine form of
machine and tell us that it should be
done and not just for narrow
nationalistic or corporate purposes but
good for for a higher end that super
intelligence should be developed for the
benefit of all of humanity and in the
service of widely shared ethical ideals
and kind of embed this idealistic
motivation in in the discipline in the
community and I know that many of you
already believe in this and I think it
might be worth trying to starting to
express that and kind of form a
consensus around this is it's too big a
deal for any small group kind of
monopolize all the benefits so one of
the things that have happened recently
as in the last few years is that what
was initially a fairly diffuse and vague
sense that it could be important to work
on something here you know maybe there
are both upsides and downsides ways in
which things could go wrong but the few
cents has now also started to
crystallize out some more concrete
research agendas including a set of
technical research challenges that have
kind of been articulated to the point
now where you could imagine for some of
these assigning a PhD student to try to
begin to make progress I list just a few
of them here in verse reinforcement
learning this is the idea of applying
the intelligence of machines to try to
learn what some human actually
values are prefers from studying the
behavior of that human and this is of
course an active area of research but
there are some specific twists in how
you might want to pursue this question
if what you're interested in is not
producing better book recommendations
next year but support you're interested
in is ultimately having some technology
available that we could use to solve the
control problem for super intelligence
you might for example then want to have
a very sophisticated model that allows
for the fact that humans don't always
act in a rationally optimal way we don't
always act in our own self-interest we
don't always act in accordance with our
values so you might want to allow for
four humans that are impatient over time
that have various cognitive bias is more
sophisticated error model in other words
than just sort of random noise or or
maybe picking randomly from the set of
rank actions below the top you need
maybe more sophisticated model of the
ways that that human behavior sometimes
diverges from from what would be
instrumentally optimal some others I'm
going to have time to explain all of
these a college ability refers to the
idea of how can you design an age and
such that it will not learn to resist
attempts than to go in and modify its
values how how you can design it such
that it will not have any instrumental
reasons to try to avoid being shut down
such that if you're working with some
advanced AI and you're still trying to
figure out how to fine-tune its goal
system that it will ideally collaborate
with you in that enterprise kind of
point out flaws by your light to how it
is constructed rather than create this
kind of adversarial situation there is
theoretical work to be done on the
mathematical foundations of inductive
reasoning logical uncertainty and so on
subtle differences in your theoretical
approach to these issues which might not
manifest might not matter when you're
dealing with some human agents that work
in a limited domain but once you have an
agent that is smart enough to engage in
philosophical reasoning and very long
range planning and to take into account
the wider set of factors some of the
assumptions embedded
on these parameters might turn out to
make a big difference transparency tools
like better ways to understand what is
going on in a system to understand to
read out or what the neural network is
thinking so that we can have a better
understanding of what systems who build
would seem to be broadly useful and a
bunch of other things as well and so to
work on this control problem including
technical work seems seems to be
valuable and and it's the time is right
for some people to start working on that
assuming we solve that technical control
problems that we can actually get the
machines to do what we decide we want
them to do then there is another set of
questions that we then get the
opportunity to confront which is what
you actually want machines to do and how
do we coordinate globally to ensure that
these technologies used for benefiting
humanity rather than say to wage more
effective war against one another invent
better weapons so here also rises all
these issues relation to impact on human
labour market if you can automate all
human labor what remains for humans to
do etc etc also in a simple model where
you suddenly have a piece of software in
a box that control the human can do the
first thing you would expect to happen
is that a lot of copies of this box to
be produced you know until the until the
wage that the marginal copy can earn
equals the cost of producing another
copy so the electricity bill and
hardware rental for building one more AI
and say Madden perhaps in the simplest
model just a Malthusian condition
quickly setting in where average wages
drop to subsistence level for these
digital minds and there's kind of work
you can do to think through there
another distinctive issue which is also
different from a lot of other
technologies that we might want evaluate
is the fact that when you're building
digital minds your potential building
something that itself has moral status
insofar as these digital minds have
sentence most people would think that
what their experiences are Kari moral
significance just as most of us think
that what happens to two animals is not
a matter
pure indifference like it matters if we
create unnecessary suffering say in
laboratory animals and there is a whole
sleuth of regulations ethics committees
and procedures that the guides the
conduct of experimentation on rats let
us say and one could one could argue
that say if we reach even just you know
far before we get a human level AI if we
get to AI that's roughly as capable as a
mouse they able to navigate cluttered
environments and using reinforcement
learning and have the other capabilities
that would make it roughly comparable to
a mouse then perhaps it wouldn't be
ridiculous to start to think about you
know what exactly are they criteria like
how far can we go along this path before
we need to start to take into account
the possible interest of this digital
intelligence itself and of course that
becomes more and more important than
more capable the system we get so if we
actually got a literal human in a
computer box I would argue that that
digital human probably should have the
same moral status as the biological
humans would have I think there's a lot
work to be down there to try to
understand better what sort of necessary
and sufficient criteria would be like
what class of algorithms can we be
sufficiently confident that here there
is no consciousness here there is
nothing that is your small status that
that we don't need to think about it and
where exactly would the lines fear where
we need to start to think more seriously
about these types of issues there are
further more esoteric issues that I
won't really have time to fully discuss
here but once you start to think about
where this technology might lead in its
limit if you produce super intelligence
that can create very detailed virtual
reality simulations and you start to
think about how that super intelligence
might reason about its place in the
world it might assign a high probability
to simulation hypothesis that is that it
is living in some kind of virtual
environment maybe a lot of a is live in
virtual environments and maybe it would
be a reasonable thing for this powerful
research also assign a fairly high
credence to it living inside the
simulation rather than directly
interacting with physical reality and
maybe that
we'll in certain situations we need to
behave in unexpected ways because it's
actually trying to create plants that
take into account this possibility etc
etc there is no particular reason to
think that we have exhausted even the
basic types of challenge in
consideration that might need to be
solved in order to get a safe transition
to the machine intelligence era and so I
think that there has been a significant
improvement even just over the last year
in terms of awareness of some of these
issues within technical community that's
been some discussion and I think the
next challenge now is to channel this
this general awareness into some
actually constructive research to some
people actually to work on this on a
full-time and begin to take the big
questions apart break them down into
smaller questions and start to make
progress and that's that's one of the
things that we will be trying to go over
the coming years and there's a little
bit more funding streaming into this
area as well so there will be a number
of other groups also springing up the
leave is um center was mentioned earlier
that's one example of that so so broadly
speaking I'm kind of optimistic about
the the current direction in which this
this type of enterprise is moving but I
still think we have a long ways to go
before we are allocating and aware near
the optimum amount of attention and sort
of quality adjusted research effort to
these questions relative to their
importance thank
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>