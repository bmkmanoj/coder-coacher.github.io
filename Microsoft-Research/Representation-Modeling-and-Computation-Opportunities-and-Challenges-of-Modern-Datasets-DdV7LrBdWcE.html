<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Representation, Modeling and Computation: Opportunities and Challenges of Modern Datasets | Coder Coacher - Coaching Coders</title><meta content="Representation, Modeling and Computation: Opportunities and Challenges of Modern Datasets - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Representation, Modeling and Computation: Opportunities and Challenges of Modern Datasets</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DdV7LrBdWcE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
this guy you might know his name is Alec
you might have met him he's been around
the lab for a year and a half or
something like that yeah so he's gonna
tell us about efficiency an automatic
machine learning go ahead so this talks
mostly also designed for sort of oh okay
people who might be having various
varying degrees of familiarity with
machine learning so in because I know
you guys in places where I know you know
already what I'm talking about i might
go a little faster so but i will start
by saying you know pretty cool to be
working in machine learning right now
because users pop up all over the place
so we're all familiar with users in web
search and ranking spam detection design
of large-scale recommender systems one
thing maybe a few of us are familiar
about applications in things like
medical imaging so when kids are put in
MRI machines they tend to fidget a lot
that's problematic so one thing people
have been doing is they they've been
using something called compressed
sensing to to reduce the amount of time
you need to spend in the MRI machine so
the amount of time you need to be still
for and it's it's been a significant
breakthrough this has been this is
actually being used in MRI machines at
this point variety of other uses rise in
computational biology for instance in
large-scale genome wide Association
studies optical character recognition to
scan checks talking to our phones using
automatic speech recognition and often
translation and so on but the thing that
excites me actually the most is that so
all these diverse applications of course
have their own sets of complexities and
challenges but they also share a lot of
common features when you think about
designing a solution for almost any one
of them and people use different names
for these aspects but I think most of us
agree on what these specific elements
are so
the first step almost always is you
start from some fairly raw source of
data and you're trying to convert it
into a form that's intelligible to a
machine learning algorithm so this is
you might start with with with text or
audio video signals or images or
whatever you have and you often hand
code these things called features to in
a process called feature engineering but
lately there's been a lot more emphasis
on trying to learn this part of the
pipeline once you have representation
the second step is what i would call
modeling which is essentially a lot of
our statistical reasoning about the
problem so what kind of input-output
mapping do we want to learn what is the
goodness of fit measure that we are
going to use this is a classification
problem regression problem clustering
problem so on maybe we want to enforce
some structure on the parameters we are
trying to learn through some
regularization techniques and so on and
even after we have done the
representation and modeling of course
have to go ahead and compute the final
solution which requires computation and
in my talk most of my and most of my
work this competition involves swings
solving some kind of optimization
problem and often the scale of the
problem will necessitate the use of
distributed algorithms in fact so my
research touches on all these different
aspects of designing solutions to
machine learning problems not just in
isolation but often also reasoning about
their interactions and various
trade-offs amongst the quality of these
aspects of course I cannot really talk
about all of them in one talk so i'll
pick a couple of favorites today and the
first part actually some of you might be
familiar with this is stuff I did when I
was interning at Yahoo research on
disputed machine learning and the second
part will be more recent work that I did
with some summer interns in a New
England lab and visitors last last
summer on on this question of learning
good feature representations using a
particular technique that I will talk
about now so let's
start with the first question of
distributed machine learning so so this
is work I did when I was visiting most
of you guys at Yahoo and the one sort of
for for me the motivation was I had
already been looking at disputed theory
of distributed machine learning doing my
PhD and then add the chance to actually
develop some of these systems at large
scale when I visited John and there were
some interesting problems and data sets
that we could apply the techniques to
like the computational advertising task
where we were trying to predict click or
no click we have given a user add web
page example and this was a pretty
sizable data set we had about 17 billion
such collection of web page ad players
and we were trying to solve this using a
logistic regression problem where there
were a lot of parameters that we needed
to fit in order to get good predictions
we had about 16 million parameters and
and so at this scale if we just could
not consider solving this problem all on
one machine disputed algorithms were
necessary right so the set up here and
in fact in a large variety of disputed
machine learning is that you have access
to some kind of a computational plaster
you can think of it as a distributed
network of communicating nodes where
each node is a computer in the cluster
and each link represents a network
connection in your data stored in some
kind of a distributed file system so so
the individual nodes might own the
subsets of your data like subsets of the
cliq logs in the previous example but
what you're interested in is fitting
some kind of a function over this entire
distributed data set so again in the
previous example the examples consisted
of some representation of user at web
page as a feature vector we are trying
to predict click or no click using some
vector of logistic regression parameters
and crucially this this fitting needed
to be done over the data summed over all
the examples so no one node can solve
this problem isolation because it does
not have the entire data
right now this is not a new problem
there are many people who have looked at
respective machine learning and when you
try to approach the problem there are
many things that often go wrong and have
gone wrong so it's very easy to design
an approach by exclusively focusing on
its communication or computational
complexity when you do that and try to
use it then you choke on the aspect you
did not care about and it does not work
it's pretty tempting often to take a
particular machine learning algorithm
and try to paralyze it machine learning
of course is a moving field so the
algorithm would often become obsolete
and your effort goes to waste so we want
to in fact do something that can take
large classes of algorithms and paralyze
them so that this can be valid at least
for some reasonable amount of time and
even when you get these things right
what can happen is that you you have an
algorithm it works within a particular
infrastructure you have a large data set
that's stored in some other
infrastructure like a MapReduce cluster
for instance these do not play well you
cannot run on the large data set so she
need to have a match between the machine
learning system and the system invested
it as being stored and finally you don't
want to end up in a situation where
you're distributed machine learning
algorithm looks completely different
from any single machine algorithm you've
ever written because that would mean
that you have to reimplement everything
from scratch and that's just a pain if
you're trying to do it yourself right so
what I will describe to you now is one
way we found to circa men these
challenges of course there might be as
possible so the core problem that we
wanted to solve was to fit a parameter
over large data set by minimizing some
kind of a loss function and there are
two main classes of solutions exist to
solve this type of problems they are so
called stochastic optimization methods
an example is stochastic gradient
descent we do not need to know what that
exactly that is for this talk I'll tell
you all we need to know and another
class is batch optimization in example
of this is just creating descent or it's
more advanced variants
so let us start by looking at what a
distributed stochastic gradient
algorithm looks like roughly so the idea
here is that you have bunch of nodes
each with its local data set each node
starts going over the local data set
running the stochastic gradient descent
algorithm whatever it is and comes up
with a local solution like w1 on node 1
which is a good solution for this guy's
local data set similarly note 2 comes up
with W to which is a good solution for
its data set and so on so you take these
local solutions you just average them
now sometimes what happens is that this
average is already a good enough
solution for this entire distributed
data set because it has a force some
elements from part of each local data
set sometimes it's not if if it's not
then you take this you feed it back up
and start another round of stochastic
gradient descent on each machine from
this initial point and you repeat this
process of U times so that is one
approach people have looked at
extensively the second approach is what
i call the distributed batch
optimization approach and the intuition
there is that so we are trying to
minimize this function which has which
has the form indicated here and one
approach to minimize any function is
that you start somewhere and do an
iterative algorithm where given your
current solution WT you find the
direction in which the function is
decreasing at that point WT this is
going to be the negative gradient
direction at that point and you take a
step in that direction and if you do
this often enough you will eventually
reach the bottom of the function right
now in particular when f looks like the
sum of losses over data points then the
gradient also looks like the sum of
gradients over data points and when your
data is distributed over a cluster then
this some further wakes up into two
terms there is the inner sum over the
examples on a particular node J so this
is completely local to node J it can
compute it once it knows the current
solution WT know Jake
compute this totally locally and then
you have an inner some across the
different nodes for which you need some
communication you need to accumulate
these local gradients across nodes
somehow in order to get the outer some
the pictorially what it looks like is
each machine now does a local gradient
computation in on its local data set
obtains these local gradient vectors and
then takes a step in the negative
gradient direction where the gradient is
accumulated over everybody finds the new
solution and resumes local gradient
computation iteratively okay these both
stochastic and batch methods whether we
are very well studied in theory and lot
is known about how when you run them how
the optimization are goes down as you go
over the data many many times so in blue
here I have shown stochastic which drops
the error really fast initially the red
one is not even on the chart initially
but after a while once red gate starts
getting to a good point then it's
dropping the error much faster and
eventually overtakes the blue so when I
first saw this picture I felt like there
was opportunity for a beautiful synergy
here by taking sort of the best of both
the world's what we wanted to be on is
on this black line really doing
stochastic initially in batch later on
it that would be the ideal thing to do
and that is roughly what we did so the
idea was we initially start by doing
this distributed stochastic gradient
descent right so we compute stochastic
gradient we we compute these local
solutions on each node we average them
and now we disseminate this average
solution that to each node and now we go
into a batch optimization phase so so
now we start computing local gradient at
each node once we are done doing that we
take a step in the negative great
interaction like before and now we
repeat just the second part of the
pipeline so so we take this update
solution and start doing local gradient
computations from it again right so we
are just repeating the batch phase now
for many iterations after doing the
stochastic ones you can do the
stochastic two times as well if you like
it doesn't sometimes makes a difference
sometimes doesn't but this we definitely
repeat many times now so turns out this
idea can be quite powerful you can show
in theory that the hybrid approach this
switching from stochastic to batch after
a while can reduce the computation by up
to a factor of two right and this factor
of two can matter because this might
often mean running something for an hour
versus running it for 30 minutes it's
not just a figment of theory so you can
even you run these algorithms in
practice what you observe is something
like shown here so the dotted curve is
what you get if you run if you take best
of individual stochastic and batch on
the computational advertising task and
the solid one is what you get with
hybrid so it's consistently better this
is optimization error versus number of
passes over data so think of it as
computation completion structure is
exactly the same except yeah okay now so
far I've told you kind of cartoon
distributed algorithms in the sense you
know I said okay we are going to average
some local waits for stochastic we're
going to add some local gradients in
batch and nobody really called me out by
asking well how do you actually do it
because you have to you know these these
things are spread over a network and you
have to actually add them up so how do
you have to understand how to do this so
so there are some good news here because
there is an abstraction called all
reduced which is extremely old in
parallel computing which has exactly the
right input output characteristics for
us so this abstraction assumes an
initial state where each node has a
local number or a vector of numbers and
produces a final state where each node
has the sum of all the numbers from
all the vectors so if you applied all
reduce to local weights or local
gradients you would be able to compute
the sums you wanted and roughly the same
way of sayin plement you you just impose
a tree structure over your nodes which
hold these numbers and you start summing
numbers of the tree so for instance here
I have you have 5 &amp;amp; 4 which are passed
up the tree a combined with this to to
get 11 on this node similarly here you
end up with 16 you propagate them
further and now root has the sum of
everything once the root has the sum of
everything you can propagate it back
down just broadcast and now everybody
knows the entire sum right so disputed
machine learning with all reduced can
look very simple now we can go into our
hybrid method just put a call to already
use here for weight summation here for
gradient summation and this now is a
legitimately distributed algorithm right
so so just by inserting all reduced
calls into places and all reduce in fact
does exist as a genuine software
implementation it is not just a
theoretical abstraction it is provided
in MPI message passing interface which
is one of the oldest parallel
computational frameworks now this is
where we ran into a bit of a snag
because large data sets are typically
not stored in MPI clusters they were
they are most often stored in MapReduce
clusters and this was definitely the
case at Yahoo where everything was
available in Hadoop clusters right and
there are some good reasons apart from
all the data processing functionalities
who provides it also gives very nice
fault tolerance it has something called
speculative execution to deal with slow
machines it provides data local
computation to minimize communication
and so there are good reasons to be
using MapReduce our solution to try and
get the best of both was to just develop
a Hadoop compatible version of all
reduced right so we we wrote our own all
reduce that works on Hadoop
this requires doing some careful
engineering to make it work right but
once you do you end up with a robust
system robustness coming from Hadoop but
which has very fast communication where
the fast communication comes from all
reduce and it is really fast so here is
an example of what happens when you do
just one iteration of gradient descent
distributed gradient descent on two
different sizes of data using MapReduce
in blue on in red and all reduce in blue
right and this is the difference in
times in one iteration now imagine if
you have to do 10 or 15 iterations which
is not a typical at all then you do not
want to be facing the red and you you
would much rather pay the blue time
overall we can reason about the
characteristics of the resulting system
now and it's pretty easy to make sure
the system has balanced communication
and computational complexity is this can
be done pretty easily just by
controlling sort of the the size of
local data on each node and the number
of nodes the system is naturally
iteration friendly this was the biggest
problem with vanilla MapReduce it's not
iteration friendly whereas with all
reduce you have a persistent
communication in topology on which you
can communicate as many times as you
like by design its Hadoop compatible of
course so we can work with large data
sets stored in the MapReduce clusters
and the thing that's practically very
attractive is that really so when I
showed you my diagram there were two
calls to all reduce but even in the code
often you can just take a serial machine
learning algorithm insert a couple of
calls to all reduce and you end up with
a distributed algorithm which is
extremely powerful want to show you some
experimental evaluation we did of our
system so I already mentioned the
display advertising cast from yahoo that
that we worked on and we also tested on
another open source open data set
available in academia witches comes from
computational biology something called
predicting human acceptor splice sites
reason we picked it it's quite large
about 50 million examples 11 million
dimensions for example
so the first thing you want to check for
any parallel computational system is its
speed up as you add more and more nodes
and here i show the speed up as we go
from 10 200 nodes and the dotted line is
the ideal linear speed-up which is the
best you can hope to get while we are
not quite there we are not too far off
either it's a pretty substantial speed
up going from 10 to 100 and the
important thing is it does not just die
off at 100 in fact we scaled the system
2000 nodes on the yahoo clusters where
it was pretty easily scaling up to that
level we also compared our method with a
couple of other approaches one that was
developed by a different group in yahoo
research itself and one that was
developed at microsoft research here i
am showing the prediction accuracy so
higher is better as we again go make
more and more passes over the data what
we see is our method is definitely
consistently higher and what we do not
show here is that these number of passes
over data can in fact have different
wall clock times for different methods
so some of these are in fact have very
excessive communication complexities so
their wall clock time might be much
higher which we are not penalizing them
for and a lot of other methods that I
have not shown here are not being shown
because they would not follow in this
chart the system is available open
source in bhopal bobot and definitely I
can speak from my experience that it is
being adopted within some team set
Microsoft at this point yahoo of course
filed and filed I guess a patent for it
when we first did it and potentially
being used in some other places as well
where VW is being used so that's sort of
the the first part of the talk where the
the thing that sort of somebody who also
does a lot of theory so the thing that
this that appealed to me most about this
work was we started with some very
concrete theoretical insights into these
optimization algorithms and by combining
them with the right engineering tricks
you are able to obtain an overall system
that is practically quite
effective now sometimes you face the
converse problem you have something that
works very well in practice you are
absolutely no idea why and that is going
to be in fact the problem we face in the
second part of the talk when I talk
about my work on dictionary learning and
like i said this work was came out of
some things i was doing earlier and then
a summer internship last summer in
Microsoft New England let me start by
describing my main motivation for this
problem so the idea is when we do
machine learning in practice data takes
various shapes and sizes sometimes it's
a text document sometimes it's images
sometimes it's audio video signals but
when we write our papers and design our
algorithms it's really tempting to think
of data is organized in this neat matrix
where each row is an example and each
example is encoded as a vector of real
numbers and you see this you got to ask
well what do these numbers mean so
typically these numbers are hand coded
by a process called feature engineering
which can take considerable amount of
time and skill can be quite painful but
it is absolutely essential to good
performance of any machine learning
system in practice and so it's a pretty
reasonable question to ask whether we
can learn these good features from data
directly rather than actually hand
coding them a different motivation for
the same problem comes from the field of
signal processing when we when you think
about signal compression so it's not a
difficult thing to recognize at all that
high resolution images or high
resolution videos can take a lot of
space to store right in general any high
dimensional signal can be expensive to
store of course if a high dimensional
signal is sparse if it has only a few
nonzero entries then you just store the
nonzero values and their locations and
that's pretty cheap but sparsity again
is a question of representation right so
if you take an image it might not look
sparse in its pixel representation but
maybe there is a different
representation where it looks sparse so
you can ask well can we just learned
representation where signals of interest
or sparse so that we can compress them
effectively now in practice the answer
turns out to be yes so here I am showing
an example does not my work somebody
else's work from 2009 so what they did
was they took a database of facial
images and they wanted to compress so
one option would be to use standard
algorithms like JPEG or discrete cosine
transform or something but they said
let's just find a representation where
facial images look sparse and then use
that to compress you do that you obtain
this compression which is definitely the
best of the lot here most accurate of
the original and this this not just a
one-off result similar successes have
been repeated over and over in fact go
that much further in image denoising in
painting super-resolution many other
applications now trouble is that most of
these practically successful methods
rely on some kind of solution of a non
convex optimization problem which is
very problematic in theory because we do
not have good understanding of what's
going on how are we able to solve these
non convex optimization problems and so
there's a there's sort of a substantial
gap between the state of theory and
practice in this area and I'm going to
provide one answer that a times to
bridge this gap so let's let us now try
to set up the problem we are interested
in a bit more formally and the idea is
that we have some example like a facial
image shown here and we want to
decompose this example into a sum of
some basis elements like eyes nose mouth
maybe you want to add a couple of years
here you know you get the basic idea you
might have another face and then you
will have a different pair of eyes nose
and mouth of course and in general you
might have a whole database of facial
images you'll have a collection of these
dictionary elements and now you try to
encode each face using this dictionary
through this coefficient matrix right so
the number of columns in the coefficient
matrix is equal to the number of faces
here for each phase
this black indicates a nonzero entry
saying this this face is going to
contain this this I and this I and this
nose in this mouth right so we are
encoding faces using this dictionary
rather than the raw pixel values now
this is just a car to an example this is
not how you're going to do this if you
wanted to do it in practice you would
probably do this over image patches or
something but this can be quite powerful
because the sparsity of this coefficient
matrix note that suggestively a lot of
zeros in this coefficient matrix and
that is because we want to do effective
compression or signal other signal
processing tasks using this
representation so just a couple of more
observations about this setup so in
general I will think of my examples as
arranged in a matrix where each example
gets a column and a column has DD
entries so think of them as like a
column is a phase which is encoded using
its pixel values we want to decompose it
using a dictionary a star and there are
going to be our dictionary elements
these are the are things we want to find
and we have a coefficient matrix that
that gives us the encoding in terms of
the dictionary and we want the
coefficient matrix to be sparse there
are few other ways you can think about
this so some of us are familiar with
what a topic model is so you can think
of wise as documents a star as topics
like business and news and politics and
whatnot and now the model posits that no
document has too many topics in it
that's why you have sparsity in the
coefficients or you can think of this as
an over overlapping clustering model
where you want no data point should
belong in too many clusters and a star
gives the cluster centers one piece that
I want to point out is that we we work
in what is called the over complete
setting here meaning this dictionary can
be pretty wide right so you want to
actually allow the discovery of
potentially a lot of disk dictionary
elements and that is because this is
often the most relevant sitting in the
in the
applications of this setup yes sir I've
told you what the problem is now let me
start describing what the practically
used solution to this problem looks like
so usually what people do is they start
with of course we want to factor eyes
the data as dictionary times
coefficients where the coefficient
matrix we want it to be sparse and one
way of enforcing sparsity is minimizing
the l1 or the sum of absolute values of
the coefficient matrix don't worry about
if you do not know why this is a good
surrogate for sparsity that is not
really crucial to understanding anything
in the talk right and now they say okay
let's start with some initial guess of
what the dictionary might look like you
might even pick this randomly you might
pick this according to some heuristic
whatever you want we fix that and now we
try to find the best set of coefficients
given the dictionary which which just
turns into what we would call a sparse
regression problem this is a very
standard kind of problem in machine
learning and statistics and there are
many good solvers available for this
once we have fixed the dictionary so now
we obtain a certain set of coefficients
and we fix them and say or what is the
best dictionary for these coefficients
and this is just a system of linear
equations you can solve it using least
squares and now you iterate between
these two steps updating the
coefficients given dictionary and
dictionary given coefficients so this
might look very similar to EML gyum for
this problem or k-means where sparse
regression is like assigning each data
point to its nearest cluster and least
squares is like a setting cluster Center
based on the average of the points just
like EMR k-means this algorithm does not
converge to the global optimum using an
arbitrary utilization a zero so let's
see a little more why that is the case
the key thing to note is that we all
these methods are trying to solve this
optimization problem where they want to
enforce the constraint y equals to ax
with a and X both being optimization
variables now this turns out to be a
non-convex constraint and the easiest
way to see this is that average of
solutions is not a solution so let us
take a factorization a times X for the
matrix Y then of course minus a x minus
X is also a factorization but now let us
take the average of the two right so a
plus minus a over 2 and X plus minus x
over 2 you get zero you do not get why
this does not happen in a convex problem
the average of two feasible solutions is
a feasible solution so this is a non
convex optimization problem these
problems are np-hard in general so if
you want to solve this and we are
solving this in practice then there must
be some some special structure present
in the problem something else going on
that is enabling good solutions so this
non convexity has precluded theory from
existing for this problem by and large
there is only one notable exception work
of Daniel Spielman and Kaufer from Yale
in 2012 who showed that okay if we leave
this alternating minimization business
we can come up with a different linear
programming algorithm to solve the
problem we do not want to use lose the
alternating minimization flavor because
that's what people are using in practice
so so we instead took the took this
method and combined it with a novel
initialization strategy and what happens
now is that you can show under certain
conditions you can get to the global
optimum of this non convex problem by
leveraging this initialization in the
over complete setting of interest so
that is going to be the main result that
I will present to you now so let me give
some intuition about the initialization
procedure the idea is we we take our
example matrix Y and we try to find a
subset of the examples all of which have
a nonzero coefficient on a particular
dictionary element like the red one
shown here so the idea is if you could
find these examples and actually if you
plot them on a graph then they look
something like the plot shown here in
which case
if they have they all have a strong
component in the right direction now if
your data looks like this and if you run
PCA and take the top PC a vector you get
something pretty close to the right
direction so given this green matrix
finding the red vector is easy so then
the job reduces to finding this green
sub matrix from our big matrix of
examples this is where one key piece of
our intuition comes in where we use the
idea of looking at correlations between
our data points so the intuition is that
if two data points have nonzero
coefficient a reasonably large nonzero
coefficient on a common dictionary
element then if you if you take their
correlation that should be relatively
large because they both have a component
in a common direction so we build a
graph where we can put an edge between
where each node is a data point and we
put an edge between two data points if
they have a large magnitude of
correlation between them right so you
you obtain a full graph this way now
what we do is we look for large clicks
or approximate clicks in this graph the
intuition here is that vonage means this
node and this node have a dictionary
element in common but now if you look at
the blue blue click you can further say
that every pair of nodes in this blue
click have a dictionary element in
common and with some work you can in
fact show that with high probability
they all have the same dictionary
element in common so dictionary element
one is going to be contained in each of
these examples similarly if you look at
the red click then they are all going to
contain for instance dictionary element
2 and so on this is not obvious this
takes some work but let us assume that
is true then our work reduces to just
finding these approximate clicks in the
graph so here is a simple way of looking
for these kicks I start from an edge
I find all the common neighbors of both
the endpoints of the edge right that
gives me the blue click I could get
unlucky if I start from the magenta edge
then I don't just find the blue click I
find the union of the blue and red
clicks and this would be problematic
because this is not a click this is a
union of two clicks some of which
contain dictionary element one some of
which contain dictionary element too but
these two neighborhoods look visually
very different right so you can just
there is a simple procedure you can just
take an edge find its common neighbors
of both the endpoints count the number
of edges in that neighborhood and you
can actually distinguish pretty easily
whether you're in the green case of the
magenta case I am NOT going to give you
the exact details of the procedure but
roughly what the initialization
algorithm now ends up looking like is
you construct a correlation graph with a
certain threshold for each of you first
steps whether the air is good if it's
good you find all the common
neighborhoods common neighbors of the
endpoints build their covariance matrix
take the top pc a vector and that is an
estimate of a dictionary element that's
your initialization for one dictionary
element and you repeat this for many
areas and you build in the whole initial
dictionary estimate i mentioned that
similar algorithm was also developed
independently and simultaneously by
Sanjeev Aurora and students at Princeton
okay now I would like to state some
results about the algorithm I just
described and for doing that remember i
said this problem is going to be np-hard
in general so we need some assumptions
and I'm going to make a couple on this
slide so we assume that the dictionary
satisfies what is called incoherence
this is a pretty standard assumption in
the literature and says that if you take
two dictionary elements they should be
roughly or they should be close to
orthogonal they shouldn't have very high
alignment with each other we assume that
the coefficients themselves are sparse
and in fact the sparsity pattern is
random is not pathological in any way so
under these assumptions suppose you've
given order r squared examples we
remember our
the number of dictionary elements we are
trying to discover now we take use the
graph clustering algorithm first and
take its solution use that to initialize
our alternating minimization procedure
then with high probability nice things
happen so if you measure the distance of
the iterates that alternating
minimization is generating to the true
dictionary a star then you have the
error at each step of alternating
minimization so with sufficiently many
steps you can recover the true
dictionary to arbitrarily high precision
meaning you're getting the exact
recovery of this dictionary with order r
squared samples and so we managed to
solve this non convex problem to the
global optimum through through our use
of initialization procedure and the key
intuition again I want to highlight is
that the first initialization step gives
us an approximate recovery of the
dictionary and then we can improve this
approximate estimate through steps of
alternating minimization so I kind of
gave some intuition about the
initialization already I want to just
show you a little more intuition about
how we establish the local linear
convergence of alternating minimization
so the intuition is ideally we want that
we start from some initialization here
is 0 there is some global solution that
we want to converge to and we take our
alternating minimization steps finding
coefficients and finding the next
dictionary and so on and we want each
step taking us closer to the global
optimal solution of course that is a
good case it might happen that one of
these steps remember a one is just an
estimate for a star so maybe when you
estimate the coefficients using a one
you actually get completely bad
coefficients and in fact doing worse
than where you were before you need to
rule out such back steps from happening
and that is kind of the main crux the
main crux of the argument is how to rule
out not making progress in some steps of
alternating minimization so this is
where sort of
one of the key results that we establish
concern which which says suppose you
have a set of coefficients that are not
too far about 1 over s close to the real
real coefficients to the true
coefficients then if you use them to
estimate a dictionary then the error in
the dictionary will be this factor s
squared over square root d times the
error in the coefficients so in
particular if s squared is suitably
small compared to rudy then the error in
dictionary will be smaller than the
error in coefficients in fact you can
further relate dieron coefficients to
the error in previous dictionary and
that kind of gives you a contraction
because it connects the error in
dictionary a time T plus one to the
error in dictionary at time T and one
thing I wanna highlight here is this
supposed condition so this this thing
only kicks in once you are already
sufficiently close to the true solution
and the only way we can do this is by
using our initialization method the
initialization method basically gives us
a dictionary that ensures the
precondition of this lemma and then from
there we can use this argument to
reliably decrease the error okay so I
want to start wrapping up so in the
first part of the talk we saw an
efficient distributed machine learning
system and the second part of the talk
was about trying to make mike Mayock
machine learning more automatic by
learning learning feature
representations that can handle diverse
forms of data and one thing I sort of
liked about both these both these works
is that they both involve sort of some
nice theoretical ideas that result in
practical algorithms and this is
something I sort of like to do more
broadly in my research which leads also
into many other directions just a couple
of which I want to point out so so one
thing I spent a lot of time thing about
and I still think about is often people
think about computational and
statistical aspects of a machine
learning problem in isolation but in
practice there are very nice very
interesting trade-offs between them so
we want to answer questions such as if
you if you want to estimate some
quantity and you have access to only
limited amounts of data and computation
then how well can you solve the problem
or if you want to design a
computationally budgeted statistical
inference procedure how do you go about
doing that right so a particularly nice
example that arises as a as an
instantiation of this general question
is so a lot of us of that that are
working often with high dimensional
objects look for specific structures
like sparsity or low rank and matrices
and so on and there are very nice
statistical procedures known to to
exploit these structural assumptions but
the underlying computation for for doing
that for doing that inference also
suffers from the high dimensionality of
these objects and it's pretty natural to
ask can you also design computational
procedures that leverage the sparsity or
low rank assumptions just like we do in
statistics and so I've worked on
algorithms that can actually do this and
doing so actually involves a combination
of techniques both from statistics and
optimization and results in nice
algorithms so another set of questions
which I have worked on and plan to
continue working on going forward so so
one situation that arises repeatedly and
definitely here at night soft is we have
an exploration versus exploitation type
scenario so so we have some system that
uses machine learning to present present
an outcome such as a set of search
results it receives some feedback from
the user and we want to use this
feedback to further improve the system
in doing so we have we cannot just apply
standard machine learning techniques as
is there are causal feedback loops that
arise that have to be properly dealt
with so this is something I've been
working on we have some nice results
here and but but but there there is sort
of a broadly open field
are both in terms of statistical and
computational questions and the second
part I mean we already saw one example
today of this so there are many of these
non convex optimization problems that
arise in machine learning they are being
solved by people very effectively in
practice but theoretically there is
limited to no understanding of what's
going on and I think the theoretical
understanding is in particular important
because you would like to in many cases
design better algorithms than the ones
that currently exist to solve these
problems faster large-scale data and so
on and so this I think is a very
exciting and sort of newly emerging area
of research in machine learning that I'm
very excited about and definitely
planned to work on in the coming years
so that's all I had to say thanks a lot
for your attention so I think we had a
whole 0 questions because simply
universe already have asked these
questions are there any additional
questions that anybody might have I mean
I feel like the people who are seeing
the stock for the first time I have
questions yeah apart from this view elem
I've seen it is mr.
great all right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>