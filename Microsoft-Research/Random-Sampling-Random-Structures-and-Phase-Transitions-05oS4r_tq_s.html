<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Random Sampling, Random Structures and Phase Transitions | Coder Coacher - Coaching Coders</title><meta content="Random Sampling, Random Structures and Phase Transitions - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Random Sampling, Random Structures and Phase Transitions</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/05oS4r_tq_s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay hi everybody welcome to the MSR
colloquium today we have Dana Randall
speaking to us she's from Georgia Tech
we're very happy to have her visiting
she's actually visiting for the this
entire week so she'll be here tomorrow
and Friday as well if you'd like to talk
further about the topics that she's
going to introduce us to and she tried
to gear this talk especially for the
social media people so Nancy you should
be very very turn it over to Dana Thank
You Nicole well it's a pleasure to be
here it's a great place to visit and
I've had interesting conversations
already with people from all backgrounds
so I can't say that I feared this toward
social media but I am aware that's the
most I could promise so I chose this
talk because I actually think that what
I'm trying to do is show that various
topics in different fields that might on
the surface seemed quite different
really are often the same problem
disguised and so while I think that
hopefully something will be familiar to
most people here there probably will be
a few topics that no one everyone should
have some topic that is bizarre sort of
oh ok so my outline I'm just going to
tell you what I'm gonna do my real field
of research is thinking about sampling
so I'm going to store it and give you
some background of how people in
theoretical computer science think about
sampling I'm going to give a very
specific example which is independent
sets on the grid and then I'm going to
talk about these crazy related phenomena
from other fields that I don't know much
about but we're going to talk from
physics chemistry and from economics i'm
going to give examples and I can calling
them I originally called it applications
i'm calling it related phenomena to say
there really is something going on
that's very similar in all of these
models ok so the basics of sampling had
i know you have a cartoon on the first
I do you know it's going to be a an
elementary talk right now okay so by
sampling I really mean that I had some
large set which is typically exponential
and size in some underlying parameter
and I want to pull one out at random so
maybe with the same probability maybe
with different probabilities and an
example might be an independent set so
if I give you a graph the black vertices
are an independent set because no two of
them are connected by an edge okay so
the black vertices are an independent
set and typically there's an exponential
number on a graph and I want to sample
one at random or according to a
different way to distribution that will
explain later another example which is
of a very different flavor is estimating
the volume of a convex body so imagine I
have some convex body in n dimensions
and I want to know its volume I might
want to sample vertices that are inside
this body and then that will give me
some you know and take the ratio to some
larger one you know you could imagine
that this is a way to estimate volume
and the reason is that there's related
problems of sampling and approximate
counting so estimating a volume is like
approximate counting ok so these are my
goals and I'm I've been very interested
in lattice models so the same problems
but put on an underlying Gladys so this
is the independent set model you could
imagine sampling matchings on the grid
which this problem if you add in the
edges out so they become these
rectangles is known as Domino tiling so
Domino coverings of the chessboard this
is a coloring model which in physics is
related to something called the pots
model a model of antiferromagnetism the
Ising model I'm actually going to say
things about in this talk so let me just
say a word about how the Ising model is
defined so each square or vertex in the
duel I'm assigning plus or minus and I'm
going to give a reward every time I have
two pluses that are next to each other
so the weight of this configuration and
I'll show this later on is going to be
some parameter lambda and think of
lambdas being greater than or equal to 1
and
I'm going to take lambda and I'm going
to raise it to the number of nearest
neighbor pairs that have the same spin
ok so when lambda is small I don't
really care so much about what's around
me but when lambda is large I really
care that a lot of edges want to have
the same spin as their neighbors so it's
sort of the peer pressure parameter all
right so I'm still up here I'm going to
be talking about independent sets but to
give you some idea of why people are
interested in sampling in the first case
I'm going to show you some examples that
I will end the talk with in greater
detail I'm just going to jump to them
right away and just show you why
sampling might give you insight into
various problems so I'm going to reveal
what the whole second half of the talk
will be in one slide each so in physics
people are interested in understanding
phase transitions which is a macroscopic
change to a system when you have a
microscopic change in some parameter so
as I raise the temperature ice turning
to water or something becoming
magnetized as an example and here are
simulations that are these are samples
of the Ising model that I just explained
at various values of this parameter
lambda so when lambda is small things
are very well mixed you just see you
know when it's one you just are
independently choosing colors when it's
small you have something that looks like
this when lambdas large which
corresponds to low temperature and I'll
say later why that is you're going to
get most of this being black or most of
this being white so the peer pressure
takes over and everybody it's junior
high school everyone ends up wearing the
same outfit okay and then there's some
critical point where you're somewhere in
between yeah exactly um okay here's a
second example this one is from
chemistry so colloid our colleagues our
milk or glue they're things that we
actually experience their mixtures
mixtures of two different types of
molecules one molecule is suspended in
the other and the only constraint that
these molecules have is that they have
to be non overlapping okay so this is an
example I don't know if you could see it
from there I have large blue squares and
tiny black squares okay and imagine that
both the black squares and the blue
squares occupy the same density so the
density of each of these is the
parameter I'm going to change so this is
a low density picture and the this is
chosen uniformly supposedly from all the
ways of having large and small squares
this number of them in non-overlapping
position and this is high density ok so
again this is chosen uniformly from all
arrangements where they're non
overlapping but it looks like something
peculiar is going on that the big things
seem to cluster together ok so above
some density we seem to see a very
different kind of behavior and this is a
turistic of colloids that that occurs
that people study experimentally what's
interesting here this is just higher
density I've just raised the number
that's right so I have maybe the small
ones are in a suspension of the big ones
and as I raise the density what I was
going to just say is that this is purely
entropic what I mean by that is it looks
when people see this picture they assume
that blue is attracting blue or blue is
repelling black that's not what's going
on this is just a picture chosen from
all the ways that you could put things
down so that they don't overlap and
somehow the big things cluster together
I have no idea thank you for what milk
it curdles know
ok um ok so again yeah yeah yeah no the
colloid this mixture of equal density so
I look at what happens at various
densities and I start raising the
density and a property a characteristic
of colloids is that at low density there
well mixed and at high density they
separate ok maybe I meet you I'll of
questions so go yeah fish intellectual
diagram but um I can both of them it
looks like the gaps in the in there like
small particles are like tend of axis
aligned anyway like you have the sort of
horizontal a little like yeah they're
not this is in real space and they
shouldn't be aligned it shouldn't be
happening so I don't know if you're say
again we will get to it at the end so
this is supposedly a simulation for
those of you who kind of know everything
that's going to be in my talk of course
simulating this is hard because we don't
really know how so people are using
things that I'm correct in assuming I'd
like given where the big blue things are
the other things should kind of just be
uniform yes they are yeah that is true
if you fix a backbone of where the blue
things are then just sprinkle this the
black things down and that should be
equally likely right ok so again this is
the second half of the talk this is the
teaser to tell you what I'm going to be
talking about later on and the third one
which I'm putting it at the beginning so
hopefully these models you'll see
similarity already um this is shillings
um segregation model oh I'm fine but I'm
moving you're not but thank you okay so
shelling said let's try to come up with
a model that we can use to study
segregation back when people thought
that segregation is formed by urban
planning and urban design and he was
showing how it could just happen
spontaneously in some sense so I'm
imagine that you have houses in a city
that are colored red and blue to be
politically correct and imagine that
people move if within some radius they
see too many houses of the opposite
color that makes them uncomfortable and
we find maybe we find an unhappy red guy
and have a blue guy and we have them
switch okay and here's an example of a
simulation that I just stole off the web
hopefully not from somebody's paper
who's in the audience of what might
happen after some time and not
surprisingly you're going to see the red
house is clustering together and the
blue houses clustering together but the
details of exactly how that happens and
why it happens aren't completely
understood okay so this is supposed to
be motivation for oh wow if we could
sample we can see these types of
phenomena and in reality the methods
that we understand in order to do the
sampling actually have a lot in common
with these three models as well okay so
i was talking to kala colleagues of
Muktuk halloween i was talking to
colleagues of mine and you know one of
my social media that's the only who is
in social media one of my colleagues
said well that's really easy if you want
to simulate these colloids just take
some configuration at whatever density
and add more things just push them into
the picture and see where things end up
moving like add more squares by just
pushing other things out of the way so
this was his suggestion he said surely
this will be fast and you'll get good
samples and I mean the problem is that
you're going to get the wrong
distribution okay so anything that you
try is that's of this type is really
going to give misleading information and
then another one for people in this area
the thing that they would think of is
pick something up and choose a place
uniformly and try to put it down and
that will give the right distribution
but it's going to take exponential time
before you find an empty space to
actually move it so how you do this in a
way that preserves the distribution so I
just want to emphasize that our goal is
to have something which is fast and
which is correct which gives the right
distribution
and so in this area and again I want to
emphasize this because I'm really
looking at how these techniques are used
in multiple application domains one of
the questions is is the problem
efficiently computable meaning can we
have any method for sampling in
polynomial time so give me any fast
solution okay but because in a lot of
the applications the dynamics are
actually the thing of interest itself
sometimes coming up with some arbitrary
algorithm is not so interesting so I
also want to know does the natural
method work and both of these are
interesting depending on the application
okay so one of the methods that we use
to sample that is often what the natural
chain is the natural dynamics are doing
is a Markov chain which you could think
of for those of you who haven't seen it
it's just shuffling a deck of cards so
you start off if you want to sample a
random permutation you have some shuffle
you're going to do and from whatever
starting configuration you get to a
couple of possible other configurations
and you keep doing it and you're hoping
that if you do this forever you'll have
a perfectly uniform sample and you're
hoping if you do it long enough you'll
get a pretty good sample okay so the
three steps to designing it useful
Markov chain is to come up with some
shuffle that connects the state space
that I could get from any permutation to
any other permutation or any independent
set to any other one you want to then
define the probabilities of choosing
each of these transitions in such a way
that you converge to whatever
distribution you're interested in which
might be uniform and it might not and
the last step is then to show that
you're rapidly mixing which means that
if you do these steps in polynomial time
hopefully you will actually be close to
the stationary distribution and
typically these two are very easy to do
and this is very challenging so often we
have chains that are provably not fast
and even when we have ones that are it's
not always easy to prove that it is okay
so the net
section is going to be the only mouthy
heart really so I want to sample
independent sets only I don't want to
sample them uniformly so I've given a
parameter lambda which is going to
control the density of the independent
set he was just any set of vertices that
are not leave us that's right okay so I
defined it in a general graph only now
I'm going to be looking at independent
sets on some this the chessboard on an
n-by-n chessboard ok so I'm going to
let's see given lambda the probability
of an independent set is going to be
lambda to the size of the independent
set that's the number of vertices in the
independent set and then I'm going to
normalize this by Z which is the sum of
that weight over all configurations so
that this becomes a probability
distribution at funds to one so I'm just
normalizing it so these are the relative
weights so just to get a feel for this
when lambda is equal to one this is the
uniform distribution over all
independent sets ok and when lambda is
much larger than 1 I'm favoring large
independent sets in my stationary
distribution and when lambda is less
than 1 I'm favoring sparse independent
sets ok and this is the simple algorithm
that will work in the limit if I were to
walk forever to sample according to this
distribution ok so I store it at any
initial independent set say the empty
one because I could find that one easily
and then I'm going to repeatedly um
choose a vertex in the graph and a bit 0
or 1 if the bid is 0 I'm going to try to
remove that vertex from the independent
set so if that vertex is in my current
independent set I remove it but I only
remove it with this funny probability
which I'll say something about in a
second and if I if b is equal to 1 i'm
going to try to augment the independent
set by adding this new vertex and i add
the new vertex to the independent set
with this probability only
it's not in the independent set and none
of its neighbors are in the independent
set so I have to stay within the set of
independent sets okay so the graph is
connecting any two independent sets that
differ by the addition or deletion of a
single vertex this connects the state
space because starting at any
independent set I could just one by one
remove everything and get to the empty
independent set so this connects
everybody the second step was to add
these weights these probabilities right
here on the transitions this is known as
the metropolis algorithm and it just
forces the chain the chain to converge
to exactly this distribution that we
wanted okay so I'm not going to say more
about it and so that means that the
chain connects the state space converges
to the distribution we want and we want
to know how long it takes okay so my
goal is to understand this and it's
known as globe or dynamics because we're
just changing things locally it's a
variant of our dynamics okay so when I
say how long I took out all the
technical stuff that the definition is
just if I look at the teeth step
transition or the distribution after
teeth steps of performing the markov
chain and I look at my goal distribution
pie I'm looking at how far those twos
distributions are point wise okay and I
want this to be less than epsilon or
less than a quarter for some input
epsilon and I'm going to say it's
rapidly mixing if this convergence if I
get or less than epsilon from the
stationary distribution in polynomial
time and I'm going to say it's slowly
mixing if it's if I requires exponential
time before I'm close it's some
parameter so it might be exponential in
route and it's exponential in some
polynomial on n yeah I'm purposely being
a little vague and we have all sorts of
techniques that we can use to upper and
in fact lower bound the mixing time of a
markov chain and the one that you would
learn in a probability class is the
spectral gap so if you take the
adjacency matrix and
you look at all of the eigenvalues it's
the largest eigenvalue will be one and
the difference between the top two
eigenvalues is going to control the rate
of convergence but we have an
exponentially large state space that we
can't even write down so we can't
explicitly calculate these so everything
else here is an attempt to estimate that
spectral gap and so we have various
techniques and a lot of these come from
physics and I'm pointing this out
because I really want to sort of
indicate the success of the
communication between all of these
fields so going back here I can try to
apply all these different techniques and
see if I could analyze this particular
train to get a bound and the first one
you might try is coupling it turns out
it's one of the simplest to do and it
gives you fast mixing when lambda is
less than a half okay so that's not very
exciting but of course people said okay
that's the first thing you would try
what else can we do and there have been
many other improvements and this is some
partial history of what we know now so
Lou bein Vigoda pushed it up to lambda
less than or equal to 1 White's had a
beautiful improvement that got it higher
and recently restrepo and this is in the
last year they got it up to two point
three eight okay so whenever lambda is
on the small side this is favoring
sparser independent sets then we know
that this globe or dynamics mixes in
polynomial time so we could use it to
sample okay however there have been
complimentary results okay here are the
complimentary results so B and C might
be people you know in this audience okay
so Christian and company showed that
when lambdas large this exact chain is
going to take exponential time to
converge okay and there have been
improvements we recently got it down to
five point three nine six or something
okay so you can see that there's a gap
now where we know less than this the
train is slow greater than that the
chain is oh sorry less than this the
chain is fast greater than this the
chain
slow there's a very strong conjecture
that says that there's actually a
critical point below which it's fast
above which it's slow and that critical
point is 3.79 okay and you know we're in
the ballpark now but there's still a
long way to go yeah it's for the
specific chain but they generalized to
Kwazii local as long as you're changing
little o of n sites so 3.79 is a
conjecture we don't know that there's a
critical point but it's a conjectured
value of the critical point it's
believed that below three point when
lambda is less than 3.79 these dynamics
should be fast and above it should be
slow mmhmm yeah I mean this has existed
for a long time and it's um yeah there's
no hard evidence I mean we don't even
know that there's a single critical
point although it seems doesn't seem
unlikely yeah jeans for independent sets
no not really yeah it's hard to imagine
you know how you eat how you get one
night mm-hmm how you get a non-local one
rights and somehow if you try to change
too much then you know you're it yeah I
mean it's something that I'm thinking
this 3.79 is not a result of some
symmetry or conformal appearances no its
numerical strong feeling that there is a
phase transition here and then that's an
estimate of the value of the base
trindon based on haunted based on magic
are low or something mmhmm yeah okay and
I mean okay so this is the state of the
art right now and before I move on to
the second half of the talk I sort of
just want to indicate for those of you
aren't familiar with us
that you know this type of phenomenon
the reason we think this is going on is
we're seeing it for a lot of different
models so oh I do actually say something
about why this is happening so okay so
why would we expect that these should be
slow all right so here are three
remember let me just go back for a
second when you have this waiting we're
talking about the case when lambda is
large when lambdas large we're really
putting most of the weight on very dense
independent sets so here are three
fairly dense independent sets these are
they to maximally dense independent sets
we have the even vertices in the grid
and then we have the odd vertices in the
grid so I'm just coloring them red or
blue depending on the parody of the sum
of their coordinates okay and here we
have one in the middle which happens to
be half black and half red if I connect
if I counted correctly all right and
this actually has if this is an N by n
region this has linearly fewer vertices
than these two other configurations okay
and so the weight of this one before we
normalize is lambda to the N squared
over 2 as is this one but the one in the
middle has n over two fewer vertices so
it has lambda to the N over 2 less
weight than the other two configurations
and I'm drawing it this way to say that
if we were to plot the likelihood of
seeing a certain ratio of even Todd or
red to black or whatever we would expect
this kind of bimodal distribution
because things here are going to have
exponentially less weight than things on
the other two sides okay no of course
I'm cheating and I'm cheating because
the height of this is actually the sum
over all configurations that have that
balance ok so all I showed you is that
any particular configuration here has to
have exponentially smaller weight than
the other two sides but there's an
exponential
number of balanced configurations so we
have to be really careful to see the
trade-offs between the lower energy the
lower weight and the high entropy which
is the number of configurations there
and that's what all of those proofs of
slow mixing we're doing was looking at
that because if you could show that this
picture is really what's going on then
when lambda is large we say there's a
bad cut in the state space so if you're
on this side it will take exponential
time before you could cross over to the
other side because to go from 0 mostly
black to a mostly red configuration you
have to pass through a balanced one if
you're changing one vertex at a time
okay so that's the high level picture
okay so the summary that we know right
now for independent sets on the grid is
that there's a conjectured phase
transition at some value maybe 3.79 and
we know rigorously fast and slow in
these regions for the Ising model yeah
it's fine if you have the same chain but
say with some small probability you flip
the set right so so that then you know
that just goes from the odd thing to the
even thing and you've folded that
picture on itself then out like a look
single hump and so that that was that
the flipping would be a non-local yeah
and presumably that turns it into a fast
chain but we can't prove it and for a
lot of graphs if you have you can't
always you don't always have that
built-in flip so if you're really
interested in the end by end grid yes
you could presumably try something like
that but we don't have proofs that it's
fast but it should be somehow
intuitively like the picture you really
is the canonical this is the Bob this is
kem the only welcome back from some
sense or um I mean I I'll explain to you
afterwards why I wouldn't exactly say it
that way okay so I said that this kind
of phenomenon is actually coming up for
many models for the Ising model on z2
particularly on z2 really everything is
known and so we actually
a very clear understanding but keep in
mind this is really the only model for
which we know as much as I'm about to
say which is we know there is a critical
point it's known what it is we know that
it's fast less than the critical point
it's slow greater than the critical
point and within the last couple of
years it was shown that it's fast at the
critical point so we have a complete
picture for this particular model that
what was suggested for independent sets
is exactly the right picture there's a
similar phenomenon happening with
coloring so three colorings on grid
regions there's no parameter right okay
so I'm just looking at uniform
probability on all three colorings and
here you see the phase transition if you
change the dimension okay so in two
dimensions if you take the algorithm
that you choose a vertex and a new color
and try to recolor with that new color
we know it's asked in two dimensions but
we know that in sufficiently high
dimensions exactly that algorithm ends
up being slow okay so changing the
dimension is sort of a way of simulating
adding this parameter all right so this
this seems to be happening in many many
other models too okay so I am and
exactly what you're asking I mean that's
sometimes not in this particular case
but in some of these cases by
understanding why the chain is slow
because of these phase transitions it
does suggest other algorithms so that
actually is the question that I ask at
the end of the talk also that is my main
interest in all of this okay so I'm
going to switch now and just say a word
about more than a word but I'm going to
talk about how these see same models are
coming up by scientists looking at very
different types of questions okay so the
physics one I have to confess I almost
took out of the talk but I'm going to
put it really quickly to just say that
you know as somebody interested in
sampling I you know these models
matchings and independent sets and so
forth
come up quite a lot the reason they come
up in physics is slightly different but
people are asking almost the same
questions so okay so to remind you this
was the Ising model so a physicist would
be interested in a physical system and
they would define a Gibbs measure as
follows so they have some function of
the system which is the Hamiltonian and
I'll give you examples in a second one
over KT is inverse temperature and they
define the probability of a
configuration to be e to the minus beta
inverse temperature times the
Hamiltonian and then they normalize by
dividing by Z which is known as the
partition function which again is just
the sum over all configurations okay and
I include this in talks on computer to
computer scientists because for some
reason as soon as I write it this way
everyone seems much more confused so and
hopefully so let me go two more seconds
okay so this is for y'all okay so so
beta is inverse temperature H is a
Hamiltonian which depends on the problem
we're looking at and z is normalizing so
hold on console let's do with the
physical universe yeah okay so
Boltzmann's constant okay one in your
units k as well yes because we don't
measure temperature it says is but some
yet I see yes don't worry about it in
the right units it's gone I guess I had
that in a previous version ok so for
independent sets H of Sigma is minus the
size of the independent set and for the
Ising model H of Sigma is minus the sum
over nearest neighbors of the product of
the spins this still for computer
scientists is very confusing so we do a
change of variables and if i define
lambda to be e to the beta now i can say
for independent sets the probability of
sigma is lambda to the size of the
independent set normalized and that's
just what i showed you on the previous
slide and this for some reason computer
scientist centers
okay myself included okay and again for
the Ising model we do the silly change
of variables and now it's just what I
said before the weight of a
configuration is some other parameter
new raised to okay my colors got messed
up but e to the equals is just the
number of nearest neighbor pairs that
have the same spin okay and we normalize
that's it that's what all of this says
and okay so what I've just done is I've
defined right I know honey so okay so
this is on a finite graph but physicists
are interested in what happens in the
limit on infinite graphs okay so we can
to find these probabilities this way on
an infinite graph so they define it as a
limit so they say we're interested in
defining a probability and we're going
to look at what happens in larger and
larger regions as we approach infinity
and trying to look within a region
whether it stabilizes okay and
unfortunately what happens is the
boundary matters now okay so think about
fixing I don't know why these turn to
white but you know I fix either odd
vertices around the boundary of an
independent set or the even vertices say
around the boundary okay and then what
happens is that at low temperature you
get these long-range effects which is at
low temperature whatever color you had
around the boundary here you're more
likely to see on the inside in other
words if you had odd vertices around the
boundary then on the inside you're
likely to see more odd vertices at high
temperature that dies out so at high
temperature whether you had odd or even
what you see in the middle region is the
same okay so i would say here no matter
how i go to infinity there's a unique
limiting distribution whereas up here
there's certainly not eliminated a
unique limiting distribution because we
found two boundary conditions that give
two different limiting distributions in
the middle okay so just really gimmicky
cartoony what's happening up here is
this was exactly where I showed you for
large lambda we had this bimodal
distribution okay and so what's
happening on the band
under e is controlling which side that
ear in whereas down here this was the
case where at the at high temperature it
corresponds to low lambda where the
independent sets are sparse we have this
you know modal distribution and as you
change it there's some critical point
and the point of all of this is that if
you're looking at the question that
physicists would ask is when is there a
unique limiting distribution for the
hard core model that's independent sets
that's the physics name for independent
sets the best rigorous results now are
exactly the results I showed you on the
previous one of the previous slides for
the mixing for fast and slow mixing okay
of the globe or dynamics for independent
sets and I want to make it clear that
these don't come automatically you
actually have to do a slightly different
proof each time we don't have something
that automatically says that one implies
the other but these results follow okay
so even looking at the question as a
physicist the techniques that are being
developed or saying something over in
this domain as well on the infinite
lattice even though we're studying them
on finite lattices okay right in the
previous question if I add or remove a
single vertex at a time right with the
appropriate metropolis probabilities do
I converge quickly to stationarity and
here it's if i look at the limiting
distribution on the infinite not a
finite but the infinite lettuce do i
have a unique limiting distribution or
not and the conjectured 3.79 that we're
talking about is conjectured for the for
this question not for the mixing great
question but people believe it's the
same no
it's it's it should be I mean perhaps
with some appropriate conditions we're
in the same field Jennifer okay so this
was just sort of to give you some
background on physics so clearly I've
indicated i hope that the mixing
question and this limiting distribution
question that physicists would ask are
the same question in in some sense okay
so i'm going to switch now to chemists
to this chemistry model and then at the
very end i'll say something about the
shelling model okay so we have mixtures
of two different types of molecules and
they can't overlap so for starters all
the kinds of algorithms that we know of
for simulating things here should be
slow okay so people have come up with
really clever non rigorous algorithms
for doing these types of simulations
these come out of papers of people using
various heuristics that might be fast we
have some evidence that they might not
be so I I don't know if this is really a
random configuration but this is what
people believe that they look like kind
ya know it there's actually an amazing
algorithm that's used and it's very
clever it's um it's boo hot and crow and
what they did is um I guess I'll tell
you after but I mean it's non-local it's
clever and I I'll explain it afterwards
but I'm not going to get through
anything if I do it now but that's an
open question how do you simulate all
right so these pictures are supposed
yeah
uniform distribution here you take goods
to uniform distribution over independent
placements of each schedule than
condition on the beam non-overlapping
correct yeah yeah that's equivalent and
I mean this is people study it in real
and discrete spaces I'm now going to
canoe which over two discrete models of
colloids rather than real models so here
there in real space okay so i'm going to
introduce a family of discrete models
that i can say something about okay so
from my discrete models i'm going to
have two types of tiles tile once it's
has some rules of where they could sit
tile chusetts has some rule as to where
they can sit and they have to be non
overlapping ok so here model one is my a
tiles are squares that sit on lattice
faces and my B tiles are diamonds that
are bisected by lattice edges either
horizontally or vertically ok here's
another discrete model in the same
family a tiles are squares on the faces
and B tiles are squares centered red
vertices so here the a tiles and the
Beatles are the same size for most of
the models they have different sizes all
right and I'm going to just tell you one
of the technical things that makes the
analysis a little bit nicer is that I
had said that we're going to look at
fixing the density of both of them to be
the same there's no reason they need to
be the same so I really have two
different parameters controlling the
density of each and I'm going to fix the
density of one of them and I'm going to
let the other one I'm going to choose
all the places where I could put a beat
I'll given a fixed a configuration I'm
going to let it be there or not be there
with probability lambda or 1 minus
lambda ok so so I could control the
expected number of B tiles and the
number of a tiles ok do these models
look familiar ok so this is the Ising
model and this is the independent set on
a lattice that's rotated by 45 degrees
so
this one I will show you a picture later
on in the talk that will demonstrate it
these are exactly what we've been
talking about it's just disguised okay
and i should say it's the Ising model at
fixed magnetization for the physicist
all right so previous work this first
model of squares and diamonds was
introduced by Frankel and Lewis and they
saw that this that the behavior could be
inferred from the fixed temperature
Ising model so the fixed temperature
Ising model has been studied really
extensively and jennifer has done very
nice work on this as well and there's
the exact limiting shape is known as the
wolf shape and there have been tons of
papers analyzing exactly what the
limiting shape is going to be and it
turns out that that is going to tell you
something for the this colloid model
that I model one that I'm calling model
one so if I in well
when you go to higher density when you
go to high enough density it's saying
that the blue squares are going to
cluster together and they're going to
behave like the + spins of a dense of an
Ising model at low temperature okay and
how the + spins are going to cluster is
going to be it's going to be square like
and which is like a minimization of the
energy which gives you the boundary of
that shape plus fluctuations around that
so that's right so you prove that with
overwhelming likelihood most of it goes
into a single bubble plus perturbations
of that and the shape of that bubble is
something which minimizes a certain
energy functional a plus all these all
all the fluctuations around that and
wolf in about 1900 came up with an
equation for that energy Thanks yeah so
again on the previous day could you
please define the model on the left
again what is the distribution ok so I'm
fixing the number of blue tiles to be a
certain density so there's at most n
squared on fixing be N squared blue
tiles ok and then the red tiles i'm
looking at all configurations where
they're there with probability lambda
and not there with probability 1 minus
lambda and i'm choosing from all
configurations where you could have that
just the blue tang is the uniform no
it's it's right so ok so I'm giving the
weight of a blue configuration is going
to be the sum over all ways that you
could have red tiles consistent with it
of the weight of the red tiles which is
going to be lambda to the number that
are there 1 minus lambda stoughton the
ones that are not there ok so
exactly what's happening here is that if
i push the red ones together and
minimize the perimeter I have more
places for the blue tiles and that's
exactly what's controlling why you end
up having these things push together so
things where they're pushed together and
the perimeter is minimized it turns out
that those are going to have the most
weight if you sort of mod out by the
blue ones so it's not uniform over I
know I said it so that it sounded like
it was that wasn't what I meant okay
okay so what we do is we define a class
of interfering binary mixtures that
includes model one and model to that
lets us argue about there being
clustering that will apply to this
entire class and we give direct proofs
that are reminiscent of what's going on
here for the Ising model so it's
generalizing this but of course we're
not getting something nearly as precise
as the wolf shape so we're getting much
weaker bounds on understanding the
limiting distribution but it will apply
to this whole class so here are examples
of interfering binary mixtures there's
many others but it includes model one
and model well model 2 and muddle one
here's another one so the definition is
going to be that I have two planar
lattices lambda sub a and lambda sub B
that tile the entire plane okay and I'm
looking at the intersection of both of
them with some finite region say a
rectangle all right and it's an
interfering binary mixture if it has the
following property that if I take a cell
of lettuce a and a cell of lattice be
there either disjoint they intersect it
just a vertex or they overlap and the
overlapping area is I so are always
isomorphic to some fixed shape ass okay
so in this case whenever I have a
diamond intersecting a square I always
have this yellow triangle in one of the
four orientations does that make sense
okay so I always have some fixed shape
we can extend this to a finite number of
fixed shapes s okay but for now I'm just
going to state it in terms of one so
this is an example of an interfering
family this is also an example when the
red and the blue squares overlap this is
the only way they can and they intersect
in a smaller square s like this so this
is in the class and that other model is
here I'm going to now show you why this
is independent sets so take the squares
and shrink them down and rotate your
head by 45 degrees so the red vertices
are the odd ones and the blue vertices
are the even ones and this is just an
independent set on a rotated grid well
it's on a rotated diamond okay so so
we're seeing the same types of models
the same combinatorial structure is
really coming up in these very disparate
things so here are I'm just going to
state the types of theorems that we have
for this class of interfering binary
mixtures so again we're fixing be N
squared a tiles so b is always going to
be less than or equal to a half so the a
tiles occupy at most half of the volume
and the B tiles are present with this
probability so we have two theorems I'll
put them up at once which just says for
any fixed number of a tiles there's some
lambda above which we're going to get
clustering okay and for any be there's
another lambda star below which we won't
get clustering okay so that's what the
two theorems say so it lets us
understand the role of the a tiles and
the B tiles independently rather than
just saying as we change them both at
once we get this phase transition or we
get clustering okay so what is the
clustering property okay and this holds
for all interfering binary mixtures that
we have defined it so this is a picture
of something we would say is clustering
and this is a picture of something that
is not clustering okay so what does it
mean for it to cluster so informally
there's a region so this black outlined
region and notice in this case it's
disconnected that has small perimeter
linear perimeter quadratic area it has
large area small
limiter the blue tiles are dense on the
inside of the region and they're sparse
on the outside okay so that
characterizes this here we have
quadratic area but quadratic perimeter
so I'm not calling that clustered okay
so this is the definition that we use to
prove those two theorems okay yeah did
you not do you know whether there may or
may not be so you could have a gap
between clustering and non clustering at
the lambdas it do you necessarily have a
gap or you don't know if they're we are
not proving anything close to the
critical point so yes we don't know that
what exactly what's happening in between
but we know that for any I mean this
thing's weren't worded in this form
before that if you fix the number of a
tiles and let the other one very I can
find a point above which and I could
find a point below which for any fixed
density yeah so that's all I can prove
yeah this stuff tonight the real world
so you know if you have I don't know
whatever your question yeah things like
protein folding right so it's hard for
us to fold protein you know it's
computationally and lo and behold you
know in the real world it takes a long
time for your proteins are properly fold
it takes on the order of the fractions
of seconds a long time right um for
these things like if i take like you
know the water and powdered milk makes
it shake it around then like do you get
these like so saying that these dynamics
are slowly mixing which is what i'm
suggesting by connecting it to the other
models is different from saying we're
going to see the clusters quickly so we
will see these clusters happen quickly
it's just to mix and get to other
clustered configurations will take a
long time and I when I say it will
happen quickly I can't prove that but it
will happen quickly yeah there's another
question okay so who wants to hear about
segregation
okay i know a lot less about segregation
I'm trying to learn more but but I think
what's interesting let me just start by
saying that there's a part of what's
interesting is that there are so many
variants on the original shelling model
and I think that a lot of them are
really worth studying so here are some
interesting variants ok so the
neighborhood sighs do I care about my
for immediate neighbors do I care about
my 12 immediate neighbors is that any
radius R do I care about everyone in the
city but maybe I care less when they're
farther away ok so these are all
variants that I think are worth studying
and we can say things about this one is
interesting so shelling said the
following he said within a radius R
suppose that we're completely
indifferent up to fifty percent of the
other color but as soon as we hit fifty
percent where as unhappy as if everyone
were the other color okay so it's just
there's two states you're happy or
you're unhappy alright and we can
consider instead a geometric function
where every time a new a new one of them
move in i get a little bit more unhappy
ok so you can imagine something where
you have a geometric function where you
just become increasingly unhappy and you
know this geometric bias function is
actually going to correspond to the
Ising model that we've been talking
about okay on just a graph that depends
on the radius and you could consider all
sorts of other things in between all
right but he originally proposed the
threshold version you could consider an
open or a closed neighborhood so in open
neighborhood means if I'm unhappy with
the demographics around me I'm going to
move to a different city okay versus a
closed city where this number of red and
blue people work in the city and they
just have to move somewhere else but
their job is in the city and they can't
move somewhere else is the closed
setting you could consider a saturated
versus non-saturated are there empty
houses and are empty houses next to you
desirable or undesirable and we've
considered it in the setting where it's
a foreclosure it's not a good thing to
be next to so you hate being next to an
empty house even more than next to the
other color okay this one is really I'm
sort of obsessed with right now selfish
versus global when I decide to move am I
just looking at my local neighborhood
and saying I would be happier over there
so I'm going to move over there or is
the fact that when I move over there I
might make a lot of other people a
little bit more unhappy do I care about
that okay so so you know I mean for a
lot of the models that we've been
talking about and I hope you can see now
that there's similarity between the
shelling model and these statistical
physics type models that we've been
playing with that it's a product measure
over everyone's happiness and you decide
whether to move or not based on the
change in happiness of everybody but
presumably there's something more
selfish going on when people are
deciding where they're going to live and
I don't know how to handle the selfish
case at all yet so everything that I'm
going to talk about is in the global
setting so for starters if we have this
geometric bias function we have any
radius we have an open City no he was he
was selfish okay yeah which out of
context sounds very bad but that's ok so
the open setting so I'm looking at the
open setting where people can move to
other cities I'm going to start by
talking about the saturated settings so
there are no empty houses so in this
case as soon as someone read moves out
someone blue or red can move in and if
they happen to also be read then it's as
though there was no change and if
they're blue it looks like they change
colors okay so just just houses are
desirable okay and so in this case
lambda is the unhappiness so we are in
the case where we have a geometric bias
function so for every neighbor that I
have within my radius of the other color
I'm lambda unhappy it's my bias factor
and I move with probability which is
proportional to lambda to the number of
unlike neighbors over Z it's
I didn't say at the right way it's the
product over everybody of this color and
you're like four houses away from you as
long as everything is within the radius
yes but we could generalize to where you
bury it and in fact we could generalize
to any radius even infinite you know as
long as yeah as long as it's decreasing
influence farther away so I can make it
so that I care more about my immediate
neighbors right now I'm just defining it
in the simpler case yeah okay and then
you know we get something we get these
two statements which are really very
similar to an Ising model on when r is
equal to 4 this is just what we're
getting for an Ising model and we're
looking at it for larger radii as well
including the infinite radii case this
is parameterised in a weird way but it's
basically saying that when when my
tolerance is high so i'm not very racist
or everyone in the city is not very
racist the city stays integrated and
when i start becoming very biased in
this case and in the open setting a
ghetto will form and one color or the
other will take over okay so there will
of course be variation but the city will
be predominantly one color or the other
and you know we are showing that whether
it converges quickly or slowly but
really there are additional proofs that
can show using kind of the clustering
definition that we had in the context of
colloids that we're getting integrated
or ghettos forming so we're getting
clustering or no clustering in by the
definition that I just gave and
presumably we could also show it for
closed cities but the proofs are getting
really complicated so we haven't shown
that yet okay and we can also do it in
the non-saturated setting so here you
have this is how much you hate people of
the other color you even greater hate
empty houses next to you okay so in
terms of these two parameters it's sort
of a funny definition but we have a
similar the fast proofs are the same and
the slope roots take into account the
extra parameter
so very similar results as I just showed
you we can handle the empty houses and
then we can generalize from geometric to
something we're calling by Lipschitz
functions which just means that I need
that you could have something like
threshold behavior but I need in
addition that every time at fifty
percent I might get a lot more nervous
living where I'm living but with each
new person of the other color who moves
in I have to get a little bit more
unhappy but okay so okay so you know a
lot of these we can I haven't been able
to say anything about threshold behavior
but Christian has ideas which I'm
excited about I don't know how to say
anything about selfish behavior using
these types of approaches ok so the
conclusions I mean especially for those
of you not in the field what I'm trying
to show is that really across very
different fields people of course we're
seeing phase transitions and are seeing
similar types of behavior but in some
sense they're really actually almost the
exact same model if you specialize it
the right way so we really can learn a
lot about the behavior of these models
by bringing over some of the techniques
that we've been used to study them but
the subtle differences really can be
significant so you know we it looks like
the same proof should work but we have
to really redefine the proofs in the
context of the parameters were being
studied in terms of housing or in terms
of they become slightly different
questions and they can be significant
differences so next steps this is the
question that he's been asking is can we
use the underlying physics to build
smarter sampling algorithms when we know
things are slow is something that I
really care a lot about for the shelling
model can we analyze segregation models
enclosed cities again I think we can do
that but we haven't yet so this is where
you people can't move out of the city
they just have to move somewhere else
within the city for the threshold bias
function so this is what again I think
there might be new ideas for this but I
haven't been able to prove anything for
or the really important question here I
think is when the moves are selfishly
motivated if my desire to move somewhere
or not it's just as is it better for me
I don't care about whether you don't
want
there yes what a Chilean um you know
shellings original model shelling didn't
say much about the way I'm presenting it
here for example I have in my model that
everybody has some probability of moving
in his you only move if you're unhappy
so there has been some discussion among
physicists looking at the shelling model
of whether the selfish behavior and the
non selfish behavior should whether
that's a significant change or whether
that's not a big deal to change it and
there isn't consensus I haven't found a
lot on it so shining waters actually
if deterministic moves yeah it was yeah
71 yes yeah yeah so I mean it was um you
know there's this holy grail to really
understand the model that shelling first
put out but in some sense i think that
we have better understanding about how
to model exactly what he was modeling
was trying to get at that might actually
be simpler to analyze it might actually
be more realistic so at this point okay
so thank you these sharp transitions
vary the temperature or something in are
there any known examples that there
isn't such a sharp transition there is
somewhere it it is non-monotonic and you
know weird graphs and yeah so does it do
any physical phenomena we've seen well I
mean there could be you know for some
models there on multiple phase
transitions that are going to manifest
in different ways so if you're looking
at the threshold for mixing it could be
yeah I mean it's so you can have more
complicated behavior for the simple
models on grids on you know these kinds
of things I don't know of a natural
example
well there's no face transition there it
is at the end the phase transition is at
zero there no seriously it is the phase
transition just happening at syrah there
are cases in which you don't have phase
transfer so yeah it depends on it
depends on the dimension there are also
cases where where something is not
global I mean this is what you know free
goods criterion gets out a little bit
where something is not global then you
just get a smooth thing instead of this
sharp transition the transition is
associated with something global
happening and that's kind of what
frequents Baron says to you and what day
missing here are these global phenomena
of kind of a a segregation or a
clustering of one type the dominant one
one type but its global righted these
mixing clamps always um I mean people
understand in some cases how things are
slowing down so how they're like how the
polynomial is changing and approaching
exponential but I don't know of anything
that's in between in the sense that I
think you're asking I mean it could be
exponential in route and you know or
things like that so yeah but I mean the
polynomial has changed so that if you
look at the change it is approaching
something which is super polynomial
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>