<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Code Completion with Statistical Language Models | Coder Coacher - Coaching Coders</title><meta content="Code Completion with Statistical Language Models - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Code Completion with Statistical Language Models</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/RTMoEfH4NC0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi everyone thanks for coming
I'm modern Maserati from the research in
software engineering group and it's my
pleasure to invite my intern who's
working with Todd on something not
related to this is actually working on
doing very fast log analysis but I think
you know veterans interest is in
combining PL and machine learning in
interesting ways and he's done
interesting work back at ETH Zurich
where he's worked with his advice of
Martin Richard and Aaron Yahav are doing
code completion using you know better
language models by analyzing large
amounts of code I see so thanks for the
introduction and thanks for coming to a
talk on code completion statistical
language models I'm a PhD student at ETH
Zurich and this work for code completion
mystical language model serves towards a
vision that we have that we want to
build systems that's all variety of
programming challenges not possible to
solve before by leveraging availability
of massing programming data so these are
big open source projects that are out
there on the web and we made this this
ideas but recently a DARPA post a DARPA
initiative created this term called big
code and we like this term because it is
today because our work is about code and
it's also big so we like it so these
systems that we develop were exactly
what to combine advanced difficult
techniques and programming languages
techniques so we have various works at
different stages in the pipeline at ETH
Zurich we have statistical code
completion that's a paper that appeared
at toti 2014 this summer recently we got
accepted statistical programming
language translation if you appear at on
word in Portland in around
half the statistical programming
language translation works like think of
it as implemented for Java and c-sharp
and just just see what happens if we if
you apply the same approaches what would
happen as the approach for natural
language processing and recently we
created a new prediction system called
J's nice it's predicting program
properties and choose by JavaScript
developers got quite a lot of publicity
and traction a bunch of developers are I
mean hundreds of developers are using it
every day and this system is predicting
properties like name some names of
arrivals and types of arguments for
functions these are things that were not
possible to get before with regressor
tranches so what's the common between
these systems the common is that they
used advanced machine learning and they
also combine it with program analysis
and what what the goal is that we are
working towards a foundation that you
actually explain how how to build such
systems and bbs a basis of many other
possible new applications so now I'm
going to concentrate more on sophistical
code completion work there's a paper QD
a 2014 you can read and it's a system
called slang so why why do we want to
build such a system for code completion
oh because the code completion problem
is it's a hard problem it's hard because
there are many api's almost every
library has non-trivial API more than a
couple of functions that are not very
easy to remember to understand by
developers and so we we made a system
called long that is statistically by
completion it learns the data
interactions from big code from
lots of examples of using this API and
then suggest completions based on this
so what are the capabilities of slang so
slang takes a partial program or
programs incomplete program where some
of the statements of the program are
given and some are missing for example
because the developer did not know what
to complete the program with so I give a
small example here that uses android api
s-- camera is an api for using the
cameras of mobile devices a media
recorder is another api for recording
audio and video and this class is
specifically known to be hard its
documentation describes it as one huge
automaton of what happens after calling
so in this example somebody opens the
camera says this presentation creates
media recorder audio video source output
format output file then it gives this
together with the question marks to
slank
an instant completes it figures out the
camera will be unlocked and camera must
be passed to the media recorder the
audio and video encoder must be set so
what are the what are the special
capabilities of slang that were not
there before so first we are able to
complete statement that involve multiple
objects so this statement involves both
the recorder and the camera on one we
call the method on the other with path
parameter there is a second capability
that was not possible for with other
systems before is that we were in for
multiple statements at once so we
complete this whole to set in both the
audio and a video encoder because this
is actually the right way to use a media
recorder cannot skip doing this and
finally I made a major capability of the
system is that it can predict things
sequences of api's that it did not see
before
axis so we checked in our big training
data that such sequence that says camera
open camera said this presentation
camera unlock did not exist in the
training data yet we were able to figure
out by some code that used some of these
methods that this will be the most
likely completion for such a program so
two capabilities that were not possible
before multiple objects multiple state
and generalizing to unseen sequences so
the key insight behind the statistical
code completion is that irregularities
in code are similar to regularities in
natural languages so we want to learn
regularities like the fact that we
create a mediarecorder before we we
called set camera of the media recorder
and it's like kind of similar to what
the natural language regularities that
would say hello is before world so
natural this speaker would not say the
other way around
I mean native in speakers so we want to
learn such natural ways to write
software and so we come to the slang
system what the slang system does is
that it takes the big code and for each
of the programs in the big coat it
performs a specially designed program
analysis that could convert the code
methods into sentences sentences are
something that the language model can
take then we train the language model
and then we obtain that looks like a
database that is the model we can query
for probabilities s query it takes an
incomplete program the one that I've
shown you before or another one it
performs program analysis is very
similar to the one that we do what
indexing time then we query the language
model in order to complete sentences so
once we complete the sentences we have a
yes yeah you put the question marks in
the code then it completes the sentence
and there is a procedure that must be
done that you complete that you combine
these completions we cannot just take
the sentences that are out there from
the language model we have to combine
them and then as a result we get a
completed program variable names do not
participate in this because we the
obstruction remove the variable names we
get some constants of API I don't care
how than how the object is named
we care what API if you rename the API
it will probably not
thank the ice are getting stable things
less words no way actually we should
discard the pipes and it still works so
that's why we think this system will be
applicable to dynamic languages as well
yes it's drinks yes it works
we weren't liking language model in
those types can after the fact if you
have multiple potential persons the
types can potentially weed out things
there this type check did you guys yeah
so we discard the types but it turns out
many things type check so in the end in
the end the correcting would be to do
type checking of the problem the
produced result but even if we don't do
it we are at very very high precision so
I will tell a bit more about what what
we do a straining face now so the first
the first component is the program
analysis component that transforms
programs into sentences and for this
component I will explain what it does on
a small example so we perform static
analysis why we perform static analysis
because we don't have inputs for the
mini program that we were windex we
cannot run them so we statically just
read the code we actually look into it
as in complete programs and statically
analyze and then we perform two type of
analysis first alias analysis and second
type state analysis so alias analysis
computes a bounded representation of the
potentially unbounded heap so there may
be many infinite number of objects in
the heap but we bound we combine
multiple objects into abstract objects
that represent the potentially infinite
number concrete objects the types data
analysis analysis for each of these
abstract objects possible sequences of
API invocations
so let's let's go to the example so
there are there are two abstract objects
here me and she they we can probably
denote them by the time the dog location
at which they are allocated like new
acts on new why but I just wrote them as
the name of the variable because
there is only one variable pointing at
each object so for abstract object me
there are several possible encoding so
the first one is that me is created with
the Y constructor so the first word that
I write is it comes from Y and then I
put some subscript in it that says this
is a result of calling the white
constructor then sleep is executed on me
so this is the statement mid not sleep
and then talk is executed to me this is
the last one this is one possible
sequence on me another possible sequence
would be that each will be called
between sleep and talk so if we enter in
the if statement it will be called as we
want so we have this sequence as a
possibility similarly for the abstract
object Qi will either type date
abstraction we get similar sequence XI
is created with the X constructor then
enter is caught on XI so this is this
statement around the end and now this is
this is an interesting word it says she
participates as an argument of a method
invocation and this is the first the
first parameter so we do not only
capture invocations on the object but
also invocations where the object was
passed as a parameter
she's got multi object type state so
once we get from a program to such a
sense of sentences we we we have kept we
can capture regularities in sentences
and these regularities in the sentences
will be equivalent to the regularities
of the API usage we designed abstraction
to be like this so if we see many
sentences that look like X you need
enter talk we can probably learn that
talk is often after enter it's very
likely the talk will be called after
enter and then once we get these
sentences with with trained us the seco
language model statistical language
model is a very widely used natural
language processing technique
the goal is given a sentence that
consists of some words that we want to
WN we want to estimate the probability
of this sentence to be part of the
language estimate probability of it
usually this is done by decomposing two
conditional probabilities so the
probability of the entire sentences
product the probabilities of each word
given the words preceding this word
so for example if you have the sentence
the quick brown fox jumped its
probability of Doug multiplied by
probability of quick given the brown
given the quick folks given the quick
brown and jump given the Queen rocketbox
of course estimating these individual
probabilities may be also very hard
because this one has placed him at
probability of jumped given some very
long sequence so there are different
types of language models that try to
solve this problem by modeling the
languages other other kind of process so
Engram language model estimate is this
conditional probability only based on
the previous n minus 1 words so instead
of word type on all words from 1 to I
minus 1 it's worth I based on the words
that are only I minus n plus 1 to I
minus 1 and minus 1 words so example
with a trigram language model
probability of jump given the quick
brown fox is estimated just by
probability of jump given brown fox and
this on its own is estimated by counting
how many times these trigrams and by
grams are occur in the training data so
this number and gram is the number of
occurrences on the training data so of
course this guess problems some of these
numbers may be 0 there are standard
techniques that solve this called
smoothing discounting interpolation we
we apply them they are standard in the
natural language processing literature
so we just use them there are other
types of language models we also try to
train a recurrent neural network
language model this is a recently
popular language model because it has
the ability to understand very well
natural languages so recurrent neural
network can learn dependencies beyond
the prior several words it works like an
automaton a probabilistic automaton so
we have an internal state that changes
by depending on the previous internal
state and the underworld hi that comes
and this from this state we predict the
probability of worth I plus 1 so these
are vectors so each component is
probability
essentially and we iterate over the
sentence with such an automaton and then
in the end we get probabilities of the
next word given all previous words and
so such a language model can capture
more more sophisticated relationships
that are furthering in distance and also
in probably meaning so we can capture
for example that quick and jump they're
somehow related in probability of jump
given a quick brown fox maybe if the Fox
was quick it jumped right so so far I've
shown you how do we get from programs to
a language model so we have this
training training phase and so now we
should be able to perform queries on
this language model so next I'm going to
show you how do we yeah it could lead to
potentially infinite length sentences so
we unroll the loops to some fixed bound
yes it's actually probably not matter
for the model because we will actually
capture the fact that something may
execute in a loop already on the second
iteration
could you learn to introduce it was
terrible but we do not introduce oh yeah
it's possible that due to over
approximation there will be sentences
that could not be executed but I don't
think this was a problem with the system
introduced language yeah the Wow is not
but it could be that there is a while
loop or for a loop but there is a
condition so that it actually executes
only once and then we will probably
generate ten times that execute C twice
so the question marks in this system are
api implications yes but we actually
experimented with other question marks
with slightly modified models and they
seem to work as well
before using this API you have to check
that our first parameter should be not
now right you'll not be able to identify
those kind of patterns yeah some pattern
for not capture it seems like
introducing a new object that's not even
in a program because everything is based
on the method calls on an object yes so
you can't introduce a new object that
was never introduced before yeah we can
introduce only constant objects what
this is simple once once we get the API
we just don't we have some missing
metals who try to fill them with
constants okay so missing parameters so
to show how how a query works I give a
small example that uses SMS messages in
SMS message SMS API in Android so this
example takes an SMS manager ant a
message it looks in the length of the
message if the length is above certain
threshold it divides the message and
then call some green API that's how one
I constrain this hole to use two object
SMS manager and list for this example
otherwise it goes into another hole the
red hole that is completion that should
have one method invocation again
constrained to two objects SMS manager
and message and so we perform the same
type of analysis on a query like on a
query program like this we look into the
abstract object so we find the SMS
Manager so for the SMS manager and then
we look into the possible sequences that
we can get while we also include the
holes s words so how long is the green
hole we we have a sequence that says get
get default result so this result says
that this object comes as a result of a
method invocation called get default
then we call the white message then we
go into the green hole alternatively we
call we get pessimist manager and then
we go into the red hole
similarly for for the other abstract
object that comes as a list of messages
we get it by divide message and then we
pass it into hole one
and the message object we call length on
it and possibly Co divide message once
we call divide message this this object
does not enter in any hole but if we
don't go divide message this object you
enter into the wreck hole so we have a
sentence that says length h2 so we want
to complete the house so we discard all
the sentences that do not have how
mention to them and for the sentences
that include close we want to complete
them so how do we complete them we ask
the language model to find the most
likely completions so we do this by
looking into by grams and trigrams that
are anyway in the language model in an
Engram language model and then we we try
all such possible by grams and telegrams
and then we get possible completions
along with probabilities of sentences so
the whole may not be only in the end of
the sentence it may be in any place one
sentence making multiple holes but we
can get all the completions for the same
classes and so now what we want to do is
we want to give cookie for Rizzo that's
the most likely result one simple way to
think is okay we just take the most
likely sentence for each of the
completions and then we'll try to build
a result from it so these are the most
likely sentences so these are some
example of rebuilding the first so it it
completed whole one with said multi-part
text message here here said multi-part
text message param three for the read
whole this sentence completed it with
same text message and this sentence
completed with length so we can probably
notice that this is not a feasible
solution these two sentences disagree on
what should direct ho be completed with
one of them said send text message the
other one says Lee so in addition to
these probabilities we have to watch
straight constraints that you say the
words that we complete with should agree
between the sentences so in this example
if for example want to look into the
average probability by taking this
sentence for the for the this completion
for the last sentence with house we
would get to a completion that
agrees with the constraints and here's
the first probability so we find VSN
text message yes they will look like
hosts with different colors in imagine
their hosts with different colors and
then for each of the colors you expect
that the completions agree have multiple
statements yeah so if we if you if you
run into this then you will unroll it
into a sentence with multiple holes
right and this course you will cover
them differently like you call coke one
hole one the other hole and then you
must have constraints that say on hole
one I use I must agree with hole one of
the other sentence or two as well this
in this result would sort of a
combinatorial optimization property you
just have to decide on different
combinations of things it could blow up
on you with all yes they could blow up
but so in this case we actually made the
make the solver that just iterates over
the probabilities just taking first the
most likely the most likely sentence
completion for each sentence with holes
if he does not satisfy the constraints
we just iterate approximates it's not an
approximation yes so this one is not
greedy it's a it's just maybe slow it
may it may explode because if there are
too many constraints we will just
iterate over all all assignments of
sentences for each foolish sentence with
holes yes why not model it like
constraint solving program a problem
also a cost method which is from it's
complete solution you want the one with
so the reason is the textual instances
of this problem do not explode with this
if you have
even if we have 1020 sentences they were
probably most likely not be so many
constraints so we will relatively
quickly get to a solution that is not it
is not infeasible we quickly get a
feasible solution but yes this is this
is a combinatorial possibly
combinatorial explosion do you divide
into the user so the user culture or
well so we have to we have to provide we
have to be feasible to the user there
may be more than one so we can we
actually give more than one solution to
the user but all of them are feasible
all of them satisfy the cancer so we
iterate over over the assignment of
completed sentences in order
probabilities and then we give the top
solutions to the user so for this
example this will be the completed
program I'll meet at some parameters
that they did not involve the objects
talked about they're filled in with
constant typically and so this is how
this is how the combined competition
looks like it should be invocation on
SMS oh yeah
so because sent multi-part text message
here it has a word without this prefix
and here it has with previous assumed
like IIIi wrote so this word then notes
it's a call on this object there should
be also constrained that two sentences
should not should not both say that it's
a call on the object one should be a
parameter at the other should be because
there are few objects that could be a
result okay to fall just and is a images
this is how it and calls the types
without actually having types
we get the combined completion so
overall this is this is the system so it
takes an incomplete program performs
program analysis get sentences with
holes completes the sentence and
combines them with a combinatorial
problem like like I've shown you before
and then gets a completed program as a
result maybe I call for different
objects separately right so what do you
combine them together into a sentence so
in the same time there are multiple how
people objects is it gonna be a homicide
model or is probably won't be affected
so in a sentence yeah so in the sentence
you have you know a sequel not API call
for one particular object particular
time right it's for one particular
abstract object yes and so for this
object we do have you know like even by
the seven seas could you have like two
objects she and me have different two
different sentences right yes I wonder
if you combine the two sequences
together into one sentence video what
would be the effect if we did not do
this abstraction no because you actually
lose the type information you actually
lose the Alice Alice Inc information but
do you capture the interaction between
different objects
well we capture it because our sentences
are pure abstract object if our
sentences were just the whole program
you would not know on which object of
the thinker's code and then you would
have to do some some other constraints
therefore she call and then me walk and
she do something in them something like
that I think I think what you're
suggesting is quite much more
complicated you have many more
constraints because you have to say on
the whole the whole is annotated but the
word the words that you are going to
suggest you do not know in these words
which objects to pass on and III I mean
looking probably we examples yeah
so hopefully in this case you have two
different sentences for me and she yeah
I imagine so you make one sentence that
says nu X nu why sleep eat enter talk
yeah and then for each step and I
navigate that and with the class yes but
so the language model cannot take a word
with some annotations that do not that
that are not shared between the between
the projects because you want that what
you get is a sentence that that you
abstract away the part that is specific
for the project like the actual
variables in the project
so what you're saying that you know
maybe the training later it's not enough
for in foreign background I think I
don't think what you say we've actually
include words because you have words
with someone notation on the word that
says that I pass the object G so you
probably include the name of the object
here what you include something like she
in it and so yeah you can include the
time right in it and then you know
actually yeah I'm sorry wisely and then
you know why then you have to include
constraints that say okay my pet might
make my proposed completion of the whole
it gives me this this API should be
caught with these types now you should
include constraints are there objects
that that that contain these api's yes
so my personally feasible and it's
probably physical but it's much more
complicated and I don't know if it will
be more precise I don't think and so in
your example all your holes and then at
the end of the sentence no oh yeah this
I guess you can also use information
that yes we actually use examples in our
training in our experimental so we I
showed you so far what the system
roughly does so our implementation is
made with Java with suit and with SLI
Alain and then we trained such a system
on 1 million Java methods which resulted
in around 700 megabytes of sentences
once we performed the program analysis
indexed into a language model it gets to
100 megabytes language model which for
today's standards is not huge we
evaluated this on 84 testing samples so
we actually make it to make up these
testing samples because they didn't
exist but we make them up from Stack
Overflow and we took questions instead
cover flow and then introduced holes
into this question into into the
solution for the other question in Stack
Overflow or
or we took projects that are not part of
our training data and then we randomly
introduced holes into the code of this
project we took a method from
from from some project and then we
randomly introduce calls so in about
half of the cases we introduced more
than one hall just to to see what will
happen with more complicated cases and
so we run this system and then we wanted
to see if we get the completion that was
originally in a court in the sake of our
if no answer or in the Foucault then we
figure out it for around 90 percent of
the cases the correct completion is seen
in the top three results so we also did
bigger experiments and they also confirm
around this number ninety percent we
also did cross validation and the number
is even higher there because the code
may have duplicated projects so overall
overall high high precision yeah the top
one is around 70% okay for example if I
wrote my code with having the first
first statements in a another function
goal okay sure grab some part of the
sentence yes in a function that I wrote
yes so right now I'll run it is
interrupt procedural so we will not not
take into account but there are words
that we enter procedure and they would
they would capture if if you don't do
some strange indirection by a summon API
it would capture it yeah then you will
have a problem in your for example with
your alias right yeah you want to do it
it's it's not necessarily giving over
approximation so different - I'd say
that's an Engram model yes which one is
so so the best result comes with
combination of the two models although
the the the trigram language model does
almost as good so I would say it's about
the same whether we will do combination
or trigram by Gram language model on the
other hand does not work very well so we
need to capture longer regularities
because of center so the sense there are
different ways you can do code
completion rate so example really just
pensioner you know hey maybe we can not
do sentences per object everything it's
not so did you actually try different
things I'm learning one of them sets
here or was this the first thing that he
attempted and so we tried the few things
but they were more like variants of this
so we did not we did not try completely
different approaches
but I'm pretty sure that approach is
like like just just looking to the the
program as an ast or sequences as
Dawkins's we just not not do it because
there are long distance rate long
distance relationships that they would
just not capture with anger our language
more than how many call away because
they are representing me
the world in your vocabulary size in the
end yeah so I think the vocabulary is I
mean the it's huge but we actually drop
a lot of a lot of the vocabulary that is
that occurs only only a few times
because these are usually method names
that are only local for the projects so
in the end our vocabulary is around
80,000 words it could be it's more than
a million if we don't drop this
yeah so the the whole the whole system
is is quite fast it takes it takes less
than a second to complete like 0.1
second or less in fact most for for for
all the examples and it takes only a few
seconds to train the language model and
the analysis is also quite fast we do
stings gar style interprocedural a few
sensitive pointer analysis and it takes
around four or five minutes to index the
whole the whole database you think that
he has some sample too small compared to
that thousand yeah but
so it's this example talk about Android
API so it's it's essentially what people
use in hundred I I don't think we can we
can quite make that many more mean we we
can make we can make other example but I
already know that in this in this random
examples that that we actually built
from Android programs it there were
already some duplications
the other dishes were to remove code and
make the queries and how much was the
annotation burden on the queries
themselves like do you have to say I'm
going to use this this precise objects
or which object and I do not say
anything else
and how do you choose which sections are
the cultural it's a random except we
don't remove the word appearance option
okay and how long did it take manually
read yeah and how long did it take on
average I don't know to prepare the data
took on okay but in order to to run it
it was just instant life few seconds I
mean it was more time to actually load
the model than to perform that some of
them are not others are quite complex
okay random you can expect that so just
just to show you some interesting points
so I show you six systems that we
trained so on different amounts of
training data so we take a date or an
order of magnitude less data or two
orders of magnitude less data and then
we also try to to intentionally remove
some part of the program analysis to see
what will be the effect of not analyzing
the programs with with with an alias
analysis in this example in this case
and what here are here are the
observations so this is his precision
for whether the correct completion was
in the top three results so the skier
with a VC zero point this is only twenty
percent accuracy this is hundred percent
accuracy so more data is means better
precision like it's clear to see
in fact theta is quite important but
there is there is another observation
that doing the proper program analysis
is also as important as the data right
it costs as much as an order of
magnitude more day so what happens is
that if we don't do arias analysis
the code we would get on the training
data what we will get is much shorter
sentences so they will not contain foo
interactions of an object and so as a
result we will learn much less from the
data and yeah it can be seen as a
precision so I would like to step back
and tell you a bit more about the big
picture
yep you guys have a really nice treasure
trove of data now have you thought about
not looking at holes to help the
programmer but maybe to look at
interactions of API design so for
instance if I start with an an it and I
know I want to do something like I open
an object and then I do something that's
end yeah but it's and there's a very
common if not always occurring sequence
of sentences from an it too close yeah
you can you can put a hole there that is
like success multiple possibly multiple
API no no you don't say 180 or you can
say the hole and and there may be
multiple if yes and then we'll try it
with one hole with two holes and so on
you give it a height my point is though
that not the use case is not to help a
program of a positive it's with an API
designer to design the rate yachts so if
I put out of me oh yeah yes so what one
way to use a small subset the match
Nvidia so what what is cool yes is that
actually this language model captures
the the it's it's not only that it's it
actually captures the meaning I mean the
it it minds the the internal type state
that the API designer wanted right the
API even though it doesn't know the
implementation so it's a big picture
what happens here so we want to what we
do is we actually train a generative
model on code we are actually learning
what is the probability of program we do
it under abstraction that uses these
sentences on the code completion but our
goal was to learn the probability of a
program so we did it by perfect foreign
program analysis and then language model
our query
a conditional query so we have a query
program and then we want to find the
complete that program such that the
probability of completed program given
the query program is maximized and so we
do this by our completion procedure so
given program we close we get to the
full program so it's very likely that if
anybody would do anything with
statistics on programs they would do try
to make a generative model some programs
and try to perform their queries after
they that are usually such conditional
queries given a program find something
so now the question is of course what
was important for code completion so why
I tell you we did it like this we keep
some we have some understanding of the
other approaches that will not work
we do not experiment everything but we
know approaches that will not work and
so what was what was actually important
is the question so the first important
thing is the right semantics abstraction
so before this word there were there
were attempts to just look at the
program as sequence of tokens so do you
predict me the next token and so most
likely they will predict opening and
closing brackets and stuff like this but
they cannot capture stuff like AP is
another important observation is that
the model generalizes to unseen programs
that's why language models are useful so
there were there are other approaches
that just looked into into code and try
to mind some automaton from the from the
function that they see or or maybe maybe
even build sentences but do not put them
into into a language model just remember
the sentences and then when I query I
will look well did I actually did I ever
get such such sentence that you let will
like like I said no so there are there
are systems that do code search and what
they do is they actually try just to
find the nearest neighbor of my function
so can you refer specifically invite
unseen program because you need your
keys you still rely on my grandmother
tiger so the bigram yeah now if the
bigram is seen but the actual query
program is not yes aunt it's important
that vision is racially compared to to a
system that it code search just will
find all all occurrences of some query
they could ask a query like 5 million
cases where I call this API and don't
call another API aunt we we found that
their system was much slower and also
did not work in about twice more cases
than our system of course we tracked it
only for small small models because we
couldn't yeah it's a problem yeah but
it's true we just we just benefit from
the fact that nature and that language
models are made to generalize and of
course it's important that everything is
fast and precise so it should be
interactive for people to query this
thing and it should be relatively fast
to build a model so big back to what we
do at ETH so I told you what we do with
statistical code completion can read
about it we also do other projects I
would like to give you a very sneak peek
of what J is nice does it's currently
under submission
I cannot say too much about it but there
is there are there are interesting thing
you can try the system its life
so what J is nice does is slightly
different type of learning it does
discriminative model for called so
recall a generative model gets some
program some big code perform some
analysis beautiful model and in the end
it models the probability of a program
and then there is a art math query that
is conditional find me the best result
given some
so this is something that people in
machine learning have done a lot and
such kind of systems I trained a
generative model then I asked such
condition or queries but I mean many
many we will ask well if I were asked
this query why do I train this model it
can be quite expensive actually tutoring
this model maybe maybe not every
application will be as lucky to get to
just two sentences like language models
and so then there is discriminative
model so in this application is nice we
we predict program properties given a
program so we train a model that that
learns what is the probability of
certain properties given a program and
then we can ask query that is very close
to what we learned and so as a result we
can learn much more complicated model
than a language model so for this of
course we need that the properties that
we want to predict are annotated in the
input so if you want to predict it names
we actually want code that has good
variable names to train on if you want
to predict types we want code that has
types in the annotated in the training
data and so we implemented this in a
system code is nice you can just go and
run it it's got yes nice torque so I can
show you so this is if you go to the
website Jace nice the torque you get
something like this so you can you can
write a JavaScript program so I guess I
guess you can you cannot easily guess
what this function does even if I
increase the font so it's got chunk data
takes parameters a and T and R I T
something push substring
well if I say 95 JavaScript to the
system what would you give me is called
with names and types so I have I have
the types of the parameters of the
function so it now tells me the first
thing is string and the other is a
number and the name of the variable is
STR and step but now I can probably more
easily understand the displeases things
in two in two equally sized steps on
three dimensional returns an array so
this system is trained on around ten
thousand projects in github for for all
of them I mean we actually actually
removed all the code they did not have
good variable names look stuff that was
minified already
for example unto a bunch of projects I
think around maybe I maybe I forgot the
numbers I think around 20,000 JavaScript
files had types written by the developer
so we learned types from them as a
result we can we can predict these types
so these types here are almost
impossible for a current type system to
predict for a current type inference
system to predict because all the other
type inference works by implication
forward if I know the type of it maybe I
can type check that something is right
after that or infer the types after I
cannot know the type of this variable so
I I probably still it's a string because
of the way I use it I call substring on
it I know this is step nope maybe
because I increment some counter by it
or are useless so with this I'm ready to
take more questions and so thanks for
listening
yep so too I like this whole area of a
lot so it seems like the two limitations
I most notice here was you have to put
those question marks in I mean a lot of
times people might not know where the
codes missing they just yeah we would it
be easy to build a model we could infer
where the blacks should go as long as I
guess you're increasing the probability
of the program and the other is your
modeling method calls but not program
statements how would we extend this to
actually be able to introduce and model
the actual ifs and whiles and and you
know weave statements yeah so we have
works in progress for for these so it's
true that once we built a generative
model of programs we should be able to
answer other queries not just once that
the holes are in fixed locations that's
true and for the other for the other
question so the solution is to make to
make slightly different abstractions
that would take data flow and control
flow into account so there are such
analysis that comparators do for example
the data flow analysis that you tell me
that some variable must flow by calling
into some methods and then the result
will come somewhere and if you also
capture cases where we want to
synthesize expressions that are adding
variables subtracting they're not just
API calls well do not during the
internship
yes so it's interesting that your your
notion here of types I mean it's
interesting to think about but what do
you amount what amounts to going on here
is a type checker which is probabilistic
if I understand what you say yeah so we
can actually encode strict constraints
that you say well do not make
contradicting types but it's two
probabilistic yeah we'll table this is
string but maybe there is an if there is
another class it has the same API it's
probably also correct right but we
cannot know about it but it's just an
interesting way to think about I mean
you have people go out of their way to
build inference algorithms which are
which are precise by that I mean they're
they're told always correct yes
therefore your inference ear is by
definition not completely yeah but I
definitely had a problem that normally
people expect to be completely and so I
think that's really cool yeah it's good
I mean you know what if I see type
checker becomes like I know generics are
really hard to talk check yeah what if
you provided a type checker which rather
than giving me all of these things that
are actually safe programs but the type
checker tells me no that's not safe
what if you took a statistical approach
where you said the likelihood that this
is actually correct or if it's high this
is this is a before the program problem
I think so we seem to I mean likelihood
to be correct must be trained on
something else not not a model of
properties given programs you just
trying to your discriminable here is
just the probability of x given a
particular yes I can give you examples
where I say that the type checker got
this wrong yeah
so this so you're basically giving me
the cases where type checker is wrong
which yeah make sense I mean I hate yo
generics we do not handle generic so we
have a small type lot is that we run
just to see what happens but the one
that issues for JavaScript I mean common
JavaScript types like the dome arrays
array although maybe you can say array
of strings control begets array of
strings and so on
I mean you'll guess like Dom element
also yes
so you said that you focus mainly on
their Android API yeah well the code
completion is yeah so to my
understanding it's really common to how
reflection goes in Android libraries did
that introduce problems for your answer
reflection oh well we will just see this
invocation on cookies invoke my socks I
don't think if you and in what sense
would it would it be bad I don't I don't
see I don't see the problem we're not
going to we do not want to be sound or
precise or something yeah yeah but for
example maybe they the common paradigm
in in your training that is to have some
my object and then get the class and
then it evokes our method to me
similarly generic so I don't know how
you would produce the correct sentences
in order to train your data afterwards I
don't know maybe it's not a problem well
if if one specific API is always called
for reflection we're probably not going
to learn on this
okay yes how is he easy to realize that
the condition is actually wrong because
I mean whatever you're you're doing this
sort of copy-paste coding you try to
have discrete the description and the
psycho profiler and say well you're
initializing the structure or whatever
because if yeah I believe that it is
probably right but you get just a chunk
of code and like it has no annotation no
comment no whatever how we see is it to
just realize it's wrong or right so what
so it's probably not very easy to
realize if it's wrong or correct but so
what we have seen in some cases where we
do completions is that it gives correct
completion but maybe for another problem
not the problem that you wanted to solve
comments and actually produce a language
model the code with the comments and
then actually add the comments as well
as the code yeah actually we're thinking
about is basically how expensive is it
in adding properties to the to the stuff
that you're inferring because I mean if
you wanted to extend it somehow he said
be abusing constraint programmers like
that would be really interesting but you
sort of lose most of information when
you check it as sentences right yes so
so the the go there is because we would
render generative model and it's usually
hard to change any model it has to be it
has to be that it's trained on some
simple structure like sentence if you
can convert what you what you want to
sentences like we successfully converted
some some cases into sentences then then
everything will be fine
if if you cannot convert your query into
sentences or or the property of interest
into sentences but you have some other
more complicated structure like a data
flow graph or I don't know what if it's
a full graph that you just cannot enroll
in some way which we can unroll so it's
not a problem for this but then you have
more problem to add more information
that's</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>