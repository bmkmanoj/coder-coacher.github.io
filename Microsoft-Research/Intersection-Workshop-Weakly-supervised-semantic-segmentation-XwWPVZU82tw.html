<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intersection Workshop - Weakly supervised semantic segmentation | Coder Coacher - Coaching Coders</title><meta content="Intersection Workshop - Weakly supervised semantic segmentation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intersection Workshop - Weakly supervised semantic segmentation</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/XwWPVZU82tw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
well welcome to this talk this is a
joint work with the machine learning
group at ETH Zurich with a student we
share with your human is name is Sasha
fashion events so this talk is about
semantic segmentation and the task are
laid out in recent year mainly but by
the seminal work on text and booze by
Jimmy chaton is the following you have
an image and you want to label every
single pixel with the semantic label out
of a closed set that's given to you so
here it will be sky three building car
and so on so this is a task of
simultaneous recognition and
segmentation of the objects done
countless applications which are not
going to recap so the biggest account is
that it's a great appearance variation
between different instances of a class
so you can see all the different type of
grass or trees that you can get two
different types of cars that you can get
and a car observation that will drive
the motivation for this work is that no
single visual cue can distinguish
between classes maybe we color you can
tell apart water from grass but with
color along grass and trees don't come
out so well you would need texture and
for some other classes such as buildings
it's much more about the spatial layout
of local corner light features that
would give you the meaning and you will
have to be successful to put together a
lot of different visual features a brief
review for those not familiar with this
field and they fill the existence a long
time let's say a lot of interest started
to gather basically in 2006 with with
text on booze and a number of work
follow that format the basic format of
honor the basic model that which you try
to tackle this problem is a pairwise CRF
where every pixel in the image becomes a
node you have unary potentials that are
basically multi-class appearance
classifiers that take some patch around
the pixel and try to predict one of the
semantic classes then you have some
perverse potential that tries to enforce
level smoothness within the image so
these are oversimplification but that
fair representation of the basic model
at the beginning with with textin
booster we're only a few features and
only a pairwise model but later works
that today achieve the state of the art
such as those in filtered group they
move to have a lot more features and
more complicated structure such as I
other potentials which allow you to
capture statistical dependencies which
you cannot model with just Perez
potentials then there is another kind of
family of works which is kind of emerged
only the last few years nonparametric
methods very much in there i would say
totaled mine a first step of school of
thought the famous award-winning work
and 2009 was trying to align training
images with global descriptors and sift
flow to the query image and then using
this a scene flow map to transfer the
labels directly and that was an
interesting alternative approach but it
tends to need a lot more training images
to work and that's why people moved to
more complicated data sets recently
which we will see makes a big difference
and possibly the state of the art today
love lab next super parsing who takes
the idea of nonparametric to the limit
basically describing super pixels in the
training images comparing the descrip
this way pixel descriptor to the test
and if it matches you can transfer the
label directly of course you need some
refinement with a CRF afterwards but
because spirit is there iolite once
again step of the artwork Tom for
figures this is a table I took from our
paper and on the beginning I was
laughing thinking man it's getting
really complicated but then she put the
source code online and I was emailing
her thanking her I don't have to redo
all this we have talked about three
thousand different features here
semantic cementation in most words that
appear so far is tackled in the fully
supervised scenario which means for
training you are given fully labeled
pixel maps where every day every pixel
is labeled with its class and instead in
this work we want to tackle it in a
weekly supervised setting which means
instead of a pixel label per pixel you
only have set of all the labels that
will appear in the image but you have no
idea where
so I argue this is an interesting
scenario because reducing the level of
supervision will allow you at least in
theory to scale to a very large number
of line images and many more classes the
fact is that if you start to do it
weekly supervised the problem becomes
much harder as we will see but in
particular as we will see it becomes
difficult to integrate multiple visual
cues because it is difficult to learn
the weights between the cues without a
reference ground truth and in fact
that's the main contribution of this
work will see how to do weekly
supervised structured learning and here
is some buildup of the model because
it's a complicated model I thought it's
a lot more fun to build it together
progressive is like the slide instead of
dumping all the bubbles and arrows what
is the simplest thing you could do for
weekly supervised Samantha segmentation
the task is you are given this bunch of
training images with labels but no pixel
availables you want to recover a period
smothers which are able to classify or
please predict probabilistically a label
for every as per pixel in the image and
the image a super pixel labeling an
image I and spur pixel J so the simplest
thing you could do is to define observed
nodes which contained a super pixel
features the gray here are the super
pixels we use which come from the famous
work of vs up in 2004 then you would
have also observed nodes y which contain
the remains level labels you are given
by the supervision then you would have
latent labels that latent variables that
are the most interesting part of the
model which you want to recover which
are the super pixel labels which you
cannot observe then you start plugging
in classic unary potentials that connect
the latent super pixels able to observe
super pixel features at the beginning so
this you canary potentials are the
output of super pics a classifier theta
which you do not have at the beginning
that's part of the learning you gotta
get it but if you had it ideally would
look like this for three then you have
would have another unary potential which
is the generate one which is basically
giving an okay if as per pixel level
takes the label from the image and
infinite
asked if it doesn't so this includes the
image constraints the image level
constraints so this is the simplest
thing you could do freely the list
modeling there is no spatial relations
it's just a big bag of segments but if
you do that you could imagine solving
this solving for y and theta by a
modification of gaming's basically where
the mean operation will be trained
appearance models and the assignment
operation will be assigned super pixels
to the closest apenas smaller so you
could run that hope that it gets to some
good local minima and it would do
something but not very well in fact
you're not modeling all the dependencies
in the data especially special one and
more importantly from our viewpoint this
energy function will be completely
unravel arised so any labeling that
fulfills the image label constraints
will be equally valid there is no
reasoning that we tell you this labeling
would be preferable over the other and
that's that we see will over fit a lot
so one thing you can start doing then
like every every fully supervised model
as this is 2006 at least is to have
pairwise potentials within one image so
for example here the super pixel would
be connected to release adjacent and the
variant potential would say now you are
fine zero energy if two adjacent super
pixel stay the same label or pay a
penalty proportional to the difference
in appearance between the tube super
pixels so that's a classic and basically
gradient weighted pairwise and you can
see this encourage label smoothness
within an image and can see a
sterilization term over the space of
labels so again this was in full advise
netizens forever but not in whisper
violence so here is a new term is a fun
new term why stopping a Paris potential
within a single image the concept can be
extended between multiple images you can
now say let's put the same the same
function the same function Phi this time
connecting to super pixels between
different images you can say to the per
pixel between different images that
share a label if they share a label and
they are similar whisper pixels then
they are more likely to have the same
label so in fact this is the same form
as this potential but now there are many
more of them and they connect four
pixels between images
so this will introduce okay powerpoint
was thinking about the concept good is
getting it so of course this is easy to
say and i think we all agree would be a
good thing to do it would introduce even
more regularization in the label space
it would transfer information between
images certainly a good idea but isn't
it too expensive ito there are a lot of
pairwise connections so in fact we can
take advantage of the fact that this
equation goes to zero no matter which
labels if to super pixels have a big
appearance dissimilarity if they're very
dissimilar no matter which labeling
they're going to say I are fine do
whatever you want energy zero and feel
you can exploit that to make to build a
tunnel filled in a data-driven manner
you can say let's now look on the
effects of images a share a label anyway
that's not the only thing we do and then
if I so if two super pixels have a large
dissimilarity we do not put the edge in
the graph so that leads naturally to a
to a data-driven sparseness which in
fact it's a it's it's a small
approximation to the total field so for
those of you that are more theoretical
Amanda you can start thinking why do
they spin residential between image
makes sense in fact you can think that
in opinion space the super Pyxis of one
class between images are shareable the
forms of manifold of connection which
you can represent with this nearest
neighbor graph in fact what we are doing
is introducing a potential which
penalizes labeling that cut through the
manifold and break it which at this
point if you see this way you see make
sense and you see that it becomes sorry
Bella riser for the labeling so now we
go to the multi much model this is
basically what we add that I ccv 2011
then we will see that the Delta we made
again we want to recover the appearance
mother's pitta and the super pixels
level why jointly gets pretty mad it
makes this a great program for most
appearance models but fortunately you
can do a tentative minimization to get
in a reasonable local Optima you can fix
the labeling for example you start with
a random leveling that's what we do
random respecting image constraints
obviously image livings then from there
if you fix the labeling learning the
appearance modest is a supervised
learning problem and foremost apenas
modest you can do it very easily like
say Sarandon forest say Selena
easy then once you fix the penis models
you can infer the latent super fixer
labels with alpha expansion this is a
multi-level problem we're all Paris
potentials assume modular so you can do
something reasonable if you know if you
set down this model so what is missing
in this model well I started and talk
motivating multiple features where are
they right where are they they they are
going to come they are coming here in
the winter what is missing is that if we
want multiple appearance and modest on
the pairwise potentials and in our model
that's the most important because that's
what carries this regularization effect
we will need weights to trade off the
relative importance and as soon as we
have many many of them say 10 it's very
difficult to set them by hand so you
start to need to have an alpha vector
that weights the report importance
between the unity and the pairwise and
weights the different Sparrow Isis
together so each Perez potential
introduce another set of edges and
carries another dissimilarity measure
color safety excellence gift weathermen
so now if i give you alpha you know what
to do to get to a good approximation you
do the alternating optimization I
described before but how do we pick
alpha that's the core concept of this
talk it's very hard to pick alpha in a
traditional manner if you try to
minimize this energy / y alpha and theta
with some monster magic godlike
optimizer that manages to do it even
then it will just set alpha 0 equal one
as which off all the various potentials
to the classical effect if you ask a
function herself how much do you want to
be regularized it would say please don't
regularize me same effect you get in as
VMs if you ask the training data what
should be c without a proper validation
set c 20 well infinity that's the first
barrier the second battery will tell me
well men just to standard
cross-validation like things or do
structure dot to learning with the euro
and with like structure these games
methods the problem is I cannot even
define a loss on this problem I don't
have any ground through training data
the pixel level so I cannot do the
traditional
lerner cannot even define a loss between
how good the labeling s I don't know
what we deliver links it is just no no
clue so here we need something else
because we want to set those weights but
we cannot set them without the ground
truth in a traditional manner so how to
set weight without the ground truth
first of all you need a cost function
that will prefer a waiting over an order
then we also optimized it what is a
better waiting once you have no ground
truth well we argued there is a way to
at least determine what is a better
waiting over are arbitrary waiting and
this is the following concept which we
call expected agreement we start by a
value so this is better than it is a
function that evaluates awaiting alpha
and we start by splitting the training
set into two subsets nothing class
across validation then we can run so
because I has given because we are
trying to evaluate it you can run the
weekly supervised learning method that
will give you a labeling and the theta a
set of parameters on this subset now you
can take the second training set and
apply a parameter she learned pretend
that is second training set is a test
set you discard the image of a label
throw them away pretend it's a test set
run your parameters that you get a
labeling so far so good now you do the
same thing in the other direction you
take the second training set you do
weekly supervised learning get a living
llegan a theta and apply to the first
training set and i dispense their inside
for a moment you pretended s that you
run it so now you get to labelings for
each of the two training sets now you
can ask today ugly are these two
labelings in agreement so if they are in
agreement we argued this is a better set
of alpha so an alpha is good if it leads
to pixel level exam parameters that
agree on a second part of the training
set so why isn't a good idea because
it's basically is it's basically tries
to check if the parameters generalize in
the generalized sense without the
grantor so do they agree on the other
side and the number of experiments to
show that in fact I suspect remained
greement grows they drop the quality of
the pixel level labelings goes up so the
problem with this I mean this may be a
meaningful criterion we hope
and it doesn't need ground truth the
problem with it is a very big
arbitrarily shaped criterion so it
doesn't have a very nice form that you
could derive for example to do gradient
descent it in fact us know on a little
credit and it's typically a 7 to 10
dimensional the space in which alpha
lives depending on your number of
features you want to use and it's
definitely the criterion is not convex
at all more important than maybe the fun
part of the work evaluating one alpha is
very expensive in the order of minutes
if I ask you one alpha you want to go
through the trouble of running the haul
weekly supervised learning on the
training set twice and each of them
involves multiple retraining of the
periods models and multiple other
expansions on the whole time is set so
you want to evaluate alpha rarely if
possible so what do we do to get out of
this do we give up on having weekly
supervisor and weights no no we really
want them we really wanted to to get
them absolutely so we stumbled over a
reasonably new optimization techniques
popular in more in a machine learning
literature which is so-called black box
optimization with gaussian processes so
gross and processes are well known for
regression and at least the less
well-known for classification but still
and you can exploit the properties
there's moves in properties of gaussian
process regression to derive global
optimizer this is not our idea this we
picked from Srinivasan SML 2010 and
before him since basically 2007 people
are playing with these things and how
does it work so the crucial point is
that it only needs to evaluate the
function it doesn't need derivatives or
other things so what do you do you start
by creating the function a of alpha at a
small number of points in our case to
less than that it didn't sound
believable and you fit a bush and
preston regresar let's say it looks like
this the crosses are the evaluated
points and the continuous line is the
mean of the Gaussian process but more
importantly the gray shaded area is say
is basically two standard deviations of
the goshen that the Gaussian process
fits on the vertical on the outer space
so now instead of just looking for
looking near the point of the nearest
aisle of the highest peak you are so far
you can ask what is the next point
should evaluate very expensive you want
to evaluate few and so the idea of
Serena's and others is to ask for the
point that satisfies the maximum of this
equation which is take the mean of the
corrosion process plus as plus this
standard deviation x some scalar beta so
basically you are going to evaluate the
point which has holds the largest
promise you don't know how big the
function is there but in this point it
is the largest promised upper bound
possible value in which the function can
go and why it is good because it trades
off exploration with exploitation if you
have a few regions of this alpha space
that you did not evaluate a lot or you
did evaluate a lot but is heavily rugged
the curvature is big then it will start
to evaluate more there try to probe
there to see if the function can go very
high if you have a part that you
evaluated a lot but it tends to you know
to have shown a local Maxima the
question process will see it and will
not give it a high high covariance of
the output so you will not evaluate
there and in nicely can jump in and out
of local maxima with this very simple
rule you don't need to define any
complicated rule just go to the maximum
of this okay as we will see in the
experiments with this process we are
able to well the process converters
after about 100 alpha evaluations in
seven dimensions and will lead to
results which are equivalent to doing
exhaustive grid search with 10,000
points in seven dimensions so it's 100
times faster it's very useful so this
was the main contribution of the work
how to set the weights in which is
provide manna so we rush through the
other parts which are more standard once
you have trained your pita and obtain
your Y labelings how do you label a new
test image well you could just apply the
teeter parameters and label every super
pixels but this will mean we throw away
the big lessons from the nonparametric
methods and in fact we managed to fuse
the two in this model we can take a test
image and retrieve the most similar
globally similar training images by some
gift or so and now you can take a
histogram of the image level labels of
the training that are more similar and
use this as a prior and use this as a
soft version of the
level levels at the test image and that
just replaces the standard urinary
potential and drives the labeling to
respect this is to them then you can
plug your test image inside the mood
image model we had so this is basically
the training images they no longer
afterwards potential anymore and they
are all fully observed because after
training we fix spare pixel labels now
you can plug the test image in the
middle and connect the super pixels that
are similar between the training and the
test and carry the usual Paris potential
we described before so in this manner
you get a hybrid between a purely
data-driven method which is just copy
pasting labels and parameterize matter
which uses the tip appearance potentials
in one simple and unified model maybe
I'll just skip through this because it's
not so important we talked about
pairwise potentials that contain
multiple features but what about the
unary stay also need to contain multiple
features otherwise what are we doing and
the way we do that is by very rapidly
it's by extremely randomized dashing
forest but in the interest of time I
think I skip over this part I want to
insist that we have really a lot of
features in order to get it to work we
downloaded Alana's code and it's really
amazing what people are trying these
days not just features inside a super
pixel but even blow this with pixel up
by deletion and recompute features
because somehow this captures boundary
and that's Lana of sanara civitan paper
this brings a quite a difference to use
all these Stein and different features
and what isn't good in this work is that
we can use them in a weekly supervised
setting so here are some results we will
show results on the level mischief to a
subset which is first introduced by a
total ban students in 2009 and
award-winning paper this is not
interesting at an MSR see my opinion
because it's recent so it does 10 times
more detail basically we are now at 2500
training images to 200 test images and a
lot more classes a lot more classes is
important because as people see the
difficulty of the otha like Rob also
argued a difficulty of a dataset depends
also on
and let's say power-law distribution on
the on the on the presence of certain
classes so you have a lot of sky a lot
of grass but very few windows and mice
and little objects so that's very
interesting when you have many classes
you can check those phenomena like there
is even a moon class like not many
classes women's here are some
qualitative results at the end of our
full pipeline you can see the original
image it's ground truth the output of
our method and the output of super
person which according to assess the
best fully supervised matters these days
so these one inputs training pixel level
labels hours inputs only for training
image level labels and when it works
well they both work reasonably well but
there are cases in which we screw it up
pretty bad for example this culture in
front of the building it's labeled as a
tree which is beyond me given that it's
grey in general the full supervised
version is it's more accurate you can
see also hearing it we've got some
elements of the road but they are quite
comparable as if we see also numerically
if you look at it in numbers we can
measure average per class accuracy so
this means that for every single of the
33 classes you measure what is the
percentage of pixels you labeled
correctly this is different than total
pixel level accuracy which is a lot
easier which you can solve to a good
degree by predicting everything is sky
grass and road yes David
pixels it's a very good comment in fact
there are two there are many issues like
one ish is what you say we did a single
class some pixels are more valuable than
others but between classes even in some
images a cut is very important and in
the other image ricotta just rolling by
force an image of your cut you don't
want to miss the tail of the cut if it's
an image of a city with a cat strolling
you don't care so in fact our
measurements are what they are given the
ground truth and we are yet to define a
protocol which will satisfactorily
determine if it's useful for an
application however in terms of pure
scientific challenge if you want to know
did you label the Pyxis correctly at
least this is a measure that is some
indication if you actually rather stuffy
address the issue with all of the
semantic work that if you actually apply
plugin that measure the ordering of the
methods changes completely okay right so
and and one at least one should do both
measures in all the papers setting and
one I would argue that the boundary
measure makes much more sense because
we'll be okay so I believe that this was
a good suggestion but I believe is that
suggestion that's different from David's
David's was arguing about I believe at
least man standing that some soup
portion of that class and that image is
useful because it gives you an
application driven information to turn
left but as you argue the boundaries
more important because it leads to the
accuracy of your segmentation they are
both useful suggestion but I don't think
they are the same suggest
saying that something much more
important to get some pixels right there
others that some pixels are so
agonizingly obvious to sue but those are
the boundedness unusual what then you
may use for 16 why do you say that
because that's that's where you stop
being a road in the US are being a bitch
is that was not the right to the
geometric when the annoying thing is how
I said you'll give it very your battery
right right religion care about about
the Weatherhead that it might be really
flexible but when you miss that's more
brutal places the fact that you can turn
the layer is missing this is a tiny
budget
ok so in defense of these protocols at
least you know certainly having such a
level of labeling stay 10 forces
advantage of its defined objectively for
everybody the one of David depends on
what people believe to be useful for
what they want to do but if I can maybe
carry on a little bit then at least to
claim some progress in protic us at
least people recently started to look at
per class securus instead of whole image
at least now you can see which classes
you get which gases you don't get so
there is some progress but you know if
you guys want to pull out another
protocol we will all be happy to follow
it yes and and I would answer to my mom
and why don't you build a better fire or
switch off the fire so I don't have to
jump over it so I expect you guys to
come up with a great protocol and which
you cannot follow you know there is room
for progress but I still believe the
measures they are they gives you some
indication they also if you look at the
outputs in the end they do look like if
you see the matters that the phone words
they do label we are seventh by a human
judgment actual results you know for all
images then the results that look really
badly still operable well so actually I
mean we need the same things we have it
hard to get access initially then with
your tribe to score just write a
bathroom break but I also think this is
Shambala actually at nips at a trained
up scoring as well along with your work
so some people are moving to that
scoring maybe you know maybe general
version we had a time up version at
least in honor of Alyosha the option of
our application I totally agree that
this becomes a task of India great so in
for what it's worth with this measure
which is at least per class and not per
pixel everybody does bad because they're
of the art at 29 pretty low but big
problem is very difficult with the 33
classes and such small objects to
conclude yes I'm closing here now you
want to say 10 finger me ok so to
conclude basically the point is we are
now basically at the point where the
weekly supervised version which we
develop is that a point basically around
the state of the art of 2009 we are
running after Lana and their future
entry works we hope to keep a three-year
gap behind we would utilize this route
supervised and we also have results on a
message see which I believe are less
interesting but they are very analogous
it's interesting also that you can beat
some of the full supervised matters with
week supervision so I skip on the
valuation of components but believe me
you need to train out for properly
diverse it fades completely and there
were some failures and one word and
failures is a lot of methods fail but
when fully supervised fails they at
least have the decency of getting the
big surfaces right and then forget about
the windows and the doors when we fail
what really fail you know like all of a
sudden the whole image sky forget it so
when you face it face more dramatically
ok enough failures and conclusion what
you need to retain for this talk if you
are interested as weekly supervised
matrix imitation means you don't have
pixel level labels to be effective you
will need lots of visual cues and
structure models and the two together
means you need to learn these weights
you cannot do it in a standard
structural for learning from weekly
level data therefore we propose on your
approach with expected agreement so
thanks for your attention
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>