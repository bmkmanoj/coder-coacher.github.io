<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Lasserre-Based (1+epsilon)-Approximation for Makespan Scheduling with Precedence Constraints | Coder Coacher - Coaching Coders</title><meta content="A Lasserre-Based (1+epsilon)-Approximation for Makespan Scheduling with Precedence Constraints - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Lasserre-Based (1+epsilon)-Approximation for Makespan Scheduling with Precedence Constraints</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/z70HEtjYDaM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay yeah it's a pleasure to have Thomas
tell us about the scheduling problem
which is I guess one of the four or
three or four remaining open problems
from Gary Johnson so the problem is
really old and promised want to tell us
something new yeah thanks I think
technically speaking we're not going to
it like completely closed it anyway yeah
thanks for getting up so early no this
isn't the time for everybody in the room
okay yeah this is five of us in the room
you couldn't talk to us a little more
personally okay yeah we'll try to
address the audience more of a person
more personally thank you James for
asking the first question before I start
okay so this is joint work with with
Elaine Levy who is also at u-dub um okay
so this is this is the problem on a talk
about you you have some unit size jobs
so you have some jobs that have like
processing length 1 and the the jobs
have precedence constraints so you have
to process let's say this job before you
can start any any of the those jobs here
and I give you I give um machines that
are all identical and all the goal is
you want to you want to schedule the
jobs in a non primitive way so that the
makespan is minimized and the makespan
is the time that the last row finishes
so okay um okay so just a warm-up let me
just explain you um simple to
approximation algorithm that's are 50
years old and it works as follows you
just get to edit anything everything
greedily so let's say you just select
any job that you that you can select and
you just well put it on one of the
machines now there's another job that
you can just process and now you see
that well in principle you have a you
have a third machine here but you don't
have a job where all the other
processors are already are completed so
you leave that's not empty and you move
on with
next time and and with the next stop so
just do everything greedily the way you
would imagine it makes sense are so this
is the algorithm would would work and
okay so here you see that well there's
this chain this chain we didn't pay a
lot of attention to that so we we have
quite some some some idle times here and
now this is the time that the last job
finishes you can see that actually this
this is the this is the makespan here so
this is at the time that the last job is
finishing you can also see that this is
not the optimal solution there's this
chain of five jobs we probably should
have started this like a lot earlier and
just work work on the chain all the time
ah yeah but this so this is an
approximation algorithm in it definitely
does not always give you the optimal
solution um but the claim is this gives
you a two approximation so how can you
how can you see this so first of all if
you if you stare at the times where
there is some idle idle time where you
didn't use all of the machines then why
did you do that why did you not process
this job earlier well actually the
reason is that there has to be a job
that it depends on coming earlier and
that's actually the only reason why you
could schedule this earlier so to be
more precise there is a chain that goes
over over all of the the non busy times
and if you wanted to be formal you could
construct this chain from from the last
job you could wonder why did I not
scheduled this guy earlier well because
of this job why did I not to give you
this guy earlier because of this shop
why did I not do this guy earlier
because I'm teacher this job ends on
time now you can wonder if you have a
chain what's the length of the chain
well it change the length of any chain
is the lower bond or the optimum because
of the optimum kind of needs to process
them the chain somewhere um okay so
that's good so this gives us a bound on
the D on the non busy periods actually
bonding the busy periods is even is
yeah because you can imagine that even
even if the optimum will would be
allowed to ignore all the precedence
constraints even then just to process
all the jobs you need at least that
amount of time okay good so and now you
just add things up and you get that the
schedule we're getting has length at
most two times the outdoor actually the
algorithm isn't much better than a two
approximation you can be a little bit
more careful and depending on how large
the your number of machines is you can
be a little bit better than two but if
that number group goes to infinity then
the ratio goes to to like the
approximation ratio of this edge room um
okay so we would like to beat this
algorithm and it's kind of what's what's
like the standard technique and
approximation algorithms it's you write
on some media program so we could do
that and this might be the natural then
your program like experience would
probably call that the time index
version so let's say you have a variable
XJ Chi and this is this variable is
going to tell you whether you want to
run the job at time T and I hope you see
that you only need to consider integer
times they're just integer time slots so
what would be the constraints like every
job should be scheduled somewhere at any
time you can schedule at most M jobs ms
the number of machines you have and then
you should have some constraint that
that implements the the pre-sentence
constraints so you should have if some
job I you should be finished before Jay
then it's kind of the fraction that's
that's finished until some time T can't
be bigger than the fraction that's that
scheduled for that other job until time
T plus 1 okay and good so this is this a
this is a final in your program but can
you can you beat the gap of 2 no not
really
it's not hard to come up with some
integrality gap construction just
imagine in this case I give you two
machines ah but you could have some some
kind of blocks of three jobs let's say
this is like a long sequence of of jobs
and it's kind of the other other jobs in
the ice block depend on the I minus
first block and now the fractional
solution that you could construct would
be that you can you can kind of process
all the jobs in the same block in
parallel and so this would mean like
these three jobs in an integral solution
you would need to time units but the
fraction solution could essentially
schedule this in 1.5 s time units it's a
it's nice to observe that in the
fractional solution the the support of
jobs can overlap even if the jobs have
presents constraints so this is
something you can't rule out that makes
the whole thing difficult so the
integrity gap it's also essentially too
so if the number of machine grows then
then the the gap will tend to two so
this isn't really going to buy you that
much you could probably come up with
some rounding algorithm I I doubt that
you could beat the simple greedy
algorithm getting ah it's for this
problem it's extremely hard to not get a
factor of two in some sense if you so
yes you probably in exercise I've done
it myself is it the same as integral
scheduling but you allow me to start
jobs and fractional times I mean that's
what it is what is takes advantage of
right like one two and three started at
second two and then they go to second
2.5 and then you start four five six I'm
just saying then you you serve can at
least for this you can respect the
president's constraints but just have be
able to UM is this the same I don't
think so no
I don't think so I don't think it's okay
good um okay so we we did see that
little two approximation algorithm by
Graham and in fact it's it's unlikely
that you can beat the two in general so
there's a paper by Biola saying that
well I'm not some variant of the unique
games conjecture you're not going to Abe
you won't be able to beat the faculty
then you're not that's the question what
I'm going to talk about in the next two
and a half hours but ok so in scheduling
it does actually make a lot of sense to
to consider cases like what happens if
the number of machines is a constant so
think of MOS being a big constant maybe
then we can beat the factor of two and
are there hasn't been in much success
actually so this is this is what we want
to do ok and your movie he'd mention
already that this is essentially this is
one of the four open problems in Gary
and Johnson so now it's maybe three and
a half open problems now that graph
isomorphism is kind of solved if M is a
large consent so what's the question do
you put it is inevitable to grow with
the input length you can't be to work
how are you gonna fit a result in
between those two bullets that's what I
don't give you everything but the
running time will depend exponentially
on on em on the number of machines and
there was no such algorithm known before
that's better than two okay um ok good
turn it in fact if you have let's say
three machines it's unclear whether this
is an NPR problem there's a nice survey
of Sherman of working uh about open
problems and scheduling it's now 16
years old a couple of problems have been
solved one of the problems that has been
open is whether it's safe or three
machines there is a peters and
so constant hard and smoke a bowl it's
not like if you have 10 billion machines
it's it's it's also open whether this is
NPR yes and the result I want to talk
about here is that actually you you can
take the data in your program UK you can
throw it into your favorite LP or sdp
hierarchy and after some number of
rounds the gap goes down to 1 plus
epsilon that number of rods is a weird
number that's a little more than pulling
log and the epsilon 0 DM actually goes
here into the hole ok so this gives you
also in it an algorithm that that finds
a that finds the schedule in some kind
of weird little more than Kwazii
polynomial running time pretty big
that's what he did right ah rule of
thumb not there is there's an M it's
really an M here and I think times 1
over epsilon square i think is the
dependence here well the other is in the
exponent so yeah good okay good so this
is this is what I want to talk about
okay so yeah okay so let's what's what
the less your hierarchy the idea is it's
a very general idea you imagine you have
some some linear program let's say with
binary variables let's say the set of
feasible fraction solutions is K and now
you want to add in some more constraints
so that your your LP becomes better so
what you would ideally want to have is
that into that that connects all of the
integer points in k yeah you're not
going to get there but you can write
down some some bigger system and it's
going to be kind of stronger than your
original in a program that system will
depend on some parameter that's called
the number of rounds of the hierarchy
and as you increase the parameter the
the hierarchy gets stronger and stronger
and then eventually after
number of variables many iterations it's
going to converge to the the integral
holla okay so many of you might have
seen this already so the idea is that if
this isn't just a general general in
your program then you aunty is your
number of rounds then you would just
take variables for all subsets of at
most t many variables and you've write
down some kind of meter variable which
is supposed to tell you the like the
fret with the extent to which all of
those variables have to be one so you
have some extra variables this is why
it's called so-called lift and project
because like the eggs are variable they
give you a lift and in particular you
will have your original variables in
there and now you just need to write on
some constraint system that gives you
some kind of consistency and you can do
this explicitly um it's not I don't want
to go into details I at this point i
would like to treat the less a hierarchy
into black box we know what properties
it has but if you wanted to write down
explicitly the moment constraints then
you would take your variables you would
throw them into a big matrix that's
called the the moment matrix and then
you ask that this moment matrix has to
be positive semi-definite you also will
take all the constraints that you have
and you would put them together into
another big moment matrix and also that
has to be positive semi definite form
for any constraint it works with charlie
adams yes so what you were describing
the desert ah imagine one of the authors
has a survey on the Las a hierarchy and
wanted to copy paste the sexes I
actually I find the I find the
definition more elegant than 40 luck
charlie adams it's it doesn't matter so
we're using we wait yeah the less a
hierarchy has a lot more power than we
need okay if I hope that doesn't make
you a doesn't cost your headache okay
we're not using any kind of fancy like
polynomial whatever
how are you okay good James doesn't look
on Vince just for the record for the
people who can't see and you follow so I
want to be prepared for okay okay okay
imagine this is jelani items and you can
just imagine for yourself this dry arms
it's not going to be any different the
algorithm itself okay so if that is that
number of rounds t is a constant you can
solve those systems in polynomial time
and well for us it's not going to be
constant it's going to be that like
weird somewhat more than poly log term
so this is going to be yeah a little
more than Kwazii polynomial okay good
one more question so if if 2 minus
epsilon was NVR then your result says
that the running time of the reduction
okay you know like assuming that likes a
sad requires exponential time your thing
says the running time reduction has to
be at least something yes do you have an
area feels like ballpark what what that
is or it's just like some function of
epsilon at him yeah it should be
sometimes I'll never figure it out but
you could have you could have sub
argument in 10 yes ok so the dallas a
hierarchy enter surely adams hierarchy
they have some nice property which is as
follows if you if you look at a solution
which is valid 40 rounds then and you
look at one of the variables that's
strictly between 0 and 1 then it is true
that this is actually convex combination
of two solutions to listeria solutions
one where the variable is 0-1 whether
where the variable is one and both of
those are valid for one round less okay
um in particular a way to reinterpret
this is as follows that if you have a
less see a vector you have a variable
that's strictly between 0 &amp;amp; 1 then you
can say oh I want to have that this
variable is actually one so you can
what's called you can induce on that
variable being one which geometrically
means you're just replacing euless a
vector by one of those guys where the
variable is actually 1 and this is going
to cost you one round
okay and we will do this we will do with
this a frequently what are you you could
do this yeah we're doing this with with
one obviously the same thing would also
work if you wanted to set the variable
20 yes yes okay good there's one
observation that's worth making that
looks trivial but if you do this
conditioning then the support of your a
sec let's see a vector is only going to
shrink now if you okay imagine imagine
this would be an actual probability
distribution and if you induce on on
some event then another event that had a
zero probability before it's still going
to have a zero probability no
conditioning will make the probability
suddenly positive okay good okay fine
mmm so this is ok let me now go to the
algorithm and okay so here's a little
bit what we don't do so imagine imagine
we kind of guessed the time that the
optimum needs let's say this is capital
T so imagine this is this is the time
horizon we kind of give this this
parameter capital T to us here and we
find some less a solution with a large
enough number of rounds which is kind of
valid for this for that scheduling happy
and now we wander around that that's
scheduling let's say our LP sdv ok so
first let's ok if this is the the time
horizon let's look at some kind of a
binary partition of that heimer Eisen so
which is partition everything always
into int'l to two intervals of the same
length and then like obviously ok we
need like Lochte many many many levels
and now let's let's imagine that these
are jobs and let's look at the support
of jobs so these are the times where the
last year vector has some positive
probability of
of scheduling the guy okay so they don't
have to be intervals they don't need to
be consecutive to support okay now we
want to do the following imagine what
the moment we kind of assign the jobs to
the to the minimum interval containing
containing all the support okay now the
idea is we we want to have an algorithm
that essentially starts at the bottom of
that partition and schedule to the job
so we would like to like first schedule
the jobs that have a very small support
and then later add in the jobs whether
the support was very long okay kind of
hoping that they had like more
flexibility okay good okay now this is
the actual algorithm um this is the
overview of the actual algorithm in the
first step we do the following we we
look at the first let's say log log n
square many many of those are levels and
we we massage the lasserre vector by
conditioning on certain events we will
get that the maximum chain of jobs that
they're assigned to those levels is
small and I will explain this a little
bit more detail and on the next slide
let's take this as given for now um ok
now after we do this let's say these are
the supports of the jobs and these are
the intervals where they assigned to yes
ok very busy what does it mean the
support of a job these are the time
units these are the time units where
where this guy is scheduled so let's say
this is JT where this is positive ok I
imagine this is this is the support of a
job and now kind of with respect to
current Lasserre solution no it's not in
general so you figure seems and the
laziness of the person drawing the
picture which is me suggest that it
would be okay i think once here here
yeah and then from now they just look
like intervals but i don't have to be
okay good I so okay I so it's like for
example like did this rule rectangle
mean that yeah there's some probability
that the job is scheduled here some
probability that the drop is scheduled
there and so on okay um good so now we
want to create some gap here and we take
log log n levels kind of somewhere in
the middle and we delete all the jobs
okay with with we throw them away now
you might be saying that I'm forced to
schedule a lot of the jobs but if i have
a small fraction of jobs then I kind of
threw away I can kind of just insert
them at the very end and I you can just
imagine that for every job you can just
insert a private new time for him and
you can just insert him and that that is
well you just pay paid this extra in the
bay expand but that's not a big problem
okay so as long as we're throwing away
only an epsilon over m fraction wing of
the jobs were good okay good now this
creates a gap in the sense that now
though the intervals at the top are a
lot longer than the intervals being down
here and if you do the math and actually
this factor is like a pulley locked erm
of this thing and I need that pulley
locked erm that's why I have log log n
levels you okay good now I do the
following I have that I have let's say a
vector and please remember that i did
some conditioning so it's not or not
anymore the original was a vector but i
do the following I now recursively run
my scheduling algorithm and I schedule
all the jobs in those in those bottom
intervals so i go through every of those
bottom in
and i just scheduled the vectors i
schedule the jobs and i do this
independently for all those intervals
and you the important thing is that i
have my last year vector and I give I
give a I give a copy to every of those
intervals here and now I since I taught
this recursively there's going to be
some conditioning going on here some
condition from independent conditioning
going on there so I schedule the jobs
recursively what does that mean what to
understand recursion you first need to
understand recursion but yeah that's an
old one sorry I think that using that
property that you know every point is a
common combination of oh I won't say
here yeah okay the ad room that I kind
of he described I described it here kind
of full for the the top interval for the
largest possible Interpol for the Holy
time horizon but you can't imagine
you're on the same album that I just
described here you run it just for
that's more time or rise and you run it
only with the jobs that had the complete
support into you because then like I
always give me the job to a passionate
center oh wait wait wait I i look at the
jobs that have to whore supported here
so and then it looks like the the
original problem okay it just only only
on a smaller scale okay and okay good so
that looks fine but there's a problem so
there are my top jobs and now i also
have to schedule the top jobs I and the
problem is I kind of have to insert them
in the gaps that that remained and there
isn't really a reason why this should
work and so what what could be the
problem the problem is that we're doing
a lot of conditioning at way in the last
year solution that this is not
necessarily consistent so it might be
that in act in any actual integral
solution it's like if you schedule this
job at the end
then in the other in the other interval
you would have to schedule another job
kind of at the beginning so that or are
also at the end so that you can schedule
those top jobs in between so there is
some consistency that we're losing okay
but it will still be enough and why does
it work the reason is that we have
decreased the length of the maximum
chain among the top jobs the one of the
jobs that are assigned to the to the top
notes okay good okay so first things
first let's let's start about the first
at the first point what was what did I
want to do I had those jobs that were
assigned to the first putting o clock
and many levels and I wanted to to
decrease the length of the maximum chain
by conditioning on certain events so
Thomas I just want to get some intuition
is it beautiful the little demons are
small yeah because yes it is okay see
cuz just look at Graham's algorithm um
just okay the bound here is essentially
you get the optimum plus the length of
the maximum chain which is that that
itself is bounded by the optimal but if
you give me a better bound on the length
of the maximum chain you can get
something better than two yeah so in
particular from from this you already
see that you only have a you only have a
major problem if you have long chains so
we're kind of getting rid writ in some
sense of of the long chain problem well
they did they will still exist but yeah
okay so what's where we we were
precisely not here okay this is the
thing ah ok so that don't look at the
statement of the appearance of dilemma
that we're going to prove look at the
picture so imagine this is this is one
of the top intervals and imagine there
are a ton of jobs assigned to it what
does it mean they are assigned to
it means the whole support is contained
but the whole support also kind of goals
kind of contains the separating line
between the decks sub intervals and okay
now imagine it happens that some of
these jobs has a lot of other jobs
dependent on him so in this case there's
the blue job and let's say there are a
lot of other jobs dependent on him but
still the support can overlap this
cannot be ruled out okay now we do kind
of the obvious thing we spend one of our
less around and we condition on the
event that this job with the high out
degree is scheduled in the right hand
side interval in the right hand side
subinterval now after this conditioning
all the other jobs that depend on him
will also be fully scheduled in that
right hand side interval so in some
sense after one conditioning the support
of of a lot of jobs actually moves down
by one level okay and so now well you
just repeat this argument and the
support of jobs always moves down you do
this often enough you count how many
intervals do you actually have among the
top intervals and then then you get
bound on the number of rounds that
you're losing so there's some little
calculation but it's this is the basic
argument still did not get this
condition so you know the color faster
solution is all this combination yes
either it is completely schedule in my
to or not at all yes so you want to say
that I go ahead or here yes how do you
just say well just go here you take one
of the variables and you condition it to
be to be a mask yeah but that the
condition fraction solution right part v
voltrax resolution in fact about
subjective I don't have an object what's
a few people it is really power
all right any other question okay ah
good okay so I hope okay what I hope I
could convince you is that I could
actually if you look at the picture i
can actually decrease the maximum chain
length of jobs assigned to the top
intervals to something well as small as
I like okay and that number well I will
lose some number of rounds proportional
to that but I'm good okay capture good
okay so that's fine but okay okay yeah
let me let me let me go back to the to
the next thing that we want to do okay
so after I recursively scheduled all the
other jobs assigned to bottom intervals
now the crucial argument is how do you
insert how do we insert the the jobs
assigned to Cobb intervals I now the
only thing we know is that actually the
length of the of any chain among those
jobs is very short is that short as we
like okay now let's move on with that
okay so where is actually the problem
imagine imagine this is this is the job
assigned to one of the the top intervals
but the job may actually depend on on
some jobs that are scheduled in bottom
intervals and it also may may have some
of those job dependent on him and the
problem is that now we would recursively
schedule this guy somewhere in this
interval but maybe we're scaling him at
the end and we might schedule this guy
somewhere here but maybe we scared you
him at the beginning so we don't have
any control over that so in principle ah
I I can imagine that for my top job the
only way to be saved is that that I
entered him in some slot that comes
after the end of of any interval where a
bottom
pendant bottom bottom job was scheduled
okay so i could imagine that i define
that i define a release time for this
job and this is some some kind of
scheduling term i define a release some
for this job which is the end of any
interval where we're dependent bottom
job is scheduled and I schedule I i
define a deadline for my top job which
is the beginning of any interval where
like the earlies interval where a
dependent bottom job is scheduled oh
okay and now okay and now i will try to
schedule my my top job somewhere between
that release i'm a deadline and if you
if you look at the support of the top
job there's a little bit of a problem
because there's some fraction of its
support where I'm now kind of forbidden
to do to schedule the job okay good okay
but here's the plane now the point is
that the the bottom intervals are a lot
shorter than the top intervals and the
gap is some poly log term and okay and I
want to essentially schedule the top
jobs in imagining in two phases in the
in the first phase i want to just prove
you that i could schedule the the top
jobs if i would be allowed to ignore any
precedence constraint other than that i
have to schedule the job between release
on and deadlines this is what i'd show
in the first phase in the second phase i
show that okay now imagine I I know that
I can schedule the job between release i
meant deadline if I ignore precedence
constraints now I can also schedule it
with precedence constraint knowing that
the presense constraints that I have to
respect don't have a long chains okay so
let's start with the first with the
first argument if if the top jobs
wouldn't have any pretense constraints
with each other what could I do I claim
that then I could actually
find a good assignment and now this is
an easy problem this is essentially a
bipartite magic problem where you can
imagine that for every top job there are
some slots some time slots where you
could schedule the job and you know that
the last air solution it was a fraction
solution for that bipartite matching
problem the only difficulty is that
there are some some parts of the
fracture solution are cut off now if you
have a you have a matching problem and
there is some part in the matching graph
that's cut off but you can check halls
condition and you can just see what is
the amount of edges that are denim that
I'm losing and okay so essentially the
only thing you need to check is the
following you look at some subset of the
top jobs and you lose what is the
neighborhood what is the size of the
neighborhood you're losing and now the
argument is that for that out of out of
q intervals out of cute bottom intervals
you're only losing two intervals you're
only losing the slot in two intervals
and the reason is that every of the top
jobs must contain the one of those
border lines and you know that you have
one of those border lines only every
every queue of those small intervals
okay so in particular it means that you
cannot lose more than to our bottom
intervals in any of the that are
contained in one of the top intervals
and I'm not convinced that this was a
great explanation but I hope you believe
that this is not a hard argument so this
is essentially it's a bipartite matching
problem you can bound the number of jobs
that you can't schedule anymore we're
just looking at halls condition and just
counting by how much your neighborhood
could possibly shrink and here you use
that well you're kind of talking about
intervals okay
okay okay so this is the first phase now
the second phase is this is might look
familiar to you if you're into
scheduling essentially we're using the
earliest deadline for scheduling policy
which is kind of it's a standard thing
and scheduling it's it's kind of optimal
in many settings it's not exactly
optimal in our setting but it's good
enough okay so what is what is what is
the problem now imagine these are our
top jobs these are the jobs that are
designed to top intervals and now what
is this setting what do we have left now
we know that the the length of the
maximum chain is not too long we can
make this as small as we like ah oui we
know that well each of those jobs may
have a release time and may have a
deadline that we we know that actually
the time horizon is partitioned into a
not too large number of of blogs which
correspond to where the top intervals
begin and where they end so we're the
largest of the bottom intervals begins
and ends and we also have some capacity
left and please and remember that we
already scheduled all the bottom jobs
recursively so there are some slots are
left so you can imagine that there's
some kind of capacity curve and we have
to fill in the top jobs somewhere in the
remaining slots and from the last slide
we do know that if we would be allowed
to ignore any precedence constraint
among the jobs we won't be able to
schedule everything okay and now the
argument is that well we can still
scheduled essentially all of the jobs
losing on your small number and here the
crucial argument is that the length of
the maximum chain was founded okay good
so what is the earliest deadline first
algorithm you are you essentially you
sort the jobs according to according to
their deadlines and now you just
schedule them greedy
and let's imagine the following if you
have a job and his deadline is coming
and we didn't manage to schedule the job
in one of the slots then we just throw
it away and we want to count how many of
the jobs did we throw away okay and
there's the last slide and this is
essentially this is essentially a
modification of a standard argument at
scheduling so if you ever look into
scheduling book you might find something
very similar so imagine this is the time
horizon these are blocks and you only
have deadlines at beginning and at the
end of those blocks okay now let's
assume for the sake of contradiction
that there is some interval where we
have discarded more than K many many
jobs and we want to get some bud okay so
let's imagine this is very very large
and they will come to a contradiction
okay good so for some technical reason
imagine that the large job that you
discarded in this block it will really
was the the lowest priority job and
making you you just delete everything
else the trick is that the earliest
deadline first policy doesn't actually
change for other the jobs that came
earlier so that's without loss of
generality okay so we know that this
blog is kind of overloaded for some
reason that we don't understand yet we
were throwing a lot of jobs away now
let's let's backtrack and let's let's
see let's go back to the last to the
last blog where we had less than see
many idle times and see was the bound on
the maximum chain length meaning that
actually the block before had more than
see many items and now the crucial
argument is if you have a job that we
did schedule in one of those blocks here
then I claim that the deadline could not
have been before this point because if
it would have been before this point and
it would have been
at this point or earlier and I had more
than see many idle times meaning i could
have scheduled him here so the point is
the observation you should make is ok so
let's say in in this picture the maximum
chin ok imagine the maximum chain length
is 2 and now here let's say i have three
i have three free slots uh now imagine
you want you want to schedule a job and
you want to schedule it as early as
possible then the only reason why i
cannot schedule him in one of those
three slots would be that well he has to
depend on this guy but why did i not
scared of this guy earlier what he has
to pend on this guy well then the DSO
depend on this guy so then you can again
construct a chain of length more than C
very similar to to the two grams elgrin
to the analysis of grams anger and then
you would get a contradiction ok so what
happens so every job that we actually
scheduled in this in this area it had
released some and deadlines here so it
had really and any of those k that jobs
that we couldn't schedule it has
released an intent line here and that
gives you a bound ok and the ball
depends on see and and that number of
blocks here yeah i think it should be k
should be bounded by pmc and so you know
that in Knobloch you discard more than
that many jobs so you probably have to
multiply that with another factor of P
which is your number of blocks and
that's actually the end of the whole
thing ok so there are some calculations
you just need to count how many jobs did
you throw away in total you choose the
parameters correctly but every idea is
actually you did see ok it's any
question
okay ah there are actually some open
problems so it's it's not so clear
whether not a constant number of the
serums would be enough or share Raleigh
items rods or at least an actual poly
log number of rounds so for us this is
like a lot this is M divided by epsilon
square times log log n so it's not so
nice actually also a nice problem is
what happens if you have running times
that are not one but you have arbitrary
running terms some of the argument still
make sense others others don't so that
would be nice whether one can have some
extension here and yeah that's what I
wanted to tell you thank you for
listening Watson booking form for this
one another to approximation so random
also works if you have general running
times two maybe two minors one or M
something like that but but nothing
better
I had one technical goshen because with
his film any sense but some of you just
like why didn't need this break up
Lowell ok because I thought you just
needed it deeply you just need to give
me large right yes yes but you could be
a large constant as well right okay
depends on epsilon Y D does it be
written off and yeah okay the problem is
like other jobs you throw away so you
want to say you want to throw away like
an epsilon or epsilon Graham fraction of
jobs throwing away would be fine there
is a technical problem which is that the
level where the jobs are assigned its it
can move because you do the conditioning
and this is makes it very hard to to
only cut a constant fraction of the jobs
so this is why we had to choose the
parameter larger it a yeah it does look
like a technical technical problem we
really thought for some time about it
but we couldn't get rid of it yeah that
that's the reason why there's the log in
to the log log n term it's one of the
things where you write it down you think
okay it's not going to take you more
than 20 minutes to find a solution and
two weeks later you say let's let's be
happy with it yeah okay that's going to
cause a hitch
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>