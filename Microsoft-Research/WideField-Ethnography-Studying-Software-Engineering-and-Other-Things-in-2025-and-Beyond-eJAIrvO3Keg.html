<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Wide-Field Ethnography: Studying Software Engineering (and Other Things) in 2025 and Beyond | Coder Coacher - Coaching Coders</title><meta content="Wide-Field Ethnography: Studying Software Engineering (and Other Things) in 2025 and Beyond - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Wide-Field Ethnography: Studying Software Engineering (and Other Things) in 2025 and Beyond</b></h2><h5 class="post__date">2016-06-29</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eJAIrvO3Keg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
all right so I'd like to introduce David
socha friend of mine who's a professor
at University of Washington at Bothell
which is pretty close by here at
Microsoft David has a long history in
many different fields including zoology
where he learned all about observation
I'm sure and then spent almost 20 years
as a software engineer in the industry
and before becoming a professor at
University of Washington teaching
software engineering and computer
science and david has really really cool
ideas integrating social theory with
stuff we know about software engineering
teams and today he's going to be talking
about a vision he's got of how software
engineering could be studied in the
future using lots and lots and lots of
cameras and ethnography and maybe some
automated analyses so I will give you
David thanks so is everybody gonna
record this on their cameras and then we
have all these streams of data and we
can analyze it and spend time doing that
at the end of the talk so yeah I saw
people taking the cameras out okay so
thank you for coming thank you for
having me here I'm really looking
forward to this this is work that
actually started probably four years ago
though it has longer history behind it
the wide field of Nara stuff came from a
collaboration with a bunch of people at
different disciplines in different
institutions including skip Walter who's
at the back there and three some of my
grad students are walking in the door at
the back here so what I want to do is
actually tell you the background where
did this thing come from what is
actually mean to be able to do this type
of thing and what are the implications
for us and our colleagues in our
discipline and other disciplines so it
really started because I had spent that
19 years after getting my PhD at
University of Washington Seattle I was
in industry good to see you again and
and I had been in places like this where
they're doing software development and
this happens to be an organization that
does a lot of agile software development
practices and so they're pair
programming and things like that so I is
in places like this
and I was really interested in the
collaboration and now I was in academia
at University of Washington Bothell and
so I need to figure out what am I gonna
do for research because this is
tenure-track you I don't do the research
it's not gonna work and I've been in
industry for a long time so I was very
interested in the practitioner world I
was more interested in the practitioner
world and what the experts do in they're
highly contextual environment then in
the control design experiments with
control groups and in the laboratory or
studies about students all good stuff
this is where my interest lay so I was
trying to figure out how to actually get
into this space and because of some work
that I had done with Skip Walter who's
in the back here and other people I also
really wanted to use video to help the
ethnographic inquiry into the nature of
collaboration in these types of
organizations so so what one first
things I did is I looked around I found
an organization turns out to be this one
we use the name beam Kaufer it's a
pseudonym to refer to this organization
and I actually got permission to come in
here and do some ethnographic video and
type video in our crew chief tech work
and so I came in here and I had a single
camera on my first day looking around to
see what actually I might be able to do
and one of the first day is I actually
videoed some of the people who are up in
this little place just for a half an
hour just but the idea what does this
actually mean what type of video is
gonna work how much video do I need to
get what are the positions the type of
things that always you have to address
when you're doing video in workplaces or
in other settings and that actually just
at 15 minutes of video actually turned
out to be quite useful we actually could
discern some things about awareness and
how people might transition between the
awareness that there's sort of my
awareness of myself and the environment
to our joint awareness so from I
awareness to wien awareness and that was
really good and got a nice paper
actually a couple papers out of that but
I only saw this tiny little bit of the
environment I couldn't see the voices
from behind I couldn't see the larger
scope of the
it's a social environment of what's
going on here so I actually went back
later and I really was curious I had
noticed that these people who are at
these pair programming stations -
keyboards - mice one computer they're
often not just two people
sometimes there'd be three people or
four people and they're talking back and
forth and all that stuff and
practitioners know that that's what
happens in here but the the literature
said almost nothing about these
interactions outside of just the two
people of the pair which was sort of
surprised and so I went back with four
cameras and set them up on either side
of the two pairing stations on the left
side of this desk to gather more widely
to be able to see who is sitting behind
these people and what the gestures were
and things like that and that actually
was useful in that we could then
evidence that these people weren't just
talking between the two people they were
talking across the table and the the
work was organically growing and
shrinking as needed and sometimes their
two pairs involved in the same work and
we actually found out that about 20% of
the time they're not just there they're
interacting with people outside of the
pair so that was useful from academic
perspective to say huh if we really want
to study organizations like this instead
of focusing just on our particular unit
analysis two people maybe we need to
broaden the scope gather more widely to
see the context in which those two
people are actually working and so and I
and that was good with the four cameras
but I couldn't see who they're talking
to on the other side so still limiting
and they were talking to people on the
other side and I couldn't see what the
gaze was and gestures so I went back
later about a year later in 2014 with
more cameras but before I get to that
here's what I'm really doing right I'm
an academic I'm in in research
environment I'm trying to do research
I'm trying to have new discoveries of
information and I'm trying to actually
in the end impact this practice scope
there's software engineers out there and
they do amazing things and they create
amazing systems yes this is adapted from
Gale Murphy's
pixee keynote last week or weakest
weekend half ago so I want these
inventions and ideally I would like to
actually impact the practice that is the
sort of holy grail of research to come
up with theories and insights so that
these people are doing this really
interesting and complicated and complex
work can actually do it even better so
that's what I wanted to do and so I went
back in here and I wanted to attend to
all of these physical and cyber and
social aspects of what's going on here
because people are sitting side by side
they have all these materials of design
on their desk they can look across to
the people on the other side they have
the laptops they have the mobile devices
they have the code repositories that
task tracking systems they have all of
these materials of design and how could
I gather all that so I went in with nine
GoPro cameras six zoom high quality
audio recorders and and also some
observations and a handheld camera and
some screen capture and so what we see
here this table here is this table right
here so these two people are appearing
at this location right here and there's
another pairing station up here so we
have seven pairings places where people
pair in this organization and I put
GoPro cameras in blue recording video
next to these and they have a hundred
and seventy degree field of view so I
could gather more widely so I have some
of those I also have one that they could
just wander with to take out other rooms
I had one hanging with a microphone
hanging on the ceiling up here so I
could see them as they're doing the
Huddle's in this area three times a day
and gathered that I also had a one these
cameras only record about six and a half
hours Tom they're totally cool he just
like being big brother
do you have pre-existing relationship
with these people is this like where you
work but I never read so-and-so after
this I resented so this in case yes I
had a pre-existing relationship with one
of the people there later I was wanting
to get more sites that I might be able
to gather from so I actually reached out
to about 50 organizations six of those
said yes three of those are pretty weak
yeses there were consulting
organizations they do some work in-house
but some with other people would they
ever be able to get permission with
those other people not clear and then
2/3 of them were actually pretty rich
there's one international well known
organization this agile softened about
well and they were willing for me to
come in and do some of their open source
projects so yes there is this issue and
this is not necessarily what you have to
do for wifey lithography I'll get to it
in the best world you have all of the
scope that these people have they're
here in this amazingly rich environment
that is seamless they can turn the head
they can listen they can perceive where
the voice is coming from they can go
into the machines and ideally as a
research you would have all of that
available to you and then of course
there's the pragmatics and you gather as
much as you can and sometimes you can't
gather what you want does that it does
actually span a broader scope which will
make it more accessible to more people
doing more types of studies things came
up they do in this case I was so I the
consent agreement here
is that if they ever want to not allow
me to use that data in the future at any
point they can send me a letter and I
will then delete all that data I have
six terabytes of data from 11 days so I
guess what I'm asking is you had
recorded the recorded private
conversations and then you delete them
after they ask you to so you have a
thank you something you said they think
you can turn it off if they want to they
have me cameras there and they can turn
them off okay
they never did they never even seem to
care when I was there / just personally
or with the other cameras they're
actually studies showing that the
cameras sort of disappear from your
awareness if you're actually doing your
work you ignore them pretty quickly
especially when their GoPros that are
really tiny and they're on a tiny little
tripod and so the most obvious thing is
the blue painters tape that's holding
the tripod in place so it doesn't get
swatted away accidentally so and in this
case the consent agreement allows me to
share this data with other research
groups as well as long as they abide by
the same constraints about privacy and
confidentiality yeah so does that
address your questions so he went in
here there's also a time-lapse so here
you can see this is every 5 seconds the
entire room so you can actually see
where people are even there outside of
the cameras this is the type of video
you get 12 ATP from the rooms where
they're doing sketching they took it to
another room over here this is the
ceiling image that was taking a snapshot
of the whiteboard this is the Huddle's
going on here and this is the type of
stuff you get from the pairing stations
okay and the other questions bubbling
they're like I realize when you're doing
a blog feed right you're wanting to get
all this data but I look at this and I
see 11 days of this and I say okay at
the end of that time you have like I
don't even know how many streams of
video and now you have to do something
with it yep like code it you have to
analyze it you have to look things like
that makes my head hurt
right so are you ice or are you gonna
get to that okay okay
so thank you you gave us and you didn't
somehow that's like super impressive to
me because I would just black your eyes
information overload
yes yes and there's so there's multiple
ways in there and I'll get to the
multiple ways and if I don't then call
me back to it and say we're more of a
multiple weight Saoirse okay so what we
discovered getting all this data is that
we could actually do some really
interesting things because we gathered
so widely we could actually follow work
across space and time somebody would
make a mark we'd see a mark on a
whiteboard and was like who wrote that
it would go back three days and find out
who wrote it on the whiteboard said oh
that's pretty cool we could see that the
work that started one pairing station
they had conversation now is a two and
then went over to another one and so now
there's six people involved this is
interesting
we also there's so much richness in here
with all this unstructured video and
audio that we can support lots of
different types of research questions
from different disciplines about
different types of things using
different types of units of analysis so
it could be the person it could be the
place it could be the pair it could be
the task it could be the the role lots
of different things going on here it
could be the source code well and this
is again because it could do that it
actually would really afford these
communities of researchers working
collectively together using all of the
different perspectives to come up with
much more interesting analyses and I've
been involved in some of these workshops
where you have a joint data set like
this with video and you'll have 50
people from mechanical engineering
design studies education ethnography or
a sociology anthropology and so on all
coming together to do a joint analysis
you could do that with this and there
would be so much that different people
could attend to power structures and so
on it also allows me to do what I've
been trying to do I can wild my
observational field of view I can follow
those things across here and it also
means that I can go in there with an
assumption what's going on and I can
gather so much
data that I can one thank you
refute my assumption I got whoops but if
I just gathered five hours of video
there is much less chance of actually
finding the data that we refute my
conjecture is my hypotheses my
assumptions and interestingly perhaps
most interesting to me it really allows
the researcher to span a multiple of
different ways of approaching research
they can have the design the the
scientific method where you come up with
a design study and you figure out what
data is to be included and then you go
in here as if you were walking in there
in real life and just look at tend to
that data and do your analysis you don't
quite have the control study but you can
also go to the things were huh I'm
interested in this space what's going to
come out and so as you go through there
they're in interaction analysis which
sociologists use and lucy such men and
such have used you actually will often
look at the videos and just make a high
level notation about ooh minute 10 and
that was an interesting power dynamic
ooh
minute 15 look at how the work is being
negotiated and the problems are being
made in the conversation and so you can
just scan through this and then find the
stuff that oh this keeps on coming up
huh I never would have known about that
so it's a complex system and you can see
the emergent patterns that no one had
even thought of going and investigating
and those insights can then drive the
more standard scientific method type
inquiry or you can go and mine the data
set to fine and evidence in in post hoc
say huh
we have this two-by-two matrix with two
dimensions plus and minus plus and minus
we see this thing here can we get half a
dozen representations in these four
boxes and if you do that you can
actually start reasoning fairly strongly
about what is the nature of work and how
these dimensions are related to the
things going on so that looks
interesting and so we realized that it
wasn't just we weren't here anymore
we were in a broader space we actually
had this thing where we were gathering
so widely using ethnographically
informed practices that we actually
started suspecting this might be
different qualitatively different from
going in with one or two or three
cameras or spending months on site not
necessarily better or worse just
different we started wondering what that
might be and as you pointed out oh my
goodness they're tools needed to
actually keep us sane and to make this
something that people can actually want
to do and do effectively without wasting
their time on all of these things and
I'll get to some of those things so
given that and one of its re one of the
other big things we realized and this is
the sociologists talk about the context
is key to reading the text so if
somebody says a particular word if
they're saying oh this this and this and
if all you have is the audio you see
this this and this but if you have the
video you can see them pointing at this
this and this and realize that those
three words are completely different
things the word the meaning of the word
is not derived from the dictionary it's
derived from its use in the social
environment in which it's being used and
so all of these types of context really
help you see cognition in action because
cognition is not just this thing that
the cognate is talked about it's in our
bodies it's in the materials of design
that are around our spaces that we refer
to as the gestures at the gaze all of
that stuff is used very effectively by
humans we've been involved to do that so
this is what Peggy story talked about in
a recent ACM SIG's off webinar last
month where you get all this big data
you get all these digital streams of
information there really looks so
promising and if you only had that
stream of the audio you only have the
commit messages you're missing so much
of the context so Peggy talks about how
you need the thick data to inform the
big data you basically want if you want
to look at the the social life of a bug
for instance you want all that social
data to inform
how bugs are socially created what's the
social influence and bugs what's the
influence of bugs on social in social
situations so that's what we did here
and in thinking about this more
there's actually four things we really
want to attend to the physical how are
we using our bodies the cyber all these
tools the social all of the norms of
behavior and the ways we interact and
really it better be economic too because
any system if it's gonna live long
enough needs to have some sort of
business model that actually has enough
value propositions and value exchanges
to sustain that business model whether
that's monetary exchanges or social
capital exchanges or whatever for thing
is to survive they need an economic base
they need a viability so really we think
of these things as physical social
economic cyber systems or P sex which
has this lovely property that you can
stick it right into the word or pull it
out of the word presence because that's
really what it is about we as humans we
are present in an environment where in
present in this situation and that
presence allows us to understand what's
going on and act in that so in some
sense why filled with nog rafi is how do
we understand what presence means with
respect to software development for
instance and this is a little assertion
from Christiana Floyd software
development is an organizational
intervention we're creating software
systems and most of those we like to
people to use and they're not actually
using the thing we haven't created yet
so we need to figure out how to
intervene into the social system of that
person to make them use the thing that
they aren't using now we have to do this
intervention which means it's about
psychology now which also means that not
only is the software development
organization a P SEC a physical social
economic cyber system but these systems
we create themselves are also P sex the
software we create is used by people and
it has to have in economic
based actually sustain itself it gets
involved in the social fabric it is
involved in cyber because we have
computer science software developers and
there's some connection to the physical
world otherwise we can't ever perceive
it and therefore it essentially doesn't
exist if there's not some eventual
connection to the physical world so this
is one in some sense what we're trying
to do here is how do we get enough
context so we don't end up in the light
post or the light streetlight effect
where we're looking for the interesting
stuff where they we have the data but we
might not actually be looking in the
right place it's just where we happen to
have the data and that's the goal of why
I feel the photography and it has issues
like this so that one collection 45
streams of data if you think about the
video and the ruffed and right stereo
and the screen capture and the other
camp other types of cameras which we
solved in 6 terabytes which is a lot
it's a mess so you need some sort of
system some sort of tooling system this
is a very high level perspective you've
got all of these streams of data coming
in from different types of media video
audio and so on you might have some sort
of psychometric or physiological data
from a Fitbit in there you might have
documents that are put into some sort of
repository on the system or physical
documents that are sitting on the table
so you have all this stream of
information that come in into this data
set and yes and and some it's very
unstructured and some is quite
structured and the community and I'm
trying to spend both of these
communities and I actually am in my work
over here we have people who use the
interaction analysis so this gets back
to your question again where those
people don't watch all 380 hours of
video they'll watch a few hours and then
they'll be sufficiently pulled toward
one inquiry that they go study that but
it would be really nice if they find
some thing of interest let's say they
laughter is a moment of interest because
when somebody person a
says something and person B says
something's like women those can't be at
the same time the same place it and then
you suddenly realize that oh yes they
can then there's this thing called
incongruity resolution theory that says
that you'll get this burst of humor
which are almost very often results in
laughter and then you can attend to what
they're saying and saying be not just
the verbal but the body and the gestures
and gaze and you can listen to them re--
conceiving the nature of their work from
before the incongruity resolution to
after it that's so interesting so if
you're starting to think the laughter is
interesting how could we write one of
these algorithms to find all the
laughter in here so that I can actually
effectively get to those pieces so I
could then analyze that five seconds or
15 seconds spending you know half an
hour or an hour or two on ten seconds of
data and that's typically what we'll do
we spend one I'll get two so and we
actually wrote that algorithm by the way
and coming out in the paper in a couple
months and if you want I can send that's
Andy has a copy of it or you can you can
email me now send your copy and actually
did really really good work by there's a
microphone hanging from the ceiling up
here and in the Huddle's in this noisy
naturalistic environment the student
actually got really good accuracy and
recall compared to all the other studies
with data like this and so we now have
another student who's actually taking
that algorithm and putting it up into
the cloud next to all of our data so we
can run across all that data and
actually get to those moments who can do
more inquiry so we both sides of these
things are useful and the question is
how can we support both sides and it's
that's the problem right because you
have all these streams of data and now
it's a mess you've taken this coherent
whole and you fractured it into all
these streams of data which have just a
part of what's going on and now they're
just associated with each other and you
need to put them together in a way so I
as a researcher can get
into this and actually navigate and find
things it turns out to be a pain in the
neck if you don't have the tools and
it's the the reality I've been living in
for two years so here's one thought you
can think of the streeams is
collaborating each stream has some data
and they certainly collaborate a corner
across time they recorded in some sort
of Universal Time and you can also
imagine they collaborate according to
location they also you can imagine
tagging these things for laughter and
now you can collaborate by laughter you
can imagine a machine algorithm would go
through and do facial recognition and
find where Bob is and now they
collaborate by person and so on so
there's lots of different ways you could
tag these things manually or
automatically and get correlations so
you now you can jump from one place to
another place do this thing what time is
it okay
and some of these streams a stream
itself so this is audio stream this is
sort of funny paper that Michael Roth
wrote if you use last year where he
found this word penis used ten times in
a high school physics class and none of
the references at pinis are actually to
the organ they're all just part of this
game and they all mean something
different but the point here is that so
that's funny
this is those ten instances of that word
and that one stream of audio has been
dissociated into one two three four five
different sub streams so streams have a
life of their own you can pull apart
into other streams you can merge streams
into a different stream it's not as
simple as as this diagram represented
and we don't you know these video
cameras they're really cool but anybody
watch the Super Bowl you saw how they
froze the action they zoomed in with the
voxel space they created so that's what
replay technologies did they have a
bunch of high resolution cameras around
some sort of sports event and then they
stream those in real time up to a bunch
of servers and then they create voxel
space so you can freeze it and with the
Microsoft Surface
Pro you can then go in and control your
angle and move around as you want and
zoom in and then play the video from
that angle that perspective so that's
the what the CEO of Intel was talking
about in this video on January 5th they
bought that company since then why would
they want to buy that company probably
lots of tips being used to do that type
of thing so if you can drive this type
of thing you might drive some chips
sales okay there's a lot of data
involved with this and furthermore
software development is a team sport
so I would as a researcher love to be
able to jump into being offered sit were
Andy let's say Andy were Sabine cover
sit where he's sitting looking at his
screen and then play the world hearing
what he hears out of his left here and
what are the right ear
sorry not knowing your characteristics
if you're hearing of your internal
organs but what you might be able to
perceive and see and then be able to
dive in to that screen and look at the
source code repository in the test
tracking system and analyze what he's
actually working on then jump back out
and move around and I'd then like to be
able to go sit on Marcy's seat across
Mandi and see what she can see and so I
can get telepresence because I can go
back to the same place in many different
perspectives looking at the data again
and again until I see a new coherent
whole that is something that wasn't
there before that's sort of cool that's
the type of thing that these things
allow that you can't get with a person
doing this standard ethnographic
practices and it gets even more oh yeah
of course there I bought the virtual
reality headset on here right to really
get the presence of it and it gets more
interesting because there are at least
two organizations magic leap and
envelope er who are developing these
types of technologies who are they're
claiming that in the next year they're
going to have their software developers
start building the environments with
these things on their head so they're
going to use virtual reality to create
saw
four systems create peace X what does
that mean how do we collect the data
about those things how do we understand
that because what Andy sees in his
headset may be different from what I see
in my headset even though we're think
we're in the same color good space
because he's got an extra couple of
screens up here and I've got some
different screens over here so now we
need to record all this stuff and it
gets so that the tool problem gets worse
crazy people doing interesting art work
what can I say it was from their website
so 2014 yeah six terabytes it's a pain
in the neck it's doable I think you can
imagine that in nine years or so it
might be more like four thousand streams
it might be more like petabytes because
of all these extra streams of
information and the higher resolution
stuff there's a problem here which means
there's an opportunity here right cuz
boy this stuff is data hungry where they
going to store the data were the
software service is going to be that
actually can do the machine learning to
analyze the data to find those tags so
you can correlate the streams and
recreate a coherent whole that is novel
for the researcher and more insightful
that's so there's there's needs to store
the data
there's needs to analyze this massive
quantities of data there's needs to
share the data there's all sorts of
stuff so that's sort of the vision and
I'm going to go back to a little bit
about problems we're dealing with today
to get some concrete types of problems
and then we'll go back to the bigger
vision thing so here's something that
we're doing the other day you're
watching this video and then this person
up here Austin says something then
they're looking across the cameras like
oh man who are they talking to you well
how today do I figure out who they're
talking to you well I look at the map
okay they're in parent station a so
they're looking in cost
peirong station see so then i open up
the browser and i was up up here and
then I have to the Windows Explorer and
then I go over here and then I find out
which video and then I open the video
and of course they're not synchronized
and it's not I don't care about video
files I care about time why is this
abstraction of files in my face not
helpful
so then I have to actually find the
correlations this is o4 and this is oh
I'm there a few seconds off and then I
have to write in the right place and now
I can actually see that these two of
these people I blur their faces but they
actually are looking across here this
person's looking here it seems it looks
like it is they're attending in that
direction and I can listen to it but of
course I want to play them together and
I actually can't play them together
because there are two separate files and
the system doesn't do that and really I
don't want to listen to the GoPro audio
because it's good but it's not great
there's this high resolution audio
recorder here and this one here I want
to listen to that in my left stereo
listen to the bath in my right stereo
and play these things synchronously by
frame fast forward reverse and so on
that's what I want to do it's not
technically difficult these are all
straightforward things but these things
don't quite live yet and so my students
that I live in that pain and this is a
variety of other pain points we want to
tell the story about the amazing results
we can find that's what we wanted to but
we have to start off gathering the data
we have all this equipment this is just
beam cover stuff all dozen hard drives
to keep all the data we have to deploy
them and upload the data which meant
until 10 p.m. every night I was
uploading through my two hard drives via
my laptop until I actually got a second
way to do it and now it was done at 8:30
p.m. which was fantastic and then
oh there's we have to correct it cuz oh
I mislabeled a file
I folded the other day so where's the
data for the 22nd so oops it's in the
21st who so and you have to clean things
up it's all that mess and then you have
to do all this stuff to find the stuff
that you care about and to now
through the system and to filter out so
you can just focus on a little bit and
do the analysis not on everything but
just on the little bit that matters
because it takes a while or costs money
to do an analysis even if it's automated
you spend money on the CPU and then you
get stuff that's more useful
this is grunt work you really want this
to be instantaneous and now you're
actually viewing it but that's useful if
you're exploring and you're annotating
in it that's slightly painful but it's
useful and then you get into the
analyzer like okay yeah this is where I
wanted to start and I had to go through
all this stuff and we're generating
hassle maps of all of the impediments to
get there and it's it's it's a pain and
that could takes half an hour to do that
thing I just talked about before in that
particular case because I hadn't been
with that files for a long time and
couldn't number where they were in blah
blah blah uh and we also of course want
to share this stuff with other people
and we want to use visualizations across
this whole stack because we are visual
creatures and they help us do things
better and then there's the issue of am
i do this by myself or am i doing this a
group of people am i collectively
analyzing or doing it by myself
different affordances wanted in
different places so we have all these
hassles and we need those tools oh boy
we need those tools and we're starting
to build the tools and we need them
sooner than that
that's I'd like one thing to note here
is you can use this with lots of scale
so blink one of our collaborations Nick
started creating a system around the
same time I was doing my beam copper
stuff to instrument a room where the
doing user experience research so they
had multiple cameras those fees that go
into a control room where they'd blend
them into one video that would then go
up into the cloud and then be redeployed
into another room where is the person
that blink who's running this use
research and the cot the clients would
be there and then there's another room
in other places around you like other
countries where people are also viewing
those videos in real time near real time
and they're chatting with a chat feature
back and forth making sense of the data
and actually changing the user
experience
search process in the on-the-fly because
they realize oops that's not working oh
there's something more important to
discuss so the actually never almost
never look at the videos afterwards
because that live in person collective
sense making in near-real-time is
actually good enough enough value right
there so you could do that it's just
small little things you could do what I
did but boy if I did this again in a
couple years I'd want to go in there
with enough cameras to make that voxel
space clicking all the digital trails I
can imagine having fitbit's or something
like that to really have a EGS can you
actually detect team flow okay be
interesting to find out if you detect
team flow what are the social or
physical or cyber or economic things
that might disrupt team flow or the
creative team flow and so on yeah so
here's another thing so there this beam
cover dataset we took it up to
University of Washington or with
University Victoria Vancouver Island
Michael Roth's office so there's Michael
Roth Skip's in the other room using the
system that blink made so he can watch
us through some cameras like this one
that are streamed up to the web and then
he's making little annotations as he's
watching this whole thing and then
there's Josh tender berg Robin Adams and
Alfredo Jornet nigh and we're in here
and we're watching this and we played
fight we'd already watched six hours of
video before we came here to the stream
of stuff we watched about five seconds
and we spent two hours discussing five
seconds
it started off the first five seconds
the people said what do you mean by
scalability and then about an hour into
this and we're talking about previous
things and looking at other pieces of
video somebody were in this group and
somebody points the other parades what
do you mean by scalability at which
point half of it just crack up we had
because we were collectively analyzing
this we had just recreated the social
phenomenon that we were actually try
to investigate so now as researchers we
could actually experience it as well as
observe it we could almost be
participant servers observers in this
space by having a set of multiple people
so we actually came up with this thing
you know spiders have multiple eyes in
some sense what are the superorganism
what is having six different eyes with
different perspectives and different
agendas going on at the same time allow
what is it afford how is this different
from just one person working by
themselves so we're looking into this
some more and and this is the sort of
the system I'm playing in today so we're
getting close to the end of this there
is this beam Kaufer data set that I have
collected other people are collecting
others Robin Adams at University of
Washington Bothell
she's a education professor and she's
really interested in STEM education and
it turns out that precalculus classes
are problem because people go in there
and they get discouraged and they drop
out of the stem path so how can we
increase people in the stem path well it
turns out active learning is really good
at that but what is it about active
learning and there's not a lot of data
around that so she started collecting
did a set of group work in precalculus
classes at UW Bothell and if her plans
came to fruition she would have
thousands of hours of this video tool
problem their education people they're
not software developers they're not
gonna be able to make much traction the
mess gets so messy so quickly then
there's a building these tools so one
eye tool in the back here she's actually
looking at what does it mean to do
wayfinding in these types of datasets
it's not just about search and finding
how do you find your way either when you
don't even know what you're looking for
or what you do know what you're looking
for
there's also see who else is there
Veta in the back here is looking at
visualizations
how can visual assistance help there's
different points in the stack Haase is
saying huh what if we had a 3d
360-degree camera how might that afford
different ways of experiencing and being
present
researcher than if you have these flat
screens that we normally are interacting
with through video so there's all that
stuff and then we're trying to do some
there's more work we're doing analyzing
that data set and there are other people
in Europe UK Canada us who are either in
or going to soon get into the data set
as soon as I can gonna have tools for
that to be a sustainable activity
already mentioned it are you looking at
ways like annotating yeah we're guessing
from all streams like saying this thing
happened here and like tagging it like
you would tag like an interview
transcript or something but in this and
Breanna cases can do done with machine
learning rooms or there's a system of
University of Wisconsin medicine called
Penn's Anna that's been around for about
15 years it's used widely and we we have
a copy of that we're starting to
integrate that into our tool system and
it allows you to play four or five media
streams concurrently forward and
backward and annotate and it supports
different annotation formats and you can
so it does a bunch of that stuff and it
also has a shared database so that as
you're annotating and I'm annotating in
different places I can see your
annotations in real time so there's
support for the collective inquiry and
instead of building that we're just
integrating that and then there's this
what does it mean to actually do this
how and we can use this not only to
understand what wide field ethnography
means but we can actually use it to do
the design experiments deploy a
visualization how does that change the
hassle map does it mean that they can
get to the value they want sooner how
does we change some of the way finding
stuff what's the benefit to the people
so that's the system that I'm playing in
at this point and it's not that we're
new doing new stuff this long pedigree
of using video in different discourses
for trying to figure out what's going on
from the the people looking at copy
machines all the way up to education and
computer-supported cooperative learning
and so non and and this a lot of this
focus is on that slow reading of the
unstructured data so you can see the new
insights that can generate opera
these for you seen their name so here's
this summary of it now what we this is
where we saw last time we looked at this
we have the research we have the
practice and really what I want to do is
I want to push these tools up here into
practice so I can take him back here and
actually use them to do this type of
work right without those tools is gonna
be too painful but it's more than this
there's a lot of other discourses
disciplines that do video and they have
these same problems so they rarely take
more than a couple of video cameras out
there so sociology education
computer-supported cooperative work
computer-supported cooperative learning
there's lots of work in there on this
stuff and others how can these tools
actually help them do their research so
well is there anything in particular -
so the software entering engineering
domain fed like specific terior your
tooling and the problem you're trying to
tackle I mean it seems like what what
you're trying to do in the data
capturing would be true of any kind of
business collaborative knowledge worker
setting is there certain things se
specific here it was motivated because
we do use a lot of digital tools that's
pretty much the case for all most
disciplines now so I think that the
software engineering still has a really
rich place because we use them and we
make them and we modify them to degree
that other people don't
so we're leading in a lot of these areas
but if you look at these other things we
might get some interest in insights
about oh that's an interesting way of
doing it or a different tool that
actually could also that's what these
lines before it could be that when we
look over here we say that could be
useful for our software developers or up
here so I hadn't thought about that so
there's lots of feedback possibilities
in here because we are people and we use
physical stuff and social stuff and
cyber stuff in many different places so
I don't think I think there's even the
broad view it's useful so many places
there's nothing special
about software development it's just
we're at the forefront a lot of these
things and we if we start using them
might make our own dogs either on dog
food whatever you call that thing we
know how to make these tools so this
community would further this faster than
just deploying it over here so this cus
the next part these all of these
communities want to eventually effect
practice most people do that's a common
thing to get that to happen it's not
just going to be research results here
we actually probably need to
commercialize that thing we need to make
this thing substantial enough easy
enough to use robust enough scaling well
enough that people could use it with
these petabyte types of datasets that
are coming down the pipe and that is my
sort of long vision at the point at this
point so that's why I feel if nog Rafi
we're doing this really wide data
collection to give you this context so
you can understand these things better
design and better and prove these P
sects as we call them down here
questions yes decision I'm trying to I'm
trying to picture in my mind's eye it's
50 years from now this vision has been
completely worked out right there's tons
of software support the tooling is
awesome what is it like if I sit down
now as a software engineering researcher
with a data set that has you know all
this tool support in it so you have that
you have the slide with the spider eyes
which is today's word pipe is still very
hands-on right so lots of discourse
among the practitioners does it still
look like that or if we crank up the
tooling does that somehow look different
a couple of decades from now so first of
all I expect you to lean will come
through
close it in much sooner than 50 years
yeah we're always optimistic anomalous
offer it may not change the world
it's gonna be like six months no all
here right so I think I'll come in
sooner than 50 years it's there's a lot
of stuff here that's not actually
technically difficult it's doing some
piping and connecting and then it's a
matter of adding to that making these
things so you can keep on adding new
visualizations new machine learning
algorithms things like that extending
something like China Senna as far as
what this means for the nature of
research well that also depends upon
what is the nature of software
development if we actually get these
virtual reality augmented reality mixed
reality things working well then we
might not be traveling around as much we
might be sitting here collaborate with
people in Bothell and with people in
London as if we're in the same room
perceiving them with the sufficient
fidelity to have the affordances of the
gestures and the gaze and the things
like that through the holographic images
yeah that might be more than a few years
out but it's this stuff is coming
there's going to be aspects of that
coming and so that changes the nature of
work because if software developers can
do that well so can other people look 50
years I don't I think I'm lucky if I can
see a couple years 50 years is way
beyond where I can it may speculate or
extrapolate do you have ideas so I'm
thinking for example by a comparison to
say the mining software repositories
community right so if you look back say
around the turn of the millennium the a
lot of that community was doing hand
work right of the kind that
ethnographers do stay right so a lot of
hand crafting of data sets with a lot of
cleaning by hand and so on very great
things have gotten much better than ours
there's a lot of tooling support right
so so now if you have a new hypothesis
you have a new research question it's
not quite as easy as writing a sequel
query over a giant database but it's
getting great bit by bit right so in a
sense I sense the trajectory there
right we're like eventually it turns
into like a small iPhone script or
something my testing a hypothesis right
here I'm trying to understand better
what's it look like it's you know
answering your research questions
probably not a sequel query right it's
probably something more than that right
well I think I could have mentioned the
news a query where was that talk where
so she was getting a question from Rob
well here are sentences it's okay now
and then you recreate this environment
and you're in it and you can sit where
you're seeing and see that oh you can't
see this person up here who's doing this
really annoying thing or something like
that
so I could imagine the ability to enter
into the present of the environment
could be quite different and to be able
to be turned to them again again one of
the huge things about the video use of
video ethnography is that you can replay
it again and again and again and again
you can share with people and they can
come up to the cone conclusion about
whether they believe you or not you've
got that raw data so if if you had
access to those repositories of the
recordings you could go and say oh I see
something different you go sit over here
and I look at what's going on or you
didn't know what they're actually
working on because you didn't actually
go back enough far enough in time but I
actually went far enough in time and the
reason they're doing these really
stupid-looking things is because the CEO
came in and said okay for the next two
weeks we're gonna have to do this really
stupid-looking thing because of this
constraint it's like oh they weren't
being stupid software developers they're
just doing what they had to do because
of the world that they were in but if
you only collected a little bit of data
you can't go back and see those things
that generate the context I don't know
if that answers your question okay
yes so I'd like to propose an idea for
how to get to a hundred years out maybe
for problem six years it's not too far
away but it feels like how in the same
in a similar ballpark of all the
qualitative research is a complete
divided it's like well you talk to two
people how do you know that generalizes
across a large variety of people let's
say that you could put these things in
every team room of companies across
North America you know and then are
there tools that would enable you to
compare two types of experiences of one
of this pair programming look like in
Ottawa versus what it looks like in
Mexico City and does it look the same if
we look at a lot of different sites
right if you had enough recordings and
you figure out the privacy settings so
they wouldn't disturb people to keep
this stuff so maybe there's automatic
ways to diiie enough or can anonymize
the characteristics of the environment
and the voice so that you can still
attend to the features that are
important but not know who is speaking
and if you have enough you can imagine
that and the social science communities
have come up with ways to be really
rigorous with this qualitative analysis
where you have a small sample size and
you're not using statistics
yeah so those things practices exist and
yes if you have a large repository you
could say wait what was it like 20 years
ago
what were we looking back there is this
pivot this this um this inflection point
it seems in history and then you can go
investigate that or if you're an
organization and you recorded all your
meetings this way you can say wait a
minute there's that discussion where is
that discussion because that was I can't
remember but it's something really
important said there and then you could
query for that and find that and we
listened to it ago and secured a new
here again in now your new context and
understand what they're saying up oh now
I know why or now I know where to go so
I could imagine that type of being able
to jump around space and time to gather
data sets that you can compare and I
personally think that any practice looks
too
any context that's important paradise
other questions
Thanks how do you even know what to
select it seems like you mentioned a
couple of times were you looking at like
chunks of what you've already recorded
it and during there's something that
jumps at you and that seems very
interesting and so on so if you isolate
it but how do you even start with what
you set out to record
trances one is I didn't bunch of
experiments I visited this place
probably fifteen times before I went to
the big data collection of 11 days or 10
times something and I went in there I
collected a little bit of data and then
I used it I realized this is a
limitation so I collected the more data
the second thing is that I'm interested
in collaboration but collaboration isn't
controlled I can't say stop collaborate
that person it goes where it wants to go
so in this sense I needed to gather
widely and I basically got as wide of
use I could with the equipment I had
available and the time I had available
so that I could then follow the work
around there it's a very different way
of thinking about research than the
classic way we say this is what I'm
going to study and this is the data
collection what's the pre havior of
sketching how does sketching afford the
collaboration and they have all these
whiteboards in the organization and I
went there and went in the first day I
realized oh there's a lot of sketches
and a lot of whiteboards but they only
actually spend about half an hour a week
sketching so I would not have time to
actually get enough data to do anything
interesting so the my assumption about
what was going on was wrong and that was
another motivation I want to gather more
widely to give me safety so I collect
the data I can get something useful out
of it
thank you for creating the tiny
thumbnail of the spider and your
scalability slide to because I'm
terrified of spiders so not gonna bring
me out
thanks I'll make it smaller any other
questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>