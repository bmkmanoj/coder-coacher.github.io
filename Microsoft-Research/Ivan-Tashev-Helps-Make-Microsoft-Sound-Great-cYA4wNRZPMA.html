<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ivan Tashev Helps Make Microsoft Sound Great | Coder Coacher - Coaching Coders</title><meta content="Ivan Tashev Helps Make Microsoft Sound Great - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ivan Tashev Helps Make Microsoft Sound Great</b></h2><h5 class="post__date">2013-11-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cYA4wNRZPMA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I'm here at the ivanov principle
software architect at Microsoft Research
he's known as the brains or at least the
ears that Microsoft and you're behind
the acoustic breakthroughs in the
original connect as well as the Kinect
on Xbox one and other products like
round table Microsoft automotive and you
worked on the microphone or a support
that started with Vista
so yeah you shipped a lot of products
for a researcher I have been over here
for a long time how long have you been
at Microsoft 15 years and so you
originally came from Bulgaria
that's correct and what was the path
that led you here to Microsoft at that
time I was assistant professor in the
technical mystery of Sofia my alma mater
actually I have worked it for two
companies only technically you still
Sofia and Microsoft and at some point
was tempted to switch from academia to
industry and to see okay it's good to
teach students and go to mechanize and
cool theoretical work can distinct work
in reality can we make some of the
algorithms which are easy to derive on
paper to be part of an industrial device
to make the transition from algorithms
from micro for microphone arrays to
algorithms for manufacturable microphone
arrays in quantities so explain what the
difference is between a microphone array
and a regular microphone so a regular
microphone is one point in the space
where we pick the sound a microphone
array contains at least two in the
connect case four microphones like this
and those four microphones give us the
sense of direction direction so we can
combine the signals from the four
channels in a way to make the microphone
read to listen towards given direction
and to suppress the sounds coming from
other directions which means that at the
end the resulting effect is that we get
one channel of a better microphone
highly directional but we can
electronically steer the direction we
can listen to
we can electronically place and know
towards a competing sound source you can
electronically steer this No
so at thus as a result we adaptively are
getting the best possible sound from the
desired direction minimizing the noise
coming from other directions and so you
can tell where in space the sound is
coming from how accurate is that so this
technology is called sound source
localization we have it in connect and
in Xbox one because we have to know
where to point the beam and the
precision is 3/4 degrees which is
sufficiently to pinpoint the beam the
beam inside the mouth at 4 meters
distance and how does a human works a
well with just two microphones a lot of
CPU first we have two microphones which
is important so it's a microphone it's
not a single point and second we have a
substantial amount of CPU power between
the two microphones is the hundred
billion neurons a computing power we
will not have for our dual processing in
foreseeable future yeah it'll be a while
and what are some of the hardest noises
to remove so in connect
we have two major enemies two major
noises we have to remove noises we know
about that's the sound from the
loudspeakers and noises we don't know
about this is the room noise the noises
from the street from across the street
etc etc and happening that the noises
from the loudspeaker are the most
difficult to remove by two reasons the
first is that they are loud gamers tend
to listen to very loud noises Chur
nice levels which you can barely hear
your own thoughts and in addition those
noises are with very broad spectrum they
are like a brick wall as in frequency
domain which means that you it's a it's
a fair game you cannot do any cheating
you have to find an algorithm which can
remove them and so you've been working
on multi-channel echo acoustic acoustic
echo cancellation since 2007 and in
hindsight it's turned out to be very
important for Microsoft what drew you to
this area honestly
doing a multi-channel or stereo acoustic
echo cancellation is a very difficult
problem even the inventor of the
acoustic echo cancellation from Bell
Labs in 1998 wrote a paper stating that
it is not possible to create a Anacostia
stereo acoustic echo cancellation since
then there was a lot of creative
research in that area and at the time it
was quite challenging so we sit and
would created the surround sound
acoustic echo cancellation which was
demonstrated during Microsoft Research
tech fest in 2008 and it was interesting
coincidence that the 30 seconds movie
clip we use it was from the launch of
Xbox at that time I had no information
about the Kinect device and what is
cooking in Xbox team but noticed that
during tech fest a colleague of mine
whom I know it's a principal architect
in Xbox team started to bring more and
more and more people this is when I met
for the first time Alex kipman without
even knowing that he is actually behind
a new and very interesting and
challenging device a couple of months
later I finished my book which was
nights and weekends project and decided
that ok now it's time to return back to
do more interesting and cool research
and then Alex kipman came and literally
drafted me to provide a set of
technologies the multi-channel acoustic
echo cancellation the microphone array
processing for a new device which at
that time was called project natal yeah
and so this also ended up in the the
product round table was that before
Connect round table was my first project
in Microsoft research at that time it
was called income this is when I started
to work for the first time on
beamforming technologies on sound source
localization technologies and I gathered
a very interesting experience actually
starting from doing research and ending
with finalizing a product and that
helped it a lot for the technology
transfers I did later yeah and so on the
original Kinect how long did you work on
that project was it
a multi-year project so for connect we I
started to work around August 2008 and
we shipped it in November 2008 in pen so
it looks like around two years in two
months and during that time I had the
challenging task to convert a working
research algorithms into algorithms that
can encode that can work in an
industrial environment in a device which
is going to be released it in in media's
mhm and then you also worked on the new
Kinect for Xbox one what did you learn
from the first Xbox that you took on to
the Xbox one project so we thought that
the microphone array and the audio
design for Xbox one is going to be
relatively easier because we already
gathered a lot of experience working on
connect device the practice always
proved us wrong when you believe that
the next step will be easier so it
happened that the microphone array in
Xbox one is way more challenging
acoustically the microphone array is out
of the device it separated and the depth
camera itself has enormous acoustical
influence the depth camera in the Xbox
one is a little is a little bit bigger
so we have two cooling fans near my
precious hyper super-sensitive
microphones and this is what basically
justified taking the microphone array
out of the device so it's a separate
block when you see the microphone array
and the Kinect in Xbox one you see the
two distinct blocks the microphone array
and the device and the depth camera but
the depth camera is sufficiently big to
do some sound reflections and this
caused a lot of problems fixing here or
there and making the microphones to
capture the sound properly and of course
we have a lot of improvements in the
algorithms which process the signals
from those four microphones and provide
a better quality sound which means
enable the user the
- port and the game designers to do more
interesting scenarios more challenging
games more interesting speech
recognition capabilities so Xbox has a
reputation for delivering lean efficient
computations for its system leaving all
the power to the game developers you
know what does that challenge look like
for you so I still believe the Xbox team
was and is one of the best engineering
teams we have in Microsoft the problem I
have to face is that those are
anonymously highly-trained its software
engineers all the procedures for
creating debugging and building the code
establish it and follow it strictly but
not one of them had for Xbox Kinect
experience doing audio signal processing
code which means that they have
difficulties to find the problem when it
is not a coding problem when it is
algorithm algorithmic problem and this
is what basically forces me to go and to
spend my fourth the four months before
Xbox Kinect release there I had office I
had desk there I was working hand by
hand and shoulder by shoulder with the
software engineers and what we tried to
do for the Xbox one is to bring people
with the proper qualification so now the
audio team in Xbox consists of four
people with PhDs in signal processing so
at least for me is way easier to work on
new algorithms and to hand over the the
MATLAB scripts and they can convert and
debug and solve most of the the problems
which are specific for this particular
implementation so in addition to
shipping products and your research
you've done 70 research papers multiple
books and you're listed on 40 patents
how what what is your what what does
your day look like that you've got your
time split between research shipping
products and doing academic things like
research papers and books
how to say Xbox Kinect converted my nice
and cool research office into one of the
focal points of a multi-billion dollar
business yeah and this means a lot of
people want to come over and to talk and
to discuss the problems with their new
projects or their new products and
especially with the trend of converting
Microsoft from software initially than
software and services and now devices
and services program the demand for
audio processing algorithm for sound
capturing algorithms for good systems
increase it because in most of the cases
those devices are small they don't yet
they they don't have keyboard they don't
have mouse so speech and speech
recognition is one of the most
convenient modalities which means good
microphones and good speech enhancement
so most of my day goes emails and
meetings so the two or three hours at
the end of the day is my time when I can
do some creative work yeah you left
academia for Microsoft Research years
ago any regrets with that you know I
never regretted that because it's one
thing to teach your students on how to
do engineering and it's completely
different to have impact a real impact
on how people leave enjoy their time
entertain themselves play games and from
this standpoint Microsoft gave me the
opportunity to make that impact and
unlike my years as a professor in the
Technical University when I know I was a
good professor I prepared a lot of good
engineers but you cannot measure the
impact now I know exactly how many
people are using my algorithms in Xbox
Kinect for example so it's not very
often I get to spend some time in a room
that's been calibrated tell us a little
bit about this room and what you use it
for so this room is the technical term
is any quick chamber which means that
there are two things happen here first
looking at those edges this means the
sound
does not reflect it just gets absorb it
so we don't have reverberations the
sound you hear is just a direct part
from my mouth to your ears or to the
microphone of the camera and the second
is that it's a quiet place one when you
close the door this is a concrete cube
which does not touch the building
anywhere else
damn the floor and we sit on this thick
layer of rubber so we don't pick the
vibrations from the building and from
the street and when you are in quiet and
non reverberant place this is not a
typical sensation for the human brain so
first we are kind of used to hear
reverberation especially the one which
is the reflection from the ground this
is a cue for distance for us and
actually when you came closer at some
point the human ear and Cas and brain
will start to sense this is two
different sounds and this is the when
the alarm bell triggers because this
means the sound source is already closer
than a critical distance in it's either
your dinner or your the dinner of death
and the second is the so from this
standpoint we're kind of hanging in the
air
somewhere very high and we're not birds
humans are not three-dimensional
creatures they're two and a half
dimensional creatures the second is
silos and our brain is used to get
information from the external world from
sensors from years from eyes from all of
our senses and suddenly one of them does
not give anything so it starts to
increase the attention towards that
sense in after a couple of minutes you
start to hear in your ears that's the
bullet in your vessels after two three
minutes you start to hear your heartbeat
Ian's body sounds from your body
how are your breathing can you start to
hear more and more of those so on reddit
people say after like 45 minutes an
anechoic chamber you go crazy anything
to that not exactly crazy but you start
to hear so-called acoustical
hallucinations because the brain is a
pattern matching machine and the noise
contains everything so at some point it
will be much to something you have heard
and the brain will classify this
and nothing more than that it's not that
scary but it's not a pleasant actually
it's a sensation and what's the longest
that you've you spent in here I can
spend hours here but pretty much doing
something there are always sounds of the
equipment instrument around the the
loudspeakers so I never basically spent
let's say one hour on purpose laying on
the floor and complete silence so try
that next we can and so you've got to
connect set up here with a kind of a
weird u-shaped apparatus around it what
is this used for so stepping aside from
this information deprivation etc etc
this anechoic chamber ISM acoustical
measuring device what we have here is a
Ark with radius of one meter with 16
loudspeakers on it and actually you can
see that they are also sixteen
microphones so this device can be used
for measuring the activity patterns of
microphones and radiation patterns of
loudspeakers so in this particular case
we have a microphone array a Kinect
device in the center of this semicircle
so the motors can basically move the the
arc and at each position you play
certain sounds from the loudspeakers and
record them with the microphones and
after 400 measurements which takes
around six minutes we can actually draw
the directivity pattern of the
microphones of canet of the Kinect
device in three dimensions and then use
those to make our beam formers to
perform better and to suppress the
unwanted sounds better and in the same
way you can put in it has been done
actually the lots are Microsoft Surface
device and to measure the directivity
patterns of the loudspeakers and to see
how we can direct the sound more towards
human which means less power and to save
some battery life etc etc so it's an
acoustical measurement tool nothing more
than that yeah what will customers
experience with the new acoustic work in
Xbox one with in
crease in developing this whole story
and transforming Xbox the challenges in
front of the sound capturing can speech
recognition and the speech enable
dialogue system erase it enormously it's
one thing to recognize Xbox play xbox
stop etc etc means a small set of
commands and it's completely different
to use speech recognition to select one
of 50,000th games one of three hundred
thousand songs or one of hundred
thousand movies and this requires way
higher quality of the capturing of the
captured sound so we can load the speech
recognizer to do its own job so the
sound isolation also it helps with phone
calls and making sure you hear people
well but it also works for the computer
to isolate and better understand that's
correct that's correct communication
scenario is one of them but way more
challenges for us now pauses having a
speech recognizer to recognize a large
amount of words and to provide the
proper out input to the user and what's
your next challenge at Microsoft I
mentioned that that that the transition
from software and services to devices
and services company poses a lot of new
challenges there are a lot of new
projects going on always there is some
microphone on loudspeaker or engaged and
of course what we want to bring is to
make the user interfaces of our
computers to be more human-like more
native more intuitive and this means
understanding better humans who is
talking what is the emotional state how
many people are they when they talk to
each other when they talk to the machine
can the computer interject in the
conversation it's something meaningful
and useful for the for the company for
the party etcetera etcetera all of those
questions one way or another they go
through the microphones and loudspeakers
because the most native way we
communicate between each other is
actually
my speech great well thank you so much
for having us over today you're very
welcome</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>