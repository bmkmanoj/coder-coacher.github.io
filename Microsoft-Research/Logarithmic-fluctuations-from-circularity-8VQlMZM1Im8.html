<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Logarithmic fluctuations from circularity | Coder Coacher - Coaching Coders</title><meta content="Logarithmic fluctuations from circularity - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Logarithmic fluctuations from circularity</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8VQlMZM1Im8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay very happy that Lionel is about to
tell us about logarithmic fluctuations
from circularity please
okay thanks about so I i gave you Val
several options for what I could talk
about and this was his choice and he
insisted I don't combine it with any
other topic because he wants to see the
full proof so well we'll see how it goes
ok so the title of my talk is
logarithmic fluctuations from
circularity and that refers to a growth
model called internal dla i'll move this
hand out to the corner so rest of them
get too annoyed I hope it doesn't bother
him too much hanging out up there what
is internal dla many of you know it's a
very simple model I start with n
particles at the origin in v2 and one at
a time each of them is going to perform
a simple random walk until it finds an
unoccupied site in other words a site
where there are no other particle and
once it finds such a sight it stays
there forever so you run n such walks in
succession and that gives you a random
set of n occupied sites in v2 and we
want to understand the shape of this
random set so here on the bottom of the
slide I'm writing out in symbols what
I've written in words on the top so i
define this random set inductively once
i have a n i define a n plus 1 is the
union of a n with a single additional
point X n of tau n where these X's are
independent simple random walks in Z 2
and tau n is a stopping time it's the
first time that this enth walk reaches a
site that's not in the set a n
so let me show you a simulation of what
this does
so particles are starting here at the
origin there's a question why do we have
two colors and I'll explain what the
colors mean in a minute essentially the
red points are the ones that join the
cluster earlier than expected and the
blue points join later than expected so
that the settee n is the union of all
the red and blue squares in this picture
and you're not seeing the individual
random walk steps but you're seeing the
results when they reach an unoccupied
site
so okay you start with set a one that's
deterministic just consist of the origin
they then inductively you define a n
plus 1 is the union of a n with one more
point and to find that point what you do
is you run a simple random walk which I
call xn because it's supposed to be
independent of all the previous walks
and I stop that walk at the time tau n
when it first exits the set a n so
that's the unoccupied site and I just
join that point to the cluster now I
have a n plus 1 okay so if if you run
that simulation for longer this is what
you get and you can see it's kind of
striking this circular so so what this
talk is about is measuring exactly how
close this set is to circular and if you
zoom in on the boundary this is what it
looks like and well you can really see
you know of course it's a random set so
you have some fluctuations on the
boundary but they seem to be quite quite
small so you have to look pretty hard
even to find a single site like this for
example which is unoccupied but all four
of its neighbors are occupied okay so
the questions you know why is the
limiting shaper a disk in and what are
the which the scale of the fluctuation
let me tell you a little bit about the
history of this problem it goes back to
two chemists weekend in deutsch in the
1980s and they imagined internal dla as
a process where you have some corrosive
particles those re random walkers and
they're diffusing in some medium and
when they when they reach the boundary
of this medium there's some surface and
they're corrosive so they edged away a
little bit of the surface and the
question they were interested in
entering is
can you use a diffusion limited process
like internal DLA in order to etch a
certain pattern or a certain design on
your on your surface and they concluded
the answer was no you you can't make any
sharply defined pattern using a
diffusion limited process because the
surfaces you get are just too smooth so
so in our model that's reflected by the
fact that these fluctuations from
circularity are very small and they were
a little bit surprised by this finding
so they wrote it it is of some
fundamental significance to know just
how smooth the surface formed by
diffusion limited processes may be and
they have this quote that really made me
smile when I read it which shows that
you know they expected like most of us
that when you ask for fluctuations of a
process that's derived from random walk
you expect some kind of square root
fluctuations or at least some kind of
power law and it's pretty clear from
this quote at the bottom that that's
what they expected so they said for them
see is the scale of the fluctuation and
L is the size of the system so they said
initially we plotted log see against log
L but the resulting plots were quite
noticeably curved figure 2 shows the
defendants of log see on log log l and
then they found a straight line and so
what that straight line is indicating is
actually the scale of these fluctuations
are only logarithmic in the system size
so parallel yes so I should say so
another impressive thing about this
paper I mean it's a thin journal of
chemical physics it doesn't prove
anything it was all done with computer
simulations which i think in 1986 is
very impressive to find this kind of
logarithmic dependence because you know
computer simulations back in other
states couldn't get to very large scale
okay so parallel to this more applied
literature there's an independent
history in in the math literature it's
not that long but you know with Moore's
law he ordered to thank you very much
you know those he was a video game where
you could throw bananas and gorillas you
know come across like cityscapes it was
also any money so somebody could you
could simulate such a process
okay how far but I teach my own food
it's a good joke here about gorillas
bananas and ideally but I'm not finding
it moving on so in in mathematician
studied this process so for its own sake
into unaware i think for a while of this
literature in chemistry starting with
diaconis in fulton who realized this
process as a special case of an addition
law of sets in DD so what they define
was a way to take two finite subsets of
ZD and add them and the the sum is a
random set whose cardinality is the sum
of the cardinalities of a and B and
internal DLA is the special case of this
operation when you take the singleton
set consisting of just the origin and
keep adding it to itself and so
motivated by this idea of diaconis
insulting law of remsen and griffith the
next year proved this limiting shape
that in fact it is a disc in z 2 and a
ball in higher dimensions so right so
this is saying if the number of
particles I start with is say the
closest integer 2 PI R squared so I
would expect it to fill up a disk of
radius R then with probability 1 for all
sufficiently large are we have that this
random set contains a disk of radius 1
minus epsilon times R and is contained
in a disk of radius 1 plus epsilon times
R and Lollar improved these bounds a few
years later to show the fluctuations are
at most order our to the one third of
two log vectors and said a more
interesting question is whether the
errors are 0 of our to the Alpha for
some alpha less than one third so that's
the question we're going to answer today
okay so the theorem which my co-authors
and I approved independently and almost
at the same time as to French
mathematicians acela and go da is that
in fact you can get these fluctuations
all the way down to constant times log R
and I write log squared here but I
should really update this slide so their
first paper had log squared but then in
a subsequent paper they improved it to
log so these are really two independent
groups of the same theorem this is in
two dimensions and you can ask what
happens in higher dimensions it turns
out there the surface is even smoother
so so there that you can get down to
square root of log fluctuations that's
right so okay so it's a question of how
you know are there really fluctuations
that are this large and actually in
higher dimensions we now know the answer
is yes the square root of log R is the
right answer so that's a recent posting
on the archive of isola and gaudy a and
in two dimensions it's still open it's
at least root log R but it we think it's
log R
okay so I'm going to try to give you a
picture of the proof so what goes into
the proof well there's an initial
ingredient which doesn't take into
account the overall circular shape and
it's just kind of a local lamb about
what happens if you zoom in at a point
on the boundary which says that certain
formations which we call thin tentacles
are unlikely to occur but then
so I thin tentacle I think I have a
picture on the next slide but it's you
know something that looks like this
where you have a point that belongs to
the cluster a and everyone see this but
not too many nearby points move on to it
so once we've ruled those out as
unlikely then we're going to in for each
direction so for each direction will
define a martingale which will detect
fluctuations from circularity in that
direction and the fact that you can't
have the intenta khals means well it
strengthens these martingale it says
that so basically the martingale is
going to be defined by summing a
discrete harmonic function over the
cluster and we're going to choose a
function that blows up at Zeta so the
fact that if Zeta is in the cluster that
a lot of nearby points also have to be
in the cluster really means that when
you some your discrete harmonic function
that blows up there it really is getting
a large contribution from all these
points near Zeta and ok I'll say more
about that and then lastly there is a
kind of self-improvement character to
the argument or maybe bootstrapping is
another way to put it so starting from
the fact that your cluster is roughly
circular you can deduce it with high
probabilities has to be even more
circular and you could keep going in
that way all the way until the log scale
and that's when this bootstrapping
breaks down ok yeah so here's the
picture of the thin tentacle so ok so
precisely what is this thin tentacle
suppose so it's a point Z which belongs
to the cluster a n but the number of
points in a ball of radius some radius
em around Z that also belong to the
cluster is small so it's less than a
small constant B times the volume of the
ball and so we show these are
exponentially unlikely in M Squared in
higher dimensions and m squared over log
m in two dimensions this is a
well either one I mean you can just
Union bound it and these are tiny
probability let's imagine it's fixed
will be fixed in the proof related how
the only the only requirement is that
this ball doesn't contain the origin so
yeah
so let me maybe comment on why you get
this M Squared in the exponent here so
if you think about you what's the most
naive way to form a thin tentacle well
here is your point Z which you want to
belong to the cluster here's the origin
and you know your cluster looks
something like this but you have to get
all the way out to Z well naively you
could just you know form a path directly
to Z and in order for Z to belong to the
cluster you have to fill in all these
points of this fat so imagine that you
have random walks that just you know the
first one visits this beginning of the
path and fills it in and then the next
one walks straight up the path and fills
in the next one so your random walks
just walk straight up and fill in these
points and it's going to take so if this
tentacle has length m that's going to
take you know order M Squared random
walk steps
to get em particles to fill up this path
in succession so just this most naive
way of building a tentacle already you
know it has this probability so you're
certainly not going to improve on this M
squared ok so now explain what the
colors meant in my simulation so those
encoded early in late points in the
cluster so we're going to measure
earliness and lightness in units of the
radius of the cluster so we'll say that
a point is M early like this point here
if at the time n equals closest injured
of Phi R squared it's already occupied
even though this point is outside the
ball of radius R plus M and likewise
this point here is l late because it's
still not occupied even though it's
inside the ball of radius R minus L
okay so these are the same definitions
in symbols that the picture showed okay
and here are the events that we want to
show our unlikely who we want to show if
m and L are bigger than a constant log n
that it's unlikely that any point in
ansm early and it's unlikely that any
point in the in this ball is l late okay
so so here's the overall structure of
the argument with this bootstrapping
self-improvement step so there are two
lemmas and they're almost symmetric so
one is that if there are no l eight
points and m is bigger than a large
constant times L then with high
probability there are no M early points
the other one is the other way around so
if there are no M early point then with
high probability there are no l eight
points but now the arithmetic is
different so you only you get some
savings here you only need L to be at
least the geometric mean of em and log n
so if you imagine applying these two
lemmas in succession and iterating well
if you start with there being no L light
points and you apply both lemmas then
you'll get that with high probability
there's no c squared log n l square root
of c squared log NL light points so and
this is decreasing until you get down to
the scale where L is constant log n so
another way to say this you know
sometimes iterating makes you suspicious
because you think secretly there's some
constant blowing up another way to say
the same thing is
suppose L and M are the maximal lateness
and earliness that occurring in any
cluster a one up through a n so these
are lowercase but they are random
variable so you have this random point l
comma M and we want to show that it
lives close to the origin so there are
no light and early points so what we can
do is say well as a first step the
cluster has to be path connected so
there can't be any extremely early
points ok so so this rectangle in green
up here is as probability zero you just
can't be you can't have an N early point
in the cluster a n ok and then the two
lemmas say that well one lemma says that
this kind of half a minute rectangle is
unlikely and the other one says that
this kind of half infinite rectangles
unlikely so you can write down a
logarithmic number of rectangles here
that are all very unlikely and and then
you get to you know this white region
where the maximal early earliness and
lightness that occurred by time n is
almost constant log n ok so so what goes
into the groups of these llamas so the
basic ingredient is a martingale which
detect earliness and lightness near a
particular or in a particular direction
ok so so fix a point in Z 2 theta and
then we're going to take a discrete
harmonic function which I'll define
precisely on the next slide but it
approximates this continuous harmonic
function which is essentially just real
part of 1 over theta minus Z so so this
is a picture it has a pole at Zeta and
its level lines are our circles
now because of so the pole at Z or sorry
the pole at zeta is really important
here because if this thing if we take
this harmonic function and some it over
the cluster or we want it to detect
whether there are points occupied near
Zeta so I mean that's the reason we take
it to have a pole at Zeta of course that
also causes problems so when you try to
make a discreet harmonic function out of
this thing you find that you can't make
it discreet harmonic everywhere in the
whole z2 so discreet her initially will
fail at a few points near Zeta which
means that if you want this process to
be a martingale then you need to stop
your particles from reaching these bad
points so we're going to define a
certain set on megas ada where our
particles are going to stop okay so this
gets slightly technical but it's sort of
i mean the details are really important
so i decided to put them in so so the
simplest case is when zeta is say
positive real so then we define H data
as just a difference of two adjacent
values of the potential colonel so the
potential kernel is this thing that acts
like the green function for simple
random walk but because simple random
walk is recurrent you need to take a
difference here so sorry in three and
higher dimensions this would be simpler
you could just delete this first term
and take so here xn is a simple random
walk so you're just counting the total
expected number of visits to the site z
okay but that's infinite in two
dimensions so to kind of normalize it
and keep it finite you subtract the
expected number of visits to zero up
till time n minus the expected over
visit Susie so okay so what are the
relevant properties of this AZ it's
discrete harmonic except at the origin
and it's asymptotics are really well
known so it behaves like constant times
log absolute value of Z plus a constant
plus a very small error term and I mean
this is kind of what all these
circularity arguments have in common is
that somewhere buried in the arguments
you're going to use this kind of
asymptotic with a potential colonel so
in our case this H data we defined as it
as you know a gradient a difference of
two consecutive values of this shifted
potential kernel which means so log
absolute value Z that's real part of the
log of Z so this H Zeta is like real
part of one over Z minus theta plus a
small error actually you do get an even
better error but we don't need it so so
that was the case that Zeta is positive
real and in general you can do something
similar where you take a linear
combination of three different values of
potential Colonel it's exactly the same
just messier
ok so i defined the harmonic function
that we're going to use now i have to
define the set where we're going to stop
and the set where we're going to stop is
essentially a ball but you know there
are lots of things that are very close
to a ball and it's important to take
exactly the right one so so the one
we're going to take is essentially a
level set of the harmonic function so
what we do is take this function which
is defined on lattice points and extend
it linearly along edges of the square
grid so now we're working with this one
dimensional grid instead of this set of
discrete points and ok and now so take
the connected component of the origin in
the set which is this grid minus the
point Zeta all the points where H zeta
is at least at one over two normals
later so what does this look like so
here's the particular example Zeta six
plus 4i ok so the boundary of this Omega
Zeta consists of a whole bunch of points
you know typically on the middle of
these grid segments where this function
H data is exactly equal to one over two
normals Ada and then it also has a de
itself as a boundary point so so the
important arithmetic here is we've
cooked up this set so that H Zeta is
discrete harmonic on the whole set and
all these boundary values are this 1
over 2 Zeta except the boundary value
adds data itself is constant order in 1
and 2 and the value at the origin will
also be important that's 1 over Zeta
okay and then because this green
function or this potential colonel has
those good asymptotics you end up you
can show that this set omega zeta is
really close to a ball so it only
differs by a constant amount in the
radio it contains a ball of radius
normal Zeta minus a constant contained
in a ball of radius not a Sega plus a
constant okay and the other thing very
closely related to this first lemma that
you need to know about this set omega
zeta is that is a mean value property so
if you take your harmonic function and
you sum it over the lattice points in
omega zeta well so use some H Zeta Z
minus H theta is 0 if H data were so you
know in the continuum if this was some
were an integral and then you would get
just 0 by the mean value property of
harmonic functions you can't expect to
get exactly zero in the discrete case
but you get something very small so only
like log of theta
ok so we're almost done with the kind of
setup and we can actually get to the
proof so the last piece of setup is that
we've got this discrete time martingale
but we really want to have a
continuous-time martingale so what we
can do is instead of running discrete
random walks we can run a Brownian
motion on this grid so
and we can define our so our martingale
was defined in discrete time by just
summing the discrete harmonic function
over the over the cluster now to make it
a continuous-time martingale we just add
one more term which is also the value of
the discrete harmonic function at the
currently active wherever they're
currently active Walker is we add the
value of the function there okay so then
we have a continuous-time martingale and
the reason we want that is to be able to
use the martingale representation
theorem which says well we can represent
this martingale and Zeta as a random
time change of a standard Brownian
motion so this time changes the
quadratic variation of the martingale so
the limit here is over all refinements
of the of the interval from 0 to n
okay so so now we can see how the proof
actually works so we want to prove this
lemma which said that if there are no L
late point the NM is like a large
constant times L then with high
probability there are no M early points
so what we're going to do is break up
the thing we want to show is unlikely
into a union of a bunch of events qzk so
qzk is the event that z joins the
cluster at time K Z's em early this here
is just a reminder of the definition of
em early no previous point is Emily and
finally no point is l late ok and now
given Z and k we're going to pick a
martingale to use to show qzk is
unlikely and so that means we have to
pick a Zeta where's the pole going to be
located and it will be located close to
Z but slightly further from the origin
so
so the picture is that we have this
early point Z and and we have our
martingale m Zeta and we're going to
place the pole here's the origin we're
going to place the pole just slightly
along the ray from 0 to Z but slightly
further along I don't know probably it
should be a lattice point so lets you
take the closest lattice point to this
okay so okay so how are we going to show
this event is unlikely well okay maybe
read the bottom line first so the goal
here where we're trying to get is a
large deviation for this Brownian motion
and the Brownian motion came from the
time change in the martingale
representation theorem so basically
we're just going to somehow show that
this event would imply that this
Brownian motion if you run it for a
certain time s it exceeds s somewhere in
the time interval from 0 to s and that's
an event that's exponentially unlikely
in s and we the time s that we're going
to take is logarithmic in n so in the
end we'll get something that's
polynomially unlikely an N okay so how
do we get there well it observed it
would be enough to show two things so on
this on this event will show that with
high probability this martingale is
pretty large and also with high
probability not that much time has
elapsed
okay so do people agree all we need to
do is show one into right so just to say
it one more time so on this bad event
we're going to show the martingale is
likely to be large and the elapsed time
is likely to be small and when you put
with those together you get that this
Brownian motion had to become very large
in a very small amount of time must've
has to be large yes
yeah so so James Ray is a good question
where do we use the no Lake point so
i'll be sure to point that out come it's
coming up so okay so why does the
martingale have to be large well
remember we have this apriori estimate
that side thin tentacles are unlikely
okay so we know with high probability
this so we've got this point Z which is
our early point and not only does he
belong to the cluster but a large number
of particles nearby belong to the
cluster specifically a constant fraction
of the area of this ball so this this
distance here is order M so a large a
constant fraction of the area of this
ball vzm has to be filled up already by
the cluster so here we have order M
Squared points in this ball vzm that
also belong to the cluster yeah I mean
it's AK and okay and how much does each
contribute to the martingale so remember
our H data was like real part 1 over Z
minus theta so it decays like 1 over Z
but like 1 over the distance okay so
each of these points contributes okay
so all the the sign is is always
positive so the negative it's in this
half plane our function is positive in
this half plane is negative for sure ah
ok because of our stopping rule so
remember we we are stopping our point
when they exit this level set Omega Zeta
that's the level set of a positive
positive number so it everything right
it's a harmonic function it's positive
everyone the boundary so it's positive
on the inside so so this ok so it means
when we run our ideal a process we will
stop a random walk either when it
reaches an unoccupied site or when it
reaches the boundary of this set omega
zeta it just stays there it could be in
between two lattice points and there
could be many particles accumulated
there and so your theorem about the
intended
which limit applies in this case
so I think we are using it for the
actual set AK but it's also true of this
modified set so yeah that's a good
question so i would have to look at the
proof again to know which that were
using it for what
yeah I mean let me come back to that if
there's time you think that it's true of
both sets okay yeah so Restless original
question is how do we know this
contribution is positive so so the point
is this function H data is is constant
equal to 1 over 2 normal Zeta everywhere
on the boundary except at Zeta where
it's or one and it's discrete harmonic
so certainly everywhere on the inside
it's not negative okay right so we're
trying to argue that the martingale is
large on this event and the point is
that because of no thin tentacles we
know that a lot of nearby sites are
occupied order em of them and each
contributes order 1 over m to the
martingale because this function DK is
like 1 over the distance okay so we get
a total contribution m squared times 1
over m so of order m okay so the one
thing we need to be careful about is how
why do we know that contribution isn't
swamped by the rest of the picture is
you know this tentacle is tiny right mm
could be as small as log in so you know
we've got a huge number of other sites
out here that are also all contributing
to the martingale why don't they just
bury this contribution and that's where
James this question comes in so this is
where we're going to use the knoll eight
points and so so the thing to observe is
that well what does no light points
means it means if I go just a little
distance inside I know that
all the sites in a slightly smaller ball
we're already occupied so this smaller
ball B R minus L is completely occupied
okay now what's the contribution of
sites in this ball to the martingale
well it's very small by the mean value
property so so this entire ball BR minus
L contributes only constant log R
because it's total contribution is the
sum of a discrete harmonic function over
the ball okay so finally well okay that
takes care of most of the points but
there's still a fair amount left so why
can't they destroy this contribution of
order M well what's the worst that could
happen so yeah this is omari functions
h8 z which is not negative yeah
so the martingale is defined by summing
so MZ de of n is the sum over the
cluster of H Zeta Z minus H Zeta 0 so
and remember that H theta 0 is 1 over
norm of theta + H Zeta everywhere else
on the boundary
so everywhere else on the boundary it's
1 over 2 Zeta accepted Zeta okay so that
means from a single point you know the
the biggest country the biggest negative
contribution we can get from this sum is
is minus 1 over Zeta okay so okay so we
only have if we we started with PI R
squared points can people see down here
no okay so
like our
m is tiny and was like potentially at
Hollis log okay so we started with PI R
squared particles and most of them got
swallowed up by this ball okay so how
many are left well about our times L
okay and so this is leftover particles
that could have a negative contribution
and but each contribute you know the
worst it could be is if it contributed a
minus 1 over Zeta okay so total you'll
get it most
yeah so this is basically minus 1 over R
so total you get at most minus constant
times L okay and remember our arithmetic
here was that M is M is larger than a
large constant times L okay so this is
this is not enough ok this is smaller
than in absolute value then done this ok
alright so that was one of the things we
need to do but we also need to know that
they're so we know the martingale is
largely also need to know that the
elapsed time wasn't was pretty small ok
well we I mean we use this I mean we use
this fact right right yeah so if you're
asking why did we have to go to
continuous time what we didn't really
have to I mean it was convenient but you
could do it without that device
okay so we want to show the elapsed time
is small and so here what we're going to
do is take this quadratic variation time
change and look at its increments and
what will show is that their independent
standard Brownian motions such that
these increments are bounded above by
the exit time of these Brownian motions
from a certain interval
so what's going on here is is pretty
simple so we're going to
see well what happens if we look at so
inside this time interval from i to i
plus 1 that's when we just have a single
particle walking around it hasn't yet
found an occupied site so if we take you
know em so I is an integer time and t is
in interval 0 1 and we look at the
martingale at time i + t minus at time I
that's just the value of this H theta
add the current current location of this
so i write beta t for the Brownian
motion on the grid okay and then i use
the maximum principle for discrete
harmonic functions so i know i don't
know where this Brownian motion
currently is but I know it's somewhere
inside the set Omega Zeta so this H Zeta
VT is at most this is really bi T it's
the ice Brownian motion so it's at most
this bi and at least this AI where these
are just the min and Max over there over
the current cluster so this is by
maximum principle
that means the agenda
no I did need to put boundary because
except for Zeta yeah so you know what
these guys well okay that's for Omega
Zeta they're the same but this is over
the this is 12 boundary of this random
set a I so we haven't oh so the passing
values are all different or a I ok but
the point is because H data is harmonic
on AI because AI tilde is always
contained in omega Zeta then the maximum
and minimum were a tilde are the same as
over the boundary by the maximum
principle ok so this means that you know
if you combine this with be you know em
of em of T is B of F of T so I
martingale is this random time change of
Brownian motion so it's saying that
so AI so if i take B of s of T plus i
minus B of s of I that's bounded between
AI and bi so that says if I take so I
want to come up with these independent
Brownian motions I should take this be I
to be you know bi of you is B of s of i
plus u minus V of s Li and that will be
bounded between AI and bi and these are
independent for different I by the
strong lock of property so yeah so
that's all that's going on basically the
maximum principle okay and right did at
this point you could ask why you're
using now it's usually get more
difficult because you're easy
so this point you guys what's the bend
there is in Brownian motion
I guess the benefit is it's easy to
control the large deviation of the first
exit time of a Brownian motion from an
interval so right i mean we want the
influence of the martingale to
right so okay so to prove this bounds
you had to work slightly harder because
of the Brownian motion but now the
payoff is now we just have to do a large
deviation for this simple
one-dimensional thing about Brownian
motion exiting from an interval and
that's something relatively
straightforward so so particular you
could show that a expectation of e to
this exit time is it most 1 plus 10 a B
we're in PR d minus a B or the endpoints
and okay so then writing the time
changes to some of its increments that's
bounded by this product of expectations
of e to the Brownian exit times and
okay and then it's relatively easy to
estimate this AI and bi and what you get
out of this is that are on this event
queue so this expectation of e to the
quadratic variation x indicator of q is
it most growth in most polynomial in n
great and okay and then buy more curves
inequality you get this
okay so I showed you the proof of one of
the two lemmas the other one
superficially looks very similar it's
all the same ingredients maybe I cheated
because I showed you the lemma that
doesn't give you that extra savings that
makes the whole thing work so I can try
to go through that but in case I run out
of time with that let me just say what
changes in higher dimensions well you
have to choose a you know this function
H say that looked like it was using some
complex analysis with this one over Z
but really what what we're using is
something like the boss on colonel so
it's like the discrete force on colonel
so essentially the function where the
harmonic function we're using is you
know one at the point data zero at all
the other boundary points and take the
harmonic extension of that so that's
what you can use in higher dimensions
and when you go to estimate the
quadratic variation you find that it's
actually constant order in higher
dimensions instead of logarithmic and
what this means about the fluctuations
is there dominated by a different effect
so rather than having kind of large
portions of the boundary that are a
little bit further out or further in
then you would expect it's really these
tiny features that are dominating the
fluctuations within thin tentacles which
as we saw at least heuristic we can grow
to this length square root of n by this
very simple mechanism of traveling
straight up every time and that so
that's formalized in this paper of isola
and Gotye to show that actually do get
fluctuations of order square root login
in all dimensions and this leaves a gap
only in dimension to where we believe
that the fluctuations are log n naught
square root of log n but the lower bound
is still open
I've stop there and if you really want
to see lemma 2 I can do that thanks
yeah so what is the strategy that the
other people use okay um I mean I can't
say I read the paper line for line but
roughly what they seem to do is define a
different process whose fluctuations are
easier to handle and then construct some
complicated coupling between that
process and I dla so the difficulty of
that paper is in verifying with coupling
and that portion of it I have no real
insight into that I won't say anything
further about it for the equivalence is
full
yeah d equals one right because this is
a fun exercise that fluctuations their
square root of n
as the other question right so is the
login to maximum awesome right so okay
right so another way that you could try
to analyze the fluctuations instead of
being very picky and asking for the
absolute farthest lattice point that's
that's occupied or the absolute nearest
it's unoccupied you could sort of take
local averages and and then we can show
that the fluctuation scale to a variant
of the Gaussian free field so okay so
the question is you know is this log
that we're getting related to the
maximal Gaussian free field I mean I
think morally the answer is yes but
I mean when you say the fluctuations
converge to do affect a world scale so
we proved it on the you know constant
order scale so you really are averaging
over a constant fraction of the picture
but maybe it's true on smaller scales
and that's you know maybe that's what
you would need to look at to answer your
balls question so I guess I'll mentioned
related to that is another question
which i think is still open although
that most recent paper of isola and
gaudiya it does say something about it
which is fluctuations in a fixed
direction so so what we found it here
are fluctuations in the worst case
direction suppose you just look along
the x-axis and you want to know you know
what's the farthest side along the
x-axis that's occupied so okay so we
believe the answer there is square root
of log in two dimensions and I think a
solid idea have one side of that but not
the other so
PS confident entire system picture for
the gospel right
I just want to make sure I understand
what you were saying about averaging got
something good in this picture you have
positive and negative color but its
energy colored by the number and an
average instead you have that's
interesting yes so the thing that scales
to go see if we field is you take this
picture but you shade it red or blue
according to how late or how early the
point arrived to the cluster</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>