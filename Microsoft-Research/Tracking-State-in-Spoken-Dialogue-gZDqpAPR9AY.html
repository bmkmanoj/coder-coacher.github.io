<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Tracking State in Spoken Dialogue. | Coder Coacher - Coaching Coders</title><meta content="Tracking State in Spoken Dialogue. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Tracking State in Spoken Dialogue.</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gZDqpAPR9AY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
I'm German O'Shea and this is gonna be
more of an applied talk than most of you
as we've heard today it's also I'm also
more of a messenger that this is
reporting on work that's been going on
over a over a few years both at the
dialogue systems group at the
engineering department and also now at
folk like you which is a start-up based
in Cambridge and generally it's about
it's about dialogue systems and using
neural networks to track what people are
talking about when they're having a
conversation with with with a computer
so a dialogue system is a kind of
essentially kind of voice interface for
a computer application
and whereas most voice voice based
interfaces that are out there at the
moment are kind of one-shot interfaces
where you say something and hopefully
the computer goes off and does something
if it's understood you correctly and I
thought in a dialogue based interface
the idea is that it's more of a
collaborative process that you say
something the computer tries to work out
what you want maybe it makes us some
suggestions maybe asks for more
information and it's and together you
kind of hopefully achieve some goal
which is that the computer does what you
want what you wanted to do so this is
just an example of a dialogue system
which is set up to help people help
people find restaurants in Cambridge and
user starts off with with a vague goal
that they might want to get Chinese food
computer says well we've got a couple of
Chinese restaurants let's try and work
out exactly what Chinese restaurant
suits your suits your goal initially the
user says I don't care about how much it
costs system makes a statement and user
kind of remembers that left or well I
think up 10 pounds in their banking
some things actually I need something
cheap visa says okay well okay it makes
some sort of update of what they think
these are once and then eventually make
comes up with a suggestion that seems it
seems to be implicitly accepted by the
user and then the user can kind of ask
ask for a telephone number or the
website or something and there's a
couple of things going on here obviously
it's a natural language understanding
problem need to work yeah we assume that
there's some underlying database that
that the system is able to query but it
needs to be able to work out well how to
map language on to on to it on to a
query and it's got to be aware of the
context these are says I don't care well
what does these are not care about it's
got to be able to or what's the
telephone number it's obvious to us that
was the telephone number for North China
dumpling but system has to it's some
sort of context awareness and it's also
got to be able to update update beliefs
in any in a in a rival way initially the
user doesn't care about how much it
costs but then changes his mind so this
is kind of the kind of data were we're
gonna deal with in this talk and kind of
application we have in mind so this is
kind of a standard slide that appears in
most talks about dialogue systems which
is this is the the top level view of
here all the different components user
inputs in by talking to the system that
has to go through speech recognition
then the speech speech recognizer passes
on so the speech recognizer is uncertain
about what the user has said so it's got
a number of hypothesis switch its assign
probabilities and then what people in
the speech community called or an entire
community called dialogue stay tracking
and in NLP community it might be called
kind of a kind of semantic parsing or
semantic interpretation that's what this
talk is gonna be about mostly but then
there are other components once to use
it once the system has decided this is
what the user wants the the dialogue
manager has to decide what to do next
so if it knows and it can also talk to
what we to this underlying ontology or
knowledge knowledge base or data base
which is so the dialogue manager might
receive the information that the user is
looking for a Chinese restaurant and
then it goes in a Scientology well do we
have any Chinese restaurants and based
on that it's going to decide what to do
next
so it might find it well there are five
Chinese restaurants some of them are
expensive and some of them are cheap so
then it decides ok let's let's generate
let's find out what price range the the
the user cares about so it's and it kind
of comes up with a scheme attic
description of what the response should
be then that has to be converted back
into natural language and then that has
to be converted into kind of an output
speech signal so as I said today I'm
just going to be talking about this
dialogue state tracking component so the
way we we conceptualize the problem is
that at each that we have we have on the
Left we're just gonna run through the
incrementally run through the utterances
that the user says and then they're
right where we're gonna keep track of
our belief a bearish wash what the user
actually means and in reality well this
is good to be kind of the gold standard
ground truth labeling in a real life
system we are never certain and we have
to maintain a distribution over over the
state of all possible interpretations so
the user starts I want to get Chinese
food and this is annotator does it's the
user is informing zazz it it's kind of
kind of it
we use these slop value pairs where
there's a food sloshed on it it's filled
by the value Chinese and system says
something back then the user says I
don't care and by looking the dialog we
know that this this means that user it's
telling this is saying that it doesn't
care they don't care right price system
makes an offer user changes his mind so
at this point we have to update
representation of the goal of the belief
system makes an offer and then the user
makes a request of the phone number so
the task is the the task that we're
trying to learn to do is to uh to map
from from an utterance at in a certain
from the utterance in a certain position
in the dialogue to this state space
state representation at at any point and
it this this is I'm in this top we're
just going to assume that the state is
consists of informs which are basically
constraints on slot values so that's
over
so for each slot we have a distribution
over all the possible values for that
sloshed kind of categorical distribution
and for each of the attributes in the
database they're either requested or
they're not so you could you could out
there well when I get to talk about the
data yep so in the dialog here the
system talks about a concrete question
but it doesn't seem to be reflected in
your state yeah that's so there is and
yeah that's kind of an assumption of the
state representation so for so the other
in this stated dialog state tracking we
only try to interpret what the user says
but obviously in the in the dialogue
manager it also know it already it knows
that an offer has been made and that's
going to help it and those as we'll see
though knowledge about what the system
has said is also useful as features for
for predicting what it is that the user
has said they're here so what what makes
it so people have been working on this
problem for a long time here and there
are lots of proposals out there for how
to build dialogue system so there are
just some ideas about what what what
would be useful in the what are the
useful desiderata for a robust
deployable
state tracker so to be realistically
useful in a deployed application
it's got to be incremental we've got to
be able to we've got to be able to
update the belief state after each
utterance we can't just do kind of batch
prediction and obviously to interpret
properly we need to have some awareness
of the dialogue context we'd like a
model that's trainable it's not given
more data we can improve performance and
ideally we would like something that is
as portable as possible that's not not
tied to us to a specific ontology
that can possibly you can take it they
can adapt quite easily if the ontology
grows but also maybe some things that we
could take out of one application and
put in another application so the idea
that one idea it so the idea that's that
we're going to talk about in this talk
which it's not the only way you could do
this but it seems to be a reasonable way
is to treat a dialogue as a sequence of
turns so essentially it's a kind of
sequence labeling problem with a
slightly structured space for the labels
and pick your favorite sequence labeler
but one what idea is to use recurrent
neural networks and the idea is this is
kind of a simple neural network for the
single hidden layer and the idea is at
each turn we take in input which which
is essentially input layer consisting of
some features we we learn to map that
onto a hidden layer and then we learn to
to map that hidden layer onto to output
- there are two components in the output
space one is the belief stage which is
essentially a probability distribution
over beliefs about what the user is
looking for and then firkin turn for
could be
we also have what we're calling a memory
which is just a vector of real numbers
which which is only for further
consumption of the of the of the system
it doesn't have any interpretation
outside the system but it allows it to
store some information about what's
going on and as a recurrent Network at
at each turn apart from the first weave
we take in the output components of the
previous turn as essentially as features
and what are those features pretty
simple pretty simple we've got some
features about what the system has just
asked or said if the system has just
said here's a really good restaurant
it's called seven days then we want to
encode that as a feature if the system
has said what price has asked what price
range the user is looking for then
that's another kind of useful feature
and then kind of very standard things
you'd expect we just we take we extract
ngrams again because we are dealing with
speech recognition where there is
uncertainty about what the user says we
have to waste these engrams by there a
period where a peer by the probability
assigned by the ASR to the to the
sequences they appear in so if it's I
want Chinese food here are some engrams
you might you might expect maybe the
user didn't say China's food but it
appears in one of the ASR hypotheses and
then we have an idea of tagging which is
essentially looking up the ontology for
for for Strings which match which match
on two entities or attributes so for the
purpose of this talk we're just gonna
assume we're doing exact string matching
obviously people don't always use
exact the exact name of an entity to
refer to it so here we we have so in the
in the first tagged Engram we've taken
the Engram want Chinese food and pointed
out that well we know the Chinese is a
value for the slot food and we know that
food is the name of of the slot food and
then we you run through all possible
taggings to extract C's tagged engrams
and then because I said before we are
may be interested in portability you or
domain adaptation and so then it can be
useful to extract D lexicalized features
which essentially say I think the
intuition here is a subject if I say I
want X and we know that X is something
in our ontology and that's a pretty
clear signal regardless of what what X
is and putting all together this is we
essentially just put it putting down in
equations what the what was shown in the
neural network schematic we does some
kind of sigmoid non-linearity in the
hidden layer but apart from that it's
all pretty straightforward we have well
except we have two models one is just
based on well these D lexicalized
features for a given slot so what once
we take in an utterance and we check
whether it contains any terms that
appear in our ontology we want to work
we want to assign that tag as score and
that can be done without actually caring
what the tag is and that's done in the
first model and the second model we
actually say well we're just gonna feed
it we're just gonna map the entire input
into a hidden layer and then we're going
to learn a mapping from the hidden layer
to all possible values so if there are
three different price ranges then we
learned three sets of mappings from the
hidden layer two to the output layer and
that those parameters are
- to a fixed ontology so not so portable
but they do give better performance when
you know exactly what when you're able
to train on the ontology on the
application that you know you're going
to be testing on um as I said before we
have the states contain kind of goals
which are distribution of where values
for a slash and that's so we we do
sigmoid transformation of the scores for
that our soft max flush and requests are
surgery binary binary elements of the
state did they ask for the postcode did
they ask for the telephone number did
they ask for the address the data using
experiments or come from what's called
dialogue state tracking challenge
it's about 3,000 data 3,000 dialogues in
the data search which were collected
from through Mechanical Turk again in
this idea of having a restaurant
information system for Cambridge and
there are there are four kinds of goals
the user might be looking for it can ask
for a specific fruit food specific price
range specific area a specific name and
then there are a couple of of other
attributes which they can request
information about so yeah Matt Henderson
who specially student at the engineering
department is hosting the data for that
um training standard kind of set up for
training a neural network was a security
under sense we do l2 regularization on
the parameters and the training proceeds
in in four stages one to get kind of an
unsupervised stage using denoising
auto-encoder then there is a shared
initialization which uses the de
lexicalized features to Train a single
model for all slots so or so it's a kind
of a slosh agnostic model so this is
something that you could plug in
anywhere and then we you specialize it
by learning specific sets of parameters
for each slot in the ontology and then
you can learn
lexicalized model which encodes the set
of value the exact set of values in the
output space and random initialization
and so on so all the results are
averaged over 12 runs um the baseline
from the DST sea challenge is the blue
bar it's the top they had a couple of
baselines is the toughest baseline it's
pretty well so not quite so dark but a
pretty good system and on the Left we
have accuracy higher is better on the
right we have a kind of an l2 distance
between the true late labeling which is
kind of a peaky distribution and the
district probability distribution
produced by the by the tracker it's in a
maths paper yep it as you can see we're
doing pretty well we were I think at the
l2 metric who was the best in the
competition and it was second best on
accuracy um so yeah thanks for listening
said lots of people involved I have a
question why not a GP as I said you you
it it's in a sense it's just a secret
it's a sequence labeling problem with
the structured output space so you could
pick your favorite algorithm I guess
some sort of inertia they work well I
mean three other questions okay so thank
you very much each year Microsoft
Research hosts hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>