<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning - Leon Gatys | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning - Leon Gatys - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning - Leon Gatys</b></h2><h5 class="post__date">2016-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bDMoidWc0ZI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright it is my pleasure to introduce
longer teeth Leon is a PhD student in
Machias patek backhands lab into bingen
and his PhD is about using cnn's and
linking them to biology and today he's
going to talk about how to use cnn's to
transfer style and thank you yeah thank
you very much for the kind introduction
so i'm leon i'm very happy to be here
today and talk to you about a neural
algorithm of artistic style which is
joint work together with alexander acre
and my supervisor matthias vodka at the
university of tubing so in our work we
use a pre train convolution in your
network for image processing so there's
actually no learning involved and in
particular we use the convolutional part
of the 19th arggg network so we all know
that when we show an image to to a
convolution to a conf net the the
information about that image is
represented in the different layers of
the network in terms of the feature maps
and actually each feature map is just a
filtered version of the input image so
for the purpose of this talk you can
think of a CNN just as of a multiscale
nonlinear filter bank now and we can
visualize the information that is
preserved in the in the future maps in a
particular layer of the network by
finding a new input image that produces
the same feature responses in that layer
and if we do that in the in the lower
layers of the network we sort of get
back to the original image whereas when
we go up to the higher layer we find
that much of the information about the
detailed pixel values is lost but the
information about the content of the
scenery and the objects in the scene is
still preserved and there's actually a
cvpr paper from this year about that by
andrea better this group that goes more
into detail
now we have a paper at this conference
where we show that if we not constrain
the extra feature activations but the
correlations between feature maps and a
number of layers we get a pretty good
model of natural textures so if capital
F is a matrix that is a matrix of
feature maps in a particular layer so
each column is a vectorized feature map
then we just take a matrix of inner
product the matrix of inner products so
correlation matrix where each entry is
just a dot product between two vectors
feature map to transform the feature
matter to transform the feature
presentation into a texture
representation that has lost all the
information about special about the
spatial content of the image and if we
do that in a number of layers of the
network and we then find new image that
matches this texture representations we
can tell we can basically get a
texturized version of any input image
now to perform artistic styles ver what
we will do is we will extract the
texture information from painting and
the information represented in a higher
layer of the convolutional neural
network of the photograph which
basically preserves the content of the
image and we will combine both of these
both representations into a new image
that actually combines the style of the
painting with the content of the
photograph so how is that done in
practice well we first show the painting
to the convolutional neural network
compute the feature map activations in
response to the painting and get the
correlation matrix on a number of layers
of the network then we show the
photograph to the to the neural network
and we compute the future activations in
response to the photograph and then we
shall white noise image to the network
and basically compute the correlation
matrices in response to the white noise
and compare those with the correlation
matrices in response to the painting and
we do that on a number of layers of the
network
and get a loss function that is just a
linear combination of the the loss
functions in the individual layers that
basically measures how far away are is
the style or the the texture of our
image that we generate from the texture
of the painting and then we basically at
and then at the same time we compare the
actual feature map activation and
response to the white noise with those
in response to the photograph and then
we get a total loss function there is
just a linear combination of this loss
function that that measures how far we
away from the style of the painting and
that the and the loss that measures how
far we away from the content of the of
the photograph and we can we can then
just use the usual optimization
procedure of convolutional neural
networks and compute the gradient of
this loss function with response to the
feature mcmap activations in the conf
net and use a standard back propagation
procedure to obtain a gradient with
respect to the pixel values now we can
use this gradient just as the input so
this just gives gives us a function
value and the gradient with respect to
the pixels and we can use that as input
to any optimizer and perform gradient
descent on the on the input image and we
can do that until we converge to a very
small loss and basically obtain an image
that simultaneously minimizes the
distance from the style of the painting
and the content of the photograph and I
prepared a movie to have a look how this
image generation works in practice so we
start from the white noise and we will
now see the gradient descent on the
input image to then generate the new
image
and so we can see that basically the
network start with matching sort of the
the low leather features and the color
map of the of the painting and then they
gradually gets the content right of the
of the photograph and now we see the the
gradient descent is almost converged and
we can just give through a few steps and
you see the the painting basically
doesn't really change very much anymore
but yeah so I will basically we we end
up with a yeah with a with a new image
that combines the style of the of a van
Gogh painting in this case and the
content of the nips poster now I just
want to make the point that this is not
only constrained to artistic style
transfer but we can actually also apply
this technique for for general style
transfer so here I have a picture of New
York by night and London by day and so
we can use the sty transfer technique to
turn the image of london by day and to
an image basically by london by night
and with that i think i wanna leave you
with a few impressions of my university
town tubing basically in the style of
several painters and i guess some of you
already seen these images but i think
it's nice to show them anyway so this is
a photograph of tubing so this is
staring I'd this is Picasso and so so
many or not many people actually know
that all the great artists have come to
tubing and faint this so this is smoosh
the scream so this is a bit older this
is Turner so tell
I went to achieving on a very stormy day
apparently and to have something more
abstract this is Kandinsky yeah and with
that I want to end and I want to thank
you very much for your attention and if
you're
and if you're interested in trying this
out yourself you should check out d
parte oh and you can upload pictures
there and if you want to see more
examples of textures you can check our
website thank you thank you I'm you're
sure so why not initialize from one of
the two images oh you can do that as
well it doesn't change very much I like
the initialization from white noise
because there you can basically sample
many different versions of the of the
same image right if you initialize where
the deterministic seed then you always
get the same image but it's true that if
you initialize some photograph I feel
that usually the pictures look maybe a
little bit nicer but the pictures I
showed you here I think they were
initialized from white noise yeah yes
hey have you explored an analogy for
texts such that it's possible to let's
say take an author take a style and put
some other content on there so we
haven't done that I have seen something
online where some people tried it didn't
look very impressive so far but I I
guess like if you have the right network
architecture it could work I you have
never worked with all your data so I'm
not really sure yeah any other pie yes
uh have you tried building a generative
model of the covariance matrices of the
features in order to try to generate new
styles so I looked into that or I'm
looking into that it's not it's not
completely straightforward because
you're not really so you can't be sure
that any that they actually exists
images for any covariance matrix you can
sample right so it might be that
actually in this texture representation
space it's only a point cloud of the
examples that you that you get when you
get when you input images right and
there's no that there's no smooth
manifold that you could model with the
with the density model so but it's a
very good questions and we're looking
into that yeah last question hi how do
you explain that taking the covariance
matrix captures the style so I think you
should so so you you have to think about
as texture modeling so it's really like
a texture transfer algorithm and so the
the fact that spacious summary
statistics on feature responses captures
texture very well that's sort of it's
it's it's not super surprising that it
works so well with deep networks that
are trained on object recognition is
very interesting but it's just a
spacious summary statistics so you can
also the simplest way case would be just
taking the mean feature map and that
already works sort of well and that's
just the second order thing and that's
that works really well yeah I mean it
reminds me were all the work by
simoncelli he got solutely using wavelet
teaspoons and this is a number
remember exactly yeah yeah very last
question I really like her work and
actually launched your algorithm on
WeChat but due to lack of money we
didn't continue with that but we attract
a lot of users a lot of them are boys
using the using algorithm to depict for
their girlfriends so one of the problem
we found is that for four faces is kind
of distortion and a lot but minor
suggestion is that if you don't pick a
specific a later for content but you
only pick the higher of the lower level
first for a couple of iterations and
then change to a higher level it
actually will make the the faces and the
textures even more clear and with a
better shape yep yeah I you've done some
experiment as well I saw you to see use
a single layer of the content activation
so I've tried using different layers for
the content and i found a cruiser to
take higher layers for that i think with
faces in particular it would be super
interesting to use network that i
actually trained on face recognition
because this network is trained on
objects right and and i think an image
net they are not that many faces in on a
large scale so yep but thank you very
much yep thank you let's thank Leon
again thank you
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>