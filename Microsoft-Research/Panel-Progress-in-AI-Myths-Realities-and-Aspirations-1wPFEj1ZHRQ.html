<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Panel: Progress in AI: Myths, Realities, and Aspirations | Coder Coacher - Coaching Coders</title><meta content="Panel: Progress in AI: Myths, Realities, and Aspirations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Panel: Progress in AI: Myths, Realities, and Aspirations</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1wPFEj1ZHRQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next have a panel to tell us about
what's happening in the world of
artificial integers the progress discuss
the myths and realities to do that who
better than my dear friend and colleague
as a moderator Eric Hurwitz Eric come on
out Eric's of course dr. dr. which you
know and he's also the head of our
Edmond research lab and I call him mr.
AI because he's been with the field as
long as in EFS was the president of
American Association of artificial
intelligence now back again Eric well
thank you very much and let me just
might my guest our panelists today come
on out
welcome to the panel on progress in AI
myths realities and aspirations our
guests today include Christopher Bishop
distinguished scientist Microsoft
Research on your on your right and next
to him Oren Etzioni chief executive
officer of the Allen Institute for AI we
call that AI to push water around here
in the northwest faith daily associate
professor at Stanford University Michael
Wittmann professor of computer science
at Brown University and Josh Tenenbaum
to my left professor at MIT beyond our
panelists of course we have many experts
in AI in and related areas scientists
with us in the room here today and I've
asked the panelists and I'll ask this
audience to think as well today as we
reflect together several framing
questions where are we today with hype
versus reality on the path to developing
richer notions of machine intelligence
along the lines of what the founders of
a I dreamed about in the 1950s where
will we be in 15 years
what are the biggest standing challenges
what are your best guesses on the
technical and programmatic paths to
addressing these challenges
I'll start by Framing discussion just a
bit with some comments on progress in AI
so I view AI as the pursuit of the
scientific understanding of the
principles and mechanisms underlying
thought and intelligent behavior and
their embodiment machines and the field
has its roots as many of you know
in the early work of Turing and church
on computability and a later work by
Turing and Vannoy Minh on the notion of
a universal computing machine which lit
up imagination about what we might do
with these machines including building
minds one day the phrase artificial
intelligence was first used in early
1956 in a very prescient proposal time I
refer that to folks to read all the time
for a workshop on machine intelligence
that took place that summer at Dartmouth
and in a beautiful document the
co-authors called for research on
machine methods of forming abstractions
from sensory and other data carrying out
activities which may be best described
the self-improvement manipulating words
according to rules of reasoning and
rules of conjecture and developing a
theory of the complexity for various
aspects of intelligence now things moved
quite fast at the outset and there's a
great deal of optimism about where the
field was going in 1965 herb Simon I
mentioned to many of us said that
machines will be capable within twenty
years of doing any work a man can do two
years later Marvin Minsky predicted
within a generation the problem of
creating artificial intelligence will
substantially be solved that would have
been the 90s now on the one hand we've
made great progress over the decades
there's been a palpable upswing lately
we've sought some examples in the first
session of today and this work has been
largely fueled by the explosive increase
in the availability of data and
computational power and of course some
some good ideas we've made progress
especially on building out narrow OLAP
but I referred to as deep but narrow
wedges of competency such as work on the
Mosel classification prediction ranking
working vision and speech recognition
and natural language processing and
these advances have quickly found their
way into our products and the products
of our competitors and indeed are
defining a shared competitive landscape
now for success in industry
on the other hand it's been a slow slog
on the dream of building machines that
show the kind of deep more general
intelligence exhibit exhibited by people
I am sure the founding fathers of of AI
would likely be rather taken aback if
they saw where we were in 2015 about our
understanding of the magic which is
still called magic behind human level
abilities to reason learn understand
with the common capabilities and the
common sense that even small children
have one might even say that that idea
six proposal if properly reformatted it
could be resubmitted to the NSF or DARPA
today and we'll probably get some
funding by some excited program managers
even though the progress on building out
deeper intelligence has been slow
researchers do have fabulous intuitions
they're working on the things that
excite them the most on the path to
answering some of the bigger deeper
questions on the challenges and
frontiers and how we might get to the
next level and this is why I've invited
these particular folks up today to help
us as guides in a sextants in where to
go next and so I each just share five
minutes of reflections and then we'll
open it up so Chris why don't you go
ahead okay thanks all right so I guess
maybe a good place is my microphone
working by the way okay great so I think
a good place to start is just just to
acknowledge the fact that this has been
a tremendously exciting few years and
we're living in a very very exciting
time and obviously one of the reasons
behind that has been the spectacular
successes in a number of problems as
eric has already hinted at in in the use
of neural networks and so-called deep
learning and I'm actually a big fan of
neural networks I I started at my career
in physics and I switched into computer
science in what you might call the
second wave of excitement and in neural
networks around the sort of late 1980
and I thought there's a really great way
to approach artificial intelligence by
learning from data and today we're in
the third wave of excitement around
neural networks and as Erica's mentioned
there are really three factors behind
this behind the fact that we can have
much better performance now and a whole
range of tasks than we would have had a
decade ago so one of the factors is the
availability of huge amounts of data
compared to what we had in the in the
1990s the second is a huge increase in
in compute power compared to what we had
back then and then also some I think
relatively minor but important technical
advances so really the whole idea of
deep learning deep networks has been
around a long time I wrote a textbook on
your networks which was published 20
years ago
and there it talks about multi-layer
convolutional neural networks for
invariant object recognition but today
we have systems as some of some of the
other panelists have developed which
have really human level performance on
many of these tasks now the fact that
we've been able to take some of these
20-year old ideas and accelerate them
through more data more compute and a few
tweaks to some of the the algorithms
means that maybe some of those other
ideas that have been around for a long
time could be right for big advances so
I do feel the next few years is
tremendously exciting for the field of
machine learning and I guess I'm sort of
implicitly assuming that the machine
learning is going to be the thrust of
our approach to artificial intelligence
maybe there are other ways we should
approach this but I think machine
learning will be at the heart of it and
I'm sure neural networks and deep neural
networks will be components in any
larger a more capable system that we
build so what we kind of nearly done are
we nearly at AI well I think not and and
deep neural networks and similar
technologies for all their advantages
they have a lot of limitations so one of
them of course is that in standard
approaches they're trained using label
data although data is plentiful the
labels typically are not often the
labels are obtained by humans perhaps
hundreds of thousands of hours of human
effort to get those labels whereas the
human brain seems to learn mostly from
unlabeled data you know kids crawl
around the world and they just sort of
take all this stuff in and occasionally
mum and dad says oh that's a cat that's
a dog you don't have to see 27,000
examples of a cat before you begin to
get the idea of what a cat is so there's
something something that we're missing
in those in those techniques and I and I
guess I'm fast running out of time but I
have a few thoughts on what the next
steps might these are a little bit later
we can we can talk about some of those
so in terms of where we've got to where
we're going to get to I actually think
we've made a very big advance in the
last five years towards artificial
intelligence in a general sense and by a
big advance I would guess we're sort of
we with 2% of the way there compared to
where we were ok so 50 more of those big
advances and I think we'll have
something pretty exciting
great well you came in under time so
orange excellent thank you I'll take up
his his exercise Eric runs a tight ship
we're not allowed to use slides I have
some notes and I say that several folks
on the panel said well no slides I'll
just do some some dancing on the stage
physical activity I was planning on it
yeah so I very much agree with what
Chris said about a we're in the midst of
what's called AI spring and that's where
I can't show you the slides and that was
my spring dance and and secondly that
this AI spring and this Big Data
paradigm not just neural or more broadly
machine learning algorithms has some
very clear limitations and I just want
to take that theme two steps further so
again as he said we need label data
often we don't have it that's a
wonderful computer science problem
whether it's Mechanical Turk or distant
supervision there's a variety of
techniques for getting more
semi-supervised learning getting more
learn data I would say that that's not
enough to me a lot of what AI is going
back to herb Simon is the study of
problems that are very hard to formalize
or maybe even impossible to formalize
directly so I feel like once we've cast
it as a technical machine learning
problem once we've identified the
objective function and all we need to do
is solve the optimization can still be a
very hard computer science problem and
actually that's a great thing for us
who's collaborating with you know folks
like Jeff Dean and Google and
others right who come from different
backgrounds and help us scale our
methods it's a wonderful success but but
many of the most fundamental problems of
the eye we don't know how to formulate
the objective function in the first
place so the problem that we're working
on at the island Institute is really
taking AI Grand Challenge problems and
figuring out how to map those two
technical computer science problems case
in point the problem that's near and
dear to my heart is machine reading very
simply take a textbook say in biology
read the chapter in the book and answer
the questions in the back of the book
okay very very hard to turn that into
any kind of reasonable optimization or
machine learning problem I mean you it's
it requires a lot more decomposition a
lot more formalization to do that it
doesn't just reduce to a simple vector
and actually I do think that you know at
AI we've had these kind of hype cycles
over our expectations while I love deep
learning methods I do worry when you
start to see terms like I saw recently
thought vectors where you were again
we're verging into the hype cycle
because thought is not something that's
expressible as a vector okay it's just a
little bit more complicated than that
it's a tosser you know a few more
dimensions there but I like where you're
going the the other point that that I
wanted to make and again actually just
to stay with the greats
I thought Allen will put it incredibly
well when he said you can't play 20
questions with nature and win you can't
reduce AI intelligence to a series of
binary or even probabilistic
distinctions it's just more complex
requires reasoning requires
formalization require mapping from say
how we think about things how we think
in language or in images to more more
formal structures anyway that's that's
what we think about I want it to use my
remaining one minute or so to also talk
about the whole fear thing right there's
a lot of concern about AI more broadly
in the popular
be right with you know with movies and
and so on but also even within the AI
community right they've been various
thoughts and useful discussions about
how do we think about the threat of AI
and so on and I guess my specific
thought on that is that I really want to
emphasize the benefit of AI the
potential benefits so when we think a
thousand or a million years ahead it's
very easy to speculate but if I think 5
10 20 years ahead what I end up with is
with a quote from somebody that I really
admire who said it's the absence of AI
technologies that's already killing
people through errors okay and that's
quote from my friend Eric which I really
think captures the fact that if we think
about AI in a rational way as opposed to
emotional way we need to weigh the costs
and benefits in the risk let's not
forget about the benefits and when did
those come from better academic search
engines or whether those comes from cars
that will reduce you know intelligent
cars that will reduce the number of
accidents on the road or you know help
in accessibility there's so many AI
systems that can really make a
difference and help us and then people
ask well what about the distant future
and my last line I want to quote from
John markoff's upcoming book he has this
great line and he says don't mistake a
clear view for a short distance we have
a clear view of where to go I see in
this room intelligent beings it's not a
short distance by any means thank you by
the way on the subject of thought
vectors in this terminology back in the
1990s you probably remember there was a
very nice paper published so it's
actually by Yen laocoon I think and
co-authors and it was very it was
essentially how to remove redundant
parameters in a neural network and it
was a very sensible paper at a nice
eigenvector analysis actually beautiful
they decided to call the paper optimal
brain damage well first of all it's very
great honor and humbling to be with
these great researchers and scientists
who have actually inspired my own work
and mentor
was a student so so Erica wouldn't he
invited us he gave us the task of
discussing two things related to AI
where have we been and where are we
going
so I want to make one analogy and Josh
already and I just agreed the backstage
we're gonna disagree even though we
actually like each other's work so um
everybody knows I'm a mom or most of you
in the audience knows I'm a mom I'm a
mom of a three-year-old so if you had
have recently had small kids or still
remember having small the experience of
having smart small kids the first thing
you probably remember is this term
terrible too but actually what we don't
talk about is there's a short stage
before terrible - they were just in
total euphoria and that's somewhere
between the depending on your kid one to
two or one and a half-year-old these
babies are just so happy and they're
just like little angels running around
they're not terrible yet but my own kid
also went through that and passed that
hypothesis and I and I promise I'll get
to AI of why this is I think that around
that time the babies have made a huge
developmental progress in their lives
and they're aware of that and and what I
call that progress is actually the
perceptual achievement the perceptual
progress they've gone through so much
actually hardship being born and dealing
with the world and for a year or two
they kind of have figured out some of
the important basic tasks especially
relating to matching patterns of objects
getting some of the words even the
language is still in formation but
they're starting to understand language
so they can match a lot of the
take vocal patterns they think their
perceptual visual perception pattern
recognition is is doing really well
there their haptic pattern recognition
skill is also doing really well and they
start to actually put that together with
motor skills so there is this euphoria
stage that we don't talk about and I
think we're in that euphoria stage in
our AI research and I think we deserve
that but I do wanna point out this is
where I'm getting that I think for the
past 50 years 60 years after a lot of
long history of me starting from
symbolic system expert system
statistical machine learning we've got
certain part of perception I mean I'm
not saying we've solved object
recognition or speech recognition a
hundred percent especially when it comes
to product we still have a way to go but
I think today where we have been is that
we've hit a great progress for
perception but I do want to emphasis
that well first of all terrible two is
coming but no just kidding
I do emphasis that there's a lot more to
perception itself but really beyond
perception it's the word cognition a lot
of intelligence is about cognition if
you read the original Dartmouth proposal
by John McCarthy you read the really my
favorite AI books to Russell and Peter
enormous book about introduction to AI
you see that embedded in the definition
of AI if you unpack the word cognition
it involves acquisition of knowledge
representation of knowledge abstraction
reasoning planning decision-making and
this touches on a lot of the issues Oren
and I think you guys will mention you
know it's not as AI is not just about
pattern recognition especially with a
clear objective function which class of
cat or you know where is the next eye
movement even there there's a lot of
nuance
ai is really about reasoning and
formation of knowledge and in my last 20
second to just be a little technical I
think where are we going I want to
emphasize on the word that Chris already
used is learning I think the past at
least 20 30 years machinery has given us
amazing algorithms focusing on pattern
better matching them pattern recognition
I think the next stage I hope to get to
is we we learn to learn we're learning
in situations we're learning in
developing strategies learning to
acquire knowledge learning to reason and
that's where I want to see AI going I
think thanks very much Michael
hey so um so I guess we're at the end of
the wonderful ones terrible twos that's
sort of disturbing but I want to you
know thank thank Eric for inviting me
that was really great to be a part of
this and maybe maybe you know just
surrounded by so many mentors and and
and and thought leaders though I never I
never thought of myself as a sextant
symbol before so it's sort of I'm gonna
cherish that I came for a while I was
worried about that word not getting
through correctly I will call it a stir
lady USA
I feel like that's worse but okay great
so yeah I I really like this idea of
objective functions it's come up both in
the discussion and also in our in our
kind of set up in the greenroom
beforehand and it does kind of point out
I think to to kind of things that AI
might mean so if you if you think about
the questions that Eric asked there's
there's a sort of aspect of AI as it is
and as it's having impact on the world
right now and then there's AI as it was
as a vision 50 years ago and as it you
know for many people still is a vision
now and and what are the difference
between those things and what are the
advantages and disadvantages and they
can they coexist and the pathways yeah
and how do we how do we get from here to
there and so I want to say that that
objective functions in some ways is kind
of a kind of a branch point for that
that one of the reasons that I
the field has been very successful and
has actually been able to accomplish an
awful lot is because you know we now
have as our practice we define a problem
we develop an algorithm to solve the
problem we maybe throw in a lot of data
we do some evaluation of that and and if
it doesn't work we you know we turn the
crank and try to try to do better we try
to engineer a better system so those
objective functions are incredibly
powerful and incredibly useful in
driving a kind of progress but at the
same time defining those the the way
that setup has to happen is there's an
objective function and then there's the
system that's going to attack that
objective function and the objective
function has to pre-exists the the the
optimization of that objective function
right says it doesn't sort of make sense
to do it any other way but when you
think about human cognition when you
think about intelligence it's it's not
so clear-cut it's not so obvious what
that objective function would be and and
one of the ways that I've been thinking
about this is I remember back back to
having kids he also had kids at a
certain point and one of the things that
I thought was pretty amazing was that
the process of trying to learn to be
funny so turned out to be a very hard
objective function especially for young
kids and there was this period that my
son went through when he had gotten the
syntax of jokes
pretty much but the semantics was simply
not there and there was no way to tell
him no you're not that's not that's not
funny for this reason because if he knew
that it would have been funny in the
first place and so I actually find that
to be a really powerful and interesting
idea that so much of what we think of as
intelligent behavior and human behavior
is actually layered on top of layered on
top of layered on top of layer to the
point where you can't set up the
objective function in advance and then
expect the system to kind of get there I
know we we tried for a while it's like
well we'll not feed you unless you're
funny and so you know it's very clear
objective function they're very
motivated to get it to work but the fact
the matter is this is this is a terrible
idea right so lose a lot of kids this
way so no easing we would only torture
AI systems that way
is that what you maybe reinforcement
learning yes this is this is what we do
in reinforcement learning we put put our
machine learning algorithms in a box and
then we we deprive them of things until
they cry for mercy this is turning out
way more dark than I intended so I
thought but the the fact the matter is
that sort of that notion of layering to
me is actually really important and I
think it's something that we need to we
need to rejoin as a field and really get
back to some of these ideas of systems
that don't you know we have the
objective function we shoot at the
objective function we meet that and then
we're done we put that system on the
shelf it solves problems for us and
we're really happy but systems that are
actually gaining capability over time
and that the new objective new
objectives can actually be defined in
terms of past competence and so that's
something and I think it's really
important machine learning not just of
here's a static data set let's give it
to it but maybe us as people interacting
with these systems you know getting them
to it to a new level of confidence and
then telling him to go even further and
I don't think we have a good model of
that at the moment but I think that's a
that's a direction that I'd really like
to go fabulous Josh you said it wasn't
clean up what's called something else so
so thanks yeah it's a great honor and
pleasure to be here and sort of echoing
what a lot of the speakers said I mean
obviously this is a golden age or you
know billina's golden age for AI and we
want to be thoughtful about what we're
gonna do with it and where we're going
next um you know I'm I'm partly an AI
researcher and partly a cognitive
scientist I try to reverse-engineer how
the human mind works in the same kinds
of terms we would use to engineer more
human-like AI and I think that that's
gonna be important to driving where we
go next I look at all the success and I
have to as a cognitive scientist I have
to kind of have to admit see the gaps I
think that the current excitement around
say for example you know data-driven
learning the scares a clear scaling
route there for certain kinds of tasks
with well-defined objective functions
but the sense of general intelligence
that's more flexible than just any
particular task a certain kind of common
sense I don't think that scaling Reuters
is going to get there not because it has
an inherent limitations it's just not
even trying
I think so I want but but I think I'm
Erin topped amidst and I think we
actually do have good insights if we
look to cognitive science and if I can
just do anything with my five minutes is
to point to the area of cognitive
science which i think is most has the
most valuable guiding vision for AI when
I was in grad school actually I don't
remember where he said this but Bill
Gates actually said this very well he
gave a talk in the mid 90s and he and he
was talking about the earth the early
days of MSR and one of the goals was to
try to understand certain basic
capacities of intelligence seeing and
speaking and he said if we can only get
computers to be as smart as a
five-year-old then that would be a huge
accomplishment and of great value and
you know this this idea that we should
try to build AI by looking at the
intelligence of young children and
seeing the the cognitive development
path over the first months and years of
life as a scaling route to AI think it's
a very valuable one right so Bill Gates
said it the early founders of AI Turing
Minsky McCarthy they all suggested that
at key points of their career we need a
lot of the the deep learning people also
talked in that way Feifei was like that
way I think you know I I not only
respect FAA's research accomplishments
but her vision is I you know I think
it's it comes closer to what I'm talking
about then a lot out there but the thing
is that it's not just enough to be
really smart and to be an observant
parent and to look at what your children
we're doing and try to think oh well
here's my kind of intuitive theory of
what they're doing there's an actual
science of cognitive development and
just as there's been great progress over
the last say two decades in AI research
there's been just as much transformative
progress in the study of cognition in
infants and young children and so that's
in the first few months of life in the
first few years and I think when Bill
Gates said let's let's aim for a
five-year-old he was already being too
ambitious because even a one-year-old is
more intelligent and has more common
sense than any of our a AI systems even
a six-month-old and there's a lot of
research about this and we should study
it and learn what are the ways which
even a three-month-old has a certain
kind of common sense and then how does
that change what are the learning
mechanisms the real learning mechanisms
which grow that knowledge over the first
few
months from three to six months from six
months to twelve months from twelve to
eighteen and and two years and three
years each of those stages are different
there they're fairly well understood in
a lot of empirical ways there's a lot of
data it's not there's not a lot of
theory by the sort of formal standards
that computer scientists would recognize
and it's one of the things that these
fields can offer to each other we with
our computational tool can go and look
at the empirical literature on how kids
thinking develops and actually
contribute quite a lot and similarly
that that that empirical study and the
theories that conceptual frameworks that
developmental psychologists have built
are hugely valuable just I'll just give
two key insights that I've learned from
my developmental colleagues one has to
do with what we start with and the other
is how we actually learn so from the
very earliest ages and some form even
like three or four month olds about as
early as you can study with the current
empirical methods a human thought is
structured around a basic understanding
of physical objects you know things like
this object here this object here
intentional agents people like you know
agents with minds I don't have to be
people they could be dogs computers they
could be balls if they roll in the right
way we can see them as Minds things that
have beliefs and desires and the
interactions between objects and agents
and this is a key insight infants don't
the brain does not start off filtering
the filtering perceptual experience just
in terms of features and more and more
features it's set up from the beginning
to think in terms of objects real things
that are there and agents how many
people have heard of an object
permanence okay so most hands go up you
probably heard about this from pop
culture from your intro psych class how
many Belov heard of Jean Piaget so he
was the founder of developmental
psychology and he introduced this idea
but you know if that's where your
developmental psychology ends for
example how many people have heard of
Liz wielki not as many hands all right
she's one of the great modern
developmental psychologist who studied
infants concepts of objects this would
be kind of like if your understanding of
a I was you know in terms of Turing or
Minsky right great but a lot has
happened since then
so Piaget introduces idea that that
there's a kind of perceptual achievement
to use face term that in
finn's by one year of age come to see
the world not in terms of just pixel
data but objects right but actually as
spell key and others have shown even
three month olds already in some form
have a proto object concept so objects
when you can't see this object it's over
here doesn't wink out of existence you
know if I drop it on if you could hear
that sound I'll take something more
massive right right so the you know the
ability to put together sights and
sounds and represent a world of things
that even when you can't see them but it
infants are set up from the beginning to
do that okay and also to think about I'm
worried now about how Eric is feeling if
I if I you know I'll give out a the
common sense of social discourse people
seem to know let's do that but but you
know again even a even a like a one and
a half year old has a lot of common
sense the ability to you know to
recognize if somebody's reaching for
something that is the thing they want
they're not just acting if I drop
something you you know to help me pick
it up and to distinguish the difference
between setting something down so I'm
done with it and dropping something and
and you know that your your wonderful
one year old well they're part of how
they're so bright is they will see that
they the ability to help you that those
wonderful ones do if we could build
robots that have that intuitive sense of
other people's goals and how to be
helpful that would be huge the other
thing again is about the learning
mechanisms that grow this knowledge it's
not just about the kind of statistics on
a grand scale but in the same way that
these these are you know again to echo
themes of some of the other speakers
here that the early knowledge isn't just
patterns but kind of these intuitive
theories understanding of abstract
concepts the way the knowledge is built
is much more like the way a scientist
builds theories that there's not just
filtering patterns of data but in
finding patterns but building
abstractions trying out different
hypotheses in a curiosity-driven way the
way our basic science research is done
going out kids plays is has come to be
seen as a kind of sort of informal
experimentation so understanding these
two kinds of things right these early
the early conceptual systems these kind
of intuitive theories of the physical
and psychological worlds around us and
these theory building learning
mechanisms I think that is a place where
is really hugely valuable to cognitive
science if we can have formal
understandings of those things and
hugely valuable to building AI I think
they're there various kinds of exciting
technical developments there I'll point
to one which I think you'll hear a
little bit more about tomorrow which is
the idea of probabilistic programming so
this is this is an idea of again a idea
that has has some some roots over the
last say 10 to 15 years the Microsoft
Internet system is one notable example
but it's one of these great places where
the early kind of symbolic and more
recent statistical paradigms are coming
together and it's a set of tools that
actually is allowing us in our models of
children to to kind of capture in the
way that you can deal with uncertainty
and even even guide computer vision in a
much more object-based way to capture
this kind of early add to tech knowledge
and even something about how it learns
hey well I'm sorry
reflect a bit on the stage and while I
do that please queue up for questions or
raise hands I guess for mics to involve
you in the discussion as well one
comment that comes to mind or a
reflection I'll share with the panel and
maybe you can each comment back or share
your thoughts is some of the the the the
magic that you me personally into a I
was reading some other besides just
being fascinated by how my own mind
worked in the minds of people was
reading some of her Simon's early work
like the sciences of the artificial
where you had a real sense for the
notion of the prospect of building
machinery to deal with ill-defined
problems in an open world and we've made
great progress both in the logical world
and in the probabilistic a decision
theoretical world in closing those
worlds in specific ways and things like
you guys you I think as Chris and Feifei
and Orin pointed out with objective
function Michael with objective
functions that tighten things up we've
been very excited about decision
theoretic optimization as we worry about
logic but we also have the frame problem
in logic and believe it or not in
decision analysis and decision theory we
have the framing problem where do these
distinctions come from what is the
objective function what am i doing right
now
and I'm just want to get to get you to
comment on whether or not or what do we
do now that we're post about decision
theoretic optimization where we assume
we have probability distributions we
assume we can we assume we actually
encode a utility function we build
planners and single-shot decision makers
that are doing great work with point
from perception to reflection and action
and even better reasoning about these
things is it time to basically put that
aside and say okay that was great
progress but it didn't get it's it's
fragile brittle we don't know how to
frame we don't know how to go with the
frame problem we need to bring AI into
the open world Chris and yet first of
all just a big thanks to Josh for the
plug for info dot net purpose great I'll
give you a hundred dollars backstage
yeah promising program is very exciting
last year wanted to make some comments
that'll pick up as yet some things that
Josh and faith day and others have
mentioned around they're sort of open
world issue how do we move away from
this well-defined task where we've got
our labels and objective function we
trained it and then it's frozen and it
does that one task very well and that's
it and that's a long way for what we
think of as artificial intelligence and
every time we solve the tasks that way
it's immediately defined to be not
artificial intelligence how do you how
do you get to something that's much more
like the child kind of making sense of
the world just said not just statistics
although I kind of think of statistics
in a very general sense so it did sort
of if it's making sense of the data the
child is observed observing how can it
do that and of course I don't know all
the answers but I think one of the
directions that we could and are
pursuing I think has a lot of promise is
to recognize that the these sort of two
modes of cognition if you like the sort
of the bottom-up fast mode which is like
the trained Network I turn around a
split second I can I can recognize it's
Eric I can recognize a predator that's
some fixed pre-trained okay so same same
neurons yeah that's kind of fixed fast
bottom-up thing that's sort of pre
trained that's trained in some other
place or some other time but then
there's something that's more bottom
down it's about an internal model of the
world so we just take object recognition
for example you've got kind of two ways
of doing this one way is to is
use a discriminative method to try to
learn decision boundaries between apples
and oranges another way is sort of
unsupervised without labels if you just
given a huge amount of data if I give
you billions and billions of natural
images of the world and I just said
compress that data which is equivalent
to modeling the probability distribution
of that data then you could discover the
presence of regularities you could
discover objects and you discover apples
and oranges you wouldn't know they were
called apples and oranges but now if you
know mum and dad tells you that one of
these is an apple you know about the
whole concept of apples and that's sort
of much more like the the you know the
child making sense of the world in this
statistical sense so there's a lot more
to AI than this but I think but let me
get to the thing that I think is really
exciting it's just a little personal
thing that I think is great which is how
do we combine these methods because if
you look at these two approaches if you
look at neural networks discriminative
methods they're very fast and they're
very accurate but they need a huge
amount of label data if you look at
these generative methods or this
analysis by synthesis then you can get
away with little or even no label data
but the problem is it's computationally
very expensive you sort of have to test
out all the hypotheses you say you look
at this thing is it is it an apple not
very good is it a an orange node is it a
bottle yeah maybe it's a bottle okay
it's a red bottle they're not quite as
it is a blue bottle yeah okay now it's
looking so you've got this
computationally very costly process in
principle of exploring all the
explanations of the world to find one
that fits okay so that's kind of the
generative the generative method so so
one of the needs needs labels but is you
know and it's very fast the other is
slow and doesn't need labels kind of
kind of train each other then we
mutually train each other and it's and
and I just give you a couple of little
evidence points that I just can't resist
because I think this is maybe not
completely crazy so if you go back to
the skeletal tracking system that in
connect you know the the the the the 3d
body sensor that system was trained
using motion capture data so real data
but the variability in clothing infrared
reflectance camera noise was so huge
that we actually use synthetic data so
we started with a motion capture data
and then synthesized all sorts of
variance so Jarett if model was built by
hand and used to create label data to
train the discriminative system here I'm
talking about
- generative models we have a system
were working on now called kyra which is
a hand tracking a real-time hand
tracking system where those
discriminative methods are pretty good
but they're not accurate enough to get
super precise details of where all the
fingers are so what we do is to use the
gent the discriminative model the it's
actually decision for us but it's like
deep neural networks to give us a very
good guess as to where the fingers are
and then we tune the generative model so
there's another example the two working
in synergy so I think that's a any one
of many possible interesting directions
I know there was a recent award-winning
paper or is the best paper or EPR
bye-bye Josh working with pushed me Koli
at Microsoft really well really my 10
just Kulkarni are graduates at MIT who
were describe their work though yeah
because it really aligns with what this
was saying yes it's a sort of joint MIT
MSR project also with the Casamance Inga
mi MIT and yeah it so it totally aligns
with that I mean it that's exactly what
we do so so Ted just introduced a new
probabilistic programming language in
which you actually take you know
graphics rendering and put it in there
as part of the model-based approach and
then you use various bottom-up
data-driven techniques it could be sort
of very simple example are kind of
hashing methods it could be deep neural
networks to do exactly what you're
saying basically to kind of learn a
bottom-up route to doing fast inference
in a generative model you know we both
know Jeff Hinton's earlier work on the
hellmouth's machine so to me the most
interesting version of deep learning was
actually Hinton's sort of mid nineties
version I guess that's when I was just
paying most attention to what everyone
said but you know how many people know
the Helmholtz machine so go back and
read it it's this was there was a
science paper called the weak sleeve
algorithm for unsupervised learning in
the in the mid 90s and many many people
who've been around for as long as some
of our older folks you know know that
that those ideas are back now in a big
way and well it's sort of it's part of
the background behind what Chris was
talking about and what we did in this
cvpr paper I I think that's totally
right on but I would just add I think
from the cognitive development
perspective a lot of what you what you
call in like what you did in connect
specifying the generative model by hand
that's also actually the way it works in
the brain in that it is I think there's
a tendency to over weight how much
learning goes on in infants evolution
did much of that for us the idea that
there's what
what we've sort of put into our system
or what in some forms there and how you
train connect a kind of a graphics
engine we believe and there's I think
good reason to see this from cognition
and neuroscience that there's something
like a graphics engine in your head and
that evolution has put certain you know
if we don't really know exactly what
form this is but has certain put certain
understanding of the three-dimensional
physical world and how you know that
leads to images it's not just graphics
but physics I think a lot of that the
phrase I'd like to use these days to
describe the infant core knowledge
system is the game engine in your head a
lot of the pieces that are in modern
game engines which include graphics
engine physics engine is and even simple
kind of planning engines I think are
part of what evolution has given us and
so we need to understand I think to
build more human-like AI how to
integrate statistical learning with all
those components of that system yeah
I'd like to just a committed them a word
that we're gonna lose some of our
audience or them into early nap by just
reflecting just just like straight on my
shirt just reflecting on the panel
without getting into too many
mechanistic details I think what's
really interesting you never know when
you put a panel like this together there
was a note of agreement which I would
state as simply there's something
missing right there's a lot of exciting
results but there's something missing in
a I think everybody reflected that and
then there was also a note of
disagreement which is always the more
exciting thing with the panel and not a
disagreement that's aggressive but we're
reflecting very different methodologies
about how to get at that ingredient so
let me repeat that in more explicit
terms and again I I apologize if doing
that I slightly disturbed where people
said my main thing is just to get the
point across so I feel like a lot of
what Chris was talking about is okay
we've got supervised learning it's got
limitations let's figure out how to
extend learning algorithms whether it's
with better ways to get label data or
with unsupervised techniques
it kind of sketches at a research
program of unsupervised learning and the
thing that I've learned over the years
when I was young I was always right and
and now I learned that this
methodologies in each one has benefits
and and and pitfalls so the obvious
benefit is that is this really
interesting algorithmic we're
to be done it's really important to
extend the state-of-the-art the
potential pitfall is that at the end of
that we'll have a whole class of
algorithms and not be that much further
along towards towards ontology it's the
next descent it's the minutes right
so you're outlining a thought for the
next 2% that's and that's great if you
go to what Josh's articulated I think
incredibly well he said look there's
something incredibly tantalizing and all
of us have had kids all of us were
interested may I get in to think of it
is I'm incredibly tantalizing about
human cognition he's saying we've got
more data on that and we can also start
to build system using you know
probabilistic mumble foo which is the
mechanism does your program people and
give it two years and or whatever but
but but the point is you know there'll
be another DARPA initiative but but but
but the point is that it's very very
tantalizing and very very exciting gets
at the deep problems that's the benefit
and also a new source of data the
potential pitfall is around are we
actually able to build systems with
stronger capabilities right so it's it's
you know that that's a key question
right where's if you look at some of
these other systems they have these
well-defined objective functions and you
can see so that's what I see some of the
trade-off and in general cognitive
science again to just you know pain
things with a very broad brush has
repeatedly given us deeper insights very
starting with the work of Newland Simon
and proceeding into the human mind and
at the same time has not been the
shortest path that AI is produced to
generating more effective technology
potential I just go through two more and
I'm done and then I want to make sure
that I have an equal opportunity
offender ever been I think you could
stop down that's fine
I actually tried trying to be balanced
III don't mean to say it and and you'll
see that you know it's not like I've got
the answer that's not where I'm going I
felt like Michael was saying look we're
excited about this kind of ill form
stuff but let's not forget let's not
forget then when we're formalized things
that's what we're really able to make
progress is can
or scientists right I heard that I'm
gonna say so again the obvious
methodologies look let's take that 2%
formalize it solve the problem
algorithmically or empirically is good
computer scientists and move on and
that's very very satisfying leads to
great theses and papers and the worry is
we'll keep going but we won't get there
and then faithfully aside from the
conversation about her her child which I
could really relate to as somebody as a
5 year old was pointing out there's a
lot more to AI than perception when she
and others make great progress let's
think about all these problems you know
reasoning and planning and what-have-you
in representation and of course when you
think about those that's great the risk
is we get hideously lost right because
those are very ill for from last thing
our methodology we've identified these
grand challenge problems as I mentioned
we're trying to connect the dots the
good news is we do have metrics and and
we will be very clear if we make
progress the bad news is again we might
not have a clue on how to do that we're
a much more data-driven and challenge
driven than we have a particular
algorithmic philosophy which again can
mean we could get hideously low so let's
open it up to the audience for some
questions from the audience and comments
and we see some folks coming in we have
a runner here yeah good hi Eric is this
huh yes okay I just want to build on on
what what Josh and Orrin were saying if
we continue doing nothing but picking a
problem and formalizing it in solving it
will never actually achieve what we want
to achieve you have to actually start
taking a different perspective think
about what you're doing is building an
organism an organism does multiple
things that solves multiple problems
that formulates its own learning goals
now there's a line of research in AI and
cognitive science called cognitive
architecture that does this there's some
beautiful examples where works been
going on for decades if you look up
akhtar or soar you'll find that they've
done an amazing range of modeling
phenomena but also building systems that
actually are practical and used as
performance systems and if you think in
terms of for instance what humans are a
human level AI really
is a software social organism that's got
human level capabilities and all of the
reasoning and learning is capable of
doing and that's a way of formulating
the goal that's completely different
from here's the technology here's the
problem it's actually a specification of
what it is we're trying to get to and if
you think about building simple versions
of that start with the equivalent of
shacks if you're thinking of an
architectural metaphor and build up two
skyscrapers then that's a path that will
actually get us where we're going and
there's still plenty of room for people
doing the traditional spica problem and
solve it and gather all of our
evaluation data and all that stuff all
that's producing a stream of ideas but
if there's not an equivalent set of
people who are putting those together in
building organisms you can't tell if
these are going to go anywhere I think
that's what I would suggest that's
question any comments on Ken's
just say yep well I think the idea of a
very much idea of a system that can make
its own goals and make its own sub goals
this I mean it's another way to put I
think what Michael was saying right
which is that there's somehow we have
this kind of intelligence that can that
it doesn't just have a single task
effective budget but can make our own
objective functions and can decide oh
well I'm going to work on this thing
like I understand AI and then formulate
sub goals and sub sub goals as part of
plans to do that integrating that kind
of approach with our sort of expected
utility optimization toolkit that's
driven so much of the excitement in
recent a I from a machine learning point
of view I think is really important
question from Peter yeah so first thanks
to all of you for a very interesting
panel there's so many things I'd love to
react to from a technical perspective
but since the title was myths and
realities of AI there's one I think huge
myth that sort of being perpetuated by
some of the language that's being used
in the in the panel and the lead-up to
the panel which is when we use terms
like AI winter and Golden Age and AI
spring it gives this impression that AI
as a field has had some huge
breakthroughs and then nothing's
happened for a long time and then
another huge breakthrough
and nothing's happened and there's this
I think there's this sense right now
that there's been this huge breakthrough
but I think the reality is instead that
there's been this steady incremental
progress over many many years and that a
lot of this I think you know Chris gave
this sense a little bit that you know
with neural networks for instance you
know there's this notion that this
so-called you know deep learning is this
huge breakthrough but really there's
it's because of the people who've stuck
to it over many many years and made
these small breakthroughs and small
progress and this is happening I think
all through AI that for a while
everybody was doing symbolic and then no
it's got to be probabilistic and for a
while SVM's where the breakthrough and
then and I think it's you know the this
is it's a it's a harmful myth in the
sense that it causes people to jump on a
bandwagon and everybody go to in one
direction we're really you know the wave
for progress is that for everybody to
stick to they you know the their their
area and there's many different really
promising areas in AI and I think you
know we should have this vision of a
steady incremental let me we're you know
at the point today where we're we're you
know jeanette wing who I'm thinking of
we think of all of his uh you know miss
formal methods it gave a 45-minute talk
on AI which is great that's great to see
you do that Jeannette but but I want but
I you know I think we also it's really
exciting and it's tempting for all of us
to say yes this is a golden age and
everybody should jump on it but I think
we all do need to also recognize that
the whole field of computer science
needs to keep moving in the you know the
steady incremental progress and we
probably will get to a point that's
where the hype is gone and where there's
not the the news coverage again and you
know it'll be tempting to say that
that's an AI winter but really you know
we should keep keep pushing and so
that's a big mystery a fabulous comment
ok smell very much
over here Erica did a great panel and
very thought-provoking I just have a
very simple question any of the
panelists mentioned that there are all
these terms with no definitions from a
mathematical point of view do we have
the right mathematics and formalisms to
formalize the concepts that AI is
struggling with
what does it what will it take to turn
AI into a science well first of all my
church people like people to say it's
not a science but go ahead you know the
the speaker is the questioner it is
quite pejorative calling it not a
science and in a response I would say
that the question really bespeaks a
tremendous ignorant of the field and a
philosophy of science most scientific
terms starting with the cell are very
difficult to define Vidkun science
philosophy of languages showed that most
terms are actually difficult to define
even the notion of definition is
questionable also most science doesn't
have mathematical underpinning in the
sense physics may be an exception look
at biology look at geology so I don't
really think the question merits
discussion the way it was supposed and
and and people know that I ask the
panelists to be as pointed as they like
so so it seems that the panelists agree
that you know we've had some great
successes recently and it's good to
celebrate them but also that you know
there's these other things that we
really need to focus on to get to AI and
we saw various I think great ideas about
how to get there but the thing the
question that was on my mind through all
of this is that that part of the
dissection some ways is not that
different from the discussion that
happened at Dartmouth and so the
question I think that I would like to
ask the panelists is what have we
learned from the failures of the last 50
years about where to get in these things
because surely it's by learning from
those favorite failures that we're gonna
succeed sometime in the future when when
we didn't in the past any comment
thought on this and I guess and you know
the the good old-fashioned days of AI
predate my involvement but
but I guess you know the 50,000 foot
view is that there was a move away from
as it were handcrafted rules to sort of
lurching to the other end of the
spectrum which is sort of learning from
data and neural networks are kind of the
this black dot model that that learned
from data and have very little prior
knowledge built into them with the
except probably of convolution which
sort of captures local translation
invariants and I think an interesting
question Joshua hinted at this earlier
is around what sort of prior knowledge
should we build in and what prior
knowledge is the brain build in I mean
the genome doesn't have enough bits in
three billion base pairs to specify all
the synapses in the brain most that has
to be learned but there are a lot of
bits in the genome and you could specify
things like I mean why would the brain
not encode the fact that it's going to
be born into a 3d world it's going to
see lots of 2d projections of that world
why wouldn't you bake that into the the
structure of the visual cortex that
seems to me you would and so you know
again one of the things you know that
what many of us are quite interested in
is how do we back away a little bit from
that extreme end of just blackbox neural
goop that kind of learns anything and
how do we bake in some high-level prior
knowledge I think that's where public
programming comes in as a very efficient
and elegant way of encoding some of that
high-level prior knowledge but still
having all the details learn from data
so I think there probably may be is a
very interesting time to go back and
revisit some of that very early
literature because you know very smart
people thought long and hard about this
and they didn't have fast computers they
didn't have neural nets they didn't have
you know tons of data but there were
smart people they thought about this
long and hard and maybe there are ideas
that we can take and then transplant
them into the modern context I think
what we've looked from one extreme to
the other extreme and now we're sort of
backing away a little bit and I'm
finding more of a middle ground it's
very interesting time and yes sort of
more generally I think learning to be
wary of extremes right learning to look
at the different eras of our field and
try to say well when some really smart
people said something and then it didn't
turn out to work then there's some
lessons to be learned from that but part
of it is to understand well what was the
really right thing that they were on to
can we extract that out from the things
that maybe they just either other things
they didn't know how to do or they
didn't have the technology or the data
to make these things happen you know
again pay and pager of course your reer
work is you know I think I think of say
for example Markov logic as an example
of understanding okay there was
something really right about logic what
was right about logic wasn't
deductive inference that's too weak and
brittle but abstraction right and if we
can combine the distraction of predicate
logic and then combine that with the
power of statistical learning and
inference we could do some pretty cool
things and you know I think that's a
field learning that and also kind of I
think having since learning as the theme
of the day or the decade the more
sophisticated appreciation for what
learning is really about and
understanding that learning isn't just
something you can just follow your
intuitions on but there's a science of
learning and that maybe maybe the way
that you know I think a lot of people in
machine learning or AI will will and
again - maybe foreshadow something that
you might be talking about soon
evolution is kind of the real learning
algorithm in a sense right or there are
tears learning over many different
timescales if you think of learning in
the very broadest sense of adapting to
the statistical structure of your
environment there's aspects of the
three-dimensional world and the fact
that we perceive it through light and
sound that is millions of years old
right and or or even more and then
there's things which happen on other
timescales of years months days seconds
and so on and understanding that no one
of those is the right time scale to
focus on but understanding how a brain
or an artificial brain or an intelligent
system adapting to the structure of its
environment over all those timescales is
something that we're gonna have to take
seriously just to make a come first of
all I think evolution has already
encoded one prior structure for coping
with the 3d world with this we have to
ice not one night so just a little
comment I think I think this whole
discussion about what's next and we we
said technically we talked a lot about
programming language the other thing I
think we should consider is actually go
back to the early a I concept but in a
modernized ways think about knowledge
knowledge formation and knowledge
acquisition and common-sense knowledge
and and here you know speaking from a
vision point of view people like Klara's
Nick and MSR is actually meeting a lot
of those research and also in the
I - you guys are doing knowledge and I
think this is one topic that we should
pay a lot more attention to to extract
us out of simply statistical pattern
matching for one task but start to
formulate that kind of back instructor
of reasoning give us a path to abstract
information and form relationships and
be able to reason in an ad hoc way more
ad hoc and situational awareness way
rather than just go for that and task
well thank you very much we're having to
break now to a break for all of you and
sorry we can take a last question I want
to thank the panelists like to say that
I had a fabulous it had to be the most
exciting green room I've ever been in
like some research done I think and they
could all share some insight with you at
the break and the plenty time to meet
each of these wonderful people and have
some some insightful conversations
thanks everybody each year Microsoft
Research helps hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>