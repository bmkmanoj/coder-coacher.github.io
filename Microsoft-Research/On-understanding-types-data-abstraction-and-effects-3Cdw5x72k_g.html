<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>On understanding types, data abstraction and effects | Coder Coacher - Coaching Coders</title><meta content="On understanding types, data abstraction and effects - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>On understanding types, data abstraction and effects</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3Cdw5x72k_g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
but okay so well I'm going to be talking
about types as as many people have
before me and this is a subject on which
Luca has written pioneering original
research and also some beautiful surveys
in fact this one I think is his most
cited paper has already been been
mentioned so there are lots and lots of
different accounts of what types mean
and what they should be for and I'm
going to talk about the best one and and
the best one is the one that PLU e has
has already mentioned it's this idea of
interpreting types as as binary
relations so the story is we're going to
start with some universe of untyped
computations and then we could carve out
the meaning of a type as a subset a set
of values in the untyped world which
have that property but we're actually
going to do something just a little bit
more subtle we're going to interpret the
type as a binary relation and you should
think of this binary relation as carving
out the set of values that have that
type and a type specific notion of
equality on those values so our primary
the primary subject that we're
interested in is this judgment that says
M equals M Prime at type a not M as type
a M prime test type a and they're equal
but they are equal at that type and the
kind of most important part of the
definition of this kind of
interpretation of types is the clause
for closer functions which I guess
everyone's seen many times before so
it's a standard logical relations
definition it says to two functions are
related at type A to B if whenever you
give them a related arguments you get
back be related results so so our view
is very much that the computations exist
before hand and then types are going to
be properties of those programs so lots
of people have studied this kind of
thing in the context of polymorphic
lambda calculi
so at the understanding of parametric
polymorphism the free theorems is is
understood by quantification over
relations which go beyond these equality
like ones but the young the emphasis in
a lot of theory early work was on
finding good models for pre-existing
pretty lambda calculi we have a slightly
different view point which is we're
interested in using this technique to
reason about messy dirty imperative
and about properties which are perhaps
non-standard types so they might not
have such pretty rules so we're going to
take the the truth about imperative
programs first and then we're going to
try and impose some discipline on it via
this by this methodology of using
logical relations so the first thing
that that I ever did along these lines
is something that's very very simple
arose from some dissatisfaction I had
with the accounts that people gave of
traditional data flow optimizations in
an imperative language compilers so what
it's all we're going to do is I'm going
to do something like whore logic so
whore logic says this command take state
satisfying a precondition P to a post
condition Q and instead we're just going
to sort of crank this up to reading
about pairs of programs and related
states so the judgments were interested
in is C it related to C Prime at Phi to
Phi prime where Phi and Phi prank'd are
binary relations on the states so this
means that if you start seeing C primed
in states that's related by Phi then
either they both diverge or they both
terminate in state satisfying in the
relation Phi primed and you can give
quite nice rules for first standard
imperative programming constructs that
reason directly with relations over the
two heaps expressed in terms of a
language where you label the variables
with one or two according to which side
they come from and as an example of the
kind of thing that you can do with this
logic and here's a judgment this is a an
invariant code motion
plausible optimizing transformation for
a compiler to do we noticed that this
assignment to X assigns a value that
doesn't get changed in the loop so we
can pull it outside the loop until you
can use the logic to prove that these
two programs are related at Phi to Phi
where Phi is the relation that says the
variables I and and Y are equal on both
sides and the thing I draw your
attention to is that this these programs
are not contextually equivalent in
general okay so if the loops not
executed at all then the assignment
doesn't happen on this side so they're
only related they're only equivalent if
you like in contexts where we don't care
about the final value of the variable X
and that's exactly the kind of
information that an optimizing compiler
needs to do interesting transformations
so simple there is this logic is pretty
it's pretty useful it embeds a whole
bunch of traditional dataflow analysis
you could do
some forms of secure information flow
program slicing and it gives you the
corresponding optimizing transformations
at the same time not just soundless of
the analysis so lots of other people
have taken this up and done fancier
things with it in particular for
security so there's a whole bunch of of
more sophisticated versions of this
logic which build probabilities in and
so forth
it's been used very successfully in in
verified crypto protocols and so on and
I should mention that the inspiration
for doing this in the first place came
from this paper which has already been
mentioned for more parametric
polymorphism - paper by martine luca and
kelly which which kind of introduced the
idea that you could have a formal
calculus for reading and reasoning about
about relations it's the second thing i
want to talk about is models of ml like
languages so the same technology but
used for something different so ml has
higher-order functions and dynamically
allocated local references and this is a
tricky combination their reasoning about
programs in that language is actually
quite hard so here's a trivial example
of the sort of thing that goes on we've
got two functions so this this
computation gives you it assigns a new
reference gives you back a function
decrements the reference and then
returns the negation of its contents
this one new reference gives you back a
function which increments it and returns
the contents so these two things are
contextual equivalent in ml because the
reference X is hidden inside those two
pleasures nobody else ever gets to see
it and the external behavior when you
make calls to the two things is the same
but let's think of how we prove these
sorts of things and the picture you
should have in your head is something
like this so at any point as the program
executes the some bunch of references
that have been created with some state
which have not been exposed to the
outside world so they're private to to
the closures and then there's some bunch
of references which are public they've
been handed out to the outside world and
the point is the outside world can do
anything it likes with these things so
for two programs to be equivalent they
have to be very equivalent on the stuff
that they hand out to the outside world
because the outside world can product
but on the private stuff you can have a
more general form of invariant so who
we're going to think about to program
executions of whether or not they were
going to give you equivalent results in
all contexts well it's a fighters to
have some setup like this so you've got
the two bunches of private store which
possibly diff
but there's some relation between them
and then on the public parts there's
some correspondence between the
references which have been generated and
if all the computations preserve this
relation on the private store and this
correspondence between visible
references is preserved in the sense
that there are always equal values in in
quitting the corresponding references
then the two things will be equivalent
so we can formalize this by what's
called a Kripke illogical relation so
we're going to interpret types as
relations again but now they're
parameterised by this pair of things
some invariant on the private store and
some partial buy action some
correspondence between the references
which have been made public now I
apologize for the slight excess of
formalism but basically there's a bezu
there's a relation on heaps which just
says what I just said in that picture so
so two heaps are in the relation at R
and Phi just when they're related in R
and then on some separate part for all
the RIT all their locations which are in
correspondence Phi they have equal value
in so it's just a separating conjunction
of of a relation and and then equality
on Phi and then the interpretation of
int type is just in each integer is
equal to itself the interpretation of
our reference type to two locations are
equal the reference type just when they
correspond in this Phi so this parameter
comes in and tells you in this world
these are the references you should
consider equivalent and then for
function types the game looks big and
hairy but it's a very standard pattern
it's normal Kripke style thing it
basically said if you've got two heaps
that are in the relation at the
parameter you've got two arguments which
are in the argument type at the
parameter then there's some extension of
the parameter that means adding disjoint
relational stuff and disjoint by
ejection stuff such that when you run
the two commands two functions on those
heaps and arguments you get back things
between the relation at the new extended
parameter and return values which are in
the interpretation of the return type at
the extended parameter and you can prove
the normal fundamental theorem and you
can pretend and then you can also show
that when things are in the relation at
the empty relation and and parameter
then they're contextual equivalent and
that gives us a method of proving
contextual equivalence is like this
okay so second thing very closely
related again semantics of effect system
so ml has complicated equation all three
lots of equations you'd like to help
don't actually hold in general because
you don't know that things don't have
lots of lots of side effects most email
programs don't have lots of lots of side
effects so what you want to do is have
crank up your type system to track a
safe upper bound on the side effects
that things have so if you know more
about the possible side effects things
can happen you can prove more equations
and this is the kind of thing that you
get this is an effect system for a
language expressed in terms of index
monads so so instead of having tea for a
computation of something we have T sub E
sub epsilon rather where epsilon is
going to be an upper but it's going to
be a set of effects and I read some
variables I write some variables so if
you dereference a location L then that's
a computation that returns an integer
and has an effect of reading location L
if you're assigned to V signed V to L
then that's a computation that has a
side-effect of writing location L and
when you sequence computations you Union
their effect so we built an ml compiler
that did optimizing transformations
based on on using a type system but like
this but we wonder for quite a long time
what it actually meant and how we could
formally justify what we did with it and
so the way we do it is we we give a
relational interpretation again to these
refine types so we start with the
semantics for the for the language
before we did anything fancy with the
type system and then we interpret the
refined types as relations over the
interpretation of the unrefined types so
the meaning of a effect refined
computation is a binary relation on the
the unrefined thing so the unrefined
thing is going to be a function that
takes an input state gives you back an
output state and some element of the
underlying type so we have a binary
relation on there and the binary
relation that works is is is like this
so so this says two computations are in
the relation at an effect type T epsilon
of X just when they preserve all
relations so to start meaning our
related state I'll give you back our
related results and and meaning of X
related sorry our related final States
and meaning of X related final results
for all relations in some class this is
bounded quantity
patient over relations and what's the
bounded quantification well for each
primitive effect we have a set of
relations that are preserved so the set
of relations associated to reading L is
a set of relations such that if you're
in the relation then s of L and s prime
devel are equal and the set of relations
associated with writing a location L is
a set of relations such that if you're
in the relation and then you update
location L with equal values you stay in
the relation and what we do is we take
the set of effects e in epsilon and we
intersect all the corresponding sets of
relations that gives us a set of
relations and then the computation has
to preserve all the relations in that
set so it's a bit quick but the slogan
well I just said oh mats to this you
have to preserve all the relations that
are preserved by all the operations that
you're allowed to use now it turns out
this semantics has fundamental theorem
but it also gives us on off the diagonal
these effect dependent program
transformations so we can prove the
optimizing transformation that our
compiler does on the basis of this
relational interpretation so here's an
example says you've got X gets my gets m
in n so we evaluated M twice that's the
same as evaluating M once
and using the value twice provided that
the collection of things which are read
by the by the expression M and the
collection of things that are written by
the expression M are disjoint so this
works very nicely for global variables
and we can combine it with what I had on
the previous slide using partial
bijections and private invariants and so
forth to extend this to a more realistic
effect system that deals with regions
and dynamic allocation so final thing
I'm going to try and cover so so this
this is this is something about proving
that compilers preserve types of the
source language so we start out with a
simple functional language compiled down
to an idealized assembly code and we
interpret the types of the source
language as binary relations over the
assembly code so this is basically the
same story which was on my first slide
types as relations over run type model
except here our on type model is real
real assembly code not not sort of
abstract untyped functions or codes for
partial recursive functions or anything
so source types interpreted is binary
relations they only talk about the
observable behavior at the outside and
they define the calling conventions but
they're independent they don't mention
the particular compiler they just talk
about the interfaces and things and we
can then give a compositional proof that
the code produced from the source phrase
is related to itself at the relational
interpretation of that type the way we
do that is use a relational separation
logic for assembly code yep okay okay so
this is a this is this is a separation
logic version of the relational logic
that I talked about earlier on and to to
exceed the coq but to explain what what
that what that theorem really means just
consider we all draw these pictures of
what happens what the memory layout
looks in it looks like in a in compiled
code and basically what the relational
interpretation of types does is it tells
you for example where I drew a pointer
here none of the code cares what the
actual value stored in this cell is its
behavior will only depend on what the
value is at the other end of the pointer
so we're quotient in the memory to get
this picture and that's what the
relational interpretation of types gives
you so we have two other applications
which I don't have time to talk about
one of which is doing full functional
correctness of a compiler and the other
is cranking up the effect system to talk
about abstract data structures instead
of concrete locations in the heap but I
will summarize by saying the relational
approach is a powerful elegant and
effective way of timing timing side
effects I will draw your attention to
the fact that I didn't instrument
anything there's no talk about going
wrong here and so two slogans so all
type systems are about information flow
they're all about how much difference
makes a difference if you like and this
slogan about preserving or relations
preserved by all the operations I think
it's a very valuable one it's something
I've been using logic relations for a
long time before I realized that was
what we were doing all along
and I'd like to encourage you to take
the semantics first so view your
syntactic types as an interface language
for components but then you can show
that a piece of code matches that
contract matches that interface by lots
of different methods it might be a
simple type system or it might be a
complicated logic and finally happy
birthday okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>