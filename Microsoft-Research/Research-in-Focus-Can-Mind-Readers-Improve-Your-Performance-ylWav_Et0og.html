<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Research in Focus: Can Mind Readers Improve Your Performance? | Coder Coacher - Coaching Coders</title><meta content="Research in Focus: Can Mind Readers Improve Your Performance? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Research in Focus: Can Mind Readers Improve Your Performance?</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ylWav_Et0og" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my next guest assistant professor of
computer science Aaron solavei of Drexel
University and senior researcher Andrew
bago of Microsoft Research are using
some amazing tools with the goal of
improving our performance on various
tasks just remember Aaron and Andrew
aren't really mind reader's even though
they've got these cool devices here so
if you have questions we got to do it
the hard way the old-fashioned way type
it into the chat window you've got the
tool right there in your viewer do that
Aaron Andrew thanks for being here thank
you we are planning research and focus
your segment has a title so no pressure
there all right so I'm told of course
that you're working on complementary
approaches for using psych psychological
physiological data to predict cognitive
workloads and Aaron I want to start with
you and your work I understand you're
studying the impact of cognitive
workload on people doing commonplace but
potentially dangerous activity driving
explain why you chose driving all right
yeah there's lots of reasons so as you
know driving the dynamic tasks that we
do it involves visual manual cognitive
load that you have so you have to
determine where you're going which is a
strategic goal you have to monitor the
road and also your vehicle and that's
more information processing and then
there's the physical act of actually
manipulating the steering wheel and
doing the physical driving and so
there's a lot going on and then also
we've been seeing this there were I
think 387 thousand injuries from
distracted driving in 2011 and over
3,000 people were killed and a lot of
this comes from the secondary other
tasks that people are doing while
they're driving so you have the driving
task plus a secondary task so what I've
been trying to do is study the workload
that is induced by these secondary tasks
I think it's important to understand
that driving is changing a lot we have
GPS system we have browsers even in cars
and also yeah so this is a picture of it
and I yeah well that's in a simulator
yep and so plus people are bringing
their technology into the car which adds
extra workload and then at the same time
cars are becoming more advanced we have
more automation cars and this can change
the role of the human in the view
go from the manual control to someone
supervising and so understanding the
workload and how that's changing as cars
evolve is important Wow okay so you're
you're trying to work to understand when
a driver's workload is either overloaded
or under loaded and you're using
something called what f nears to study
brain activity yep so f'nor is one of
the tools I've been using it's a brain
sensing tool it's been used more
recently and it measures blood flow and
blood oxygenation which is similar to
what an fMRI measures but it's portable
non-invasive pretty easy to use and so
we can get this information about your
cognitive state while you're driving and
see you brought a little toy with yes I
must ask you to fashion show us what it
is what's its role with F Nia okay I'll
put it on for a moment come on all the
kids holidays yeah so this is actually a
device this isn't what i've been using
more recently in studies but this is one
that we put together for earlier studies
and really the the way that it works is
going take it off young lady so yeah so
the way it works is in these and here
the reason we have this is there's
little holes to put light sources and
light detectors in here and they hold
them in place on your forehead and the
light goes into your forehead and it
your bone and tissue is transparent to
light at these near-infrared wavelengths
and it's the oxygen in your blood that
actually absorbs the light and so we
have the light sources going in and then
there's detectors that are embedded into
there that can detect how much comes out
and from that we can calculate how much
oxygenated blood is in that part of the
brain which is an indicator brain
activity Wow ok so this headbands
reading the level of brain activity in
the person who's wearing it is this the
only data input you consider are there
others um no so this is one of the
things i've been using i have also done
work with the EEG brain sensing but more
recently I've been also looking at
physiological measures so body sensors
looking at heart rate skin conductance
level and then in addition I also look
at the task the tasks that you're doing
in any context information we can get
from the task you know if you're using a
computer while we're sensing you we can
also see what's going on the computer if
you're driving men
be able to use the sensors in the car
and use all of that to get a better and
figure out your cognitive state while
you're driving or doing your task in
talk about your actual process or is it
all simulators was there people actually
on the road yes so I have done both so
with brains so far with the brain
sensing I've done it in a simulator so
you saw the picture earlier which was
someone wearing f'nor's in a brain and a
car simulator which yep and so we had a
full car and then there's a screen in
front of you but all of the steering
wheel there's a pedal to accelerate its
all active and so you can use that and
then I with the body sensors the heart
rate skin conductance level we've done
Studies on the road in a actual car on
the highway where we gave pute people
drove and then he gave them a secondary
task to do we did a pretty large study
with a hundred people over a hundred
people on the road and trying to
determine see if we could use these body
sensors to determine their workload
while driving Wow ok so you're getting
all this data and what do you do with it
I assume this super machine learning
comes in yes so exactly we what we're
trying what we'd like to ultimately be
able to do is use these sensors to
automatically determine your current
state and so to do that one of the tools
were uses machine learning but in order
to do that we need to build up big data
sets with the brain and physiological
data that's labeled so we need labeled
data and so a lot of my studies have
been building these data sets where we
like I said we had a hundred people on
the road and then we gave them a task
that has an own level of workload so we
use tasks that have been studied in
psychology for years and those have
known level of elevated workload and
then we'll also have them just driving
and then we can build these data sets
that say this is what your brain and
body sensors look like when you're
driving alone and this is what it looks
like when you're doing a secondary task
and then that can be used to build a
classifier that can when we don't know
your current workload we can use that
data to classify it this is fast I'd
love to put this on my head to see ya
what is it thinking about no not right
now those moments that we've all had
where all of a sudden you discover
yourself on the road
many blocks or even miles down the
freeway from where you were when you
last checked out in your brain where am
i how do they I guess this part of my
brain kept driving and this part of my
brain was on something this fascinating
stuff and Andrea I want to bring you
into the conversation I understand
you're using similar devices to measure
what psychological physiological
activity but instead of setting drivers
you're looking at computer programmers
so what is the goal of your research so
my goal is to look at when computer
programmers get stuck or confused with
the software they're working on that
they were actually writing like for
example at Microsoft rebuild a lot of
software and we have about 30,000
engineers that work on that software and
sometimes rarely bugs make it into the
software that we ship and those bugs
have to get fixed and that's expensive
so we with my research when I'm looking
for as a way to detect when the
programmer is about to cause a bug and
stop them before that bug can enter the
code mom and what my theory is basically
that I can start using some of these
devices and actually you can see some of
them here yeah I gotta give you figure
out like whether the programmer is
confused or frustrated with what they're
doing maybe that's not the time that
they should be actually typing code
maybe they should go ask a question of
somebody else okay so are you actually
measuring the same kind of physiological
mental responses so I'm using a slightly
different set of sensors so the one on
my wrist here this is a shimmer 3gs r
plus sensor which is basically measuring
house how much sweat I'm putting out on
my skin which is the measure of arousal
how much I'm paying attention to what
I'm doing right so if it's a low signal
I'm kind of probably just came back from
lunch and not really paying attention
maybe that's not a good time to be
coding we also have this sensor this is
an eco Mimi set of cat ears over here on
the front is an EEG sensor and the EEG
sensor is placed against the forehead
where it's basically measuring be
basically one part of the prefrontal
cortex on the left and then there's a
little ground that goes in her ear
nobody'll even though you're wearing it
and yours kind of like like that it
worth to show basically like the ears if
I'm really like paying attention the
years will pop up and then if I'm super
calm like they kind of relax and the
years go down wow this is built for the
japanese market
so it's I could certainly see the social
value of yeah hey that person like you
try to use the ones without the ears so
we can like plop ears off actually you
could buy new years for it I like to be
fashion accessory business which is kind
of cool so we've got those kind of eight
years and then what we also do we've
also been using eye-tracking so this is
where the computer itself is projecting
infrared light at your eyes and trying
to figure out where your pupil is and
then it knows how far you are from the
screen and using geometry you can figure
out what exactly are you looking at on
the monitor Wow so when you're
programming we want to start and you get
confused we want to find out oh it was
that class or that method over there
that got you confused or that was the
trigger for Ewing mom used I know we
actually have some video of all of this
in action we're gonna roll that video we
take a look here great so what are we
seeing here this is my eye tracking this
is a visual studio programming
environment the little red ball that
you're following is where the subjects
is actually looking on the screen as
they look at that code yeah we've asked
them to just read the code and there's a
question at the bottom of the code that
what it draws two rectangles and they're
asked if these two rectangles overlap
and if now you can see this huge red
thought that means the person stared at
that one spot on the screen Wow because
that was particularly confusing and
particularly difficult for that person
he's actually doing it multiple times
before he starts reading the rest of the
code you can see a picture and picture
of the subject in the bottom of the
screen there and this particular thing
will actually was kind of difficult just
because it was sort of spatial relations
for well most people is just actually
kind of difficult so you're using
machine learning algorithms draw
conclusions from these from all the data
you're getting here to explain the
process of machine learning that you're
employing so we're trying to build a
bunch of different classifiers to tell
is the person experiencing difficulty
did they feel that what they're doing is
tough for them so we had a whole lot of
people come in about 15 people come in
and do eight different tasks each person
took about an hour and a half to do it
while we were measuring their EEG
watching their eyes also measuring this
on my the GSR device on my hand to
measure how attentive they are and then
we take all those signals into our
machine learning environment and what we
were doing is trying to predict
three things one was if we watch 14
people do this task and then we take the
last person can we predict as the person
is working is that task difficult for
that person doesn't work that well what
works better is if we say well we
watched everybody else do this task if
we then watch a new person do this task
can we figure out what's going on and
then in fact we do really well in that
kind of environment and so we're trying
different combinations of that to get a
classifier that will actually run as the
programmer is working we're in real life
you don't know what the task is like the
person is supposed to be working on a
bug or writing a new feature for their
program and there's no beginning there's
no ending it's just kind of like it's
getting hard it's getting easy but when
it does get more difficult that's the
point where we want to try to intervene
in the programming environment and do
something to either make them pay more
attention or maybe to get them to stop
or slow down or maybe ask a question of
somebody else so you're studying you
know programmers you're looking at
drivers if we've stuck this on somebody
driving was trying to write code with
this is on fire pretty much yeah they
would get stopped by the place we have a
big online audience joining us today and
one of them just wrote into your and
says what type of secondary tasks did
you analyze you know they want to know
talking changing my music texting yeah
right question yeah it's a good question
um so we've been using generally a lot
of working memory tasks is we're
thinking about someone who's driving and
maybe trying to weather it that's
involved in having a conversation it's
also if you're trying to remember the
direction somewhere you have to store
something working memory so there's a a
task called the end back which is used a
lot in research where you have to so
this is a proxy for real task so I don't
imagine anyone to actually do this in
the car but this you can set it up so
that you hear a series of numbers and
you have to respond with the number that
you heard to previously from the one
that you just hurt so you're listening
to the information and storing it in
your head and then so as you hear these
numbers when you hear you have to
remember what you heard two back there
and then update it and so this can be
you this has been used in lots and lots
of studies and this is really just to
calibrate the system and say this is
what a working memory
would look like and it's not realistic
for something someone would do but we
can then train a classifier using that
that can then look at other tasks that
you're doing and see if it looks similar
to when you're doing that elevated
cognitive task or not Wow um yeah this
is while some fascinating stuff thank
you both unfortunately route of time if
I had that on the ears would ago at a
time for the segment thank you both very
much okay thanks for stopping by
explaining a remarkable advances in this
technology it's really fascinating stuff
thank you both so much thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>