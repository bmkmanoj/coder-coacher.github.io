<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Fusion4D: Real-time Performance Capture of Challenging Scenes | Coder Coacher - Coaching Coders</title><meta content="Fusion4D: Real-time Performance Capture of Challenging Scenes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Fusion4D: Real-time Performance Capture of Challenging Scenes</b></h2><h5 class="post__date">2016-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2dkcJ1YhYw4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we contribute a new algorithm for live
multi-view performance capture that
generates compelling high-quality
reconstructions of non-rigid motion and
shape in real time our system takes
noisy input from multiple cameras in
this case eight def cameras and produces
a temporally consistent 3d model in real
time this model can additionally be
textured with the RGB data the input to
our system our RGB D frames an
Associated segmentation mask
captured in real-time from a performance
capture rig a learning-based technique
is first used independently on each RGB
D frame to estimate a correspondence
field these correspondences are used to
initialize a non rigid matching phase
that aligns a volumetric model to the
input point cloud' using embedded
deformation this warped model is then
blended volumetrically with the data in
a novel step which is described in
detail in the paper this produces the
final result here we show another live
capture using our system notice how the
details on the clothing such as the
skirt are being reconstructed faithfully
also note the topology change that
occurs at the beginning of this sequence
as the hands move from the hip to above
the head also note the noise in the
input sequence we further demonstrate
our real-time technique in a number of
challenging sequences again captured in
real-time in this sequence a performer
is first taking off their jacket which
is an extreme topology change then their
scarf which is another topology change
followed by the large motion as they
wait their scarf around our system is
also robust a large frame to frame
motions as shown in this fighter
sequence this robustness comes from both
the learning-based correspondence field
estimation as well as our non rigid
matching scheme our system has no prior
on the scene that's being captured and
does not use a skeleton model
or other kinematic model associated with
human shapes allowing arbitrary scenes
to be captured such as this dog
interacting with their owner in this
sequence we show multiple people
interacting a topology change as the
ball is being thrown from one person to
the other as well as large motions of
the ball another sequence shows the
detailed interactions between a person
and a deformable object in this case a
teddy bear again it's worth noting that
these reconstructions are being
performed in real time we believe that
this type of real-time performance
capture has many different applications
for example this could lead to the
ability to watch a remote concert or
sporting event live in full 3d another
challenging example is shown here where
a performers hair is being robustly
reconstructed even though there are some
artifacts here we show an example where
the user is interacting with multiple
objects even simultaneously in this
example the user actually steps on a box
and breaks it forming a big topology
change we believe that these types of
challenging scenes have not been
demonstrated by any real-time system yet
and our hope is that this type of live
performance capture will lead to many
new applications
in these last two sequences we show very
detailed interactions between a
performer and an object in this case
being deformed in very fine ways as well
as interactions between two performers
in this case involving many complex
poses we compare qualitatively to
state-of-the-art technique in the middle
is a reference volume being
reconstructed non rigidly
as in the dynamic fusion system and on
the right a template is accumulated and
then tracked as in the work from xel-há
for a tell from SIGGRAPH 2014 note how
topology changes and large motions cause
inconsistencies in both approaches this
is because the template or reference
model becomes out-of-date with the real
world data instead our system shows
robustness because our reference model
is continuously updated supporting
drastic changes in topology and
alignment errors we also show a more
quantitative example here where we
compare to the work from Colette a towel
from SIGGRAPH 2015 here notice that our
error maps are comparable to this high
quality offline system but we require a
fraction of the compute and less cameras
again the state-of-the-art real-time
techniques such as from Newcomb and
xel-há suratul cannot handle these
kinds of large motions finally we show
reconstruction examples of our system
running in real time notice here that
the frame to frame motions are
incredibly large and yet we are able to
reconstruct fine scale shape as well as
non rigid motions note however there are
some artifacts appearing due to the very
large motions this includes some holes
appearing in the 3d model as well as
some over smoothing due to alignment
error but again our result is in
real-time thank you for watching</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>