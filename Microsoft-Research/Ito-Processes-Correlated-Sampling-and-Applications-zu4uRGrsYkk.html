<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ito Processes, Correlated Sampling and Applications | Coder Coacher - Coaching Coders</title><meta content="Ito Processes, Correlated Sampling and Applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ito Processes, Correlated Sampling and Applications</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zu4uRGrsYkk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good afternoon so we were starting a
summer tradition that Nathalie Niall
started here years ago love expository
talks and this one has also a specific
aim to prepare us for Ronan L Dan's talk
tomorrow
so happy to welcome James Lee who'll
tell us about discrete Ito processes and
I'll tell you about Ito processes not
discrete processes okay so the at a
broad level the talk is about correlated
sampling which is what sort of we might
call in computer science or or path
coupling as one might call it in
probability basically a way of sort of
computing a coupling or describing a
coupling between two random variables in
some kind of filtered fashion so you
sort of slowly sample both random
variables and you're trying to minimize
something so actually many times in
computer science one is trying to
minimize things like communication
between two parties for instance and
communication complexity or and
probabilistically checkable proofs and
as we've all said okay so the point is
that in the in the Gaussian setting
actually this correlated sampling in
some sense is given by this Ito
processes and there's a whole beautiful
Theory the Ito calculus to analyzing
them so I want to talk about a bit about
this today and how you can use it for
some geometric applications and also to
set the stage for what Ronan will talk
about tomorrow but actually let me
motivate what's going on now by starting
with telling you what Ronan and I proved
so ok ok so suppose we have a and by the
way as you've all said this is supposed
to be elementary so if you have any
questions please interrupt or ask okay
so let's let's start with the function
on the hypercube ok and let's define
this what's sometimes called the
bonhomie Beckner noise operator okay so
this is an operator which Maps F to at a
point
X
to the expectation over this random
point this random point of the hypercube
X hat where X hat is described in the
following way X hat I is going to be X I
with probability 1 minus Epsilon
and it will just be a random plus minus
1 independently with probability Epsilon
ok so you should think about this for
epsilon bigger than 0 you should think
about this is some kind of smoothing
operator you you averaged F over small
balls or you can think about averaging
over short random walks in the hypercube
ok so just as a sanity check let's check
ok if we apply no noise and we just get
our original function back and if we
apply sort of maximum possible noise
then T 1 of F is just a constant
function which is the expected value of
f expected value over the uniform
measure on the queue ok so one might
suspect that when you apply this
operator you tend to take functions that
were you know you tend to smooth
functions out because you're doing some
kind of averaging and in fact ok it is
the case so let me remind you about
hyper contractivity and here I will list
some people in alphabetical order so in
other words the listing of their names
has no bearing on anything it's a set
because I should probably have something
or we can do it ok ok which is the which
is the following sort of phenomenon that
given such a function f what we want to
say ok for every epsilon bigger than 0
for every P bigger than 1 there exists a
Q bigger than P such that if we okay
such that the Q norm of T epsilon F is
that most of the p-norm of F ok so ok so
the point here is Q is bigger than P so
we apply some noise of the function and
average the function gets smoother
what's that no no what do you mean no
there's no constant in fact if you want
a constant then it's it's only known to
be equivalent it well it's okay
it's false in general that if if a if a
Markov operator satisfies this with a
constant and it satisfies it with
constant one constant one is called
hyper contractive with a constant it's
called hyper bounded I think this is the
terminology it's used
anyway it does all with constant one
okay for some q bigger than P but you
know this depends only on Epsilon and
how big P is okay
but the point is that the function gets
smoother we went from having an LP
estimate to an lq estimate right and so
if you if you think about this means for
instance combinatorially this encodes
actually like small set expansion in the
hypercube because it recalled something
about the isoparametric profile of the
queue okay and this is very useful kind
of theorem yes yes so the point is it's
you know none of the things depend on on
if that's sort of the that's the point
so yeah there's epsilon P and Q such a
for every F this holds okay hmm okay so
now what we want to do is we want to
prove something in this spirit but you
know what but here we have some operator
estimate on F we have an LP estimate so
to tell you this conjecture of Tala
grond
we want to actually basically make very
minimal assumptions on the on the
function f ok so let's simply okay so
let's make the following assumptions
assume that F is non-negative and has
expectation one with respect to the
uniform measure okay by the way notice
that this hyper contractivity has
nothing to do with there's no it's not
about cancellation here you can replace
F by the absolute value of f and this
inequality only gets stronger
so this is about non-negative functions
it's not
somehow magical cancellations in these
averaging okay so let's let's take an
arbitrary function and just normalize
those expectation 1 on the cube so what
can we say about for instance the tail
behavior of such a function not very
much we have only the estimate coming
from Marco's inequality which is at the
probability that F is say bigger than
alpha is almost 1 or alpha we have
Markos inequality so what telegram
conjectured and I'll write the
conjecture now is that if you apply some
smoothing via this noise operator to a
function then actually you get tails
that are better than Marcos inequality
so the okay so here's a conjecture made
by telegrammed in 1989 I'll start this
new trend of putting the the prize money
in the also in the okay so it's worth
$1000 if you can solve it so the
conjecture is the following for every
amount of noise you might want to apply
there exists a function you'll see where
this function comes up in a second this
is the this is this function just
represents the tail that's better than
markers inequality such that again for
every F so ok here the assumption
applies to the theorem so f is
normalized at expectation 1 so for every
F probability that T epsilon F is bigger
than alpha is that most P alpha over
alpha and okay okay so this fee
represents a beating of not beating
sounds violent but an improvement over
Marcos inequality right so for it for
every fixed amount of noise if we if we
average that noise then no matter what
function we start with we improve the
tale okay so this is the this is the
conjecture ok so one thing you might ask
is what could you expect here so
the optimal thing you could get it would
be something say some constant depending
on epsilon divided by alpha square root
log alpha so the optimal thing you get
is theof alpha being 1 over square root
log alpha this is achieved for instance
if F is just a delta function at a
single point and it corresponds I mean
well it corresponds to the a delta
function in the cube when you apply some
noise looks kind of like it looks like a
half space so more general you can think
about this this is tight for balls in
the hypercube okay this is bound okay so
that's the conjecture I guess I should
yeah so right now the conjecture is open
for it's this this the conjectures for
every epsilon but it's still open to
good for any epsilon and it's open to
prove it
even if F is the indicator of a set okay
well it's the scale indicator of a set
so it satisfies this bone all right so
the conjecture is still open I will say
that sort of many people that actually
here worked on this problem so Ryan
visited here for a month years ago work
was working on the problem Jonas Sherman
was an intern who spent his whole summer
working on the problem and also well Gil
told me that he and Al and Jeff also
worked on the problem during a visit
anyway so you can solve it you can also
sort of you you know if you're more than
a thousand dollars you minimize the
future cost of Microsoft employees
working on the problem okay okay so
we're not gonna talk about this one
today but what we what what Ronan will
approve tomorrow is the is that the
Gaussian version is true okay so so
let's say what is the gaussian version
okay so I need some objects one is some
n-dimensional Brownian motion so one can
state the conjecture easily without
Brownian motion but the but it will be
fundamental and what comes next
that's one thing okay and I'll take a
function now in our hand non-negative
let's assume okay that the function is
expectation one okay so if I mean the
the Brownian motion at time one just has
the the distribution of a n dimensional
Gaussian so just to be just to be clear
and at the same time introduce okay
so gamma n is the N dimensional Gaussian
measure so we assumed that the expected
value of F is one okay and then I also
want to introduce this semigroup so okay
where you start a Brownian motion at X
and you average it and you average the
function f under this Brownian motion
okay so with this now I can state the
layer okay let me say it this way the
following theorem for any T less than
one okay and say alpha bigger than than
two doesn't it's not so important we
have the the probability okay we'll come
back to this quantity in a second but
this is bigger than alpha okay is that
most some constant depending on T okay
divided by alpha log alpha to the
one-sixth there's also some log log
alpha term but let's since then it's 1/6
is not tight since it should be one half
let's not be late with a log log alpha
term okay this is the this is the
theorem run annual proof tomorrow I'm
not gonna say much more about it except
to notice what's happening here so you
know what what does this look like when
we first take a Brownian motion for time
T and then average over sort of a
Brownian motion for time 1 minus T right
the right picture is to think about sort
of you have a Brownian motion up to some
time T and then you compute the sort of
the average of F well you can think
about as the average
f over sort of a Gaussian with variance
1 minus T or more geometrically the
average of f where you average over the
rest of the Brownian motion you think
about a Brownian motion at time 1 you
sample it up to time T and then you
average over the future all the way up
to time 1 right Yes BT start at 0 yeah
okay yeah yeah so okay so the point is
sort of what is this quantity right if
we if we went all the way if T was equal
to 1 if we all could go all the way to
time 1 then what we're just looking at
is is f of B of 1 when T equals 1
there's no averaging at all and we're
just looking at this quantity so it's
just F and this is just F at a random
point of Gaussian space so we can't
improve Markov for such a function just
because you know you can just yeah you
could choose f to be you know like J you
can just choose they have to be the
indicator of a set and then you know
then the tail will be exactly achieved
sort of at the level of the set but now
what we say is well we don't go all the
time one will run the Brownian motion up
to time T you can think about T as close
to 1 if you like and then we'll average
over the average over the rest of time
average over the future if you like
that's another way you can write it as u
Falls pointing out you can also think
about this as a doob martingale which is
a yeah
so it's just it's it's sort of the
expectation expectation at time one
given the path up to time T okay so Li
okay so this is the this is the proper
analog of the of the conjecture in the
cube and in fact one can see this is a
this is a special case if you could
prove the conjecture for the discrete
cube we've proven in Gaussian space okay
so let me just to finish start talking
about this let me just say that okay I
should mention that ball part ignores
all the sheds and loss in 2010 okay
proved that you can get some bound it's
not this is not as good as they look
it's some bound but the constant depends
on the dimension and then in fact it
depends exponentially on the dimension
this is the whole point of this is that
if the dimension free phenomenon so okay
so if one but actually you know even to
prove it in the case N equals one is an
exercise and N equals two is already
more than an exercise but the point is
to prove it something here which is
independent of dimension okay so so
that's all I'm gonna say about this
Ronen will will prove this tomorrow
but now what I want to talk about is is
sort of the okay so now you could think
about just think about the case when F
is the indicator of a set okay in this
case scaled by the measure of the set so
it has AK station one okay so now we
have some set sitting out here and we
want to prove we want to prove something
about this set s okay so if you look at
what's happening here you know to study
this at s we we sort of take a Brownian
motion for some time and then you know
and then average sort of average over
the future and see sort of like some
piece of s under this process okay now
the problem with doing this this process
like this is that this theorem is sort
of interesting when the measure of s is
very small so if we just took a Brownian
motion and try to study s by
sort of like how this Brownian motion
sees s then most of the time of course
this Brownian motion will wander away
somewhere else off in space and will not
see any of us at all right I mean that's
representing the fact there is this sort
of 1 over alpha here which when alpha is
going to infinity ok
so so okay Brownian motion is nice but
it's not quite appropriate to study the
geometry of this set s because you know
it doesn't it rarely comes too close to
s if s is small ok so what do what we
would want to do is consider a different
process let's call it WT which is a
which is Brownian motion conditioned to
have law F at time at time 1 ok or if F
is just indicator we said this is
Brownian motion condition to fall in
this set right there now if I condition
that I fall in this set then I then I
sort of you know I get rid of all of
this
spurious information coming from
Brownian motions to just wander far away
from the set ok so ok so we'd like to
sort of study this property so one way
that you could form such a process is
just you know sample a point of s
according to the gaussian measure and
then just take a Brownian bridge to this
point now this is not very useful for
studying the geometry of s because I
mean we're essentially writing s as a
union of points and then doing something
for every point right so this is not a
generally good way to study the geometry
of a set what we'd like to do is have
something like a Brownian motion so
which sort of like approaches s but but
sort of slowly ok so that it's you know
so that you see what's happening along
the way ok so I mean what you should
think about is we want to have some sort
of local process that approaches s and
you know in general the process wants to
be like a Brownian motion except for the
fact that it has to hit s at time one so
suddenly the process kind of feel some
pain at every step up from the fact that
it's being pulled towards s ok and it
turns out that by studying the amount of
pain that this process feels you can say
it says a lot about the geometry of s so
for instance the pain that you're
feeling at time one will turn out to be
related to the surface area this which
makes sense because it's
one you're just about to you know step
into the set
yeah so that's gonna be today we'll
basically set in the geometry of sets
like you know sort of like by
empathizing with the pain of this
modified process tomorrow
Ronan will do what many that people have
done throughout history which is once
you understand something then you try to
hurt it so Ronan will be basically
tomorrow will be sadistic and see what
happens sort of like whenever the
process is feeling pain if you you know
push it a little more you know like you
know sort of see how it responds okay
but today we're just being empathetic
okay all right so okay so this is sort
of a that the general idea it makes
sense we would like to have this process
that lands an S at time one but gets
there in some slow way that sort of
examines the geometry of s and if you
think about it sort of if you do if you
have this averaging over the future then
when you do this you're kind of you're
kind of looking at the geometry of s at
many different scales you see it for a
while from far away and then from
mediums distance and then closer okay so
this is gonna turn out to be important
okay so the question is okay what does
it mean
alright so now let's consider processes
that do exactly what I said okay so
let's try to see how we could build this
w so okay at time zero is just going to
be at the Brownian motion it's just time
zero and then let's see how okay and
then W is gonna change a little bit okay
so and I want it to change like a
Brownian motion plus some drift apply to
this Brownian motion so this is going to
process WT is gonna be of this form and
and I want this drift to be to be
predictable so at time T you should know
exactly what is the drift you want to
apply to the process okay and then we
want one more property here and I'll
stop writing after here because of its a
little bit low which is that a time one
we have the log of the F so so okay so
what is this thing at time one if we
integrate it it's the Brownian motion at
time 1 plus just the integral of the
drift from zero to T and I want this the
last condition should be
that this is this is distributing
according to according to F or if we
have a set just according to the
Gaussian measure on the status right
this is the description of the process
and the point is I mean you can come up
with many such processes like this right
like I mean you could just you know do
nothing just screw around until very
close to time one and then just suddenly
jump you know to a point of this set
okay but we want to consider sort of but
you should think about this VT as some
kind of yeah this is the pain that
process is feeling so you'd like to do
this in a way that kind of minimizes the
amount of pain that the process feels
along the way okay so okay so let's
let's give a first of all okay I mean
obviously if the set is very small or F
is very far from the gaussian measure
you will have to feel a substantial
amount of pain to get there
okay so here's one way you can measure
measure pain in terms of the relative
entropy okay so this is in entropy so
the relative injury of F with respect to
the gaussian measure is just okay it's
just the expectation of F log F this is
the definition of relative entropy and
you should think about okay just to make
sure that sort of everyone sign
conventions are in the right place if F
is sort of constant if it's close to one
then it implies that the the relative
entropy is small and if Fe is you know
if F is sort of spiky in the sense that
it's very far from the gaussian measure
at some places then it implies that the
relative entropy is large this is the
way you shouldn't be thinking about
yeah okay yeah so here I've conflated
the a you've all saying I've completed
the the the the this is really a this is
really F D gamma and the gamma and I've
conflated the density with the measure
but actually people do this all the time
so I mean good company to do to make
this to make this choice and if you
think about it in discrete variables
this is if you were as for instance on
the cube and this was the uniform
measure on the cube then this is like
the entropy deficit Aleph you know when
F is uniform it would have entropy zero
because it has full n bits of entropy
and when it was on a single point it
would have relative entropy n because
yeah okay because it has no entropy okay
I mean because the corresponding this
region has notion has no Shannon entropy
right the point being that Shannon
entropy and relative entropy have
different signs so okay all right so now
let me tell you a theorem various parts
of the theorem are due to former and to
Josef logic I will say we learned about
it from from Joseph's work okay so the
theorem is the following if you want to
okay so the relative entropy of F with
respect to the gaussian measure is
exactly the minimum over all drifts
satisfying star okay so I didn't put a
star here but let's call this star okay
so we look over all drifts that sort of
satisfy the fact that at time 1 we have
where we're distributed according to the
density F of something beautiful which
is this okay
so the relative entropy of F with
respect to the gaussian measure is
exactly equal to the mineral amount of
energy you have to expel in order to in
order to push the Brownian motion to
have to have a distribution f at time 1
right does the equation make sense it's
a yeah okay so this is the equation and
even more than that there's an explicit
form for the optimal VT which I mean
Optima is attained it is it's unique but
let's say and the optimizer is VT which
is has this formula and I'll explain in
just a second
this woman is also equal to gradient log
okay okay here's the here's the theorem
okay so what does it say it says that at
every point in time what you should do
is kind of you should look in the you
should look in the direction in which F
is increasing multiplicatively the
fastest but it's not F it's sort of the
average value of F over the future is
increasing the fastest okay so so in a
second I will tell you about the proof
of this theorem but for okay so but I've
decided okay in some sense yeah this
formula looks a bit strange or I mean
maybe doesn't look strange it might seem
like it's kind of the right thing but I
want to stress the fact that this is the
most natural obvious thing to do okay so
so to do that let's let's go back for a
second to the to the discrete cube and
let's just let me just tell you the same
process in the discrete cube and then
there you'll say oh of course
okay that sort of motivates this form
for VT all right so now again we have
it's the same set up sort of all in all
the philosophy is the same we have a non
negative function expectation of F
equals one and we like to sample
you can think about we'd like to sample
a random variable according to you know
with the according to the density F
right so how can you do it
here's a very simple okay so we want a
sample let's by analogy sample W
according to F okay so how might you do
it well okay
you might sample the first bit so the
remember sort of W here this is a random
string in the discrete cube how might
you do it well you would first sample
the first bit according to the marginal
distribution on the first bit then
sample the second bit according to the
marginal distribution on the second bit
conditioned on the first choice for the
first bit and so on you're just okay
okay so let's just so a well let's just
compute the the biases you would apply
at every step right you're just you're
at every step you're flipping some
biased coin right to decide whether you
should set the coordinate to be one or
two minus one and let's just compute the
biases and you'll see that the biases
are exactly the analogues of these
values so okay so let's okay so let's
define okay so suppose that we've we
sampled sort of w1 w2 these are the bits
of W of W up to I minus one how do we
sample the next bit okay
so let's define VI to be the expected
value of okay B so and again analogously
to what we're doing over over there B is
a uniformly random on the cube okay so
okay so now VI will will sample
according to a uniformly random bit if
if if the past had been the samples we
make sorry and also if the okay so this
is the expected density at
the string if we choose what how we've
done so far and set the 8-bit equal one
and I'm gonna subtract from this the
expected value of F at a random string
if we it's exactly the same thing so
this if we if we've if this what we've
seen so far but the I it bit equals
minus one okay and then I'm gonna divide
this by the by sort of by the average of
these two things which is which is the
expected value if you don't condition on
what happens to right bit okay okay so
up to I minus 1 W up to WI minus 1 okay
and then we should put half here for the
formula I want to write down okay and
then how will we sample the eigth bit
with the eyes bitch is gonna be one with
probability 1 + VI / - yes and minus 1
with probability 1 minus VI / - okay
and what we're doing here is just I mean
sort of the if we average over the
future we just see this thing right so
this thing is exactly half of this plus
half of this because this thing chooses
like but to be one or or minus one
uniformly at random and so what this VI
is computing is just how much more
density is there in the direction of I
equals 1 versus in the direction of I
equals minus 1 ok so it's exactly the
it's exactly the conditional proper this
is exactly the yeah this is exactly the
conditional probability that the okay
it's exactly the marginal probability
that the if--but is 1 conditioned on the
choices we've made so far so and and I
just want to sort of like now if we
define sort of this partial derivative
operator so partial derivative of G at a
point X is well set the if--but to 1
look at the difference when we said - I
put - 1 versus setting that
to minus 1/2 then this VI is exactly the
partial derivative of you know okay
I'm gonna use shorthand at this fi minus
one just means that we said it's just
this this is the divided by by this okay
so this is and we this is sort of okay
it's just the partial derivative so you
see the formula is actually exactly the
same one as the one we put here this is
exactly the derivative of the at WT
zouri are now this p1 minus T is
averaging over the future so it's
exactly the derivative it's exactly
measuring sort of how much do we you
know the the the sort of the the rate
that we should change multiplicatively I
mean okay sorry uh does it sort of does
it make sense what's going on here these
V eyes are exactly partial derivatives
so sort of like by analogy this
shouldn't be they shouldn't be
surprising anymore they says each other
just like conditioned on the past how
should i sample in the future that's all
I was trying to say yeah okay so there's
a reason that everything becomes so the
answer is yes you can say the same
statement the problem is that in the
continuous setting in in Ito processes
sort of like you know all the
expressions are much nicer so this is
actually something like e to the log of
1 plus blah blah blah but one doesn't
need all the parts of log just needs
okay I'll say something about that in a
second you can say the same thing in the
discrete setting it's just that the
expression will not look as nice and in
fact it sort of by necessity if these V
eyes are much bigger are big if they're
not epsilon then you will not you know
you will get a different expression here
the sort of you're feeling since you're
feeling the VT instantaneously okay
things work out much more nicely
okay let me just say one more thing
about this setup which is also that I
can I can tell you okay I can tell you
the value of F at this string W just by
examining what happens here so I'll just
I'll make the claim and then so this is
w I VI okay so this is my claim on the F
at W and the reason is just because you
know if we if we happen to choose the
sign that goes in the direction of V I
sort of like our sign is is in the right
direction then the value of F increases
by you know 1 plus VI and if we choose
in the wrong direction the value
decreases so if one thinks about it just
for a second this is exactly the fourth
well no no this is this is that both
sides are random variables here this is
exactly what we want
yes yeah yeah this is this is a random
variable this is a random variable right
everything is OK all right so okay so
now yeah let's go okay so now okay so
actually I think let's let's change the
order a bit now let me give you a couple
of applications of this theorem and then
I'll explain to you the proof the proof
well I'll explain to you some part of
the proof ok we'll see after I give you
the applications we'll see how much
energy how people have for the proof but
the applications in cold sort of the
interestingness of having this minimum
energy coupling between between some
measure that samples from f and some
measure that sample you know and the
bretton Brownian motion okay
yeah so you can say oh okay so I mean it
doesn't make sense anymore
it can now be I mean if you look over in
this setting to say to what I had what
happens now
you'll get probabilities that are bigger
than you know that are bigger than one
or less than minus one I mean I what
will happen I don't know but but what
does it mean what will happen it's not
clear I know if you it's not clear
haven't even interpret this process well
okay what what do you well defined I
just if you ask me what does he if it's
better in some sense I'm not sure
because I don't actually know what is
the I mean you will not end up certainly
you will not end up in the law of F at
the end if you do that you will I have
no idea where you'll end up but you see
I mean if you're if you're not careful
you could like overshoot the set I mean
you can you know if you're not yeah then
you will not end up in the I think okay
I I think but now I have to think about
it but since we're
it's a duck no no no you want exactly
overshoot but you you could do some kind
of a Scylla select or anything it's not
clear what will happen at time one right
you I guess what you're saying is you
know as you approach time one you're
sort of you know you are insisting that
you hit the set but now you could be
jumping over the set back and forth many
times especially if the set has some
crazy boundary and you don't and you
lose this smoothing effect
okay so let's pause on this question for
a second let me tell you one fact about
this optimal VT which will be important
and if we get to the proof of this
theorem then then we'll see the fact
that this this VT is a martingale okay
so the right so the so for instance the
the expected direction at time one said
can you know at when you're at time T
the expected direction you'll be
pointing at time one is a is the
direction you're pointing now okay so
you know alright okay let me give some
applications and then then we can talk
about the the proof okay so what the
first application is the log so live in
equality in Gaussian space and I should
say also both these applications are due
to I mean the are due to Allah heck not
the really the conclusions which are
classical but the use of this to prove
them okay so the first thing is the is
the log so black inequality which is
which is equivalent by the way to the I
mean in the in the discrete cube for
instance the logs table inequality is
equivalent to the hyper contractive
inequality so should think about this as
a proxy for the thing we discussed at
the beginning okay so for this
inequality we need one quantity of a
function which is its Fisher information
so this is this with respect to the
galaxy measure and then if you if you
sort of okay let me write it also in
this way
which is also equal to this okay so if
you think about efference is that the
indicator of a set is just zero or one
value and then this is this is really
you know this is measuring the surface
area of the set in some you know the
gaussians are reserved the set at least
in some analytic sense okay so okay so
that's the that's the definition of
Fisher information and then the logs
don't believe in equality is just the
following the relative entropy of F with
respect to the gaussian measure is that
most one half the Fisher information of
F okay so it tells you that you know if
the function f is not okay this is most
first set if the service area of a set
is not yeah it's not too too big then
then the set has to be you know then the
the set has to be fairly flat okay
in general it relates sort of the global
ability of F to be different from the
gaussian measure to just sort of to some
local property of F okay so let's let's
now using this theorem let's just prove
the logs oblivion inequality and it's
really like completely effortless so
okay so the relative entropy is exactly
half now VT is gonna be the optimizer
half the integral 0 to 1 of this thing
now we use the fact that VT is a
martingale expected value of VT squared
is that most expected value of v1
squared right so this is at most half
expected value of v1 squared now but
just notice what is v1 v1 is exactly the
gradient of F yeah so v1 is exactly the
okay actually we need to do maybe one
more gradient log square this is at time
1
I see okay there was one mistake there
was one problem with going out of order
let me see how to correct this problem
was going out of order
ah crap
okay what is it if we if we look it's a
gradient F at W 1 square divided by F of
W 1 square this is not what we want we
want we want we want gradient of F at
let's put expectation here so it makes
more sense we want the gradient of F at
a sort of a random Gaussian point not at
not at a point of W 1 which is should be
according to F ok yeah this is a bit
this is a bit sad because now I'm gonna
have to write something and then ok ok
ok so here is the last step of the of
the proof which you won't be able to
understand for a second and then in the
last three minutes that I have I'll
explain to you the the proof but but
this this is because 1 over F of W 1 is
exactly the change of measure that that
sort of transforms W 1 W into Brownian
motion actually the whole process WT
into Brownian motion unfortunately you
didn't see this yet which is a bit sad
because what's that thank you
no no no of course of course of course
yeah you should have said it before I
started to do all this ok
yeah okay good yeah we only okay this is
yeah here I wrote something stronger
which is that it hopes for the whole
path but really we only want at that
time that at that at time 1 F you know
at time 1 this is the change of measure
and the point is that ok
so yeah the point is that w1 is
distributed according to to the F times
D gamma so f of F of W 1 is exactly the
yeah I mean this is it exactly gives you
the scaling of the probabilities or this
you know sort of the scaling of the
probability so that you map if you know
ok that you map w want to be one it's
exactly the change of measure from W and
to be one by definition ok ok that was
the proof sorry if the beauty was marred
by my confusion yeah ok ok let me give
you one other proof that doesn't even
need this change of measuring it's a bit
simpler which is the telegrams entropy
transport inequality okay so the
inequality here is that so first let me
write it I have to remember what is here
is also a factor of two so let's say
the inequality is the following
okay okay so here's another inequality
which is that I'll tell you in a second
the w-2 distance from any again this is
this is the shorthand for f2 gamma and
okay the WT is between any measure and
given by density F and the Gaussian
density squared is bounded by the Fisher
or by the by the relative entropy okay
and just very quickly what is W - W - is
the it's the earthmover distance between
the between the two distributions so so
in general W - between two distributions
you can write it as in probabilistic
notation like this so you look at all
random variables that are distributed
cording to mu and nu respectively then
you take a coupling between them this is
on a product space and you look at the
minimum distance here equal to the
minimum over over the the best coupling
between mu and nu okay
you can also just think about it is if
you think about the amount of sort of
just like piles of mass it's the you
know it's the least you clearly in
distance you need to move the pieces of
mass so that you move them Gaussian mass
to F okay so that's the that's w - so
this says that you know if a function
just to sort of like an information
there the quantity if if a function is
not you know has as small entropy of the
back to the gaussian measure then
actually you can move the gaussian
measure to that function without doing
much work okay all right so now let's
let's do the proof and hope I don't this
should be really easy so it will be hard
to screw this one up okay so this is
that most the distance between B 1 and W
1 simply because this is a particular
coupling of the two this distance is
exactly I erased the formula
unfortunately but it's exactly the
this is exactly the distance when I
sample this is the drift I apply to get
from w12 to from v1 to w1 right and now
we can just use convexity to say this is
that most 0-1 VT square I guess strictly
speaking we should put here in norm
square which is equal to the two twice
the relative entropy by the theorem
right so again you just sort of you give
you get sort of 1 again if you think
about this tree case the most natural
coupling and then if you just look at
the amount you transport over this
coupling it proves this sort of
inequality okay so alright so now we're
out of time okay so seven minutes in my
the way that was your chance to object
to the seven more minutes
you know I paused okay so so now you can
ask okay how does one prove prove such a
theorem in order to make the best use of
my time let me just okay how does one
prove such a theorem you do exactly I
mean you you just sort of like well
alright let me remind you since I erased
it what is uh WT it looks like okay it
looks like this so the point is this is
this is and what's called a neato
process okay and there is a calculus for
dealing with these things just in the
end let me tell you you know how okay
let me tell you what is the what is the
Ito calculus and it's very simple but
it's very it's coming out very powerful
because all of these you know it means
that all in basically all the error
terms that you wouldn't want to deal
with go away in the gaussian case okay
so here's the here is probably the best
way to understand the Ito calculus
consider the function which is e to the
BT
so the exponential of Brownian motion
right and suppose I want to ask you if
this is a if this is a martingale okay
so I say you know basically okay is this
a martingale
in other words are the infinitesimal
changes of this thing have expectation
zero okay yeah so if you ever lost 10%
in the stock market and then made 10%
back and then looked at your bank
account you would know that this is not
a Martin yeah okay but here so here's a
proof that it is okay let's just take
the derivative with respect to time so
okay so it's like either the BT x DB t
okay this is sort of how one takes three
lives in calculus and then just take
expectation over both sides and the
point is that okay this is 0 this is 0
because DB T is independent of BT it's
some right so this is equal to 0 okay so
that something so then this thing is a
martingale but of course this proof was
this proof was BS and the reason is just
ok so what do we really want to look at
we're sort of looking at what happens
when we we're looking at EDB T so we can
expand this by a a Taylor series what do
we get 1 plus DB T plus 1/2 DB T Square
you guys tell me when I can stop okay
ok good we get something like this and
now if we take expectation of both sides
what happens we get a 1 which is what
are we expected we were you know if this
was a if this thing was a martingale and
this would have been 1 we were just
multiplied by 1 an expectation plus 0
great ok ok the problem is that is that
the expectation of this thing really you
know you should think about it is we
compute expectation this is like half DT
if we compute expectations yeah because
Brownian motion has ok what's its you
know sort of non-trivial quadratic
variation okay I mean I'm I just some
people believe this immediately and I
don't know if
other people are concerned by this order
square root of DT then because of the
independence that kills cancellations
we'll just make the Brownian motion
constant so I mean the way you construct
Brownian motion is exactly you know
basically by adding plus minus root DT
this is how you construct Brownian
motion from simple random walk if you
have a better explanation you involve it
doesn't require so the point is that
when you try to do calculus with respect
to Brownian motion the the terms that
would naturally go away the second order
terms are actually real things ok so but
everything else goes away ok so that was
the whole you know that's that's the Ito
calculus that that you know the Ito
calculus is really that like when you do
calculus you know DT squared equals zero
and sort of okay I mean you should think
about it squared is equal to zero you
should think about BT square as as DT
and then everything else DT times DB T
equals zero and DB T cubed equals zero
okay you have to worry about the
second-order term for Brownian motion
that's what the eto calculus says so let
me just tell you for instance the you
know a lemma which is that if I want to
compute the derivative say of a function
of Brownian motion and in also of time
because I'll okay then normally what I
would do here is I would compute the
derivative of F with respect to time and
then also the derivative of X with
respect to the first variable DB T but
then Ito says we have to go one more
step and compute 1/2 Delta X square F DT
okay so this is the you know that's
that's like the whole of Ito calculus
that's sort of to compute the ridge with
respect to Brownian motion you have to
include a
a second order derivative for the for
the quadratic variation of the Brownian
motion okay so as an you know as an
exercise then you can see exactly you
know exactly what the what your
martingale should be right so you know
if you look at D BT minus T over two and
take the derivative okay let's just
compute what it should be if this is
very exact at time so it's minus 1/2
this okay plus B BT plus the second half
the second derivative with respect to
the first variable which is just the
same thing DT uh-oh there's a ok good so
you see what happens here which is that
this thing is a is the martingale term
this thing has excitation zero and these
go away okay so so this is you know this
is a legitimate martingale okay and now
that amount of time let me just say that
by using this you can prove the theorem
I can explain it to anyone offline if
you if you want but this is really all
you need and then you then you can okay
then you can prove this here so I okay
so I guess I should wrap up by saying
that so Ronan and I friend know how to
for instance take these proofs and
translate into discrete cube so you can
use exactly this method approve true
proof to prove the Locks of Love
inequality in the discrete cube with a
little more work you can use exactly
this method of proof to prove loksabha
life in the symmetric group and it's
unclear how much further you can go but
it seems like a very powerful kind of
method to do this correlated sampling
and then consider functional
inequalities along the path of the
sampling I should say it's not a new
method although you know I mean Burrell
was doing these things for at least 20
years and many other people but okay but
I mean you know this is so clean that it
should have a number of other
applications and and the theory goes you
know in you can go directly to the
district
via the sort of sampling I talked about
okay so let me stop there
easy trivial to see I mean if I have to
think about it what's not trivial so
that's sort of an easy question so if
you so mind if you remember perhaps
another way to see it is that if you
that if you remember before we wrote
down exactly what is f of w it was
exactly product I equals 1 to N 1 plus W
I VI where the VI is with the partial
derivatives so if you write down the
same formula go over there ok so then
you will see that that at time 1 you
should be recording to F the the benefit
over there is that when you write down
this formula because of Ito calculus you
only have to this is if you think you
write this as expectation of log and
then you only have to use the first two
terms of log and sort of everything
becomes much nicer but if you just write
down the analog here then you then yet
you'll see that that you distributed
according to F at time 1 or a drone
inside you could discreetly approximate
all the jumps and then and then believe
it and then transport it here
yeah yeah that's why I did the discrete
case because it's it doesn't take very
long but but but okay we should do it
offline I can if anybody's interested we
can stop and we can do the proof the
only issue is that you know one thing I
don't want to do I don't want to
calculate derivatives in front of people
because it's it's been mind-numbing so
you know there were there were I would
have to hand wave over one of the
derivatives you do have to do use some
Ito calculus somewhere so this year like
what what you're optimizing a discrete
world yeah unfortunately you mean you
can write down a quantity but it's not
nearly as natural and somehow that's
yeah that's somehow that's the benefit
of going to the of being in the
continuous case that sort of like you
know there are certain things that are
much cleaner here in the discrete well
it's not easy okay this pretty world is
tough because here you notice there is
no to do this sampling there's no
additional randomness this thing is
deterministic in the discrete world this
was just a bias and then I had to use
some additional randomness to choose the
bits this this makes things much uglier
somehow you know you could do
but if you see the second film will be
some publication out there there is yes
there is some well okay it's hard to say
when duality is not happening because
you know I saw so many times it was
happening but okay but I don't know off
the top of my head there is a duality
here because you know there is a duality
just in the in the notion of relative
entropy but ok but I don't see in the
discrete case how it would tell you the
answer immediately
each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>