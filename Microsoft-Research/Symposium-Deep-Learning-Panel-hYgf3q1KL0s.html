<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning - Panel | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning - Panel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning - Panel</b></h2><h5 class="post__date">2016-06-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hYgf3q1KL0s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
I'll just start with with the first
question so we know in deep learning
there's a lot of papers that you see
that our you know improvements to the
set of learning algorithms right to
small changes or you know important
changes we see this morning which are
you could say are sort of plumbing right
you know we need these algorithms to
work really well and what do we do to
make them work really well but there
might also be fundamental research
questions like you know what what don't
we yet understand about deep learning
and I wanted to ask everyone here if you
know they what they think about sort of
what is important between those two but
also if you can identify a set of
fundamental problem that you would
really like to understand and you
currently actually don't understand
there may be you know encourage other
people to find an answer for I guess we
just go sort of you know in sequence you
actually are you want to start you have
the microphone so that's a it oh you're
not in okay no it's not working for me a
very interesting question is how do we
expand the computational capacity of of
the networks that we are not using it's
possible to do many interesting task
like classification and so on with the
current feed-forward neural networks but
for instance problems like segmentation
reasoning about relations and so on most
probably require representations that
are more expressive than what we have
now I think it's very interesting
question how how these can be built into
the current systems okay for me I think
how to earn the networker structures
especially is a kind of connection of
the neurons work on iran's HD should be
connected so far you can see the most of
gravity was a successful net
computer vision is a covenant and that
right it's a its connections that based
on the the neighbor spatial neighborhood
and if they are close in space they are
connected but I believe that probably
there are some other criteria and to
model the correlation between neurons to
find their connection probably also
there are some new biology evidence
showing that for example you look at as
a human being and the six years old it
has a many connections between your own
pet owner owns and when the it grows up
and some connection just at this period
so why this happened it means that
probably the ways and the the network
they are jointly autumn eyes is not
simply design manually i probably i
think a property seized the words to
further our future study yeah so one of
the questions that that is very
interesting for us is the ability to
ingest all the labels that exist so for
example if you have become you can have
a lot of data as well a small fraction
of that data is going to have labels so
for example for images you're going to
have some images that have category
labels some of those images might have
bounding boxes are very few images are
going to have segmentation masks for
videos you're going to have more
variations of this for other domains are
going to have more and the question is
what is the principled way to take
advantage of all these labels where some
of some of them are costly to obtain but
even perhaps a single bounding box can
give you a lot of information so what is
the principled way of taking advantage
of all this yeah I actually agree with
what Sergei was saying are all the joint
of all of them in yeah I agree with what
Sergei was saying and since that we I
think we don't know how to combine all
this sort of disparate supervision
together in a really efficient way I
just feels like we should be able to do
better that our models with you know
just a few more
examples can use all their existing
knowledge to generalize these new
examples incorporate this all these
extra tasks you just don't have good
frameworks to do that at the moment I
think I'll give to two answers that I
think actually follow in the spirit of
what the previous speaker said first I'm
just going to copy what Jo Bates said a
minute ago when he asked me the last
question of how do we integrate all
these things together and do a single
greater confidence i think that's still
an open challenge and and and one that i
look forward to and then maybe a related
comment or future challenges i
specifically interested in if we can
have these architectures learn more the
way children learn or more the way
people learn leveraging what we know
from cognitive science especially as we
get into the realm of these joint vision
and language models if we're teaching a
new term to a would be nice to be able
to teach a new word to these models you
know with three or four examples the
same way you can train and teach a three
or four year old and so there are models
from cognitive science and and concept
learning models and be interesting to
see if they can you know see how they
can be brought to to this world as well
so one one direction that I'm really
interested in and seems very difficult
it's something I've been talking about a
lot but we haven't really found a lot of
good solutions I think Hong lack
presented some things in that direction
at this nips which is how do we discover
representations that capture the
underlying causes of what we observe and
the reason this is important is that if
you want to generalize to new to really
new situations the only good way of
doing it is by having a kind of implicit
model of how things unfold in the world
and that sort of is not something we're
paying enough attention to I think and
probably is more in the realm of bones
provides learning but can use any
sources of data we have including
labeled as excuse for what are the
underlying causes that that's nice
bridge to the next
you know top rated question here
unsupervised learning so there's been a
lot of excitement in unsupervised
learning lots of people are working on
it but it's not so trivial to actually
figure out how to evaluate whether your
model is doing well so some people
report probabilities on test data some
people look at pictures and they look
pretty you know the prettier the picture
of the bed of the model so the question
is how do we evaluate unsupervised
learning and how important is
unsupervised learning do you think for
you know deep learning in general so
it's an open problem and I think we
should work more on it one interesting
thing that has showed up recently in
some papers with genitive models is we
show the generated examples to humans
and their supposed to figure out if
these examples are coming from the
machine or are coming from the true
distribution of course the problem with
this is the machine could just cheat by
remembering examples by heart so you
have to make sure you have a way to
counter that by comparing with training
examples and that's also a common
practice one interesting twist is to
train a model to play the game of the
Turing test by trying to discriminate
between the generated examples and and
the training data and that's one of the
ideas that we've been pursuing it in my
group and Ian good fellow has been
leading in terms of a serious answer I
don't really have one except to see how
well the unsupervised representation
transfers to other tasks but that
doesn't seems to be a bit of a cheat but
which desk stand that's acting it's why
sensitive cheat it's part of the story I
be good ultimately that's what we want
so you want to have these tests my-my
facetious answer is I just show the
pictures to Alyosha afros and he tells
me if they're pretty and then I know
okay I think that unsupervised learning
without any in the other reason is
useless we should always do it for a
purpose so if we are trying to have good
classification then we can measure how
unsupervised learning is helping
classification if we want to do
compression then we can measure
compression and so on and so forth the
nursing is something that we used for
measuring how well the network had
learned the underlying distribution but
I'm sure there are others but yeah I i
would recommend you to always do
unsupervised learning for a good purpose
rather than just for a paper yeah I mean
exactly you know what is the point of
doing unsupervised learning the point is
tacchi maybe then take your model and
apply it to the task you're actually
interested in but what if you want to
apply it to many task or to ask that you
don't know yet with our that will come
in the future yeah I mean it's not it's
not an easy question I think like trying
to you know do some unsupervised
learning on a model then test it on a
suite of tasks does it do better like
that's what really what we're after we
don't really care if the images look
pretty or not like although it looks
really cool so that's what I would say
yeah I don't have much to add to what
the previous speakers have said so if we
can train a good representation and then
realize that we can actually use that to
train the best classifiers and
localizers and whatever else then that's
a good presentation and we can use in
supervised learning just because we have
a lot more unlabeled data than labeled
it yeah agree that both on service
learning and the superest learn years
ago used to learn the representation
which can separate or disentangle all
the factors as you can gather this kind
of resent ation you can just apply using
a simple as we a more linear class where
you can solve all this kind of
classification problems so so I think
even for also writes learning so you
better you can separate these factors
also we hope that they can also achieve
some environments for example our human
when we watch with a manipulator this
object to multiple to watch the multiple
wheels and also can track objects we
hope that the future has many variants
if we move the objects and sure
and in skill and the viewpoints and the
so far these are our experience if you
check the object you look at the for
example detection score you can see the
car to feature change dramatically which
is not good I would just like to comment
on your shoes comment if we have an
unknown task coming our way I don't
think it's very much different from held
out test label so we can just have held
out tests task right so it seems we can
take this a recommendation for the field
to come up with a good test suite for
you know testing or unsupervised
learning algorithms because right now I
think we still need to do that so maybe
another related question is so how much
how far can we get with deep learning
other words in AI in terms of solving a
I problem so we have like you know
logical reasoning or first order logic I
guess we haven't quite integrated that
fully in deep learning although people
are working on it so are there
particular fields within a I that would
really need some really new ideas in
order to be tackled and not everybody
has to answer I guess if you have a if
you have an idea about this then
I think that deep learning is has been
able to do something a part of what
human cerebral cortex is doing but only
part of it and i think that there are
many other things that like basal
ganglia and and so on that that we we
haven't really tackled at all so i think
that we are just scratching the surface
here definitely things like reasoning
symbolic reasoning this is something
that we can do I'm i don't i'm not
saying that we should implement symbols
as symbols but like sub symbolic
representations of symbolic reasoning i
think are definitely going to be there
and we don't have that like know anybody
else who wants to comment on this or no
okay so if anybody sorry ah there's a
question by juergen schmidhuber go go
for it you're in a max thank you so much
um I would like to add something to your
most popular question talking the
microphone please it's not very clear
can can can you gimme how do I don't
just talk into microphone can you hear
me yes that's good there we go I would
like to say something on your most
public question and the panel wasn't
very sure what to do with it but I think
it's totally clear what is the purpose
of unsupervised learning you you want to
compress the data you have a life long
history of observations and and actions
and then part of this history is regular
so you want to figure out these
regularities how do you measure whether
you capture the regularity well you see
whether you can compress it for example
through predictive coatings or you for
example a recurrent Network which takes
as an input all this history and tries
to predict the next thing how do you
measure the performance how do you
measure whether you have a good
unsupervised learning or a bad one well
you just use minimum description length
so so you you look at how many bits do
you need to encode so we can't network
or whatever you have that is doing the
predictions plus the deviations from the
predictions
the extra bits that you need for for
compensating for the errors of the model
and then the total number of bits per
standard minimum description length
gives you a quality measure of how good
that unsupervised learning is now what
can you do with it that is then the
second way of evaluating the thing you
have to solve problems and reinforcement
learning or supervised learning now you
can take this thing as a preprocessor
and feed it into your reinforcement
learner or uncivilized liner and then
you measure can it learn more quickly or
faster and there have been many examples
over the decades since 1998 lees were
both reinforcement learning and
supervised learning became better
through these unsupervised pre-training
stages so I think it's not really an
open question we can certainly improve
the methods for doing unsupervised
learning but at least the objective i
think is pretty clear okay thank you for
your contribution is there any people
who have questions for the panel please
go to the microphone otherwise I'll just
go down the list so one question could
be can we learn something from biology
all right can we you know other things
from biology that we can get inspired by
maybe yes yes sure I just wanted to
comment on your guns comment about
compression I do agree that in some
cases compression is very important but
then we are always limited with the the
amount of representations we have so I
don't think that compression is
necessarily a good idea if you have a
certain type of information you want to
represent and process if you if you know
anything about the relevance of
information you should take that into
account and we are not really interested
in often we are not really interested in
compressing of representing the original
images but rather we are interested in
using them for some purpose so i think
that compression is nice if you have
unlimited and resources but otherwise
not do I can I say something on that or
better not
yes you can but keep it a bit short
maybe I'll try my best yeah so what you
are referring to Israeli the usefulness
of the data of course that is the
primary thing that we have to we want to
just optimize the policies of our
reinforcements manners and supervised
learners and so on and then the true
purpose of unsupervised learning in that
context it's just how well does it help
our supervisor learners or reinforcement
learners to solve the problem that's
true on the other hand all of science is
really just about finding regularities
in the data and all of science is a
history of data compression basically
whenever you come up with law such as
when you invent gravity for example or
the law of gravity you discover that you
can greatly compress through predictive
coding all these falling apples which
always fall down in the same way and
that means that you can greatly compress
and that's really useful if you have the
code for that for solving all kinds of
problems that are connected to following
apples okay so let's keep it at thank
you so was there another question maybe
Peter yeah so in the last few years
we've seen huge progress in deep
learning abstract representations of
sensory data of perceptual data but we
haven't really seen the same movement on
the motor end there hasn't been a huge
application of deep learning to learning
abstract motor representations or ways
that an agent can interact with the
environment so I'm wondering what do we
think is missing what's the research
direction we have to go in to achieve
agent that can actually intelligently
interact with a real environment well I
would direct you to Peter Beals talk
this afternoon and Anna panel there I
think there's still a lot to be done on
really apps high-level abstract
reinforcement learning but there is
progress anybody else we need people
like you to work on it
I think that hierarchical reinforcement
learning is a hugely important topic
we're working on it i think many other
people are working on it and I think
that understanding how we can compress
and generate sequences is one important
part there because eventually what we
want to have is high level high level
representation of complex action
sequences or complex interactions with
the environment anybody else else wants
to command against maybe data is another
big issue so if you want to model the
interaction between the agent I
environment you how to also Claire a
huge amount of data you know use a deep
learning so it's a kind of data-driven
have the image net we have they learn
the representation so we probably needed
that kind of date of a data set okay
thank you okay anybody else wants to ask
a question otherwise I will ask
questions okay yes please go ahead hi we
keep saying that we would like to the
deep network to learn like a child and I
was wondering if there is any reason to
believe that the the leather of
difficulty is the same for deep networks
and four children typically you right
now we could evaluate the difficulty of
a task by computing how many bits of
information you have in the network so
the question is is the the degree of
difficulty the same as it might be for a
child according to for instance soup
legit or something anybody who can
answer this
maybe you can rephrase your question
what did you mean by the number of bits
of information in the model and how it
relates to the rest of the question well
well I mean if we are considering a deep
network as a program we could evaluate
what is the complexity am I right so far
right okay so then we can say that we
can compare the difficulties of
different tasks right under 10 typically
recognizing your face is something and
trying to predict an action is something
else do you mean like the number of the
size of the program that's needed to do
that task that's what you mean yes and
what's the question and the question is
that we know that the children they are
learning in phases right there are some
activities there are some skills that
are required before others right right
so I think this is a very good question
in machine learning we tend to have a
model of learning this is which is very
very simplistic where we show all the
examples in random order and it fits
well a lot of the ideas we have about
learning but it's not at all of our
children learn and so there's a
realization maybe because of
optimization issues but maybe for more
fundamental reasons where people see
that it's sometimes better to train in a
sequence of tasks rather than directly
the task of interests and so some people
call that curriculum learning and there
are other names but but basically we
don't know how to do this well it's more
like heuristics that people use in order
to help training models which otherwise
seemed and trainable if you don't use
these kinds of you can think of pre
training as a different forms of pre
training as an approach to that and but
we don't understand this nearly enough
so I think it's good if more people
think about it yeah I think this is
going to be become more of a thing
curriculum learning as we get more and
more
located tasks and you can't just cold
start things and you need to start
introducing a curriculum into your
learning and these are all open open
questions on how you do that effectively
and how you have this continual learning
without forgetting there's some more
questions there hi related to the idea
of trying to get more sparsity in
networks and also just bringing some
neuroscience and I was wondering if
anyone's looked at trying to come up
with the concept of different types of
nodes so in there for the cortex you
find that there's specific cells that
make connections only two other specific
types of cells there seems to be some
types of rules about how cells will
connect in that way and that imposes the
type of sparsity in the network and is
this something that anyone's been
thinking about and do you think it might
be useful and well if you look at a lot
of the progress recently people design
architectures so things like neural
drink machine memory networks and the
kind of data structures that people tack
on normal neural Nets really or LSD ms
for example they all like specialized
architectures which seemed to be very
useful in a number of tasks and I don't
think we have a big picture of where to
go next but it seems important this
exploration has been very very fruitful
and it corresponds to different roles
for different types of neurons in these
artificial neural Nets somebody else
would like to say something no maybe
Kevin wants to ask a question yes this
is a question primarily for Val Paula
but I think max might be interested I be
interested in Max's opinions as well
which is so in in Harry's tokyo's
talking about eam and variational
inference and common filtering and then
he said let go of your inner
statistician and let's blur the model
algorithm a model inference distinction
and just treat it as a circuit can you
talk about the pros and cons of that
compare
more classical methods belief
propagation and so on so i would say
that in supervised learning the reason
why this deep supervised network works
so well is that we are not trying to
impose our idea what kind of internal
representations it should use we are
just giving it enough capacity to
represent the computations that are
needed to get from the input to the
conditional probability of the output
given the input and I think that this is
the kind of leap of faith that we need
to do in order to get unsupervised
learning working properly too we have to
be able to let go of the idea that yes
we we want to model our data
distribution with with this kind of
parametric model and so on I think it's
much better to rely on the powers of
deep learning what if the model class is
nonparametric I mean I agree if you've
you shoehorn everything into a simple
parametric form it's not flexible but
it's suppose we have you know we have a
bayesian Oracle that can do exact
inference in some sense this is a base
in Oracle okay so let me let me rephrase
a little bit what Harry has said so
imagine you're you consider a supervised
learning task and but you imagine that
the the correct graphical model for this
should include some latent variables
which correspond to what you think are
the underlying explanatory variables and
so on and from which you can derive the
answer if you were able to do a sample
from the posterior the problem is that
we're presenting that posterior
distribution in in the ways we usually
do it with graphical models is often
very difficult we have to resort to all
kinds of approximations and often we
have to end up sampling from that
posterior if the that posterior
distribution is is complicated we may be
in trouble and might take a lot of time
and we're going to have potentially poor
approximations instead if you think
about what's going on in these deep
supervised networks without any in you
know explicit distribution in the middle
it's like if we're
have this deterministic representation
implicitly of what the these latent
variables would be capturing as far as
what concerns the task of course
throwing away the things you don't you
don't need so you you avoid these
approximations and you only concentrate
on the approximation that are relevant
to the task I would want to add one
thing since you asked my opinion to
which is that so we've heard a wonderful
talk by Rob tipsy Ronnie which is about
inference so it seems that prediction
tasks can be done quite well but
inference is something of its own you
know it seems hard to infer causal
relationships between variables if you
don't have a graphical model and if
you're not actually doing probabilistic
reasoning over this graphical model so I
think there's room for both I would say
there's a question there yes I'd like to
touch a little more on about this
learning like a child question and and
get a little bit more at a what's the
hang-up you can take only a few million
neurons and in one week it can learn a
thousands and thousands of objects and
as a father of a six-year-old I can tell
you what take a long long time for them
to reach that point if you were to build
a network that were to take six years to
properly train what more would you need
because I claim that if you wanted to
work on a graduate student life time you
want to read you're aiming for
superhuman abilities great question
mm-hmm well I think the comment was not
to learn faster than a child it was to
learn like a child just because it may
be interesting to do so and I think we
still haven't discovered where the image
net training data is encoded in the
human genome for us to you know have
that capability from birth and whether
it can be just done an unsupervised
setting but in particular children learn
I think one of the famous cognitive
science results is they learn only from
positive examples quite well and very
few learning machine learning algorithms
do well in that setting so that's just
an example of the kinds of things that I
think are interesting
and they learned mostly unsupervised I
mean in the first two years you don't
get much supervision because languages
and really there's sufficiently that's
debatable i mean if you consider motor
and food and some i mean what is
supervision maybe the most important
question to answer it I mean now the
kind of supervision we get an image net
precisely so if you had unlimited
resources and unloaded times a train
what do you think you're missing to get
you to that point a short answer because
we're almost running out of time and
there's some few more questions is there
anybody know I still understand the
question cuz you're seem to be vocal
focusing on accuracy not voting not on
accuracy but on the process of one of
the things that stops you for example
from really training well is the fact
that you have finite resources and the
fine amount of data but a child is
learning for years and years and years
and years before they get to the point
where they're competent enough to learn
some of these things in your feelings
but it's all unsupervised or very weakly
or weirdly supervised so I don't think
our algorithms quite can handle it yes
so what is the fundamental advances that
have to be made outside of resources I
yes I so my answer would not be so much
about what needs to be done which is
probably a combination of having more
data having a lot more time to do the
training and you know having more
powerful machines but uh but I kind of
feel that for children like you don't
just want to think about how many years
they've head of their lives to learn but
also you have a lot of things which I
encoded so one example like to think
about is that if I if I draw a stick
figure of a new animal for a kid they'll
probably be able to recognize that
animal when they see that animal in a
photo or in real life even though it
doesn't look anything anything like that
I cannot draw very well but you already
have the representation that allows you
to do this transfer so I think we should
actually stop here I'm very sorry for
those people who lined up because you
know food is being served then I would
hate for you if the food is too gone
because I kept you here so but let's at
least thank our panelists here and give
them a big round of applause
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>