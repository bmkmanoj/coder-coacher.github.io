<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Algorithms for Strategic Agents | Coder Coacher - Coaching Coders</title><meta content="Algorithms for Strategic Agents - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Algorithms for Strategic Agents</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1BEYoKjVQKQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
we're delighted to welcome mat Weinberg
from MIT will tell us about algorithms
for strategic agents Thanks um so thanks
a lot for having me coming to the talk
so okay so I want to talk about so I
don't know how many of you have seen
this picture before but um this picture
was shown to me and like my first
undergraduate algorithms class so what
this is is um this is a Soviet railway
map from 1955 and apparently the CIA
asked early computer scientists to find
a min cut in this graph because they
wanted in case they ever wanted to like
disrupt the Russian supply flow okay and
now if we fast forward to 2014 this is a
graph of what autonomous systems in the
internet looked like and algorithms are
run on this graph every second in to
help root Internet traffic okay and so
one difference between 60 years ago and
today is that you'll notice that the
graph on the left has less than 100
nodes and the graph on the right has
42,000 notes okay so obviously our
algorithms need to be better and faster
that's actually not what I'm going to
talk about and instead what I want to
point out is it the graph on the left
all the nodes are controlled by one
central authority notes have no
interests and in some sense they just
obey whatever the central authority says
or is in the graph on the right there
are forty-two thousand autonomous
systems that are making their own
decisions and they have their own
interests and they behave in their best
interest so they're not just going to do
what someone tells them to okay so let
me first give you an example to convince
you that this is a real thing this is
not just like some crazy model so in
2008 there was a faulty bgp table update
that caused the worldwide youtube outage
and so if you don't know so bgp excuse
me as the protocol that num is used to
route the all of our internet traffic
and so right so first several hours two
thirds of the world was unable to watch
to keep videos of cats and so what went
wrong was there was offensive material
on youtube that prompted pakistan to
want to censor it and so the Pakistani
ISPs up
to their bgp tables to map youtube to
nowhere and the problems that this was
inadvertently broadcasted to the rest of
the world as well so the point of this I
think this is like a nice quote that
summarizes what happened was it nobody
ran any viruses or worms or malicious
code this is just the way the internet
works right now so you know no one was
trying to take down YouTube but it just
happened because the ISPs were acting in
their own interest instead of what the
central goal of BGP was ok so now I'm
going to put this in a little bit of
more of a general context so normally
when we think of algorithm design we
think of being given some input that you
know and ask to be produced some alp
asked to produce some output and what
happens in between is what we call the
algorithm ok so the model I'm trying to
get at is called algorithmic mechanism
design where we have this extra step
where you don't know the input you're
not given it but you have to get it
reported to you by agents who are
strategic and have their own interests
and at the end the agents experience
some kind of payoff based on the output
that you choose so they actually care
about the algorithm you run and what you
choose to do and so for this talk I'm
going to call this a mechanism instead
of an algorithm to denote the difference
ok so in a seminal paper by Nissan and
Ronan they introduced this topic to the
computer science community and among
other things they posed this general
question which is how much more
difficult our optimization problems on
strategic input versus honest input so
how much harder is mechanism designed an
algorithm design so the dream is we
would love to have some kind of a black
box reduction that says as long as you
can solve algorithm design problems you
can also solve mechanism design problems
and just throw it into this wrapper so
what I mean by that is what you really
want to do is have some mechanism that
works on strategic input so it should
take as input em different agents are
going to report their input and then
it's going to produce some good output
and instead what you have is just some
algorithm that works on honest input so
it takes the input that's known and is
correct in some sense and then produces
an output and even more we'd like to say
that you just have black box access to
it which means you can't actually look
inside you can just probe it with inputs
and see what it outputs okay so what
we'd love to be the case is that you can
design a mech this mechanism on the left
with just black box access to an
algorithm output that's both what you
want to do and what interacts with the
agents utility or are you allowed to
have private output versus rewarding
agents so for this talk I'm going to say
there's one output and you have a goal
in mind and that goal would be the same
if it was an algorithm problem or a
mechanism problem so for instance maybe
your goal is to make the agents as happy
as possible and it's not about doing
something different for the different
agents but you want to find the outcome
that makes all the agents as happy as
possible something like that did that
answer
so you don't have a output that's should
if we define your own goal to predefined
independent of what it could be or it
could depend on what the agents want so
so as an example let's say that um let's
say that I'm a government and I have
some contract that I want to award and
you know everyone here is a business and
I just want to give the contract to the
business that can like benefit the most
from it then what would be private
information to all of you is how much
you would benefit from it as a business
and that based on how much you value it
would affect who I want to give the
contract to does that but my goal is to
that okay sorry okay okay so let me say
so why would we want a black box
reduction and so one one reason is it
much more is known about algorithms than
mechanisms okay so one hope is that
maybe we can reduce some unsolved
problems in mechanism design to problems
in algorithm design that are already
solved okay a second a second important
thing is that the algorithms community
is much larger than the algorithmic game
theory community so some kind of
reduction like this would allow lots
more people to contribute to mechanism
design problems and they wouldn't have
to necessarily learn game theory to do
it
yeah I guess that's arguable but um I'll
say it's a plus and the third is it
hopefully this would provide a deeper
understanding of mechanism design
because really we'd like to understand
what makes incentives so difficult to
deal with both computationally and
otherwise okay and so what I'm going to
show you through this talk is it with
the right qualifications some kind of
reduction like this does exist okay so
i'm going to set up the problem and then
after it's all described like a series
of papers that culminates in this result
ok so the set up there's going to be
some central designer and there's going
to be some agents and there's going to
be some possible outcomes that the
designer is allowed to choose the agents
are going to have a value for each
possible outcome the kind of the notes
how happy they are with that outcome and
I'm going to say that this information
is stored in their type so for the rest
of the talk just remember T stands for
type and T is going to be a function
that takes as input and outcome and
outputs that agents value ok so how
happy they are and also for the whole
talk we're going to be an evasion
setting which is normal for economic
applications so each agents type is
going to be sampled independently from a
distribution d and every agent in the
designer knows its distribution okay so
also for the rest of the talk just
remember d stands for distribution okay
so now the designers goal is to decide
some outcome and this outcome should be
feasible so I'll give you some concrete
examples later but think of it as if I
only have one item to give out I should
not be giving seven people the same the
item right if I only have one I should
be giving it to one person and also in
addition to choosing an outcome he's
allowed to charge prices to the agents
and he has some objective function in
mind that he wants to optimize and this
objective functions like i was saying
could depend on the types of the agents
and it can also depend on the prices
that he charges and it is also going to
depend on the outcome he chooses ok so
before i give you examples let me tell
you the strategic aspect of the problem
so the designer first is going to design
his mechanism
mechanism you should think of as just a
function so it takes as input a profile
of pipes so we'll report from every
agent it's going to output an outcome
and it's going to output a payment for
each agent okay after he designs his
mechanism he's going to ask the agents
to report their types and then he's
going to choose whatever allocation he
promised and charge whatever payments he
promised so a profile is a type for
every agent so like if there are if
there are five agents would be a type
for a bitter one two three four and five
yeah sorry okay so now each agent is
going to decide what type they want to
say and they're going to do this based
on the mechanism that they're playing
based on their beliefs about what
everyone else is going to do and based
on this they're going to report some
type and if they were honest they would
report their true type but they're not
their strategic so instead of telling
the truth they're going to report
whatever type happens to maximize our
own utility okay so if they think that
they can gain based on the algorithm I'm
running if they think they can benefit
by lying then they're going to lie so
the designers goal is to design a
mechanism that first it should encourage
the agents to tell the truth okay the
specific notion of truthfulness that
we're going to use is called Beijing
incentive compatibility what that means
is that if everyone else is telling the
truth it's also in my best interest to
tell the truth so it's not as strong as
dominant strategy which means that it's
best for me to tell the truth no matter
what but it is a excuse me it is an
equilibrium for everyone to tell the
truth and second condition on being
truthful it should optimize his
objective function subject to this so
maybe it's not possible to do as well as
the best algorithm but he should at
least do is right so your target is of
all truthful mechanisms do as well as
the best one okay so that's the
benchmark
you optimize the objective function if
you're in this particular equal of it
yes that's great but there might be
there may be other equilibrium that's
correct yes ok so now I'm going to give
you some examples to help ground this a
little bit so it's one example let's say
you're this nice guy and you have a
bunch of gifts so you want to give to a
bunch of kids so you shouldn't be giving
the same gift to more than one child you
know but it's okay for the same child to
receive multiple gifts and so you'd say
that an outcome is feasible if it
respects this so it's feasible if it
doesn't give the same item out more than
once in this case because you're just
trying to make the kids as happy as
possible you want to maximize welfare so
as a function that would look like
summing over all agents their value for
the outcome that gets chosen so remember
TI is there the function that represents
their value the second example maybe you
sell houses so you should also should
not be giving the same house to multiple
agents and also you should not be giving
the same age in multiple homes in this
case so in this case you would say that
an allocation is feasible if it's a
matching of homes to agents and because
you're a Salesman you want to maximize
your revenue so a notation what that
would look like is you sum over all
agents the payment that they make to you
as a last example maybe you have to
schedule jobs and in this case each job
should be assigned to exactly one
machine but the same machine can process
multiple jobs you'd say that an
allocation or I'll call it a schedule is
feasible if it respects this and in this
case you want to minimize the makespan
which is the processing time of the
slowest machine so the last machine to
finish all the jobs it's processing and
so again in notation you'll be trying to
minimize the maximum over all machines
of their processing time seeing example
yeah it does it make it
have not only tell you a type of them
that they have a accept or reject for
the solution is you got charged with a
payment to give them a good so so the
idea is that if the agent is truthful
then they shouldn't they then the price
that you give them for the house should
always be less than what they're willing
to pay for it so they should have no
interest or say that again so you go you
go that into it yes yes that's true so
there's a condition so part of
truthfulness is a condition called
individual rationality which I didn't
explicitly state which means that it
should be in every agents interest to
participate in the mechanism so what
would happen here is if you wound up
giving them a price that was above what
they wanted to pay then it would not be
rational for them to participate because
they would rather just sit at home and
not take the house so yeah that's good i
should have said that and um but that is
a condition that is imposed but normally
we think of that as being imposed by the
truthfulness property rather than the
feasibility constraints yeah and that
should hold for all the examples not
just the housing and okay so now i want
to tell you I'm what's already known
about this and so what we do know is
that if your goal is to optimize welfare
truthfully no matter what kinds of types
the agents have you can do that as long
as you know how to optimize welfare
algorithmically ok now for revenue I
know there's some notation in this line
that I'm going to define shortly what we
know for revenue is it for very simple
bitter types if you want to optimize
revenue truthfully you just need to be
able to optimize virtual welfare
algorithmically and I'll say what these
terms are now so four types of bitters
what it means for a bitter to be
additive is if it makes sense to say
there are items so like the gifts or the
houses or the jobs in bitter has a value
for each item and their value for a
subset of items just sums their value
for each item in the set so there's
really no interaction between values for
items okay single dimensional is a
special case of additive where as far as
the bidders are concerned all of the
items are exactly the same so think of
additive is maybe like you have two
items one of them is a TV and the other
one is a car then your value for a
carnot TV is just your value for their
sum and single dimensional would be like
you have 10 copies of the exact same TV
for sale okay and lastly when I say
maximize virtual welfare for this talk
how you should interpret that is I'm
just saying modify the input and then
maximize welfare so if you want to think
of virtual welfare as welfare that's
fine but just understand that the input
is getting modified a little bit first
okay so okay so that's what we know for
welfare and revenue however for revenue
beyond single dimensional settings so
for additive we don't know anything and
what we'd really like is to be able to
let the bitter types be arbitrary and we
really don't know anything there and
then also as soon as you go beyond
welfare and revenue we really don't know
anything okay and in fact the only thing
we do know is an impossibility result
that says that it's not possible to
reduce truthfully optimizing any
objective to algorithmically optimizing
that same objective and in particular no
reduction like this can possibly exist
from minimizing makespan okay so what
I'm going to show you in this talk is it
moving beyond single dimensional bidders
for additive bidders and actually for
arbitrary kinds of bidders as long as
you can optimize virtual welfare
algorithmically then you can optimize
revenue truthfully and for arbitrary
objectives as long as you can maximize 0
plus virtual welfare so that same
objective plus virtual welfare then you
can optimize that objective truthfully
and so this side steps the impossibility
result because we change the objective
okay
example you gave where you're just
giving stuff out so welfare just refers
to the objective of trying to make
people as happy as possible so it's not
necessarily just you have stuff and you
want to give it away it could be like if
I'm trying to build a bridge and I want
to put it in the location that makes you
know the most sense for everyone
something but welfare just refers to the
objective of my goal is to make everyone
here happy doable condition that you can
solid algorithmically get there if
there's no problem with agent Scott the
truth yes yes oh yes that's right so
what that means is that if it was
possible for me to find the best
location for the bridge if I knew
everyone's value then it's also possible
for me to design a mechanism that you
know accommodates the fact that you guys
have your own interests and you may
choose to lie that will still wind up
putting the bridge in the best location
possible is that Apple's how it could be
that that second problem was not Alvin
so one example would be um so let's say
let me think real quick so let's say
that I was instead of just giving away
gifts I was trying to let's say that I
was trying to run a spectrum auction so
the FCC you know has this like large
radio band and they want to give it away
and there are these very like
complicated constraints on which
spectrum can be allocated in which
locations or something so in some sense
it's a little bit like an independent
set problem where you know you have to
make sure that wherever you allocate the
spectrum that it's not going to that
make sounds like if i allocate part of
the spectrum here i also can't allocate
it anywhere to nearby and independent
set problems are hard to solve right so
there are problems where perhaps your
their constraints yes that's right yes
then you can do yes and empirical simple
yes that's right yeah when you say
welfare it is it's okay and refer to all
these references you're not assuming
revenue neutrality so the auctioneer may
have to pump in some so I don't believe
in any of the examples I cited that the
auctioneer will ever lose money it's
possible that he may not gain money so
sorry if it's the case that he has to
pay money to build a bridge it's
definitely possible that the cost of
that what everyone pays you may not
cover the cost of the bridge that's
right yes so that's uh that's I guess I
would consider that as a different
direction than this but those are
definitely important problems
yeah okay
yes try to understand how the revenue
problem is different from welfare
problem revenue you get to charge
anything up to what the welfare is for
that person right so how is it different
so the reason it's different is because
um let's say that my mechanism is just
going to charge you whatever you say
then like even let's just say it's just
you and me interacting and I tell you
the mechanism is it if you tell me that
the item is worth ten dollars to you I'm
going to charge you ten dollars then
you're definitely not going to tell me
your actual value you're gonna tell me
something much lower when the agents
were just going to tell you the truth
than you could yes trying to be exactly
that's correct it would be exactly the
same as well packet ism you might not be
able to charge yes that's right and in
fact you have to charge them something
less because you want it to be truthful
right okay good okay so so i told you so
the main result is this black box
reduction so it's a poly time reduction
from the mechanism design problem for
any objective that you want to optimize
to the algorithm design problem for that
same objective plus virtual welfare okay
so what that means is it in this picture
whenever the right hand side this
algorithm design problem is tractable
then so is the mechanism design problem
that's on the left okay and so to fax I
wanted to emphasize that this reduction
is approximation preserving so if you
have a hard problem to solve on the
right like independent set that you
can't maybe an example that you could at
least approximately solve if you can
approximately solve the algorithmic
problem then you can approximately solve
the mechanism design problem and it's
the same ratio and also there's no
constraints on the types that the agents
have to have in order for the reduction
to work so however the types get input
to the mechanism design problem they get
passed in the exact same way to the
right hand side for the algorithm
problem okay and so one way to
object so if you're trying to so let me
say so if it's in for the most part it
can be anything if it's an objective
that interacts in a weird way with
randomness then it has to be concave if
you're maximizing it or convex if you're
minimizing it but if it's like a diff
it's an objective that like you would
say expected makespan might be something
like you compute the makespan of this
you compute the makespan of that and you
average them then if it behaves like
that with randomness and it can be
anything okay did that yeah well there
was something that you sort of decided
to add him to tell the existing elevator
yes that's right so it's definitely
possible that maybe adding virtual
welfare makes it a much harder harder
problem that's definitely possible that
that might happen and actually we'll see
an example later where that's the case
as if you run the existing algorithm on
that
agent thanks to get this so how do you
then go back so um so so in this slide
I'm just thinking of this as not
pretending that you know the actual
agent types but as an algorithmic
problem imagine that you did know the
agent types that's the one that you have
to be able to solve so it yes that's
right yes that's right think of it as
you have a machine that solves this
problem on the right you can probe it
several times and that will let you
solve the problem on the left yes that's
right that's the right way to think of
it just in the polynomial in number yes
good so um so it is the case that the
runtime is polynomial in the number of a
total agent types so it's different than
the number of type profiles so that
would be very bad was if so say there
are ten agents then the number of type
profiles would be exponential in 10 so
that would be really bad in some cases
even just the number of agent types is
really not good but in some cases that's
also the best you can hope for yeah
that's a good question okay and so this
at the bottom this is one way to think
of this result is saying that
transitioning from honest to strategic
input is no harder than adding virtual
welfare to the objective ok so maybe
adding virtual welfare to the objective
maybe that does make the problem a lot
harder but dealing with strategic agents
is no harder than that ok ok so now I'm
going to tell you a little bit about the
tools and techniques that get us here
and so for now I'm going to say the
objective is a revenue and the agents
are going to be additive and just remind
you what that means there are n items
and agents have values for each item and
their value for a set of items just sums
their value for every item in this set
ok this is just going to make talking
about it a lot cleaner ok so the first
thing we have to look at is how can you
how should you describe a mechanism so
one observation you can make is it a
mechanism is just a function so it takes
as input type profiles and it outputs a
price for all agents and it outputs a
distribution over outcome
so one way to describe a function is a
really explicit description where you
just list for every possible input what
is the output okay so i'll call this
like a laundry list so with this
description you can think of a mechanism
as a really large dimensional vector
that just lists for every possible input
and for every possible output what's
happening yes so yes so by that i mean
the mechanism is allowed to be
randomized so so like let's so same
thing if i'm trying to build a bridge
then my mechanism could decide with
probability a half it builds a bridge
here with probability half that builds a
bridge there and maybe that lets me do
something that I couldn't do with a
deterministic mechanism okay so now that
we decided we're going to think of
mechanisms as vectors one thing you
might ask is can you write a program
that will just optimize over the space
of truthful mechanisms or going to
depend on the auto do this say that
again so there because it is the place
that you don't listing the price so for
now we'll say it um it could be
deterministic it could also be a
distribution as far as the agents are
concerned so I didn't explicitly say
this but I'll assume that the agents are
risk neutral so as far as the price is
concerned they don't actually care yeah
and let's also say that as far as you're
concerned you're also only concerned
with the expectation so if you want to
you can use randomness okay so the
answer is sure you can definitely write
a program that will optimize over the
space of truthful mechanisms but really
what this is going to look like is it's
going to look really silly it's going to
look like you're up you're writing a
program to optimize overall algorithms
and then you're going to throw in a
constraint to make sure that the
algorithm is truthful okay so what this
looks like is you're going to have
variables like I said to explicitly
described this function so for all
possible inputs and all possible outputs
what's the probability that you choose
that output on this input and for all
possible inputs for all agents what's
the price you pay on that input okay
then you have to constrain that the
mechanism is truthful and I'm not going
to write them but you can write that
with linear constraints and you have to
guarantee that the mechanism is feasible
those are also linear constraints and so
by feasible for this I just mean that on
every output sorry for every input we
have a variable denoting the probability
that an outcome is chosen these
probabilities should sum to 1 in order
for this to be a real distribution so
that's all that's going on there ok and
now to optimize you just want to
optimize your expected revenue and I'm
also not going to write this for this is
also a linear function ok so I just told
you here's a linear program that solves
the problem you want and so what's the
problem the problem is that this is
enormous and there are way too many
variables so what we need is a smaller
description ok in the description we're
going to use is something called reduced
forms ok and so the idea is that we
really don't need all this information
ok so let's just try and keep what's
important it's what we're going to do is
we're going to make a variable for every
agent for every item for every type
what's the probability that they get
that item when they say this type and
this probability is going to be over the
randomness in the mechanism if there is
any and over the randomness in the other
agents choosing their types ok and this
pift is just going to be the expected
price they pay when they say this type
ok so now you can also think of this as
a poly dimensional vector so it's much
smaller the description and you want to
say that a vector is feasible if it
corresponds to an actual mechanism ok so
it doesn't have to be a truthful
mechanism but it should be an actual
mechanism so as a picture what's going
on is on the left we have the space of
all mechanisms and on the right we have
the space of all vectors that at least
have the right number of coordinates and
every mechanism induces a reduced form
and so the set of feasible reduced forms
is the image of this map and that's a
subspace of the vectors that have the
right number of coordinates ok so the
first ingredient the solution is going
to be to write a linear program using
this comp
description instead of the laundry list
1 ok so the variables you're going to
have our this what I just said so from
the reduced form you still need to
guarantee that the mechanism is truthful
and again I'm not going to write this
but you can do this with a small number
of linear constraints and now the
interesting problem is that it's kind of
hard to guarantee that a description is
feasible ok so you can't do that with
few linear constraints and the new
challenge is how can you tell if a
reduced form is feasible ok but you're
still maximizing expected revenues to
that part is easy ok so the first
ingredient we wrote a succinctly near
program and using the reduced forms so
all we need to do now is find out how to
tell if a reduced form is feasible so
that's going to be the next step ok so
to help you understand this i'm going to
give an example so the purpose of this
example is one just to give you an idea
of what it means to say a reduced form
is feasible into to convince you that
this is an interesting non-trivial
problem ok so to do that I'm going to do
a really simple example is just going to
be one item in two bidders and each
bidder is going to have three types
furthermore each bidders type is going
to be chosen uniformly at random ok so
here's my reduced form that says that
when bitter one says his type is a he
should always get the item if he says
his type is B he should get it with
probability a half if he says his type
of see he should never get it ok so
let's try and figure out is this
feasible so the first thing we can look
at is definitely whenever a shows up he
has to get the item so something that we
have to do is a has to be d e and f
whenever they show up so we can do this
and now we know that pie of a is equal
to 1 so that's good also now that d is
losing to a d has to get the item
whenever else he shows up so that means
d has to be B and C ok but if we do this
then PI of d is going to be equal to
two-thirds so that's fine another thing
we can do is eat C&amp;amp;F don't want the item
at all so whenever B and F
show up we might as well give the item
to be and whenever C and E show up we
might as well give the item to e and
that gets both of their pies up to
one-third and now the last decision we
have to make is what should we do with B
and E's show up so in order to get PI of
be all the way up to a half B would need
to win with probability a half and in
order to get PI of e all the way up to
five ninths you would need to win with
probability two-thirds okay so at this
point you say well a half plus
two-thirds is larger than one so it's
clearly not possible to do this so this
reduced form is infeasible ok so what
just happened so we worked out a simple
example and that was already kind of a
lot of work all right and I want to
point out you know so like what would
have happened is if PI of a wasn't equal
to one we wouldn't have had a starting
point to go through that kind of
reasoning what if there were more than
two bidders what if there's more than
one item and what if there are
interesting constraints like maybe a
matching on who can get what at the same
time okay so hopefully I've convinced
you this is a somewhat interesting
problem and what we need is a consistent
approach to solve it so the second
ingredient is going to be what's called
the equivalence of separation and
optimization and to tell you what this
means i'm going to give you a definition
so a separation oracle for a convex
region takes as input some point x and
it's going to output either yes if x is
inside your convex region or it's going
to output a violated hyperplane so how
you should think of a violated
hyperplane there's some Direction W
where X goes further in Direction W than
any point inside the polytope and
therefore it's definitely not in the
polytope because it goes too far in
Direction W okay so this is some famous
theorem by Cauchy on in 79 where he
showed that if you can get a separation
Oracle for a convex region then you can
optimize linear functions over that same
region and the algorithm we use is
called the ellipsoid algorithm okay so
what this means in our contacts is that
we just need a separation Oracle for the
space of feasible reduced forms and then
we can solve our linear program now
what's less known is that the other
direction is also true
so in 81 grouchy love Austin Shriver and
independently carbon papadimitriou
showed that if you can optimize linear
functions over a convex region then you
can get a separation Oracle for that
region too okay so a good question to
ask yes what is feasible when you could
be computationally very complex require
that it still be a convex problem yes
and it's all it's actually always going
to be convex and the reason you can
think of that is if it's feasible for me
think of it like this if it's feasible
for me to run one mechanism and it's
feasible for me to run another mechanism
it's feasible for me to run this one
with probability a half and this 1 with
probability a half so it will also be
Fiza in some extent so it's feasible for
me to choose this one give some give
each person a house but only one house
or something like that though I'm not
sure how complicated these rules to be
but those still have to define a convex
set so those actually don't have to
define a convex set so what I'm saying
is that if i look at the probability of
probability vector that you get each
different house if it's possible for me
to do that and it's possible for me to
give you a different probability vector
then it's also possible for me to give
you this one with probability a half and
this 1 with probability i have not do
this much smaller yes that's right you
get a congress yes you immediately get
on thursday oh yes that's right that's
right okay so a good question to ask is
you know why is this second theorem i
showed you why is this ever useful like
who uses separation Oracle's for
anything other than optimizing linear
functions okay and so the answer is that
the most common usage is if you want to
optimize a linear function over the
intersection of two convex regions and
in this case just being able to optimize
a linear function over one doesn't
immediately tell you anything useful
about optimizing that same phone
over the intersection of two regions
unless you use this reduction okay and
um and so actually this is this
application is what gave the first poly
time algorithm first a modular
minimization and there are other uses of
this and one of them will come up later
in the talk to okay so the second
ingredient which was not our
contribution is the equivalence of
separation and optimization which says
that if you have optimization algorithm
for this region then you can get a
separation Oracle so all we need to do
is be able to optimize over this region
okay and I'm actually going to skip the
details on this but I'll tell you that
one thing we did show is it if you can
optimize virtual welfare as an
algorithmic problem then you can
optimize linear functions over this
region okay and i said i'm going to skip
the details but i'll say that one way to
interpret this is it it's a stronger
version of the equivalence of separation
and optimization but specifically for
this mechanism design application so
it's not like a general tool okay so now
when you combine these three ingredients
together this says that if you have a
poly time algorithm that can optimize
virtual welfare you can go back through
ingredient three then to them one and
that will give you a poly time algorithm
to find the optimal reduced form okay so
something is still missing and that's I
told you that there's an algorithm to
find the optimal reduced form but a
reduced form is not actually an auction
it's not a mechanism because I threw
away a lot of information so what I need
is I need an actual mechanism that can
take as input a profile of types and
output what to do it can't just be the
case that everyone shows up and says
they're types and then I say this is the
reduced form of what I'm trying to do
right I actually need to do something
okay and so this is another use of
separation Oracle's which says that if I
give you a separation Oracle for a
convex region and a point inside that
region then I can decompose that point
into a convex combination of corners
okay of extreme points of that region
and the reason that that's useful is
because
we're able to show the following that
any reduced form that is a corner of the
feasible region has a really simple form
and can be implemented as a mechanism
really easily and it's just by
maximizing virtual welfare on every
profile so what that means is you should
think of every corner modifies the input
in a different way but then it just
maximizes welfare at the end of the day
ok so the corners are really simple
mechanisms so what that means is to
implement any feasible reduced form
first you use a separation Oracle to
write it is a convex combination of
corners and then you implement that
corner and the corner just modifies the
input and then runs an algorithm that
maximizes welfare ok corner this convex
set is it actually probably topher so in
most examples that you would think of it
is a polytope if it's not a polytope and
it's just a convex region then by corner
I mean like an extreme point that's you
know not what's word I'm looking for yes
that's yes that's right that's correct
that's right way to put it yeah the
input edit or no do you mean that
different partners have different
versions that yes that's what I mean
yeah ok ok
okay so now this is the last ingredient
and so with all four of these together
this means that you can find and
implement the mechanism that optimizes
revenue and poly time as long as you
have black box access to an optimal
algorithm for virtual welfare okay so
what I just proved was a theorem that I
just read which was for revenue for
additive bidders and for exact
optimization algorithms what I promised
you at the beginning was the following
more general theorem that said any
objective you want and it preserves
approximation and the agents can have
any types you want not just additive
okay and so the proof uses the same four
ingredients plus a little bit extra that
I'll go through now ok so the missing
ingredients I need to tell you how to
deal with approximation I need to tell
you how to let the agents types not be
additive and I need to tell you how to
change the objective from revenue to
something else I'll give a one slide
overview on each now so for
approximation so recall this theorem
that I told you earlier which is it if
you can optimize linear functions then
you can get a separation Oracle and a
reasonable question to ask is what
happens if you use exactly the same
approach but I just start with an
approximately optimal or an
approximation algorithm instead okay and
so you can call the output of this we
call it a weird separation Oracle the
reason we call it that is because it is
an algorithm that sometimes says yes and
it sometimes outputs hyper planes but
it's not really a separation Oracle the
reason for that is that it can have this
really weird behavior where it's
possible for it to accept the point X
and accept the point why but reject
every convex combination of x and y okay
whereas if the region was actually
comebacks not only should it except some
of these points it should accept all of
these points okay so that's why we call
it weird okay but an informal statement
of the theorem that we show that says if
you can approximately optimize linear
functions over a convex region then you
get some meaningful notion of an
approximate separation Oracle for that
same region going the exact definition
of what i mean by
meaningful notion is a little technical
so I didn't write it okay but an
overview of what happens is we showed
that the same algorithm that was used in
the original reduction works directly
and the hard part is we have to
understand what happens if you run the
ellipsoid algorithm like over a non
convex region like what will happen ok
so the idea is it um if you have a real
separation Oracle then the set of points
that it accepts are going to be a convex
region and so I so this weird separation
Oracle doesn't have that property so
it's going to accept some points and
those points are going to form a set and
this X is this set may not be convex and
it might not even be connected so it can
be a really weird set
first yes for each queria gives a
consistent answer but it's in some sense
not consistent with any single convex
region that's right so it could be the
case that like in one direction it says
you can go very far and in this slight
this perturbing that direction just a
little bit it says you can barely go
anywhere so it's possible that that will
happen okay so that's how you deal with
approximation is you need to use this
some stronger version of the reduction
okay so now how you deal with so for
arbitrary types let me first try and ask
so what goes wrong as you move beyond
additive bitters yeah so this
approximation you will still just aim
for the worst one for example when you
said four different in posts it gets in
some sense an approximation in a
different time yes that's right so yes
the worst one so but you guaranteed it
in every direction it does at least half
as well as the optimal then that's what
you're targeting yes yes yes that's
right so I so so I don't know how to
exploit that property that's right so
even if it did well in every direction
except for one I wouldn't know how to
exploit it yep okay so let me know ask
so what's the problem as you try to move
beyond additive bidders and the issue is
at this reduced form i was using is
completely useless and here's why so say
there's just one bitter and there's two
items you should think of the items as a
left shoe in at right shoe okay so your
value for both shoes together is a
dollar but your value for just one shoe
or getting nothing is zero okay so
that's an example of a bitter that's not
additive oops and dumb in one auction
maybe I give you both shoes with
probability a half or nothing with
probability a half or in a second
auction you just get a single shoe
uniformly at random and these two
auctions have the same reduced form but
your value for them is really different
okay so the problem right so that's the
problem and how do we deal with it so we
use a different description of the
auction that's really implicit okay so
we'll use
since you can think of this is like a
swap value so we're just going to
explicitly get at what is your expected
value if you're real type is T but you
choose to say T prime instead okay and
then we store this for all pairs of
types okay so i'm not actually storing
any information about the auction other
than directly how happy does it make
certain types for reporting certain
other types okay so that's how you deal
with them arbitrary types and i'll tell
you how to deal with arbitrary
objectives so what you want to ask is
what makes revenue special for this
approach and the answer is it expected
revenue is a linear function of the
reduced form or the implicit form okay
whereas most other objectives aren't so
for instance welfare is but makespan
isn't okay and so the issue is it if I
just give you the implicit form of a
mechanism there is no way you can
possibly hope to compute the makespan
okay so the solution is we're just going
to add another variable that stores this
value directly okay so we'll take the
implicit form and we'll add one more
variable and that's just going to store
the expected value of st. may expand
okay so this definitely makes writing
the LP easier the issue is that it may
make determining feasibility a lot
harder okay because now I have to
determine is it feasible for me to make
you know you this happy when you say
this other type and for me to do so in a
way that gets makespan exactly five or
something so now this is a much harder
problem to deal with okay so just to
recap so this new implicit form is going
to have these three components the first
is going to be this swap value which
says if you're real type is T what's
your value when you say T Prime it's
also going to store the expected price
that everyone pays it's also going to
store the expected value of the
objective when you use this mechanism
okay okay so now let me go back to these
four ingredients and tell you how they
change when you want to make these
generalizations okay so instead of using
the reduced form to handle arbitrary
types and objectives we're just going to
use this implicit form that
told you so all we're doing is changing
the variables and as far as the LP is
concerned nothing interesting happens so
to handle approximation we have to use
this stronger approximation preserving
version of the equivalence of separation
and optimization but once we do that
that's the only change we need to make
okay and so for this third ingredient
optimizing virtual welfare no longer
lets us optimize over the space of
implicit forms because we added this
component 40 but it turns out that
adding this extra variable is just
causes the problem that you need to
solve to change so if you want to
optimize over the space of implicit
forms you just need to be able excuse me
to optimize oh plus virtual welfare okay
so that's how it changes and that's
where this problem of 0 plus virtual
welfare comes from okay and for the last
ingredient because we no longer have an
actual separation Oracle we can't use
that decomposition algorithm that I told
you about before so instead we have to
use a property of the approximation
preserving reduction so this
decomposition will just come immediately
out of using the technique okay so now
I've shown this more general version of
the theorem which says that you can find
and implement an approximately optimal
mechanism for any objective for
arbitrary agent types in poly time as
long as you have black box access to an
approximately optimal algorithm for that
same objective plus virtual welfare okay
okay so now let me tell you about some
quick applications so the first
application is you know not surprisingly
for revenue ok so in 1981 in meyerson
seminal paper you showed the following
structure will result about auctions we
said that the revenue optimal auction in
single dimensional settings is a virtual
welfare Maximizer in a major open
question since then is what does the
revenue optimal auction look like beyond
single dimensional settings so even for
additive we don't know anything and
definitely beyond additive we really
don't know anything okay so what I
showed you in this talk is that no
matter what the agent types look like
the revenue optimal auction is a
distribution over virtual welfare
maximizers okay so it's not quite as
simple as meyerson's but it's not like
super far from that it's definitely more
than what we knew before okay so a note
is that Myerson also showed the other
direction which is it any approximately
optimal approximately optimal mechanism
necessarily approximately maximizes
virtual welfare as an algorithm okay and
so we can show something like this to an
are setting which i'm going to say now
okay so what we show is it for revenue
this reduction actually holds both ways
so what I mean by that is if I gave you
an algorithm they could find the optimal
truthful mechanism or even an
approximately optimal truthful mechanism
you could turn that into an algorithm
that can approximately maximize virtual
welfare algorithmically okay and so the
proof of this i'm not going to talk
about it all but has nothing to do with
the geometric techniques that you saw in
the rest of the talk okay so an
encouraging corollary of this is it in
this setting that means that maximizing
virtual welfare is in some sense the
right way to maximize revenue because
you can't avoid doing it if you had an
algorithm that can maximize revenue you
would also have an algorithm that
maximizes virtual welfare okay so an
evil corollary of this is it we're able
to show as a sorry as a corollary that
it's NP hard to truthfully approximate
revenue it within any polynomial factor
even for a single monotone sub modular
bitter okay and if you don't know what
those terms mean monotone just means it
as he gets more items he gets happier
and sub modular means he gets
diminishing marginal returns from adding
more and more items okay so as a second
application i'll talk about makespan
okay so you know if you remember there
was this guy who was trying to schedule
jobs and now he's a little bit excited
because he just has to design algorithms
from makespan post virtual welfare so
let me give you a specific problem so
you want to truthfully minimize makespan
on unrelated machines and so with that
problem sounds like is there are n
different jobs &amp;amp; M
machines and processing job I on machine
Jay takes time p IJ and this is private
knowledge to the machines okay so you
don't know how long it takes to process
any job on any machine but the machines
do and I want to point out this is the
original problem that was studied in
this seminal paper of Nissan and Ronan
okay so in this talk I told you that
this reduces to an algorithm design
problem for minimizing makespan plus
virtual welfare okay so one way that you
can interpret this problem is that
processing job I on machine J take some
processing time and it also costs some
monetary value okay so think of it as
you have to pay the machine to process a
job and it's also going to take them
some time and your goal is to find a
schedule that minimizes the time to
process the last job so that's a
makespan component plus the total
monetary cost of processing all jobs and
that corresponds to the virtual welfare
component so think of it as you only
care about the time it takes to finish
the last job but you also care about all
the money you spend okay now what kind
of sucks is that this problem is np-hard
to approximate within any finite factor
so not just within a constant factor
it's empty hard to determine if the
answer is positive or negative okay so I
just you know spend a half hour telling
you about this really general reduction
and now I gave you an example of a
problem that says we can reduce a
problem we don't know how to solve to a
problem that's impossible to solve okay
so you should ask if you know is this
not the right approach okay but the
answer is we can still accommodate this
but we need to improve the reduction a
little bit ok so I'm give you one more
definition and this is a promise this
will be the last definition of the talk
so we'll say that an algorithm is an
alpha-beta approximation if the output
satisfies is following inequality and
how you should interpret this is it if
beta was equal to 1 this would be a
normal alpha approximation okay but by
letting betta be something less than 1
this is letting you cheat a little bit
so it's letting you discount the
objective by some factor before you
compare
to alpha times the optimum okay and so
what we're able to show is it if you
have a poly time alpha beta
approximation algorithm for optimizing
your objective close virtual welfare
then you can turn that into a poly time
alpha over beta approximate mechanism
for the objective okay so that means
having beta naught equal to one just
causes you to have to sacrifice another
factor of beta on your approximation
ratio okay and so I'm also not going to
give any details of the proof but I'll
say that it's by basically extending
this equivalence of separation and
optimization to accommodate some
geometric notion of this kind of
approximation okay now it's really cool
is that for makespan this problem was
actually studied 20 years ago &amp;amp;
schmoozin Tardos showed that there is a
poly time 11 half approximation
algorithm for minimizing makes band plus
virtual welfare so what that means is
that when you plug that back into our
reduction you can get an actual two
approximation for a truthful makes panda
minimization on unrelated routines in
this Beijing setting I want to point out
that first that matches the guarantee of
the best known algorithm so even if we
didn't have any strategic input on
honest input we don't know how to do
better than a two approximation and also
if you think this is a really important
problem then this is the first like
general Beijing setting constant factor
approximation okay so in conclusion so
we studied a you know this general
question motivated by Nissan and Ronan
it said how how much harder is it to
solve problems on strategic input than
honest input and we started it through
this specific open question which is
when are there black box reductions from
mechanism to algorithm design okay and
so what I showed you in this talk is it
for all objectives intubation setting
there is a black box reduction from
mechanism to algorithm design as long as
you preserve the objective okay and so
one way to think of that like I said
before is it transitioning from honest
to strategic input computationally is no
harder than adding virtual welfare to
your
objective something we did was we
extended this equivalence of separation
and optimization framework to
accommodate both traditional
approximation and alpha beta
approximations and I also showed you
that this reduction is I didn't show you
I told you that this reduction is tight
for revenue okay so what that means is
that maximizing revenue in this setting
is exactly as hard as optimizing virtual
welfare okay and something else if you
care about structure I showed you that
the optimal mechanism has manageable
form which means that how you can
implement it is you randomly sample a
corner and then you run the
corresponding virtual objective
Maximizer we're modifying the input is
going to depend on which corner okay so
that's all I'm going to say about that
and i'm just going to really briefly
talk about two other things that I've
done okay so changing gears profit
inequalities are kind of a fundamental
problem in online algorithms and optimal
stopping and it turns out that this
actually has strong applications in
mechanism design ok so I'll define the
problem so the offline input to this
problem is a list of distributions and
what happens online is that very random
variables are sampled one at a time from
each distribution they're revealed to
you and as soon as it's revealed you
have to immediately decide you accept or
reject okay if you accept then you get
what you get reward equal to the random
variable you just so you just saw in the
game stops if you reject you throw it
away forever and then the game keeps
going your goal is to maximize your
expected reward okay so if you were a
prophet who knew the future so this is
where the term profit and equality comes
from you'd always get the maximum
element and the question that you want
to ask is if you are a gambler who
didn't how well can you do and so
there's a seminal result that says in
this setting there is a strategy for the
gambler that guarantees him half the
expected reward of the profit okay and
this is the best you can possibly hope
to do okay and so recently people have
been trying to study what happens if the
gambler has multiple choices
so I'm going to change the offline input
of the problem to be also a list of
distributions and they're going to be
some feasibility constraints that say
what elements you can simultaneously
accept the elements are still revealed
one at a time and you still have to
decide online whether to accept or
reject now the difference is when you
accept an element the game doesn't
immediately stop it just gets added to
your accepted set of elements and the
catch is it at all times you're accepted
set has to be feasible ok so what you
lose by accepting something is it will
prohibit you from accepting some other
things in the future your goal is still
to maximize your expected reward it's
still the case it if you were a prophet
you would always choose the max weight
feasible set and I'm what I showed with
Bobby Kleinberg is that if the
feasibility constraints are mate roid
then there exists a strategy for the
gambler also guaranteeing him half the
expected reward of the profit ok and
this is the best possible because it's
the best possible even for the single
choice problem ok and also recently with
also with Pablo Azhar we showed that
there exists asymptotically optimal
strategies for the gambler that only
require a single sample from the
distributions so he doesn't actually
need to know the distributions outright
one sample is enough and this is for
several special cases of may Troi but
not actually for mate roids in general
I mean the independent sets for my mate
roid yes that's right okay and so the
last thing I'm going to talk about is
auctions for everyday people and so the
motivation for this is that the
mechanisms that I just finished
describing to you i would consider them
manageable but i would not call them
simple so what i mean by that is that
the FCC could run this mechanism is a
spectrum auction they're definitely
capable of doing that but what I also
mean is that I could not run that
mechanism to sell my pokemon cards okay
so there is some bad news with respect
to this problem which is it even in
ridiculously simple settings the unique
optimal mechanism can be very
complicated so in particular hard and
runny showed that even if there's just
one buyer in two items and his value for
each item is drawn I ID from a
distribution of support three then the
unique optimal mechanism is already
really complicated okay so the good news
is this this doesn't rule out simple and
approximately optimal mechanisms okay
but we do have to start kind of small
trying to approach this okay so that's a
good question um for this specific
example so I would say one measure of
complicated pneus as if it uses a lot of
randomness and another measure might be
I guess it's kind of a fuzzy notion of
complicated and that it doesn't look
like it looks weird so what their
mechanism I'll just tell you what their
met the optimal one is for this setting
said it offers you it offers the buyer
like the following four options he can
either pay a lot of money and get either
item deterministically so with
probability 1 or he can pay less money
and get sorry get both of them at the
same time or he can pay less money and
buy a lottery ticket for one item that
gives him the item with probability i
have so he can buy a lottery ticket walk
over to another counter hand them the
lottery ticket and they'll flip a coin
maybe they'll give him the item maybe
they'll give him nothing you can buy one
of these for either item okay does that
so I don't know
I would say that's something that to me
seems complicated okay so the model is
just going to be one additive buyer one
seller and n items the buyers value for
each item is going to be sampled
independently here are two simple ways
you can sell the items one is you just
sell them all separately okay so I just
put one price on each item you walk in
you buy whatever you want and then you
leave so think of that as probably any
time you've ever bought something was
probably like that another simple thing
you can do is put them all together into
one big bundle and put a price on it say
you can buy everything or you can buy
nothing ok so there's bad news even for
this which is it there do exist
instances where selling everything
separately does really bad compared to
the optimal and there are existences
where's telling everything together does
really bad compared to the optimal so
what we showed with them Moshe above I
off Nicola muy loca and Brendan was here
is it for all instances one of them does
good though okay so it one of them is
always a constant factor even though
there are instances where right so even
though for both of them there are
instances where they both suck okay so
as a fuzzy corollary of this this means
if you sold anything on ebay recently
you probably did it in a way that is
provably approximately optimal okay the
seller decides which of these to apply
the yes the driver option where the
seller would tell the buyer well you
could either by about that straight or
bi them forget see that's right easy no
so this is the seller beforehand decides
which one do I think will make me more
money and then he uses this one and it's
actually it's very easy for the seller
to tell which one will make him more
money
thinking of giving the buyer of the
option ah ok so i guess i would say you
know by this result kind of trivially
that would have to be good because you
can always like you can always just set
the price of one of them to be infinite
or something and that right or i could
set it to be something so high that you
will never actually choose it or if you
do choose it that i'm making a ton of
money so it's only good right so that
that would be an if yeah maybe that's a
better way to state it which is it you
can just sell either the options of buy
everything separately or maybe much
higher price you can buy over you or
maybe yeah yeah um yeah i mean unless
you don't want him to choose that option
because really you want to sell
everything separately then but yes
that's true okay and so that's
everything I have thanks a lot for
listening I guess in Felicia you just
completed as I'm Tobias and said but it
was a get arrested so it's actually so
it's not comparing to meyerson's it's
comparing to whatever the best really
complicated thing you could possibly do
you don't about for the last result this
10 fantasy over their life example
advice is hitting you it's not clear to
me that you do get my senses on yes
that's true so so I'm actually so in the
main result I'm not comparing to the
optimal deterministic mechanism
character the actual optimal the best
thing you could do for any complicated
truthful mechanism that's what we're
comparing to so it could use randomness
it could you know do something really
crazy places that plan this is not in
this city
so not yeah so so not for any new
settings we can't so like so one thing
that we did try is we tried to say now
that we know all of this could we read
arrive meyerson's result and the answer
is yes and you could give a geometric
proof of that instead of using calculus
it's not clear that that's really
simpler but you could but we didn't um I
think that's a great question but that's
not something that we've been
successfully able to look at so do you
explain your benchmark in the beginning
as you're comparing to the optimal
truthful mechanism yes now give them
second expression some special settings
requiring truthfulness doesn't doesn't
hurt but something but there's something
done so what tickets if the benchmark
was the best maybe a natural that work
is started potato care about necessarily
about truthfulness they just want to do
the best I know that saying you know
saying something like you won't motivate
people to tell the truth but i'll still
be better off so yeah so um that's so
that's right so you're just saying what
if there's a higher benchmark which is
the best you could do with an algorithm
so okay I guess me sorry let me answer
that first and then maybe there's a
second thing you were trying to get out
so I'm the first is that stuff that's a
better benchmark and we do know in some
settings like for welfare you can
achieve that benchmark and as far as I
know actually there are not a lot of
settings where we know that you can't
for probation incentive compatibility if
you want dominant strategy truthfulness
then there are some settings where we
know that you can't do as well with the
truthful mechanism as a algorithm and so
one useful thing I think is it you know
so we are working to actually code up
these algorithms and implement them so
with this you could actually run it you
know run some experiments and see like
try and get some intuition as to say for
makespan do you think that the gap
should be a constant factor should there
be any gap at all or should it be
enormous and dumb so we haven't finished
coating up the implementation so we
haven't done that but and honestly I
don't have any intuition into that maybe
this another interpretation of your
question would be like what if you just
run something that's not truthful and
see what happens how much revenue will
you get and so you know so there is this
thing called the revelation principle
that says that you know well if the
bidders are actually behaving
strategically then you could make just
as much revenue by like behaving
strategically for them via a truthful
mechanism right so you know it's unclear
that bidders actually do behave
strategically if you you know give them
more options but I think it would be
nice to have some kind of robustness
argument that says that you know like
it's in everyone's interest to tell the
truth so they should tell the truth and
you make this much money when they tell
the truth whereas if you just kind of
let them do whatever they want and you
have no guarantee on what they're going
to do then it's much harder to get any
kind of guarantee but I understand only
vaguely was when you have solved the
problem in the low dimensional space and
you're trying to find action fuzzy way
together that first instance where
additive that you not the problem to
want to find it separating Clinton
because these extreme points have nice
properties then it works but I didn't
see it is it the same when you go to the
night of case you replace these
representations by just sort of expected
values of what happens yes yes so um
right so so first let me tell you so for
revenue when you go to this more general
space with this swap value description'
instead of the other description then
it's still true that the extreme points
have this nice property which is that
they are still virtual welfare
maximizers but what virtual welfare
means gets more complicated as you let
the pipes become more complicated so for
instance when you start with additive
bidders the virtual welfare maximization
problem is still going to be on additive
bidders as you if you start with
something like sub modular bidders so
let's say that all of your bidders have
some modular valuation functions then
the virtual welfare the virtual welfare
problem might ask you to maximize
welfare when they have like the
difference of two some modular functions
which could get much more complicated
than just as a modular function so let
me say as a characterization result it's
still true that all of the extreme
points are virtual welfare maximizers as
you go to this more complicated
description then what it means to be
able to maximize virtual welfare gets
more complicated and harder there's a
second thing which is so I told you that
if you don't have a real separation
Oracle so if you just have this fuzzy
approximate version you can't run this
algorithm to even find the corners to
begin with and so what happens is that
whenever let me say like this so
whenever you use this approximate
equivalence whenever you say that a
point is feasible you can actually
explicitly find a convex combinations of
points they give you this one such that
you can find that point just by running
your algorithm in a certain direction so
like I've
so what that means is that if i have an
approximation algorithm and i want to
implement some mechanism i can do it by
randomly choosing a virtual
transformation and then running whatever
algorithm i use to find it so if i had
an approximation algorithm it'll be that
same approximation algorithm that one of
those two that's right okay yeah okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>