<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Advances in Quantum Algorithms and Devices: A Quantum Approximate Optimization Algorithm | Coder Coacher - Coaching Coders</title><meta content="Advances in Quantum Algorithms and Devices: A Quantum Approximate Optimization Algorithm - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Advances in Quantum Algorithms and Devices: A Quantum Approximate Optimization Algorithm</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qjIeeB0srew" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
great so Eddie's gonna give us a
whiteboard talk okay can everyone yeah
he's gonna talk about a quantum
approximate optimization algorithm yes
so take it away Eddie thank you can
everyone hear me okay I'm my sound check
okay sure okay so what I would like to
talk about is a an algorithm which I
developed with my colleague Sam Gutman
and Geoffrey Goldstone over the last
year which is designed for finding
approximate solutions to optimization of
come in combinatorial search so what I
this my talk won't be that elementary I
assume we all know what combinatorial
optimization is I'm going to be
interested in working on strings Z and I
have a cost function C of Z these are
this is an n-bit string z12 ZN i have a
cost function which is presumably a sum
of clauses or local terms which act on a
subset of the bets and the course when
and i'm doing a maximization here
because when we talk about approximation
ratios it's important to talk about
maximization because sometimes like the
minimum of a cost function is zero and
then when you talk about ratios it gets
very confusing so I'm always talking
about maximization and one thing that we
are interested in is something called
the approximation ratio so if you have
an algorithm the algorithm will output C
output which means it finds a string
that tries to do a good job and you can
divide that by the maximum and that's
called the approximation ratio okay so
that's something if you have an
algorithm if you know so it can be
something very difficult to estimate
this
times because sometimes you don't know
what the denominator is if you have an
algorithm maybe you can figure out what
the numerator is but you don't always
know what the denominator is so that can
be confusing and I will talk about that
in the context of the work we did where
sometimes we know the denominator and
sometimes we don't okay so i want to i
want to approach this with a quantum
computer so i'm going to make up a
couple of primitives one primitive i
have is i call you of get of C gamma and
what that is is e to the minus I gamma C
so this is just an operator which
depends on the cost function and what
this does this you see gamma does to a
string Z is it produces the phase e to
the minus I gamma C of Z on the string z
on a base of state and the other
primitive I have a cool you I'm going to
find an operator B to be the sum of the
Sigma axes where these over the n bits
and then you of B beta is equal to e to
the minus I gamma B and this is just
rotates the cubits by an angle beta and
it's the same rotation on all of them so
we decided so now the algorithm says
let's start in an initial state and the
initial state we're going to take his s
which you can think of as I ghen states
as the product of the eigenstates of the
Sigma X okay because the Sigma X
eigenstates we usually call plus but we
can also write this as one over the
square root of two n the sum on Z Z
because this we all know this this if
you line up your spins in the X
direction you have the uniform
superposition in the Z direction of all
possible strings we complete with that
please stop and ask me questions very
small group if I say anything unclear
okay so this is a starting point of the
algorithm and this state of course it
represents the uniform superposition of
all possibilities so if you made a
measurement at this point in the
computational basis you would simply get
a string Z with probability 1 over 2 to
the N and therefore that corresponds to
just randomly picking a string or
randomly guessing so the way the
algorithm works is we're going to i'm
going to define get a state which going
to depend on a bunch of angles gamma
gamma 1 through gamma p and beta 1
through beta P and that's going to be
you of just try to remember whether the
beta yeah the baby's on the outside you
of be beta P U of C gamma P so I nest
these and then I have you of B that's a
B beta 1 you of um C gamma 1 on s so
this is so what I have now is this i
have um these n excuse me 2p angles i
have the set this this set of angles and
this set of angles these are angles
because this has integer eigenvalues and
the cost function has integer
eigenvalues so these things are just
angles if you wrap around they come back
so so this is the state which depends on
to pee angles and then the what the
whole algorithm is create this state for
a given set of angles and measure and
the goal is to optimize the state gamma
1 through gamma P minute let me write
this is gamma vector and beta vector the
cost function gamma beta the idea you
want to you want to maximize that so the
algorithm is ultimately call the cost
function in the
exponential the cost function the
rotation call the cost function rotate
and that's the whole algorithm now the I
now you'll notice that what I really
want to do that was choose the Mac the
best angles I haven't said how to do
that but if I say to you now the real
way I want to run this is to find the
best angles you'll see that as i
increase p i can only do better because
if i if i if i if i fix my angles let's
say for p equals you know one if i look
at p equals two well p equals 2 is the
same as P equals one with the angle 0
for a you know beta 2 equals 0 u of c a
gamma 2 equals 0 and then I have you of
be a beta 1 etc you see so if i increase
p um the and I do my optimism i said at
level p plus 1 i am doing an
optimization which contains the
optimization at the previous level so i
can only get better i say that clearly
enough yeah so it only improves so that
means that the approximation only can
improve as you make go to a bigger depth
and we can also prove that is P goes to
infinity it's perfect and the way you
can see that happens is because if you
think about the 80 I don't want to
really prove that but if you think about
the adiabatic algorithm if you have the
adiabatic algorithm and you run it for
infinite time then you'll always get the
optimal solution as long as you have a
Hamiltonian which has a nonzero a gap
and if you have a stochastic Hamiltonian
which this would correspond to it'll
always have a nonzero gap and f4 you can
view this as P goes to infinity as a
Trotter ization
of the infinite time adiabatic algorithm
so it can prove that is P goes to
infinity this will will work perfectly
no no no when I said this you mean that
it only improves no no oh no no all
that's happening here is that if i look
at p equals 2 i have four parameters I
need to optimize them but the P equals
one algorithm I can view as having four
parameters with the fees to set to zero
so when I relax them I can only improve
this the result it has nothing to do
with convexity ok so now the question is
so let's see as an example let's let's
look at some examples of vision you know
and as I go through an example we might
see how how you i'm going to show you
how you can predetermine the angles in
advance with classical pre-processing
okay at but there's um so let's do an
example I want to first start with Max
cut so max cut is the fault the way I
want to view max cut is I haven't I have
a graph whatever graph it is you know I
don't know I don't know why I'm doing it
like this but I have some graph and the
idea is I want to put on the vertices I
want to put I have bets and what I want
to do is my constraint says that the
bits should disagree that's how you get
the cut so I want to maximize the I want
to put down debts on the vertices and I
want to maximize the number of
disagreements it's like a coloring it's
like a to coloring max cut ok so in
terms of the if I turn in terms of the
Z's my cost function C is minus the sum
over the connections of I J and let me
write this as zi zi j as operators but
here I'm thinking of these
taking the value 1 and minus 1 so I want
to maximize the number of this this this
this is the max cout function or we
comfy with that or that this is the max
cout function okay so I want to maximize
that now let me tell you some results
which are sort of interest rate yes this
is what I mean why I input is a graph
and I then and this means I'm summing
only over I and J in the graph and then
my cost function is minus Z is DJ
because I maximize that if one is up and
the others down okay so that's my goal
to maximize that so let's just
understand like how hard is max cut well
one simple algorithm for max cut is to
guess it random string if you guess a
random string form ax cut you will
satisfy half the bonds because if you
just think of this as I mean these are
now random variables so if I if I guess
a random string i satisfy half the bonds
now interestingly and and that's that's
an algorithm guess a random string and
interestingly for a long time that was
the best algorithm for max cut but then
gold mines and Williamson came along and
showed that there was a better algorithm
for max cut which I will not explain but
if you ask me to it's very clever and
cute but anyway so and and and that
algorithm the Goldmans Williamson
algorithm that takes the approximation
ratio from a half to something like
point eight seven eight dot dot dot dot
dot which you can figure out what that
is it's the solution of a transcendental
equation now what's interesting about
this I mean this is a little bit of an
aside but what's interesting about this
is that that was not improved
very long time and people couldn't
understand why they couldn't improve it
and then it was shown that if the unique
games conjecture is false is true excuse
me if the unique games conjecture is
true then there is no polynomial time
algorithm that can beat gold mines
Williamson so it turns out there was a
reason for it well sort of a reason a
computer science type reason where you
know that there are consequences of
finding an algorithm and so for max cut
so anyway we decided to apply our
algorithm to max cut and i'll tell you
what our result is and then maybe i'll
try to show you how we analyze it when
so when we do max cut with first of all
we made a restriction we only looked at
three regular graphs so this means that
graphs where every vertex contain a
every vertex has three edges now that
that of course makes the problem easier
because I've given you information ok
but then what we could what we were
capable what we could do is at level p
equals 1 ok at level p equals one on
three regular graphs we got a point six
nine approximation dot dot dot now of
course that is not as good as gold mines
williamson and in fact for three regular
graphs you have to go beyond goldman's
williamson for it to be significant 2.9
something because once i give you
information you know how can i say with
the government when I say point eight
seven eight is the unique games boundary
that's for all graphs if I then tell you
there's a restriction so that the graph
has is three regular then it pushes the
ratio up that you have to achieve to
break the unique games boundary so it's
point nine something I don't remember
but we did not achieve that but we did
improve on guessing and in that sense I
think it was significant because it was
an improvement on random guessing and of
course had goldman's Williams had not
existed then the quantum algorithm would
have been
you know more much more interesting but
go but it does exist so but it is an
improvement on random guessing but I
like to say one more thing about Max cut
I another example we did is the ring and
so we have a ring and I'm looking for
the maximum cut on the ring this is a
two regular graph and what's the maximum
cut on the rain it's 1-1 1-1 1-1 and if
it's even you know there's not even a
defect so I very easy to solve but what
we could show is that our approximation
ratio for this problem is a 2p plus 1
over 2 P plus 2 now so that has the
feature that I've said that as P
increases it gets perfect now but I want
to say something about this post p is 1
then we get a three-quarters
approximation now so what happens in
this algorithm you you have to set the
angles and at p equals one you're going
to I mean maybe I should have said what
the algorithm is holdin the algorithm is
pick angles create this date and measure
in the Z basis I should have said that
yeah okay measure so what happens so if
i go to p equals one I choose my angles
properly for this thing and I measure I
get a three-quarters approximation but
what I want to point out is that every
string I measure satisfies
three-quarters of the bonds it's not
true that I'm finding this with
probability three quarters okay this so
so this algorithm it is not working by
producing a certain probability on the
best configuration it's working by
producing only strings which
meet that approximation ratio the small
variance yeah I mean yeah but i mean
when i make stavia when i make
statements like that i mean as as the
number of clauses goes to infinity you
know I could I could make it more
precise I could say exactly what i mean
by that yes but I mean yes of course
it's there's a statistical distribution
you know there's a statistical
distribution but but if you ask at p
equals 1 what is the probability of
getting this which is the perfect thing
it's exponentially small it's
exponentially small so i think that's a
very interesting feature about this
algorithm it is not a fad it's not I
mean it's working to really produce
approximations and in that sense it's
different I mean you know if you look at
the quantum adiabatic algorithm you
could also say well maybe what if i run
it and i don't get the best solution you
know then i'm still probably going to
get a good one and you could run the
adiabatic algorithm with an approximate
optimizer and I don't really know of
course it can't analyze the performance
of the quantum adiabatic algorithm for
finding the best state much less the
approximate states so I would say that
the significance of this these results
are that we have the tools to actually
analyze the algorithm on all instances
of certain satisfied combinatorial
optimization problems okay now maybe
okay instead of telling you know maybe
it's better to just tell stories and not
show formulas so let me tell you the the
next result which has to do with another
problem III Lin to and then I can maybe
go back and show you a little more
detail that okay yeah yeah there to
instantiate the algorithm you must
specify the angles so did that step is
that dependent on the instance so you
got your three regular graph now you
choose the angles depending on that
graph or do you do that independent of
autographs great okay yeah in this case
if for any fixed pain there is an
efficient classical algorithm which will
allow you to find the best angles for
every instance now when I say efficient
it's doubly exponential in pay so
quickly as Pete gets big it gets very
very hard but it's not it's efficient in
n it's not it's polynomial in n so uh so
you can classically pre-process in other
words if i give you any instance of Max
3sat a max cut excuse me I am ax cut for
example I can tell you what the best
angles are for a given graph mm-hmm I
can show you the best angles for a given
graph now some of the things when I show
you if III Lin 2 i'm going to pick
universal angles to get the results we
get now this brings up another point
about this algorithm there's another way
to run it instead of pre prot one way
one thing you can do is you can go home
and calculate the best angles by doing
what gets to be quickly a very
complicated computation but for max cut
at p equals one I could do this on my
computer and this number comes from a
computer doing some math ensuing some
you know arithmetic not math arithmetic
although it's because we had to take but
we that's the worst case you know you
have and also we estimated the
denominator here we got the denominator
also but um what am I trying to say oh
yes there's another way you could run
the algorithm which is this a fit in put
a bunch of angles and then run the
quantum computer and and get the string
out and measure its the cost function
then pick another set of angle
measure the string and get the cost
function and then you could have a meta
routine which is optimizing the angles
making calls to the quantum computer to
get the value of the cost function so
that's that is a way you could run this
and I think if P gets large like if you
go to peers 20 probably that's what you
would want to do unless you know in
advance how to pick the angles so and
that's going to be case by case we're
going to have to think about that but um
that you know yeah okay so let me just
say one thing about that you see the
fact that one of the ways that you could
run this algorithm is to pick angles and
then make calls and then pick another
set of angle make a call pick another
set of angles make a call and try to
optimize that means that if you have
control error it may not matter if it's
reproducible so for example which is
yeah so for example suppose you think
you're you're you're you you're doing
this you know you you you're you're
telling the quantum computer I'm putting
in an angle beta you know execute this
rotation on all the qubits by an angle
beta and it it does it and it outputs
something and as a function of data
suppose that you know the cost function
looks like this and you're trying to
optimize now suppose instead it's not
doing that it's putting in e to the
minus I beta plus you know point 0 to B
it's making a mistake but when you do
the calls as long as this is reproduced
every time and you're optimizing you
don't care that the that the quantum
machine is not exactly doing what you
want all you care about is that it's
reproducibly giving you an answer so i
think this algorithm is very robust
against control error when you run it in
the mode of making of optimized
by making calls to the quantum computer
which i think is significant because one
of the things i want to do is I want to
advocate that people start thinking
about running this algorithm on a small
quantum computer because I think it has
um uh well maybe I shouldn't go on that
time well yeah I'll come back to that
but I mean that's one of my goals here
is to try to talk to the Microsoft
people about thinking about implementing
this either through simulation or in
their vision of the near-term quantum
computer because this algorithm we don't
really know what its ultimate
performance is it gets better as you
increase p it gets harder to analyze by
hand as you increase p but it's very
robust against control error and it has
very shallow circuit depth so i think it
may could probably run it without error
correction at the basic levels and the
reason you can see it has low circuit
theft okay maybe i'll talk about that
for a minute see let's let's suppose
let's go back to max cut then this cost
function is this but that's you know so
look at look at this object this is e to
the minus i gamma and let me write it
then as the product over I jay-z I you
know ZJ maybe have my sign wrong plus
then maybe so you see if I tell you in
my graph bits one in 99 it connected
then I have to do a single phase
rotation using bits 1 and 99 which is
diagonal in the Z basis so all and so I
have pairwise um it form ax cut I simply
have pairwise diagonal unit Aries and I
know Chris you've been writing papers
about the implementation of diagonal
unitary and this is a case where I think
that um it's very natural so for example
here if you get if i gave you a graph if
i can implement this function
then I can do single qubit rotations by
an angle beta I'm at level p equals 1
the circuit depth is very small and
already at p equals 1 we have reasonably
interesting results so maybe if you go
to p equals 10 you'll get there you know
you'll see much increased performance I
don't know but I again I know I'm
preaching a little bit but I would like
I think that I think this thing has an
inherent robustness against control
error I think it has very shallow
circuit depth it has very simple
primitives which are just rotate one
cubit rotations and cost functions which
are local and diagonal Mizzi basis and i
think you know if you just alternate
these you may be able to do without
error correction at least you should try
it without error correction and that
means that I think it might be a good
thing to do with a small quantum
computer in the near future unless you
have something better to do okay um it's
our question oh no oh um I just like to
understand the distinction between your
version of machs gut and the traditional
definition of the mascot problem and
complexity theory is the same thing
which is you know you have a graph and
then you want to find a cut of the
verdict vertices that maximizes the
number of edges between it's sanitary
sides but the max cut problem and
traditional complexity theory has a
problem that there is you cannot find an
arbitrarily close approximation to it
unless P equals NP right so are you
implying that as you increase p here and
get an exact solution then you will have
shown that p equals NP oh I see what
you're saying no because it may be that
the P I need
to which it may be I don't know well
first of all I'd like to break the
unique games boundary you know but okay
you're saying to me what about the P
versus NP boundary but it may be that I
need P to be exponentially big in n to
achieve that I see for fixed and I can
show that is P goes to infinity it's
perfect I am NOT saying that yeah yeah
yeah no I yeah but again I mean the
statement that I should have said more
precise Lee's for fixed an in the limit
as x goes to infinity we achieve
perfection so you know p may need in
practice that may mean that p has to
grow exponentially in it so i don't
think you have to preach too hard we
read the paper and then implemented this
for quantum chemistry and quantum
materials and so we have a version turns
out p between four and six is plenty to
get chemical accuracy which is what the
quantum chemist care about and in a
variational technique very few gates as
you said the depth is very very very
small matthias want to interrupt you
want to take it after you want to
interrupt okay let me let him take it
crystal what time do i go tell 10 won't
be for a very small problem i said yes
yeah for the small problem this table
not for a big one because cuz you
talking about you know the one in two
placket hubbard models in 332 800 gate
death and with enough accuracy to just
show that you can solve the problem no
it's not interesting from a quantum
computer solving a problem i can't do
very quickly on my laptop agree
completely but for first machines for
first just qubits that we can actually
control we have
experimentalists now interested and
we're going to try over the next period
of time to actually get this up and
running physically on on real cubits not
just in simulation and I said Hubbard
motzo know they're they're just planar
can nearest neighbor connected and then
we're also doing this for water which is
fully connected across so to body terms
across in that case 14 cubits ok so I'll
ok so so late ok so let me tell you
about since some people were interested
and didn't come to my talk on Wednesday
let me tell you what our results offer
another problem III Lin too so this
problem is the following I give you I
have n variables and i have m equations
and each equation is of this form let's
say for if so every equate it is called
max III Lin to max III Lin to but it's
the same as three XO assessment it
doesn't matter it's max III land to let
me tell you what these words mean it's a
maximization problem every equation has
exactly three variables so it might be
z1 plus z2 plus Z 3 mod 2 is either 0 or
1 in other words every equation involves
three variables and each of these
equations is exactly in this form of the
form variable plus variable plus
variable mod 2 is either a 0 or 1 so the
way you specify an instance is by
specifying a set of triples and whether
they sum to 0 or 1 okay now this could
this problem deciding if there's a
solution is in P because you can just do
linear algebra so the and so I'm not
interested in case when there's a
solution i'm interested in case when
there's no solution and the task is to
maximize the number of satisfied
equations and that's why it's called max
III
Lynn too does that make sense my problem
any question about what I'm doing okay
that's max III Lynn too now it turns out
that there's again a good strategy which
is guess and if you guess a random
string you're going to satisfy half the
equations can you because if you just
guess a random string you know there are
eight possible values for z1 z2 and z3
and for them add to zero and for them
add to one okay so you guess a random
string is satisfy half of the equations
so it was known in the year 2000 that if
you can satisfy excuse me if you can get
an approximation ratio of a half plus
epsilon for any epsilon if you could do
that if you could get an efficient
algorithm that gets a half plus epsilon
for any epsilon then P equals NP so
that's pretty amazing that you know the
slightest improvement on random guessing
leads to what so you know this is a
really difficult problem to approximate
then okay now but I'm now going to do
something else i'm going to say let each
variable be in no more than d equations
that's called bounded occurrence no
variable is more than the equations now
I've given you something and the fact
that I've given you something is going
to make allow you to make a little
progress and what you can in and then it
was shown you know and I think about the
same time that you could get a half plus
constant over D approximation ratio okay
so is he d D you fix it you'd say no
variables and more than the equations
then that was achievable by hast add
around the same time okay and then we
applied our algorithm this one here at
level p equals 1 and what we actually
showed this was in the fall is that we
could achieve a half
plus constant over D to the three
quarters times the number of equations
so what that means is that we actually
showed that every instance you could
satisfy that many equations because we
showed that the quantum computer would
output a string that satisfied that many
equations so that's not the same as an
approximation ratio an approximation
ratio you have a numerator which is what
your algorithm is doing in a denominator
which is the best for that possible but
that but what we showed is that to get
this many equation satisfied and you
needed the quantum computer to find the
string ok so then Scott blogged about
this but the key thing was I think for
the classical computer scientists who
had been looking at this problem was
that we showed that there exists
solutions and that you know when I wrote
we wrote to Luca Travis on we said we
have a half plus constant over Dean of
the three quarters he said how do you
estimate the denominator we said there's
no denominator it's a half plus constant
with either the three quarters times the
number of equations and you know he was
very surprised that got him going so
then the classical computer scientists
got together and they managed to get for
a classical algorithm a half plus
constant over D to the one half again
existential times the number of equation
so they the classical computer
scientists got this they put out that
paper a couple of months ago with 0 dead
rag ave and luca travis on and boas
Barack and a bunch of other people ten
north of paper and hast that also has a
paper on this getting that so then we
went back to a quantum algorithm and we
looked at it more carefully and we could
do the following we could that week we
are able to get
at level p equals one-half plus 1 over a
hundred and one d to the one half log D
times the number of equations so we are
off by a log factor relative to the
classical algorithm now on the other
hand if we look at typical cases and let
me tell you what I mean by typical what
i mean by typical is i specify the
triples but the every specification of
the triples every equation could add up
to 0 or 1 so there are 2 to the M
instances for every specification of
triples because either everyone can be a
01 so if you specify the triples and
then you average over that you get what
I'm about to show you but it's all so
tight it is very little spread and what
we get then is a half plus 1 over 2
square root of 3 e d to the one half
times the number of equations so are our
average case or a typical case is
consistent with this and I don't know
whether that log D is there because of a
weakness of our analysis or whether the
quantum computer cannot do better I
don't know but I don't actually have a
case that requires this mean almost
every instance has this almost every
instance we have this but I don't know
whether this is just a weakness owner of
analysis or is really there so anyway
I'm not looking at that now because I'm
just not ah now but it is interesting
for this problem that if you could get a
half plus constant over the e to the
one-half for sufficiently large constant
than P equals NP so we're really still
we're approaching again the P versus NP
boundary but again I mean I think will
be interesting if I can't analyze p
equals 2 or p equals array to run it on
a quantum
computer and see what the quantum
computer produces um so I guess my time
is up so that's more say anything else
hey thanks Eddie yeah maybe maybe one
question we had a couple questions
during the talk okay Angie so these last
results you've described for what can be
efficiently obtained how many equations
you can satisfy in reasonable time is
there anything stronger known about just
the purely mathematical question of how
many equations can you say can be
simultaneously satisfied if you don't
have any time constraints if you could
search through all strings what's the
best you could did principal do well no
you see I mean how can I say it see in
this result we actually proved that the
typical instances satisfy that many
equations see we our result is
existential because what we did is we
showed that the quantum computer will
output a string that satisfies that many
equations that means that many equations
are satisfiable oh no no I don't know
you can't get more know that I don't
know that I don't know no no that it no
but not this the outcome that we run
will not find more because it has it
finds that a certain level of
approximation and that's it ownership I
shouldn't have said that you know
because if I if I if I adil if I if I
optimized over the angles I don't know
whether I wouldn't push the number
higher what I should have said it says
if I fixed my angles then I know that
every string that I output will satisfy
the same number of equations now this is
worse case so but if if I ran the
algorithm by every single instance
finding the best angles I might produce
a lot more you know suppose I had
something that's trivially satisfiable
you know like this every equation sums
to one you know so then I just put down
all ones
I i I'm pretty sure I have to think
about this at the quantum algorithm I
can find angles which do a lot better
than that I can get a lot closer to one
and a half I can but I haven't yeah I
can does that help a little bit yeah
great okay let's thank Eddie one more
time each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>