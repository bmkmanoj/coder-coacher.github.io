<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Blind Deconvolution Using Unconventional Beamforming | Coder Coacher - Coaching Coders</title><meta content="Blind Deconvolution Using Unconventional Beamforming - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Blind Deconvolution Using Unconventional Beamforming</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rtb3xcnQJg8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning everyone both of you who
are here and those of us who are joining
us online it's my great pleasure to
welcome to Microsoft Research Shima add
body and Shima completed her PhD in 2013
at the University of Michigan in the
field of blank decomp convolution and
now she works jointly and partially as a
research scientist at Columbia
University and parsley at the University
of Washington in the School of
Oceanography and she will be presenting
today her talk entitled blind
deconvolution using unconventional
beamforming and without further ado she
may have the fourth thank you so much
mark for the introduction and thank you
for coming to my talk today I'm going to
talk about blind deconvolution using
unconventional being for me in my PhD I
worked on array signal processing
specifically I worked on blind
deconvolution and I developed a new beam
forming technique I applied these two
techniques to underwater communication
marine mammal localization and
biomedical imaging but I also believe
that these techniques can be used in
audio processing and devices for example
like Kinect I will start my talk with an
introduction to acoustic signal
processing task grinding convolution and
application and then I talk about
synthetic time reversal which is
applying the convolution technique then
I talk about the mathematical
formulation of synthetic time reversal
plane wave beam forming and my new beef
farming technique frequency difference
before me then I will show you some
results and they discuss conclusions and
future work at the end acoustic signal
processing has three main tasks
the first one is signal detection by
signal detection I mean finding a
specific signal among a lot of sound
sources a good example of signal
detection happened recently it was the
search for the bakbox of fight 370 which
was lost in the ocean there are so many
sounds so
underwater we have ship noise seismic
activities like earthquake we have sound
from school of fish from marine mammal
but among all these sound sources wanted
to find a back box and so we were
looking for a specific frequency and
bandwidth that comes from the black box
the second task is localization and
tracking which has two subcategories if
we want to know the direction of
acoustic energy we need to be firm the
signal being forming is a powerful
signal processing technique for a
spatial filtering we also can use a
localization technique to find a
location in two-dimensional or
three-dimensional a good example of
localization is a collocation for
example bats use ultrasound signal
record the reflected signal and by
localization technique they navigate and
find their prey in animal biology we can
use a localization technique to study
the migration pattern of marine mammals
or in electronic devices like Enoch we
use beam forming technique to find the
arrival angle the third task is
identification and identification means
recovering the actual source signal for
example in room acoustic when we say
hello in at the receiver location we may
hear a distorted signal by
identification techniques we want to
recover the actual source signal from
the distorted signal Brian deconvolution
is an identification technique we use
binary convolution for recovering the
source signal or identification is
sometimes called in some cases echo
cancellation - in blind deconvolution
we have a sound source which is unknown
it broadcasts a signal and propagates
through an unknown environment and we
receive signal by a single receiver or
an array of receivers blind
deconvolution use
the received signal to go back and
recover the source signal synthetic time
reversal is a pointy convolution
technique we use synthetic time reversal
for recovering the source signal but
before talking about synthetic time
reversal I want to talk about time
reversal itself time reversal is a
technique for focusing waves and it's
based on a feature of wave propagation
called reciprocity let's say we send a
delta function at Point a what we get at
point B is going to be the direct path
and all the reflections from the wall
and hard surfaces in the rule now if we
reverse this signal in time and
broadcast it from point B what we get at
Point a is the Delta function so this is
the main idea of time reversal synthetic
time reversal gets the main idea but we
do not need to be able to broadcast from
point B the broadcasting part is doing
synthetically the advantage of time
reversal technique is we do not need to
know any information about the
environment as long as it's not changing
now let me talk about synthetic time
reversal in synthetic time reversal we
need to know the location of receivers
and we need to have the received signals
these are the inputs and we get recovery
can recover the source signal and all
the impulse responses as I told you
synthetic time reversal is a fully
passive technique we do not need to
broadcast we just listen and it's very
efficient there is no searches or
optimizations or iterations now let me
talk about the mathematical formulation
of synthetic time reversal but before I
want to define some notations here
I shall source signal by s transfer
function by G received signal by P and J
is the receiver index from 1 to n n is
the number of receivers that I have
as you know the transfer function the
received signal is a convolution of
transfer function and source signal in
frequency domain we have a simple
multiplication like that we have the
received signal we want to find the
source signal when the transfer function
is unknown so this is the main problem
now if we write the received signal like
this which is the norm D but it has been
divided by the summation of the
magnitude square of all the receivers
signal the source the magnitude of
source will be cancelled from the from
the top and bottom so what we have here
is an estimate of transfer function plus
an extra phase which is the phase of the
source signal we can measure this part
so we have the left hand side from the
right hand side if we can remove the
source phase we will have as we have we
will have an estimate of transfer
function so we need a phase correction
the phase correction here it's shown
here W is the weight function P is the
receive signal we multiply these two
together and we sum over the number of
receivers and then we take the face of
this summation if we choose the correct
weight function this phase is going to
be source phase plus a linear function
in frequency now so the critical point
is how to choose the rate function in
synthetic time reversal the rate
function is the weight function of plane
wave beamforming here in this form one
you are familiar with that D is the
distance between each two receivers sees
the speed of sound and trailer sub L is
the arrival angle now if we choose this
W put it here we will get this as the
output for alpha and if we multiply we
take the fit we will multiply e to a
minus I alpha from the normal received
signal we will have an S
of green function plus an extra phase
which is linear in frequency now if we
take the inverse Fourier transform it
will be trans now if you build an
estimate of transfer function with the
time shift B which is the travel time
along the path that we chose from the
beamforming output now that we have the
transfer function we can use back
propagation or inverse filtering to
recover the source signal again when we
take the inverse Fourier transform the
source waveform is going to have a time
shift B okay now we know how synthetic
time reversal works let me show you a
simple simulation simple experimental
result in this experiment I have a
source here and I send a very short
signal at 2 kilohertz down here I have
an array of receivers 8 microphones this
is a sample received signal you can see
all the echoes after the direct path and
the correlation between this signal and
the actual source signal is only only 5
59% now I use synthetic time reversal I
get this signal which has 95%
correlation with the actual source
signal so I was able able to remove all
the echoes and get back to the source
signal but in this case being forming
was working and I was able to use the
beam forming output for the phase
correction well how about the phases how
about the cases that been forming does
not work in the next couple of slides
I'm going to talk about being for me let
me just briefly talk about plaintiff 8
me for me you all know about that this
is an diagram of plane wave beam forming
we have n receivers so we have n
received signal we take the Fourier
transform of these signals we get the P
as a function of frequency and we
multiply each signal by an appropriate
time shift tau which is exactly like
what we had in the net in the previous
right so when we multiply the time shift
at the end we sum them up we take the
magnitude the square it's going to be
our beamforming
output here in plane wave being forming
beamforming output is a linear function
of all the signals we just have P here
now let me show you a simple simulation
result when we have a free space just
one source and end receivers no
boundaries
we have 16 receivers and the frequency
that we send is very broadband from 20
Hertz up to 20 kilohertz which is almost
the same as the here human hearing range
now we beam for that it's going to be
like this this is the low far ground and
it's usually we have theta which is a
steering angle on Y axis from plus 90 to
minus 90 it's usually versus frequency
but here I'm showing verses V over
lambda these the distance between each
two receivers and lambda is the wave
length we know that from signal
processing sidelobes will be present
when the over lambda is greater than
half so when we are down here let's look
at the marginal case when the over
lambda is equal half we get a nice peak
in the middle so the results are good we
are getting what we want
but what if we go to higher the over
lambda like 1.5 kilo Hertz we get a nice
peak in the middle which is for the
which is coming from the source but we
get a lot of side lobes
now if we go to even higher frequencies
even higher the over lambda ratio like
here which the over lambda is 40 which
means the array is 2 is sparse the
beamforming output is too noisy and it's
confused we can resolve the angle so the
problem is here but why it's not working
here we assume that all the receivers
are receiving plane waves however when D
over lambda is very large which means D
is very greater than lambda the
wavelength
then we are not receiving playing wave
anymore we the receivers are feeling the
curvature of base funds so that's why
the plane wave being forming is not
working now I want to add two
reflections to the previous simulation
one reflection from positive angle 2.6
degree and one from negative angle minus
two point four degree and we have the
same receiver receiving array for
resolving these angles we need at least
one degree resolution in beamforming so
based on this calculation which is the
resolution we need to manufacture
somehow 1.5 kilohertz information to
have at least one degree resolution
let's look at the loafer gram of plane
wave beam forming it has the same
setting as the previous slide so if we
look at the D over lambda over have
equal half we get a nice fat beam in the
middle it's not able to resolve three
angles because we don't have enough
resolution at this frequency for having
higher resolution we need to go to
higher frequency so let's go to 1.5 kilo
Hertz that we'd expect to be able to
resolve the angles so you can see in the
middle we have three peaks at right
angles but we also get side lobes now if
we go to very very largely over lambda
again plane wave beamforming is too
noisy and featureless so what if we only
have the information here in very large
D over lambdas how can we resolve the
arrival angles from being forming output
what should we do here even the average
being forming is not working at all if
you have a broadband if you take the
average over frequency it's not helping
so now I want to talk about the new beam
forming technique for resolving this
problem the idea is very simple P which
was the receive signal if I have that at
Omega to 101 frequency in the bandwidth
in the face I will have one mine
I Omega 2 times T now if I take P at
another Omega Omega 1 but this time
complex conjugates in the face I will
have plus I Omega 1 times T now if I
multiply these two together in the face
I will get the frequency difference
times time remember that Omega 1 and
Omega 2 are in the bandwidth so they are
in half there are very high frequencies
but the difference can be small now
instead of being forming P if I be from
this product at Omega 2 minus Omega 1
I'm manufacturing the employ frequency
information so this is the Nubian
forming technique is called frequency
different spin for me now let's look at
the diagram of this technique you've
seen this before for plane wave being
for me I just want to show you the
different part which is inside the red
box instead of being forming P I'm being
forming the product P times P conjugates
at two different frequencies and instead
of being forming at Omega I'm being
forming at Delta Omega everything else
is the same as plane with me forming I
sum them up take the magnitude square
that's going to be the beam forming
output but this time being forming is a
quadratic function of received signal
not linear anymore now let's look at the
beam forming output for the three paths
simulations simulation that I had before
remember that Omega we can play with
Omega 1 and Omega 2 to get different
Delta F right but the minimum Delta F
that I can get is a function of the
sampling rate and the size of f of T in
this case the minimum is 12 point two
Hertz this is the low for Graham
frequency difference being forming at
twelve point two Hertz we get a fat beam
in the middle we don't have enough
resolution to resolve three angles
exactly like plane wave being forming if
want to get better resolution I need to
go to higher frequencies so
let's go to 48.8 Hertz you see that the
beam in the middle is getting narrower
but still not enough resolution so let's
go to higher the beam in the middle is
getting even narrower but we are getting
the side loads these are the costs lines
related to the side lobe remember that P
has three terms for each arrival when we
multiply P by P conjugate we get nine
terms but the only one three turns like
that the three terms that we want are in
the middle the other six terms are the
cost lines here so it's still not enough
resolution let's go to higher frequency
we can get we can see the separation of
path in the middle and more side lobes
but let's go to 1.5 kilohertz that we
expect to get enough resolution for
resolving three angles this is the low
program at 1.5 kilo Hertz it doesn't
seem to be working but I want to do a
magic here let's rotate this figure by
90 degree you see the three paths here
right so we can get we can keep the
persistent part at the right angles by
taking the average over frequency now
let's look at the output this is the
average frequency difference and plane
wave beamforming output the dashed line
is for plane wave output which is
featureless the solid line is for
frequency difference being formed we get
three peaks at right angles now I want
to show you the average being forming
output for different Delta F Delta F is
increasing from bottom to the top I want
to show you some similarities between
frequency difference being forming and
plane wave being forming when we have
been you are a low frequency we don't
have enough resolution to resolve three
angles but as we go to higher
frequencies we are getting more
resolutions and you can see that it's
very similar to plane wave beamforming
other thing that I want to show you is
side lobes for example at 20 degree we
will get side lobes at this frequency if
you do the calculation at 1178 hertz
look at the 20 degree beamforming out
with here we don't have any side lobes
and we don't have still any side lobes
but at eleven seventy two Hertz we are
getting the side lobes so although the
frequency difference being forming is a
nonlinear technique there are some
similarities with the linear technique
no sure superheterodyne radio receiver
you have very large and with the insight
there there is some signal that you want
to recover and you expect that the
majority of the radio spectrum there's
not very much information and in a very
small bed with various that information
you want and it's often not not feasible
to work at this frequencies directly so
instead you use an intermediate
frequency where you introduce a mixer
and that effectively shifts the spectrum
down to some intermediate frequency it
may not be baseband but maybe something
else and that's effectively a frequency
difference kind of problem are you
introducing another one kind of
modulation that shifts your your
frequency of interest yeah and on that
you can then by informing techniques or
face array techniques or anywhere in
existence I'm I'm not sure I understand
the difference between doing that and
what you're doing here if they seem to
be the same thing well I guess in that
case you are shifting the linear term of
signal to the lower frequency right you
are not making it not nonlinear when you
don't have the product right okay so
that then becomes quadratic well yeah
this is actually a good point and it has
been mentioned before but I didn't
compare that where the frequency
difference been forming yet so I'm not
sure if I can answer it correctly right
now because I don't have
enough information about the technique
but maybe we can discuss that later
yeah sure asking questions to make sure
I understand to these Delta X these are
the difference in frequency between the
basically sub bands in each channel that
you're multiplying between yes these are
execute that Omega 2 minus Omega 1 that
I showed in the previous slide so for
example for 1,500 Hertz you're taking
something and say 20 Hertz in your
correlate or multiplying that was
something at 15 exacts that's good so
actually maybe it may be so it's
interesting that your demodulating kind
of one sub band by another sub band that
could maybe be difference between using
like an elbow which is a set frequency
and and I mean you're just using a
little different you're using like other
sub bands as loz for other sub bands
maybe that could be the difference yeah
it is secret I mean I don't know these
very well but in a synchronous receiver
you you use its own carrier to
depopulate itself hmm and that thing is
very similar see I can see that yes it
feels like there are some similarities
there okay
sure so now that we have a bean farming
technique which works I want to apply
the beamforming output to synthetic time
reversal to recover the source signal
but this time
you remember we have this rate function
for the original synthetic time reversal
which comes from the plane wave
beamforming for this case I need to
change the rate function to use the
nonlinear rate function which depends on
the received signal itself and if I do
this change and apply synthetic time
reversal I can recover the source signal
this is the original source signal that
I sent it's a I guess 50 with 60
millisecond chirp and this is one of the
received signal it has only 57%
correlation with this one you can see
the distortion now if I use this rate
function apply synthetic time reversal I
can recover the source signal now I have
98% correlation with the actual source
signal okay now we know that it's
working in simulation let's look at the
experimental data the experimental data
that I used was for underwater
communication and signal and I had the
exact same receiver area had 16 channel
with same distancing LM a distance and
everything was the same and if I do the
plane wave before I mean I get this
dashed line here exactly like simulation
it's not helping at all but if I use
frequency difference before I mean I get
these two peaks I should say that I'm
being forming the signal after the red
red line here because we don't have
enough information about the environment
to know the exact arrival angle to make
sure that frequency being forming is
working but you see this noise policy
here that's because of cable is slapping
and bike we have the time difference of
the arrivals at different channels so we
can calculate the arrival angle which is
we know it's at 25 degree so if I be
informed that when I get a peak at 25
degree it's for this pause I can say now
frequency beamforming is working in our
experimental data now if I use synthetic
time reversal for experimental data this
was the original sound signal that was
sent the citizen received signal one of
the received signal has only for the 8%
correlation now I apply synthetic time
reversal to these signals I get 92%
correlation so it's a big improvement
for the experimental data now if I want
to conclude my talk I'll show you that
blindly convolution with synthetic time
reversal is a as possible when being
forming works and I showed that
frequency difference before me and can
be used with a sparse receiving array to
resolve the arrival angles when plain
wave mean forming fails to do that now I
just want to talk about a little bit
about future work frequency difference
bein forming is a new technique at least
in acoustics is very new and I just
applied frequency difference being
forming to uniform linear array but one
research topic can be applied this
technique to non-uniform linear array
like what we have in connect maybe we
can improve their beamforming output for
that by using these techniques or
applying to non-linear array that is
very cool array also i like to know the
number of microphones that we need for
frequency difference be informing to
board what if we have just few
microphones a couple of hydrophones the
other research topic is are we able to
remove side lobes in not very largely
over lambda here when we are resolving
the angles but we get side lobes oops I
don't know what happened no one did the
presentation just went out
okay anyway so but for not very large
the over know it's logging off oh I
didn't have anything it just wanted to
say that for not very large the over
lambda how we can use frequency
difference being forming to remove the
side lobes and how it works better or
worse compared to and vdr or other
nonlinear beam forming techniques and i
just wanted to thank my collaborators in
this research study professor darling
from university of michigan and dr. song
from university of california at san
diego and thank you all for your
attention I welcome any questions
you remind me how that exactly the beam
former weights we need a great to be
able to get the correction phase be
linear in frequency the extra term to be
linear because if it's nonlinear then we
get the phase distortion right so if we
choose not a not appropriate wave
function then we get phase distortion
that's why that's why it depends on
being 40 and then another question I
found that is what happens when that
magnitude
like that average magnitude they do has
zeros or has very small values doesn't
that transformation estimate blow up
when you have those zeros in the
denominator well we take the the
magnitude and then be a square right so
compared to and so if that that case
happens only if maybe for just one
receiver right that I don't know when
that happens because we take the
magnitude and then we square that so
it's going it's adding the values right
new average yeah was the average over
all channels overall China's let me take
the magnitudes first so it's not like
having a possum - to be canceled well
but but that magnitude - easier
potentially then o then each receive
signal has a small value - right so that
the top and bottom they both are small
I didn't boys you know what I mean that
the ratio is going to be yeah going on
from the problem that usually comes up
with in room acoustics when you have a
single source of single receiver if you
were to take that up channel and then
plus it's in zeroes on both plot in many
cases those zeroes my outside the unit
circle and so if you wanted to
completely remove those zeroes by
placing poles in that in the place you
end up with a filter that is unstable
and so then there is no solution in that
case or move it a single chapter base if
you have multiple optical aberrations
and no serious don't lie in the same
position then you no longer have that
uniqueness problem you're absolutely
right yeah foot before well I studied
this performance of synthetic time
reversal for number of receivers that I
need in simulation shows that I need at
least four or five hydrophone depending
on the situation but I need more than
one receiver to be able to recover
source so they be that in room acoustics
there the the definition of how common
to zeros is not very clear-cut think you
have two zeros they're quite close to
one then what results is that the
filters that you design have a very
large white noise gaining event at those
frequencies so if you had a microphone
that had no self poise then you'd be
able to recover it perfectly but then
there are issues that when the
microphone does have its own noise you
can't then start introducing
very large amounts of gain
his frequencies so that's a fundamental
limitation we usually come across
I miss at the beginning of your talk but
how easily through generalize if you
have multiple sources so currently what
I curtains so is one source and some
kind of noise and reflections and in
general what we call a Berber of
environment what if I have to sound
separate sound sources to sources that
are sending the same signal or totally
uncorrelated different signal you and
you're talking about synthetic time
reverse or end bind accomplish a
technique then we need to remove two
different face sources we need to
probably need to separate the signals
I mean separate source first and then I
mean we need to recover the source
signal separately I don't know I didn't
work on multiple channels yet and I
don't know if we can apply synthetic
time reversal to multi-source sound
sources but maybe by finding a correct
wave function which has both sound both
source faces and an extra linear face in
linear in frequency
I should think about that the other
which is how robust is this approach the
noise to noise yeah I studied that for
the lab experiment that I showed you I
increase the level of noise what seems
that working variable for the experiment
that I showed you was we had 14 DB SNR
and I was able to go lower like nine
eight but so I mean after that we need
to have I studied that we need to have
more receivers to be able to recover the
source signal at for having at least 90%
correlation but it decreases the
performance decreases as a function of
we have lower signal to noise ratio
from the underwater acoustics maybe
correlation is a very good quality
measure but in audio in acoustics in the
real environments typically we use some
different measures have you ever tried
to do signal restoration from a speech
signal introduced and say based on some
psycho acoustic objective or subjective
measures for quality also instead of
correlation what measurement to you this
is a human speech in general there is a
subjective or objective but psycho
acoustic weighted perception of how
political understandable their values of
objective and subjective measurements
have ever tried of this sort well I I
don't see any limitation for that
because it's not just for underwater
acoustic at the experiment that I showed
you was airborne experiment so it's a
good researcher study we should try that
I don't see any limitation I don't know
I haven't so in the experiments that you
had you have these these relatively
narrow band shares of these 4217
kilohertz you're saying the point for
performing but yet the underwater
acoustics and your quality measure is is
the correlation what ultimately you
doing with these signals after you've
done your deep emotion with the yeah
with the signal coming young once that's
come back what's your use what would you
do with it well as we discussed earlier
in coming in underwater communication
for submarines for example they send the
signal in the other submarine may
receive a signal which is distorted and
they want to know what was the original
message so they are particularly looking
for that signal coming from synthetic
time reversal what was the original
message after coming you know underwater
is like a sound channel we get
reflections from the surface and bottom
and the signal recorded far you know
it's soundtrack can travel very far
underwater so after a couple of
kilometer underwater
the signal that we receive is distorted
we want to know what was the signal
originally it says that that chirpies is
a synthetic message exactly so you're
just using that in place of some
modulated yes it alert basins yes
for the second expert for the underwater
experiment they sent M sequence which
was it was in the church it was M
sequence signal but the first one the
simulation I just said let's check your
signal okay so you can see you can see
whatever ultimately used to estimate an
impulse response yes yes so you're
you're using blind deconvolution to
clean up the receipt signal from which
you then apply an another supervisor
system identification in the sense that
you're using M sequence you know what
the original was and what received was
yes and that gives you another estimate
of the channel yes it yeah the beauty of
synthetic time reversal is not is that
we can get the original signal and all
the impulse responses at the same time
so we can I mean recovered impulse
responses we haven't then you have
information about the environment but
there is I mean this is correct as long
as the transfer function is not changing
its constant you know if you have a long
signal sound sound source signal and we
have wave you know the surface wave
underwater then the environment is
changing constantly but if we have a
calm sea then we can use this technique
even for the law long signal the
application so you're sending a chirp or
you're sending your name sequence and
then you're doing your very best to deep
evolve it's the point if you've got a
high correlation between what you sent
what you've seen then there's no
information in it I mean you've got you
you've already removed all of the
reflections of the vibration why would
you send a name sequence if you're very
if the very point of what you're doing
is to remove what in in the experiment
we already know the original thing
but but in real word we don't know the
original signal so that the purpose of
synthetic time is don't find original
signal you know what I mean in the
experiment we know that it's an in
sequence with that is specific criteria
but in real word we just have receivers
we receive signal want to know what was
the word you okay you're if you use the
M sequence then the residual of the
things that you weren't able to receive
the things that come it's that way yeah
you were saying that as an evaluation
criteria yes yeah exactly for this
technique I need to have something to be
able to say that it's working right so
for the experiments I knew the original
signal but in the in the application of
this research is when we do not know the
original signal and you want to recover
that
doing experiments with more
non-stationary signals or natural
signals hold positions I I applied this
technique to marrying mammals and they
are moving you are right but the
movement was not I mean we can assume
it's movement it's not that much that
much big so we assume it's a stationary
but if it's moving very fast and we can
assume that were able to recover yes yes
actually an extension of that was way
localization I did I used synthetic time
reversal to find a location of marrying
mammals underwater I was a chapter of my
PhD
pure so if the purpose then is to the
localization then the informing need not
necessarily come in this area to me if
you have a prepared receivers and say
you are able to work up a correlation
between them and you can estimate that
the time delay of arrival we can
estimate the time oh yeah yeah and if
you then introduce the third receiver
then you can estimate again the time
difference of Robin mm-hmm and then you
can create a very pair you can create a
locus of potential source locations and
that then isn't subject to a using
problems how far apart you have those
receivers if if your plan is only to
localize the source as opposed to
extract the source well is that your
right but these are two different
problems we want to find a location or
we want to find a source signal yeah for
finding the source signal we need
beamforming right but for finding the
location you right if we I mean we are
not never in that range of the over
lambda
right because frequency variable
frequency is always low so we RP don't
have that problem the problem that I
talked today was for the communication
signal that are in high frequency
you know exactly circularization
this it was an extension of that so we
need some other information - for
localization it's for for recovering the
source signal we didn't use we didn't
use any information about the
environment but for localization we need
some information so it was another
project an extension of synthetic time
reversal for socialization but for
recovering the signal we just need
before me to work
sorry another question so when you do
this frequency difference thing so
obviously there's finite frequencies you
think was bandwidth you can use so do
you like wrap around you know the
necklace no actually that's the reason
we need a broadband signal because when
we are close to the end of the bandwidth
then we get to have zero after that so
we get you know for the Delta F at the
end of the bandwidth we will have zero
so that's what we are losing information
for that part but since we have a
broadband we are okay so is the case
there and Delta that increases you have
less and less cross multiplications
between frequencies we have less or more
less so like if you're let's if your
necklace bandwidth is up to two thousand
and let's say that your Delta F is 1,000
so you can go like 1 and 1/3 of 0 and
1000 and then without the mm yes
but then if your Delta it's 2,000 then
you can only going 0 and G has a great C
or less it's not working across
institutions but it's not working in
that case we are not able to resolve the
angles we need a bandage to take the
average so you know it's efficient being
yes so that as you go through stopped up
you just needed a packer mark bit yes
any other questions so if you just had a
source signal that was just assumed a
single spot frequency then the students
you go into that region of heavy special
aliasing then there's nothing even good
you have to have some fact that you're
able to perform some degree of aperture
yes actually you know because the make
that the main part of that was taking
average over because you know they don't
have just one single frequency there
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>