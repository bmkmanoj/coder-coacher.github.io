<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The intersection of artificial intelligence and robotics | Coder Coacher - Coaching Coders</title><meta content="The intersection of artificial intelligence and robotics - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The intersection of artificial intelligence and robotics</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/zwJdM2sRhlY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I
hey there my name is Seth Juarez we're
here at the microsoft research faculty
summit 2015 i'm here with manuela
belloso so tell us about your work with
robotics so my work is on the
intersection or the combination of AI
artificial intelligence and robotics so
I work on trying to have these
artificial creatures these robots be
capable of doing an autonomous cycle of
perception cognition and action so you
try to understand how can the algorithms
process their sensors make decisions
about how to achieve their objectives
and eventually actually actuate the
decisions this feels like a very good
mixture of engineering not just for
software but also real engineering what
are some of the challenges you faced in
both areas yeah so indeed we want to
address the physical world to the
physical machines so it's not just a
cyber project not just a software kind
of research but it does have to run with
real sensors and with real actuators so
we care about also mobile robots which
is not just manipulators as actuators
that actually machines that move so go
from one position to another by
themselves and I've been working on
these autonomous mobile robots for a
long time so the challenges have to do a
lot with these integration with this
problem of having whatever the
perception whatever the real sensors
come up with be used by an algorithm
that is trying to decide which actions
to take to achieve of goal and also
making sure that those type of actions
go were not executed in a real platform
in a real hardware platform so what does
it mean to put these pieces together
like a speech recognizer
seen record of visions algorithm
planning algorithm a learning algorithm
eventually into together so that you can
have this perception cognition and
Ashley integrated and I've been working
on this problem for almost more than 20
years what are some cool sort of use
cases where you've seen these sort of
perception cognition and actions were
really work well together so you have to
understand that we have been working on
robot soccer for a long time and the
issue there is become is full autonomy
in the presence of a lot of uncertainty
which are the opponent but complete
autonomy now input from humans you are
supposed to play on a customized field
on this specific size and specific like
lines and landmarks and the colored
balls and everything is kind of
customized like a basketball field a
basketball court or a soccer field is
all customized I mean the sense that
it's not the real kind of like
open-ended environment but the opponent
is a big uncertainty you really don't
know what are they going to do how are
they going to actually act so these
robot soccer problem has been a teamwork
problem so how do they work together but
also these planning and these thinking
and the sensing and is actuated and
there are a lot of uncertainty with a
very very clear goal so you want to win
the game so it's a very interesting
problem from a research point of view
how to handle this uncertainty with such
a clear goal so we've talked a little
about action it feels like we started to
talk a little about about cognition
what's the best is there a certain way
for robots to think that's better than
other certain algorithms that work
better than others or it's just a whole
mishmash of things it's a it's a
complicated kind of problem but the
cognition part basically is about being
able to get as input whatever the
perception gives you and being able to
generate an output for the motors for
the actuators with in real time that's
all so complicated because for example
you have your sensors at 60 Hertz 60
Hertz meets about like every frame comes
in about 60 million
seconds so you have 16 milliseconds to
from a cognitive point of view analyze
all your possible actions or plan your
routes or see what the scene looks like
making decisions about actions and issue
the actions to the actuators so that
they move in real time so we don't this
is another thing about the integrative I
i we don't want that robots to be just
they're stopped and saying what does
this seem look like and tomorrow they
actually act upon it so there is a lot
of like real-time aspect to this
cognitive process and the cognitive
process usually usually is based on a
planning problem so it does an
abstraction of maybe not at that doesn't
plan at a pixel level but you get a
representation of the world and use that
representation to generate routes to
generate actions at different levels
either high level actions for route
planning or low-level actions for the
motors like motion planning so let's
finish up with perception what are some
of the challenges with perceptions it
feels like there's going to be a lot of
challenges there yeah perception is a
really difficult problem in general but
let me just tell you that one of the
advantage of these also this integration
of perception cognition in action is
what I call purposeful perception so
it's almost as if you think about the
seeding that we are seeing here and it's
kind of overwhelming if we would like be
having a computer process all these
details like the color of this carpet
all the way to the width of these
corridors all the way to how many people
are around I mean imagine however if we
actually do a perception algorithm that
is connected to a cognition algorithm or
that it's a producer of what cognition
needs so cognition and perception work
as producers and consumers so whatever
the perception produces is what can be
consumed so if the robot cannot read
that whiteboard it doesn't really matter
to process it because there is no use
for that information from a cognitive
point is here so it's like when you and
I get out of an airplane in some Airport
where we have never been
we always get through because no matter
what the colors of the chairs are no
matter how wide this thing we only look
for baggage claim that's it that's out
of the whole scene because we want to go
out from a cognitive point of view it
kind of filters down what's needed from
a perception point of yours it's like a
constrained perception yeah exactly it's
very constrained by what's needed so
when the robots move in a soccer field
and they don't know where the ball is
the only thing that the cognition is
telling them is ignore everybody else
just find the ball it's like very
beautiful the fact that because you are
doing a task that the task constrains
what's needed in perception and of
course if a fire starts you would like
to be able to robot to now but maybe the
current robots don't have that because
they are not processing all that
information so it will be another level
of research to try to them do them
purposeful perception so that that
particular task gets executed and on top
of that be alert for everything else
well we are not there yet you understand
so that's the point well thanks so much
for spending some time with us thank you
very thank you so much for watching and
we'll catch you next time take care
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>