<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Manual Deskterity: An Exploration of Simultaneous Pen + Touch Direct Input | Coder Coacher - Coaching Coders</title><meta content="Manual Deskterity: An Exploration of Simultaneous Pen + Touch Direct Input - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Manual Deskterity: An Exploration of Simultaneous Pen + Touch Direct Input</b></h2><h5 class="post__date">2010-05-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/uUN4oVpmEdc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello my name is Michelle Perry and I'm
walking with bill Buxton and canning key
at microsoft research so our research
focus on looking at how to do by manual
input and look at what kind of things we
can create with that we are looking at
large tabletop gain of display like
surface also tablet pc as well as a
smartphone kind of this device so this
demonstration will be mainly focusing on
the surface so by default depend right
and touch manipulate you can also use
touch to zoom and pan and so on but now
if you combine both together let's say
if i combine pen and touch pen and touch
at the same time i can create new tools
as an example if i hold an object and
cross through with my pen my pen become
exacto knife also if i hold an object
and go across i can copy the object i
can also convert the pan into a star
player so if i select a value object and
then tap with the pan it creates a pile
of those objects i can also create
straight edge by holding the object with
two fingers and then crossing with my
pan and i have a straight edge on the
top of that i could stop also if i put
my finger down and tap with the pan i
create a staple of the image i can even
change the color by putting my finger in
one of the color and then stopping again
and i can change the color what i showed
you on to your face was that i could pan
and zoom using my non-dominant hand
while writing with my dummy intent so
now if we look at the smartphone how can
we convert this model on a smartphone so
the smartphone you know that the non
demure 10 will be holding the smartphone
so here the conceptual model that we
have done to stay through with what we
have done on to your face is that you
move the smartphone to pan or you go up
and down to zoom and then you still have
your demeanor tend to write on your
diagram in conclusions basically we have
looked at what we can do with pen and
touch this research is just an ongoing
research we believe that there are a lot
of scenarios where it could be a huge
impact for the user want to annotate to
be able to manipulate objects with a
minimum of you
I on the screen</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>