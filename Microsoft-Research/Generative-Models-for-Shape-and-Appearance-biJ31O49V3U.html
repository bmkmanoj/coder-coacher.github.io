<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Generative Models for Shape and Appearance | Coder Coacher - Coaching Coders</title><meta content="Generative Models for Shape and Appearance - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Generative Models for Shape and Appearance</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/biJ31O49V3U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
yeah okay good morning everyone it's a
great pleasure to have Neil Campbell
pair from go a little bit of a
beginning there are these four
generations of Investigation I think we
need to think so I'm very excited okay
what I was going to talk about today on
Jenner tomography cool I cut a load of
slides about how to motivate why you'd
want to use a generative model so we
don't have to go through that so I
thought for you guys it would be a
simple thing so I'm not even going to go
through the offering that many
advantages but just a particular
advantages that I'm interested in and
it's a go actually the other ways often
we at the moment we're going from
computer graphics to try and help us
with some vision and I'm saying let's
schedule Oda training data of images or
shapes and perform some unsupervised or
semi-supervised learning and then use
that in a new context going back the
other way so I'm more interested in
recently in some applications and
graphics how we can help people in
graphics by using some vision learning
and building some bundles of this sort
so there's sort of three things I was
going to talk about today I generative
model of fonts so this is more shapes or
human man-made shapes I consider funds
just a specific example of a set of
shapes of the bay certain rules and not
crazy about font and generative model
for appearance and which is where just
come from cvpr and their we're targeting
sort of deformable part based visual
objects things that don't conform to
normal simple subspace parametric models
and then really briefly this a sort of
in this application of something we
brought some of these ideas together
with recently and just come out in the
video graphics forum on how you can make
serve an artist tool using this sort of
training data to help help build some
models cool so starting with the fonts
and so we started looking at this and I
found very rapidly what everyone already
knows that designing editing font is
really hard you have to be an expert
typographer there's loads of rules that
you have to learn and you have to use
really bizarre gear new complicated
software or pay Adobe a large amount of
money to make them and you're basically
given a curve editor and told to make
curbs that are only fonts so if you're
me the everyday user what can we do well
we've all got access to a large
collection of fonts and I hard disk and
so can we use some kind of unsupervised
sheen learning to try and help capture
the rules that we know are encoded in
these fun designs so that we don't have
to learn them all so if you like the
motivating example would be if we have a
standard font editor and I pick a point
on there there a set of outlines of a
set of Bezier curves by grab a point and
move it around we get something like
that and now I think we're all agreed
that's not really a valid front anymore
so if we had an intelligent font editor
and I grabbed that point and pushed it
down maybe something like this would
happen where we know that like spoke
contrast is the thing that's preserved
under on the font so for base gets
thinner my stroke contrast is getting
sinners at the top corner should get
sinner and then if we had a really
intelligent font editor as I grabbed
that and push that down then perhaps all
the other glyphs would automatically
also themselves in a similar fashion to
keep them helps consistent with the Edit
that I'm making so that's a sort of just
a motivating example of why and this is
very easy to achieve if you had a nice
generative model of system so why should
we build some canary models cool so
obviously from machine learning point of
view these rules are well if you take
the space of closed curves but a massive
set and not all of them are fonts so if
we consider as a representation that
maybe we go round our curve and
subsampling a set of points and said
give a polyline representation and then
of course we have all these
interdependencies which is giving us a
much lower dimensional space in reality
that's occupied by fonts and the general
space of closed curves so there should
be something we can learn there
and there should be some low dimensional
manifold that exists so that's something
you should be going looking out for like
people have worked before on just
assisted front design so they've been
some work on parametric methods before
including the method font system is
system which looks something like this
where you would make explicit the sort
of you sort of hand coded generative
model of the font for the set of rules
and it would you could then very a
couple of the parameters so he's got
some parameter sliders on the width of
course some of these are valid would
come create ballet configurations some
wouldn't but it was a bit complicated
not the best of interfaces there are
industry standards for doing this and
they're called sort of like Adobe
multiple masters so you have a font file
that encodes a couple of different
states and they exist as a linear
interpolation between those states or
try linear interpolation but the problem
is you've got to design all your funds
like this to be where all your Bezier
curves and their control points are all
an exact correspondence so just linear
interpolation in the curved space will
create your fatter or thinner font or
something like that so that's quite a
lot of work to put all these in
alignment and so our approach is very
similar to this kind of thing but we're
saying we just take the existing fonts
from your heart this a talented
alignment at all we don't require and
you want to go in and edit all the curbs
to put them in alignment we find the
correspondence as automatically and also
we do more intelligent inverted commas
interpolation extrapolation where we're
finding the probability on the
underlying manifold from the fonts
themselves so we don't just as much as a
linear interpolation between some match
points it's a sort of non linear
interpolation and extrapolation based on
data so in general sort of they did in
synthesis and hinting there's lots of
works and we're not going to talk about
font hinting and things like that so
people have been working on sort of
other tangential topics related to fonts
there's also browser ring structuring of
fonts and again I'm treating these moral
shapes as opposed sub okaying
specifically that they're that their
fonts so obviously there's a lot of work
on shape matching
and shape interpolation and the main
thing I'll say about this is a lot of
work at the moment is being done in the
graphics community certainly with
pairwise matching techniques and these
introduce problems when you're trying to
build generative models so the other
sort of subtext for this which is on the
next slide is the representation that
you juice use and how you choose to do
the matching i think is very important
and there's also sort of other works
that show shaped with templates and
things like that like I've stole from
paper and things and having these sort
of models allows you to do lots of
useful things so what I would call the
universal parameterization is the answer
to the sort of pairwise matching system
so global matching when I mean
globalizing across all my fonts as
opposed to global optimal that we have a
representation where you free each font
of the polyline and we try and find in
one to retreat each bliss as an example
of it we match outline to outline and we
do them all at once so that they can't
they create a vector at the end where
each point in the vector is in
correspondence across all of the fonts
so this creates a huge parameter vector
but is uniquely parametrized across the
whole space of the funds so if we had
pairwise matching I could do something
very similar and try and reaper ammeter
eyes a curve to the other curve to put
them into correspondence and if I do
that for a to be and for Pompey to see
and then for C to a then of course i
have this consistency problem and
there's no reason why if i go around
that loop that if i propagate my
correspondences all the way around the
loop they should come back to the
identity and that can be a big problem
especially when you've got lots and lots
of fun because now you've got a
quadratic firstly pairwise matching you
have to do a quadratic matching thing or
you have to sparse by the space and
match along the tree or dag or something
like that and then you're going to be
suboptimal because you don't know
beforehand which the right way to build
your tree is and also if you if you do
quadratically and then for some
consistency equation you've got been a
massive outer optimization it has
roughly the same number of parameters of
this one as well
letter A and you may not be able to come
up with a good mentioning at all this
week oh yes I will come across that in
just a second so hold your sort for a
few slides if you still have it create a
guy tried to me again so the way I sort
of do matching is by just preparing the
outline so we take all the Bezier
outlines throw away the rest of the
information we normalize and align our
polylines and just to get them into the
rough scale the right scale so we can
the curvature and things like that and
then we normalize to try and find the
correct starting points which is
starting to cheat because I'm now doing
something that I said I wouldn't do
which is to start by pairwise so we do a
rough alignment based on pairwise
matching and at that point we assign
each outline to a neighboring outline we
can't handle different system topology
so we assume is the same number of
outlines time I work out for the inner
loop it matches to the inner loop and
the outer loop matches to the outer loop
and if there are different glyphs we'll
see in a second with the G we we just
throw that away and ignore that for the
moment and so once we've got these once
you've got these alignments then we find
these dense correspondences so for each
of the individual this we find the
correspondences using an energy model
and once you've got that gives us this
parameter vector which uniquely defines
the shape of the font and once you've
got that we can take this font and put
it into a gpo vm generative manifold and
find the mapping for each fonts and then
we can generate new fonts so new
locations in this manifold will then
give you a parameter vector and that
parameter uniquely defines the holes the
font so I'd start by talking about how
to find the dense glyph correspondences
and so the curb parameterization is very
straightforward we just take a sort of
parametric approach with 0 to 1 going
around a closed curve so you go as you
go from 0 to 1 you call there around the
curve and so if i take the first fund i
would choose some specific values of t
and i will sample it it a you sort of
uniformly son played at t all the way
around
so each T value then gives a point on
the outline so the p-values define the
polyline given the shape of the font
that makes sense and then for the second
front I do the same but with a different
set of T values and the sir and so on
with the empty fun to have a sense of T
values and then my idea is that when I
stack all these T values up that I put
the first one in correspondence so the
value of T in the first one corresponds
to the same point on the matching point
on the curve and so on all the way
around so by setting the values of this
parameter T i imply a correspondence
identical respondents across funds ok
that makes some form of sense and then I
had this very long key parameter so it's
about five hundred and twelve points or
something like that for each outline and
stack them all up and do an optimization
on energy optimization on that so had
what if that energy optimization looked
like well we start over get mad lift
that you're coming up with this sort of
tease yes I each each each glyph shape
is matched independently in fact you
sorry he's outline so the outer outline
is has one set of T values that match
and you know any malian could could be
treated as a different glyph of that ok
so for the curvature matching we're
trying to say we obviously we want
concavity and convexity is to be
preserved so we would have an
optimization that tries to put
corresponding points in areas of high
curvature and low curvature we have an
elasticity constraint that says you
shouldn't collapse all your points to a
single point they should be spread out
around the curve that and tries to
encourage a uniform parameterization we
also have a special font only bolt-on
make it work extra term which takes care
of normal matchings on sarah's because
there are some fonts where you can have
a seraph that stretches out massively
and so you have to sort of basically
override your normal elasticity
conspectus some regions you can let it
massively expand for this special
defontes and there's also that a monitor
citty constraint in the fact that each
of those t values effectively re
parameterization so the ordering of the
t values must be preserved otherwise you
jumble them up and that's the one that
makes it a little
tricky to optimize because there's now a
constrained optimization and so I put
all this through in case someone else
difficult question because it's an
audience where they might heart physical
question but I wasn't really going to go
through the energy terms to fight it a
safe that was the the understanding that
this this monitor citty constraint
action comes down to a linear
constraints so it's just a linearly
constrained optimization which makes it
a little bit more simple as well but the
normal matching term just sort of
Illustrated if you have a fun with a
really wide serif base and a very narrow
not sans font or something like that and
you use it without the normal term and
you look at the base fit there you
haven't quite oh sorry without the
normal time here you can see the sort of
correspondences of going up around the
side as a letter which is clearly not
right as on the far side the yellow and
the purple dots are the boss am NOT
allowed to expand outwards so it's a
little bit of a little bit of a hack but
vaguely principle hair and then we could
just optimize all of that we're not in
optimization so all of those equations
can be you can take great analytic
derivatives for them and we solve with
the Lindy constrained causing you some
methods are using lbf yes updates and if
you do that it doesn't quite work and
the reason it doesn't quite work is
because of the monitor citty constraint
and so we can see hopefully that so the
giant blue dot isn't quite in the same
places across all of them because bids
and totally not a convex problem at all
we've got stuck in a local minimum and
it's because as you move a t-value vent
you got to push all the Smarties or
whatever you want to call them in front
of you as you Reaper ammeter eyes and so
pushing that through a big barrier like
the combat the sort of sorry the
concavity at the bottom of the a is
really an expensive operation so you
can't do it depending on how you
initialize but the answer that is to do
a course to find the throat so if you
take the elliptical furrier components
of because it's a closed curve and you
go down to two elliptical Fourier
components then you basically have the
combination of two ellipses and so no
matter how different A's are at the end
of it they all look the same like this
because they all eventually collapse
down to just an ellipse so if you start
here and you might
here it's very easy to match with this
you have no strong concavities you can
just go straight through and then of
course you use that initialize the next
solution and so on and as you go in this
guide you into a local minimum and we
found this isn't usually enough to make
sure that you're always in the right
right sort of place and so if we oh yeah
basis for these well this is a peaceful
space or so just fished for this sort of
elliptic one for a coca is just just
just take the X if you if you because
you've got your t value going between
zero and one you've actually got a
pretty serious it just continues and
continues and continues so you just take
a separate for your transform for x + 4
y you still need to a self associated
two dimensional coordinates was designs
I was a tee a single a single T value
for a given fun because you fix see so
once you've done the octave once you've
them like give a certain shape you take
the transform and that gives you the fix
shape of the transform and then I just
reap Rama tries it by changing my t
values so a new T value then gives you a
certain position within that curve and
that gives you the X and white I can see
how this one emotional characterization
how you can do something about how do
you get to do to get the plot that you
just showed but these are curves in 2d
space what defines a 2d coordinates of
the smartest of the continuous thing so
I say I have a value of 0 points out on
this curve yeah so we waited for the
smarty so it's it's actually you know
you could do a Fourier transform where
there's not evenly spaced and like a
standard for a transform you have your
samples evenly spaced in time say and so
if i did a furrier transform where my
samples weren't evenly spaced in time
but we were spaced at t different t
values that would give me a different
fourier transform but it would be linked
by the same equation it's effectively
just a smoothies version if i took the
cut of and filtered it so i took they
took the curve and it still is always
parametrized by t is 0 to 1 and I just
chiltern then it collapses to be smooth
and then I do the Fourier transform in
that space once a smooth space which is
effectively like doing a thorough
transform the big space and then
throwing away those are the coefficients
are just keeping to and that gives you a
low yeah sorry maybe it's easier if I
draw I draw but this then guides you
into a bag by going all the way down
this chain and reinitializing you get
guided into the into the right local
minimum so now you can see the curvature
bit they're all are in correspondence
and then the rest of it is quite
straight forward so for the learning the
manifold we just use the GPL vm and guys
can process taking variable model so
this is chosen because it's powerful and
that has probabilistic and
nonlinearities in it so it's quite
useful for the able to know the mapping
and its generative so we basically start
with our high dimensional vector which
of these we now the high dimensional
vector on the t values once we've
optimized the T values you put the 2d
coordinates back in again so now when
we're creating the manifold you have
actual 2d polylines that we're putting
in and we just say that is made up for
some mapping from some low dimensional
space plus a bit of noise and then our
goal is to try and find low dimensional
vector and find the mapping that takes
us back into the high dimensional space
so we take our particular glyph we take
our polyline samples in 2d that give our
XY coordinates as a big vector and then
we do that for all our other glyphs and
a fond and then we stack all of those up
as a massive vector in comes to
something like thirty seven thousand
dimensional vector and then we say
clearly that 27,000 mental vector
generated by a 2d space and so we embed
that in some low dimensional manifold
and so these grey points are the points
that the original training data come
from so each of those grey dots is Times
New Roman or Arial or something like
that and then the heat map is the
probabilistic variants of predicting and
of course it's not actually 2d I've just
shown it as 2d so I can draw it on the
screen but we have ways of using sort of
Bayesian methods of ways of estimating
the actual dimension
t of the manifold which is in this case
came much closer to 44 was and it was a
bit of a kind of freak it a little bit
between four and five and things like
that but it's for and you can kind of
see that in the structure in that we've
taken it and kind of unwrapped it so you
get these sort of islands of holes where
you sort of forced it to learn to D in
this case and so roughly the predictive
variant is telling us for the responders
likely or unlikely it's a bit
counterintuitive but kids and regions
they're really unlikely far away from
data you just revert to the mean so that
actually gives you the average font so
it's not necessarily completely unlikely
but areas in the borderline like away
from the data you are extrapolating more
than your interpolating and that's sort
of dangerous the injury territory and
then generating a new font is really
simple so you can take our sample on
this point that gives us a new low
dimensional location we apply our
mapping to it to get a high dimensional
vector and then we can unravel the high
dimensional vector to get entire fun the
fact that's the average fun generative
about this process and so if we do that
as we move because it's a smooth mapping
as you move smoothly we can smoothie
interpolate between all the fonz and
every point that exists in this space is
a new font and the closer you get to a
great job because you get to one of your
training ones and the further way you
are the more you've created a new font
or something like that but this is quite
fun and it could it be addictive I've
got the tiger sideways for this work I'm
going to break everything by doing this
is that the right can you see that no we
go so as everyone has the opportunity
you could do this so efficiently you can
even do it in JavaScript so everyone has
the opportunity to have a fun if you
bored one day if you go to my website
say we do F or something like that you
can see the individual ones and you can
have a play this is quite fun and in no
way wasted a good four hours when we
first created oh sorry yeah sorry what
do you get blue so the blue if you go
right off the blue this is the
fridge this is the average case so you
aggress to the mean as you go very far
away so the border line is where let's
see if we can find something weird
somewhere around here maybe it's getting
a little bit weird in the border getting
a little bit of wobble over here maybe
although part of its also my lazy
javascript rendering algorithm which is
probably not very good um and we'll see
that there are some we can find let's
find something where it goes wrong
there's somewhere I did it wrong and I
think capital j goes wrong so we talked
about this there's some yes down here
you have this weird outline font so
there aren't normally font for the
massive bar all the way across and there
we need another extra serif term because
as you see going there it's not instead
of curbing here rather than perhaps a
more intuitive match would be just to
shrink the links at the bar and things
like that so it goes a bit wrong down
here but that doesn't stop it from being
okay up here you were using a an RBS
colonel so it's locally system it's more
ji Young's anticipating a question you
can see GE and we can also see somewhere
around here alternate G yes it's not my
first rodeo so we'll talk about that in
a second event like popular funds and oh
yeah it was popular fonts and you know
particular areas of density is giving
our you know our popular funston to be
you know indenter areas or they so yeah
I mean there's quite it's quite
interesting that that we haven't really
spoken to someone who's a super pro on
on phones but I mean the biggest divide
is obviously sans-serif and things like
that but there is a you can use it and
and one of the ways of like I I've
always hesitant
so we presented a siggraph and I my main
concern was that there would be someone
who spent their lifetime studying fonts
and they would go ice completely
ridiculous that you would do that and
and so obviously they're not is not
necessarily capturing all of the
artistry of the fun creation but one of
the reasons they thought I actually
spoke someone afterwards and they
thought it would be useful was
exploration of places where they might
wish to create a new fund because you
sort of you start seeing things like
Arial Helvetica and all these sort of
funds a rig can be quite well clustered
and actually the variations that they're
creating in there are pretty subtle and
so actually as a whole as a whole sea of
things that here that you might want to
go in and make sure but you aren't you
font into sorry yes so its cunning and
hinting that there have been works on on
those sort of thing and they can get
quite close to doing a lot of that baked
you automatically so I set aside step
again by saying I'm I treat them the
shapes and another's such as one
certainly hinting can be done a lot of
that can be done automatically these
days so we you can also embed all the
kerning information in you can because
it's a a big vector you can just
concatenate any information information
on the bottom of your vector and that
will also be generated at the same time
so if you want spacing and things like
that to go in you can put that on the
bottle go back there and you also get
numbers that match the data coming out
of the bottom of that and and so just as
just reiterate when we do it jointly I
didn't show you the joint funds but if
you do it jointly and every point is a
full font so you can obviously sample
from an entire typeface is from a single
point in there in the manifold and now
I've broken my a magic clicker thing or
indeed PowerPoint by doing this I hope
you go so a relation coupon and
something is a very fast process so
we've also shown there some individual
from manifold so you can just show that
and these to show you the quality
directly of the dense correspondences if
your correspondence is mess up you have
that thing let me show you with the J
going a bit wrong and there's just some
examples and so the rav we when we
started this project we looked a number
of different representations as well and
the curb parameterization with was
really the key and lots of people these
sort of embody previous works in shape
matching of things like this like
scientists as transformed obviously can
handle lots of bearing topology which is
good but they have no constraint about
you can't have very difficult to
constrain topology and so if you go from
say Times New Roman at home or something
like that with your signed distance
function then unless your curls always
unless the sort of centroid line of your
the skeleton line ago curb always lies
within the the shape you're going to
come into problems and even things like
more intelligent things like the garage
your mass transport which are trying to
sort of solves part of these problems
can't really cope because they don't
wear the masks gets moved around from
isn't very clear and it's very hard to
enforce any consistency in that this
sort of I think the secret of it working
is the fact that we represent as curves
and it's simple to sort of its intuitive
to have this elasticity constraint of
things in the curves and give the kid
natural parameterization at the shape
and it comes of course of the cost of
preserving topology and so yes obviously
things can go wrong and topology so we
are matching outlines so we cannot match
double-bogey to single bulgy because
there are three three lines two lines
but I would argue maybe I can sidestep
the other way we're now putting a fun
hat on and forgetting that their shapes
what does it mean to be halfway between
these two I think you could argue if you
really had a high level abstraction of
how you might draw gee you could say
well if I draw a double bogey and if I
stop a little bit early then maybe at
some point there is an interim result
that becomes a single Bochy but in
general and fonts they actually have
both of we can get around this problem
because even if one font has a standard
G has the other one embedded in it in
his Unicode set somewhere so we just use
the right one to match and the same is
true for a double sad day in a lower
octane and I would argue there isn't
really an interim case it would be a
valid font and we were sort of
interested in batted shapes oh yes and
so here's yeah so that was where
our failure managingness have you've got
the whole height of that being matched
obviously the cross way there and that's
not very intuitive cousin so locally
that corrupts the manifold but it
doesn't destroy the whole of the
manifold it just destroys our local
region okay so um inclusion here is that
we've sort of blended a framework for
building this generative model of
typefaces and it was it sort of backed
up hopefully what we thought was
intuitive with the font muscle I on a
low dimensional manifold so one of the
reasons it works so well is that the
rules the number of rules that use of
design well-behaved funds like these
fonts haven't used crazy funds ah sort
of relatively small set of rules and
therefore we can learn and capture those
directly from that from the curves
himself that happen to be explicit which
is good obviously we haven't shown any
crazy fonts that don't correspond to
this with magical actually fiddles and
things like that but again that sort of
facing the problem of what would it mean
to be halfway between what does it
really mean to be halfway between some
fun with sort of massive curls on the
end of it can you sort of half twirlers
adders at a valid thing so the next
level up in that requires quite a high
level of high knowledge about funds and
is also subjective about an individual
font designer would probably say halfway
between the two is something different
but we can capture these rules from
examples and this whole process with
entirely automatic we just put in we set
some parameters in the energy cost
function but they're quite robust and we
just put the fonts in at the top and get
the whole thing out of the bottom which
is quite nice and so if only we have
really begun to go into details about
what we might use as applications for
this but also the generic the framework
is reasonably generic if you throw off
sorceress matching turn you can use it
for matching other curves so for future
work we would like to look at the
topology limitations may be a skeletal
vase the model would be more suitable
and try and extend beyond these standard
fonts and there's also the option of in
the moment the manifold is completely
unstructured so it's a completely
unsupervised manifold if we put some
label training data for somebody we
labeled some information about some of
the fonts
we then put that in and use that to try
and give some structure to the manifold
that would be nice as well cool so oh
yes yeah a typical problem with using a
manifold representation is the
dimensions of the manifold don't mean
anything specific anymore yeah so many
different semantic concept que no es
gender but you started with a very clear
example where you wanted to make the
font see no bigger but you cannot do
this so that's what I mean if I won't
break like that's what I sort of meant
when I went unstructured in this part of
it and so the moving from on to vice
assembly to divide is putting that
structure back in and yes so there has a
whole another area of stuff that we are
working on which is just general
manifolds or how do you explore as an
artist say if you have a five
dimensional manifold of shape spaces of
valid shapes and I wish to create a new
shape and I saw i take my existing one I
wish to edit it and I'm basically going
around one of those Islands and that I
might have to move through an invalid
shape in order to achieve a valid shape
over here and I think that is a very
interesting I work in terms and will
well touching it again at the very able
to talk offline afterwards because if
you have any ideas because I'm very
interesting that the example the final
like the final piece here example this
final application makes use of exactly
that or we start to touch on that okay
so subspace appearance models this is
very old news this is probably going
back to before Janna couldn't started
doing a work on defense but substrate
models have worked very very well when
images are all aligned and had fixed
structure so I guess everyone is
familiar with something like I ghen
faces or Fisher phases where if I take a
stack of images that have been where
they're all in correspondence so all the
pixels corresponding sonos are in the
same place I can just stack them up take
off the mean and do some
easy a or do some factor analysis or Lda
or something like that to give me a set
of basis and our bases and then load
load them up and that gives me
parametric model that I can use to
describe faces and this works very well
but it doesn't work very well when
objects can't be aligned and so things
like Zippo have done very well when
there is a nice mapping but if it's not
as ice mapping you can't align these
data sets so your cat sitting down in
the front part of the cat walking
there's no easy warp that would exist so
building the substrate model in these
sort of situations it's very difficult
so there are situations where it can be
aligned and so active appearance models
and gain lots of popular active with
faces so if I have some key points and I
can bring these into alignment I can
find some dense warp and once I've
walked into alignment I can then build
my standard subspace model and
everything's fine again but this
requires some non-rigid defamation to
actually exist so it's not even that we
had to just find the wall the wall has
to exist and there are many situations
where you can see that such a warp
wouldn't exist so if you have varying
structure or occlusion self occlusion
visibility changes topology changes
different instances there will be no
nice smooth dense warp it exists to
align these data sets so my rather web
example those bunches of bananas so here
we can see that definitely each banana
shares an appearance subspace and the
bananas you could conceive would lie on
some substrate model of appearance but
there is no walk especially one that's
nice and smooth and unrealizable that
can transform three bananas onto one
button or the two bananas on two three
bananas again so we can't make any of
the assumptions that have been used to
Seoul for things like deformation fields
are not valid in these things and this
is not just this is not a rare case this
is I you often have to go the other way
you have to go out of your way to find
things that have nice deformation field
so standing cases not to have a nice
defamation field and so we're presenting
all the Seas a which is context
condition component analysis and so the
idea is to say well even though we can't
find a dense war correspondents does
exist
so the red dots corresponds the end of
the banana the blue dots correspond to
the front of banana and so if we go to
some higher dimensional space where we
put all the bananas in the same place
then we could build a subspace model
where they all lie on top of each other
and then unwrap that into a specific
example of an image and so this is a
sort of the key is that we can find our
correspondences implicitly by putting
vectors into some context space and I
haven't said anything yet about what the
context spaces but just some space that
brings everything into alignment does
explicit correspondences and therefore
the process of generating image would be
to take some form of structure map we
would then sample from this linear model
into structures in the context space and
then project that down back into the so
from this 5 by finding feature pixel
image where it should have come from in
the context space we get a context
vector you go into the context space and
you look up that value and you put it
back there and that pixel and so you can
generate a new image and so as I sort of
caveat the way we're doing this with our
inputs is that we don't just have the
images now we have them what we call a
part map so our input training data for
things like this is pigmented images of
horses or elephants or something like
that and at the moment hand labeled part
map that we say this is what we this is
a sort of this each part that
corresponds to one thing there's
obviously ways we can go about now
getting hold of these are the part maps
of things like shape also machines and
things like that could be generative
models of part maps so it's a bit of a
limitation at the moment that we need
these part maps but we have ways there
other people methods exists to try and
get hold of these sort of part maps and
there's also discriminative methods that
could be used to gain them so just as a
rough overview of related works
obviously far from exhaustive got loads
of people have looked at and subspace
models to loads of things that we work
on align subjects models especially
faces and there's also the active
appearance models and led their deck for
fear of spoke with multiple models and
and then there's some also been some
work on combining the parametric
models with non parametric models so
often subspace models you lose
high-frequency details by definition
because you're going to truncate your
eigen vectors and so there's a way of
using sort of image crossing or
something like that to go in and we
instigate your high frequency data from
a low frequency model and there's also
or interesting work is the the sort of
work on jointly estimating deformation
and appearance and again these have been
there's a really nice work on this but
these also assume that there is some
deformation field that can be applied
and so in the cases where there isn't a
deformation field this becomes a bit
more tricky so and just a verb this
would be a bit more concrete about it
the the model is basically looks right
very similar to a standard subspace
model you've got a mean plus some set of
basis we each with a factor loading age
and you've got some noise at the end of
it and then the trick is that unlike a
normal thing we've got this extra that
is extra vector C so if every single
picture we have this context vector
which tells us where in the context face
and then the theaters are our parameters
that would normally be linear parameters
and we've also haven't said anything
about the form of them but we've also
got these regression functions so these
regression functions take as an input
the context feature and the parameter
vector and give back a scalar and so if
we if we apply those we get back to a
normal subspace model but we see that
each mean vector and each basis loading
is now dependent on the context which
means it's specific to each image rather
than general so if I could sort of
illustrate that back the other way we
can see the normal PPC a probabilistic
PCA is just a special case of this model
so if I set all the context vectors to
be the pixel locations then my mapping
would not depend on the context it would
just be a mapping back to a simple
linear transformation and this model
would enrich collapse down to this our
standard PC a model just like that with
some noise or if we looked at that
graphically we could take our image and
our contact space here will be
two-dimensional and it would just be the
pixel coordinates the 2d pics of
coolness at each
so came from and then we would just
apply that grid so if we pretended for a
moment and we'll say more about how we
get this but if we pretend that in the
context face you have a continuous field
so these parameters to find the
continuous field then the context basis
tells you where to sample from so if it
was 2d pixel locations you just dump all
the 2d grid in your 2d context space and
that would then all give you the same
thing as normal probabilistic pca hope
that make some form of sense and now we
now to be a bit more concrete about how
we define these mapping functions so
attract ability because we can't store
an infinite continuous field in the
context space we assume that the context
space takes this form which is that it's
a linear product but are after some non
linear mapping of this there's a linear
product with the parameter vector after
some nonlinear function a is applied to
the context space so this is a good
choice because this linear projection
means that lots of standard regression
techniques can be expressed in this
fashion so you take some non linear
function of your contact space and then
you just do a dot product with some
linear basis vector and then you're
basically spent can be learnt in the
same way as a normal PCA so if we take
something like that we would say okay
any complex function EG any regression
process could be used and put in this
form of the most more common regression
processes things like basis functions
gaussian processes or something like
that in general we choose sparse linear
projections because it makes them
oppressors much more efficient because
you have a big context face you don't
the store lots of things so if we just
use k-nearest neighbors regression into
the space then we can only store we only
have to store a sparse data points in
the fields and then we keep separate
costs nice and low but in general
there's nothing to stop you from using
any regression function you wanted from
the space and so this gets rid of our
continuous fuel problems and now we
don't have a continuous feel so the the
general learning procedure now is that
we say okay well if we take a model like
that I could also Express it if I just
make it part image so I Izzy image
instance here so I make pie
I have a different move actor for each
image that's because I example from my
contact space and if they take a
different back for the bases bases space
from context and they have go back to my
standard model like this and then I
could just write that as a probabilistic
interpretation so we just have it's a
Gaussian with some noise term just
written on the end there and we put a
gas in prior on our factor loadings all
very standard normal PC a probabilistic
pc8 approach and then ideally we'd like
to maximize we do if we do maximum
likelihood of learning or something like
that we'd like to maximize this log but
we have this big integral to perform and
we can expand out into the hidden
variables and there's a number of
possibilities for things you can do and
we probably take the simplest which is
just a replace the integral with a
maximization and then you can just
alternately optimized for your hidden
variables and feel unknown parameters
and that just becomes a special case of
generalized DM with slightly more
involved update equations which will
like this we won't go into but it's just
very it's just a space of standard am
once you've applied the context space so
the final piece that I haven't told you
about is how you would get these
contexts vectors in the first place so
the way we do it is we we take our part
labels that was of this why we need the
part labels and we can volved em with
some filters so we take our part labels
on each part we can roll wit with the
filter bank and we get these contacts
vectors so there's a caveat that what
I'm showing here is quite hard to
visualize them i'm showing here is pca
having been applied to contact lenses to
go down which is why you don't see the
separate parts and but these each one of
those is effectively a dimensional if i
stacked each of those on top of each
other and then took it for a pixel that
will give me a vector and that vector
will be the context vector and you can
see it making sort of sense in the dead
bite I've got a leg like that and I
apply horizontal filter i introduce a
ranking across it so i start to get like
local coordinate systems in the part
labels which then form imply some form
of correspondence
and and so we can do this for a variety
of different shapes and we do different
power models for different types of
object but once we've got that we can
learn our components and so in the same
way that the old substrate model sumed
align factors we can also calculate our
means and our basis sort of deformations
among the principle basis but in our
case they're now dependent on a
particular contact space so each of
these horses has a different structure
map which gives it a different context
space and so once you've given the
contact space you can then calculate the
mean and you can calculate the
deformations from the mean in the
principal components but they are
different for each example because they
use different context vectors but they
show standard mapping so in terms of
their sort of consistent amongst one
another and so the way we can look at
that operation happening is if I expand
it out my son there so I start with my
mean and my basis loadings and
effectively I go in and I fill in my
context vectors for each of the spaces I
then do my k-nearest neighbors look up
into the parameter vector and that gives
me customized mean and the customer I
said the basis vectors for that
particular pose and then it's just a
linear combination of those pote of
those factors and go back to generate a
horse and so we've now will show sort of
how we could use this model on to
example tasks so in appearance transfer
we would fix the factor loadings for
particular horse and then apply those
factor loadings to a context vector of
another pose that would transfer so the
factor loadings encode fully the
appearance and the context vectors
encode the shape of the horse and the
same thing can also be done with
structured in painting if we cut away
part of the part of the horse and we
just learn the factor loadings on the
bit that we observe and then use a
structure map for another observe bit we
can then transfer those factor loadings
on to the unobserved context vectors and
so in all of these cases we are using
the part labels to get the context so we
had
access that even in our we have a test
in a training set in terms of learning
the parameters of the model but for
every example in tests or training set
we always need that their part labels to
get the contact space so this is what it
might look back if we fix the factor
loadings I think there's ten factors or
something like that then the first line
is the original data the second line is
a reconstruction under ten factors so it
is cap the factors are capturing quite a
lot of the appearance model and as we
expect you lose high frequency content
but the basic low-frequency captures
being captured and then we've picked our
factor loadings on to the rest of the
model and hopefully all the horses have
black tails or black rear legs and that
next going through and we can do it with
slightly more extreme pose changes and
so even from a weird cow horse or
something in the third line you can
transfer the appearance I haven't said
how we do color color is just we have
three factors for RGB and we do estimate
a rotation translation to try and align
the color spaces as we go but it
transpires the Wiesmann horse dataset is
full of really bizarre horses so the
weird blueness isn't necessarily us
that's the actual original training data
has for some reason that luminous blue
holes in it or something like that if
you want to get really tricky we can go
to cats and so this is quite fun because
we only see the head of the cat and so
we fix the factor loadings just for the
head and then transfer them across the
rest of the cat and so even though we've
never said a factor loading for any
other body or something like that we do
know that the rest of the cap should
also be black and so we can write black
cats by clicking the facts alone yes all
images will training in tests have party
labels and near used for this process
yes they use that gets the contact space
so we need a context face for each of
them and so that's oh so maybe that's
deceptive actually we should probably so
the purple isn't really purple the
purple is the unknown region but I do
have the part labels for those for those
unknown regions but of course and I can
do structured in painting in the same
fashion yep so in some tight spot
and some quite challenging ones with
with cats but if now we've been
struggling a bit actually if anyone has
any comments afterwards we've been
struggling a bit on ways to really
identify how well we're doing because
it's a very difficult problem to
actually judge how well you're doing
when you're doing a parent is
transferring things like that because
you don't have a data set of what the
horse would look like in that I'll
oppose so maybe we need to go and make
that data set of or some different poses
and so our limitations are as with all
then we lose these high-frequency
details but we could come up with image
quilting or something to come back there
is this problem now if this context
generation is inconvenient so we use a
fixed function for the context back
there there's no reason to suggest that
that was the optimal one and there's no
reasons Jess it's not in any way over
complete maybe using far too many
filters so there's obviously lots of
room for learning we can learn the
context face directly why doesn't we
don't necessarily have to go buy a part
map that was as for convenience for us
anything else and so the final this
little example I was going to show is
this um application of sketch synthesis
so if you don't like fonts you can still
build nice manifolds and match things
but you could build them for something
like elephants which is much more fun
say than fonts and if you really don't
like elephants everyone loved cats if
the internet is full of cats so you can
also build some of these models for cats
and you might notice some of these red
shapes wandering around the manifold and
that's because in this particular
application we're teaching the draw so
one of the ways you'll talk to draw is
with these masses so ellipses are you
sort of sketch out the masses of an
object give you the right pose the fig
suppose and get the proportions correct
and once you've got your masses correct
you go in and fill in the contours and
all the high details and so in this
particular framework our goal was to say
okay so you have a tablet and you're
going to draw your you can sketch draw
your masses and it's going to give you
feedback in the forms of these color
ellipses as to where you might want to
put those masses and it lets you move
them around as you move around these
shadows will change and just where you
might want to draw and then once you've
done that it will also
help you with the outlines it will
suggest where you might want to draw
your outlines and once you fix your
contours and your masses you can pick
some haven't really done very well on
that part we just gave a parent or
something like that you pick a
particular palette or something like
that and then you go and you generate I
photorealistic course it's probably too
dark to see oops um but the idea being
that all of this process all of the data
in this process is learned from actual
images so it's not encoded and unlike
things like a shadow draw we are
providing we don't just sort of return
you some nearest neighbor images to
suggest what you're doing we're actually
interpolating in the space and coming up
this suggestion so the idea is it's sort
of customizable clipart if you have in
your mind what you want to create we can
make you the horse in that pose and so
again our training data is similar we we
use our part labels again and then from
those part labels we determine our
masses and then we also take the
outlines of the silhouette and we find
some correspondence points just to
normalize the outline and then those two
are the inputs that we learn in our
manifold put into some manifold so that
goes into the manifold then you can
build your your manifold the shape and
now you can do things like if I start
querying where the ellipses are if I fix
the ellipses I can go into the manifold
and this I guess is maybe asking your
question Theo so you can start by doing
an optimization you start with load of C
points around the whole space and do an
optimization of trying to locally find
parts that look more closely it's your
ellipses and this gives you a load of
modes I have very similar ellipses on
the or valid valid lips configurations
that we have on the manifold and the
corresponding contours and so once
you've done this you can get some
feedback and then you can and so for
this example mode you see we've always
got an outline is in the right pose and
we also have some neighboring images
that we get from that as a query and so
those we can use to learn models to
generate local good when we come to the
texture synthesis part and so the way we
do the final thing is actually image
melding so this is before we did the
appearance model and so we actually take
some features from
ellipses and the contour and use them to
guide Pat's matching so we take
neighboring images that we know in
roughly the similar poses and we warp
them and then blend them with different
ways and walk them together by combining
two horses together in the right pose
cook and so by now I'm fed up of looking
at horses and cats and elephants are we
added pigeons in as an extra bonus
option which are also really annoying to
look at largely defensive and so in
conclusion this this manifold can
provide intelligent feedback is not just
showing we're not just showing the
nearest neighbor results we're actually
creating new ellipse configurations and
and contours that we never seen before
in order to provide this feedback um and
so we can therefore generate novel poses
but proposes that are validated by the
data so we don't again we're not we're
not doing procedural modeling we don't
have to write down the rules all of
these rules are learnt from data sets
and at the moment the limitation this
one is the appearance model only
supports nearest neighbors so we can't
if you if you don't have any training
data locally of horses in that pose we
can't walk them and obviously we can
we're looking at using our previous
stuff to try and overcome some of those
limitations and we still have this
problem of labeling a training data set
purpose again going to be dealt with
hopefully in the same way that a shape
balls watching or something can do the
generative model part of that as well so
for the future in conclusion so it'd be
nice to have all of these has always
been a stopgap at some point so we'd
like to have end-to-end learning say for
the context space and everything like
that so you go straight from the also
they went to the final appearance model
learning learning how to generate the
context base in between that would be
nice and we'd like to combine properly
all these generative models of shaking
the parents instead of having interim
stages and and also I mean ultimately if
we're doing graphics applications if you
want best possible image quality so we
need to look at that as well and as also
all of this has been to D but lots of it
an equally applying in 3d and I'll talk
just a bit i'll talk about this for you
guys individually Darren asked me to put
this in his PR for bars because we've
got this new grant and the epsrc on
doing we've got a lot of money for
motion capture so five million we've got
a whole bike on system
for gate cameras and things like that
looking at motion capture with people in
health and sports as well as a VFX and
augmented reality in VR and things like
that and we're keen to lab right with
anyone who's interested in getting lots
of data we're trying to make a system
that can go outside as well to get some
outside and we've got lots of students
who are going to be coming up in
September and working on it cool and
just to thank the Daniel was V PhD
student at UCL who is working on this
and the context correlation analysis is
work with Simon and yan and the final
the sketch based one dango when's the
adobe will see a guy who came around
doing the sketching and lots of this was
started with my former boss at UCL yang
counts is now in video research but
thank you very much indeed you showed
that these context spaces for the horses
for example where many only define and
this makes a lot of sense right bananas
have a good intuition for that but in
there may be many applications where you
would be willing to make this annotation
during training time and then giving the
mobile mobile image you want to do is
fully automatic and yeah in the example
you shot of the horses how and how much
does it deteriorate visually if you for
example corrupt the label maps to
contact me on the contact from
regressing the context maps just for you
so we haven't done those experiments but
well we haven't got them in the paper
yet but the thing we are working on next
is is doing effectively that but if you
say something like the shape Boltzmann
machine we train that so we use labels
of the training time to train that and
then you condition that say on an input
silhouette and so you're you have to
specify something if you want to
generate so either bits purely tentative
and I just click a button let's say I
want a new horse in which case you can
sample whatever you want or you have to
specify something somehow so either part
of a silhouette or or a full silhouette
and then you would condition the shape
Boltzmann machine the part shake bolts
machine on that silhouette that would
effectively give you your contact space
or you could learn is the contact face
rub in the park April's and so that's
erm we've been talking to Ali a bit
about doing this
kind of the next the next step and then
I wouldn't yeah I'm trying to find the
data to be it was there to answer that
question but you're quite right I could
I could just corrupt the partner of it
have a go we haven't really tried
compute i doing that month task so all
use one of the discriminative because
those are those apart just coming to
classify us apart labels yes so we could
try one of those and see i see how that
came very cool well let's think Neil
again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>