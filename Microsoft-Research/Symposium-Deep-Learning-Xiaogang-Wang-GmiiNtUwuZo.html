<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning - Xiaogang Wang | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning - Xiaogang Wang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning - Xiaogang Wang</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GmiiNtUwuZo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay so we are very delighted to
introduce satin one so shebang is a
professor of electronic engineering in
chinese university of hong kong his
group has worked on deep learning and
computer vision has and has done many
great works in particular his group
achieved near human performance in base
recognition such as over ninety-nine
percent in label faces in the wild data
set and also his team has achieved pub
entries in large-scale object detection
challenges in recent years so today
xiaoguang will talk about deeply learned
based representation ok to thank you i'm
going to talk about the feature
presentation for face recognition so in
the past two years a tip learning has a
boost the performance of his recognition
substantially so on the well-known face
recognition benchmark lfw and the fifth
verification accuracy has been improved
from ninety nineteen sixty percent were
almost perfect and even surprising the
human performance on this benchmark so
you need to talk I'm going to briefly
talk about how to learn the fees
representation from the classification
and multiple reconstruction task and
given the high performance network I'm
going to present some empirical study on
the properties of the neural responses
and the making use of such properties
which show that we can make the reduce
the size of the networkers a substance
substantially while keeping the
recognition performance it also have
some other interesting applications so
currently at the most a comedy way is to
learn the visual representation so
through this identification task
basically give an input training image
goes through the ComNet you to classify
as a value of the large number of recent
entity class and so the in the top layer
the neurons in the top layer the other
feature representation we want to learn
so the capture to reach interpersonal of
its variations because they need to
classify a large number of theses and
that they are discriminative also can be
well generalized to new identity outside
training data so also on top of it we
also added a verification signal so
you'd be busy if you have two images
from the same person will require that
they are learned a feature
representation to be similar so this
verification and identification signal
they are jointly I to the multiple
layers to learn the feature
representation we can also learn the
future Fitz representations through
reconstructing multi-view representation
we know that infinite recognition the
view we're reaching is a major factor
affecting the performance so we in this
network give an input image in the
arbitrary view we want to reconstruct
all the viewpoints of the same person
here I'll show you the examples these
are new construction result and the DC
of the conscious and the trini intensity
that they have no overlap on the other
identity so in the network we are the
identity and view representation they
are represented by different sets of
neurons so you can separate identity
features and the viewpoint features also
the viewpoint has a continuous
representation so this is our network
structures x and y they are input and
output phase images input different
viewpoints and that is of H hid they are
the noodles encoding the identity
information of other input image x it
has removed the viewpoint information
from X they are the determinants season
neurons and that is H hv they are the
new random numerous encoding the pupil
and information of the output image the
sample from uniform priors and this HR
these are neurons encoding the features
of the output image why so either
combined posted the identity information
and the blue pony information actually
these you can see this network is a
combination of deterministic neurons
also random urine
and the lisa hv at least v2 these are
the identity features they are useful
for this face recognition and this
viewpoint label can be inferred from
output image as well as from these
random neurons encoding these viewpoints
so when you can use em to update the
proper listing model on the network it
creates bound to the forward and the
backward of propagations so at the east
ab we infer the values of the random
neurons which includes the viewpoint
information and I'm slab we use to
update the parameters of the network and
because we have a continuous view
representation and you can we can
interpolate and predict the images under
the viewpoint observe in the training
data and units example our chinny data
only have 0 degree 30 degree and the 460
degrees in a we want to reconstruct the
image fits image under 15 degree and the
45-degree neopoints and a desert the
construction result and this as a ground
truth and in P will improve the image
are under the 15 degree and the 45
degree we want to reconstruct the front
of you you can see that even we observe
some new wheel points because we can
interpolate the images they can be
reconstructed well so actually this idea
can be also generalized to other factors
besides besides viewpoints and such as
ages expressions Lighting's et cetera
actually you can also jointly consider
multiple factors here I give you example
given an arbitrary fits image as input
we can reconstruct different combination
of the poses and the inspirations and
the in this example we constructed the
first image and the different
combinations or Lighting's and
expressions and given three some are
high performance in your network and
some people think leaves the tip
learning
few years simply use a large nanometers
of filter data so we are interesting
studies of properties of the response of
the neurons and actually this is a
property that are naturally owned up to
large skill training with we don't
either is pleased is pretty added some
drag racing organization to the to the
model here give an input image and we
look at the neural response in a top
hidden layer and then you can see that
some neuro I responded and some have no
response it's not surprising we have
this a sparse representation because we
use rectified linear units as activation
function if you if you add some
occlusion and change the viewpoint of
the same person we observe that this is
a magnet here that could be valid can
change it to some extent but the
activation pattern could be is a
relatively simple stable and if you
change the identity of the person we
found out the activation pattern a 01
patent you're going to be changed
substantially so Lisa inspire us we just
use as a barren area code from this ad
with activation pattern for face
recognition and as a result is a pretty
promising with Duke even you use this
binary code which you can get very high
reckon your face recognition performance
on over ninety-nine percent so Lisa
implies that the active activation
pattern maybe even more important than
that than is magnitude also it has the
important it's important for
applications because if you use these
binary padding for recognition you're
going to save a lot of storage and also
the computation time so if you look at a
inputted has image and we observe that
about a half of these neurons are
responded and the other has of 54 have
no response so if we want to you want to
compare the Hamming distance of the
activation pattern from to face images
and the Lisa moderators positive
response i can give you the maximum
distance between these two images on the
contrary if you have the three
the representation which is which is a
highly sparse most of the neurons has
zero response and then their distance
will be small you're going to waste a
lot of apiece and if you look at a
particular neuron we observe that on the
test the image and about a half of the
image you have responses and the other
half have no response so it means that
it can maximize as a discriminative
power Massa Massa at the entropy of this
neuron describing desert has the images
said but if we look at a particular
person for example in the RF w george
bush has 500 images and you can find
some neurons which always always respond
to george bush and you have some other
neurons which also has zero response to
push so our training data and as a RF w
have no overlap on the identity of the
persons and the similar thing also
happened to the attributes you can you
can find some general the obvious
response to the female my offices have
no response to a female faces so we
found out the listener or they have a
strong selectiveness on the identities
and also the attributes and here we show
you some example listen this neuron
always have the response to push and
listener on of your hand no response and
we'll show you more examples on more
people and it's also happened to the
identity and these neurons always
responds to malfeasance or it's a no
respond to female vc there on the
country and these are the risks related
attributes for example listener always
respond to our very people had no
respond to other attributes relate to
the race so this means that if you want
to classify a single person from others
or recognize a single attributes you
probably can find a particular neuron
which can have a very high recognition
accuracy even with a single euro for
and on the contrary if you compare with
the high dimensional RPP you'll find the
path of a single feature from our PP for
recognition the dragon easy reader is
all the only 90 is only sixty or seventy
percent of quite low now we can also
look at the other neural responses here
I saw the list neurons according their
average response according to to that
particular person from large to small
and then we can keep the other and look
at their average response for all the
other images and we can see that it's a
kind of a pretty uniform distribution on
the other remaining images and if you
look at their recognition accuracy on
single with a single neuron and then we
found out of course of these neurons
they have to the recognition capability
on bush because they always respond to
bush and at least this neuron they also
how good is a recognition accuracy
because they always had no response to
Bush and in the middle we found some
unity to have a lot of uncertainties
right so by the in comparison and for
high-dimensional BP if some feature have
a high response to a particular push a
particular person he also has a higher
expand to other images they are not good
for recognition and here we also can
visualize as a neuron so for each mural
we divided the images into three groups
high middle and low response and
calculate the average e image in each
group and then we can see that each
neuron Cal clearly a semantic meaning
for disabilities one represented the
gender age etc so because of such
McCleary subshell properties we can
actually simplify the spotify the
network structure as i mentioned that it
because they have selecting these are
attributes if you want to drag
particular attributes you only need a
very small number for neurons and we can
remove a lot of four edges and this is
also happen to we can use blow the
correlation between the neurons and in
different layers right so if you want to
predict a neuron at a higher layer you
only need to very few number of neurons
or from the lower layer and so you can
remove many these kind of connections
and so we propose to alternatively
optimizes learning ways and also the
structures okay your trim you to dance
network and the Spotify the Fertile
layer and between the network and then
specified as a second layer and it and
so on okay yeah I just running all the
time I just to give you the final result
and that is why is that you start with
the dance dance or network and the least
is a spatula network it only takes 10 9
days of the amount of parameters that
even wake up even higher recognition
performance I'm going to skip all the
remaining parts so in summary I'm
introduce how to learn surf is a
representation and also talk about that
they are some empirical study of the
properties and also make use of such a
properties we can make the network is
smaller okay thank you
so you know we have some time for
questions so if you have any questions
can you come forward in front the mic
have you tried this on larger data sets
where the pruning might not might hurt
because you're less under fitting the
you a lot of wii u need the property of
the neurons or the Holy the pruning is
probably helpful because you're working
in a small data set right we do or don't
have a special which is a regular to
putting up putting layers on the pruning
so removing edges oh ok oh yeah not
about the producer so far this is a
training opportunity that we do we have
war 4400 result in the changing images
is a junior the data it's a pretty large
yeah so do you have any idea how to so
what are the limitations of the current
CNN that you're using and how what do
you think is going to be the frontier
and in the next you know 23 years what
you think you're going to work on and to
improve okay yeah I'm quite interesting
how to make the network is smaller so it
is really know that it's your particular
office recognition we have a very good
recognition performance but if you want
to apply this to some mobile phone
camera through the front end and then we
you want to make unity to make it
smaller and also we find this kind of
trying to learning the ways and also the
structures it's a cool to be quite a
faculty and so it doesn't one of them so
so in some of the early deep ide work
you guys were using key points keep
comment on the importance of key points
and are they required not required what
is your most recent works of the kittens
future so we use in the face recognition
with you because we use multiple models
so basically we crop multiple regions is
for you to return the cattle feature and
then
to the production to the average and
with you you will need to crop a
multiple regions that then we rely on
the key points kind of handle is mr.
misalignment but if you we use only use
a single say single model single region
for the face recognition we only have
two very simple geometric normalization
brutale 3k use key ones hi I'm this is
really good work can I ask about a
little bit about pruning since we also
experimented with ZN our cm and i'm
curious on face recognition tasks how
many percent of the parameters can be
pruned and what is the heritage a more
more than eighty percent and still get a
unit higher performance and what is the
heuristic you use for pruning so
basically you start a tuna original
Network and you cause the ways and you
know the correlation between different
neurons and then you'd remove some
connections which has a weaker connect
weaker correlation the first layer and
then you reach in a network and then you
specify the second layer and so are so
tool is iteratively so we are specifying
a sponsor find the first layer the rest
of players are fixed to be that's likely
right we will be fixated and then we jus
chilln Edward the second day so in the
first part of the talk you had
stochastic latent variables representing
pose and and viewpoint whatever and in a
user nghiem procedure and then you went
on to just have a fully deterministic
feed-forward Network as usual and train
it with STD when that second approach
seemed to discover Lane attributes could
also discover latent viewpoints in which
case do you need the hidden variable
method what are the pros and cons are
those so you're so one for possibly
little held is a kind of a random
neurons because we need to represent
that is we want the information
continues
way so we can really we have this a
property model only such a onyx Academy
order that I'm sorry what's a second
question well so the second part of the
talk you're discovering Layton
attributes like gender and so on right
say jen is about example let's say race
which you could think of as a continuum
viewpoint is also a continuum does it
discover the viewing angle of the face
organically even though it wasn't
labeled no you did so it's actually the
second part if cowards are the
properties we are based on this we
didn't use we did we only have the
deterministic in your sweetie we don't
have is it was not a bass sound it's a
model you fistrick fistrick construction
yeah okay so we have one more yeah last
question oh you have any thoughts on
using this for anomaly detection like
for example if you want to detect a mole
on a face be didn't have any already had
a very small amount of mole training
data or even so sorry can you repeat
okay oh yeah sorry um have you do you
have any thoughts about using this for
anomaly detection for example detecting
moles on the face uh I haven't thought
about it right no against this kind of
example where everywhere in the in the
training data and I think the for the
car the representation property is going
to be hard is it because it to learn
from the normal normal fuses and what he
was saying kind of some normal regions
right cool thank you okay thank you les
thanks how far we get okay
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>