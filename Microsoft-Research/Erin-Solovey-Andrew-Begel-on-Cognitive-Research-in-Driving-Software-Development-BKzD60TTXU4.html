<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Erin Solovey, Andrew Begel on Cognitive Research in Driving, Software Development | Coder Coacher - Coaching Coders</title><meta content="Erin Solovey, Andrew Begel on Cognitive Research in Driving, Software Development - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Erin Solovey, Andrew Begel on Cognitive Research in Driving, Software Development</b></h2><h5 class="post__date">2014-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BKzD60TTXU4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">my next guest assistant professor of
computer science Aaron solavei of Drexel
University and senior researcher Andrew
bago of microsoft research using some
amazing tools with the goal of improving
our performance on various tasks just
remember Aaron and Andrew aren't really
mind reader's even though they've got
these cool devices here so if you have
questions we got to do it the hard way
the old-fashioned way type it into the
chat window you've got the tool right
there in your viewer do that Aaron
Andrew thanks for being here thank you
we are planning research and focus your
segment has a title so no pressure there
all right so I'm told of course that
you're working on complementary
approaches for using psych psychological
physiological data to predict cognitive
workloads and Aaron I want to start with
you and your work I understand you're
studying the impact of cognitive
workload on people doing commonplace but
potentially dangerous activity driving
explain why you chose driving all right
yeah there's lots of reasons so as you
know driving the dynamic task that we do
it involves visual manual cognitive load
that you have so you have to determine
where you're going which is a strategic
goal you have to monitor the road and
also your vehicle and that's more
information processing and then there's
the physical act of actually
manipulating the steering wheel and
doing the physical driving and so
there's a lot going on and then also
we've been seeing this there were I
think 387 thousand injuries from
distracted driving in 2011 and over
3,000 people were killed and a lot of
this comes from the second other tasks
that people are doing while they're
driving so you have the driving task
plus a secondary task so what I've been
trying to do is study the workload that
is induced by these secondary tasks I
think it's important to understand that
driving is changing a lot we have GPS
system we have browsers even in cars and
also yep so this is a picture of it and
I yeah well that's in a simulator yep
and so plus people are bringing their
technology into the car which adds extra
workload and then at the same time cars
are becoming more advanced we have more
automation cars and this can change the
role of the human in the view
go from the manual control to someone
supervising and so understanding the
workload and how that's changing as cars
evolve is important Wow okay so you're
you're trying to work to understand when
I drivers workload is either overloaded
or under loaded and you're using
something called what f nears to study
brain activity yep so f'nor is one of
the tools I've been using it's a brain
sensing tool it's been used more
recently and it measures blood flow and
blood oxygenation which is similar to
what an fMRI measures but it's portable
non-invasive pretty easy to use and so
we can get this information about your
cognitive state while you're driving and
see you brought a little toy with yes I
must ask you to fashion show us what it
does what's its role with F Nia okay
I'll put it on for a moment well all the
kids these holidays yeah so this is
actually a device this isn't what i've
been using more recently in studies but
this is one that we put together for
earlier studies and really the the way
that it works is going take it off young
lady so yeah so the way it works is in
these and here the reason we have this
is there's little holes to put light
sources and light detectors in here and
they hold them in place on your forehead
and the light goes into your forehead
and it your bone and tissue is
transparent to light at these
near-infrared wavelengths and it's the
oxygen in your blood that actually
absorbs the light and so we have the
light sources going in and then there's
detectors that are embedded into there
that can detect how much comes out and
from that we can calculate how much
oxygenated blood is in that part of the
brain which is an indicator brain
activity Wow ok so this headbands
reading the level of brain activity and
the person who's wearing it is this the
only data input you consider are there
others no so this is one of the things
i've been using i have also done work
with the EEG brain sensing but more
recently I've been also looking at
physiological measures so body sensors
looking at heart rate skin conductance
level and then in addition I also look
at the task the task that you're doing
and any context information we can get
from the task you know if you're using a
computer while we're sensing you we can
also see what's going on the computer if
you're driving
might be able to use the sensors in the
car and use all of that to get a better
and figure out your cognitive state
while you're driving or doing your task
and talk about your actual process or is
it all simulators as their people
actually on the road yes so I have done
both so with brains so far with the
brain sensing I've done it in a
simulator so you saw the picture earlier
which was someone wearing f'nor's in a
brain and a car simulator which yep and
so we had a full car and then there's a
screen in front of you but all of the
steering wheel there's a pedal to
accelerate its all active and so you can
use that and then I with the body
sensors the heart rate skin conductance
level we've done Studies on the road in
actual car on the highway where we gave
few people drove and I me gave them a
secondary task to do we did a pretty
large study with a hundred people over a
hundred people on the road and trying to
determine see if we could use these body
sensors to determine their workload
while driving Wow okay so you're getting
all this data and what do you do with it
I assume this app or machine learning
comes in yes so exactly we what we're
trying what we'd like to ultimately be
able to do is use these sensors to
automatically determine your current
state and so to do that one of the tools
we uses machine learning but in order to
do that we need to build up big data
sets with the brain and physiological
data that's labeled so we need labeled
data and so a lot of my studies have
been building these data sets where we
like I said we had a hundred people on
the road and then we gave them a task
that has an 01 level of workload so we
use tasks that have been studied in
psychology for years and those have
known level of elevated workload and
then we'll also have them just driving
and then we can build these data sets
that say this is what your brain and
body sensors look like when you're
driving it alone and this is what it
looks like when you're doing a secondary
task and then that can be used to build
a classifier that can when we don't know
your current workload we can use that
data to classify it this is fast I'd
love to put this on my head to see ya
what it is it thinking about no not now
those moments that we've all had we're
all of a sudden you discover yourself on
the road
many blocks or even miles down the
freeway from where you were when you
last checked out in your brainy where am
i how did I i guess this part of my
brain kept driving and this part of my
brain was on something this fascinating
stuff and Andrew I want to bring you
into the conversation I understand
you're using similar devices to measure
what psychological physiological
activity but instead of setting drivers
you're looking at computer programmers
so what is the goal of your research so
my goal is to look at when computer
programmers get stuck or confused with
the software they're working on that
they're actually writing like for
example at Microsoft we build a lot of
software and we have about 30,000
engineers that work on that software and
sometimes rarely bugs make it into the
software that we ship and those bugs
have to get fixed and that's expensive
so we with my research what I'm looking
for is a way to detect when the
programmer is about to cause a bug and
stop them before that bug can enter the
code mom and what my theory is basically
that I can start using some of these
devices and actually you can see some of
them here yeah I got to give you figure
out like whether the programmer is
confused or frustrated with what they're
doing maybe that's not the time that
they should be actually typing code
maybe they should go ask a question of
somebody else okay so are you actually
measuring the same kind of physiological
mental responses so I'm using a slightly
different set of sensors so the one on
my wrist here this is a shimmer 3gs r
plus sensor which is basically measuring
house how much sweat I'm putting out on
my skin which is a measure of arousal
how much I'm paying attention to what
I'm doing right so if it's a low signal
I'm kind of probably just came back from
lunch and not really paying attention
maybe that's not a good time to be
coding we also have this sensor this is
an eco Mimi set of cat ears over here on
the front is an EEG sensor and the EEG
sensor is placed against the forehead
where it's basically measuring he
basically one part of the prefrontal
cortex on the left and then there's a
little ground that goes in her ear and
nobody'll even know you're wearing it
and then yours kind of like like that it
worth to show basically like the ears if
I'm really like paying attention the
years will pop up and then if I'm super
calm like the kind of relax and the ears
go down wow this is built for the
japanese market
so it's I could certainly see the social
value of yeah hey that person like you
trying to use the ones without the ears
so we can like plop ears off actually
you could buy new years for it I like to
be fashion accessory business which is
kind of cool so we've got those kind of
eight years and then what we also do
we've also been using eye-tracking so
this is where the computer itself is
projecting infrared light at your eyes
and trying to figure out where your
pupil is and then it knows how far you
are from the screen and using geometry
you can figure out what exactly are you
looking at on the monitor Wow so when
you're programming we want to start and
you get confused we want to find out oh
it was that class or that method of
there that got you confused or that was
the trigger for Ewing mom used I know we
actually have some video of all of this
in action we're gonna roll that video we
take a look here great so what are we
seeing here this is my eye tracking this
is a visual studio of programming
environment the little red ball that
you're following is where the subjects
is actually looking on the screen as
they look at that code yeah we've asked
them to just read the code and there's a
question at the bottom of the code what
it draws two rectangles and they're
asked if these two rectangles overlap
and if and now you can see this huge red
thought that means the person stared at
that one spot on the screen Wow because
that was particularly confusing or
particularly difficult for that person
he's actually doing it multiple times
before he starts reading the rest of the
code you can see a picture in picture of
the subject in the bottom of the screen
there and this particular thing will
actually was kind of difficult just
because it was sort of spatial relations
for well most people is just actually
kind of difficult so you're using
machine learning algorithms draw
conclusions from these from all the data
you're getting it up explain the process
of machine learning that you're
employing so we're trying to build a
bunch of different classifiers to tell
is the person experiencing difficulty
did they feel that what they're doing is
tough for them so we had a whole lot of
people come in about 15 people come in
and do eight different tasks each person
took about an hour and a half to do it
while we were measuring their EEG
watching their eyes also measuring this
on my the GSR device on my hand to
measure how attentive they are and then
we take all those signals into our
machine learning environment and what we
were doing is trying to predict
three things one was if we watch 14
people do this task and then we take the
last person can we predict as the person
is working is that task difficult for
that person doesn't work that well what
works better is if we say well we
watched everybody else do this task if
we then watch a new person do this task
can we figure out what's going on and
then in fact we do really well in that
kind of environment and so we're trying
different combinations of that to get a
classifier that will actually run as the
programmer is working we're in real life
you don't know what the task is like the
person is just supposed to be working on
a bug or writing a new feature for their
program and there's no beginning there's
no ending it's just kind of like it's
getting hard it's getting easy but when
it does get more difficult that's the
point where we want to try to intervene
in the programming environment and do
something to either make them pay more
attention or maybe to get them to stop
or slow down or maybe ask a question of
somebody else so you're studying you
know programmers you're looking at
drivers if we've stuck this on somebody
driving was trying to write code with
this is on fire well we're pretty much
they would get stopped by the place we
have a big online audience joining us
today and one of them just wrote into
your and says what type of secondary
tasks did you analyze you know they want
to know talking changing my music
texting yeah right question yeah it's a
good question um so we've been using
generally a lot of working memory tasks
is we're thinking about someone who's
driving and maybe trying to weather it
that's involved in having a conversation
that's also if you're trying to remember
the direction somewhere you have to
store something working memory so
there's a a task called the end back
which is used a lot in research where
you have to so this is a proxy for real
task so I don't imagine anyone to
actually do this in the car but this you
can set it up so that you hear a series
of numbers and you have to respond with
the number that you heard to previously
from the one that you just hurt so
you're listening to the information and
storing it in your head and then so as
you hear these numbers when you hear you
have to remember what you heard two back
there and then update it and so this can
be you this has been used in lots and
lots of studies and this is really just
to calibrate the system and say this is
what
working memory task would look like and
it's not realistic for something someone
would do but we can then train a
classifier using that that can then look
at other tasks that you're doing and see
if it looks similar to when you're doing
that elevated cognitive task or not Wow
um yeah this is while some fascinating
stuff thank you both unfortunately route
of time if I had that on the ears would
ago at a time for the segment thank you
both very much okay thanks for stopping
by explaining a remarkable advances in
this technology it's really fascinating
stuff thank you both so much all right
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>