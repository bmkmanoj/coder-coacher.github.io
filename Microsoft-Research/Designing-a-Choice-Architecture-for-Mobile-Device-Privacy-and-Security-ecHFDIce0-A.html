<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Designing a Choice Architecture for Mobile Device Privacy and Security | Coder Coacher - Coaching Coders</title><meta content="Designing a Choice Architecture for Mobile Device Privacy and Security - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Designing a Choice Architecture for Mobile Device Privacy and Security</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ecHFDIce0-A" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning everyone it's my great
pleasure to introduce ergy eco men and
many of you already know him and have
collaborated with him Sergey is postdoc
at Berkeley with David Wagner's group
this a scrub group of researchers
professors and collaboration with Intel
and so on and so answer do today is
going to tell us about his recent work
with his colleagues on the security
privacy permission systems and and so on
mobile devices thanks for the
introduction and thanks a lot for having
me yeah so most of the talk today is
about permissions I say mobile devices
but honestly I think a lot of this is
applicable to a lot of other different
types of platforms as well so most of
this was inspired by some work that
several of my colleagues did looking at
malware on mobile devices and so they
did this study about a year ago a little
over a year ago and we're analyzing
malware found on mobile devices in the
wild and found that the actually a
majority of it is aimed at you know
monetizing various information collected
off devices and so in terms of putting
this into information that's useful for
users so they found that a lot of it is
sending premium SMS messages whereas
most legitimate applications don't use
the SMS permission so if we want to give
advice to users we might say that you
know the SMS capability signals
potential malware therefore if you see
apps that request SMS ability you should
be wary don't use them and so the
question is given the current way that
most mobile platforms are designed is it
really possible for users to follow
advice along these guidelines so looking
at potentially harmful permissions and
screening apps based on that so to give
an example so I'm going to show this
with regard to Android so we've done a
lot of this research on Android but
again I think a lot of this is
applicable to a lot of other different
platforms so anyway so we go to the
android market say we want to find a
clock app so we search for clocks it
brings up a whole bunch of
different apps we find that one that
looks appealing based on the title or
the price we click it then brings up a
description lots of other information
here more of a description the title the
manufacturer some screenshots so if we
like this one will click download and
then it brings us to another screen so
on this screen it gives the user the
choice first and foremost to accept this
and download but then below that it
lists the permissions that the the thing
is requesting and of course with limited
screen real estate you can only really
show three permissions at a time so if
the user wants to scroll down they find
all the way at the bottom that yes this
wants to send SMS messages so now they
have to go back go back to the
description page go back again go to the
search results and now we find another
app so we click this one brings up a
description page again we click click
download and now we find that it doesn't
have any offending permissions so this
took ten steps just to figure out which
apps are requesting SMS permissions or
not so you know maybe one possible
improvement is by you know redesigning
the architecture of the market we could
if SMS is the most important one that
users care about we could add me maybe a
little icon to annotate and so now this
goes from 10 steps into one step to give
another example of this problem to
emphasize this so if we have an existing
app and you know users just hear about
this that their apps sending premium SMS
messages maybe they have some fraudulent
charges on fair bill they want to look
at existing apps on their phone so they
go to the main screen click the menu
thing it brings up a whole bunch of
their apps they have to scroll down find
the settings app click that and then it
brings up a whole bunch of different
settings panels so if we have to scroll
down again find the applications one
click that click manage applications now
it shows a bunch of applications on here
I'm so maybe they look at the flashlight
one they want to look at that one first
so it brings up settings for the
flashlight app now we have to scroll
down just to see what permissions it's
requesting so the problem is because the
permissions are done at install time the
only time that the user is aware that
it's sending SMS messages is when they
click the install button when it
actually sends the SMS messages they
have no way of knowing so now it takes a
12-step process in order to figure out
post talk which app was sending the SMS
messages so there must be a better way
and we've done you know some thought
experiments on this so one example just
you know the off the top my head is
maybe the first time an app sends an SMS
message you could have a pop-up box and
if the user you know doesn't click
cancel in time it sends the message and
it shows where the message is going and
what the text is or maybe even just
having a little icon that appears in the
status bar these are you know simple
methods that would result in more
awareness of what the phone is doing and
how it's using permissions so the talk
for today is about this notion of choice
architecture and how these design
decisions can have profound impacts on
security and privacy and we're going to
look a little bit at the problems with
the current approaches as well as some
improvements we've come up with based on
how to best use permission mechanisms in
certain contexts for different types of
permissions as well as looking at what
sort of permissions and risks users
actually care about so just to give a
brief bit of background this idea of
choice architectures was popularized by
Thaler and Sunstein in very book nudge
it's a pop behavioral economics book
it's quick good read but the idea here
is all about framing so when people are
presented with options how you frame
those options can have profound effects
on what options they ultimately choose
so soft paternalism so to give an
example just looking at the different
popular mobile platforms they have
varying numbers of permissions that
users are confronted with so on one end
you have Android which has 165 different
permissions one thing I'll say right now
is that this number 165 fluctuates
throughout the talk because we've done
this on various different versions of
Android and so the number of permissions
has gone from 120 some to 170 I think in
the most current version so roughly 165
permissions now 170 depending on which
version of Android you're using Windows
Phone is sort of in the middle with 16
permissions
I OS is on the other end of the spectrum
with only two permissions that users are
prompted with location and popup
dialogues so the problem with having
different numbers of permissions is on
one of the spectrum if you prompt users
with you know 165 different permissions
that's going to quickly result in
habituation they're going to start
ignoring everything because they see so
many requests so frequently on the other
end of the spectrum though if you're not
towing users what they're doing with
their with your with their data that's
going to quickly result in outrage once
it you know becomes public that a lot of
the state is being collected potentially
against their interests so you know
we've actually already seen this there
have been several stories in the news
about apps on iphone that have been
collecting data that users were
completely unaware about so for instance
their contact lists there was the whole
path Fiasco with the address books being
uploaded so there needs to be some
amount of transparency but too much can
be counterproductive yeah patient can
just directly access your camera without
asking them correct so there's a vetting
process I'm going to get into this in a
bit but there's a vetting process that
apps are supposed to go are supposed to
go through and it's completely opaque so
who knows what Apple does to vet
applications there's a Terms of Service
that says what you can and cannot do
without with data collected from the
iphone so for instance collecting
address book data was completely against
the Terms of Service and an application
that's being downloaded you know by
millions of people that should have been
caught in the vetting process that it
was doing this the fact that it wasn't
says something about the you know
efficacy of the vetting process so to
look at some specific current problems
my colleagues and I did a study this
past year where we're looking at android
permissions and again i think this is
applicable to other platforms some of
the shortcomings here so we did this in
two parts we first did an online survey
and the main thing was that we wanted to
recruit existing Android users and make
sure that they actually you know had an
android device and we did this by using
AdMob which is a mobile
advertising service so we commissioned a
bunch of admob ads that showed up on
android devices and we basically had
people take this survey on their device
we had a little over 300 respondents so
the first thing we did was we had three
different permissions so we randomly
drew these from a set of ten I or nine
or ten and we had multiple choice
questions where we showed the actual
text of the permission so in this case
here it's a granting internet access and
we had these multiple choice questions
asking users what ability this
permission is requesting and so you know
the answer here would be loading
advertisements and sending your
information to the application server
the other of these aren't really
applicable people who answered I don't
know for these we just filtered out so
there were five multiple choice answers
which were not mutually exclusive well
none of these is mutually exclusive yes
so go back to so this list doesn't give
me the best answer if I'm a technical
person why not me because a seller
information to the application server in
just one perspective it should be this
app can talk to any server on the
internet right I mean the question
though is which of these does this
permission allow and so saying like it
doesn't give me the best answer I can
truth if I'm a technical person I don't
know if that will impact of people's
response oh I'm not sure that was the
case i don't think that impacted any of
the responses because most of the people
didn't really have very strong technical
backgrounds but anyway so we gave people
three of these randomly drawn from a set
of 9 and what we found was while the
percentage correct was significantly
higher than what the expected value
would have been for random guessing at
the five different responses it was
still very poor so people got point six
questions out of three on average so
there were only eight participants out
of the 300 who were correctly able to
define all three of the permissions
so we found that you know comprehension
was very poor so we decided to follow
this up with a laboratory experiment to
try and get some qualitative data to see
why comprehension was so low so we
recruited 24 participants from
craigslist again existing Android users
we had them come in with their existing
Android devices and we did the
experiment on very Android device so we
had them installed two different
applications we gave them scenarios
where they were to find applications
from the market and we observe them to
see whether they paid any attention to
the permission scream screens during
these in installation processes and then
in the third part of the experiment we
asked them about an application that
they use frequently on via phone and we
asked them what permissions it uses and
we had them go into the settings panel
like I showed you guys so that they
could actually see the permissions and
we had them describe those permissions
to see even when the permissions were in
front of them whether variable to
correctly define them and then the last
part we asked them a specific question
so based on that list of permissions we
asked can an absent can this particular
absent SMS messages and we found that
the majority of them were incorrect so a
lot of the problem came from so during
so this shows on what they looked at
during the installation processes so a
vast majority of them actually looked at
permissions and actually only about
forty percent were aware that
permissions even existed so in terms of
the takeaways we find that most the
problem comes from the fact that people
don't actually look at the permissions
because the screen comes too late in the
process another explanation was that
people were simply habituated they said
of the people who we didn't observe
looking at the screen then an Herve said
very aware of permissions but they don't
look at them because they see these all
the time many said that they actually
thought it was a license agreement and
so clicking through was just a formality
and so we had some suggestions on how
this could be improved so one only
prompt on the permissions that are
really important that people actually
care about that have some likelihood of
actual harm and also the information
needs to come earlier in the process so
when
permissions appear right now it's after
the user already clicks install and so
their various cognitive biases that
might prevent a user from going back in
the process after they click install and
deciding to find another application
then so I think there is something
that's kind of love that set so we did
studies along some of these lines
ourselves and I think what you find is
that the way you talk about permissions
is something negative right something to
minimize something to use something to
entertain so on and so forth now while
what we find is that for many users not
all of them but quite a large number the
missions is the way they read that word
means capabilities capabilities means
better so the more permissions you have
the better off you are and if you can
get a free application as the most
permissions under the Sun like 112-54 in
the case of Android then you're golden
basically you just want the water yeah I
I won't get me just get to that's in a
bit okay yeah but um sort of the
activity versus positivity sort of
colors the interpretation of these
results quite a bit um yes yeah I agree
and that's a result that we found later
on Stewart so she said this is too late
in the process is that presupposed that
way you're trying to do is make an
install decision if you are allowed to
deny
the permission when it's requested well
okay so I'm gonna later contradict what
I just said which is if we if we assume
that we want to do this at installation
time and that's the assumption that i'm
going to contradict later if we assume
that we want to do this installation
time we shouldn't show it after the user
clicks install so there's you know maybe
a choice supportive bias so user clicks
install then sees the permissions and
they might agree that these are bad and
they don't feel comfortable granting
these permissions but at the same time
they don't want a second guess fear
previous you know choice or you know
decide that they made a bad decision so
if you're going to go ahead with it and
so that's one of the problems if we
agree that we're going to do this in
installation time we should have it
earlier which I'm not agreeing to
question so look at the result it seems
like a lot of people just don't know
what some permissions are yes and then
and I personally observed how my dad use
android phone and this recently then
maybe sink I mean shall we actually even
give user permissions shall look at the
pub with different angle to solve the
problem from at mark as much as we can
because they're gonna be of significant
fraction of users who have no idea of
what permissions yeah and um I guess
this is sort of a larger point which I
don't think I've I wasn't playing he get
into during this talk but what we found
in this experiment was this is in the
paper the vast majority of the users
were making decisions based on app
reviews rather than permissions and the
reviews were actually a pretty
reasonable proxy for misbehavior of the
apps so people tended to trust reviews
and felt the reviews were pretty
accurate and also a lot of people who
thought that permissions were maybe
overreaching in many cases that tended
to be reflected in the reviews and so as
a more general point I think that the
problem of malware on mobile markets is
really non-existent and instead the
problem that we're trying to solve is
gray where apps that actually do offer a
positive value proposition to use to
most users but
are using data in you know secondary
ways that might make some people
uncomfortable and so then it just
becomes the objective is making these
you know uses for the data a lot more
transparent and give people choice so
anyway so the second problem was
comprehension so of the small fraction
of participants who did pay attention to
these and then also when we showed them
permission screens and ask them to
define these we found that you know
almost everyone could was unable to
define these permissions when we
explicitly asked does this application
that you use frequently send SMS
messages 64% were unable to say
correctly whether it did or not and one
of the big problems we found was
confusing the category with the actual
permission so here's a screenshot of one
version of Android and you see that has
these category labels which are in
bigger bold text right above the actual
permission so for instance you know
Hardware controls is the category of you
know recording audio so asking people
what this meant they really only read
the hardware controls part first and
thought well maybe it has access to the
camera we can record audio maybe can
vibrate the phone turn the flashlight on
and so there was a lot of ambiguity here
based on these category labels the other
problem that we found was given the
extent of the extensive list of
permissions a lot of the permissions
required required understanding the full
set to understand the actual scope of
anyone permission so for instance
reading SMS or mms messages there are
actually two different permissions for
reading sent versus received messages
and unless you're aware that those two
permissions exist you're not entirely
sure of what the scope is of this
permission so our suggestions from this
was that these descriptions could be
improved possibly eliminating the
categories and also narrowing the list
of possible permissions so that users
don't have to understand 160 170
different permissions in order to know
what capabilities and app is trying to
request so in this previous study we
looked at the insta
all time warnings but what about other
mechanisms so for instance on iphone and
i think windows phone as well there are
some pop-up messages so like for
location it will ask if you want a grant
location so that's a different type of
mechanism altogether and of course this
is applicable to more than just
smartphones in terms of mechanisms for
granting permissions so to recap there
are install time warnings and you know
these have been used extensively in
android because we are adaptable to many
different permissions the permissions
are granted a priori before the user you
know even opens the application so the
advantage here is that you can grant
future abilities you don't have to
really do much from a platform developer
standpoint you just need to you know
read in the manifest and then populate
these fields in the installer and some
of the problems there with these is that
there's limited real estate so if you're
prompting on all of these install time
you can really only show three at a time
here on you know this particular Android
device if there are more than three
permissions you're relying on the user
to scroll down then their questions of
what order these permissions appear in
there also over easy to overlook as I
mentioned before and the biggest problem
though is if they lack context because
for granted a priority the user doesn't
understand in what situations these are
actually going to be requested so one
improvement on this might be during
runtime warnings so the advantage of
runtime warnings is that you can add
contextual information so you know the
user clicks a button and then they see
this morning well they knew what they
were trying to do when the warning
appeared and therefore if they have a
little bit more contextual information
that they could use to make a better
decision another thing you could do is
you can even put some of that you know
contextual information in the warning so
you know here's a mock-up of maybe
something pairing a device you can show
what the name of the device is it's a
lot more dynamic when you're doing it at
runtime then you know ahead of time with
the install time warning but these have
drawbacks as well so habituation is a
big problem so if your account
constantly showing warnings for
everything eventually users are just
going to swat them away users often see
these as a barrier to a primary task so
I probably don't have to go into the
problems with UAC here so another
approach that Apple has been doing in
addition to their two different runtime
warnings they curate the market so every
app that's uploaded
has to go through some sort of vetting
process but this you know this this
should be a great idea because it keeps
everything from the user we're just you
know telling them what's safe and what's
not safe user doesn't actually have to
expend any sort of cognitive effort on
deciding whether or not I should install
this program of course it's very
resource intensive so if you're hiring a
team of people to manually vet apps then
you know this can get quite costly and
it doesn't scale very well the other
problem is that it's completely opaque
who knows what they're actually looking
for and so you know the example I
mentioned before so path was uploading
contact list even though this was
expressed you expressly against the
terms of service well because you know
we have no idea what the actual process
was there was obviously some sort of
flaw there have been several other
emerging approaches which I guess sort
of fall into the cast the category of
trusted you I then the Apple does that's
interesting is that they also have
curating for what the movies things like
a harsh language and kind of
questionable content kind of thing like
movie care right kind of grated article
stuff and preserver that's actually
important to some category of their
users sure um but it's also a huge
source of frustration for developers
because you know in their terms of
service it's you know offensive well
what's offensive you know it's a
completely subjective process and the
other thing is that also
yes the developer center must be
frustrated i was looking to deport early
their application on the iOS seasonally
and basically it has all of these
warnings you can imagine because you can
download books that would have harsh
language share all of these other
characteristics and such typically there
obviously is to blame for that yeah it
is another well so there have been
several papers on trusted you I most
recently work that Helen did on access
control gadgets at Oakland this year and
so the idea behind trusted you I is that
you integrate the permission granting
mechanism within the users workflow so
buttons that are drawn by the OS so the
developer specif the application
developer specifies a placeholder the us
draws the button so nothing can be drawn
on top of that and it's a trusted path
to granting this permission it's part of
the user's workflow so they're not
taking extra steps this isn't an
impediment to the primary task and they
can't be spoofed I mean they can be
spoofed but there's absolutely no
incentive to spoof these because you're
not going to grant the permission by
spoofing them so you know here's here's
a mock-up of you know maybe we have one
for sending SMS messages and so maybe
the OS draws the destination number on
the button and now it's you know just up
to the user to click this button and it
sends the SMS message another advantage
of trusted you I is then you can have
more complex gadgets and use them you
know like choosers to choose subsets of
the data so maybe you have a calendar
thing that wants to add a bunch of
things to your system calendar when you
get you know a prompt then the user can
go in and you know do some fine finer
grained editing on what they approve and
what they don't approve of course you
know trusted you I aren't really that's
not really a panacea either because they
can't really be granted you can't grant
abilities in the future easily and they
also can't really handle a synchronous
request so things that the user didn't
initiate that's a big difficulty so you
can't use trusted you I for everything
but I guess so
hey I'm sure you could design you know
several you know maybe objects in the OS
to you know with callbacks where you're
looking for specific events you know
from sensors when you're going to
trigger the the permission so maybe you
have a button that the user grants but
that sort of defeats the spirit of the
trusted you I it's no longer part of the
user's workflow now scheduled yes yeah
that's exactly what I'm talking about
but it's no longer really part of the
user's workflow it's now a separate task
that they're doing to schedule this
permission request and that sort of goes
against the spirit is exactly fond of
the Spirit because as the user who
sketch
no one else for the future an era where
no one is not that user who schedules it
for the scenario we are the schedule is
not our clear values or that the program
is to use a permanent access nasty
scenario that there's no way for the
user um in at least privilege wick I
don't know I think there's a much larger
discussion there okay well take that
offline and so so there are several
different mechanisms that you could use
to grant permissions but I think one of
the big shortcomings that we see why
there are problems in a lot of systems
is that everyone just chooses one
mechanism there can be only one
mechanism that we use for every
permission so in android all of it is
done through install time permissions
and install time certainly has cases
where it's effective but um my next yeah
that's weird that's just the preview for
the next slide was really screwed up so
anyway we did this thought experiment
where we were looking at all of the
permissions that are available on all
the mobile platforms and we combine them
together by also emerging redundancies
and getting rid of stuff that the users
don't really have any business being
confronted with so you know like for
instance multicast or turning on
debugging users probably don't care
about those sort of things so we can't
what 83 unique experience unique
permission so we did this thought
experiment where we just sat down over
the course of several weeks I'm going
through each of these permissions and
deciding what would be the most
effective mechanism for granting this
permission and why so to give an example
maybe you have a security app that will
permanently disable the device if you
report your device stolen you go to some
website and then it you know fries your
device so one of the things we looked at
is risk level so this is you know pretty
severe you wouldn't want a random
application breaking your device without
your consent is this you revert able no
that's the whole point is that it can't
be undone is their incentive for
widespread abuse probably and so the
consensus is the only real way of doing
this given
mechanisms available would be at install
time so you're not going to have you
know a trusted UI element on the device
to you know break it in real time
because you don't possess the device
you're not going to have a runtime
warning asking the person who's stolen
your device whether they really want to
erase the device or not so another
example on the other end of the spectrum
yeah that's full of useful I would
someone want to do that what's the
mandala still yeah blackmail um changing
the time at the other end of the
spectrum so risk level really just an
annoyance um can you undo it yeah
absolutely you can go back and change
the time is their incentive for
widespread abuse I mean maybe you can
think of some you know James bond-esque
nefarious plot where you update the time
on everyone's cell phones as part of
some you know heist but you know
realistically you're not going to be
spreading their it's unlikely you're
going to see a lot of malware that the
main attack vector is changing the time
on people's phones so the consensus here
is that this is so minor and you know
revert a ball that maybe we should just
grant this implicitly when whenever a
device wants to change the time but
maybe we can have some audit mechanisms
so the users can see what application
changed the time and so then this came
up we came up with this idea of the
implicit access permission mechanism so
for things that are very minor and are
either revert alors just pose an
annoyance we want to minimize
habituation so there's no point asking
about these before if they're granted
instead why don't we just let them go
and make it easy for users to figure out
what app is doing this so in the case of
changing the time then maybe we have an
audit mechanism by annotating the
settings page indicating which app most
recently changed a time and you know you
could see this may be for wallpaper as
well showing which app changed the
wallpaper last and so users can see if
there's an offending app that's you know
doing things against their wishes they
can then identify the app and remove it
and of course though this isn't to say
that this permission shouldn't exist
anymore for you know wallpaper or time I
can still imagine this being declared in
a manifest file so that
you know people then could audit what
applications are actually doing it's
just that we're not confronting the user
with these decisions so from this we
came up with this sort of hierarchy of
permission granting mechanisms from
least desirable to most desirable so in
the absolute best case you know we would
hope that we're not going to confront
users with things we're just going to
make it so it's easy to undo bad things
that happen and you got the other end of
this spectrum there's you know if
there's really nothing else we can do
we're sort of forced to use an install
time warning and just sort of hope for
the best so you know previous scenario
where i talk about to take time and
stuff yeah because if you wanna does not
eat you kind of disturb the workflow of
the youth all right so yes apparently so
you have see you a couple permissions
that need to go into effect at once so
entrusted you I you'd have a series of
button presses you just you I to gently
the application has to use assistant
test it you I didn't sure but if you're
gonna have you know sort of compound
permissions um this privilege computing
capability no I understand but if you
want a couple things to happen all at
once so you know what does that cut
composition composition okay so I think
that but I do see there's a month in
America understands conceptually
neat they may not need to know that the
times that needs to change for something
right this is not user does not need to
do anything user just need to the
application just use a system UI to trim
to the time rather than your I think you
broke in the API so then okay there is a
benefit to your approach nevertheless I
think the benefit is not to disturb the
user for the benefit is to reduce the
application development costs sure um
yeah I just I still disagree that in
practice I think that there are a lot of
cases for where trusted you I is just
going to annoy the user and disturb the
flow not too well so okay so some of the
things different it's the application
you already need to ask the camera you
already need to ask the user to click on
the camera the application already needs
to sure okay sages you know changing the
wallpaper so you have an app that you
know maybe does themes on the phone so
it's gonna change you know the wallpaper
the you know skins system UI sure but
then it's not it's just exactly like
fell peeking that's already being
implemented I Lucilla check offline guys
yeah take this off um so anyway we came
up with this flowchart for how to choose
permissions yeah
discussion of trusted you I think there
are two mechanisms missing here at least
one wishes user-initiated configuration
of the permissions another which is like
an admin push permissions where you
might be getting an enterprise app from
grand prize administrator who is setting
some appropriate default permissions I
think the latter is out of scope because
that doesn't involve the user or the end
user really I guess the point of this I
mean that case that you could sort of
lump that in with implicit access right
because it's stuff that's going on
without you know user involvement at all
and user involvement so we're going to
be presenting this at hot sac in two
weeks we came up with this flowchart
then for how to decide you know when to
use which permission mechanism so to
give an example here so granting
internet access so can this be undone
well not really you can't get the bits
back is it severe what if it's abused is
it going to cause is it just an
annoyance well probably I mean if you're
not roaming internationally and you have
an app that's using a lot of data
there's only so much that could happen
so we want implicit access here with an
audit mechanism so if we do find that
we're over our you know bill one month
we can then look and figure out what
application is hogging all of our
bandwidth so say we're roaming though so
now this changes the severity did the
user initiate it well in many cases no
the request you know to transmit data
isn't really part of the users flow can
this be altered do you want to you know
it's on like yes it could be altered you
could have some sort of firewall that
the user is you know configuring but
that's unlikely in most cases um and so
does this need to be granted ahead of
time well not really so this would be a
case for you know a confirmation dialog
maybe a runtime warning when the
application wants to request data when
the users are roaming internationally so
the other example is a permanently
disabling device there's one really when
you're talking about CDA information
seems like considering one provision at
a time is not the right way to do right
because sit internet access right by
itself it's not that bad and what what
else can go back there but like if you
have access to camera and internet
access well you know thanks my kid go
back right oh yeah this is a larger
question I think so many people bring
this up with internet access but
actually you know so we've we've been
crawling the several application markets
and looking at what permissions
applications are requesting a ninety
percent of apps request internet access
and from the users perspective it's sort
of expected that applications are
accessing the internet so and that that
sort of is figured it when you know when
we ask users about what are the risks of
using the camera it's sort of implicit
that one of the risks is uploading that
you know what's taken from the camera so
permanently disabled so you can't undo
this it's very severe not really
initiated with the user who's holding
the device can it be you know can you do
a subset of data well not for this
purpose if you want to brick the phone
and you know does this have to be done
ahead of time yes so the only time
you're going to be able to do this
easily is with an install time morning
so we looked at of these 83 permissions
that we started with and how many of
these could be lumped into each category
and so we found that actually a majority
of them could be just granted without
approval ahead of time and then add some
audit mechanisms and so this has the
potential to greatly reduce the number
of user interactions therefore
preventing habituation so about a
quarter of these could be done with
trusted you I and you know how many of
those
inclusive access can also be gets out by
trusted you I that would be a very yeah
and I and I agree that I think a lot of
the implicit access could be done with
trust you I actually can be now that
mess with you either got home without
user going honey yeah okay um so one
caveat with this is this is just
categorizing the set of permissions so
this doesn't say anything in terms of
how frequently users are going to be
interacting with one of these and this
is actually a future thing some joint
work which I'm going to get to in a
little bit that I'm doing with Jay on
one thing we're piggybacking on this is
hooking we're doing a field playing to a
field study and as a secondary thing
we're hooking the API calls so that we
can actually measure the frequency with
which each of these permissions are
actually granted typically will not
grant it but used typically I'm glad
people um yes like how author on this
adrian is well Adrian I see you guys
soon yeah because I mean that I'm do I
permission Allah it's just so broken yes
um and actually it's funny google hasn't
been very receptive to this we've
actually gotten a lot more the mozilla
people have been listening to a lot of
this more so than the Google people i
don't know i guess you guys must be
familiar with boot to gecko so they're
creating a whole new mobile platform
based on the gecko browser and so yeah
right yeah so so this comes up comes to
the last question which is you know
which permissions are actually important
to users so we've done a series of
studies on this so in one which i
presented recently a twice we looked at
we did a willingness to pay study to try
and get at what permissions are
important we did this on Mechanical Turk
we showed different screenshots of
fictitious apps along with the
permissions that those apps requested
and prices and the idea was to look at
we counter balanced for the different
apps for the different fictitious apps
so that we can control for price and
permissions requested we had almost 500
people a third of which were Android
users us-based and so what we did was we
had four
ditions the first condition was you know
the cheapest we asked people which of
these apps would they purchase if they
had to purchase one of them so for about
50 cents 49 cents was the app that
requested the most permission so
internet access GPS and recording audio
so we chose these three permissions
because well one for the app that we
described internet access would be
required and also internet access as I
said is requested in practice by almost
every app anyway and then we looked at
record audio and location we looked at
location because it's been the subject
of most of the mobile privacy research
for the past 10 15 years so we figured
this would be a good starting point to
look at how do people actually care
about location relative to other
permissions then we looked at record
audio because we asked about a couple
permissions during our initial lab study
that I talked about and we found that
recording audio against you know users
wishes is one of the most severe ones
people stated so we decided to contrast
that with location so the next cheapest
one was 99 cents it was only internet
access and the audio than a dollar 49
location and internet access and then
finally for the fewest permissions it
was a dollar ninety-nine so the task
looked like this again these are
fictitious apps there they look
different so the names are different the
manufacturers are different the prices
well the descriptions and the
screenshots are all different but we
counter balance these so and so what we
really did was control for just the
price and the permissions but so we
found that twenty-five percent of our
participants were willing stated a
willingness to pay more money for fewer
permissions to I guess gets a Benz point
so it's surprising here that people were
paying you know a dollar 49 we would
weeks we were surprised at the number of
people who were in the middle two
conditions and the reason was in the
exit survey they thought that some of
these additional permissions signaled
desirable features so if it requested
location that's good they're willing if
they want to pay extra for the location
and we found that this effect carried
for about half of our participants so
the request for location was just as
likely to signal desirable features as
an undesirable encroachment on personal
privacy users actually have to pay
somehow Express yes it was just yeah it
was stated willingness to pay um orianna
it's good are they to dig into us don't
they use anything so because eating is
anything we we measured that actually so
after we asked them to pick a nap we
asked you know how interested are you in
this app because we originally thinking
that if there was gonna be a correlation
between you know their willingness to
pay and also desirability we were gonna
you know toss out the people who were
just uninterested but we found that
there was actually no significant
correlation whatsoever so we ended up
using all of our participants but again
this was you know stated willingness so
this is probably an upper bound but it's
still interesting that a statistically
significant proportion of our users were
willing to pay you know three times as
much more for well four times as much to
get fewer permissions yeah so there was
the difference between the first
condition in the last condition
of the internet access GPS recording all
you and so from this in our exit survey
we also asked about several other
permissions we had I think 15
permissions that we asked people about
and we have them rank them in terms of
concerns and so we ordered those on the
right and we had also done this in our
initial survey that we did on AdMob and
we found some differences based on these
rankings and this came down to there are
several confounding factors here so one
is we use different recruiting
mechanisms one was AdMob loans
Mechanical Turk we did this over
different time periods but also we
didn't use exactly the same permissions
that we were asking about in both cases
one thing though that was interesting
was that of the permissions we asked
about location was consistently towards
the bottom but based on the
discrepancies and the confounding
factors here we decided we should do
another survey just looking at concerns
over permissions of all the permissions
that we could find so we took all of the
android permissions at that time i guess
it was around 170 we used the 16 Windows
Phone permissions we were going to
incorporate iOS as well but we had
already covered that set based on these
and then we merge redundancies and got
rid of extraneous ones and we were left
with 5412 permissions so we did this
card sorting exercise on a whiteboard so
to give an example of redundant ones you
know there are two different permissions
for reading received versus sent SMS
messages that doesn't really need to be
two permissions what's the difference
between power off and reboot not that
much the difference between you know for
stopping applications and killing proxy
processes and so on so we decided we can
merge these into single permissions Bend
so given all of these how how did this
really wire to the Commission
come about seems like somebody was just
sort of randomly inventing these things
and right I've heard different stories
the one the story that I've heard most
consistently it was that it was forced
upon the developers by the legal team in
this yearly I don't know about the
number of the permissions but in terms
of doing it the way that they do where
they show everything you know ahead of
time I mean it's no wonder why many
users said this looked like a license
agreement it's because the initial
version of Android was sort of this was
the lawyers decided this is how we're
going to do this I don't know how they
came up with 170 some or if they decided
what would be a permission what wouldn't
I can't really answer that but um so
another example would be getting rid of
extraneous ones so enabling multicast
for instance what user is how many users
are going to be qualified to answer that
question so we got rid of that and so we
did this survey again on Mechanical Turk
we had over 3,000 participants from
these fifty four different different
permissions we wrote down possible
negative outcomes and we came up with 99
possible outcomes that correspond into
these permissions and so from these 99
for each participant we randomly chose
twelve of them that we showed to each
person and we had them rank these and
the idea was we weren't interested in
sort of baseline level of concern that's
impossible to determine without really
well context and also you can't really
determine that without these actually
happening to most users but we wanted to
try and rate these relative to each
other so we could figure out what are
the most concerning permissions and what
are the least concerning so we had a
five-point likert scale and we were did
this as you know how would you feel if a
nap dot dot dot without asking you first
and so we showed 12 of these concerns we
had people rate them and what we found
was that for the the high-concern risks
most of this came down to financial loss
so sending premium SMS messages which is
how most malware monetizes itself making
expensive calls you know long distance
or international 1 900 numbers
destroying the device or destroying data
such
you know doing a factory reset deleting
contacts contacts incidentally I was
just talking with Helen about this a lot
of these big concerns like the data loss
could be potentially you could revert to
a previous state if we had you know
really good really well integrated you
know cloud backup and recovery so you
might not you know in the future you
might not need permissions about you
know for surrounding these if we would
make it really easy to get your data
back yeah there's the recovery maybe
these scenarios are easily done other
honor there may be other damages
associated you know all your contents of
being sent to other people yeah so we
found we were surprised that we found
sort of in the middle of the list was
sort of the privacy stuff like you know
information disclosure and the reason
why that was in the middle of the list
is that that was very high variance so
it was like twenty five percent of the
permissions were at the top were
universally concerning so stuff with
financial loss and data loss at the
bottom the low concerned stuff so
changing settings which could easily be
undone sending stuff to other computers
only so for instance sending your
location just to an application servers
to find location-based services and no
human sees it people really did not care
about that at all and sending other data
like that so like unique identifier ziff
song as no human sees the resulting data
people don't really care about that then
there's sort of the middle fifty percent
and it wasn't that people just route
ranked these in the middle it was that
these are very polarizing and high
variance and so I think a lot of work a
lot of more work is needs to be done
maybe clustering these may be coming up
with you know persona is to look at you
know developing better algorithms to
decide we of the ones in the middle what
users are likely to care about these and
which users or not oh but again so one
of the points I made earlier is that and
this was echoed here is that location
people really don't care about this well
I misstated that it's not that they
don't care about it they care about it
less than many other things that their
devices could potentially be doing so
mobile privacy has been studied for at
least 15 years now but location has been
the sole focus of that but
compared to all these other things that
could have profound privacy consequences
people care about location a lot less so
we asked about location sharing in four
different context so sharing location
with members of the public was the most
concerning but it's still ranked 52 out
of 99 concerns sharing with advertisers
friends and then you know at the bottom
app servers so as long as no human was
seeing it people didn't care at all
about location and so then this brings
me to the last point which is looking at
context and how contacts impacts a lot
of these decisions so you know given two
different requests so maybe you know
Twitter wants your phone number and this
is how a request might currently appear
where there's no other information it's
just saying the this application wants
this type of data allow don't allow but
maybe we're going to add some context so
if we say that it's for advertising
purposes obviously this is going to have
a huge impact on whether users allow
this request or not so this is work than
I'm currently doing with Jay on where
we're looking at the impact if we add a
rationale for the request what are the
impacts on users so the initial idea was
basically to add a UI to taintdroid so
that we can say you know if we know that
this is going to known advertisers why
don't we put that in these warnings live
there more contextual and there are a
lot of variables now this is work in
progress so I don't really have that
much data on this but some of the things
that we're looking at our differences
between if we see if we say that it's
going to you know first party versus
third party is that going to make a
difference if it's only viewable on the
device versus leaving the device does
that make a difference and actually to
the latter question we can say no we've
already looked at that and so we did an
initial pilot we did this on Mechanical
Turk with 100 users and we had them view
a screenshot of a request we said you
know you're using Facebook for instance
we did this for four different apps and
you see this screen what would you do
and why so in the control condition we
had facebook requesting the address book
with no other information we then
specified that the purpose is
application features and data will leave
the device another condition was
application features and data will not
leave the device advertising data will
leave the device
and analytics data analysis data will
leave the device and so from this
preliminary pilot one we found that
people had no idea what was meant by
analytics and so we probably shouldn't
specify that or you know just maybe
group it into advertisers or either
first party third party there was no
distinction between data remaining on
the device or going to the cloud so the
difference between application features
that were going to be processed in the
cloud versus on the device people didn't
care but across all these conditions
despite specifying a rationale in a word
or two sixty percent of our participants
regardless of condition still wanted
more detail so we did a follow-up we had
five different conditions here similar
to before we did control where we didn't
specify any other information we had
what we call the app functionality on
cognition which is shown in the picture
here so we specified both the purpose
which was application features and
customization as well as a sharing
policy so data will not be shared with
third-parties we had another we had an
ad condition where for the purpose it
said advertising yeah specified this
purpose is it like the app developer
will specify this purpose and this
sharing because it's like there's really
no way to enforce these things right
well there's way there are certainly
policy ways of enforcing it I mean
privacy policies are enforceable right
will enforce that is it the mobile OS
well I mean if people are lying in these
the that's FTC enforceable legal yeah
policy I mean so this is sort of a
thought experiment right so we're not
you know forgetting the limitations of
the technology if we were going to
engineer at some you know this way if we
found this as effective what then the
question would be what are the steps
that we would need to do to make this
possible so we had advertisements where
he said the purpose was advertising and
it's would be shared with third-parties
and then we got rid of the purpose box
altogether and just specified sharing
between first party or third parties and
we also had four within-subject
conditions where we just varied the
application and the type of data so we
showed Facebook requesting the address
book and we had Yelp looking for
location skype asking for their phone
number and my calendar app wanting
access to the calendar we chose these
apps because they were
the most popular apps on Google Play
that requested these permissions and so
the preliminary findings are that when
no information was given this was really
surprising in the control condition
people assumed that data would not be
shared there was no statistically
significant difference between the
control condition and the conditions
that said data would not be shared with
third-parties which was surprising
because we're cynical and thought that
you know I tend to think anyway that
when no information is given about
sharing policy it can be assumed it's
going to everyone this wasn't the case
for most users so we also found that
there wasn't really a difference between
whether or not we showed the purpose it
really came down to who was being shared
with and why people asked afterwards in
the exit survey that regardless of the
condition that they were in everyone to
know more information about why the data
was being shared and with whom it was
being with whom it was being shared if
it wasn't being shared they cared a lot
less so our next steps with this is
we're planning a lab study and so this
is sort of a new mock-up that we've been
doing so people want in for Miss apin
Swan tadesse information about who data
is being shared with so the idea is now
maybe we want something expandable so at
the high level gives you a brief
synopsis and for users who want more
information they could maybe click you
know if it is shared with the other
companies they can click that something
expands stating the name of the company
contact information why the date why
that company is requesting the data what
that company does these are all the
things that people wanted so we wanted
to look in the laboratory whether people
will expand these and be able more able
to answer questions about what's
happening with their information and so
this is an iterative design process and
once we've you know home to the designs
we're planning to do a field study where
we're going to instrument people's
phones with these permission with these
warnings and look at how we interact
with them and also whether they at what
point habituation takes effect so at
some point people are probably going to
swap these away without paying much more
attention another thing we're looking at
its scoping so clicking the box for
remember this decision under what
circumstances would people want to
select that so we'll
that will they want to revisit this is
the decision if you know sharing policy
changes if the purpose changes do they
want this decision to remember it to
hold for this applicant one application
for all types of permissions a specific
subset of permissions so these are the
questions we're looking at now yo case
is that the location is used a voice for
the main purpose that's funny
restaurants and also sure was the ad
network yes and then it's kind of hard
to automatically tactile one first
second is a it's also hard to figure out
which one's primary which one second so
what's your take on that um I mean this
needs to be put into the yeah I put in
the morning that I don't think primary
purpose is that's probably not the best
wording but you know purpose and so it
might say both right application
specific features and advertising and
that's why we're doing these iterative
you know design experiments to try and
figure out you know what's the best
wording to communicate that area through
introspection to see which component of
the code is asking location access
so as long as the location is accessed
by third-party people to within the code
we know which components to it so that
way we can differentiate but there's
question of if you have this first part
a component active requesting little
pitching and that's also shared with
other forests at that then makes this
morning
yeah why did you throw in some random
explanations into the mix like do a bird
global warning to save bodies yeah oh
that's a good idea we the bill do
whatever I know to save the puppy yeah
um I mean the issue is that's a good
control contagion no I mean that yes and
there is there's a famous behavioral
economics i dot e on this where people
you know if you give any explanation
people generally comply with requests
regardless of how ridiculous the
explanation is but the point is actually
going back to the previous question the
idea is that the text that we put there
is standardized so one thing I want to
test in the near future is iOS 6 is
planning to have developer specified
text next to the warning so why location
is being requested and my hypothesis is
that if developers are specifying this
and there's no standard text that's used
it's going to quickly lose all meaning
to most users and so the platform
developer needs to specify what's the
you know appropriate text that will
appear here and so under that constraint
I don't think anything like you know
preventing global warming or saving
puppies most platform developers would
allow to be on their set of you know
permissible text so the conclusion is
that a lot of the current choice
architectures for mobile privacy and
security or failing users because the
requests are going unnoticed they're way
too many of them and they're difficult
to understand but at the same time users
really do express an interest anyway in
knowing what the apps are doing and
there's a lot that we can do in helping
to design the platform's to accommodate
that so that's it
so I mean all the emphasis is on can I
kind of figure out you know asking
people at the kind of install what what
permissions have been a grind I mean
have you looked at at all you know do
people have any understanding of you
know of the 10 or 20 apps that have got
on this do you understand how many of
these have any of the permissions your
now you know making such a big deal
about right you know oh I don't want to
share permission for a drop so you have
any idea about the 20 that you've
already got have you no no I mean the
answer is now so I mean in that the
first study that I talked about when we
had people you know we had them open an
application that they've used frequently
and they claim to be familiar with and
while looking at the permission screen
we ask can this send SMS messages and
you know sixty-four percent couldn't
answer that question when looking at the
list of permissions that the app was
requesting as well as based on their
knowledge of the app having used it so
you know I don't want to allow my
occasion for others as well you've
already done it with 20 otherwise it's a
joke sure well and I think again that
advertising is that's a little bit more
nuanced but I think generally speaking
if a lot of the data uses was made more
transparent to users so you know maybe
with notification icons so when I don't
know when location is being requested
having a more interact so when the the
GPS icon appears if user wants to vacate
click on it maybe and it will show what
applications using the GPS and maybe
some you know short explanation of why
it's likely that a lot of people will I
believe that many people you know might
actually interact with that to make some
effort but right now the mechanisms just
don't exist for the people who are
interested in learning more my privacy
posture like no I absolutely no idea
what my privacy posture is your
measuring how big a deal is it to have a
delta what I I go from no idea to no
idea right now well I mean so we know
that people express concern we know that
they're not currently being served and
so if we can you know incrementally show
that you know we're getting closer to
aligning with fair you know stated
preferences I mean certainly we know
that stated preferences
our kind of bogus to begin with but
there's some grain of truth to you know
when people express desire for keeping
certain data private
so if you look at this relation tigra
missions which is which is greatness of
a difficult office what about the other
side of the story which is what about
people who delete their applications
what about queer questioning them and
asking why um we've actually done that I
don't have the data off the top of my
head Adrian just ran a survey I haven't
looked at the results yet so we designed
to survey a very qualitative survey
where we're asking them if Avon
installed applications before and why
they have uninstalled those applications
but I don't have the data off the top of
my head I can send it to you once i have
it
I'm not sure we've this so we started
the user yeah yeah i'm not sure if we've
submitted that anywhere yet I haven't
seen the results so I would hope that
she didn't submitted any um but yeah
okay thank you thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>