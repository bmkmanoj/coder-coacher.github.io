<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Proof Engineering, from the Four Colour to the Odd Order Theorem | Coder Coacher - Coaching Coders</title><meta content="Proof Engineering, from the Four Colour to the Odd Order Theorem - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Proof Engineering, from the Four Colour to the Odd Order Theorem</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/d-oV0fs3e6s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
all right now I'd like to introduce my
colleague Oh George gontier who is a
principal researchers here in Cambridge
he is also very deeply involved in our
joint center research center in Paris
Andrew Blake mentioned George work
yesterday it's about using computers to
prove mathematical theorems George work
is tends to be more longer term so he
spent a few years to prove the four
color theorem and most recently the
fight Thompson theorem that took you six
years i believe and earned you the the
price by the EAD s foundation in france
so very prestigious awards that the
george received for this yes and you'd
like to spend the next hour to tell us
more about that work thank you George
thank you yes this will be a sort of
talk on my adventures in trying to teach
math to computers and I'll start with an
old story but it's a rather good one it
starts here in Cambridge middle of the
19th century when a math and cartography
student who obviously had too much time
on his hands toyed around coloring a map
of the counties of the the kingdom and
figured that for color were enough to
make sure that no adjacent counties got
the same the same color now being
studying math as well as mapmaking I
asked his teacher who was the famous
logician Augustus de Morgan where this
was always true and the Morgan didn't
know and in fact i found this was a
rather nice puzzle to torture his guests
and he kept it under the hood for or in
a desk drawer for about 25 years his
successor kaylee published the problem
25 years later and a miracle of
competent competitive research a year
later someone came up with a solution I
was
really neat solution based on using a
theorem of Euler that says that in a
planar map the average number of
neighbors has to be slightly less than
six sort of think of a football if you
want to close a football you need a
couple of pentagons in addition to all
the hexagons and so there has to be a
pentagon somewhere and now you study
this configuration of regions around the
pentagon figuring out how it can be car
they're basically three ways it can be
covered and in each of these cases you
make some recursive argument that this
allows you to color the map by induction
so everyone was very happy with this sir
kemper got knighted and ever always well
for about 11 years and then disaster
struck because someone found a bug in
the calculations and the bug could not
be fixed and there was an independent
proof in the meantime and it had the
saintly exact same bug so these sorry
state of affairs persisted for well
nearly century really there was some
progress people realize that well maybe
looking at the Pentagon was a bit too
greedy we could look since the average
is less than 6 you can look at larger
sub maps and in each of these you look
at the more promising configurations and
you'll have so little n configuration
which will hopefully be less than big
little m and for each of these you look
at all the colorings and unfortunately
that means you'll get big end coloring
where big n is pretty large indeed it's
so large that the only way of doing this
coloring is to use a computer which
meant that one had to wait for
electronics to catch up in 76 in order
to get enough compute power to do this
coloring indeed it turns out that you
need to look at 10,000 map which is
painful to do on paper but can be done
about 1500 configurations and then about
a billion colorings to look at which at
the time required programming your IBM
mainframe in assembly and run it for two
calendar months or do all the checking
now this was wild widely hailed as an
achievement by the specialists and then
the non-specialist had some doubts about
it so it was kind of split between the
new generation and the old generation
the new generation South computers were
cool but couldn't possibly believe that
10,000 little drawings could be all
correct in the old generation thought
that these computer things they're full
of bugs and no one has the money to this
to spend another two calendar months of
mainframe time to recheck this so it's
basically a narrative producible
experiment and so things stayed this way
for about 20 years then the problem was
revisited by a crack team of comm unit
orest who realized that if you optimize
things you could get things down to
about 633 configurations and more
importantly you could move the map
analysis into computer code write your
programs in C have a neat texts proof
that fit in 35 pages so I single a
normal journal article rather than two
tomes of a special specialized publisher
and all of this checked at the time so
still 20 years ago in three hours on
your average PC so basically all
objections drop because all
mathematicians at this time already had
a PC in order to run text processing
software written by
one of our famous MSR turing award easy
but specialists like myself realized
there was a still a problem with this
nique proof that there's no real
evidence that the C programs actually do
something that has the proper
relationship to what the math text says
and so this may be a case of garbage in
garbage out now there's a known solution
to this which is to apply formal program
proof techniques and so this is what I
set out to do in the early 2000s with
Benjamin Verner and so what we did is
replace C with a functional language
that actually has a mathematical
semantics use a program proving system
to actually prove the code correct and
then I realize that I just move the
problem because I just move the problem
of describing the correctness of the the
program to describing the correctness of
the program spec and if I really wanted
to prove the theorem what I had to do
was replace the actual mathematical
texts with a formal proof and the logic
supported by the proof checker is rich
enough that it can actually do arbitrary
mathematics and I was able to do that
and so now the nice thing is that you
don't need the Royal Academy to certify
the proof because everything is check
rigorously from the statement down so
early lessons from this project so this
sort of finished 10 years ago that is
possible to actually have computer
program computational proofs be as
rigorous and possibly more so than paper
proofs more interestingly and that doing
the proof on the computer not only helps
you check the program at a actually
helps you understand the problem I'll
explain that a bit later
and the third thing is that the way you
organize your formal proof actually
matters quite a bit that as well as soon
as you're trying to do something a bit
ambitious you have to understand how to
program the mathematics correctly and
modularly for example so I'll give a
little more detail on the proof on how
it works it's basically an induction
argument so any common oral proof tends
to work this way and so the way it works
is if you want to color an arbitrary map
you identify a piece that's easy to
color configuration so little sub map
and what you do is you don't try to
color the configuration because that's
that's easy you try to color the rest of
the map in order to color the rest of
them if you use the magic of induction
you modify the configure the map
somewhere in the middle of the
configuration that gives you a smaller
map because it just erased the border
for example now you color the whole
thing by induction and now you try to
repair the damage because obviously the
coloring you have is not going to be
valid because it has two adjacent red
regions so you try to recolor the
configuration and since your
configuration is supposed to be easy to
color you'll have many colorings to
choose from now it may be the case that
you don't have even so you don't have a
coloring that fits in immediately but
you can also try to modify the existing
coloring by essentially swapping two
colors in an adjacent region like here
called swapping the yellow and the blue
in that part of the map and if you do
this in this case then everything fits
and in fact this particular
configuration with four Pentagon's is
such that you can always do this so it's
called a reducible configuration so the
whole proof is just that find a set of
configuration that has two properties
unavoidable T you're sure to get one if
you're if you have a planar map and
reusability each one of them is
reducible which means each
one of them lets you do coloring by
induction and there's this is where you
get to really use the computer because
unavoidable t that requires you to look
into 10,000 cases and reducibility
requires you to go into a billion
colorings and then there's the part of
doing the math so how does a the
computer help you prove these very very
complicated combinatorial arguments well
it very much actually depends on the
logic you're using to describe math and
it goes back to an early objection point
cafe the French mathematician made to
early formalisms especially ones prone
by Hilbert he objected that to prove
something as basic as two plus two makes
four the way Hilbert would have you do
it would be to well define to as maybe
adding two sticks and four has adding
four sticks then have a whole algebraic
derivation culminating with this silly
conclusion and point our objector that
this is not how one did mathematics in
practice what one did in practice yeah
you showed that you could color any
configuration was it given any coloring
of the surrounding context this can you
can with this configuration you can
color it you can recolor given any
coloring of Sura surrounding coloring of
the context but it's a property of this
configuration not all configurations
have this property famously kempe got it
wrong by thinking that the configuration
around the pentagon had this property
what is the base case then well
obviously if you're down to fewer than
four regions you're you're pretty good
have four colors you just sign a
different one to each okay so super kind
objection that this is not the way one
does math and the modern interpretation
of this is that if you've defined two
and four you can also define not only a
constants you can define operations and
so if you have a formalism that lets you
define algorithms and not just a static
constants then you can define what
edition means and then you can just
realize that two plus two equals four is
really of saying a way of saying that
four is equal to four is just that
you've written for in a different way on
the left hand side and so that's a
that's a very silly way of proving two
plus two equals four or it's very silly
to build our logic just to get two plus
two equals four to work properly but
actually if you build your logic this
way then you can prove the four color
theorem easily because what you do is
you define a mathematical property of
reducibility then you define a decision
procedure that's going to run some
computation and that's going to return
true or false and then you can prove
that this procedure is valid which means
that if it actually returns true then
the configuration is mathematically we
do
possible which means it allows coloring
by induction and then if you need to
prove that a specific configuration this
is a configuration number 232 in the
catalog figured out by Robertson and
colleagues encoded with this kind of
genetic kind of genetic code I will just
apply the theorem and then then just
compute your decision procedure and if
the decision procedure returns true then
the theorem is proved so there's no
logic involved so this goes into 20
million cases but the actual logical
proof just has two steps apply the
theorem and then apply reflexivity so
the second thing that I learned during
this project was that you actually know
more about the math if you formalize it
properly so the way you describe a map
even in the Robertson revised paper is
so to go from this fuzzy drawing to
something that actually makes sense
mathematically is to say oh well I
recognize in this map I have regions and
I have edges and the edges connect Oh
edges that connect that's a graph but a
graph doesn't really characterize it map
because what you want to do in a map is
navigate the map so go around around a
region around the face and so on and
there's no way to do within the graph
structure because it doesn't have any
order to it and sounds like the
structure is insufficient and what you
have to do is to have a mixture of the
graph and then the embedding of the
graph the continuous embedding in the
either the sphere or the plane and
that's not very good if your that's not
very modular because you're mixing a
purely combinatorial argument with
something with arguments that come from
topology I was very clear that this
would not work if you were doing before
proof formally if you can do it on the
paper waving your hands vigorously
and drawing little pictures and inviting
your reader to see what's going on but a
computer doesn't see anything so this
would definitely not work there's ever
an easy solution to this which is just
to be a little more precise as to pollen
map is and instead of putting big fat
blobs at the middle of intersections you
put little black dots at the corners of
each face and now all the ambiguity
vanishes because you can have a precise
relation that lets you or really
function that lets you go around faces
and then the second function that lets
you go around nodes and so nodes are
defined as cycles of the red arrows and
faces cycles of the green arrows no more
mapping back to the edge of the sphere
and if you're clever enough you'll
realize that there's actually a lot of
symmetry in this and to make the
symmetry complete you need something
that characterizes edges and you do that
by filling in the diagonals of the red
green squares you had and so you have
blue blue blue arrows green arrows red
arrows that satisfy this triangular
identity and in this case the blue
arrows are always going pairs but that's
but you can drop that requirement and
that's more general structure is called
a hyper map and using the structure made
the entire mathematical argument easy
very easy to formalize in a even a
completely rigorous and fairly stupid
proof system one of the things that
makes this formalization particularly
elegant especially elegant as the fact
that really the red green and blue are
completely symmetrical and so the
criterion for describing the fact that
this is planar which is a really oily
formula comes out as something that's
symmetrical in edges nodes and faces or
as the more classical ball he drove
formula has some kind of a similar
into it and it's really nice to have
symmetry because then you get to prove
one theorem and use it in three
different ways yes a note in the middle
of the region and then I find the find
adjacent recent and I put an edge to it
adjacent regions isn't that sufficiently
bother for the coloring problem that
actually doesn't help at all because
it's it just corresponds to doing a
circular permutation in edge nodes and
faces so you actually have the exact
same combinatorial problem graph
coloring our map coloring it's really
the same it's really the same problem it
helps draw pictures because it's easier
to draw to draw graphs and maps if
you're making notes on a piece of paper
but that's the only it doesn't help the
math at all this does really it
specifies the problem you just do the
waiter said we like what you told first
bite where you have the notes for the
for the region like was just about going
that simple graph I mean that specifies
a problem but it does as far as I
understand that what are you doing right
now that helps you then improve being
what you want to prove yes for one one
glaring example of this is that the key
lemma for the for the combinatorial
proof is the one that characterizes the
relation between a configuration and the
rest of the map and the proof of that
lemma in the revised paper is this is
full or the proof is the proof is
unnecessarily complicated no one has
bothered writing it's obvious that it's
true but no one can write it and if you
do things this way then the proof is
indeed obvious even to a computer okay
so so that was the that was ten years
ago the other four color theorem and
after that I wanted to do some more
serious mathematics and I decided to
to group theory which is still a theory
of puzzle Rubik's cubes notably but it's
a little more serious it was developed
to show that certain polynomial
equations had no solutions in terms of
radicals and it got famous in the in the
20th century for helping solving lots of
interesting problems like understanding
quantum mechanics or devising good
cryptography for banking operations
there's one a very important tool in a
group theory which is probably one of
the major achievements in 20th century
and that's the call the classification
theorem so there's a rather basic
theorem in group theory that tells you
that a group can be broken down factored
much like an integer into elementary
factors clerical simple groups and then
quite importantly there's a theorem that
characterizes all possible shapes of
simple groups so for many many
properties you want to prove about
groups you can reduce them to the study
of simple groups and then you can just
go through the list and the list has
kind of four general categories and then
26 exceptions which are described in
great detail and should we just go
through the list and prove as your
theorem holes in all cases now the that
classification theorem is known as the
monster theorem it's quite famous
because it's it's proof is huge it still
hasn't been at this time it was
announced in 81 the I think the last
unpublished bits of the proofer publish
actually published ten years ago in 2004
and the proof still hasn't been compiled
into one complete text it's there's
still bits that are in various articles
and various publications and that has to
need to be pieced together
so I thought it would be a great great
challenge for computer proof sir now we
could show that we could do serious math
but actually it's a too big of a
challenge to tackle even with the
support of both enri and Microsoft so I
tried to decide to look at the first
peek of that big mountain chain which is
the odd order case so just the group
that have an odd number of elements in
this case the classification is really
simple it says that the simple groups
are exactly the Prime of the groups that
have a prime number of elements so the
internship most amount of prime
basically and but that even that proof
is very very ambitious it's 250 pages
long it uses a whole well basically an
entire algebra syllabus and we started
from nothing we had not the then we're
even at the foothills we were at the ant
hill before the foothill yeah we and and
we did it so so this uh so that's the
fire the Aurora theorem and it's usually
stated this way which is equivalent what
I wrote which is that all five groups of
otter are solvable unsolvable is a term
that goes back to gala and the
solvability of polynomial equations so
the proof has 250 pages it was a
conjecture for 50 years before it was
proved and the revised proof is pretty
much the same length and it took 20
years to come up with it and so the rice
proved did fix a number of important
gaps in the original proof so the
general proof schema the proof line of
argument in the proof was never really
put in doubt but there were parts in it
that were clearly wrong and that took
quite a bit of effort to fix so in
comparison the computer proof has this
statement which is pretty much the same
thing it's a proof that's remarkably
easy to to describe so the the statement
is remarkably easy to describe
starting from the raw logic even
defining integers and groups I just need
54 lines of code to specify everything
you need to describe the theorem the
actually proving it requires quite a bit
a bit more effort there's 45 thousand
lines of proof just for the proof itself
and it took basically two years to write
those and a lot of Pacific basically
twice that effort both in terms of lines
and time to prove all the background
theory for it so these are the two books
that contain the revised proof and what
we had to formalize was not just these
two books but basically a library shelf
which goes back from basic algebra and
has and then goes through specific
topics in group theory and and feel the
finite field theory Galois theory and
character theory so here's the graph of
the whole thing it's quite a big a big
cloud of things and each of little boxes
here is basically a course you would
find the equivalent of a university
course on a specific topic if you look
at this graph you can sort of see the
various parts the parts that are
actually part of the four-color proof
they're part of the background theory of
a fork or proof is just that little part
down here the lofty Tower up here is the
those actual to green books and the big
blob in the middle is the whole
development of basically a whole algebra
syllabus and just to just again to give
you a feel for size each of these little
boxes is a course so that Finn group or
for example is a basic course in finite
groups and this would be the syllabus of
the course justic scribing the things
are defined in there and then this goes
into all the results you want to you
want to use
and indeed all of the proofs of those
results and since the results are pretty
basic here the proofs are pretty are
pretty short so importantly the doing
all this work it gives you a perspective
on mathematics it makes you understand
very clearly that mathematics is yes
about definitions which is what the
first blue part you had describing the
things that were defined in this file
it's about theorems knowing what
properties the objects you define have
but it's also about notations being able
to describe all the objects and
concisely in a way that makes the
property apparent and also exercises
figuring out how to combine properties
in order to prove other interesting
things and so all of these
configurations if you look at it from
the perspective of someone that comes
from a software background it's all
about designing interfaces and design
components and that was the thesis of
the project i started at inria of
designing components for mathematics and
it is understanding how to do this now
to see how this works in practice here
is a real theorem a real part of the
proof so it's a rather complicated
mathematical statement and I had to jot
down a few notes just with a pencil just
to understand what this was about but
ultimately once all of the background
theory was in place you could write down
the same statement formally pretty much
in the same way this is the actual
computer input to the to the computer
system as it appears when I edit it and
not only can of course the this is you
know not just input to a text processing
it just doesn't print just print a
pretty picture it actually is understood
by the computer system to the point that
the computer system can also understand
the proof
so this is about half of the proof of
that big theorem loss of gobbledygook
this is about half of the proof in the
computer system even more gobbledygook
but there's something that a computer
system does which is it helps you write
down this this text so it actually
understands what you're doing and this
particular theorem is a big proof by
induction and if you want to understand
the paper proof you have to reconstruct
the inductive argument in your head at
all times to understand what's going on
because otherwise you will your you risk
making a mistake in what your actual
induction hypothesis is here if you run
you can run this proof to any given
point and for example at this point the
system work I have computed the
induction hypothesis is this huge thing
and so this all thing that you would
normally have to keep in your head to
understand the text in which the theorem
proving of the proof assistant keeps
track of for you now i'm going to show
you in a bit more detail how you work
approve but on a rather simpler example
so from a more basic linear algebra so
this is a basic identity that says that
a trace the matrix product commutes
under the the trace operation and the
way you would prove this in in a
textbook or if you were a student and a
computer in matrix algebra 102 would be
while expanding the definition so the
trace is the sum of the diagonal
elements then expanding definitions
again the general term of a product is a
basically a dot product of a row in a
column then realizing that what you have
to do is swap the two sons swap the out
of the elements of the Sun assuming your
ring commutes and then applying this
expansion the other way around to
realize that now what you
is the trace of the product with taken
in the other direction so easy for line
proof easy for line proof in which
basically follows the steps of this one
I guess the only main difference is that
we weave in this proof we've actually
applied a line of reasoning twice
implicitly by saying oh well we do
precise computation of what the
expansion is and then we use it the
other way around so we can to capture
that we actually not need to state that
we're going to do it so so when you run
they run it in the computer it'll first
tell you that okay you have to prove
that the trays of product one way is
equal to appraise the other way and it's
figured out the shape of the matrices on
its own then you're going to give it
this explicit step that you want to
prove that the trace of a B satisfies
this expansion which I've written down
here so it's pretty easy to read in the
original script and that's just
expanding definitions and expanding
definitions under under the some
operation so that's done in one line and
now here I've said that I want to
generalize this statement so I've
actually have here as an assumption the
same statement but for arbitrary
matrices and so now I can use it on both
sides at once and exchange the sons and
so now I'm almost done my proof because
I just need to apply commutativity which
is this lemma here under the under the
iterated sums which is done in one line
and my proof is done and I've proved my
theorem so that's how you do proof and
so in the the pieces that go into making
this proof work are I guess another
triad so you've got part of the job
that's done by the logic and the part of
the logic does is
so it lets you prove the lemmas and the
theorems and what the logic does is it
provides you types so it makes sure that
the computer understands what kind of
objects you're working with and when
you're using operations what those
operations ought to be and you're lemmas
and functions they will define what the
types that you define what the types are
and lets you package bits of computation
and bits of reasoning and then you have
the language for describing prove that
lets you invoke the packages and then
control how they how they work together
and the way this is all implemented is
by using the computation in the logic so
the very feature that was used for the
four color theorem is now being used
just to make the math work together so
here's a little more and this that and
this works even in this very basic
example it's actually crucial so even as
a very basic example used sums and I was
casually using some underscore I and so
on and this is something that's very
important if you're doing algebra so I
call those big operators because this is
what you get when you type biggest
something in latex but the difference
when you do this in is that
actually understands what you're saying
so this which pretty much looks like the
delay tech input for this is actually
the really understood by the system as a
lightness formula 44 determinants and
even in something as basic as defining
the trace there's quite a bit of
machinery to make sure that the logic
and the notation the visible notation in
the underlying logic agree so this is
the definition of the matrix trace in
the system pretty obvious sum over I of
AII
but if you look under the hood at how
this this works out then quite a bit you
see that the system works quite a bit
for you so the first thing it does of
course is get rid of the ASCII art this
is really a generic big operator so
where is a generic big operator well
it's basically a nap my produce so
you're you're mapping this function
which comes from the general term of the
Sun where the eye is the name of a bound
variable over this list and then you're
reducing using this operation in this
operation so the sum is just hiding the
fact that you've chosen to reduce with
addition in zero and the fact that you
have when you left the bound unnamed
that means that you're somehow getting
enumerated all elements of the type so
to make sand and the sugar coating
syntax has lots of gaps in it and the
gaps are going to be filled by type by
type inference also by the type checking
algorithm and so the first thing type
checking algorithm does is realized that
ok this is a matrix matrix isn't a
function so we can't really apply a
matrix two indices so what you have to
do is insert this coercion so this
interpretation that has you interpret
our matrix as a function which is
basically the indexing function of the
matrix and that's going to tell you to
two other things one is that this I here
has to be since this is an n-by-n matrix
this has to be the type of midna sees
ranging from 0 to n minus 1 and the
second thing is that the return type
here is going to be the type of
coefficients of the matrix now we get to
the business when you're saying what
these operations are because
this is just saying oh yeah some
addition operation which addition
operation well that's going to be
described by another interface which
describes basically algebra and so it's
very standard and algebra textbook has
this telling you that okay well you have
rings and rings are a special case of it
you have a whole hierarchy of structures
ring are a special case of additive
groups adding a multiplication operation
and then you have things on top of rings
like commutative rings that add
commutative property as well as the
other actions of rain or unitl ring that
has a unit and invertible elements and
so on and then complicated things like
vector spaces and algebra and f algebra
and morphisms on those things so in this
case we're just using something very
basic we just have a ring and want an
addition operation now the addition
operation is defined not in the ring
structure but in the parent structure of
the said module structure and so really
this is interpreted as okay the addition
operation of the present mode you'll
projection of this this ring type
structure that's fairly straightforward
type inference however there's still a
gap here for what you're rearranging
over so how do we get the list of
indices we're going to use for the
reduce operation for the MapReduce well
that goes back to much more basic
structure and so you in that stack of
algebraic structure you at the bottom of
the stack you had much more basic
structure that are purely combinatorial
so one thing you might have a need for
example is a comparison operation
there's no built-in comparison operation
because in mathematics especially
constructive map I thinks you don't
necessarily have a way an algorithmic
way of comparing objects so there's
going to be a structure that going is
going to give you that operation and it
were an interface if if you prefer and
so for example that interface obviously
is defined in terms of boolean because
we will return the result you're
returning is boolean it's also
implemented by bullying us because you
can compare billions you can compare
integers you can compare lists of
comparable things and so on and then
what the structure that's going to
interest us is a slight refinement of
this which says that you have which is
just gives you an explicit enumeration
of your type so it gives you all
possible values and so the definition of
this of course depends on lists and this
structure is going to be implemented by
the type of indices because four indices
you have actually have a list of all
entities from 0 to n minus 1 and
interestingly this structure is the only
structure that you need to prove the
four color theorem so that's that's
about as deep as the as we start that's
basically what we started from when we
started this at the project on group
theory so if we now fill this in well
the much the type of inference is has
enough guts to it that it can use a
figure out that it has to use the finite
type structure for the the indices to
fill in the gap here and so now you have
a complete logical description of what
you meant by this simple expression and
you can understand why the system would
be completely unusable if you have to
describe this type in this explicitly
all the time we have no chance
whatsoever to do any kind of interesting
algebra and prove any really interesting
theorem there's a little more to it you
to make this proof work you also had a
generic theorem that was used to
exchange the two summations and if
change iterated operations which is just
exchanging the reducer you need basic
monoidal properties you need the
operation to be commutative and
associative basically and you have a
bunch of these generic lemmas and what
they rely on is another set of
interfaces and this time there are not
interfaces that are based on types that
are not probably interfaces that give
properties of types their interfaces
that give properties of constants so
they tell you that the addition of a
ring is commutative and associative and
indeed there are implemented every which
way so if we to summarize the big
operators in terms of definitions they
just use lists and bullion's in in terms
of interfaces they use they might use
the finite interface to get an implicit
enumeration so you don't necessarily
have to always specify what you're
reiterating over and in terms of prove
you having general emma's are going to
use a different set of interfaces to get
the properties of there that are needed
for the operations and these interfaces
are going to be implemented generically
for all the algebraic structures so
there are many more mathematical
components in the end the project and
covering finally grew a lot of them on
finite group theory obviously character
theory one I'm the ones I'm most proud
of are the last ones that cover linear
algebra because there was actually a
problem I actually had a problem
understanding how to code up linear
algebra in a formal system in a way that
was usable traditionally there to sort
of two schools of the new algebra the
the french european school that
has does is based on abstractions and
how so it has an axiomatic description
of what vector spaces and then there's
the u.s. tradition of doing using almost
exclusively matrices and depending on
what you're doing you might prefer one
or the other matrices are great because
they let you compute things explicitly
and they're also great because they have
a notion they're very concrete objects
they have a specific shape and you all
can often reason about just the shape of
the matrix vector spaces are nice
because you can they let you they have
all kinds of definitions for aggregating
specific sets of a vector zin two
subspaces and this very important
concept of dimension now as it turns out
if you're studying group theory one very
important thing in in groups is to use
group representations which lets you
interpret groups as groups of matrices
because then that lets you pull in all
kinds of arguments from linear algebra
into your combinatorial group theory
another important tool in studying
groups is group characters which are
just the traces of representations but
the character is ISM cells form a vector
space and as it turns out when you are
using group representations you really
want to be talking about matrices and
matrices only you want to don't want to
go back and forth between matrices and
abstract vector spaces if you're using
characters you don't almost never want
to see the the matrices and there's a
well-known way of going from one to the
other wife if you're in an abstract
space you fix a base and you pick
coordinates and that gives you
everything in terms of matrices and if
you have matrices and you want to get
abstract spaces well actually there is
another operation operation that goes
other way around which is to consider
the row space of a matrix so matrix can
actually be interpreted as describing a
subspace rather than just a function or
vector and going back and forth around
these using these these bridges to go
back and forth the two interfaces of
linear algebra was one of the very
important tools in both making group
representation and group character
Theory workouts for us one another
reason for presenting this is that this
was probably one of the cases where I
push the concept of interpreting
mathematical notation formally to it's
the farthest so mathematicians are very
fond of abusing notation and they're
quick to say that of course this has no
meaning whatsoever in logic now lots of
notational abuse can be encoded using
interfaces or just it's just the fact
that managers have no training in
software engineering so they can't
recognize that what they're doing is
type inference or components but even
things that don't don't look like
they're made of interfaces and
components can be translated so one is
one salient example is the notion of a
direct sum of subspaces and in linear
algebra so the traditional way of
describing this is saying okay I have a
social space that's the fine as a son
and I'll have a statement somewhere in
the middle of my proof that say oh well
that some is direct if you have a direct
sum of subspaces then that means you
have a unique decompositions as a very
powerful combinatorial property but if
want to prove that something is direct
then it's is actually boils down to a
very simple numerical equation it's just
saying that the dimension of the sum is
equal to the sum of the dimensions and
we can capture that exactly in in
so we can write down this property
saying that being we can define a direct
predicate in such a way that we can
characterize the prayer the predicate as
the rank of the of the of the sum is
equal to the sum of the rank and we can
actually use this in definition so we
can write down a definition saying okay
I'm defining the sum of the v's as the
Sun as subspaces of all the visa buys
and then state a theorem that says that
that some is direct now that doesn't
since V here purposely define the
subspace saying the subspaces the rack
doesn't mean anything what what happens
behind the scenes is that this very
mechanism that was used to just resolve
overloading for the in the trace example
is now used to to really quote look at
the actual definition of this of this
expression here and say something about
how this definition is written out and
having this being able to talk about
direct sum is absolutely vital to doing
reasoning in linear algebra especially
when in this case where this is about
freezing about I can I can space
decomposition okay so so that's for the
the interface in notation I have a few
things to say about proof so you saw a
big ugly proof
earlier on that translated to an even
bigger and uglier proof so there this is
usually how it happens the the formal
proof tends to have more indications in
it than the informal one because the
computer is quite adamant at not getting
any any gap being glossed over however a
few cases where the computer proof is
better and those are in their ability
cases that involve using algorithmic an
ocean so one of the one of these cases
is this pretty clear proof which
involves recurrences so a series of
groups defined by some inductive
relation and so in this case having a
logic that supports a notion of
computation in which you can talk about
algorithms as first class objects lets
you define the recurrence once and then
have the logic use it automatically and
that means that where this proof has to
spell out explicitly each time the
recurrence is being used the computer
proof can just use it automatically and
so you have two pages of obscure math
that are translated into one page only
of obscure computer proof here's another
interesting example so this is the final
part of the fight Thompson proof which
is otherwise known as a scaring ly
complicated relations and a generator
argument so you have these very
complicated algebraic expressions that
basically basically telescope one
another and the only way of explaining
the telescoping in the authors found is
to write down this hugely complicated
expressions with upper braces and lower
braces to explain try to explain what's
going on
fact it's very easy if you just if
you're just able to write definitions
and and functions to explain how this
telescoping work and this means that
this entire proof and in fact there are
two pages behind them translate as just
again one page of code and that's just
because we've been able to describe how
the telescoping works rather than
expanding it in four different places
and of course there's these the proof by
reflection which we had in the four
color theorem which doesn't occur much
in the the fight thompson proof of the
RO theorem but there is one place where
it does occur where one is trying to
prove properties about vector addition
systems and so there's this very
complicated combinatorial argument and
it's really a in the four color theme
you have basically SAT problems and mold
checking problems this is a base
basically an smt problem so it's a
something that involves both logic and
computing with basically dot products /
integers and the best way of solving
this is to use an smt solver and indeed
the best way of doing this is to program
a little specialized smt solver and
and then use it and if you do this then
you can really use this entire these two
pages into again one page of argument
have the system do not wave your hand
about what how a spirit clear statement
is proof because you actually have a
decision procedure that does the work
for you and indeed actually lets you
understand what's going on this
combinatorial argument and realize that
a third of it is absolutely useless it's
just the sort the same thing as being
done twice because the author hasn't
realized there was a symmetry there
and lastly whenever you're doing
verification work in computer in
computer science you're always asked
while did you find any bugs after all if
you're verifying something is to find
errors so if you doing that the
understanding what's going on is
actually a lot more important but still
you might want wonder after 20 years of
revision there might not be any bugs
left so there aren't any there weren't
any serious bugs but there were lots of
little ones so the variation wasn't
totally useless and probably the
quaintest of them is this wandering typo
error so I said the proof was a revised
proof was published as two books that
are about four years a four-year gap
between the two publication so the first
book prudently had a summary of all the
important results so for example and
section 15 there this complicated
theorem who's a tenth conclusion has all
of these facts and some of these facts
are incidental and some of them are
important and are included in the
summary so here the relevant part of the
summary and you have to be quite
eagle-eyed to realize that in the
summary the H has turned into an M so I
didn't spot it it was only when I tried
to enter inside the computer the other
summary that the COPE you told me no
they proved that the summary follows
from the other things you've proved
isn't obvious there's something some
some place where it doesn't match it's
the wrong letter so of course typos
happen in books it's a no no big deal
but what makes this one fun is that the
second tome of the proof prudently
starts with a summary of the previous
results of the first book that are
actually needed in the proof for the
second book
and lo and behold if you look at the
summary of part 2 or summary of the
previous episode the M is still there
Yeah right right there and the only
saving grace is that actually there's a
double error because even though the
book of the preface says that the things
are in the summary all things that are
used this part is actually not used so
two wrongs make a right and well I guess
that's a that's about it so things you
can look forward to is with all this
technology we now know pretty well how
to verify computer computations we know
how to verify complicated proofs even
ones that professional mathematicians
consider to be complicated the rough
wisdom is that you need it takes a
trained mathematician a year to
understand the the order theorem proof
so it's not too bad it only took us two
years to to work it out it's the systems
of these systems support safe
collaboration between people with
various backgrounds and it's quite
important telling that none of the
people that work with me on this project
were mathematicians so we were all
learning this stuff as we went and the
computer kept us straight and actually
was you in several places could actually
explain to us complicated notation which
we'd forgotten about and and they're a
source of inspiration because they
actually left there actually a pretty
good tool for exploring refactoring
reorganizing proofs and the even the
proof of the our theorem is sink
significantly better factor than the
revised text in in several places
because of this okay thank you very much
George so I i have a question i
understand you know work was the
mathematician some very prestigious ones
in collaboration can you tell us a
little bit more about that are they
starting to use a theorem provers a
and SS reflect what's the nature of
those collaborations ah so they some of
them are using SS reflect some of them
are using straight i guess the the
most famous mathematicians are the
people that have been trying to use
to do very complicating things in
algebraic topology notably of vladimir
wolski who got his fields medal for
inventing some weird field called
motivic homotopy and he realized that
the mask he was doing even though he was
probably one of the top mathematicians
around but he got things got to the
point that he didn't understand whether
what he was doing was wrong or right and
he realized that there was a very very
neat embedding of his theory inside the
logic of which actually has also
consequences for the for the the
underlying logic it's not that actually
gives gives a whole back to the the
formal system
and quite famously they recently got a
rather generous 7.5 million dollar grant
from the DoD to pursue this project in
pure mathematics yeah so what's the
story on the challenges to more computer
scientists and mathematicians using
kalkan informal caregivers and
particularly for us PhD students we're
where we might be able to use it in our
own work arm on is there perhaps
something we should wait for or should
we all go ahead and read the software
foundations book you probably if you're
going to work in theoretical computer
science you probably should quite a few
papers quite a significant fraction of
submissions to main conferences now come
with computer proofs and the reason is
partly the verification part that
referees got sick and tired of waiting
through pages and pages of bland
arguments about about subject reduction
and figured that they wanted to read
about the interesting stuff and not have
to check those bits the part of it is
that the people that do this find that
doing the formal proof actually helps
them understand what's going on in a way
that scribbling things on
four or five notepads doesn't this is
taryn costume which lie in your proof
but we love it they are correct I mean
oh word sure that the tool you use is
not messing up basically because many
people work with it so the huge
difference between my proof of the four
color theorem and the one that had been
done before is that the previous proofs
relied on the correct operator the
correctness of specialized software
whereas the the my proof really relies
on the correctness of the logical kernel
of a proof system so you don't really
rely on all of the proof system all of
the part that interprets the notation
does a type inference and so on or even
interpret the proof script doesn't
impact correctness because there's a the
only part that impacts recognize the
part that implements the logic and all
the work that goes into building your
proof goes into working the part that
doesn't impact correctness so there
there may be a bug in the implementation
of the logic it's very unlikely that the
bug would let you prove something wrong
if you weren't trying to exercise it and
more important and importantly if these
bugs will get corrected and your work
will still be valid because you'll just
rerun it under under the new the new
system so it's as experimental evidence
but it's very good experimental evidence
in fact it's much stronger experimental
evidence than running your paper through
referees ok thank you very much nothing
left to close the session now we could
peps you can take other questions
offline now each year Microsoft Research
hosts hundreds of influential speakers
from around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>