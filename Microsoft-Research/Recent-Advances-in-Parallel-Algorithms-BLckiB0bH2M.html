<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Recent Advances in Parallel Algorithms | Coder Coacher - Coaching Coders</title><meta content="Recent Advances in Parallel Algorithms - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Recent Advances in Parallel Algorithms</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/BLckiB0bH2M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
welcome everyone for the session on
recent recent advances in parallel
algorithms traditionally parallel
parallelism has been has gotten a lot of
focus since the 70s and the 80s and it
still continues to be an active area of
research and in this session you know
our goal was to actually bring together
some of the recent work that's been
happening on how we deal with
communication irregularity and breaking
dependencies and so our first thought
today is by gray Ballard
he is from Sandia National Labs in
Livermore and he's he recently graduated
from University of California Berkeley
working with Jim James demo on
communication avoiding algorithms and so
it's going to be talking more about that
great thanks very much so before the
talks that um I forgot to mention that
you know we're going to have a more like
a conference style session so three
talks twenty five minutes with five
minutes of Q&amp;amp;A so hold on to your
questions till the very end and since
this is recorded you know even though we
can hear you hear it we prefer that you
actually ask your questions when there's
a micron or with you so that it's record
their questions are recorded properly
I'll remind you again at the end of each
talk
thank you okay thanks thanks very much
for the invitation to talk so I'll be
focusing on parallel algorithms for for
the dense linear algebra and I'll talk
about what I mean by avoiding
communication so a high-level summary of
what I'll tell you first communication
is expensive and I think you probably
are all convinced of that but but not
not just can expensive in terms of time
but but also energy and I'll tell you
what I mean it by avoiding communication
so for for algorithms like dense linear
algebra and sparsely algebra in related
computations we can actually prove lower
by lower bounds and and tell you how
much communication you have to have to
do if you want to solve these problems
on a parallel machine and this
theoretical analysis these these
balance that we get in theory that help
identify where the state-of-the-art is
is not yet optimal so identify a gap
between the best algorithm and and the
best known lower bound and those gaps
exist and we can start to work and see
if either the lower bound could be
improved or better yet we'll get a we'll
get a new and better algorithm and I'll
show you some examples that when we do
get these new better algorithms in
theory we can translate it to two tuned
code that gets that speed ups in
practice and when we come up with these
new algorithms often we have to be
careful so sometimes they require
careful tuned implementation for
particular architectures to get
performance often there are trade-offs
that you need to be able to navigate
sometimes you trade-off reduce
communication for more computation for
example and then also these are
numerical algorithms and and you have to
be very careful about the numerical
properties of the algorithm so sometimes
changing the algorithm makes it run
faster but you have to make sure that
you're still getting the correct answer
or the the accuracy that the computation
deserves okay so that's the high-level
summary and I thought I'd start with the
one of the one of the most fundamental
computations for linear algebra and
that's dense matrix multiply and dense
matrix multiply is very well studied and
very well tuned and so start off with a
question can we improve this computation
that lots of people have worked on many
different machines so so I'll show you
performance plot to start and and this
is a strong scaling performance plot so
along the x-axis I'm increasing the
number of processors processors we're
using and this is on a big gray super
computer along the y-axis is performance
so up is good and I've got one curve
shown and this is scale of pack this is
a standard library that people use on
machines like this and and the the other
line I'm showing is a dotted line for
the Machine peak so this is the best
that any classical algorithm could do
and so for this strong scaling plot if
you see a flat line that means perfect
strong scaling and so this actually this
code looks pretty good because it's it's
strong scaling perfectly but there's a
big gap between the performance and and
the peak performance of what you could
hope to get and so I'll just show you a
second curve with a new classical
algorithm it does exactly the same
computation but the
formas is much better the difference the
the way we get this better performance
is all in reduced communication okay so
the big speed up to a standard problem
by improving the communication
properties of the algorithm returns out
classical algorithm for matrix multiply
is not the best you can do you you're
probably aware of an algorithm by my
strossen from a long time ago and you
you could try to parallelize strawsons
algorithm it reduces the computation
that you do and for on the left side of
the plot for a few nodes you can
actually get better performance by using
strawsons idea but it turns out that
once you scale up to large numbers of
processors on this big machine you start
to lose even to the standard scale fat
code but but most recently we've we've
come up with a new algorithm a new way
to paralyze strawsons idea which gets
much better performance so comparing the
red curve and the blue curve the
computation is is the same it's both
using strawsons idea but because we're
very careful about the communication
pattern we minimize communication with
the algorithm we're able to get much
better performance than the old parallel
versions of Strawson and we're able to
beat actually the best that any
classical algorithm could do okay so so
the difference in the red and the blue
curves there between the green and the
black curve is all based on
communication communication matters all
right so so let me just be a little more
specific i've been talking about
parallel machines where communication is
sort of clear it's it's an messages sent
across the network between processors we
can also think about communication on a
sequential machine so the standard model
a first clincham machine is two memory
levels where you have a slow memory
think of main memory DRAM and fast
memory is like a cache and we're
concerned with how much data we move
between that link where all computation
happens with data and fast memory and
the distributed memory model is probably
more familiar so communications
happening over a network
okay so communication is is moving data
and when we analyze algorithms to sort
of figure out if they're the right ones
to tune for our architecture we can use
these high-level models to get at a
basic model of their runtime so the
runtime model that we want to think
about includes both computation and
communication so
the standard where to think about
algorithms is just to count how many
floating-point operations how many
arithmetic operations am i doing
but the more accurate model especially
on today's machines you really need to
take into account the amount of
communication the amount of data
movement that's happening so we can do
that with counting number of flops to as
units of computation and counting the
number of words as units of
communication so if we have some cost
forward some cost per per flop we can
get a gross estimate of our running time
with these two terms and so the takeaway
here is beta this is the cost of moving
a word it's often much much bigger than
the cost of doing a floating-point
operation okay so that's that's been
that's been the case for a while but
actually these these costs are both
improving but at very different rates
and the gap between beta and gamma is
increasing exponentially okay so you you
probably know that in in terms of time
but but it's it's also true in energy so
here's some here's some data to support
that so if we look at the annual
improvements in time of flop rates and
this is over the last fifteen years much
due to Moore's law and and more recently
due to multi-core nodes and compare this
this improvement of about sixty percent
per year with improvements in bandwidth
to DRAM bandwidth across the network
those are closer to 25 percent per year
so so a big difference in how quickly
these are improving so even if if your
algorithm isn't dominated by the
communication this year and in a few
years it likely will so that's time but
also if we look at at energy in this
plot at the bottom this is actually
taken from data for for excess scale
planning so in this plot there's several
different operations that your machine
might do and I'm not on the y-axis is a
measure of energy so so the blue curve
is sort of where things are now and the
red curve is projected but what I really
want to point out is the comparison
between the three operations on the
right and these three operations here so
these are all correspond to data
movements so accessing a word from a
register is or from one of the levels of
cash is orders of magnitude cheaper in
terms of energy than accessing DRAM
which is the
first column or accessing data across
the network okay so if you want to you
want to save energy you want to access
data and close button and not across
your network okay so so big big
differences in time and but we also see
big differences in energy and as that
becomes more of a constraint devising
algorithms that minimize communication
will help keep down energy costs okay so
so let me go back to matrix
multiplication and sort of look at it at
a high level and see if we explain the
performance that we saw on that first
plot okay so I'll use in for matrix
dimension P is my number of processors
and in there's gonna be my metric of how
much local memory I have so I'm thinking
about a distributed memory machine where
each processor has m words of local
memory so the scalar pack algorithm what
I'll call a 2d algorithm if we look at a
computation it does n cube flops
divided over all P processors and the
communication scales like N squared over
the square root of P ok well there's a
known lower bound for parallel matrix
multiply and if you do this these n
cubed flops then the lower bound is
given by this expression so it depends
on the matrix dimension the problem size
and also the size of that that local
memory okay so so you don't have to do
the comparison your head basically the
2d algorithm is is suboptimal if you
have a lot of extra memory so if your
your local memory size is much bigger
than N squared over P N squared of P is
like your fair share of the matrices so
if you have a lot of extra memory lying
around that means this 2d algorithm does
more communication than necessary okay
so as I showed with the the green curve
on that first plot a new algorithm which
is called 2.5 D matrix multiply comes up
with a communication cost which matches
the lower bound okay so it's it's
optimal if if you don't have any extra
memory if you have extra memory around
it makes efficient use of it to reduce
communication but the basic takeaway
with this optimization is that there's a
trade-off to be had if you can use extra
memory efficiently you can reduce the
communication that you do and get better
performance so if the memory is just
lying around you use it and it doesn't
it doesn't
I heard anything to use it and you can
get your answer faster okay so that's
the sort of high-level theoretical
analysis just to show you a little bit
more data to support this so here's a
plot with with a fixed number of
processors and two different problem
sizes we're comparing the two D
algorithm that's like scale back to the
2.5 D algorithm and now the y-axis is
time so down is good and so so the big
takeaway is looking at the red parts of
these of these charts so the red
corresponds to communication going from
the 2 D algorithm to 2.5 D algorithm you
cut down the communication by a huge
amount and that cut downs your overall
run time and in this problem so this is
an 8,000 by 8,000 matrix multiply across
16,000 nodes it's very small and I
compared to the size of the machine and
maybe a more realistic matrix size is up
in the hundred hundred thousand range
but even here the the overall speed-up
isn't isn't as impressive but if you
look at the red curve now the cut down
is about an order of magnitude okay so
so this performance point is coming just
from not changing the computation
changing the algorithm to reduce the
communication okay so so let me tell you
little bit more about the lower bounds I
mentioned for for dense matrix multiply
they've been around for for a while so
if you do the classical algorithm on a
sequential machine then in the lower
bound is given by this expression so
this is proved back in in 81 and it was
later expanded to the distributed memory
parallel case and that's that's the one
I showed you before and and and so if
you do classical matrix multiple have
these lower bounds you have targets for
for your algorithms and for these these
sort of high level machine models we've
got optimal algorithms both for
sequential and parallel cases okay so so
that's nice for matrix multiply and and
what we've been excited about is that
these lower bounds can be extended to a
very general set of computations so let
me give you a precise theorem if if it
computation smells like three nested
loops and it must communicate by by this
expression okay by three nested loops
I'm thinking you can write matrix
multiply with code that is the the three
nested loops and and if your computation
looks enough like that three
nested loops where you can write matrix
multiply then this lower bound will
apply now it doesn't matter if so matrix
multiply is smells like three nested
loops it doesn't matter if your matrices
are dense or sparse lower bound applies
and applies to our high level machine
models both sequential and parallel so
so that's nice I haven't really been
specific about what smells like three
nested loops and why this is exciting so
let me just give you a list of things
that smell like three innocent loop
loops it's it's mostly it's most of
direct linear algebra so if you know
about the basic linear algebra
subroutines they all smell like three
nested loops algorithms that you use for
for solving linear systems so cholesky
lu decompositions things like that they
smell like three nested loops this lower
bound applies QR decomposition released
squares problems and other things I can
value SVD reductions so even sequences
of algorithms of these types of
computations and even some graph
algorithms that are similar enough to
linear algebra okay so so we have this
lower bound which can be written really
simply just in terms of the number of
flops that you do and the amount of
memory you have but but the sort of
theoretical lower bound is nice but what
really gives it power over really gives
it the utility is that it's a target now
for for all these computations we have
pretty good algorithms that that
implement and solve these problems we
can ask now are they are the
communication optimal or are they
hitting this lower bound or can we do
better and so that's what we've been
working on for the past a few years and
we can start to classify all these
things so I'll just give you a little
bit of an overview but we can look at
each of these computations so the Blas
cholesky factorization Lu and QR and se
are their algorithms out there and that
achieve them or should we work on and
try to improve and so I've put some
references on the right side and so you
can sort of tell by the years that in
some of these cases there are some some
existing old algorithms which which are
good and the theoretical sense and then
there are some more recent years showing
out that that shows some of the
improvements we've made more recently
and so this is the sort of stories for
the squinch case parallel case gets a
little more complicated but we can start
to do the same analysis say ok for all
these computations are we optimal yet or
or do we need to make improvements so
let me just highlight a couple of these
computations so suppose we have a linear
system to solve our we're solving ax
equals B and our matrix a is symmetric
but it's indefinite so it has negative
and positive eigenvalues if it were
definite then we could run a choice key
decomposition and we have vision
algorithms for that okay we're
indefinite which means we need to worry
a little bit about numerical stability
and we need to do some symmetric
permutations so what we want to solve
this problem is to get a factorization
that looks like this
Soapy's a permutation matrix so we'll do
some symmetric permutations along the
way but we'll get a factorization looks
like ltl transpose so L here is is lower
triangular and T say it's simpler
so so once we have this factorization
solving this system ax equals B should
be very cheap okay so the standard way
of doing this is that that T matrix in
the middle that simple guy
it looks like a block diagonal matrix
with one by one and two by two blocks so
LD L transpose D is this block diagonal
matrix and that's sort of the standard
way of doing things that's what's in the
standard libraries like lay back the the
problem is it communicates its a
suboptimal how we're going to
communicates too much and trying to make
an optimal algorithm out of it seemed
quite hard so the pivoting is sort of
complicated we couldn't really see how
to make you for that so we went back to
another old algorithm that was devised
by Austin and and his middle matrix T is
tri diagonal so it's a little more
complicated than just one by one and two
by two block diagonal matrix but it's
still simple to solve the problem with
this and it turns out that you can take
this algorithm which so here's a picture
of the matrices T is now try turns out
you can make a sort of block version of
this algorithm which is is communication
efficient and and solves the problem in
an optimal way okay so I won't go into
the details of the the block version of
the algorithm but basically ideas we we
had to go back and find an old algorithm
which sort of fell out of use because of
the
good properties of LDL transpose but now
that this has become more communication
bound we were able to update this old
algorithm with with communication
optimizations and get better performance
so let me just show the performance this
is on a shared memory machine so now the
parallelism is on one nodes this is on
48 cores and this is a performance plot
varying the matrix dimension along the
x-axis and performance along and whacks
and so so up is good
Laidback is a standard algorithm for
doing this and and the new algorithm
which which has much better
communication properties is is getting
much better performance in practice ok
so that's that's a one computation that
that we ran across with lower bound
applied and existing algorithm wasn't
optimal and and we devised a better
optimal algorithm and ensured that that
the performance improvement in practice
reflects theoretical improvement ok so
let me give you another quick example
this time coming from a video
application so so suppose you have a
surveillance video and what you want to
do is subtract the background out of the
surveillance video so you can really get
at the action going on its other but
robust PCA algorithm was devised to get
at this and and and so the basic idea is
you take your your video and each frame
you you make you unfold it into a column
of the matrix so each column the number
of rows and your matrix is the number of
pixels and a frame and the number of
columns and your matrix is the number of
frames and what you want is a
decomposition additive decomposition
where L is low rank it corresponds to
the background and s corresponds to the
action so in this case people walking
around ok so so the algorithm is
iterative but basically all the time
goes into this thresholded SVD
computation and the matrix because there
are a lot of pixels in each frame and
not that many frames is really tall and
skinny and so if you want to do SVD of a
tall and skinny matrix you always start
with a QR decomposition so basically all
the timing this goes into the QR
decomposition of a tall skinny matrix
and and that's one of the the classic
examples of of an old algorithm which
communicates too much and a new
algorithm which really reduces
communication by a large amount and and
so we implemented this communication
avoiding algorithm on the GPU
and comparing the best GPU version of
the old algorithm to our our new GPU
version of the communication voting out
and we got we got good speed ups okay so
this helps speed up the entire
application because because all the time
was spent in this QR decomposition so
here's sort of a least squares problem
another example finding a new algorithm
and showing implementation improvements
in practice okay but at the finish I'll
talk I want to go back to matrix
multiply and and and so the question is
is can we do better than the 2.5 D
algorithm I mentioned so I told you it
was communication optimal there was a
lower bound it reached the lower bound
can we do any better and and what I sort
of didn't mention explicitly is that
lower bound really assumed that you're
doing the classical algorithm for for
matrix multiply so if we change that
computation we do something like Strasse
and that lower bound doesn't apply
anymore so that means if we do Strawson
can we can really reduce can we can we
now beat that lower bound so let me
remind you about strawsons algorithm so
the basic idea is if you have two by two
matrices and you want to multiply on
Strawson show that you can do that with
seven multiplies instead of the
classical eight so here's the classical
algorithm the left side there's eight
multiplies you do and then you add them
together to get your output matrix
Strawson shows you just taking these
weird combinations of entries of a and B
you do 7 multiplies take a weirder
combination of those 7 multiplies and
you get out your output matrix ok but
but the beauty is you use this idea
recursively and if you solve this
recurrence for how many flops you do you
get this in which is the matrix mention
race the power log base 2 of 7 so that's
about two point eight one important
thing is two point eight one is less
than three so that's great that means
you can multiply on matrices and fewer
floating-point operations
but as I've been sort of saying this
whole talk we really care about how much
communication you do so what happens if
you implement strawsons algorithm on a
sequential machine and you do it in a
straightforward way you write it
recursively let's let's look at the
communication cost so okay classical
algorithm does n cube work in Strawson
does into the log base 2 of 7 if you do
the communication analysis you see this
exponent 3 showing up in
classic algorithm and that exponent
becomes log base 2 of 7 for first rasam
so just as we're reducing computation
here asymptotic I mean in the exponent
we're reducing it for the communication
as well so this is kind of nice
this is a win-win it's that it usually
doesn't occur I mean usually you have to
trade-off computation communication or
something like that but here you get to
reduce both with this idea okay so this
guy's excited I mean if we want to
improve performance let's let's use the
algorithm that does less computation and
communication but first I mean this is
just one way we just wanted to write
this recursively on a sequential machine
can we do any better than this I mean as
this communication cost as good as you
can do for strossen so we worked on that
problem found that yes that's as good as
you can do on a sequential machine we
can prove a lower bound
it looks really similar to the classical
lower bound but the proof is quite
different but that you get this this
lower bound and on the sequential
machine you get a similar lower bound
just divide everything by P for the
parallel machine and so then we in the
sequential case we have a nice story we
have a tight upper and lower bound so
the next question to ask is well do we
have a tight upper and lower bound in
the parallel case and and so we started
looking because people have worked on on
paralyzing Strawson before and it turns
out that all the early attempts to
paralyze Strawson were suboptimal in
fact some of them actually increased the
amount of communication that was
required and and so because there
existed this this gap we had a lower
bound but not an optimal algorithm we
worked hard on coming up with with a new
algorithm we call the communication
avoiding parallel Strawson and let me
just give you the the sort of high-level
idea of the algorithm so so Strawson
works recursively and and and basically
the parallel choice to make is that when
you generate these recursive subproblems
so seven in the case of Strawson you
want to decide whether you assign each
of the seven problems to a disjoint set
of processors and so we call that doing
a breadth-first search so you doing all
sub problems at the same time or do you
assign all the processors to the first
subproblem finish that and then all the
processors second sub-problem finish
that and that's what we refer to as a
depth first step so there's two sort of
basic questions of how you
curse the the recursion tree of strossen
and and turns out you want to take a BFS
step whenever whenever possible it
reduces communication to do that but the
trade-off is you pay extra memory and so
that's okay I mean if we have extra
memory lying around I don't mind using
that to decrease our runtime so you got
to be careful about how you how you do
this at every recursive level but but
that's how we got the performance that I
showed on the early slide so this this
red curve is the Cape's algorithm and
it's beating this blue curve which does
the same computation because it's it's
much more careful about the
communication pattern okay so let me
just finish with the question that okay
so we we looked at the classical
algorithm we got an optimal
communication algorithm and we said can
we do any better so let's just do the
same thing in the Strawson case we have
an optimal Strawson algorithm and it
matches the communication all around can
we do any better and and you guys
probably have have known that there are
there are many improvements to the
exponent of matrix multiply that have
happened over the last 3040 years and
and so here's a plot showing that so
this is years along the x-axis and
exponent on the y-axis so the class of
exponent is at 3 Strawson in 1969 show
that it was 2.1 so there's a bunch of
improvements here some of them even
recent even though the slope of this
line over 20 years is very shallow it's
still an important improvement so why
don't we start benchmarking these guys I
mean what are the communication lower
bounds for these guys and and so
unfortunately a lot of these aren't
practical algorithms so Strawson is
practical I mean I showed you we're
getting better performance in practice
but but not all these guys are practical
for various reasons maybe I won't go
into them now but not all of them are
impractical not all of them are only
theoretical and and maybe we can't get
the exponent 22.3 right now and remain
practical but we can have modest
improvements in the exponent and still
remain practical and furthermore
strossen really prefers to have square
matrix multiplies so it wants to divide
things evenly and and there are many
algorithms that work better for
rectangular matrices so if we can make
use of those then then we can actually
do better than Strawson so these are
some some
very recent results were working on this
right now but here's a performance
supply this is a sequential machine and
the black curve is is Intel's math
kernal library which is a very efficient
implementation the classical algorithm
the red curve is Strawson and so even
for small matrix dimensions so these in
hundreds strossen can show a performance
improvement but these other algorithms
which are sort of encoded with numbers
like 3 &amp;amp; 4 which are already beating
strossen for these shapes so it's
possible to beat Strawson these guys
actually have better communication
characteristics in theory and so we've
got some initial results to say that
yeah we can make them practical and and
our parallel implementations of these
algorithms are underway ok with that
I'll think many collaborators on all
this work we also had a finished recent
very long paper for act in America so if
you can wade through 150 pages there's
there's lots more details if you're
interested and and with that all thank
you very much sure I think we need to
use a microphone I think she's coming
very nice Jean I have a question your
first matrix what about 10 to the 5th
right I always tell my students in
scientific computing that matrix
multiplication for large dense matrices
doesn't occurs on your theoretical
result do you know any applications
where you get matrices hey even of size
10 to the fourth
I'm not even ten to the fifth why are
there such applications so there are so
so there's some computational chemistry
applications that have motivated some of
this work you can still make the
argument I mean so so people are
multiplying they're in the form of
tensors but they're doing a matrix
multiplication of of this size you could
argue there's some structure in those
matrices so there they're dense but
there might be other ways to to avoid
doing these big dense mammals but but
that's what they're doing right now and
and so that's that's one application we
might be able to help by coming up with
with alguns like strossen it's 10 to the
fifth
and you've need 10 to the 10th elements
where where do you get the 10 to the
10th elements inside the application
well if you multiply matrices of order
10 to the 5th that means are 10 to the
10th element in the matrix where do you
get 10 to the 10th elements so I mean I
think the they correspond to
interactions between orbitals of these
small chemical systems those numbers
come from Oh some some sort of integral
relationship I'm I don't know the
details of how they they compute them
because I find that hard to believe that
you're dealing with matrices of size 10
to the 10th for real applications
that's my question ok afterwards ok sure
sure
hi does the stress an algorithm have
longer critical path than the classic
metric multiplication algorithm is this
a problem for the scalability of these
algorithms when they extend it to many
machines thank you sure so the critical
path is not longer so all these
subproblems are completely independent
so that's nice there are some additions
to be done and some of the optimizations
of strassens algorithm involve a few
more dependencies so those those can be
a little bit of a hindrance but but if
you only do a few steps of Strawson
before switching to the class four
algorithm usually doesn't get in the way
what is the state of the outturn
irregular our algorithms problems so I
think still andrew sunder if I answer
that question so I think I think Adriel
spend a lot of time on irregular
applications one last question
so once you've divided up the problem in
recursive algorithms you need to have a
base case of what's good granularity for
the machine how does that granularity
interact with the recursion right so so
are you thinking more on one node or in
these big distributed systems so if you
have a either multi-core or where you
have local caches or a distributed
system where you have memory and local
caches how do you decide the granularity
at which you stop the the dividing it up
and doing the recursion that's the first
question and then does that granularity
affect the scalability and the
parallelism at the second granularity
because these systems are all big and
complicated right right so a lot of that
depends on the performance of the
classical code that we call so so if we
have an Intel machine and we're using
mkl at the base case it's we decide that
empirically based on
the performance of the different base
case sizes and then does that choice and
then my second question is does that
choice affect the different ways to do
the partitioning does it change the
shape of the problem at the higher level
or do you like because they're
rectangular not square is it is it of
influencing how you divide up the work
right so yes that will happen so for the
big distributed systems we haven't tried
these rectangular algorithms yet so I
think that will complicate things for
strossen it doesn't really matter
they're sort of they're sort of stuff
everything's square thank you this is
really interesting work thank you so the
next speaker is going to be Andrew and
Hart from UT Austin so he is a
researchers research associate in case
of Vinales group there and he's the
primary implementer of the the Galois
system which is what he's going to be
talking about right now
he graduated from UIUC working with
Professor Victor mafia sensor okay so I
am going to talk about something
entirely different almost from what we
just saw which was classic regular
algorithms so going to this question
about what do irregular algorithms look
like right now so I will spend some time
on that so this is kind of the required
slide for all these kinds of talks which
is parallelism is everywhere and I'm
gonna be very fuzzy about what that
means right now but well but basically
what I mean is it's exposed to the user
right in the high end we've seen this
for many many decades going back to the
60s but now we're at the point where
your phone someone programming the phone
needs to be aware of parallelism to get
good performance right it's now the
second most important thing to get your
performance on these machines over using
your cache well right so that that leads
to the question how how
parallel programming tools evolved over
the years and there's been a lot of work
and there's a very mature theory
involving in the compiler realm
involving data dependencies and now
various static analyses for things like
matrix multiply that do very well
they're at the point that any good
compiler you get is going to implement a
reasonable subset of them and these
these are focused very much on very
classic HPC algorithms which look like
Triple E nested loops or doubly nested
loops now once you start saying I need
all my algorithms to be parallel a lot
of algorithms don't look like that all
right they don't use matrices or vectors
they use sets hash tables trees and
these static methods really start
falling down once you're exposed to
these very complex more complex
irregular data sets where you can't
predict what's going to happen often
until you've already read your data all
right so I'm going to talk and talk
today about the Galois project which is
a project we've had going on for five or
six years now which is looking at
parallelism not from kind of a loop
centric computation standpoint but from
a data centric standpoint I'm going to
focus on parallelism but you can use the
same kind of analyses the reason about
locality and we do and I'll talk briefly
about our implementations on multi-core
system so I'll talk about up to large
scale Numa systems GPUs various other
accelerators we have work going on in
hybrid and distributed memory so I won't
touch on those very much but you can ask
about them if you want so let's consider
kind of the classic approach we have
right now in compilers which is focused
on these HPC examples so here there's a
very simple for for clarity finite
difference that computation right so
what are you doing you have two arrays
and they represent two timestamps and
your up your computing a new timestamp
from an old time stamping you're looking
at the value of an array element and its
neighbors and maybe you're computing how
heat is transferring between that
discretization of your surface and your
computing a new value the key thing is
these two arrays are
completely distinct the compiler can
prove you're writing to unique locations
in the new array the other array is
read-only that's easy for the compiler
to prove as long as it can prove that
two arrays are separate but that's a
whole different compiler realm and once
it does that it has basically it
basically can do arbitrary restructuring
of this loop introducing parallelism
optimizing cache locality using the
mature theory but let's consider a
slightly less regular algorithm which is
the lonny mesh refinement this is also
actually an HPC usable algorithm people
use this and what you do is you take a
triangular mesh and in this mesh some of
the triangles are gonna be misshapen
they're gonna have very they're gonna be
very narrow so they're aspect ratio
doesn't lend themselves to numeric
stability so what you want to do is you
want to take those triangles and replace
them with better shape triangle so we're
gonna do is we're in read them we're
gonna read a mesh and we're gonna look
at all the triangles in the mesh put the
bad ones
these misshapen ones in the work list
and we're going to go over the work list
pulling a triangle out finding some
data-dependent area around it replacing
those triangles with new triangles some
of those new triangles may also be
misshapen and in which case we're gonna
put the misshapen ones back in the work
list and we're going to keep going until
we run out of bad triangles and at least
in 2d under certain constraints this is
guaranteed to eventually happen now if
we think about the classic parallelism
we would look at the sloop and say okay
what data dependencies exist well every
iteration reads and writes the work list
which already means it's a serial loop
and there's no parallelism but even if
we ignore the work list you can't from
this loop say what triangles touch other
triangles
whereas what iterations are independent
from other iterations there's no data
for that until you've actually loaded
your graph right so the compiler can
basically do can do nothing here because
it doesn't know what the mesh is going
to look like and the problem here is
this is a computation centric view of
parallelism but if we actually look at
what's going on so on the top left I've
marked the bad bad triangles in a simple
mesh in red they're triangles that you
need to look at to be able to replace
those red triangles and just intuitively
looking at this all of those retro
will should be able to be replaced in
parallel because the data each data each
computation needs doesn't overlap it's
independent but you're not going to
discover this looking at actually
looking at the body of the code so we so
we were so we're going to look at a data
centric view of parallelism oops wrong
direction all right so here here's our
data centric view of parallelism it has
several components the first is what we
call an active element if we're gonna
think about parallelism from a data
perspective the question is where do you
need to do computation and where you
need to do a computation if Mark didn't
marked in red on this graph so in DMR
where you need to do computation is a
bad triangle in sssp where you need to
do computation is a node to which you've
changed the distance label on all right
so it's an algorithmic dependent
property but it's just a general notion
of where should we actually do
computation the next question is what
computation should you do this the
programmer has to give right so in DMR
the computation you have to do is to
search the search the local area of a
graph collect a set of triangles replace
them etc this is what we call the
operator it's the code the user wants to
actually apply to the graph now one
thing we don't know because in this
irregular realm is what data you're
going to touch right so in DMR you touch
a data a input value they this specific
region of the graph it's not just your
immediate neighbor triangles it could be
hundreds of triangles it usually isn't
but it could be and we call this the
neighborhood of the neighborhood of an
activity right it's the data you need to
perform your computation there are many
there are many kinds of algorithms but
they fall in generally into two
categories
so DMR is an example of an ordered
algorithm you can replace triangles and
in any order you want you doesn't matter
how you process them you will get
correct triangulations out of the
algorithm single source shortest paths
there are algorithms that have this
property to their fixed point algorithms
right some orders might be more
efficient all right Dijkstra's is a
particularly efficient order but other
orders will get you the correct answer
eventually right so for correctness we
don't need to
about the order for performance we might
but then there's other algorithm say
you're doing like a billiards billiards
ball simulation or discrete event
simulation same thing the order you
process things in is critical to the
correctness of your algorithm so these
are two classes of algorithms so I'm
gonna talk about unordered for the rest
of the talk
order it's a another complexity and once
we have this view of our computation
this leads to a notion of what we call
any morphus data parallelism right as
long as we respect the ordering
constraints on the work that needs to be
done if the neighborhood's don't overlap
we can execute things in parallel all
right so there is a there is one
neighborhood I've highlighted for one
particular activity this one here
overlaps that guy so they can't be done
in parallel but maybe these other two
are perfectly parallel right so we can
run three things at once but we don't
know that we can run those three things
at once until we actually load the graph
and look so when one thing you have to
consider is where do you introduce
parallel is parallelism in your code
right so the classic methods are trying
to do static parallelism you look at the
code
maybe parameterised on the size of your
matrix you parallelize your loops and
you can do that because you have all the
information you need at compile time but
for something like a graph you actually
need to know that what the graph looks
like
so think about something like BFFs if I
have a very branchy graph I have lots of
parallelism right because I can do lots
of paths on the graph in parallel if I
have a straight line
there's no parallelism at all so I may
have to actually load the graph load my
data first and look at it to figure out
what parallelism exists
BFS or SSSP are simple because I can
look at the code and tell you if you
give me a node you're just going to
touch your immediate neighbors in the
graph something like DMR doesn't have
that property you don't know what data
you're going to touch until you start
inspecting the various coordinates of
the triangles with respect to the
triangle you started with so there you
actually have to discover the data you
need to use
for each task and you could you could
for example discover all the all these
neighborhoods computing interference
graph execute a parallel independent
subset of that there's also various
approaches of with speculation which I
won't talk about so we have a particular
implementation of this view of
parallelism we call the Galois system
and this is really trying to get very
simple to program system for for your
typical programmer right our goal is so
that your normal programmer can write
correct parallel code without being
exposed to things like synchronization
we do this in a very similar way to
languages like SQL you have you have a
simple front end and then expert
programmers deal with all the complexity
and translating and translating to
actual machines so what does gawa
concretely it's essentially it's a
library of concurrent data structures
and it's a runtime system that optimum
optimum is discovers parallelism deals
with conflicts between tasks when
they're running discovers these and
execute code to the normal programmer
they write in sequential c++ so we
actually provide a serial a serializable
x view of their of their loop and
they're not exposed they're not exposed
to any synchronization and we do this
without transactions but that's a whole
nother talk right so your typical
programmer can just stylize a for loop
use our data structures in they'll gate
they'll get a correct parallel execution
all right so what does the Galois
program actually look like this is kind
of about the simplest you can get Galois
is the C++ framework we declare a graph
in this case it's a compressed sparse
row representation it has data of type
struct data on the node there's no data
on the edges it's directed graph we
write our operator as a C++ functor now
if I were redoing this slide that would
be a lamb
because they're much nicer too right but
this is a very simple this is just going
to go over take a note in the graph it's
gonna take get the data on the note it's
gonna take that particular field add one
right it's just a toy example but
there's no restriction on what data you
can access as long as you can reach it
through the data structure if you want
to touch every node in the graph feel
free if you want to touch your neighbors
that's fine if you want to do some
random walk great and then we just have
a stylized loop here that takes some
things to work on and executes them it's
we use a dynamic test models so
operators are free to add more work to
the work list at runtime there's a whole
domain specific language for scheduling
which I'm not going to talk about so
there's there's a lot there's a you know
there's a bit more to a good Galois
program than this but this is a good
minimum example now given that we're
doing all of this stuff for the
programmer can we actually get good
scaling in performance and the answer is
yes so here is an SGI ultraviolet this
is a large Numa machine each each blade
has two boards each board has two
packages of eight cores each connected
by internal network running through
SGI's directory controllers between
blades you have another torus of
connecting those directory controllers
right so this is a classic this is a
classic me my machine and here we see
scaling for some graph analytics and
more HPC like algorithms of 50 to 80
percent of 512 cores and so this is
non-trivial scale now you might say
scale itself relative scaling is easy if
you start with a bad baseline so
hopefully if you want to read the table
you can suffice to say that the
baselines we're starting with our
competitive or better than handwritten
so we're starting with decent baselines
I said we've we've had a lot of work on
implementing on these on GPUs the
execution strategy is fairly different
from what you need for a CPU but if you
do it right the latency masking on the
GPU lets you get very good
implementations assuming your problem
fits if your problem doesn't fit we've
been working on that and some hybrid
execution - you know swap in and out
parts of the graph I won't show any
results there yet we have compared to
other graph analytics frameworks this is
an area where there's lots of work right
now in this more narrows area of graph
analytics so on the Left we're comparing
to a couple of graph analytics
frameworks like aura and paragraph
paragraph is a distributed version of
graph lab and the key takeaway here is
that these are frameworks that restrict
their restricted programming models you
can you can write to a node and you can
read your neighbors and you can only and
that prevents you actually from writing
the most efficient algorithms we know
for some of these problems like for
connected components you can't do path
compression because you you know it's
not expressible in the dsl so having a
more general programming language
actually lets you express better better
algorithms to solve some of these
problems than some of these other
frameworks you might ask what if we fix
what if we fix the algorithm how do you
do on the right basically what we've
done is we've taken the benchmarks
provided by these other systems wrote an
API shim so that we could use our run
time with their API and there you see
that for parallel graphs which is the
top top row they do pretty well but once
you start getting high diameter graphs
like road networks or planar graphs the
performance concerns you have to take
care of change considerably right so if
you're over optimizing for parallel
graphs you might do very poorly on these
other classes of graphs exactly why this
is going on going on we could talk about
after if you would
now that was our comparison you don't
have to believe us
there was an Intel study recently
published the left bar the left blue bar
is where Intel threw some engineers over
the course of six months or so at these
problems and wrote hand-tuned
implementations and the far right bar is
what we are shipping written by a couple
of graduate students right so more or
less using there's some small there's
often a very small performance hit from
having all these automated things
happening for you in the runtime but
it's very very competitive with
handwritten code and often you know much
better than the competing frameworks
right now hopefully they will get better
now that just says that you can take our
code and the benchmarks we've written
and get good results unbeknownst to us
someone wants someone some people at
Berkeley went and downloaded our
downloaded our framework which you can
do to implemented their FPGA place and
route tools and without any hints or
performance from you no hints from us
they didn't talk to us they also could
get you know very good scaling right so
this is a very different class of
problems and it's quite applicable
so in conclusion think think about
parallelism from a data centric view
don't think about having to preserve
loop dependencies where that's just a
construct of how you solve the problem
rather than what's something inherent in
what your algorithm actually needs to do
so we think about parallelism data
centrically we have a particular
formulation we like we have what we
think is very good implementation that
has scale to very very large machines on
top of on top of this implementation
we've been doing various work in
domain-specific languages so can you
express graph algorithms as a simple
rewrite system there is a working but
not yet optimal or released distributed
memory system where you can take the
same source c++ source recompile it and
get a distributed memory application out
of it essentially because we
already mediate the data structures in
Galois already mediate access to data so
if there are distributed data structures
the code that uses them doesn't have to
change we have a lot of work as I said
on hybrid executions CPU GPU Intel fees
distributed heterogeneous that's all
work in progress so you can feel free to
go download the code try it yourself we
have some benchmarks both CPU and GPU
irregular benchmarks if you are
interested in doing work with the
regular algorithms you need a
non-trivial benchmark set by all means
review some of our benchmarks and read
some papers thank you any questions
thanks I great talk so you said that at
the beginning that you you're talking
about parallelism but you could talk use
this for locality as well yes so I'm
very interested in locality and the one
difficult thing I see is that the
locality basically depends on the data
structures which often you don't know
until you read in but when you read in
you often have put them in memory which
may be what you didn't want to do or
want to do a different way so I'm
curious how you handle locality yes so
you you're not you're not gonna get good
scaling on the new machine without
dealing with locality we don't we don't
alleviate the need to express a
partitioning if your data is
partitioning ball if you have a
partitioning of your data we can lay it
out in the particular machines memory
correctly and we can do scheduling of
tasks based at least on where they start
in memory so we can preserve locality
that way all the data structures are
numa numa aware so they are aware of how
the memory banks are laid out between
the cores and they you're not gonna have
nodes in its edges on different memory
banks for example and we're gonna
schedule tasks from from the right
cores beyond that there's a question
where something like DMR where you're
recursively producing tasks there's
temporal locality you can exploit and
that's a property of what order you do
tasks in so this is actually one of the
reasons why we have a language for
expressing scheduling policy so you
would tell us I want something that
looks kind of like of a local life oh
right the taps I just generated should
have should be done first because I know
that if I do them first I will get you
know higher locality which is the exact
schedule that serial code Henrich and
serial code uses for that problem so you
just want to make sure that if there's a
particular schedule for your algorithm
that's good because it captures locality
or because it captures algorithmic
improvements
you know reductions and algorithmic
complexity that you can express that to
the runtime and that we have good
implementations of that have you
developed any understanding which
resembles what the prior or talked gave
about the relationship between the
communication need especially when you
have a very regular layout well things
can really be messed up relative to the
best we can do and whether sometimes we
run into situations where you can do
very little somehow I was looking for
some understanding at the level of the
prior talk and I didn't see any any
Theory here or any any analytical issue
yes communication optimality is really
going to depend on your particular
application
alright the runtime doesn't know these
things now the runtime itself is very
very communication aware so all the
internal structures like the work lists
are aware of the communication costs
between themselves and other threads and
we do a lot of kapala G aware
optimizations there but we can't tell
you for so we can't tell you for a
particular algorithm what the minimum
communication cost is because we're not
you know that's that's not the layer of
the stack
we're writing at so if you if you know a
particularly good way of executing your
algorithm for communication we we hope
that you'd be able to express that using
combination of data layout and
scheduling but we can't automate that
because that's per application thing so
you view it as something which is beyond
scope for your walk it's something it's
something where if you know if you know
what it is for your problem you should
be able to express it in this language
and internally where we do where we do
have things like barriers or work lists
we've we've optimized that as best we
can according to communication
minimization okay my other question is
what is the difference between what you
call a amorphous parallelism and the
walk depth outlook that was developed in
the parallel algorithmic communities in
the 80s there is a term called walk
depth parallelism which you can find in
any textbook on parallel algorithms and
the question is is there any difference
between that and the amorphous
parallelism that you describe
okay let's thank the speaker
so I'm your third speaker so I'm modern
Maserati from Microsoft Research I work
in a in rice which is a resurgence of
engineering and recently I've been
interested in parallel algorithms
especially trying to paralyze algorithms
that look sequential so this is a slide
you know that we have seen in Andrew
stock like hardware is parallel so
there's parallelism all around starting
all the way from you know FPGA is to
your phones to the may I mean I knew
amount of Allison we have in a data
center but there are a lot of algorithms
which are sequential right think of it
like the 99% of the algorithms which are
not able to make use of all the
parallelism that we have and we would
like to somehow you know try to see if
we can make use of all the hardware
parallelism in order to make these
algorithms go fast so here is my
motivating problem
I want to grep terabytes of data in
seconds so why is this problem
interesting I'm going to argue that this
is a Quinton's quintessential big data
problem where you have lots and lots of
data in arcane unstructured format and
you would like to be able to parse them
and look for patterns you know look for
useful patterns and in many cases you
don't even know what patterns you're
looking for so you actually want an
interactive system where you can try out
different things and the system will get
back to you in seconds so that he can
refine look at the answers refine and
then you know a try again and we like to
support something like a very rich query
language like what we're used to with
grep right like a regular expression
language where you can ask different
kinds of queries and the basic problem
is that you know if you have
terabytes of data and you're trying to
read it sequentially from the disk it
can take hours right and so the only way
in which you can make the system
interactive is to use Aria parallelism
take this data distributed along law and
make numerous disks like make thousands
or ten thousands of disks and do your
computation in parallel so in that sense
if you want interactivity or force to
use parallelism but the problem is that
all the implementations of grep that I'm
familiar with right they are sequential
they are based on like building a finite
state machine that processes the input
one byte at a time right and so you can
there's no way you can do a grep you
know within seconds and this is sort of
has been our one of the motivating
problems and this talk I'll try to show
how we can go about trying to paralyze
these sequential computation so first of
all I'm going to like to take a few
steps back and look at why some
algorithms are difficult to paralyze its
profits because of these sequential
dependences let's say you are doing some
computation F which is producing an
output which is which G requires in
order to operate to produce an output
for H and so on right so you have this
computation where there is a sequential
dependency and you in order to do this
computation in parallel you need some
way to break these dependencies and we
know of many instances where you know
you can you can paralyze despite these
dependencies a simple example is let's
say if every block here is adding some
numbers right since addition is
associative you could break up the
dependencies do things out of order and
then put them all together right now
what I'm going to tell you is something
very surprising which is that you can
find an associative operation in any
computation for example if you look at
this you can think of this as a function
composition right you're applying the
function f then you're applying G then
you're applying H and then I and
function composition is
associated right so at least in theory
there's a way to do things or in out of
order and paralyze them so let me
explain this by focusing on just one
sequential dependency let's say we have
s producing an output that G requires
and you want to break the dependency
right so what I'm going to do is that I
want to be able to run G in parallel
with F but I don't know what input to
run G with because that input is
generated by F right so instead what I'm
going to do is I'm going to assume that
G is going to take some symbolic value X
I don't know what it is but I'm going to
treat it as a symbolic value and then do
this computation symbolically right and
so what I would get is a simplified
expression that tells you what the
output of G would be given a value of x
right now once I do this and I'm going
to do this in parallel while F is
computing the value right once I know F
output I can essentially plug it into
this formula to get the output of the
entire computation right so this is
another way of saying that oh I can take
function composition and then it's
associative and do things out of water
and this is not you know a new thing
people have known this for a very long
time since the 70s and 80s and in fact
if you look at the way your adder works
in your hardware the carry look ahead
adder you can think of that algorithm to
actually do addition efficiently as an
instance of in applying this idea okay
but at least for me right
I used to whenever I would see this
dependencies I would just there would be
a mental block which would say oh this
is that means I cannot paralyze it by
looking at it this way it sort of
release this mental block and now I
though so essentially in order to
paralyze some competition I have to
solve two problems so first problem is
can I actually do this symbolic
computation efficiently right because
I'm actually G's running symbolically in
parallel while F is doing the its
regular computation so the symbolic
competition better be really fast and
the second thing is is there
simplification achievable so that
evaluating you know substituting B in
that formula is actually more efficient
than running G in the first place right
so these are the two problems that I
would like to solve and what we have
done is like looked at several instances
of algorithms where we have taken this
idea stared at it and you know it came
up with algorithms that could do both of
them efficiently so so first we looked
at finite state machines so this was
motivated by the grep problem where we
actually have a regular expression
engine that is actually data parallel so
we can make use of any kinds of Paris
immed at it can throw others so
including instruction level parallelism
so that's why we are actually three
times faster than the sequential
implementation on a single core and we
get linear speed ups beyond that and
we've also applied two classes of
dynamic programming optimization
problems like Viterbi and you know I can
safely say that we actually have the
fastest software with Derby decoder and
the reason why I'm very I can
confidently say that is that we actually
took previously the world's fastest
software Viterbi decoder and used it at
a black box to actually add additional
parallelism and get linear speed-up
beyond that implementation so if you if
you if you have another implementation
which is faster then we can actually
paralyze that as well so we actually
linear based on any sequential
implementation that you could give us
and we can actually the our software
decoder can beat a commercial FPGA
implementation in terms of throughput
where are the implementation is running
on CPS
so I'll give a dig deeper into each of
these two problems and first focus on
the finite state machines and you know
finite state machines are like it's a
fundamental aspect of computer science
or lots of applications I already
mentioned grep then the other thing is
like tokenization let's say you want to
you know parse HTML web pages or another
interesting application is Huffman
decoding so the way Huffman decoding
works is that you have a decoding table
that you're looking up on everybody to
find out how to decode your input and
since you have a fine
dictionaries finite state you can
actually encode that computation as a
finite state machine and you can use our
algorithm to paralyze it so I'm going to
start with a very simple example of a
finite state machine so this is a state
machine with four states that accepts C
style comments right this is just for
demonstration purposes and what happens
is that the way you implement a finite
state machine is that you actually have
a lookup table something like like this
right and you start from the initial
state and what you do is that for each
input you look up the table to find out
what the new status so the new state
depends on your current state and the
next input character that you read and
this is I mean if you if you look at
this example there's hardly any place
where we can exploit parallelism right
because of this dependency between this
state in the previous iteration to
compute the state of the current
iteration and even the loop is not doing
a lot of computation you're just doing a
seek sequence a series of memory lookups
so there's highly any ILP to to actually
use in this example and so we're going
to use this technique to break the
dependency here and
let's say how we can do this okay so
let's say I have a sequence of input and
I would like to paralyze it on two
processors p0 and p1 okay now for p0
it's very what I can do is I can
actually start from the initial state
and process one byte at a time and do
your regular computation but the
question is what I'm going to do for p1
right so remember the example I said
before right so we're going to start
with the symbolic state the nice thing
with finite States is that you can you
can do this for all you can do this for
all execution by explicitly enumerated
all possible finite states of this
finite state machine right so in our
case we have there are only four states
so B what we can do is like essentially
run the finite state machine for each of
the possible initial States right so
there are four ways and so you will run
it for all possible four states now one
thing that you might say is that you
know why do you want to do with all four
why can't we just guess and maybe we'll
just speculate on and by looking at
staring at the finite state machine and
say okay maybe it's most likely to be a
right the the starting state is most
likely to be a and so let me just do
speculate for just that state the
problem with that is that you might be
wrong and if you are wrong you have to
throw away your computation and then
redo from the correct state but we can
avoid all that by actually doing this
for all execution because there's no way
there's no way in which there's no miss
speculation so you don't have to go back
in time now the one problem with doing
that is that you know you are doing four
times more computation than the
sequential version right so and so
whenever we are paralyzing these
constants actually make a big difference
so imagine you have a state machine with
hundreds of states right and if you're
parallel version is 100
I'm slower than the sequential version
then you will when we get a suite up of
two on 101 course which might not be
very practical so we have to somehow
come up with a way to optimize these
constants away from your algorithm and
and that's where our key contribution is
in trying to come a figure out ways to
hide these constants in these it is
algorithm and one thing that I've done
here is actually colored the states so
that some redundancy is actually visible
in this computation so if you look at
these two states C and D on reading a
star they both have both of them happen
to go to the same state okay so what
this means is that the rest of the
computation starting from here and here
are going to be exactly the same and so
you don't have to read an early repeat
them right so what you can do is that
you could sort of remove one set of
computation saying that you know what C
and D go to D and so there's no need to
repeat the fourth computation you can
also do the same thing with with in that
in the second step as well so so as you
can see you started with doing four
times more computation as a sequential
version but you dynamically looked at
how these states converged and you use
that idea to actually reduce the amount
of computation that you're doing and we
have found that essentially like if you
the ultimate the cost of doing this
enumeration is proportional to the
number of unique states not the number
of states in your final state machine
and what we have found is that for many
finite state machines that you you get
in practice they have enough structure
that there's a lot of convergence in
these finite state machines okay and
here's a graph that demonstrates this
so what we did is that we actually
looked at around 2700 regular
expressions from us not a bad benchmark
of regular expressions called snort and
for each of the regular expression we
converted into a finite state machine
and we found out that input that
actually is the worst case input in the
sense that it causes the least amount of
convergence and this is the this is the
worst thing an adversary can to to our
algorithm and what
what does graph plow plot is on the
x-axis we have the input length as
generated by this adversary and on the
y-axis the proportions of finite state
machines that converge to less than 16
states is the black line less than equal
to eight stages the red line and less
than or equal to four States is the
green line right so the high level thing
is that as you increase the input many
finite state machines actually converge
right so some of these state machines
have us as higher like thousands of
states but they converge to a very small
number very quickly okay and so just to
highlight some to two points here right
90% of these finite state machines
converge less than or equal to 16 States
just after 10 steps right and but
interestingly only 65% of them converge
to less than or equal to 4 states right
so even after 5,000 steps so what so
just the high-level point being that
there is a lot of convergence but not
convergence to 1 right so we need to
converge to 1 in order to be compete
competitive with the sequential version
right in order get near linnaeus speed
ups but it's but we can reduce the
constants from very large numbers to
somewhere between 16 and 4 ok which is
something that's reasonable and so what
we did
we actually used vector instructions to
hide this additional constant so that we
are competitive with the sequential
version and so this graph shows our
performance of the parallel algorithm
when we are hiding these additional
constants in Cindy and I'm actually
hiding a lot of details between the two
slides here because we worked a lot on
trying to get the simply version two to
perform really well so again what this
graph shows is for randomly selected I
think two hundred and fifty regular
expressions and on the y-axis we have
the speed-up the sequential speed-up
over the baseline the speed-up over the
sequential baseline and as you can see
for many regular expressions we are
actually three times faster than the
sequential wordly this is because since
you know we are we are parallel we can
actually process multiple bites at the
same time so we are able to make use of
instruction level parallelism and that's
why variable we are much faster than the
sequential version and but there are
some finite state machines for which we
are slower and you know so we are like 4
times up to like four times slower than
the sequential version but we can hide
that by actually scaling to multiple
cores and here you see the the speed-up
of a technique on being to organization
which is again a finite state machine
and we get near linear speed ups on on
multi-course okay so now I'm going to
quickly I just have five minutes but I'm
going to quickly go over how we apply
this technique to apply to dynamic
programming so there are many
optimization problems where which can be
phrased as trying to solve a done in
terms of dynamic programming and you
know - the best way to think about it is
that you have a table and
you want to fill up these tables with
values and there's a formula there's a
recurrence equation that will tell you
how to fill up a particular entry if you
know but the values for previous a set
of previous entries the many
optimization problems that can be
phrased this way two important things is
like with Derby and DIF which is trying
to find the longest common subsequence
of two files and again if you look at
these these recurrence equations usually
you can group these cells in two stages
and as I have done so in the Viterbi
algorithm each column is a stage and in
IND if each anti-diagonal as a stage the
night the way I've group this is that in
order to compute the values in a stage
you act you only need values in the
previous stage and you can actually
there is parallelism within a stage
where I can compute all the values in a
stage in parallel but what we are
interested in doing is that you know if
you look at the sequential computation
where I'm computing one stage after the
other I somehow want to break the
dependences across stages because you
want to get more coarse grained
parallelism by which you can split the
table in multiple cores or multiple
machine and compute them separately
despite dependences okay and you know we
can our algorithm works when the
recurrences of a particular form so I
will not go into the details but the the
basic idea is that with our restrictions
we can actually phrase the optimization
problem is finding a shortest path in
some graph for example in this graph
what each of the cells is going to be a
node and they're going to be edges
between the different cells where
there's a there's a weight on each of
these edge and you try you're interested
in finding the shortest path from this
node to this node here okay and so let's
say I want to do this computation in
parallel and I want to split the table
at this point
right now the problem here is that I
don't know where the shortest path is
going to intersect this boundary here
right so in this case it happens to go
through this first node but it could be
on any one of these nodes and so we
actually again use our idea of like the
for all computation where what we do is
that split the table into two parts
compute all the shortest paths from the
source to all the nodes in the boundary
and the shortest paths from all the
boundary nodes to the destination and
once if I can do this computation in
parallel then I can actually put them
together to find out the shortest path
between the source and the destination
and essentially what I have done so it's
also just extending this if you want to
do it on you break it break the table
into multiple pieces I essentially have
to solve the all pair shortest path
problem from the big the left side
boundary to the right side boundary and
that again the overhead is proportional
to the size of the stage right because
I've converted the sequential version is
doing the shortest path problem and the
parallel version is doing the the all
pair shortest path problem and we
actually have some techniques to
actually reduce the computation of the
all pair shortest paths and the basic
intuition is that if you if you are so
let's say you look at a road network and
you're trying to find the shortest paths
from all pairs on the west coast to all
nodes in the East Coast and the the
intuition is that the road networks you
know have some structure there are going
to be these highways through which the
shortest paths have to go and there are
only a few ways to go across the
Cascades and the Rockies for instance
and there are like there only few
bridges across the Mississippi right so
all this structure is going to mean that
many of the shortest paths will actually
converge to to cross these are these
bottleneck points right so so this is
the same intuition but we are actually
seen in practice as well so this is
actually doing the shortest paths in
a particular instance of finding the
least common subsequence of two DNA
sequences and as you can see if you want
to find the shortest paths from all
points here to all points here they seem
to be going through this particular
instance here and so we actually use
this structure to do the all pairs
shortest paths as efficiently as the
single source shortest path and based on
this technique we actually get really
good speed so this is the speed-up over
a software Viterbi decoder on multiple
cores and as you can see we are getting
very close to a linear speed-up so that
with that I'm going to conclude so I
demonstrated how we can break
dependencies in classical algorithms in
order to get parallelism and the basic
idea was to use some kind of dynamic
convergence properties in the finite
stage we use the fact that many states
converge to the same state on reading
input and for the dynamic programming we
use the insight the fact that you know
this all perish shortest paths actually
go through these small bottleneck points
and the interesting question is can we
actually apply these ideas to other
algorithms that might be interesting for
example we've been looking at parsing
and can we actually do context-free
grammars parsing in parallel can we
apply these ideas to graph algorithms
and so on and one thing that we are also
very interested in see if we can
automatically paralyzed by breaking
these dependences so currently we are
doing it manually and we hope in the
future we'll be able to come up with a
sophisticated compiler technique to
generate new parallel algorithms so with
that I conclude and I'll be happy to
take some questions
so my objection to what you are doing is
that you seem to be desperately trying
to convert every algorithm into a divide
and conquer yes why is that a bad thing
problems are not inherently there there
is no inherent general purpose structure
which will always allow you to do that
okay it's in the case of some specific
problems like yours maybe if I meant to
say that I like your dynamic programming
problem is also next what you're going
to do is matrix multiplication right I
mean right so I'm interested in
improving the class of algorithms that
we can paralyze correctly and so I I'm
not trying to take every computation and
try to paralyze them but my hope will be
that there's useful
algorithms that we need this additional
parallelism for and we can come up with
algorithms for those computation and so
as I mentioned about grep it'll be
really nice if we can apply if you have
a grep like tool that can parse and find
patterns and petabytes of data in
seconds and I think that is it's an
important problem in practice we don't
have a parallel algorithm and it'll be
useful them that's why this this area is
interesting right but you're right I
don't want to make all our cordless
power right I mean I wish I could but
but you know there has to be I mean if
there's a good application for that it
problems interesting
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>