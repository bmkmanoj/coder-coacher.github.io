<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GNM2013: Learning Equilibria of Games via Payoff Queries | Coder Coacher - Coaching Coders</title><meta content="GNM2013: Learning Equilibria of Games via Payoff Queries - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GNM2013: Learning Equilibria of Games via Payoff Queries</b></h2><h5 class="post__date">2016-08-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rGgXncXYUEE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
right so welcome back our next talk is
going to be by Rho Sevani from the
university of liverpool will be talking
about learning nash equilibria of games
using payoff quarries over to you thanks
a lot thanks to the organizers for the
invitation told you to be here so this
is joint work with John fernley paul
goldberger Martin Goering so it's it's
about applying ideas of query complexity
to game theory and in particular finding
Nash equilibria so the motivation some
rough motivation so games of practical
relevance might be very large and
obtaining or maintaining a represent a
trip of a full representation of the
game may be costly so the basic
challenge here is to find at colibri a--
with only partial knowledge of the
payoffs so for as an example consider a
routing game where you know the network
but you don't actually know the latency
functions on links in the network okay
so some related work so actually what
inspired us to do this work was a talk
by Mike Wellman he came to Liverpool and
talked about empirical game theoretic
analysis where he basically had a
simulator for limit order book markets
and another simulator for for ad
auctions and essentially he was wanted
to study what good strategies would be
in these particular domains and he did
so by actually using the simulator to
generate payoffs and then solve the
resulting games and so he basically
asked the question is there is there a
theory of how many of these type payoff
queries we need to be able to find
equilibria there's also history of
studying best response dynamics for
example in potential games which can
actually be thought of in this query in
this query setting since what you're
actually doing is for a particular
strategy profile you're asking what
payoffs are and what payoffs would be if
you switch to some related strategy
profile and then actually switching if
its profitable there the dynamics are
intended to capture decentralized
behavior say for example individual
players locally improving it's not
completely decentralized in the sense
that you normally assume synchrony
tissot one player updates everyone knows
what that player does and so on but it's
meant to capture these decentralized
settings that's quite different but with
what we're going to do we assume that we
have a centralized algorithm that
chooses queries and tries to find equi
lib riya with few queries okay so I
think we can place the work with in
general framework of looking at
constrained algorithms for finding
equilibria so some very natural
constraints that people have looked at
in equilibrium computation uncoupled
algorithms which means that essentially
a player is only using her own payoffs
to make decisions without knowledge of
other players payoffs communication
constrained algorithms we're actually
players start knowing their own payoffs
but not the payoffs of others and there
is a cost associated with communicating
payoffs and oblivious algorithms which
actually only query the game for very
specific types of questions like is this
strategy is this particular mixed
strategy profile an epsilon equilibrium
for example okay probably the the the
restriction we know best is a
restriction to polynomial time
algorithms where when we're asking can
we find an epsilon Nash equilibrium
what's the best epsilon Nash equilibrium
we can find we mean what's the best
steps on Nash equilibrium we can
confined in polynomial time and in
general studying these types of
constraints when we can actually prove
lower bounds or in
possibility results they inform us about
what a successful algorithm needs to
actually do okay Neen so what do I mean
by payoff query complexity I mean that
we have some class of games G so in this
talk we're going to consider congestion
games and strategic forum games and we
have a particular solution concept in
mind we're going to consider both exact
measure colibri ax and approximate nash
equilibria and then we say that the
query complexity is the smallest n such
that there's an algorithm a that given n
payoff queries to a game can find a
solution to G what I mean by a payoff
query is you tell the querier specifies
a strategy profile and finds out the
players payoffs for that particular
strategy profile ok then so note that
this imposes no computational bound on
the algorithm so in principle we could
have polynomial query complexity but
actually you need to use exponential
time given those queries to actually
find the equilibrium and also note
naturally but it's worth stating
explicitly that queries can depend on
the responses to previous queries so you
do a query you get the answer and then
you choose your next query ok then so
specifically for strategic form games
initially the query is only going to
know the number of players and let's
assume that all players have the same
number of strategies the number of pure
strategies of each player so we're going
to select a pure strategy profile we get
the corresponding payoffs back now there
K to the end pure strategy profiles and
of course we could learn the whole game
by using that many queries but that's
not very interesting what we want is we
want algorithms that require only a
small fraction of this many queries and
what this means is as we'll see for sale
by matrix game sometimes we have to
settle for approximately equal abrir
because as we'll see as one of the first
simple
results if we want an exact equilibrium
we need to learn we need to find out all
the payoffs okay so rough outline of the
talk we'll talk a bit about by matrix
games a bit about congestion games on
parallel links and then I'll tell you a
bit about what's in the reading the
paper without going into detail in case
you're interested and then we'll discuss
some some future directions okay Neen so
just make sure we're clear on on what
queries look like them and what the idea
is let's consider pure equilibrium by
matrix games so for simplicity since it
just it means I just need to draw a
single payoff in each box we're just
going to look at zero sum games and in
fact for our for a lower bound on exact
equilibria zero-sum games already can
have that have that lower bound okay so
if I just query a particular cell I just
get back a payoff ok- so this is zero
sum game so this means player one would
get minus one player player to the
minimizer would get one and what I've
given to the to the quitter what I've
given as a query is I've said give me
the payoff for Row 3 column 1 I can't do
much with that so if I really want to
try and find a pure equilibrium I at
least need to find out if a particular
cell is a best response so let's
actually query the whole first column
what would I do next I note that in this
column the first row is a best response
so if I'm if I'm going to find a Nash
equilibrium that uses this particular
column I'm going to have to now query
the first row but unlucky that's not
actually a pure Nash equilibrium because
the column player is now actually I
forgot to change the payoffs that
actually is a pure Nash equilibrium the
column player is minimizing but of
course by matrix game zero-sum or not
may not actually have a pure Nash
equilibrium so we're going to go on and
look at mix equilibria okay
sir so any questions before we go on on
the model okay so mixed equilibria again
zero-sum setting I've just highlighted
the diagonal because in this particular
game we've got ones on the diagonal
minus ones everywhere else this is meant
to indicate a hide-and-seek game where
one player is simply trying to pick the
same cell as the other find the person
and the other player simply wants to be
elsewhere so the point here is there's a
unique uniform completely mixed Nash
equilibrium okay so player 1 mixes
uniformly over the rows player to mix is
uniformly over the columns it's not a
fair game because yeah okay so it
depends on the size of the game exactly
what the value is but the point is that
there's this unique completely mixed
Nash equilibrium and if we tweak any
payoff in the game we're actually going
to change the probabilities that's the
crucial thing for the for the simple
lower bound and what that actually means
is this is a zero-sum game we can also
tweak the probabilities in such tweak
the payoff since in such a way to
preserve the zero-sum property and that
will also tweak the the unique
equilibrium probabilities so first
simple observation is the payoff query
complexity of finding an exact
equilibrium is K squared for a k by k
game even for zero sum games ok so what
we're going to do is we are going to
relax our our notion of equilibrium
we're going to allow approximately
librium yep the possible deal say on
easy on one or jÃ¶rgen symmetric games
no I have not no not thought about that
at all actually where's good question so
if we okay so we're going to look at
approximate colibri now and for doing
that we need to restrict the range of
payoffs in order that are our measure
epsilon of the approximation quality
actually makes it makes sense and is can
assistant across different games okay so
we're going to assume all payoffs are in
the range 0 1 and in a Nash equilibrium
players cannot gain by unilateral
deviation okay they cannot gain anything
in an epsilon Nash equilibrium where for
these type of games where the perps are
between 0 and 1 epsilon is also between
0 and 1 a player can gain at most
epsilon by unilateral deviation okay so
you have a pair of you have a pair of
you have a pair of mixed strategies
against the mixed strategy of your
opponent you get a certain expected
payoff for your mixed strategy and you
now look at what you would get by
playing pure strategies against that
mixed strategy and you want to ensure
that you can gain no more than epsilon
by switching from your mixed strategy to
a pure strategy ok so for epson equals 0
we've seen that the query complexity is
K squared meaning you have to find out
every pay off and we're going to
consider three intervals for the larger
epsilon okay so first at the far right
end if if epsilon is 1 then it doesn't
matter what we play but actually even if
epsilon is just bigger than 1 minus 1
over K we're in good shape we don't need
to make a single query because we can
just play uniformly over all of our
strategies so then okay so we've kind of
dealt with really bad approximations
some might claim even even point 3 or
something is really bad but actually
that's I mean the best we can do in
polynomial time for a by matrix game is
point 33 so that gives you some idea of
where the state of the art is not
actually sorry I mean the best we know
forgetting payoff query complexity if
you know the whole game the best we the
best epsilon we can we can do in
polynomial time is about point 33 so
just to give you some idea of where
we're at in terms of the state of the
art for standard algorithms for finding
a proximate equilibria
absolutely yes but of course we need to
I mean we might use related technologies
because in the end we need to find an
equilibrium so for example for
congestion games what we do is we take
an idea for an existing algorithm and we
do a payoff query efficient
implementation of that algorithm so they
are different they are different they
are different but I would claim there's
a relationship in fact one of the refuse
of the ec paper actually said why should
this even be different from why should
this even be different from normal
computational complexity and I guess I
mean it clearly is because if we look
for an exact zero so we can find the
exact equilibria zero-sum game in
polynomial time but I mean we need to
know the whole thing for that so there
is a difference you're right but I was
just commenting that that actually the
state of the art for finding approximate
equilibria is not that great respect to
a pair of query complexity okay then so
then okay so now we're going to look at
the range between a half and and one
minus one over K and and i'm going to
show you again it's it's simple that the
payoff query complexity is between K and
2 K minus 1 for the upper bound we're
going to simulate an algorithm of
daskalakis Mehta and Papa Dmitri that
obtains a half Nash equilibrium and if
you see I mean we actually just directly
implement their algorithm so if you know
it there's there's nothing new going on
here so there are algorithms very very
simple you simply pick an arbitrary pure
strategy so let's pick the first row and
you now find a best response to that you
now take that best response and you find
a best response to that okay so so what
we've done is we've found the best
respond
against the first row of player 2 who in
the zero-sum game is minimizing so we
get this minus 1 and I've kind of broken
my my promise that the payoffs range
between 0 and 1 but it's not important
for for the how the algorithm is
implemented and now we're going to find
a best response against that and now
simply we're going to play the players
are going to play uniformly on these
three strategies that we've identified
the row player is going to mix between
the original arbitrary choice of his
pure strategy and the best response to
the best response to that pure strategy
and the column player is going to play
the pure strategy that's a best response
to the original arbitrary choice and the
reason this is at least a half Nash
equilibrium is because essentially each
player is putting half their probability
mass on something that's the column
player is putting his probability mass
on something that's a best response to
something played half the time and the
row player is playing a best response
with probability or half okay and what
did we what did we need where we just
needed to k minus 1 queries and now for
the for the lower bound the adversary
against the querier is going to is going
to report a game of the following form
it's going to have zeros everywhere but
somewhere in there there's going to be
this this row of all ones that the the
adversary has in mind but of course that
row of all ones he's going to report it
as the very last row that it gets
discovered and the the the query has to
discover that row because there has to
be probability mass on that row in order
to ensure the epsilon is less than then
1 minus 1 over K
okay we're of course so k is the number
of the number of rows ok any questions
right so now for now let's so now we're
doing between zero and a half strictly
less than a half so it's easy to find a
half both in terms of computational
complexity and in terms of payoff
queries now we're now in the bottom part
02 a half we know at zero we need k
squared and unfortunately we don't have
a good upper bound here so what I'm
going to present you is a lower bound
that basically says that there is an
epsilon strictly greater than zero so
that we actually need superlinear number
of payoff queries so this is 2 in
contrast a kneading between K and 2 K
minus 1 for a half and above we're going
to need a super linear number for some
epsilon strictly greater than 0 I'm
going to just sketch I'm going to do a
fair bit of hand waving now so excuse me
but you know it's slightly technical but
the idea should be clear enough and so
essentially as epsilon goes to 0
excellent actually features in the
payoff query complexity bound that we
get but essentially as epsilon goes to 0
we get K log k ok so we're going to
start with a non-square game which later
we can make square by duplicating rows
and columns and it's actually going to
start off as a zero-sum game and it's
going to have it's going to be L columns
and L choose L over 2 rows for some even
L and we're simply going to have row
payoffs with with half of the entries
being one the other half being 0 and
we're going to have all the different
rows of that form ok so the game so the
first thing to note is the game has
value a half and it's again again
where people mix uniformly and now
considering an epsilon equilibrium where
epsilon is actually less than a half so
no player can receive too much
probability so the basic story here is
if any column play receives too much
probability then the row player can fix
on those rows that happen to have ones
in it for that column and actually get a
better payoff ok also the role players
payoff cannot be too high because it's a
zero-sum game in the game has value a
half okay so we need to have the column
player getting a suitably high payoff as
well relative to his best response okay
so now suppose a query algorithm makes
very few queries and achieves this
epsilon less than a half I'm going to
argue it for a contradiction with just
hand-waving though so then there must be
a row that also received very few
queries okay they're very few queries
overall in particular there's a row that
received suitably few queries not saying
what suitably is and actually because
the column player doesn't put too much
probability mass on any column actually
there's not there's not too much
probability mass on queried cells of our
okay so there is suitable amount of
probability on cells within this row
that we have not queried yet and we're
free to to set them as something
different which is what we're going to
do now so we're going to replace all the
uncured cells in that particular row
with once what this does is it means
that now row are will have a high payoff
and this is going to be a pure this is
going to be a pure strategy best
response that's going to break the
equilibrium the epsilon equilibrium
property for the role player okay was
that believable okay
and then that's not actually that's not
actually a square game but then we can
duplicate rows and columns to actually
to actually make it a square game and so
we actually get I see it looked really
messy i considered showing some of the
expressions but i didn't in the end we
actually get a an expression that
depends on epsilon as well and for
epsilon less than an eighth this thing
works so there's an epsilon so for
epsilon less than an eighth basically we
have something that's superlinear but
it's very interesting what we can do
what decent upper bounds are between 0
and a half we leave that completely open
okay then any questions at this stage
I'm not so sure i would say more the
Berrier is you I mean you solve
typically for those algorithms you solve
an optimization problem where you
actually need a need an exact solution
or we don't have techniques to actually
reason about getting approximate
solutions to that and so yeah we simply
would need new machinery to be able to
somehow argue about applying any of
those techniques they get you less than
something for a half basically no not
not even a candidate yeah I wouldn't
yeah I mean it might be doable but I
wouldn't cherish taking some of those LP
type algorithms that get you even worse
than point 33 worse than the very best I
wouldn't cherish the idea of making a
query efficient implementation if it's
at all possible but still I think the
general question is interesting so yeah
okay so so i started at three-thirty did
i okay
so we're going to talk about congestion
games now and parallel links okay so
this is essentially as simple a
congestion game as you can imagine we do
have some results on more complicated
consistent games in the paper but this
is I think a nice one to present so in
for a general congestion game we're
assuming that the player that the
querier knows the graph knows the number
of players but knows nothing about the
latency functions so what's the query
what's the query complexity of finding a
pure equilibrium okay we didn't consider
a proximate at all we just proved
results on finding an exact pure
equilibrium which exists in these games
by by a potential function argument and
actually they can be computed in these
games in the computational complexity is
polynomial okay then so so we're going
to look at two linked examples and so
I'm going to represent the to start with
for a lower bound and so the idea is
we're going to represent strategy
strategy profiles as as just points on
this x-axis which say how many players
on a red link and we've got a blue
player link that has all the remaining
players on it we just have two links in
this example okay and so these red lines
are just meant to indicate if I stick
one player on the red link then the
latency is one which we read off the
y-axis and that's true all the way up to
having four players on the red link but
as soon as I have five players on the
red link the latency goes up to 30 k and
and then so the point about latency
function is its non decreasing and we
have a similar latency function for the
blue player and then a Nash equilibrium
is a strategy profile where neither
player can gain so no player can gain by
switching from there
so no one can switch from the red link
to the blue Lincoln gain or vice versa
and we have an equilibrium they're
essentially where the costs are
equalized they're not exactly equalized
here but near where the latencies are
equalized okay so the first thing I'm
going to show you is a simple login
lower bound which uses only two links ok
so I'm going to actually tell you
upfront that the blue link has always
latency one and then I'm going to simply
pick I'm going to maintain two variables
lower and upper Ellen you one is going
to be L is going to be at zero to start
with you is going to be at n which is 10
in this example and I'm simply going to
do the natural thing if you report me
something less than less than half way
along I'm going to make all of those
costs 0 if you report me something now I
passed a half way or at the halfway mark
I'm going to report all of those as
having cost to and you need to find the
switch point ok so essentially you can
solve this problem by binary search and
you can do no better than that ok then
so given that if we can only query
strategy profiles we also have a plus m
in our lower bound that comes from a
separate type of instant so that the log
n came came from a very simple instance
where we had just two links end players
but not and now imagine another
extremely simple instance with one
player and M links if we can only query
strategy profiles then we need to query
all M links so that gives us a plus M
for the upper bound I'm going to get rid
of this plus M consideration and I'm
going to look a slightly stronger query
model that remove some of the details
but i still believe it's interesting
because the log in lower bound still
applies because note because the blue
costs are always constant here it
doesn't help you at all if you can
actually query some other stuff on
on the other link as well or whatever so
we're gonna so I probably wasn't clear
that to be absolutely clear we're going
to now allow queries where there is at
most n players on each link more
generally in a congestion game at most n
players on each pure strategy may we
never need more than n players on a pure
strategy because we don't never need at
most n but of course we potentially gain
something by allowing if you've only got
10 players in the game allowing 10 to go
on two different paths actually might
buy you something we believe that we can
implement our upper bound using the more
restricted queries but it would be a big
mess and we we didn't bother ok so we've
allowed these slightly stronger queries
and then the lower bound is just a log
in without the + M because of course if
you're if you're allowed to query up to
n on each link a one-player game M links
I do one query I find out the best link
ok so the upper boundary aiming for is
this thing and I'm going to do it by by
talking through an algorithm more
hand-waving the algorithm is going to
work by finding equilibria four blocks
of players so we're going to start with
a big block block of players
conveniently chosen here to be a power
of four if if the thing is not a power
of the amount you're going to divide
your block size by each time then you
actually need to maintain a special link
and prove some extra stuff along the way
and I'm not going to go into the details
of that so here this k equals four in
the title that's the amount we're
dividing the block size by each time so
we have 64 players three links and we're
dividing the block size by for each time
step one is to stick all the players on
the cheapest link and we can do that
with a single query with our stronger
query model now we're going to do and
now what we're going to do is we're
going to have an outer for loop that
just brings this block size down x
factor K each time and we're going to
always maintain an equally
of a well what you'd imagine an
equilibrium to be only blocks can
deviate they have to stay together as a
block okay so we start with an
equilibrium where the block sizes all
the players we find the cheapest link
that's an equilibrium we're now going to
divide that block size by for those are
blocks and the blocks can deviate and we
want to find an equilibrium with that
smaller block size so what we're going
to do is we're going to query up which
by which I mean we're going to look at
places that blocks can move to and so
we're going to check what would happen
if we put blocks on places increasing
the amount and and then we're going to
make a guess okay not guess we're
actually gonna do a binary search how
many players move how many blocks move
and using another binary search we're
going to determine if that candidate
number of blocks to move is actually
correct so we have an outer loop that
basically reduces the block size each
time and then we do a double binary
search and I'm going to try and indicate
that with a couple of diagrams okay so
we're going to set the new block size to
n over K so now we've got groups of 16
players that are going to move we've
already got 64 players on on link 3 and
the latencies are shown and I'm not
drawing any red on link 3 because at the
beginning we're only going to move away
we're not going to move anyone to link 3
and so what we're going to do is we're
going to look what happens when I put
sixteen thirty to forty eight players on
the other links and that's what's
indicated by there by the three red
blocks on each of those links so we see
that somewhere between 20 and 40 is the
latency if we stick 16 players on link 1
and then what happens if we stick
another 16 on and so on okay then what
we're going to do okay so the thing to
notice is apart from some special cases
that we won't concern ourselves with
here is in general only K minus 1
should be going to another link k minus
1 blocks should be going to another link
if more we're going k is the amount we /
if more we're going then that should
have been an equilibrium in the last
stage okay so so that's one crucial
aspect we can bound the number of groups
that move as essentially km okay so what
we're going to do is we're going to
we're going to once we know these we do
this once for finding this new
equilibrium for the reduced block size
and then we do a binary search on the
number of blocks that move so what we're
going to do is we've done we've we've
done this queering up and we get a
literary list of costs associated with
all of these these red lines and with
that so we just order that it's a multi
set of course and we just order it from
small to large we're going to guess the
number of blocks that move and we're
going to pick out the k plus 1 smallest
entry from this ordered list so if that
number move we need to ensure that on
every link we have no more than the q
plus 1 cost for that link and so what
we're going to do is we then do another
binary search to determine how many
would need to move to ensure that we
have cost no more than the q plus 1
element and then we simply check is that
the right number when we add up all the
number that need of blocks that need to
move is that actually the original q
that determined the q plus 1 smallest
entry okay so to give an example an easy
example because we only have people on
one link to start with in general you
have people and lots of links but to
give the basic idea what we've done is
we did the query up we got these numbers
here we've also queried up from the red
from the yellow link but I actually made
the yellow link in this example I made
its its its latency constant for higher
for higher numbers so that's why you see
a string of 90s in there which is at
that level so we've ordered these costs
so actually this one was 31 the cheapest
ones have 16 on it
we've ordered them we've guessed a
candidate three here is the number of
blocks we're going to check if they move
we've picked out the fourth entry from
that ordered list and now that guess was
correct if so because we want to move
three we need to check if three is the
smallest number of blocks that we need
to move from link three in order to
satisfy that link 3 has a suitable
latency remaining on it when we've moved
those blocks but left some on there
potentially and so that's true if when
we take away three blocks the cost is
less than six less than or equal to 63
but if we only remove two blocks
actually the cost is then greater than
63 if that's true then actually what we
do is we just stick then three is the
right number to move and then we
literally stick buttons on the side
somewhere is it oh they're so we'd
literally stick the cheapest second
cheapest third cheapest we would move
the blocks to those three and then we
would have an equilibrium for the
reduced block size okay Lynn so very
roughly for each block size we do a
binary search on cue and for each queue
in this binary search we do essentially
k payoff queries to determine C min kyu
log km payoff queries to determine the
Qi Xin parallel which is the number of
blocks we need to shift from each link
and so for any particular Q we're doing
this k plus log km the binary search
from Q itself adds an extra log km
factor so basically this is how many we
do for each block size and then of
course we need to account for the outer
for loop where we start with n players
and are dividing by K each time so
that's log n over log K
so if we just picked two 4k or for 4k we
would get log in log squared M and and
the whole thing would look more pleasant
but actually we improve slightly by
picking k is log in and we get this
extra log log n in the denominator okay
so it sounds fancy but this is sent to a
poly logarithmic factor away from a
lower bound but actually with this being
only log in maybe actually maybe
actually one can do much better than
this it's completely unclear but the
important point to note about lower
bounds here is our lower bound literally
uses two links n players doesn't feature
em at all we spent a bit of time
thinking but we fail to come up with a
lower bound that was actually of the
form f of n g of em where they're both
non-trivial so actually getting this
kind of simultaneous dependence on N and
M from a single example and that's one
of the I'd say the key open problems
there so I've run out of time i'll just
briefly say what we do for dags more
general things is we actually discover
equivalent cost functions so imagine a
path I can't find out exactly the cost
of the individual edges because i only
ever find out the cost of the whole path
but what we do is we find out equivalent
cost functions that allow you to then
solve the game using a normal a normal
algorithm that's not ideal one would
actually like to discover less to do
less payoff queries and still be able to
do it but actually even doing this is
quite involved because you need a scheme
to actually infer things about edges
from paths for graphical games we also
do essentially a discovery of the whole
graph structure there we assume you
don't know the graph structure and the
payoff functions but again that's not
very attractive because you've
discovered everything and what we're
really interested in is examples like
for conditioning is on paranoia links
where one can actually discover
not too much about the actual payoffs
and still find an equilibrium ikonen so
some open questions to wrap up what
about an upper bound trips on less than
a half lower bounds for congestion games
that actually feature m in it in a
non-trivial way other types of games
three or more player strategic phone
games asymmetric network congestion
games I think probably we've actually
finished that case but it's very messy
just discovering all the payoffs there
you need slightly stronger queries and
it turns into quite a mess that actually
relates to some work of Allah natal
where they're essentially trying to do
economical graph discovery in a rather
similar model but they let have a bit of
a cheat in their paper they allow you to
reuse edges multiple times which gives
you a lot of power and we don't so in
some sense this work even though it's
maybe not that appealing in terms of
getting great upper bounds for pay up
query complexity it actually has
applications in other models that we
considered for just graph discovery and
finally what about other query models in
particular if we're really claiming if
we're really claiming this is a very
practical relevance at all maybe we
should consider noisy payoff queries
where we don't necessarily get back
actually an exact pay off we might maybe
get a noisy payoff or perhaps even best
response queries where we get back just
the best response things like fictitious
play can be seen as getting best
responses to mix strategies or maybe
even we actually just get back yes or no
answers to questions of the form is this
epsilon best response or something okay
then thank you very much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>