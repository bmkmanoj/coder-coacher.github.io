<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Information-based approaches for Bayesian optimization. | Coder Coacher - Coaching Coders</title><meta content="Information-based approaches for Bayesian optimization. - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Information-based approaches for Bayesian optimization.</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/O9FhbwurkR8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay hi everyone
so I'm Matt and I'm gonna talk today
about Bayesian optimization in general
and Bayesian approaches for black box
optimization but I'm going to focus on a
method that we have developed recently
that we call predictive entropy search
and this is mostly based on joint work
with Miguel Hernandez Lovato and Zubin
and on the left side I'll briefly slide
I'll briefly talk about some work that
I've done with Bobeck Johari okay so
first off what is blackbox optimization
so in this talk primarily what I'm
interested in is tackling problems where
I have a function that I want to
optimize F but F itself is only given to
me via what I'm calling a black box now
what I mean by that is that I only have
access to F point-wise I can't
necessarily even get gradients of F and
even when I evaluate F at some input X
what I'm going to get back is some Y
that is corrupted by noise the only
requirement I'm going to make on earth
is that the expectation of this black
box at my evaluation Y is going to the
expectation of that is going to give me
the function that I'm interested in so
from there I can take this I can
evaluate a sequence of of X's and then
try and find the point that is the best
point there okay so some applications of
this are a classical one that also comes
from sort of the bandits literature is a
B testing so where I have multiple
configurations of say some website the
button size the layout of the website
and what I'd like to do there is tune
those parameters in order to find the
best configuration possibly I could do
this in an offline setting possibly I
can do this in an online setting another
example that that we've looked at a lot
is sort of hyper parameter tuning so
there what I have is some algorithm it
could be a machine learning algorithm
could be an algorithm for optimization
some other such setting and I have these
hyper parameters that are hard to - now
this might be let's say I have a neural
network maybe I turn the tune the neural
network and I I do gradient descent to
to to actually fit that to some data but
then I have parameters like the the the
depth of the neural network the size of
the layers then I could use Bayesian
optimization to tune those hyper
parameters so now I'll give sort of a
cartoon example of what Bayesian
optimization looks like so I'll start
with some function that I have
illustrated here let's see does this
have oh there we go so I've Illustrated
this function here using this dashed
line and that's the function that I'd
like to optimize so there is some
maximum that that's over here but as we
can see there's sort of this periodic
behavior and this sort of smooth sloping
behavior here so then what I'm going to
do is get an initial sample of this
function so I never actually have access
to the function itself so after that I
have this initial sample I'm going to
fit some sort of posterior model to the
data that I've actually seen and what's
important here is that unfitting both my
predictions and my uncertainty in those
predictions from there I'm going to take
this model that that that I have fit in
some way and I'm going to define some
exploration strategy where this
exploration strategy should should tell
me in some sense where to where I should
sample next in order to gain the most
information about the optimizer of this
function so the next step is to take
this this function right here I'm going
to call it in the next couple sides and
slides an acquisition function to take
this function and find the maximum of
that this is telling me again where I
should sample next
from there I will take this point I will
evaluate that point so actually get a
sample from my black box and then I will
add that back to my data set and update
my model so if we see here I've I had a
high degree of uncertainty there I add a
data point and that lowers my
uncertainty although we see that it
didn't really change my prediction as
much okay so then I will repeat this
process over and over until either some
convergence criteria or until I've
reached a maximum number of iterations
and so as you can see here this also is
changing where I should sample next okay
so I repeat this process and then I'm
going to return some recommendation of
what the best possible point is so okay
this is Bayesian optimization in a
nutshell but there are two sort of key
points that that we have to decide on to
apply Bayesian optimization that first
point is what sort of model do I use so
what is the the prediction mechanism
that I'm using so essentially the first
of these two graphs right here and
second given that model what is my
exploration strategy so what is the the
acquisition function that I'm going to
use in order to decide where to look
next okay so the the first thing that
I'm going to talk about and this is
about the level of detail I'm going to
give here but is the type of model that
I'm going to use and as I said before
there there are two sort of important
things that that we need to make certain
of the first is the the predictions that
were able to make but almost more
importantly I need to have some measure
of the uncertainty in my predictions so
for for me at least this really suggests
say a Bayesian approach to this problem
and for the type of functions that I'm
interested in optimizing
a really general and flexible prior for
functions of this form is a Gaussian
process so I'm not going to go that into
this in really much more detail but
definitely take a look at the the book
of Carl to get more information on
Gaussian processes okay so now I'll move
on to to sort of our contribution to
this literature and the and that's the
type of acquisition function that we're
using so a a common strategy in active
learning where the setting where we're
actually interested in learning
functions is to sorry is to select
points which maximize the expected run
reduction in posterior entropy so here
I'm interested in actually learning more
about where my optimizer is so the the
point X star well since my function
itself is unknown to me and I have a
probability distribution over that
function that also means that I have a
distribution over the location of the
Maximizer X star so what I can actually
do is look at minimizing the entropy of
this unknown Maximizer which will give
me the maximum reduction in the
posterior entropy okay so that looks
like this first equation right here so
this is just the entropy of X star given
the current data set that I have so this
is just DT is just the set of X&amp;amp;Y points
that I have gathered up to step T now
this this next part of the equation
right here is just the expectation under
wise given a particular X of the entropy
of viewing that new point X so
essentially what I'm doing is I'm
hallucinating a new point Y conditioned
on on the input that that I'm trying to
evaluate here X and I'm adding that back
into my data set and looking at the
entropy that would result from viewing
that new data point however one of the
problems with this approach
this approach is is known as entropy
search and Villa monta and Hennig and
Schuler independently developed this
method with various approximations one
of the problems here is that you can
take this expectation relatively easily
using Monte Carlo methods but the
distribution you have to construct X
star condition on this new data point is
actually quite hard to construct and
then computing the entropy of this it
requires a number of difficult
approximations so instead what what we
can note is that this is just the mutual
information between X star and our our
point Y that that that were we're taking
this expectation with respect to so what
we can actually do is just flip the
order of this since that is symmetric
and what we'll end up with is the
entropy of Y just given my current set
of data and then the expected entropy
not of X star but of Y condition on X
star and we call this predictive entropy
search because now all we're dealing
with is predictive distributions of of Y
this component right here is easy to
take care of because of the Gaussian
process assumption I made so this is
just a Gaussian then this component what
I'll see is that I need to do two steps
here so here I've just repeated this but
now I've replaced the expectation with a
Monte Carlo average where what I'm doing
is just sampling X stars so the first
thing I have to do is I have to sample X
star then given a sample X star I can
move on to this next step
well this quantity right here this is
just replacing this entropy with the
entropy of a Gaussian so this is just
the marginal variance of my Gaussian
process evaluated at the input point
that I'm evaluating X so then if I am
somehow able to approximate this
distribution of Y given X star with a
Gaussian I can replace this entropy with
again the same
of quantity summed over my Monte Carlo
average here so this has two steps what
I need to do is again sample X star and
then approximate this distribution right
here Y condition on X star with a
Gaussian and from there I can compute
quite easily you see the predictive
entropy search acquisition function so
first off how do i sample the the
optimizers x star the optimizers x star
what we'll going to do what we're going
to do and and I'm going over this at a
very high level so I'm skipping many of
the details here what we're going to do
is instead we're sample the function f
so if we're able to sample the function
f we can then maximize that sampled
function and that will give us a sample
from the posterior of X star so here's
an example of that where I've sampled
these grey functions here taken their
maximums and or the the maximum of these
and and over these many different
functions and that gives me these
samples and so in this illustration
we've shown just a histogram for this 1d
problem here of the distribution of X
star now one thing we could do is just
sample these functions however this is
an infinite dimensional object because
this is just a function here so what I
could sort of consider is building this
up incrementally and so my optimizer
could take sort of a lazily evaluated
function and then it could evaluate a
data point while optimization is going
forward and then add that back to my
data set and crank through the Gaussian
process equations to get the the updated
posterior however that can be quite
expensive if we have to optimize this
function very deeply so instead what
we're going to do is replace our
Gaussian process with a sampled feature
based representation where these
features are sampled in the same way
using this same approach as as Ricky
Mian wreck the also known as the
of random kitchen sinks approach this
also corresponds essentially to a sort
of continuous form of Thompson sampling
if if you're more aware of sort of the
bandits literature and this was also
used in some other work we did in order
to actually implement Thompson sampling
for these continuous sorts of problems
so that's given a sample of X star we
need to approximate this entropy the
earth we in order to approximate the
entropy actually we need to compute a
Gaussian approximation to the
distribution of f of X given X star and
then given f of X we can easily get the
distribution of Y so really what we need
to do is conditioned on the fact that X
star is a global Maximizer well
essentially what we've done here is
we've approximated the fact that X star
is a global Maximizer by saying that f
of X star is a local Maximizer and then
added some additional constraints to say
that f of X star should be greater than
all previous observations we've made and
then that it should be greater than the
point that we're currently evaluating so
we've already sort of made an
approximation here and we're going to
approximate that further the the first
thing we're going to do is we construct
this distribution over f of X star given
these first two constraints which we see
these first two constraints have nothing
to do with the next point we're going to
evaluate there's also some additional
latent variables here that that are sort
of unimportant because we're going to
marginalize them out so what we can do
is construct a Gaussian approximation to
this distribution where essentially we
can do that using gradient observations
which can be done in closed form and ep2
basically handle the fact that since
this is a we want to make sure that this
is held and also the fact that f of X
star is a local Maximizer that requires
some inequality constraints basically on
the Hessian
so we can we can perform that
approximation using ep
which I won't go into detail because I
definitely run over time if I were to do
that but then given that Gaussian
approximation we can for any X construct
a new Gaussian approximation for the
Joint Distribution of f of X and f of X
star we can do that in closed form given
this first approximation and then with
one more moment matching step we can
include this last constraint and
approximate that with a Gaussian now
this gives us the V that we needed for
the conditional distribution of f of X
given X star so we can plug that into
the earlier equation I gave and directly
evaluate the the predictive entropy
search acquisition so okay we've shown a
number of different approximations to to
this acquisition function but now the
question is does that actually help us
well in the middle here I've shown for a
particular set of data points the
entropy search objective so essentially
using the mutual information in the
other direction and here what I've shown
is using a number of a very intensive
sort of Monte Carlo approximation to
this that we're going to use as ground
truth so this is essentially ground
truth this is entropy search and this is
our predictive entropy search objective
function and what we see is that this
gives a much better approximation to
this then does the original entropy
search approximation now that's all well
and good that we get a better
approximation to the to the acquisition
function but does that actually help us
in practice in optimizing functions so
what we've shown here is samples of of
functions that are unknown to us to our
optimizer that come from a Gaussian
process prior and here we're comparing
our approach predictive entropy search
the earlier entropy search
approach and another method expected
improvement and we see that predictive
entropy search does significantly better
than either of these two methods so this
new approximation does actually help us
in performing optimization now this was
sort of a synthetic example but we've
also done and and this is small for a
reason since I don't have enough time to
go over all of these different plots
here but we've shown examples of this
working on a number of different
realistic problems so for example the
earlier example I gave where you were
optimizing a neural network with that's
this example here we've also shown it on
a number of samples from the from the
global optimization community and a
number of other realistic examples so
the the key point that I should make is
that we always perform as well as as
entropy search and or better than
entropy search and as well we perform
better than expected improvement in many
of these different problems now finally
one last thing I wanted to go over and I
was hoping to show a demo of this but
since I had to use another machine I
didn't want to try and do that on the
fly so what I have here is in in the
cartoon example of Bayesian optimization
that I showed earlier there's actually a
number of places where you can make
different choices for example for the
actual model that one uses for a
Bayesian optimization for the way that
the initial points are sampled for the
way that the recommendations the final
recommendation to the user is given back
so there's a number of different ways
that these can be set up and what one
can do is what this suggests at least is
sort of a modular approach to Bayesian
optimization so we've we've sort of
broken this apart into a number of
different components that you can plug
one into the other and we've sort of
written about this but also
you can go to to github and actually
download all of this code right here and
run all sort of all of these sorts of
examples that I showed today with our
acquisition function different
acquisition functions different
recommendation methods and I believe in
about three lines of code you can get
all of this working and sort of start
playing with your own Bayesian
optimization methods and that's it thank
you great we have time for questions
yeah I've won many practical
applications that may be the case that
you have a population of optimization
problems and but because the acquisition
strategy influences how you sample your
functions could you still use it to
learn from the sample of hope from that
population to basically improve your
performance on future optimization
problems oh so basically sharing between
different optimization problems yeah you
can definitely do that and and that
would I mean in some sense that sort of
informs your your prior model that you
you you start that you start this task
off with and and essentially yes not
myself but Eric Brochu has done that in
some of his earlier work ok any more
questions no let's thank Matt again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>