<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Optimal Real-Time Bidding for Display Advertising | Coder Coacher - Coaching Coders</title><meta content="Optimal Real-Time Bidding for Display Advertising - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Optimal Real-Time Bidding for Display Advertising</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OoI2aCWdWKA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
all right I think I'll start now this
afternoon we have guests from UCL
several researchers from UCL never
pleased and that to students of John
Wang who is the professor at UC l will
be giving a presentation and that's why
were and vain and junk ash why is the
doctoral student in the last year of his
studies and wane on is the second year
student some of you may have already met
why because he recently interviewed for
postdoc position he talked about his
research for his his thesis but today
both why Whelan will be talking about
algorithms they used a particular event
it was a competition in real-time
bidding for display advertising with the
Iping you a competition in 2013 and they
had a fantastic accomplishment that won
the first prize which actually was quite
ahead of the second one about almost 30%
in performance if I remember correctly
so I will let now so I start so please
okay right thank you very much everyone
I'm showing from University College
London and actually we are trying to
build an earth science research team
research group within the department of
computer science in University College
London led by our supervisor dr. Jim
Wong who is absent at the moment and
today also my colleague we9 Jung is with
us you know last time I talked about the
optimization problems in supply side in
real-time bidding but now today we are
taking a different angle we are going to
talk about the optimization problem from
the demand side especially the feeding
algorithms the today's talk will be
splitted into three parts the first we
are going to quickly go through the you
know background knowledge about
real-time bidding and by giving an
example and by introducing the ecosystem
and then we are going to talk about our
experience from last year's open your
global bidding commutation where we won
the first prize and
we have some in a practical knowledge or
experience and then the third part we
will talk about other theoretical
development based on experience and our
solution to that all right
and the first part is about the
background of real-time bidding for
those who you don't familiar with the
real-time bidding you have to know that
real-time bidding is getting really
popular and how popular that in 2014 is
this project to have for 4.6 billion US
dollars
you know our total spending and it is
project to have 30% of total display and
spending in 2070 in 2017 that's a huge
number and that takes a lot of inert
others and it gives a lot of
opportunities hence there a good amount
of research effort around this topic
especially in recent years alright so it
is popular but so what is real-time
bidding anyway real-time bidding means
every online addict impression can be
evaluated bought sold and or
individually and all instant in
instantaneously right
what does it mean it means instead of
buying a bundle of impressions several
thousand impressions together
advertisers are now buying impressions
individually this means they are
actually buying users individually
directly advertisers urine used to buy
impressions based on the websites
reputation right they negotiate a
contract between sales people and then
they claim that they have to trust the
publishers who claim the user behind
that the impressions to be you know have
some characteristics but now they have
their own judgment they can build their
own data set to understand the users and
to place a pit for every single user but
what does that mean especially
scientifically it means a challenges
buyers to bait for every impression you
see it's a fundamental thing a challenge
buyers to bid for every impression to
bid for every
based on a variety of attributes both
contextual and behavioral attributes and
especially you have to do that in real
time by in real time it means you have
to return a bit in about 100
milliseconds this is also a very huge
engineering challenge right it
challenges the other side as well
it challenges sellers all the publishers
to dynamically allocate and price
impressions to achieve a higher payoff
it also challenges data providers so
effectively track and analyze uses
unalaq tivity and probably trade with
each other understand some mechanisms
and at last it also challenges users as
well to understand the trade-off of
privacy and free services which I
believe many of you are aware familiar
ways all right
haven't talked so much probably it's
better to show you an example
what's the real-time bidding actually
means let's take away 9 for example
winning is very interesting you know
computational advertising research so
who wizards in marketers come regularly
that's his long term interest and
occasionally weena has some travel
demands for example he recently checked
London hotels for one of his friends no
there's no login is required actually
this represents winners short-term
interest it only happens within some
months or you know win some weeks after
all these events
I mean visiting the websites winner
receives relevant ads on Facebook calm
all right in the middle you can see
there's an ad for an escape for for
travel interest and to the right you can
see there's an ad for in marketer
reports or services
these ads are created based on his
interest post long-term and short-term
not only based on the context of the
page but wait there's an extreme case
there's even add our supervisors
homepage when we now visit it you see
the ad is actually from booking.com
about hotels it has nothing to do with
the
research always advertising at all so
you see in this case the behavior
targeting totally dominates the contest
okay that's the trend that's the
emphasis of the real-time bidding to
understand a user to beat against the
user interest the segment alright given
all these you may ask how actually does
it work it works like this in the first
in in the first step you visit a verbs
website and this website has an ad slot
it will give you as we create an ad
request and forward this ad request to
some exchange this exchange will forward
this bid request to all the advertisers
who are willing to participate in
auctions and other prizes we'll check
the data management platform for user
data or their own database for the user
interest and they will create a bid
response after collecting all the bid
responses from advertisers Ad Exchange
will hold an act auction normally the
second price auction and it will select
a winner and send the win notice to the
advertiser as well as display the ad of
the winner to the user and you know at
last the user would probably give some
feedback by clicking add or navigating
around the website or even ultimately
complete a purchase of us of some
product alright this completes the
circle of real-time bidding and you know
it it is a complex ecosystem and we have
to understand what we are our position
in this ecosystem all right
the the complexity of the ecosystem has
a long history you can see from this
figure which I showed last time in my
talk and now we are more focused in the
center part of this ecosystem where we
are participating in ad exchanges and we
are representing advertisers and we are
trying to make sure we can bid optimally
okay in this talk we only talk about
bidding and now let's talk about the
we already seen that for every atom for
every webpage for every impression you
create advertiser has to give a bit
alright that bid is not you know it has
to consider many different features it
has to consider both contextual and
behave features as we talked just now
but how actually did that work let's go
deep into this bidding engine all the
bidding algorithm to see how it works in
this talk alright
firstly I like to share our computation
experience which in you know in turn
inspired us of the third core study of
the third part the competition was held
in 2013 and was splitted into three
seasons we participated in the second
and a third season and we won the 1st
place of this earth season and by the
way we won the 4th of the second season
ackerman precisely but you know it's a
gradual progress this competition was
held by a Chinese DSP demand-side
platform company called IP knew the
demand side platform refers to the you
know the technology provider for the
advertisers which enables them to
participate in the real-time bidding
which ultimately gives them the power to
return a bid for every ad impression all
right an IP no claims to be the biggest
DSP provider in China in Chinese
advertising market so this is quite a
formal competition the task for this
competition is quite simple actually
it's very easy to understand it's
basically you receive bid requests and
you have to create your own bidding
algorithm and you have to return a bit
based on your own understanding of this
bid request and you need to develop a
bidding algorithm that maximizes the
object function which is defined by
adding all the clicks and conversions
together and conversions are apparently
given different ways because they are
more important and all these will
subject through the budget constraint
of course your kana you cannot spend
more than the money you have the
evaluation process of this competition
is splitting these three different
stages the first one is a training that
is the training stage they give you the
training data set you use the training
data set to develop your own model and
test it and then on a daily basis they
update the daily ranks the answer the
rank based on the test data set
well this data set is not given in the
beginning but you can actually see it
when the daily rank updates and finally
they have a how to test the data set
which gives it the final ranks you see
there's a hidden test data set which has
the chance of overfitting which we will
see where soon for the data set itself
there are four types of different logs
these logs are bit logs impression locks
click locks and conversions logs there's
unfortunately there's no log for the
user segments you know user activities
around the world there's no log for the
user navigation in after the click but
before the conversion right and these
logs include very many different fields
in like the standard ones like the time
staff and the web page a URL and a slot
it also has some interesting ones like
the ad slot visibility you can see
there's a sixteen there is ad slot or
visibility it says the second wheel it
means this ad slot exists not on the
first screen you have to scroll down to
see this ad slot okay it also plays an
important part in the whole model there
are also user tax the last one the 24
the user tax these are user interest
segments basically they say this user is
interested in buying something this user
is interested in travel this user is
interested in reading but unfortunately
we don't know what these you know
numbers really represents so we don't
have
correlation between them and we don't
know the hierarchical structure of it
all right the another two fills the
twenty bidding price 753 this is a price
you submit in the log it means from
history advertiser submitted this price
trying to win this impression and the 21
the paying price is defined by the
second price auction it means this
advertiser has won an impression and
this impression was won at the price of
15 it's eerily substantially lower than
the bid price okay and based on these
data sets we have all you know the
member bids and impressions and clicks
and conversions they're there they're
there are normal figures like the
click-through rate normally they are
around 1% or you're less than 1% and
above 5% but there are also interesting
ones like are there is a conversion rate
you can see there is a fifty five
percent conversion rate that's very high
and by the way they define a commission
rate to be the number of conversions
divided by the number of clicks not by
the number of impressions all right yes
please
the conversion is urine defined as a
purchase of something or the download of
the software it's it's the ultimate
commercial goal you like the user to
accomplish do you explain now that some
results of a cereal percent conversion
rate absolutely nothing or beyond the
precision here and others have 55
percent yes it's it's based on a
different definition of the conversion
you see these belong to different
advertisers these are the sizes are not
shown here but they belong to different
verticals or categories some of them are
like on the travel like the online
marketers and some of them are like a
very difficult ones like the financial
services you can you can imagine for
example for financial services it's
really difficult for P
for to register form and complete
something but probably for on a shopping
is much easier like pushy something
right these are just the different
characteristics of the advertisers
company that I'm working with the
appetizer is free to define a conversion
to be whatever they want and it might be
like they just land on some other page
so they don't have to buy anything you
might if they doesn't wants to they can
just say oh if this one visits this page
then this will call that I'm sorry
the it works like this the the
advertiser they have a web page and
expect a user to visit you're lazy
embed a small script on the final
conversion page and this script belongs
to the DSP platform that script will be
triggered when user reach to that page
and will be attributed as one conversion
website the user has already played
right yeah okay so he if he chooses he
yes yes theoretically yes yes yes that's
true okay do you have lost for non
winning bids or just for the window
please the winning base is defined as a
impressions yeah and the the bidding
activity is defined by bit that's the
bid request for that well let me also
you this way we we know which auction we
lose but we don't know why we lose it
you see you have some record if we have
the impression you know there's an ID of
the bid of the action auction ID right
if we win this auction we will have an
impression and we will have the paying
price knowing
much we have paid but if we lose it we
have no log for the for the last but we
know we lost we know we lose yes yes
okay these are the overviews or the
statistics of the datasets and based on
these datasets
the competition was divided firstly into
two stages the first one is an offline
stage well let me talk about the
solutions of the offline stage first
with the training dataset we broke our
offline bidding algorithm or the engine
into many four parts the first one is
the trying to extract the features
second one is a click-through rate
prediction third part the whitelist
revision and the fourth part is the in a
more subtle revision of the final bits
and after all these four steps we give a
bid for my impression the first part is
about features we first you see there
from the log format you already see
there are 24 different fields and based
on these fields we extract the first
other features as well as the second
other features by giving the combination
of two first other features and of
course we remove some meaningless ones
like um you can't you can't give our
equals to 8 and our equals 9 together
it's just meaningless and we have around
700,000 features in total at last this
is the first step and for the second
step click through rate prediction we
used a very basic logistic regression
model and you know with some
cross-entropy training objects and outer
recognization and we implement this in
Java this is very basic largest
regression with with and without any
fancy you know modification and the
third one I'll sorry for the
click-through rate prediction model we
have to make it slightly complicated
because you know you are not supposed to
beat too high because the clicks rate is
is predicted to be high and you and you
have to you have to cap your bit based
on a clicks will raise prediction right
this is a method we try to
modify the bid based on the city a
prediction as well as applying a cap
okay
these perimeters are learned empirically
from the training data set and you know
actually in the set in the third season
we also talked to the organizer of the
accommodation and we also talked to
other teams of the during the
conversation we learned a lot about
these perimeters especially there is a a
you can see is a exponential parameter
that I we learned a lot from other teams
this using the click through rate
prediction alone with a capping give us
rank 5 and you can see the curve this
our billing function it gave the curve
of our convex but the question is is the
convex shape correct or not
this spinning function that's on top
right corner is totally based on our
intuition right it's not based on
theoretical development we want to
understand is this convex shape correct
or not that's what this is exactly the
part that inspired us for the third part
of work ok ABCD parameters they will
they will learn from the training data
set we just to work research right but
especially for this parameter a it's
very difficult to you know even for the
great search it takes a lot of
computation power mean learn to maximize
the initial objective plus yes yes okay
and based on this bidding function they
surfers the snap we are to have a bit
right that's B over there we already
have a bit but this is not very
satisfaction this is fine okay this is
totally based on intuition we want to
build a you know we know that if the
predicted click-through rate is high we
should be higher and if it's low we
should be
right and there should be a relationship
it's based on the prediction and we also
know that it can't be too high and it
can't be too low that's why we're
capping it I'm just saying the y0 after
multiplying your clip really be the
squash clip prediction divided by the
base video we convinced appear okay how
granular
estep global model that you fit yes
actually in the training as i said
there's only one advisor all you're
talking about two different features
actually in the training data set there
is only one advertiser and i will talk
about that later in on a stage and
honestly they challenged us of a by
giving different and multiple
advertisers without giving the
corresponding training dataset okay okay
after the first stage we won the run
five and we don't think is enough so we
introduced the some revision the first
revision is based on the whitelist a
whitelist
is well is based on the human
understanding of of rules for example
from the statistics of the training data
set we already spotted some are sloths
giving were high performance we can
build as high as possible and this
whitelist is purely constructed from the
training descent but there's one thing
worth mentioning which is the the the
the matrix the performance matrix in the
second season we use the wrong
performance matrix which which is
totally based on the predicted
click-through rate but in a certain
season we use the high ROI which
you know cost-per-click or the clicks my
/ cost
this gives the significant improvement
which give us a lesson say the correct
performance matrix is really important
okay
this finally give us rank 3 and we still
think this is not enough because some
features are actually more significantly
important than the logit regression
model SAS and it's probably due to the
whole feeding problem or it's probably
due to the model itself right
for example we try to do something more
subtle instead of building as high as
possible with a fixed value we are
trying to do something more subtle like
if the advertiser is someone are not
sorry this is a for example as I said
there's only wild Tizer
but if the ad visibility is something we
multiply the bit by some factor okay
this is still mind from the training
data set it's a post adjustment which
might impose on a bit itself and this
gives us rank two and as as at the end
of the a fly stage we actually received
the first place this give us another
service some lessons like you can out
all of it if you all of it like the leg
legs are guided for the who won the
first place in a before the final
offender rank he all fit is and he
received a slightly less score compared
with with us okay and the second lesson
learned from the offline stage is we
need to use a correct matrix which is we
believe to be the effective cost per
click instead of the clicks rate all
right I'll show you how this influenced
our in the online stage but before I
talk about the honest stage itself there
are some statistics of the on stage as I
said the there are four different
advertisers and this is the first
challenge and second challenge is there
were no logs you don't have any analog
about it no be logs no impression logs
no click logs and no conversion logs all
right but the good thing is
there was no competition among five
participating teams they selected five
teams into the online stage and they
claim there's no commutation among them
among us
okay the how did they manage to do that
after the commutation they disclosed how
they how they did the selection when an
ad request comes in they first asked all
the teams to generate a bid to generate
a bit but this is just a test it doesn't
count as a bit request
okay the Jay asked each team to generate
a bit and the check if the bid is higher
than the reserve price the result price
is a minimum price you have to you have
to beat if you want to win the option if
you didn't if your bid didn't beats the
reserve price you will not be able to
participate in the final random choose
choice okay they finally random choose a
bidder from the remaining teams and you
can see it is certainly biased because
some teams are generally giving lower
bits which are much lower than there is
a prize if it's not biased these teams
will simply be able to bathe but loose
but now the spitting opportunity was
given to other teams all right and in
online stage our solution is basically
the same with sorry it is biased because
some teams will generally give the bid
even lower than there is a prize because
it is it probable as it didn't consider
this factor but it is likely that they
didn't consider this factor and they
just give a bit lower than the Reaser
prize and if it's not biased they will
be able to see this bid request or they
will be able to have a bid request and
just lose it all right
but with this selection they will not be
able to see this bid request that could
belong to them and this request we're
simply given to other bidders given to
other teams I will show you how this
bias is
in the final statistics okay and but
let's come back to our solution our
solution is simply modifying the bidding
function based on the you know the
offline stage with the revisions and
with the CTR prediction and an
interesting factor is a perimeter e
which is modified for each advertiser
you know that's the only thing we can do
because there's no training data for
each advertiser and we have to adjust
this factor e dynamically during the
online stage as if competition proceeded
all right
and we used the remaining budget and EC
PC as the main factor we would monitor
during the on stage all right and we we
created a simple monitoring interface in
Python from the plots there was
something we did during our stage all
right first you can see we in the
beginning we beat slightly higher then
we kept reducing the bit because we want
to make sure we don't deplete the budget
too soon all right
and then we gradually increase the bid
price by adjusting the factor e to make
sure we to make sure that we can win the
majority of impressions and our ECP C is
within our target range you know not
attacking range but within a preferable
range as long as possible and we also
want to make sure we can deplete the
budget all the way failed you see at the
end we only spend some 75 75 un in RMB
but we were given 100 okay and in a
generally speaking our tuning was trying
to win as many as impress as many
impression as possible and not deplete
the budget too soon or too late all
right
and you can see from the plot there are
vertical lines and each vertical line
indicates a change of the parameters and
this is for a single advertiser and
actually for other other sizes is more
things
changing this particular lines is
changing the each other yes what was the
logic that changed it the logic of
changing the perimeter II is as I said
in the figure we try to maintain a we
try to maintain preferable ECBC the
cost-per-click
value which we consider to be the major
a performance matrix or all the
indicator and we don't want to replace
the budget too soon or too late while
winning a lot of impressions you know
it's it's because there's no lock we
want to have the statistics which is
given every 15 minutes and this
commutation lasts two hours or so so see
we can't adjust as frequently as
possible no we can't learn you know
what's going on over there okay yes
they kind of published different parts
of the of the training data and then you
adjust the e parameter
every no they they didn't give the
training data they didn't give the log
level data they only gave the data as
you can see from the plot the number of
impressions you have one and number of
bits you have potato shion's you have
participated in and the your remaining
budget and your average cost some
conductor every every 15 minutes every
15 minutes and yeah okay
and the on a stage that turns out by
using the correct metric the effective
cost per click we want the commutation
and we want 30% better than second place
well I think this basically because we
try to spend as much as possible and we
intentionally kept this BCP celo by
talking to other teams after the
competition we learned some of them
simply use the linear function of the
predicted click-through rate and some of
them you know even even simpler than
that
all right and for
probably they use that you can you can
imagine but using a linear function of
predicted click-through rate it's a
wrong matrix right and it was something
even simpler than that won't give you a
better result so just to review a little
bit what are the lessons learned from
both the second season as I talked a lot
you see the click-through rate or the
conversion rate prediction is not enough
all simple variations the linear or the
exponential form is not enough and by
adding the budget constraint is still
not enough right the availability and
the win rate or using the industry term
it's a big landscape it must be
considered right that's why we tried to
win the majority of impressions not a
majority but as many impressions
possible and while considering the e CPC
but you have to understand we did that
totally manually in the in a competition
because there's no feedback there's no
log level feedback and our admins goal
is actually trying to develop a model
that takes takes into account these
factors and be able to do that
automatically all right and note that
the availability and the winning rate
could be dynamic right it could be
influenced by the supply fluctuation and
market competition and actually I
escaped from a one slide here which is
you know during our competition for one
advertiser even though we increase the
bid a lot gradually a lot you know in
the past of our we can't win more
impressions because the market is also
increasing the bit or simply because
there are not many impressions available
there right it could happen
so you have to take that into
consideration well I'll stop for now and
hand the controller to Wayne and we will
talk about the third pass the
theoretical model and solutions we
developed based on our experience from
the this competition yeah sure
talking about here I'm sorry so these
training data that you got for this
competition how much data are we talking
about are we talking about megabytes
gigabytes terabytes gigabytes 35
gigabytes okay okay thanks
all right after I show that we have a
lot of considerations in during our
competitions such as the function form
of the bidding function and the
whitelist and also the final abating
relation so all this actually decide our
manually who required some heuristics so
we actually after after the competition
we want to develop kind of framework or
theory to automatically learn the
optimal bidding function we just
directly from the data so here in this
table in this section we will propose
our a bid optimization framework and the
solution of the feeding function in this
experiment and some future so actually
in this real-time bidding ecosystem will
now focus on the demand side platform
perspective that is you will receive a
bit of request and also the user data
from outside the world and you will you
will need to return the bit B response
that is a big price for this impression
and you will connect the user feedback
afterwards and just so the problem state
objective will be just as I mentioned in
the competition that is you give a
bidding strategy you you buy by tuning
the bidding strategy you want to
maximize the campaign level K
performance indicator that could be the
compare campaigns achieved a clicks
number conversion number and the
constraint will be the campaigns cost
should be a lower than the preset budget
and this is a just an abstract
optimization framework and before
showing the formula we should introduce
some components here so each bid request
are formalized as a long high dimension
vector here include
the user as future features and based on
the input features we can have an
evaluation function about the KPI brains
brandies being request opportunities
such as the city ROC we are so citta
here means the idea or savior of the
feeding being request X and based on
that we can have a bidding function that
is our based on maybe the city are of
this bid request and also some features
of the X we will return a bid price we
will return the bid price of the of this
case and based on the basically for this
been a request and a way return this be
price there is a winning probability
function that is Ranieri to rush right
just mention the waste you to consider
in the framework so these these are the
optimization formulas we won't actually
use actually we also simplify our model
by some dependency assumption that is
first ISM we can directly evaluate the
key performance indicator that is a
reward bring from this request how much
it can reward you if you win this
auction and based on this reward and
also you know the campaign they will be
the landscape that is how much you could
cost you could pay if you beat this be
price and then you can dip to my the bid
price you want to response for this
auction and based on that based on the
bid landscape you will know the winning
rate because you already know you
already know how how much you beat in
the bid landscape of this campaign so
you want to maximize them so here we can
use one two we want to maximize the
campaign levels total click number so
here empty means the campaigns expected
auction number during its lifetime T and
for each opportunity where you consider
there to the bidder request the feature
is
generated from identical at the
independence distribution and with this
probability density function and based
on that we evaluate its CDR here and
performs a beat and gives the reigning
rates based on their speed so that's the
probability of waning impression and
times the city are here we will have the
expected clique number of the campaign
level and also similarly the cost as you
see we have we haven't defined the form
of the function so this is actually a
function optimization framework so what
do you want optimizes our functional
under you you want to needs of the form
of the function and also the similarly
the cost will be like this and here the
bidding price we use the bidding price
as a cost upper bound because it is
normally a second price but we're not
just use the second price because
firstly is the second price it is not
able to easy to estimate and the second
why is you know the price the auction
reserve price will always push the the
reserve price next to be between the
first price and second price and very
close to the first price actually so
based on that and the way also of sorry
here actually has some notations of this
optimality meditation function and based
on this optimization we can actually
simplify it because we have since we
have already the CTR estimation function
we can they're actually simplify this
integral based on the substitution
methods of integration we only integrate
on the CTR of the X here so we we
integrate the city are here and you have
the simplified repeating optimization
framework and the solution will be based
on the calculus of variation because
what we want optimize what we want to is
the function so here the lagrangian's
file Lagrangian formula of this
optimization and take the Lagrangian or
functional derivatives with respect to
the bid price and set
to zero we can have the Lagrangian
condition of this solution so please
look at this function here this formula
here as we can see this is an condition
of finding the best feeding function the
optimum obedient function here we can
see that actually the probability
density function has already been erased
because the two of this have they have
the same term here so actually in this
condition what we care about is a form
of the weighting function here that is
given the speed how likely you the
advertiser will win this auction so if
we have this device have even have known
the form of the W function here you can
directly derive the function of your
bidding strategy so what so what kind of
what is the shape of the weighting
function here with our learning from the
data so here are the six campaigns in
this in the IPO data set as we can see
that although when the X rate X is a
campaign speech and Y is the waning rate
if the campaign beat in with this value
so it's you can see that like that the
the winning rate has a concave form with
respect to the beat the winning rate
will increase dramatically at the very
beginning and the count finally converge
to one so with such observations we can
propose some weighting functions and
based on that formula condition formula
we can derive directly derive our
bidding function so first the winning
function will be like this like we can
just motivate using the bid price over
say plus P price where the say parameter
can be learned from the data from the
training data and based on that or you
can see that the optimum derived bidding
functions like this it is actually on a
square root form it is a concave form
with respect to the KPI here so actually
in your in your competition we have
derived very first the convex and the
concave form with respect to the bit
along with a lot of white whitelist and
the beta revision rules so here is this
bill this bill which is quite clear and
we can only to change the winning
function for different campaigns if this
campaign will have such kind of winning
winning function such as I if this
campaign are a little competitive and it
has the bid we are not increased
dramatically at the very beginning only
after maybe 10 P are over 10 it will
increase dramatically we model the
function even more the weighting
function like this and learn the same
parameter using the data we can also
have our bidding function so if
different weighting functions will lead
to different bidding functions so in
these two cases the bidding functions
are or in a concave form with respect to
the predicted city are here so compare
we want make analysis here compared to
the linear bidding form what we we our
beautiful will allocate more parties
from this area to this area that is the
linear form bid bid will be more than
ours when the city are estimated Cydia
is very high and the way we will
allocate more budget we will be the more
we want to win more about the chip and
low beads with low bids so actually
since the waning probability function is
in compiled form so when the bid is
already lower if you increase a little
bit of your pitch you will have you will
earn a large winning rate increase but
when the bid is already high you will
only earn a little very little winning
rate increase so this this opportunity
this actually Chris is very consistent
with what we learn from the unlike
computation of IPO because when the
bidder is already lower if you just a
bit like this maybe it will be it will
not even surpass the reserve price and
you will lose this bid opportunity but
we can earn it by increasing the bid at
a very beginning
so we use that competition there are
Center for evaluation and the devaluated
split eg will be constantly beating
which is new the normally using sponsor
search and the random beating and also
the max CPC that is advertisers have the
previous CPC target
you won't you shouldn't have
have earned higher CPC than this kind of
sympathy that is you you you can learn
the actually you you can regard the ECP
see in the previous that I said as an
advertiser is a private value and you
just beat based on the true value times
the predicted CDR and then the last one
last the comparator is a linear platform
linear linear form bidding function and
the way have our two buildings of
functions based are to winning functions
with proposed PC PC and y-you can infer
the advertisers profit then okay that is
this if you you served as a feed of
tamasha
framework so what you should do is you
try to lower the ec PC before before
your optimization right effective cost
per click it is normally used it could
be also called CPC cost of per click but
since the guess this player can play
this play advertising is always charged
by CPM so we actually use effective hear
the term here effective CPC so so before
for example if you before the be dropped
before the bid optimization you will
spend maybe one dollar to earn each
click we want to apply optimization your
bid you can earn you can spend just a
zero point eight dollar for more than
one click so just like that so also the
it has the evaluation flow will be based
on the data set that the data is a row
per record each record is has been being
requested features and the auction
winning price and also the last of the
users feedback on the ad impressions
shown and each time we send a bid
request to our biddings engine with a
different bidding strategy that is
bidding algorithm and a bidding
algorithm will response to be the price
for this bid price for the speed request
and the auction the testing environment
will do the auction that is to check
whether your bid is actually higher than
the log the winning price of that
auction if so the actually actually is
this advertised the wind is our
impression and the users feedback that
is already logged in history data will
be retrieved to say whether the user
click this ad or even convert and the
result will be returned to the bidding
engine the tester will ends if the year
there is no test or data more or maybe
the budget has already run out so the
performance is like this so here the one
over six means that we just stated a
budget of the test as one of our six of
the original total spend of the tester
log because we cannot spend it we can
not a set of the budget higher or eco
then to the original test original cost
or in the test data because if so we can
just be there as much as possible in
every cases and we can earn all the
click without without spending of the
Partridge so with such budget limited
budget condition we can see that our
real-time bidding algorithm actually
outperforms the other algorithms and
also this is on compare this is a
configure of a clicks and also for
compare the ECP see here that how much
you spend to earn each click you can see
that on we also have Louis de CPC and we
can also set another KPI in your
optimization save you set a conversion
number as Europe
my objective that you can still have the
similar result and when the budget got
increased from one over six to our over
sixteen you can see that the actually
the improvement got lower but here we
can actually have an analysis about
budget here actually you can see that
when the budget is of very limited
compared to the original cost you can
see that the impression the improvement
of our algorithm we choose a against the
linear bidding form is actually quite
large but when the budget goes higher
and higher there's more and more party
to the increase which should be lower
and lower and the of quicker of course
when we have the one point here there is
knowing no improvement because you've
just a bit as much as possible will be
okay so here when the budget is quite
lower we can actually spend more budget
on the chip cases because cheaper cases
as always always on cost cost effective
because the other marketer were always
concentrated on some high performance
high quality advertised opportunity here
so the future work will be away will but
just try to expand our assumptions that
is we want to the such as a bit
landscape will be depends around the
feature of X such as a time feature or
location feature and also we want to use
the exploration exploitation strategies
during our Peter to connect the data
because everyone knows that only if you
bid hard you can have the adding
question and then you can train your
data if you lose you cannot know what
the user will will feed back so this is
a biased trading situation in display
advertising and also responsive search
and also we will try to look at the
roadblocks that is you want you will try
to buy several combinatorial I'll sort
in one page of view because if this page
was dominated by your ads actually some
analytics say they're today's
advertising performance will be even
higher than the sum of the individual
added impression and also we will look
at the dynamic process aspect of the
bill
that is the changing of the market price
and also the users click model which to
balance the reward and the uncertainty
of your advertising performance so risk
aware bidding strategy will be another
very important research topic niche okay
thanks
you're hearing our unsetting way way
many care about headaches but of course
you can care about the competition that
you even have less training data
corrosion in the sparse their click so
and also different advertisers will have
different conversion definition so here
we managed to study the clicks so I
think we also useful to use the semantic
neighborhood be you between the so
statistical semantically twins between
users classes of users based on browsing
history because in the beginning the
example was that you're searching for
booking hotels and then you are in
nursing at behavioral targeting is more
important than contextual yeah but at
the end if you actually don't know what
is semantics with interest of the user
it doesn't really matter for for your
bidding function right
you mean the semantics between the
context and your nads let's say sorry
the user interests they're using okay so
actually in each tsp in each T month up
top and we actually are implicitly you
stick to the user segmentation so only
actually if you say if you like and
science this is a user segmentation but
actually you like if you if this page is
is this as if is about general research
you actually have the you know so
semantic relevance right but insert
currently in this current platform we
don't use user signature gesture the
user which we don't use the semantic
relevance just to use the segmentation
directly match okay yes that's a good
oh please
yeah related to the question the clicks
you know in our company their
advertisers complained that though the
rhythm buys lots of clicks advise they
say oh it buys lots of cheap books and
these cheap clicks a really crappy place
because the they're not clicks the lead
to conversions and then so on so we look
at like these sort of bounce rates as
well non non bounce clicks or sort of
quality clicks but I was just wondering
whether you know in your framework you
have anything kind of you could say
about the quality aspect of buying lots
of clicks actually it takes any kind of
feedback called matrix are they at the
object object you want to optimize so
the only reason we use the click is in a
commutation it says click and especially
in the search season the wait for the
conversion is 1 that means the
conversion is equally important as a
click so that that's why we that's why
we followed that tradition and you're
that in the model because clicks are
easier easier to understand and it
removes the you know sparse observation
problem but the motor itself can take
any kind of feedback as the object and
actually in the in the paper we also
evaluated the combination of clicks and
conversions you know you can give
conversions a very high weight right in
the beginning you don't have any
conversions at all but the clicks plays
the as the object then you have several
conversions which plays a more important
rule naturally in the model itself so
here the framework is trying to optimize
the campaign's levels KPI actually you
can define the KPI what is the KPI you
could be the impression number plus plus
curriculum click
the conversion number you can define
yourself any you don't model your
competitors in this framework so what I
asking because I know they say that
there are some patterns where the cost
of the the beating cost depends also on
time on day of week on the other Optima
because they have a receiver budget they
have lots of money to spend and they
just spend and even some companies spend
the money at every 30 minutes we spend
more money every 30 minutes and on the
other time so do you think in future
work to consider absolutely yes that's
totally true and that's the probably the
most important part of the future it's a
first one of the future work well they
market competition leads to the
difference in landscape distribution if
the competition is high you can you will
win less even if you meet hard right
that's that's what we call the paid
landscape and at the moment in this
framework we assume this in landscape is
static and it totally depends on how
much of it and yes has nothing to do
with a market outside market but Sun you
know the future workers will be doing
that dynamically the consider the
competition and probably you know as
some decay factor to it because you know
the recent information is more valuable
would you have information on those
kinds of families do you have any
information on how maybe yours have
changed we don't have the auctions we
know you're right so you know the
I seem to functional form for the wind
rate and then you derive the bidding
rule from the equation from any
differential equation is that is that
right yeah if you do that what you're
suggesting there learn with rate
function and vertically is it easier
than to turn that function into East you
do you mean to learn that in Kirkland
you mean still some kind of oh why we
use these kind of winning function is
because we notice that the data is look
like this
we probabilities and you can pay from
them we give I arrived to contravene
functions here and you of course the for
some campaigns may be the weighting
function is different and you can
propose different weighting function
formula actually this is an open more
doing or you know framework that's the
slide you can see the shape of the
actual winning function is not very
complicated you can always find the
curve that fits to it
very nice other problem is this curve
changes this is the dynamic dynamic
length PD Netscape this is the campaign
the right way to slice the orange candy
you have the target you have a target
group and then you will have you will
receive the bitter requester which
matches your talking yeah well you try
our bidding functioning in your platform
I would like to know
yes very much because it's just linear
but it's basically just total linear
function of the of the predictor CTO or
predicted commercial instead of the
bargain cry limited sorry can you set
the barges quite a limited you just used
a very limited partner to do the
comparison thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>