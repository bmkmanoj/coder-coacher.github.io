<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Theano and PyLearn | Coder Coacher - Coaching Coders</title><meta content="Theano and PyLearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Theano and PyLearn</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/x5Xf79Q-wM8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi I welcome to this presentation on
piano part 92 and Libby Perry GPU re i
am frederick passion and a buck van mary
bar we are from the alicia lab at the
university of montreal in canada I know
I look like an undergrad but it's my ATM
staff at the little lab at the
University so at a high level I present
our software stack it is based on
fightin then there's the new PI sci-fi
and Lib Shapira i read that provide some
functionality then you build on top of
that and they respond to that is on top
of Tendo so I suppose you know python
but it's a object-oriented cutting
language nope i prevail provide the base
object that we use entiendo it's an N
dimensional array object and it provide
many shins free computing functionality
site by add a sparse matrix object and
even more since the computing
functionality leave the aviary provide a
GPU and dimensional array that is based
in sheep and it worked for cuda and
opens here piano itself is a compiler it
worked on the symbolic on a graph and
can and the user can do graph
manipulation for example doing the
dative active and partnering to is the
machine learning framework on top of
that software stack so python is a
general purpose I leave all
object-oriented language it and fancies
code readability there is a very big
sandal library and many optional
packages that can exist it is adamant
dynamically type in and the memory
maintenance management is automatic one
of the inconvenience of Potomac can be
consider it as slow as it is interpreted
scripted language but it is easily
accessible with see and there's many of
the software like the hood that's use
that functionality to give a great speed
up and this is and python is pretty
popular in web development and
scientific computing since if it
communities so one of the problem for
hpc on pattern is an owl object or I'll
element or object event floats so that's
not great but then PI provide the N
dimensional arrays the average like was
told in the previous presentation
written a load to do slices on that
return view and the slices can be traded
so pimp I provide many operation like a
limb Wozniak as a bellyful VA random
numbers CyHi provide more than that and
it's used solvers optimization
algorithms matlab compatible there's
many other libre he that i won't talk
about for plotting and moral evil and
interactive shell so what's missing with
that stack if other operation are non
lazy that means they must be evaluated
as soon as the line is it is bound to
the cpu there is no a symbolic
representation and there is no automatic
differentiation and there is no
automatic optimization for spin or for
numerical stability that's what train
ten would try to provide dando by itself
is a domain-specific language that is
teller it for numeric competition we try
to mimic as much as we can then in
percentage it can a compile most
expression to see for cpu oh and or GPU
we limit the expressivity of pattern
that can be and led by a channel for
example there is no super thin so we can
do global optimization and
computation grass it is strongly type
edge so we can generate the good code
beyond the sheen to see as the object
our array object there's directing the
user graph competition a very high level
of parallel ishment so we can
efficiently use the GPU at this level
and their support for looping and
branching so tenho admony automatic
optimization for speed and numerical
precision as Python a low is the exam
extensibility with C code we keep that
with tian dou xiao tian dou can reuse
type i blush it down but i could ah ku
dah for speed up and there we can use in
fact everything that is accessible from
she so we do automatic differentiation
on the graph but we also have air
operation and l operation that are used
for asian free optimization so you don't
need to compute all of them manually it
can be done automatically by 10 and with
sport sparse matrices under CP so
partnering to is a machine liberally it
is made for researcher so if you want a
black bug system don't look in 2.2 I
know there's a start-up that's you spurn
to and provide the black box interfacial
pen and to was made to provide that was
made to it make sorry the goal of
pioneering to is to make the research
easier so we wanted to make it easy for
the user to specify variant of different
machine learning algorithm and try
different combination it is very modular
and configuration the user can use
pattern to via to interface via a ml
configuration file or directly in Python
partnering to contain many scripts for
visualizing wage and plotting monitoring
value so just a little bit of it work
there's T a new that provide the base
layer for object in the graph you will
have just an illumise multiplication and
you will build on those basic elements
panel to give a layer level of
representation when you can have one
layer of your narrow neural network for
example the fact that the gradient is
defended at the basic element make that
just swapping some basic element in
neural computation graph make that you
don't need to re-implement the gradient
the gradient is made directly under 1000
level and there's the other project it's
the newest project its leaves if you re
it is a command and dimensional GPU
algae on the GPU that is for both cuda
and opencl come on right now it's just
us it's our goal to be comin that's why
we made it at this level it's not
binding tube stone there's a Teton
binding that exists but it is completely
independent from the lib CPU ally itself
so why do we created a new objects it's
a few years ago we found that just in
the Python community there was at least
six different GPU array objects the fact
that we have many different GPU array
object is that if one of the stem f1
functionality it makes it harder to port
it to the drain system that's why we
want to add something more common we
want it to work also with other language
support to ever more community that's
why we met it at the sea level I'll
dolls a different area also have
different interface and they are mostly
income and compatible between each other
you need to think about it when you do
the conversion between wind system and
the
others because they don't have the same
memory layout properties and stuff like
that but they are all a subset of new p
and dra properties that's why we try to
mimic it at the GPU level and the
syllable this is the new backend for
piano so the goal of this for stack of
this tag is to be fast to develop a new
machine learning algorithm fast to
execute all right hello everyone so I'm
Bart I'm a first year student at the lab
and I'm going to talk a little bit more
about the yellow give you an example of
how it works and i'll talk a little bit
more about Pilar into which is the
project i'm mainly working on fred is
more of a developer in piano so quick
recap so tno is the mathematical
symbolic expression compiler we it
mimics numpy syntax up to the point
where very often you can actually use
code that'll work both on an umpire
rayon on a piano variable you don't have
to change anything in the background it
creates all the see included code using
a variety of methods whichever one you
want to use PI kudasai tandem number to
create the kind of fast running code
that we want because we're working with
a symbolic graph computational graph we
can do efficient differentiation and
before we actually compile our code we
can do a lot of speed and stability
optimization so you can look at the
graph and you can see which combinations
of operations would could become
numerically unstable you can replace
these computations with alternative
computations which give you the same
result but in a more numerically stable
way and often maybe you apply certain
operations in a sequence in a you know
in the end turn out to be the identity
you can just kind of take out that part
of the graph optimize them in another
way so tno is really good at if you give
it very kind of numerically unstable
things we're tiny numerical values like
log 1 plus X then it'll give you the
right answer even for kind of like these
values
on the fringe piano has very extensive
unit testing and sell verification so in
general it's it's pretty good that even
with all the optimizations you know that
the answer that comes out you can be
pretty confident it is numerically the
correct answer it works on online ups
but also Mac works on windows as Fred
mentioned it uses a GPU you can use the
GPU very easily it's as simple as
setting one environment flag in in your
shell and it'll automatically switch
between CPU GPU very easy for
development although on GPU right now
it's just 32-bit floating point numbers
although one slip GPU rate becomes a new
back-end to TMO will have support for a
lot more and on Windows support is
limited in the sense that none of the
developers actually use Windows but
everything should work fine as it is and
spars operations are only in CPUs so
here's a simple example of how you use
piano in in Python so you just import
the framework you clear your your
symbolic factors in this case is a
vector with floating point values you
build your symbolic expression so you
use the kind of notation you see from
numpy from Python itself so in the
background Python converted this into a
symbolic graph which is a plus a to the
power 10 and once we actually want to do
the numerical calculation we asked the
n.o to compile a list so we asked piano
for the part of the graph that takes a
is an input and gets bees and output and
the background piano will see which part
of the graph it needs optimize it make
sure it's numerically stable compile it
the C code and then give you a Python
handle to this compiled code you can
actually done pass Python values to it
it will run the computation and it'll
give you a nice numpy right back so
here's an example of the graph we've
just created on the left and on the
right you see with the graph looks like
after theano is kind
optimize it so you see that the kind of
graph optimization help speed things up
quite a lot because large graphs can
often end up being very small if you
optimize them so piano has been around
for a while over six and a half years
it's been used a lot in research
especially at our lab it's it's tool
almost everyone uses as over the years
is it's pretty well documented we think
it's God lively mailing list but also
with a lot of people from outside of our
lab it's also used in industry few
startups have used it Google views that
you know uses that universities teach it
so all in all it's is pretty stable and
I think will support it software sted a
little bit about Pilar to which is the
kind of machine learning framework as
fragmented build on top of it so the
idea of parlan two is that it provides
you bits and pieces that you need in
machine learning and you can kind of use
use each of them separately so you can
implement your own model in Python and
as long as you make sure that the kind
of a few basic interfaces are there you
can use parlance to training algorithms
to train it or you can you advise first
so you can write the model in parlin to
and use your own cost of training out
we're going to train it so if you've the
kind of objects and bits and pieces that
it provides for the trading algorithms
like SGD we'll also more model specific
algorithms it provides costs so
different ways of calculating supervised
unsupervised cost exact estimated also
magnetic likelihood score matching noise
contrastive estimation etc there's a few
monitoring methods which allow you to
monitor also the parameters and hyper
parameters which are very important
during the training of neural networks
so even though kind of want to determine
to stop training your termination
criteria even those are kind of all
factored out so you can use them very
individually so if you want to do
something strange with you know ending
your training in a different point in
time then you can just kind of use
everything from pilot too but only
change that part so training extensions
can be our can be used to kind of
perform other actions
training process then there's your
actual models so a lot of lot of them
have been implemented in Parliament too
so it's mostly used for neural networks
to do convolutional networks we can also
do restricted Boltzmann machines deep
Boltzmann machines and either they're
kind of more traditional svms k-means
pca like everything is implemented in
pilot to you just kind of use it as the
data set so there's there are dataset
wrappers for kind of the most common
data sets that we use so amnesty for 10
so if you just kind of want to use pile
and doing your own data set just write a
rapper plug it in and everything should
work it's Fred mentioned you can do it
in two ways you can just access point
you from your Python scripts but you can
also use llamo file so those are just
txt files where you kind of say i want
this model I want this training
algorithm I was with these hyper
parameters you load it into pile and two
from the command line managed to just
train one other kind of obstruction part
line to ads is data specification so
instead of working with the raw data we
describe how Ireland to should interpret
this data so if you have your your
labels for EM nests which urges integers
that's a 1d array of integers you tell
pile onto two interpreters as in DC's so
it can automatically convert between
that and have one hot factors or can
automatically convert between images and
kind of resemble flat floating-point
arrays so the kind of data specification
structure we have is actually quite
powerful and very long island to in the
background move between all of these
different representations of numerical
data so you don't have to worry about
that whether you're whether your words
are represented as integers or one heart
vectors it does all of that
automatically for you parlin too has
been has been around as long as piano
but it has been used in quite a few
scientific publications as well it's
been used to compete and I think wind
cattle competitions and a lot of people
at our lab use it it's still developing
very quickly although we've tried to
make sure that now the ape
p I doesn't change change anymore so you
don't worry about starting to use it
documentation for like the core parts
are all there and they're quite good but
working very hard trying to get all like
all the parts to the library documented
and that's quickly improving but we do
have an active mailing list if you want
to use it and you have any questions you
can always email and be sure to get a
response like mostly within a day there
are a few features which you know
currently being developed to think of
our interesting so recurrent neural
networks are currently being implemented
better hyper barometer search report all
that stuff is being worked on and should
be in there with like the next couple of
months so now I'll give it back to
Freddy is going to talk a bit more about
the details of the lib GPU array
so as told the gold of the project is to
become and so the base objection she and
we want people from all other software
to use it but we are mounted I'm sure to
not be too much simple many of the
system that a van GPU I object just
support for example a fixed number of
mission like a matrices we want to be
generate to be able to cover much more a
different type of algorithm and domain
we want to support all the type we want
to keep traded views to limit the number
of memory copy and lower the memory
usage but we also want to make it easy
to add new implementation so if we have
a much more complicated memory layout or
at least a possibility of having a more
complicated memory layout we have also
many function to automatic convert with
the basic a memory layout like see Fatah
or Fortran other memory layout that way
if you want to add a new functionality
you don't need to take care about all
the added complexity if you don't want
to because you just want to go fast with
a new implementation so currently you
can use it but it's not all
implementation that are available the
municipal GPU back end ad lib shipping
available work this is already you said
by 10 do but not by default there's
still a few of the current a GPU
implementation that I've not been ported
to decimal system for the opencl version
it also work in 10 do but it missed more
functionality and the middle GPU is
underway so in conclusion this stack of
software tried to provide a good
environment for our communities where it
is fast to develop and fast to execute
at the same time
so I would like to talk and to thank our
people working or having work at Lisa
I'll TN do parent who user contributor
and then if you don't come to contribute
code it's pretty l food to know that
some error message is not good having
feedback from the user is always great
at all was to make the software better
and we want to we want also to thank our
on our funding and agencies thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>