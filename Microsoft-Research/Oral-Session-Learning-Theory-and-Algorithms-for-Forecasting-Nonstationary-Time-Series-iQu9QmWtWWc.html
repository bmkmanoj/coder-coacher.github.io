<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oral Session: Learning Theory and Algorithms for Forecasting Non-stationary Time Series | Coder Coacher - Coaching Coders</title><meta content="Oral Session: Learning Theory and Algorithms for Forecasting Non-stationary Time Series - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Oral Session: Learning Theory and Algorithms for Forecasting Non-stationary Time Series</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iQu9QmWtWWc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so let me introduce the next oral
presentations which is about the
learning theory and algorithm for
forecasting non stationary time series
and the talk will be given by the
vitally kuznetsov in the current
institute and nyu thank you for the
introduction let me just set up my
slides here
and thank you again for the introduction
it is my great pleasure to present my
joint work with Mary amore on learning
theory and algorithms or time series
prediction so let me start by telling
you what i mean by time series
prediction and i will do that by
contrasting this setting with the
standard learning scenario in the
standard learning scenario the learner
receives labeled sample which is assumed
to be drawn iid from some unknown
distribution and then the goal is to
predict the labels wise on unseen
examples axis which are again assumed to
be drawn iid from the same unknown
distribution now in time series
prediction the learner now receives a
realization of a stochastic process X 1
X 2 up to X T and the goal of the
learner is to forecast the next value of
the stochastic process X T plus 1 of
course in general there might be
dependencies between these random
variables and they may even have
different distributions so in general
iid assumption may not be valid so how
can we analyze this setting right how
can we derive algorithms for forecasting
time series in the absence of this
assumption well the standard way to
proceed is to assume that the underlying
stochastic process is stationary or
suitably mixing stationarity simply
means that the distribution of your
stochastic process does not change with
time and mixing is a slightly more
technical condition but roughly speaking
it means that the dependency of your
stochastic process on its past decays
with time so these two assumptions may
seem rather natural twist the first side
and indeed they have been widely adopted
in machine learning and statistics
literature
right but are these the right
assumptions let me criticize a little
bit these two notions first of all both
of these notions stationarity and mixing
they consider only the distribution of
the underlying stochastic process and
they actually ignore other key
components of the learning problem such
as the loss function and the hypothesis
set these assumptions are not testable
except for some trivial cases and
moreover in fact it is often the case
that these assumptions are actually not
valid and let's let us look at the very
simple example first suppose I flip a
fair coin and once and for all and if I
see heads then my stochastic process
traces out a sine curve and if I see
tails then my stochastic process will
trace out a cosine curve it's actually
easy to see that this stochastic process
is not going to be stationary simply by
observing that the mean of this
stochastic process is not constant and
it is also fairly easy to see that this
stochastic process is not mixing and you
can do that by recognizing that the past
of this stochastic process completely
determines its future so existing Theory
sort of suggests me that learning should
not be possible in this case yet
learning or forecasting in this setting
is trivial right I just told you that
the past of the stochastic process
completely determines its future okay so
this is just a simple example but there
are many other real-world examples of
stochastic processes that are non
stationary and non mixing so for
instance so-called long memory or
fractional arima models may not be
mixing just by their nature
markov chains most widely used
stochastic process and applications is
not going to be stationary unless it
started in an equilibrium distribution
in fact most of the stochastic processes
with a trend or seasonal component are
not stationary so it is natural to ask
whether it is even possible to learn
with this stochastic processes so and
this is precisely the question that I'm
going to focus on in this top so I'll
start by giving you some definitions and
tools that we're going to need and then
i will discuss learning theory for time
series prediction and i will use this
theory then to present some algorithmic
solutions for this problem ok so let us
start by examining the goal of the
learner in time series prediction a
little more formally in the standard
learning scenario with iid data when we
fix the hypothesis set and the loss
function the goal of the learner is to
find the hypothesis with the smallest
possible generalization error that is
the smallest possible expected loss on
unseen data however when it comes to
time series prediction we're actually
facing our first challenge because this
is not immediately clear what the goal
of the learner should be in this setting
so one natural option is to seek a
hypothesis that has the smallest
expected loss in the near future
conditioned on the whole history that we
have observed and this intuition is
captured by so-called path-dependent
generalization error that you see at the
bottom of this slide so how can we
analyze this pilot path-dependent error
right because I told you that we don't
want to rely on assumptions such as
stationarity and mix
so what are the tools that we can use
for this analysis well there are two key
ingredients that we will require for
this analysis and the first key
ingredient that we're going to need is
the notion of so-called expected
sequential covering numbers so if you're
familiar with covering numbers from
classical learning theories then you
could think of these as natural
extensions of classical notions to the
setting of sequential data the second
major ingredient that will need is the
notion of discrepancy measure which will
help us to quantify the divergence
between the distribution of the future
that we are trying to predict and the
distribution of the sample that we're
observing in these circles focus on
discrepancy measure due to the time
limitation but I would like to emphasize
that covering numbers are also a key
component of this theory okay so what
exactly is this discrepancy measure is
defined to be the maximum possible
difference between the generalization
error of the hypothesis in the near
future and its generalization error on
the sample that we are observing and one
can think of this discrepancy as a
natural measure of non stationarity of
the stochastic process for instance if
the sequence of random variables that I
was observing was actually I ID then the
discrepancy would be exactly zero more
interestingly if we're doing with a
large class of weekly stationary
stochastic processes with squared loss
and linear hypothesis then the
discrepancy is exactly zero again and
this actually highlights an important
property of discrepancy that it captures
not only the distribution of the
stochastic process but also the loss
function and the hypothesis said that is
being used discrepancy is a new notion
but it is closely related to other
generalized kolmogorov-smirnov distances
that have been previously considered in
the main adaptation
and drifting settings it has a number of
other additional useful properties such
as it admits upper bounds in terms of
familiar distances between distributions
such as a 1 distance relative entropy
mixing coefficients and so on but most
importantly at least in my view under
some additional mild assumptions
discrepancy can be estimated from data
ok I think now we have all the tools
that we need to present our learning
grantees and what we show is that with
high probability uniformly over
hypothesis set but dependent
generalization error is going to be
bounded by the following three terms the
familiar empirical air on the sample
discrepancy that I have just mentioned
and term that captures the complexity of
the hypothesis said that is being used
and this term is expressed in terms of
the expected sequential covering numbers
that I have mentioned earlier now since
we have non stationarity in our data it
may not make sense to value the errors
of hypothesis on a different sample
points in the same way and in fact it
may make more sense to emphasize certain
sample points more than the other sample
points right and it turns out that
actually we can replace the uniform
weights 1 over T in this bound by an
arbitrary probability distribution Q
over the sample points and the exact
result is on this slide this is going to
be important for us later on when we
derive our algorithmic solutions but
before we get to talk about algorithm
solutions i would also like to talk
about discrepancy estimation because
it's also very important for algorithms
the bad news is that in general
estimating discrepancy directly is
hopeless this is simply because as you
may remember at
scrappin see depends on the distribution
of the future that we are trying to
predict and we never receive any samples
from the distribution of the future but
we can upper bound discrepancy by Delta
1 and Delta 2 where Delta one is the
discrepancy between the recent history
of the stochastic process and the whole
sample and Delta 2 is the discrepancy
between this recent history and the
future that we are trying to predict now
Delta 1 as we will see on the next slide
can be estimated from the data and Delta
2 is assumed to be small this is this
turn out to be actually a rather mild
assumption because one can show that
even in the case of drifting which is a
sub case of the problem that we are
considering here this Delta 2 enters a
lower bound on the generalization error
making the learning hard if this
quantity Delta 2 is large okay so our
final learning guarantee is presented on
this slide and the difference with the
previous result is that we replace
discrepancy by two terms Delta to that I
have just explained to you and empirical
discrepancy Delta tilde and this
empirical discrepancy is defined to be
the maximum possible difference between
the air on the recent history and the Q
weighted empirical error on the whole
sample these are the first learning
grantees for non stationary non mixing
processes and these grantees are data
dependent and it is important that these
grantees are data dependent because it
allows us to derive algorithms for time
series prediction by simply directly
optimizing this upper bound so in
particular we propose to optimize the
following objective we the objective
consists of the following four terms the
first term
take you waited empirical l2 loss the
second term is the Q weighted empirical
discrepancy that we have discussed and
the last two terms are regularization
terms the first regularization term
controls the complexity of the linear
hypothesis that we are using and the
last term controls the deviation of the
distribution cue from the uniform
distribution now the unfortunate
property of this formulation is that
since the optimization is joint over Q
and W this optimization problem is not
convex but it turns out that using
duality change of variables and slightly
restricting the domain of the
optimization we can arrive on an
alternative formulation which is going
to be convex and that's a nice property
the final ingredient that we need for
our algorithm is computation of
discrepancy because as I have mentioned
to you discrepancy is used as an input
to our algorithm right and let me tell
you how to do that so here is again the
definition of empirical discrepancy at
the top of this slide and as you can see
that in general finding this discrepancy
is a non convex optimization problem but
if the loss function that you're working
with is actually a convex loss function
then you realize that this optimization
problem is a difference of convex
functions optimization problem and one
can use a DC algorithm for instance this
algorithm of tau and ant to solve this
optimization problem moreover if the
loss function is the squared loss as it
is the case for us DC algorithm can be
shown to recover the global solution to
this optimization problem which is nice
again since we can accurately find the
inputs to our algorithm
okay I'll conclude in summary we present
the first learning guarantees for
learning with non stationary non mixing
processes our grantees are data
dependent and they're expressed in terms
of a discrepancy measure that can be
estimated from data and we use this
theory to provide some algorithmic
solutions for forecasting non stationary
time series now in this talk I've
focused mainly on the theory due to the
time constraints but we have implemented
these algorithms and we have some
favorable preliminary experimental
results for this and I would be happy to
talk about this at the poster so that
concludes my presentation thank you for
attention and I would also like to use
this opportunity to invite all of you to
a time series workshop that we are
organizing this Friday thank you okay so
we can take a few questions but in the
meantime I would like to ask your
spotlight presenters to start up lining
up here so any questions
then let me let me ask you questions
actually and the discrepancy measure you
introduce this is something related to
the rad marker complex theory well it's
not directly related to redeemer
complexity but it's similar in this in
the sense that it captures not only the
distribution of the probe the process
but also the loss function and the
hypothesis set so it's fully captures
all all the relevant notions to the
learning problem okay good yes one
questions hi thanks very interesting
question about Delta to the piece of the
discrepancy that needs to be small over
learning to be possible what can we do
with the available data to check that or
try to look at the rate at which in the
historical past of the sequence it in
fact wasn't small and well it's one of
those lines you can sort the fluke at
Delta 1 and if Delta one is actually
smaller than you could you could expect
that hopefully Delta 2 is small but I
mean in the verse very adversarial case
right if I give you one stochastic
process and then I try to ask you to
predict something completely relevant
than the quantity like that should enter
the bound right and this is exactly
Delta 2 okay so you need to impose some
kind of idea of regularity in order to
say yeah i mean if again if you're
trying to you if you see irrelevant
sample then you shouldn't be able to
predict through it yeah thanks okay it's
very interesting work so my question is
that whether discrepancy and Express
sequential covering enough to
characterize what is learnable like in
other words is it possible that there is
a learnable problem but discrepancy or
sequential the covering either of them
are infinite
so you're essentially asking for the
lower balance it's okay so yeah they're
in certain special cases for instance
just for sequences right in online
learning right the sequential covering
numbers completely characterized
learning in that setting and
discrepancies I said enter the lower
bound evening's in special cases for
this scenario like drifting
generalization error can be lower
bounded in terms of the discrepancies so
yes if either of those quantities are
infinite then you wouldn't be able to
learn all right okay still left thanks
to a speaker again
my stuff
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>