<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Panel 1 - Capturing the Research Lifecycle | Coder Coacher - Coaching Coders</title><meta content="Panel 1 - Capturing the Research Lifecycle - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Panel 1 - Capturing the Research Lifecycle</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-8pLJO7ajAg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so good morning everybody and welcome to
the first panel of the morning and
entitled capturing the research
lifecycle my name is Courtney Soderbergh
and I'm the statistical and
methodological consultant at the Center
for open science we're a non-profit
startup in Charlottesville Virginia and
this morning we have a great panel of
people who are working on increasing the
openness reproducibility and
accessibility of many different points
across the entire research lifecycle so
over the past couple of years there's
been a growing movement to increase the
openness and transparency of science as
well as the reproducibility of science
and so what we will be happy you today
is leading organizations and companies
who are working towards that movement
we're going to talk a little bit about
how we are trying to accomplish those
goals and also some of the challenges
we've encountered while working towards
those goals so together our panelists
represent work that is going on at many
different points in the research
lifecycle so we have tim gardner from
riffin a company that is working on
automating data acquisition and analysis
to increase reproducibility arfin smith
from github a company working on sharing
and collaborative coding Ryan Dooley
from Texas Advanced Computing Texas
Advanced Computing Center there we go a
leading youth University
high-performance computing center that's
working on sharing code and scientific
data we also have Lars Nielsen from zen
odo a project out of CERN working on the
sharing inside ability of data and code
we have jon lees Miller from overleaf a
company working on creating
collaborative tools for publishing and
writing we have Robert Spiegel from
publicized an organization working on
increasing the dissemination of
scientific research and we have me less
awkward way to say that from the Center
for open science a nonprofit working on
increasing the connectivity
documentation and openness across the
entire scientific workflow using our
infrastructure project to open science
framework so how this is going to work
is we'll start out with everybody giving
two to three minute lightning talk so
you get a better understanding of who we
all are and what we do but the majority
of the panel will be four panel
discussion and Q&amp;amp;A from the audience
so I'll go ahead and start us off as I
mentioned I'm from the Center for open
science we're a nonprofit organization
who is dedicated to increasing the
openness reproducibility and
transparency of the ensign of the entire
scientific workflow and we do this
through three major efforts don't worry
so the first is our meta science project
so we do science where's the cyclic ha
so right so the first is meta science
project so we do science on science and
we do this to be able to track the
extent of reproducibility issues and
also look at how changes in scientific
behavior leads to changes in the quality
of scientific output we also have
community efforts so working on training
scientists and better open and
reproducible practice as well as getting
journals to adopt open standards and
practices and finally we have our
infrastructure project to the open
science framework which is really about
it's a free open-source platform that is
trying to make it easy for scientists to
implement these open and reproducible
practices so as I mentioned the open
science framework is a free open source
web tool and it's really trying to
connect document and archive and also
make openly accessible the entire
research workflow so everything from the
beginning implementation of a project
idea all the way through publication and
post-publication discussion to making
that research and data searchable and
discoverable by other researchers so the
OSF does this by allowing researchers
and their collaborators to upload all
the files related to a research project
so they can upload all the input and
output a research problem sorry research
project in one central location there's
also automatic logging and versioning so
that the evolution of a project is
documented and then with one click of a
button up here they can either make the
entire project or parts of that project
publicly accessible and searchable so
that other researchers can find their
research output and input and also use
it inside it so the research kind of
propagates to other research projects
and so by making this very easy for
scientists to do and putting it at all
one location what we hope to do is make
open and reproducible practices more
normative throughout science we also
connect the OSF to a growing growing
list of add-ons which currently includes
dataverse big share dropbox github and
amazon s3 and the reason we do this is
to allow researchers to continue to work
with the tools that they like and they
are familiar with so rather than rather
than requiring researchers to make this
huge overhaul to their workflow in one
fell swoop we allow them to kind of make
slow changes to the workflow so they can
still use these tools but they're all
connected in one central hub and the
reason why this is useful is that a
makes things less likely to get lost so
if you have some of your project and
your email and some on a server and some
on your collaborators laptop these
pieces and parts can get easily
disconnected and things can go missing
but it also makes it easier to share
that entire project with your
collaborators and with other scientists
and so it's really about meeting
researchers where they are so allowing
these kind of incremental changes to the
workflow which will lower the barriers
to implementation by scientists because
they don't have to make this huge
overhaul and so the aim is to make it
easy for researchers to make these
choices and these workflow changes to
allow open transparent and reproducible
scientific workflows for everyone all
right so next up are these all on one
slide deck or okay yep cool okay thank
somebody um so my name is almost myth I
work at a company called yeah and we've
got a cool thing in the corner oh there
we go all right so I'm apologies for the
stupid title I was trying to think of
something funny so I work at github
before get hub i co-founded a
crowdsourcing platform called universe
we did lots of citizen science I'm
interested in tools that help people do
research better together basically so
very briefly
I go to the next late clicker this one
okay so what's github well github is a
place where people do software
development together why can't I scroll
this way just get page to page sorry all
right let's just see how we got them
okay so github as a platform where
people build software together there's
about 10 million people working up there
and there's about 15 million software
repositories so these are places where
people actually collaborate around
software development together um the the
way that I usually explain research to
researchers version control is this most
of you probably have a folder on your
computer or many folders on your
computer that look exactly like this
maybe with some other versioning
technology that you're using my PhD
supervisor by the way used underscores
instead of naming conventions like this
because if you put a number and an
underscore at the start of a file name
in most operating systems that jumps to
the top of the tree so you can put
multiple underscores if you really want
to make it the latest one and that is
what he did this is obviously a terrible
idea so there are better ways to do this
which things like get so this is a
versioning technology here we've got
about 50 people writing mathematical
textbook hour and as you can see there's
sorry for the transitions this is the
way it's going to work you can see
time-based changes and each of those
changes if you look at those are you
know there's an explicit red-green-red
four lines taken away green four lines
added this is a technology get the
technology that powers this is a
technology that was developed originally
for managing the 20 or so million lines
in the linux kernel so the thing that I
spend most of my time thinking about in
github is increasing the status of
software in academia there's a in my
mind that I think in lots of people's
mind a fundamental problem and the way
that we do research and we credit
research activities that right now you
don't have a particularly good career if
you spend a lot of time writing software
in academia and so one of the one of the
things we can do to help with that is do
things like this this is a integration
that we put together
by our mutual api's with dinoto Lars is
going to talk in a second looking about
this may be a bit more about sort of
hacking the existing system so getting a
DOI for a github repo does that make it
sigh tible well it was already sizable
with its URL but it gives it something
that smells a little bit more like an
academic citation and so this is
actually something being used about
1,500 times now in the last six or so
months and fifteen hundred times as 1500
research software packages that have
been archived in zone odo not just you
know that's a relatively small fraction
of the tens of millions of repose up on
github but these are research ones the
thing that I'm most excited about when
thinking about github and the
opportunities of the platform within
academia is that there's actually a way
that open source communities people
build software together that's very
different from the way the academics
usually work and in short open source
communities are better at collaborating
than most of us because they have to be
because otherwise they wouldn't be able
to build something together and so when
we talk about open source lots of people
think this is a kind of sort of open or
Die rant about doing all of our doing
all of our software development or all
of our research open and in the public
and it doesn't actually have to mean
that the principles of open source ways
of working are actually things that we
would all recognize as a thing of value
and those are pretty simple they're
things like electronic communications
with all your communications being
available this doesn't mean email email
is not available unless you're going to
give everyone access to your inbox so
it's about everything having a URL the
process by which decisions were made
being exposed and this is again this is
actually an internal conversation thread
this is a screen grab of one of our
internal repositories that github where
we're making we're having a conversation
about a change in the product but I can
go back and look at that three years
later and see how that process came
about and this is a technology thing but
again some technologies allow lots of
processes to happen in parallel and then
conversations approval and increments
improve improvements in what you're
working on there
decision can be deferred till later so
this is actually the CMS software that
runs the detector on the Large Hadron
Collider this is lots and lots of
different development branches all been
worked on in parallel together at the
same time and decisions being made when
when sign-off is ready so open source
collaborations are lower friction and
academic ones usually and actually
fernando perez who writes the ipython
notebook had a great frozen a blog post
of his where he described open sources
being reproducible by necessity and i
think this is something there are
communities who work in reproducible
ways because they have to and so i think
i just wanted to say because we're about
to have a panel and you meant to set
yourself up by saying something stupid
you're going to regret later I don't
think reproducibility is a technology
problem or a new technology problem I
think reproducibility is actually a
workflow and cultural one and so I'll
stop there ok so I'm Ryan Dooley I'm
from Texas Advanced Computing Center it
is a if you've never heard of tak tak
focuses on operating a lot of the large
supercomputers for the academic science
computer I'm located in austin we're
hiring if you want to live in austin and
do cool stuff and play with great
technology come talk to me afterwards
but i am here talking about agave right
and gaba is the sciences service
platform and what do we mean by that
well it means that we it allows you to
run your scientific codes on HBC or
there's high-performance computers these
big big bay leaf clusters
high-throughput computing lots of little
computer spread out all over the place
they just need to turn through a bunch
of work or cloud resources manage your
data from the web and remember how you
did it all right it's it really just an
api platform very restful it's
multi-tenant hosted identity management
so we
and provide you with you know your your
ldap if you need it or we can plug into
your local identity solution we support
multiple I teepees like I said we have a
you know a standards-based
authentication mechanism we provide API
management we can run on-site or
off-site there's a lot of flexibility
the point is that it's a platform that
allows you to build your digital lab all
right so whereas I think the the Kino is
talking quite a bit about that the need
for infrastructure and the need to have
kind of these fundamental building
blocks that that other people can just
kind of take for granted like the
utility grid that's really what what
agave does right so is funded by the
National Science Foundation for about
ten years now it's adopted in several
countries joint funded internationally
we have data replication all over the
world and it's free free to use I'm just
coming use it you can fork it on github
or bitbucket and take it to do whatever
you want what to do but it's easiest if
you just think of it like a Salesforce
for science so it kind of meets your
needs if your developer great you have
API is to use if your service provider
great there's stuff for you to integrate
with if your infrastructure provider
there's ways for you to delegate and
kind of modernize your infrastructure
you're an educator it gives you rooms to
gives you a facility to really spur
discussion without having to understand
the underlying technology if you're a
researcher it just tells you to do your
science faster right so it's used in a
lot of different places these are kind
of larger funded projects for the
building web applications on at the left
hand side we also build mobile apps on
it at TAC are we eat our own dog boots
our mobile app is built on top of it and
it's also used to extend existing
processes so you know for all the coders
in the room here's the terminal okay so
one of the interesting things and I
think kind of the reason I'm here today
is it we've been working a lot with
docker reef recently to release /
reproducible science and whereas the
gamma really focuses on infrastructure
and providing you the mechanism for for
conducting your science and capturing
those experiments in a reproducible way
the code themselves tends to be a big
tripping point if you want to run in
environments it becomes very difficult
just having a social coding platform is
helpful for the development but you
still have to set up your environment I
mean all the DevOps processes involved
with it are huge roadblocks to people so
we've been working to build up this
application repository where people can
integrate a containerisation of dr.
ization of their their application codes
so they can share those in run those in
a very reproducible way using agavia
it's kind of an execution mechanism and
what that's allowed them to do is as a
researcher you can develop your code
locally you can develop it in
collaboration over a distributed source
control management solution and then you
can run it locally you can run it on
your local university systems in the
cloud in your local data center and a
private data center on all of these
commercial providers with a single
interface in a single way so that when
you have to go back and you have to
reference your your discovery you can
reference not only the the the the code
that you use in terms of a source code
you can actually reference a
reproducible docker image that someone
can pull down and it's a it's an answer
box right so it's just black box where
if you give it the same data it'll give
you the same answer and you can validate
the results they got were accurate and
that's been hugely helpful for us but
I'm going to run out of time here so I
just want to say if you need more
information here's some links and these
slides should be available on that
website
okay so yeah my name is LaShawn Nelson I
work for CERN and it's often assumed or
sonus but for those who don't know it's
the European Nuclear Research Center in
Geneva Switzerland we have a very large
research infrastructure that has been
running for nearly 60 years now and
basically we go here that's quite a lot
of ways to to lose your research data
here's just one example of a lost laptop
with crucial scientific dates and many
years of research work inside I have
more examples for those who want to see
it so basically what we're trying to do
with the nodal is make it as easy as
possible to get your research data into
a proper digital archive and avoid a
fate like this that's the cool part of
it and one way that we are trying to do
that is collaborating with github and
making it as easy as possible to
snapshot your software and get up and
give it a DUI and make sure that it is
available in the future so it works
pretty simple you sign in with your with
your github account you flip a switch
and your source code repository and then
you go to github start making releases
and every single time you make a release
we automatically track down a snapshot
you don't even have to worry anymore
about about getting it and you can even
using our DUI patches you can then
advertise that you actually have a DUI
and that you should cite this piece of
software if you're using it and not only
can we then wrap the software and get it
into Sonora we also export the software
again the one example is that we have a
community for high-energy physics where
we then grab software from github we
exported again to the high energy
physics repository called inspire and
they capable of actually linking this
software together with with the paper
that is citing this piece of software
it's all so just one example of how this
workflow can be made super easy for for
researchers so they don't really have to
think too much about
what's happening in the background and
that's basically it so i'm jon lees
miller i'm one of the co-founders head
overly so overly we're basically
building Google Docs or maybe I should
say office online for scientific papers
so it's online collaborative editing but
with a focus on features that scientists
need so we're now up to about a hundred
and fifty thousand users all over the
world and they've written over 1.5
million documents now on overleaf but
overleaf actually started as a much
smaller project it was basically
something that I wrote when I was a PhD
student just to make it easier for me
and my colleagues to write papers
together so we were we were using this
tool called etherpad which was like a
really basic sort of precursor to Google
Docs it was basically just an editable
text file in the cloud you could all go
in and you could write at least a draft
of your paper but it didn't really it
solved the collaboration problem really
well but it didn't do things like
figures or references or equations and
you couldn't really see the results of
what you were writing you know how it
would look in the end so so basically I
always sort of incremental II wrote
extensions to etherpad that would kind
of help solve these problems and it's
slightly embarrassing to show you what
the first version of overleaf looked
like in about twenty twelve it was very
basic that's what it looked like it was
basically an ether pad on the left there
you could write your source code so we
were all mathematicians so we would
write in latex because that's what we
like to use you could upload figures in
the files menu there and there was also
a real-time preview of the final type
set output you could finally see what it
was going to look like with done so it
was very basic but it was sort of
minimum viable product as they say got
it out there was on the internet people
started using it they invited their
collaborators and that's what really
could have kicked off the growth that
we've seen so fast wording Tuesday the
product has come on a lot but you can
still still see it got the same sort of
idea I'm you're right in this sort of
rich text manuscript view so
you don't have to know latex anymore to
use it it's it's all sort of hidden away
from you so you know if you write a blog
in wordpress you can either edit the
HTML directly or you can switch on rich
text mode and not have to worry about
the HTML we do basically the same thing
with latex underneath and you can switch
it off if you want to see the sauce
underneath other things that we've been
working on are around really making it
easy for people to manage different
versions so our phone had a great slide
that was pretty much how we use to
manage things except instead of dot docx
you with tech but you know final final
v1 final so now you can take your right
latex project you can compare any two
versions there's an integrated
commenting system you can have a
discussion in line in your document and
sort of manage those changes and see
who's changed what and then when you're
finished with your paper you can then
publish it to one of our publishing
partners we've now got about a dozen
people on board so for example if you're
going to submit to life sciences publish
your app 1000 research you can just
click a button and we send all the files
and all the metadata and all that stuff
over in the background so you don't have
to worry about it and we're sort of
building these integrations up now so
that with f1000 research in particular
when you submit that sort of back and
forth between their editorial staff and
you the author happens now on overleaf
so you don't have to send a bunch of
files around by email so that makes
everything just a little bit faster a
little bit nicer and that's really an
important part of the direction that we
see for overleaf which is the new name
for right latex which is our original
name it's all about one collaborative
editing it's about the rich text modes
you don't have to know latex to use it
and it's about bringing more of the
scientific process off of people's
laptops and out into the cloud because I
think that if you make that process easy
you then have a lot of options for how
you make it easy for people to to then
make things open and make things much
more transparent and that's a really
powerful idea so thanks for overleaf
hi everyone I'm rob seagull I'm the
founder of publicized and essentially
what publicize is is it's a science
communication platform to essentially
provide and help researchers formulate
the research into terms at any one can
understand so that we can start
disseminating research to different
audiences so I like to think of research
dissemination being broken down to three
different audiences first there's the
intra disciplinary audience and this is
kind of scientist to scientist of the
same field communication this is journal
articles and for obvious reasons this is
kind of what everyone this is basically
how everyone this is essentially the
most attention is paid towards this
audio and we can kind of see that here
today everyone's kind of talking about
how can we help researchers out better
communicate with other researchers but
there are two other audiences that
receive very little attention and that's
the interdisciplinary audience and the
public and as a result because these are
audiences that don't have the
terminology they haven't gained
experience for so many years and all the
terminology you have to reduce the
complexity and reduce the jargon and
this is a very difficult task and this
is something that's often overlooked so
in this in these two audiences the
interdisciplinary and the public this is
where really great things can happen
this is often where implementation
actually occurs when a researcher puts
out there all the information to someone
in the private sector who's not active
in research they can actually take this
knowledge and implement it there's lots
of obviously Crossfield collaboration
this is where people say from biology
can interact with someone from
atmospheric science to look at some
different research project and this
often doesn't happen when you know for
example I'm an atmospheric scientist I
don't go and read biology journal
articles so how is it that i can
actually discover the latest research in
a different field and then there's also
we obviously innovation this is when
different minds of different background
can actually bring new things to the
table so that we can innovate faster and
then policy also is extremely important
and that is a very very difficult
challenge how do we get this information
from us to people of the different
audience so that we can implement and
make change there are other examples as
well so this is kind of where publicized
sets publicize essentially the main goal
is to disseminate research in terms that
everyone can understand so we can take
all of this great knowledge that we have
and actually bring it to different
audiences so I've created a few months
ago I've created a kind of a Minimum
Viable Product and this is essentially a
website where scientists can go up and
they can essentially rewrite their
research article in about three to four
hundred words and there's guidance to
help the scientists formulate for a
different audience so they go up there
and there's kind of a back-and-forth
process so we essentially act as the
editor so that we can make sure that the
information is not only understandable
by the layperson also scientifically
accurate so that we don't have
miscommunication so we essentially have
this back and forth process where
publicise helped and then what you get
are these is this website with articles
written by the scientists that can be
systema nated on it throughout social
networks and anywhere else throughout
the internet and i'll leave it with that
a quick overview of all our panelists so
I guess we'll go ahead and open it up
for discussion questions from the
audience how do you prevent look down
into your platforms like we saw before
was portability as one solution I would
like to hear you know how to prevent
somebody working your platform and then
cannot take this away
oh I can go first if you like and so
with whatever leaf everything is still
stored in latex and lay tech is an
open-source technology has been around
for a long time you can always download
everything is one click and then compile
it locally or whatever else you want to
do it so we definitely don't lock people
in with riffin first of all all of the
design files will be exportable to an
open standard called animal anim l which
is an ASTM supported standard so it's a
container you can push it out its
text-based so if you don't have software
you can still read it or you can write
your own software for it well also we're
planning to make the entire driver
technology for data acquisition open
source as well our our platform is is
totally open source right so you can get
clone it and then you can you can just
do a darker build he will deploy the
entire thing all your data is exportable
and the systems and science that it
enables run on systems that we don't
know so you know you own your stuff you
you have access to it so get is
distributed technology by sort of
definition so github role is a
collaboration point around something
where anybody could host that
collaboration point I guess is probably
metadata associated with the
repositories that is not in the get data
but that can be exported there's a rich
API the people use so yeah sure okay
so the question was if if I cut afraid
how you can how you can win the login
prevent login yeah yeah prevent login so
at the sunoco the entire platform is
open-source GPL license on top of that
all the me today says cc0 license you
can take it away the actual data files
has a license attached to it if you own
that data there's nothing preventing you
from taking it out and putting it
somewhere else in with publicise I'm the
whole point is to get the information
out to everyone so it's inherently kind
of open source but essentially the way
that it works is a scientist own the
content so they're free to do whatever
they want and it's an open source and
they're simply licensing rights
licensing it out to me so that I can
publish an unpublicized but completely
owned by the scientist yeah and at the
OSF it's also completely open source
anything that you put up there you can
take down at any time you can download
files that you put up there and we also
have a sustainability fund in place so
if something were to happen to us the
whole system would be frozen at that
point in time and you would always be
able to get to anything you put up and
download it at any point in the future
right yeah go ahead yeah and then I'll
repeat questions repeating myself
worried so each of these products are
all a certain step in the kind of life
cycle of research from cat from getting
the files off your machine to the point
where you're disseminating it to a wider
audience through publicized so but this
is already six different things and I
just wanted to have people comment on
the idea that one solution fits all my
personal thing thinking is it shouldn't
but you know elsevier do a lot of that
what do you have to they can do
everything but it's a it's a lot of
stuff but otherwise we're expecting
everybody to sign up for italy
six accounts for things and then and
kind of where is the balance between
those things because yes some people
think one size fits all some people
think six different products is great
how do we link them all together should
I start okay so in terms of senato so
one is I think we need infrastructure
like all kids so we support the login
with orchid I think that's you know most
of the tools here should just support
that then we have one account that we
can all use and I really don't believe
in one tool for for doing everything I
think you have to do one thing really
well and then do the decoration less you
say between the two like for instance
the github integration that's we both
have I wouldn't know to be honest I mean
the problem i have in my roller covers
that the majority of users of github and
not academic users so the idea of an
orchid ID is sort of confusing yeah you
can't log in with your Facebook account
or your Twitter account to get help so I
would argue they would properly come
first before orchid that said if we
solve one then you know it's a standard
um as to so your question kind of gets
to what I was thinking about I i would
just reinforce what laws of saying i
think we like I think products are best
when they focus on solving one thing
well and get hubs role and it's been
kind of repurposed and academics very
good at hacking systems I think to do
what they want gabs trying to build the
best possible tool for building software
with other people just turns out the
lots of academic formats are versioned
well in gear and by github and so I
don't know I I think yeah I think it's a
potentially a problem having all these
products but I would rather see people
solve problems really well and then
expose their data and allow people to
build around their product I think
that's the way the web works yeah so I
got this kind of a low level piece you
can think of it like a platform so it
provides a federated out
authentication and authorization
framework so you can plug directly into
whatever you're already using so it
actually means you have one less account
that you need to use but in terms of you
know integrating with other applications
and building the entire stack on top of
that you know whether it be a center for
open science building you know execution
into their their framework then you most
of the time people don't know where
underneath right we power hundreds of
applications and no one knows yeah sure
so I I'll echo the sentiment that
probably we're not going to find a
single tool that does everything that
every scientist wants to do just because
scientists do so many different things
certainly at overleaf we've had quite a
lot of success sort of doing API
integrations I think open API is well
documented api's are very good things so
we integrate with fig share you can link
your right latex overleaf account to fig
share and we also now integrate with men
delays you can link your mendeley
account in your overleaf account so you
know I think that having this sort of
system where where things are separate
but can all interoperate is a much more
powerful idea than just trying to build
one monolithic tool yeah and I kind of
agree with that model as well publicised
is dramatically different and get out
for example you know so that's going to
be pretty difficult to be able to do
both of them really well but but yeah so
publicized is still in its very early
stage so we don't have anything you know
kind of fancy sign-in methods but but
that is definitely in the future I agree
with everything everyone said and I
think people are just fundamentally to
creative to try to constrain them to a
single company or person or
organizations view of how everything
should be done so you need to give them
the ability to to gain advantage from
the tool you provide but the flexibility
creative freedom to take it whatever
direction they want and I also think
there is something to be said for
allowing users to still use the tools
that they're used to in their
comfortable with but add on to that some
additional benefit so you know if you
really like you
dataverse but it can't do some things
you want allowing you to easily connect
that up with other things so rather than
having to overhaul your entire workflow
which is going to be harder for people
to do an implement allowing them to make
small changes but connect all of those
things up together so that everything is
still together and you can make it open
so I want to follow up on marks question
and actually one of my favorite quotes
from mark and a talk and talk to given
is if you build it researchers will do
whatever the hell they want so on that
theme can you talk about how you reach
out your audience the audience you've
built your products for and sort of as a
follow on that what happens when people
that you were not advertising to start
using your product using your services
for things you didn't anticipate and do
you pivot do you focus on your core
speak a little bit about reaching out to
your audience how do how do they
discover you and then what happens when
people start using your product in
unexpected ways
ok so i guess with with overleaf for as
it was known right lay tech there was a
very clear community of people that used
latex and so we built up connections in
the end of that communities you could
open late echt m plates and things in
right latex really easily we also do a
lot of work on social media and other
sort of fairly cheap ways of reaching
people so i guess pretty much right at
the start people started using where it
lay tech for things that i didn't think
they were going to like one of the first
documents on relay tech was actually a
wedding invitation as far as i know it's
the only one but you know people use it
for everything right so i think
definitely we've seen a lot of growth in
the sort of interdisciplinary science is
so if you have computational biologists
working with mathematicians or or
physicists and biologists you know
there's there's sort of an impedance
mismatch between the tools that each of
these people use and trying to provide a
platform that kind of does the enough
for both of them that they can both come
together and use it is I think a very
powerful idea and one that I'm quite
excited about seeing it with overleaf
now so with publicize this was actually
it's an interesting question this is was
my biggest concern with starting
publicize I didn't want anyone just
going writing any article in there it's
actually not published research so with
publicize their is essentially to even
be a scientist user you have to get
approved that you have been an author on
a published scientific paper so that
kind of eliminates that problem a little
bit but I think that what that actually
has done is kind of created a little bit
more closed of an environment and I
think that it probably would be more
beneficial to allow a little bit more
freedom not just published research to
be publicized essentially but yeah that
is that's definitely kind of a concern
because this is you know I'm trying to
build this brand that this is reputable
information so it is extremely important
to make sure that the information that's
posted is legitimate so yes I didn't
address that question so what I the the
best way is actually
listservs in academia those are really
powerful so listservs are really great I
got an article in inside higher ed that
was extremely helpful with the
universities and I've been active on
social media although I'm not very good
at it but but yeah that's been I've been
trying to be as lean as possible
designing our product to be sensible we
want people to use it in unexpected ways
so it's not at all a problem to help
with that the core architecture is built
to be kind of a visual programming
language and the it will be will have
api's Export Import as many possible
ways to end up using it in unexpected
ways and for reaching people part of
reaching people is to create a tool that
is so extensible that people just have
fun with it and share it with each other
but shareability in the core
architecture is critical so the design
files are essentially documents that can
be collaborative like Google Docs or
shared as a flat file export which
everybody wants by remarketing that's
not so easy to achieve so we hope to
achieve some level of that but we don't
expect it to sell itself so it will be
marketing components as well um so I
can't really speak for how get help
again that was sort of 2007 I know we
did a lot of work to get call
communities on the platform so you know
we you know getting high profile open
source projects on to github was very
very significant in its early days I
think that's a transferable thing
bringing a community along I think so
thinking about kind of people who are
significant kind of in a particular
network of academia and getting them
onto your platform using your tools
would be a good strategy so but it's a
speed to sort of how people are using
github that I've seen the weirdest stuff
in the last year there's libraries who
have upload
hundred thousand bucks to get hub who as
they're all open source don't pay a
single dollar Jeff was saying something
about having your revenue model aligned
with your your mission maybe I'm
paraphrasing play you know our mission
we you know we people pay for privacy on
github people as people don't realize
how we make money we make money for on
those repositories that people choose to
not make open source so if you come
along and upload 200,000 repositories
tomorrow in an open-source fashion we
won't charge you a single sin and so
I've seen libraries upload huge amounts
of data that's actually tested
infrastructure at times I've seen
academics shard genome sequences and put
them in repositories again like things
but usually usually expect the
unexpected I think that happens a lot
and so that isn't necessarily affected
how we present the product but it does
affect sometimes it affects technology
decisions about the way that you go
forward like academics of being amongst
the most sort of abusive of our platform
in the nicest possible way so I would
actually say in terms of outreach we're
not actually very good at it at sonora
and as an international organization as
well it's definitely something we hope
to warm up what we do is that we we do
try to spread the word to a lot of
people that can multiply it we do engage
when people then come to come to us we
do engage heavily in them and make sure
that they are happy with what with the
features so that they can spread the
word and in terms of unexpected uses I
think a lot of the use we have I've
completely in live with what's in all of
us I think the most unusual ones are the
people who say hey can I say install a
copy of sonoda at my local institution
and in those respects I think it goes a
little bit against this infrastructure
principle that Jeffrey was was talking
about as well but we're happy to help
them actually for coughs a note of which
fork of the underlying software menu and
actually help them build up their own
own data repository network yeah enough
usf you know we purposely build it to be
very flexible you
whatever you want to it I haven't seen
anything too bizarre yet I'm sure at
some point somebody will start uploading
cab pictures because it's the internet
and cancer everywhere but you know
that's it's really fine with us we built
it or scientists so those are our
audience that we do try and you know
always check in with them and say hey
how is this working for you what can we
do better but it is open and free to
everybody so if you want to upload
pictures of cats you're welcome to do
that and in terms of restoring our
audience we've started doing a lot of
outreach so going around to universities
interacting with grad students postdocs
researchers doing training events about
you know open and reproducible practices
some of which are just about general or
flow some of it's about you know how to
integrate the OSF practically and to
what they do and we also in terms of
outreach are always looking around to
see hey are there people out there who
are kind of doing similar things to what
we're doing or thinking on starting
similar things and maybe they don't have
a home for it yet can we find a way to
collaborate with them on their project
to help grow both projects yeah oh sorry
for questions okay oh I was just wanting
it was so we heard a little bit about
some of some sort of relationship that's
some of these handles of their products
have with the library so it seems like
you know they love its product to end
user and user being the researcher but
where do you see libraries fitting in
here at all and just wonder lots or any
relationships or that was flatteries do
you mean physical libraries or so so
first and work with a text digital
library and we work with a lot of
supposed non non traditional larger so
you know we we see a lot of people that
they come to us and say hey I have you
know I
you know five or six petabytes of data
that I need to offload it the reference
connection there reference collections
there there are archived manuscripts
there every book that's been you know
written electronic theses dissertations
all that stuff right so we kind of need
to we've been working with them trying
to figure out as part of a larger data
initiative of how we can keep that stuff
available for for long periods of time
in in dark storage we can keep it
available in in terms of the metadata
and discovery and what search means in
in context like that so I've been
involved with the National Digital
stewardship allowance for a while in my
previous role and still sometimes this
now um I guess my main relationship or
get main relationship is probably
through personal connections with people
like preserved in here in Hobbiton and
Lars no dough I mean I worry about the
fact that you can go to get haven't
delete all your stuff this does happen
by accident usually when people are
trying to turn off email notifications
and somebody made them an admin by
mistake and they just delete that whole
company's profile and luckily we can get
that back for you really easily if you
do that but it's a real problem
especially for archiving of I think
software especially there's a longevity
thing that actually isn't kind of built
into what we do so more formal than that
not really but but conversations
happening for sure so I would actually
say that libraries are one of our end
users we've been working ever live with
with Chris admin at Harvard CFA for
instance we also have a lot of smaller
libraries that are interested in using
sonoda as a platform and I see that it's
actually the the bigger libraries that
are not really interested in using
external platforms where all the smaller
ones see the benefit of not having to
run their own infrastructure anymore
when we rely on a common place for us
we're not really targeting libraries but
we are trying to integrate with
publishers and some of the new
generation of publishers fig share or or
factory 1000 that
our publishing figures methods research
objects and so our protocols and
processes would be able to get a digital
object identifier and then one kick
click publishing of a complete
experimental record including what you
did and all the data associated with it
in a in a Mynah bowei so that ultimately
will make it to a library but not
directly sure I guess that overly if we
kind of work with libraries in two ways
first I know some libraries have taken a
sort of leading role in procuring
software for researchers to use and sort
of a research informations perspectives
we sometimes deal with them to sell both
licenses of overlay for to look at sort
of trials and things like that and then
second I know we're working with some
universities to handle thesis
submissions that go through the
library's so I overleaf it's quite easy
to make sort of templated documents so
if you have a standard thesis template
and you get all your students writing
their thesis on a relief then everything
comes in in the right format and that's
been of interest to number of libraries
and for publicise I haven't really made
any strong effort to work with libraries
but I would like to I think libraries
are a really good resource especially to
connect with the researchers at the
universities I plan to implement the DOI
so each one of these lay articles can be
actually cited by the UI ultimately my
big vision is to have kind of like a
mouse-over effect or something on a
title where you can see the title in its
full form but then kind of mouse over
and then see the late title I think that
would be the most efficient for anyone
so that's kind of the ultimate goal and
it's going to be a long road to get
there and at the Center for open science
we kind of work with libraries in two
different ways because libraries at many
institutions are the ones who do a lot
of work and training and outreach on
data management and data curation for
the researchers at that institution we
generally talk to libraries about how we
can support them in the training of
those practices and you know the new
tools that are out there unavailable to
research
and we're also working on the share
notification system with the ARL the
American research librarians yeah I'm
terrible thank you I'm terrible with
acronyms it's really bad oh so the share
notification system which is a system
whereby universities and institutions
can get notifications and researchers at
those universities publish articles and
the code and data sets that are open to
the university can better track what is
being out there by the researchers who
are working with them yeah sorry really
odd I was struck by mr. Smith what you
said the end of your presentation about
reproducibility being a workflow and
workflow um cultural and not a
technology problem and that really
resonated with me so interested to hear
any more discussion or commentary that a
panel wants to have on that I can
comment further I mean it ah yeah so we
touched a bid on it already i mean my my
my I'm I'm always kind of skeptical of
reproducibility as a goal in itself I
think it's obviously you can't argue
against it but at the same time it's I
think we should be reaching for their
like let me star get there are so many
people when I go and talk on a campus
about github who have no idea what
version control is there were a very
very long way away I think from kind of
executable papers and turnkey kind of
kind of research packages that can just
be shared and forward and whatever and I
think I would love to see us there but I
think we're often I would like to see us
focus more on some of the kind of
earlier stats towards that goal and I
think if you use tools like a lot of us
develop and work on then reproducibility
is a kind of a byproduct of using better
tools and I don't so yeah that's my so I
I'm slightly I am nervous and skeptical
about lots of resources going into
platforms that solve this wonderful
problem that we all understand because i
think in mrs. i think we end up focusing
on
reproducibility goals / kind of product
goals which can be making great tools
that people enjoy using and so if you
can do them both then great but most of
these product projects are run on
relatively small budgets and I think the
amount of money that you would need to
do it well as in also anyway I've told
you I was going to shoot myself in the
foot by I I fundamentally agree right so
reproducibility is a byproduct of good
research all right so we we build it
into a gob a platform because we got
really tired of watching tens honestly
hundreds of millions of dollars go into
reinventing the wheel in academic
software over and over and over and
people not fundamentally understanding
the difference that research software is
different than commercial software and
the effort it takes to go from one to
the other is more than the effort it
take to come up with a research software
so we bake it in right I think it's
sometimes confusing when we start
talking in this context that we we
forget that there are a lot of different
kinds of users right so the the target
audience for for our platform are
developers people that are actually
building tools right you know see very
often a n scientists come in and say oh
you know i love what agave did for me i
love you know did this man i really like
the API ooh hypermedia yay they just
they don't value those kind of things
what they value is hey I i was using
this app the other day and I was able to
share this you know three petabyte data
set right with a single click I can get
a URL for anything and I don't have to
authenticate again right I can share
anything from anywhere right I could
publish my paper I have a DOI for this
whole experiment when people went to
review my work they could rerun the
entire the entire thing end and
invalidate the output that I got that's
what they get excited about right but
those are different end users and you
kind of got to keep those in mind and I
don't I think that there is value in
building these platforms and I am in my
humble but accurate opinion there's
Paris value in building these platforms
because they're really stinking hard to
do and
people aren't going to pull them off and
as our keynote pointed out we've tried
it over and over and over and over again
and when you when you try to get it and
infrastructure is a byproduct of
research you're you're sure you're
you're aiming it nothing and hitting it
every time right because what you need
is infrastructure you don't need
research so I think that you need to buy
into that and you need to invest in the
infrastructure so that the
reproducibility is just taken for
granted right that it just be it's just
something that's there just like when I
look I'm going to hand off the mic but
when when I open my laptop in here I
started getting flooded with
notifications because I've been in four
time zones in two days right so
microsoft online thinks that my account
got hacked because I'm you know I'm
logging in from all these different
places in a short period of time
security is a byproduct of using that
platform right I think reproducibility
should be as well yeah that's a very
interesting anecdote actually um I I was
also going to do an anecdote so I don't
disagree with with any of this but I'm I
think it's maybe a little bit a little
bit negative like I think we've got such
a long way to go between from where we
are now to like perfect reproducibility
that there's a lot of progress that we
could make so like for example when I
was an undergraduate I was assigned a
task to implement an algorithm for
variational notions segmentation or
something and this this was described
over the course of like three or four
papers in hard to find journals and the
key bit of it was actually in like an
unpublished technical report in Japanese
that I had to go and like dig up from
library inter loan services so like
that's that's kind of where we are now
with reproducible research I think that
using tools like github or any of the
tools we talked about today would
already be such a huge improvement on
that that I think is a long way to go we
shouldn't be should be too negative
about things that we can do to improve
reducibility I agree completely with the
statement about research reproducibility
essentially it's a problem of the
workflow but but I guess from the
publicized perspective I look at
reproducibility from a different
perspective in that I think a lot of
research
is being reproduced unnecessarily and
because there's a lack of communication
between fields so from my perspective
actually I want to reduce the
reproducibility of research and
replication yeah or reproducing so yeah
so essentially I think that it would be
very useful if we can get all of these
research projects in terms that other
people can understand so that we can see
what has actually happened in different
in different fields because there's a
lot of overlap especially with methods
and algorithms between all these fields
as as especially as we keep advancing in
computers so I think that yeah I come at
it from a very different perspective so
there were there's really two questions
that were being answered the question of
workflow I so wholeheartedly believe and
agree with that that started a company
riffin to make workflow a part of the
process and explicit part of the process
not an afterthought or oh I'm going to
document it as metadata or some sort of
side project so I think workflow is
critical and I think it's critical to
start that at the very beginning as
upstream as you can go in the research
undertaking and that's what we're trying
to do the second question was about
reproducibility and I have to say I
totally disagree with the idea that
reproducibility is a byproduct that's
like saying that airline safety is a
byproduct of running Airlines if you
don't focus on safety with a hundred
percent of your effort it will not be
safe we get to experience it as a
byproduct because as users that's not
our our primary objective but the people
who are at that airplane at those
airlines take safety with absolute
seriousness and manufacturers take
quality with absolute focus and until
the rd industry takes quality with
absolute seriousness it will not be
quality and so what we're trying to do
is make it easy at riffin to take
quality seriously not make it a huge
drain on your research
it's on I think I agree with a lot of
that things that have been set here it's
definitely that you have to get the
reproduces reducibility worked into the
tools so that it's really a no-brainer
for a researcher to do the right thing I
think it's about the usability of these
of doing it the right thing that's
important and I think that research
could actually learn quite a lot from
software development when you look at
the lot of the packages and on github
they can actually be downloaded
installed and tested in a fully
automated way most software developers
don't have to think too much they just
have to follow the short guide that is
actually on the front page which is like
three lines of codes they have to do and
if more research tools were like this
then I think you wouldn't have something
so much about the reproducibility yeah
and I mean I agree with a lot of what's
been said but there are different types
of reproducibility right depending on
what field you're in that word can be
used very differently there's
reproducibility in the sunset if you
take some of these data and the code and
you rerun it you should reproduce the
same numbers but there's also the
question of you know if i take the
methods and the material is used and i
go and do your experiment again will i
actually get the same results and I
think workflow can help with both of
those right if I have really well
documented data and code then it's and I
made that open source it's more likely
that somebody can download that or we
run and get the right numbers and if I
you know provide all my materials online
it's probably more likely that somebody
can at least try to replicate my
experiment because they at least know
what I've done but in terms of you know
replicating the statistical findings if
you redo the whole paper there is a
large component of that that comes down
to really you know having a good
statistical workflow that's something we
didn't talk about a lot but I think that
is something that can be done in an
open-source way but it's something that
really has to start even before
project has been done and so I think it
is having the goal of reproducibility is
important it does often come out of
having goals of openness and
transparency in a well-documented
workflow but I think it's important to
keep both in mind okay so i'm william
gun with that min delay and it's been
really interesting but i know we're
coming up to the through the end so i'll
try to be precise it seems to be a lot
of what you guys are talking about is
your things that are on the top of that
sort of Maslow's hierarchy of needs
reproducibility as this ultimate in goal
you know pie in the sky sort of thing
but there's a lot of basic stuff you
know infrastructure is kind of stuff
that needs to be there in order to get
to there so I was kind of inspired by
some of the stuff riffin was saying with
instrumenting the actual lab equipment
you know and getting that stuff in there
so that you don't have variability from
how people record stuff that seems to be
kind of one of those lower down on the
on the pyramid what are some other
things that you know that you guys with
your platforms could do to make the
metadata attached datasets better so
that for example data search works
better our discovery or something works
better so we're pretty late in the in
the research data life cycle if you look
at it will write down at the publishing
process and actually the best place to
start collecting all your meter data is
by using tools that does it for you so
it's already when you start planning
your your your data collection that you
should be prepping this data out we
should be using tools like for instance
the lab notebooks it's a good example
where you can then go with a barcode
scanner scan and say hey I use this
slice of the mouth spray and I use this
plasmid I use this from this drawer I
think we need to develop the tools that
really support you in doing the things
in the right way and then all the later
stages can actually depend on
although all this metadata this B can be
ingested into the files so I would love
to see people versioning their desktop
or whatever whatever they're working
with whatever file formats they're
working with it and you point in time
one of the not sure there's quite
answers your question but one of the
differences I see between software
development and academic collaboration
sometimes around software to is a large
astronomy project is currently looking
at moving lots of their software to get
hub and they have a fundamental
difference in the way that they use for
example apart the product like comments
on a line like review comments a typical
comment from a colleague from on my co
to get BB hey whitespace fix you know
two spaces here please whatever like
code formatting sort of problems or
sometimes hey actually that isn't the
syntactic styles like here in this other
project there'll be actually I don't
agree with your version of gravity here
and then they'll have this huge
discussion that actually is crucial in
terms of like the decisions that were
made around how the software was put
together or even maybe how the paper was
put together but it's a fundamentally
different type of discussion that's
happening and so um we don't capture
that very well or it isn't kind of front
and center when you go and check in on
the work again in a few years time so I
think I don't know I'm yeah so I mean I
think versioning is just kind of
sensible a lot of people aren't doing it
I would love to you know so I consider a
pretty low level activity but then
exposing the decisions that were made to
make a change at ism I think a hard a
problem because often that's kind of
hidden away and buried in weird places
so my wife and I hate making our bed
right we have like a bunch of sheets and
comforters and pillows and stuff you can
matter we hate making our bed we were we
were traveling back we were looking one
of the SkyMall catalogs and in there
there was this there was this product
and it was it was the set of sheets
right that they they had a lot of flack
the top sheet was like really really
huge but it it it buttoned on to the the
corners of the bed
right so you could get in get out you
can move it but your bed never got messy
and we SAT there and we looked like we
just found fire we were like Prometheus
hello this is awesome right it was a
game changer for us and I think that
when you wouldn't you know we as tool
builders sometimes engage new audiences
that they look at these tools a lot it
in the same way or though wow I didn't
even know that was possible well I can I
can link stuff and and I like what
you're doing because you you know you uh
it's it's it's another step in the
process of automating the delivery of
software to to an end users right and it
just it takes the people out of the
middle and I think that that's where it
really needs to start is you know what
you want to really minate
reproducibility well you have to
communicate what's been done first and
let people know it's available so I it's
a hard problem but I think we kind of
need to start there just engaging more
and more people yeah that's very
interesting um I'd say again overleaf is
kind of a bit later in the research life
cycle but a lot of people do use it just
as a sort of electronic lab notebook as
a way of just capturing stuff as you're
going forward so it's it's not automatic
but it is very flexible so I think
anything that just helps you capture
things and version them is a very good
step I kind of I guess want to repeat
what Arvind said about commenting I
think that that was kind of his main
point in that I think comments are
actually probably encode or basically
the details associated with the decision
making process of your research that's
actually what's most crucial and and the
vast majority of researchers don't put
those details in the paper because I
mean that would be a horrible paper to
read so one of the big challenges of
reproducibility is actually
communicating every single decision and
every single basically
of code that where you made some kind of
decision especially when researchers use
different languages they use different
tools that's a fundamentally difficult
that's a very difficult problem and I
think that better communication is the
key riff on our ultimate vision and
mission is to get to the point where
quality provenance shareability of
research isn't an oh yeah let's do that
after i'm done with my research it
actually is the research it is the way
you do research just the same way that
you would start a mechanical design
process with a computer-aided design
file or a architectural project with a
blueprint you would never do that after
the fact you do that as part of the
process and that's what we're trying to
do go upstream so it's not a separate
thing it is the process and and that I
hope will dress at the OSF you know part
of what we do is we try and get journals
to adopt that are open and reproducible
practices because a lot of times
researchers will say you know okay I see
the point but that's one more thing I
have to do but if it's something where
you know the journal says hey we suggest
this or we require this you can get a
lot more movement from people so one of
the things that we suggest and that some
journals are starting to implement our
pre-registrations so you know before you
run an experiment saying what you're
going to do what hypothesis is
statistical analyses you're going to do
and so that thinking about the workflow
and the versioning really does have to
start happening way before like anything
has ever been run but part of that is
just because the community came together
and said we now care about this so like
in cognitive psychology you see a lot
more detail about the computer systems
that are used recorded because people
kind of came together and said wait this
really does matter for a research we
figured out that you know the refresh
rate of the computer is actually
something that is very important for our
research in social psychology you don't
see that detail recorded as as often I
think it's detailed that it's really
important but I think
something that the community will have
to at some point come to a realization
about hey these are important details
for us maybe you don't include them in a
paper but they are you logged in version
somewhere CSV files they were uh
pleasure excel files but no one but the
person who originally did the experiment
can make head or tails of it when it
comes up when it finds it later yeah as
a part of the training is to teach
people about Leah what a code book is
and what a well-curated excel file is so
that you know the the osf is never going
to be one of those really well-curated
and it's never trying to be data
repositories like icpsr where you know
when your data set comes in one guy is
literally assigned go through your data
set and make it available we kind of see
ourselves as the middle ground where you
know that data is going to have to live
somewhere before it maybe eventually
moves on to repository if it does ever
move on to our posit Ori so you know we
would love for it to be hosted somewhere
where it is log and version and open
hopefully you upload it in hope it that
other people can understand it and we
will help that's through training but
it's not a requirement like it is and
one of those really really well-curated
for posit or a break for coffee so she's
holding you up there which she said this
discussion reminds me a little bit of my
research group meeting last week those
of you don't know me I'm an astronomer
and I do have an astronomy research
group that's my job but anyway um some
students and postdocs we're having this
bizarre conversation where they were
fighting about whether there really is a
workflow and whether you can get a paper
done by having a plan in advance taking
some data doing what you're supposed to
do publish a paper go on to the next one
or whether screwing around was more
productive and I always xperia and so
when you said a minute ago there's no
you know you would never do blah blah
blah without a blueprint yes you would
okay and so I think there's a lot of
science that gets done where
we'll take some data for one reason and
I just like mess around with it and then
they mess around some more and they
don't really know in advance you know
what their process is and so it's really
hard in some fields to sort of back that
out and I think that the reason that
these workflow systems get used more in
genomics and feels like that is because
there is more of a process and in labs
there is more of a process it's more
important to have a process but it feels
like astronomy where nobody's life
depends on this there's a lot of messing
around and the most creative results
come from that so I'm not saying that we
should give up but I agree with our fun
that that actual reproducibility is
usually not our goal it's sort of
reusability of what somebody did and so
we have a very different set of
standards and goals and so I'm just
going to say that I know that Jeff told
us that you shouldn't think about
discipline specific things but I do
think that in disciplines where you know
people's lives depend on it there's a
whole different story around
reproducibility than in fields where
they don't each year microsoft research
helps hundreds of influential speakers
from around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>