<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Practical Partial Packet Recovery for 802.11: Maranello | Coder Coacher - Coaching Coders</title><meta content="Practical Partial Packet Recovery for 802.11: Maranello - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Practical Partial Packet Recovery for 802.11: Maranello</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/sgn6sWFWcOE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
Kyle gave a great tutorial on and
explained the work on phased arrays
which had so many different applications
now I think he'll switch on to a
completely different sort of part which
is recovering partial packets so I think
I'll I do okay alright thanks Krishna
okay so um yeah so the second hour today
I'll be talking about making this line
of work that I started back in 2007 on
partial packet recovery practical for a
tour to eleven devices so the basic idea
behind this partial packet recovery is
to do with the nature of wireless errors
okay so unwired links we have bit error
rates that are very very low and as a
result the Wild links are usually either
all or nothing meaning that the packet
either arrives correctly or the link is
completely cut and you get no bits in a
packet you send over a wired link but
wireless links often deliver packets
with errors as you must have heard
before because the bit error rate that
that particular wireless link
experiences is a function of many
different things there could be
interference from nearby other links
there could be mobility in the
environment and the link could be fading
so on the result of this is the packets
oftentimes only arrived arrived only
with a few localized bit errors in them
and the observation is that wouldn't it
be nice if we could Salvage most of the
bits in these packets that arrive with
just a few errors and then conversely of
those packets that have mostly aired
bits why don't we just throw those away
and then just keep that small bit of
self salvageable content so that's the
basic idea that my PhD advisor at MIT
hurry about Krishna and I looked at in
back in two thousand seven two thousand
aite partial packet recovery from
wireless network set at sitcom and back
then we were experimenting with some of
the first software-defined radio
platforms that were on the market namely
the latest research the new radio usrp
platform and that platform happens to be
still on the market today addis research
got got acquired by a larger company and
you can still experiment with those same
same software radio platforms back then
we were interested in just transmitting
only the bits that needed correcting and
the receiver would combined the original
transmission with those retransmissions
of those corrected bits and then form
the correct package and we had a
protocol that accomplished this we
called ppra RQ for partial packet
automatic repeat request and there we
showed that these this protocol
increased throughput because basically
re transmissions were smaller than the
original trans transmissions and they
used less overt i overhead on the
wireless medium and the other
interesting observation we made was that
for a given bitrate a smaller
transmission would have a higher
delivery probability because a smaller
packet we less likely to collide with
other ongoing transmissions or
experience fading due to mobility right
so this nice kind of accidental
synergistic effect happens when you
shorten your subsequent retransmission
and then this this kind of these two
effects lead to a higher delivery
probability and the bit rate adaptation
algorithm that you heard about
previously selecting higher bit rates
and the packets lasting for even shorter
time directions so all three of these
factors kind of work synergistically to
increase throughput when you're
recovering
shal packets those very nice and we
compared with many different approaches
the first approach we compared with back
then was the block checksum right so the
idea now is that instead of recovering
partial packets that could span any any
boundaries in the 802 11 packet we would
set fixed boundaries and put check some
bits just like the checks on bits at the
end of your 802 11 transmissions at the
end of each of those fixed boundaries
receivers would then check some these
blocks just like conventional 802 11
receivers check some entire packets and
throw away fragments or blocks that
failed that checksum right and then they
were the receiver would tell that the
sender about that in a negative and
acknowledgement frame explaining to the
sender which block numbers the sender
would need to retransmit in order to
recover the entire package so back then
we call this the fragmented CRC approach
a fragmented checksum approach because
you only pay the overhead of recovering
an error block in the common case and
you know many other systems since then
had been built in this in this way you
might be thinking to yourselves this
looks a lot like 802 11 n and AC frame
aggregation and you'd be right same
ideas are kind of coming back in in the
form of aggregation the other approach
that will be coming back to today to
partial packet recovery is a completely
different approach and I'm going to
refer to it today as forward error
correction for their correction approach
so in this approach we're saying okay
let's not even attempt to identify which
bits in the packet are correct and
incorrect let's instead form an air
correcting code over the entire
contents of the packet and then send
parity bits if the original transmission
isn't received from our code send more
parity bits that contain information
about every bit in the package okay and
some work by delicate Abby and her
students in will become 08 implemented
just this for a 211 in two rounds so
forward error correcting they call it
zip TX right in the first round they
would send a small number of
reed-solomon parity bits if the original
packet didn't get there and then even
more parity bits in the second round
then they just give up and retransmit
the entire packet if those two rounds
failed that's one application of a
reed-solomon code but what they did with
Reed Solomon was actually code over the
entire packet so you can choose which
bits you want your parity bits it bits
in the packet you want to form your
parent a bit strong right so it's it's
versatile and let in that respect yes
yeah but you see the disadvantage of
this conceptually right is that if just
a few of the bits in your packet are
errored then you're sending information
in those parity bits about every bit in
the packet well you already have the
correct bits for most of those most of
the packet so you don't need any more
information about the correct bits you
just need information about the
incorrect bits okay so in general right
that's so the question was do you know
the locations of the errors in general
if you can identify the locations of the
errors a partial packet recovery scheme
will be better as we'll see later on in
in the talk when we talk about maranello
if you don't know the locations of the
heirs for whatever reason these schemes
tend to shine sure sure so okay so there
there are also hybrids that the question
was Reed Solomon can tell you some
information about the location of the
airs so that's a good point yes so there
are also hybrid schemes you know that
you can imagine between right so the
approach that we took back in 07 / port
for partial packet recovery was to use
these physical layer hints that tell you
the locations of the errors so
essentially we have schemes by which the
physical layer can score every bit that
it receives with a numerical confidence
in that bits corrected correctness and
passed the score up to higher layers and
then in back then in that work we asked
the link layer to ask for
retransmissions of just the bits in the
low confidence part of the frame okay so
today I'll spend most of the time
talking about marinello which was a
paper that was by some people at
Maryland University of Maryland in the
user next twenty ten conference and what
they did was I think is a great systems
building work what they did was they
made a partial packet recovery practical
for a tour to 11 right so the the
platform that we used back in 07 was
that software radio but what they did
was they took a broadcom chip set a tour
to 11 hardware and they implemented a
block-based checksum design remember
dividing the packet up into small blocks
with a checksum in a very clever way and
they implemented that on the firmware of
that 802 11 hardware so it ran at line
rate
okay and they they're block-based
checksum design was a clever mechanism
we'll talk about next that in the common
case where there are no bit errors on
the wireless links they free up the need
to spend bits on crcs in the packet okay
so I'll tell you how they do that in a
second but designing for the common case
where there are no bit errors and making
that fast was another strength of their
system and then as I said they
implemented this on the firmware running
in a small microprocessor living on the
broadcom 802 11 network interface Nick
card ok so at a very high level here's
what the protocol looks like we have a
corrupt packet arriving at the receiver
with some incorrect bits and they have
an 802 11 checksum so the receiver is
going to compute that packet that frame
level checksum and compare it to the 802
11 frame checksum field and then if they
if they match we know where we're good
we've received a packet successfully if
they don't we need to begin this
recovery protocol to recover the court
of the correct bits okay so notice at
this point for the first transmission
there are no CRC fields extra CRC fields
added in the interior of the packet okay
so now recovery so in that corrupt
packet the receiver not the sender the
receiver is going to break that aired
frame up into fixed sized blocks okay
and there a sender and receiver are they
are going to agree on the block size
beforehand and the land the errors will
fall into one of those blocks at that
point the receiver computes these fast
software-based checksums called Fletcher
32
receive a complete computes those
Fletcher 32 checksums for each one of
the blocks and in its link layer neck
reply the receiver includes all the
checksums for every block in that neck
negative acknowledgement reply okay so
instead of an 802 11 ACK the receiver is
is sending if it didn't check their
errors the receivers sending a knack
back to the sender and then the sender
knows has agreed with the receiver
beforehand where the block boundaries
are so now the sender can compute the
block checksums likewise in the same
manner over every block and compare the
values that it computes with the values
it receives in the neck okay so we're
trying to find the locations of the bit
errors so for all the locations sorry
for all the blocks whose sender
checksums match the receiver knack check
sums we know that the receiver got them
okay at the sender the sender knows the
receiver got those okay for all the
block checksums who is nak values don't
match what the center computes send earn
that the sender knows that the receiver
got those with errors so essentially
we're locating the errors with a coarser
precision than for ya
for the overall packet yes but not for
each block so this nice property that we
don't have all that overhead yes right
right so the question is when do we
begin recovery at this point when the
frame checksum does not check the
receiver knows they're cynare and begins
recovering yeah ok so we've located the
errors now at the sender so now we need
to repair the repair the packet so the
next thing that maranello does are no
ascender does is the sender is going to
transmit repair blocks now corresponding
to just the blocks that received the
contained errors ok and that's going to
be in a repair package so in this case
we're transmitting just blocks three and
five in that shorter repair package and
just like 802 11 and the other 802 11
transmission the sender's can be
doubling fall it's dissenters can be
following the medium access protocol on
later to 11 so doubling the contention
window before that repair transmission
right remember you are familiar with the
bounded exponential back-off procedure
in 802 11
so this point you might be wondering to
yourself okay what happens if that
repair packet contains errors right
won't we the back at step one all again
and they just punt on this okay if the
repair packet contains errors itself the
receiver sends no more and the sender
just goes back to retransmit the
original frame so that's the beauty of
this problem if your protocol gets too
complicated then you get to just punt
and we transmit the original frame it
just so happens that this happens rarely
enough that this doesn't make such a big
impact on performance approach to sure
that the jacket recovery probability of
packet recovery this is better than with
so in so the question is is there any
analytical approach to to show that the
probability of packet recovery is better
than so in in all cases the probability
of packet recovery will be one what we
want to show is the performance will be
better so I'm going to argue I'll show
empirical data in a second that shows
you the performance is better and
actually in general it's possible to
show it's possible to show analytically
an optimal packet length for a given bit
error rate the problem with with this is
that bit error rate fluctuates so
quickly because of fading and collisions
that it's it's very difficult to apply
this this theory yes that's right right
so in in essence what these protocols
are doing is kind of adapting the
optimal length in response to the
conditions on the channel tomorrow we'll
talk about rayless codes which is
completely different step in this kind
of evolution of thinking that does even
better so let me leave that to tomorrow
ah so okay so the question is how does
the receiver know to put the blue block
right there with the with this error
right so the receiver so transverse and
receiver are going to number each block
and have a header specifying the block
numbers that I'm that the sender's
retransmitting yes yes yes and I believe
they did that in their in their work and
remember they've agreed on the block
length and the numbering ahead of time
yeah okay okay so then the receiver gets
the repair packet plugs in those repair
blocks right where they belong based on
those numbers and then re computes the
entire frame checksum and end-to-end
checks that the recovered packet is
indeed correct and then moves on to the
next packet so that's the protocol so
the nice thing about this work is they
really thought hard about how to
integrate excuse me integrate this with
legacy 802 11 Wi-Fi right so two cases
suppose we have an 802 11 sender and a
Maranello receiver the 802 11 sender is
going to be transmitting the maranello
receiver sends that neck back and the
802 11 sender doesn't recognize it so
the sender will just fall back to
treating that as a dropped packet and
retransmitting as normal right so we
have this really graceful degradation to
normal 802 11 behavior if you have an
ear to 11 sender conversely a Maranello
sender with an 802 11 receiver that
receiver will never send knacks so
marinela will never come into a fact and
the maranello sender will retransmit the
entire frame after a timeout after
receiving the neck okay so nice inter
about interoperability okay so let's see
how well this performs let's talk about
performance now so they built this as I
said on the on the 802 11 firmware in
the broadcom chipset and they took
empirical traces looking at the location
of bit errors in 100 corrupted packets
and you can you can literally see that
things are very very localized here at
the bottom we have packets with more and
more errors and likely right we have
some kind of collision with an ayah with
a packet arriving at this point in time
let's wiping out all of the bit errors
in that packet right so we see many
packets with just a few bit errors that
we can easily correct many packets that
might be interfered with or lose
synchronization so first question they
asked in terms of performance is how
many repair blocks do we need in order
to repair a packet okay so they looked
at on the horizontal axis they looked at
a number of the bit errors in in packets
okay so their packets were up to 5.8
kilobits long and on the x-axis we have
how many bit errors are in the packet on
the y axis we have bars that are showing
you how many 64 byte blocks you need to
repair that a packet with that many bit
errors okay so for example for the
packets with one bit error in them one
block always repairs the one bit error
so all the all those packets have a
white color in this graph
for the packets with two-bit errors in
them 99.7 percent of the time those
two-bit errors are within the same block
so one block suprises to repair it but
0.3% of the time they're in different
blocks and so we need to so this is tiny
sliver of of red up there for the two
blocks required to repair those packets
okay so now let's look at the white
portion of this graph so these are the
packets that are repaired by one 64 byte
block you notice that under 15 corrupt
bits ninety percent the majority of
those packets can be fixed with one
block that's all we need and our package
size by the way is 1500 bytes so quite
big so that's four percent overhead so
it's looking pretty good at this at this
stage so 23 bucks per packet so this
orange area here with 23 blocks is
representing packets that need that
complete retransmission and look how
small that number is right very few
packets require that complete
retransmission okay so to summarize this
data so far we've seen one block of one
repair block is a four percent overhead
on the package if you have just a couple
of Arab it's one block fixes those under
15 there are bits one block fixes most
of the packets and we have very few
packets requiring a complete
retransmission so that's what's in the
paper but i think the lesson to take
away from this is when people kind of
bombard you with data like this and
you're reading a paper think to yourself
are they are they asking the right
question so it is the number of repair
blocks required the right question right
what we really care about in the end is
throughput right we don't care about
repair blocks fundamentally what we care
about is what can we what's the best
throughput we can achieve on a wireless
link so always be thinking about when
you read a research paper I think listen
is always be thinking about what's the
end metric you care about and does this
data tell us anything about how often
how many bit errors occur right it
doesn't right we're on that x axis and
that graph were we most of the time I
didn't tell you ok so the next thing
they look at in their in their paper is
the repair size how many repair bits of
protocol needs to fix one incorrect bit
right now we're getting closer to
throughput right because this is a
measure of the overhead for one
incorrect bit when the wireless channel
makes a bit error how many repair bits
do we need to overcome that error ok so
now they're using trace driven
simulation using broadcom cards to send
and receive packets with known payloads
over-the-air recording traces of those
frame frames and then running a software
simulation protocol to be evaluate to
evaluate the protocol they're interested
in testing right so trace driven
simulation another very powerful tool
that we use in research when we're not
we don't have we're not we're either not
ready to build the entire system or
their hardware limitations preventing us
from building the entire system so we
take traces and we use those traces to
drive a simulated system right and we're
getting to all the interesting effects
of the real world in our performance
evaluation so this is a technique we use
really often in read in research
okay so results in terms of now repair
bits it takes to fix one aired bit on
the wireless medium and now we're
looking at trace driven simulation
broken down by the average bit error
rate okay so a full retransmission if
you have a low bit error rate will be
extremely expensive in terms of repair
bits per aired bit and as the bit error
rate rises that full retransmission gets
relatively less expensive why is that
because there's more error bits in each
frame right ok so these orange curves
here on the graph are what we could do
ideally retransmitting just the
incorrect symbols if we knew what those
incorrect symbols were ok so they're
calling that PPR in this graph the blue
curve is reed-solomon but this is reed
solomon that knows the number of errors
that need to be repaired and transmits
exactly the right number of parity bits
to overcome those errors so they call
this ideal reed-solomon that's a blue
curve and then this maranoa protocol I'm
talking about today in red so at a
little bit error rate we're seeing the
overhead of maranello increasing
relative to the reed solomon approach
but as bit error rates increase we see
this interesting effect where maranello
and the partial packet recovery approach
are both outperforming setia the
reed-solomon approach
right so we see the reason for this is
we see the effect of read Solomon's
transmitting information about the
entire packet even though that that
information is wasted if we've already
received the bits correctly
so the interesting the thing so they
took that performance data and they
looked at how this actually performs in
the real world now operating with the
medium access control protocol and the
bit rate adaptation protocol all
together in conjunction right so i think
the nice the nice really nice thing
about this work is now they took partial
packet recovery and they investigated
how it performs in the in the when it
runs over different types of bit rate
adaptation and back off strategies it
turns out both back off and bitrate
selection impact performance right so
the standard specifies the back off chip
says it turns out don't always respect
the standard the standard doesn't
specify bit rate adaptation so chipsets
are free to select any bitrate they care
to for subsequent retransmissions it
makes sense to step down your bitrate
but they can step down at whatever rate
they care to do so this is these are 82
11g cards arg cards so intel steps down
gradually the bit rate using 54 mega
bits for the first two transmissions
then 48 3624 a throws at the time keeps
the bit rate high for the first seven or
so transmissions and then for the last
two transmissions gets desperate falls
back down to one megabit per second very
slow right so these are very very slow
long packets that are taking up quite a
bit of time on the wireless medium right
so in both cases marinello recovering
the packets before the bit rate
adaptation gets a chance to step down is
going to help because it's going to
avoid those stepping down of the
retransmissions and it's also going to
avoid that back off time that bounded
exponential back-off time increasing on
each subsequent retransmission right so
two ways it's it's it's reducing the Mac
overhead by recovering packets
okay so to implement this they thought
of several alternatives so if you were
building this system where might you
implement this right so you might want
to be tempted to do this all in the
operating system kernel driver software
but if you did this you would see that
we have as latency between when the
packet is received on the wireless nic
and when the when they when the kernel
driver software is able to respond to
that packet receipt okay and this is
because of the cpu when the packet is
received at the Nick the CPU is going to
have to it's going to raise an interrupt
with the CPU in order to respond to the
packet being there ready for processing
on the Nick and I'm ready for transfer
from the Nick to the computers wrap
right so we have this latency associated
with this generating of the interrupt
and the handling of the interrupt and it
turns out that you can measure about 70
microseconds of of time between the
receipt of the packet and the triggered
response other software defined platform
radio of software-defined radio
platforms like a new radio have a very
high latency ethernet or USB bus then we
have sora which couldn't will tell you
about this afternoon which has a much
lower latency in terms of the transfer
from the packet to the cpu so totally
possible that they could have used soar
to implement i think at the time sora
might not have been available for them
to use so they didn't
so what they did was with something
pretty cool anyway they took this
platform platform called open f WWF and
it's it's basically firmware for the
microprocessor that runs on the broadcom
802 11 Nick &amp;amp; is freely available you
can download it yourself on the internet
and you can they modified that firmware
assembly code to run maranello at line
rate on the neck so this is a great
example of systems building that they
did here and it's an interesting isn't
very interesting platform so the Nick as
a whole has a microprocessor sitting
next to the microprocessor it has
transmit and receive fifo queues for
packets both coming from and to the
physical layer okay the fiscal air
itself is implemented in an ASIC in
silicon elsewhere on the on the Nick but
this firmware and the small
microprocessor is working with the
physical layer and all these components
I'm showing you here to run the mac
protocol and the bit rate adaptation and
the link layer stuff okay so it's a nice
little layer of the system that they're
modifying okay the color the Nick also
has internal shared memory for state
variables because remember 802 11 has
this big state machines need to keep
track of in which state a turtle Evans
in template ram for composing a frame
just before it's transmitted over the
air and then registers and external
conditions to interface with the
physical layer and timers to accomplish
back off okay so the the firmware works
with all these components they modify
the firmware and they got marinela
working
so immediately we have these issues with
the timing of 802 11 right so remember
802 11 is a very tightly timed protocol
so ax need to turn around and come back
within a certain amount of time and then
once the ACK has been transmitted it's
the it's the net time for the back off
to the next frame to be to go ahead on
the air ok so there's issues involved in
lengthening the knack frame which goes
into the place that the ACT frame was
previously so you need to think yourself
in the reverse link for the ACK in the
neck what's the bit rate that 802 11
will use to transmit both those frames
so it turns out that the bit rate is
going to be a function of the forward
link transmit rate so 454 megabit per
second packets in a turtle Evan G the
reverse link will be 24 that megabits
per second or thereabouts-- right 46
megabit packets the reverse link will be
6 megabits per second it's a function of
it's a function of the forward link so
if our knack packets are slow enough and
the neck feedback is is big enough so
the air time is greater than the ACK
then we're going to cause problems in
the case of hidden terminals right
because here we have the receiver
sending a knack ok the sender will know
that the knack is still ongoing because
it can carry your sentence what about a
hidden terminal can a carrier sense by
definition a hidden terminal can carrier
sentence right so the hidden tourmalet
can then collide and make a collision of
the sender decreasing throughput it
turns out they just didn't see this
enough for this to matter too much so
they actually overrun the ACT length
with their necks
then they're very interesting problems
that arise when you try and build this
on that small microprocessor living on
the 802 11 Nick okay so they they try to
do that build it and it turned out that
the microprocessor wasn't fast enough to
receive the half the packet be received
and then go and compute the blocks check
sums one by one in the time interval
between the corrupt packet and when the
add the a core the neck should come back
okay so 802 11 is saying that you must
send that Acker neck by the Act timeout
duration this is a small number of
microseconds right just over 10
microseconds you must send that a
connect back okay each block checksum is
taking for microseconds so by the time
we have three blocks were out of time to
compute the checksums so the solution
that they did was which was a very very
nice hack is they have the packet coming
in from the physical layer silicon the
ASIC okay and it's the ASIC is
transferring bits into the into the
template realm of the packet as it
arrives on the air what they did was
they modified the firmware to compute
the first block checksum once the
transfer for that first block was just
complete and the second block transfer
ongoing so at that point the firmware
can start up and be computing the first
block checksum while the second block is
received and compute the second block
checksum while the third is received and
so on so they're pipelining their
pipelining one blocks check some
computation with reception of the next
block in fur
or so they're using the using the
hardware very skillfully to do this yeah
yes the question was is it possible to
pipeline at a higher level where the
acts are for two blocks before it is
indeed and we actually do this in ppar q
back then so yes yes that's right yes
but sometimes you want very low latency
right see okay so question is does the
protocol demand you respond 802 11 does
demand you respond 802 11 says you
cannot act blocks and in the past right
so in this case they kind of had to do
this if not freighter 211 for latency
but yeah very interesting i think i
think this area by the way is you know
Mac research is a very well there's been
a lot of work done in the mac in some
very well trodden area but i think this
type of low latency hardware hacking mac
work i think there still room in this in
there in there in the in the research
space for good work in this area so if
you're interested in this type of stuff
i'm going to show you at the end of this
lecture i'll show you some related work
some further reading that you might look
into
okay so continuing with their
implementation now building the repair
packets right so the sender transmitters
starting that act timer after sending a
frame and then the sender is going to
retransmit always the first block right
so this contains the important headers
that are syncing up which of the blocks
need to be sorry which which of the
blocks the receiver hasn't gotten yet
correctly which number of locks and then
repair packets are containing an extra
32-bit checksum in the last four bytes I
think this is because 802 11 you know
there could be bugs in the firmware and
a total Evans checksum is giving some
false positives or or undetected results
now on the sender side recall that the
sender has to compute block checksums in
order to compare with the receiver if
the packets the first transmission is
errored okay and we want that repair
packet to go out immediately in the case
of errors so what they do on the sender
is before the packet has even left the
cpu on the host computer they precompute
blocked checksums in the kernel driver
and send those block checksums down to
the firmware right for comparison later
with the receivers neck in the event of
a packet error right the main cpu is
more powerful we can spare the time
before we sent the packet at that point
we're not in this time critical 802 11
loop and so the block checksum should is
best kind of done there
ok so now getting to the performance
evaluation how well this all works they
are comparing they're evaluating on 802
11 channels 16 and 11 so they're
spanning the entire range of the
unlicensed frequency band they have
environments with background traffic
right advantage they're characterizing
institute right so they're getting all
the weird interference and fading that
you really get a native 211 the
disadvantage of this approach is that
you lose the repeatability of the
experiment right so results will differ
you have to just fall back on averaging
to report something meaningful ok so
kind of a fundamental trade-off you were
you make when you do performance
evaluations in implementation and then
they enabled the state-of-the-art bit
rate adaptation algorithm at the time
for 802 11 it was called minstrel
so first question they asked was by how
much this is the end to end performance
improvement by how much does maranello
increase link throughput okay so they
run using I Perth in UDP mode ascending
UDP packets over one of the links in the
test bed and they make a one-minute run
for a tour to 11 and then immediately
afterwards a one-minute run from
marinello with a 15 second gap so likely
that they're seeing the same wireless
conditions for both protocols then they
repeat 10 times with the sender and
receiver in the same locations change
locations and repeat again so here
they're running in one of two locations
this is there a University building
we're seeing throughput of maranello on
the Y and throughput of 802 11 on the x
axis and each point is one of those each
point is one of those iperf runs right
for one of those links so if we're on
the x equals y line we're seeing our
breakeven of throughput about a third of
the time we're seeing little to no gain
but then in a third of the time were
past that 2x line that you see here on
the graph getting up to almost 2x game
in terms that link it's a big winner
next question they asked was does
maranello decrease the time it takes to
correctly deliver one packet across a
link so now they're measuring the amount
of time the firmware of between when the
firmware fetch it fetches a packet from
the head of the transmit queue to
receiving the ack for that packet all
correct and that includes the
retransmissions the repair RIA
transmissions and back off in all those
vectors okay so if you're running a
video or telephony over your network you
care about this and they're using them
occur seconds the firmware itself has a
time a micro second accurate timestamp
counter that's measuring this time
precisely was there a question yep does
this legacy if you just complicate the
entire packet which is a erroneous and
you are great transmitting it what says
you kind of a block the entire packet is
the legacy going to be much worse in
partial credit recovery are it is not
know it's going to be better if anything
right because you only are transmitting
you're not spending time transmitting
the correct bits right and oftentimes
those correct bits are the ones that are
taking out that are dominant in the
package
that's what we see here right so we see
if we look at the cdf of latency we see
now maranello decreasing latency quite a
bit right so 802 11 inch 11 cdf here
with the black curve we're seeing most
of the packets delivered correctly with
a latency under way under 10
milliseconds or just a couple of
milliseconds latency and then we see two
humps in the air to 11 curve for falling
back to 1 megabit per second in the rate
adaptation and then we see maranello
doing even better than 8 to 11 for this
reason because not retransmitting the
correct bits not spending that time
retransmitting the correct bits ok so by
the way a bit of a data presentation
note for you poor young researchers in
the audience you know if you're if
you're showing a latency distribution
like this where you have very small
quantities please use a log scale right
we want to see detail down here at the
lower end and less detail at the upper
end so this is a ripe candidate for a
log scale CDF on the x-axis
okay so whenever you tell people that
your protocol is going faster than
somebody else is good at home you should
tell them why so why is your protocol
doing better okay so what's the source
of Mara knows improvements right there
measuring now delivery probability of
every transmission attempt okay so
probability of a successful transmission
on the y-axis and that's transmission
attempt 1 2 3 and so on on the x axis so
the purple curves here are four 802 11
and we see that for the first
transmission here the black curves
marinello are roughly the same
probability of a successful reception on
the first transmission that makes
complete sense right is the first
transmission is the whole packet in both
cases right now the second transmission
in the case of maranello is that repair
packet and in shorter so remember what
we said about shorter packets there
they're going to be sent at the same bit
rate because maranello is following 802
11 s bit rate adaptation protocol and
they'll be sent at the same time because
marinelle is following a turtle Evans
back off protocol okay but the
difference is maranello sending a
shorter repair packet so what happens to
delivery rate it goes up in the case of
maranello as you see here with the boxed
data points in black at transmission
number two
we go on transmitting each time
maranello is sending fewer packets so
it's maintaining a higher probability of
packet reception and then a transmission
number for minstrel is doing this
horrible thing to us falling back to one
megabit per second very slow and all the
delivery probabilities go up and then we
see the same pattern playing out again
right so we're this is one reason why
Marlo is working we're increasing the
delivery probability alright so that's
performance on in isolation on one link
okay how well might marinela perform in
a network of consisting of an AP with
multiple clients right so what they did
was they set up maranello on linksys
wireless routers associate to desktop
clients a and B with a Maranello ap and
then send uplink traffic from both a and
B using I pro birth right
okay so here you see performance of a
going down from the from the ZeroAccess
here in the middle performance of a and
performance of be going up in terms of
bits per second megabits per second okay
we have four cases both are 802 11 both
are maranello and then one of the two is
maranoa ok so if both stations both
clients now are running maranello we get
a big throughput win comparing the 802
11 and the maranello curves right that's
expected because we're sending less bits
over the air so that's fine strange
thing that they observed was when they
try to run maranello on one of the
station one of the clients but not the
other ok so if you go and you run
marinello on be but not a it turns out
that ace throughput will increase ok so
and vice versa if you run marinella on a
beez throughput increases in blew up
there above ok so does anyone want to
open the floor doesn't want to
conjecture why we have this inversion
property that running maranello on a
increases the throughput of B and vice
versa
anyone want to hazard a guess
let's assume that they kept a and B and
I think they did at the same locations
throughout the experiment
yes this that's on the right direction
so so that the answer the with the
suggestion was reduced contention right
so but why exactly yeah yes I think I
heard the answer yes okay so the basic
explanation is that if a is maranello a
is is following exactly the same back
off procedures as 802 11 as a running
802 11 would so they're getting the same
transmit opportunities but a as you say
is sending shorter packets okay that
means that they sense a and B get the
same transmit opportunities freighter
211 when be grabs the medium and guess
that transmit opportunity it sends a
longer packet and thus is throughput
increases relative to the baseline right
so we have this inversion of running
maranello lets you be let's helps your
neighbor rather than helping you so much
now you notice that a is throughput
certainly let's say a strippa doesn't
decrease much if it runs Marinella right
so you're not hurting yourself too much
but you're helping the other guy by
transmitting shorter so in a sense this
is like the classic the classic rate
anomaly in 802 11 playing out in maranoa
ok so then earlier earlier today and
yesterday you heard about frame
aggregation right so this is these ideas
coming up again basically as bit rates
increase and trying to reduce the
relative over
head of those fixed contention overheads
relative to the body of the packet so
Annan AC are aggregating many frames
together in an approach that looks a lot
like block checksum okay so what are
they what's the response to this because
aggregation was already beginning when
marinela was was being was done
aggregation basically increases the
latency on your link and they claim that
maranello is complimentary with
aggregation I think I agree with that to
some extent right so marinela is working
with in one frame checksum whereas
aggregation is working a priori right in
the end the thing that's transmitted in
the frame is transmitted they also talk
a bit about the optimal block size and
as we talked about before you can
actually an allylic analytically compute
the optimal block size in general a
larger block is less efficient on the
wireless channel but you have to do you
don't have to do as much computation in
the firmware to support larger block
science so one possible Avenue might be
dynamically varying block size and
aggregation size based on the ER as we
said that's difficult when you have a
wireless channel it's changing so
quickly was that a question or a
statement flesh ah I expect that there
is work in this area yeah i haven't seen
exactly this myself but i expect yeah
alright so that's all from marin oh I
think for takeaway points you know
interesting system that realizes pract a
partial packet recovery very interesting
platform that is open f WWF go and check
it out that is ripe for experimentation
of other aspects of the link layer and
problems in medium access control in
general
and the nice thing about this platform
is it enables you to run testbed
experiments at scale so back in the 90s
and the 2000s we saw a lot of link layer
and Mac layer work that was done in
simulation and we didn't really know how
these protocols would work in the real
world with real wireless links so these
types of platforms let us answer those
questions which is why I think this work
this work was done back in 2010 I
believe and that's why I think this work
is kind of still relevant today and why
I'm telling you about it all right so
questions yeah yep yes
I think they were using 1500 bytes
packets in these experiments I think we
would have to go back to the paper to
see but if i remember correctly was 1500
bytes correct yes same initial packet
sizes yeah initial packet sizes yes yes
yes yes not not that I'm aware of I will
say that you know most of these this
most of maranello is implemented in
firmware in assembly firmware right so
that's really the right place to do it
which is why it's such a nice system
design just to see how they did that
right so I mean these issues that we
talked about the pipelining the time to
compute these would all come up in any
implementation really I mean oh I say I
say you don't want one okay so the
question was in hardware isn't it easy
to implement a checksum in a sick right
but in this case you don't you don't you
might not want to spend those gates in
your in to complicate your ASIC design
right you might want to put that in the
firmware ah okay okay let's take this
take this off like it's definitely
debatable where where to put different
functionality right you have the a cig
you have the firmware you have the
software so you know a debate can be had
about where to put these functionalities
yeah yeah they didn't take it to scale
in the paper no no true fair enough
thanked alert Kyle and you guys will be
seeing some more cutting-edge stuff
tomorrow on rate less codes and sort of
pushing the next boundary</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>