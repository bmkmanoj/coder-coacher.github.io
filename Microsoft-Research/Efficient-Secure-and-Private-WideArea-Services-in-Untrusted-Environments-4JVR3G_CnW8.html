<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Efficient, Secure and Private Wide-Area Services in Untrusted Environments | Coder Coacher - Coaching Coders</title><meta content="Efficient, Secure and Private Wide-Area Services in Untrusted Environments - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Efficient, Secure and Private Wide-Area Services in Untrusted Environments</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4JVR3G_CnW8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
I ended at a university of washington
sewing up does distributed systems
networks in security he's also just an
example of a very complete sisters
builders how do I put it able to do
great an analysis and fantastic system
building at the same time he's got a
variety of systems and not only has he
published in our top systems and
networking conferences but he's also
published at places like KY and nips and
Ally ww so really looking forward to his
one-on-ones with everyone at the lab
thanks honey thank you said so hello
everyone can you hear me well in the
back right so thank you for coming to my
talk so today I'm going to talk a little
bit about my research and some of the
future directions as mentioned i have
pretty broad interested in any areas in
computer science worked on the
distribution system security privacy you
become and some machine learning and
computer vision related stuff so before
starting my PhD was studying in south
korea and worked for as a software
engineer for three and a half years and
then started PhD in 2010 so i also did
internship with MSR three times before
twice in redmond and once in cambridge
although this is actually first time
being in New York City so thank you for
having me here so today's todo many
different research project I hope we
will be focusing on the systems and
security stuff so let me start so in
recent years how people use computing
devices has evolved rapidly do we have
many different devices like from
traditional computers laptops to
smartphones tablets and or computer like
smartwatches and glasses and now the
internet of things such as old devices
around we or our owners will have some
sort of computing power and connect it
to the internet so along with distant
new devices we have many different
applications which access our personal
information so the amount and the type
of personal information have ever been
increasing
it includes user's location or contact
address has information or some of the
application may use your search queries
so it becomes very easy for users to
access those information through the new
devices unfortunately not only the users
but the other parties can easily access
users in personal information as well
and when we are using internet there are
many different entities which we can't
trust or we can rely on so these are
raising the security and privacy risks
at the same time users may not
understand how their information exposed
and also they do not have much control
about the information exposure why do we
feel free to ask any question during the
top so we can apparently we can change
the first two to point so we are going
I'm trying to address the third point so
we want to give users control over how
their information is exposed and used
from the remote services what does it
mean so let's look into the simple
diagram showing the interests involved
in the internet communication so you may
run some application on your computer
your smart phones and it's connected to
the Internet and they are talking to the
remote services so throughout my PhD
research I have studied various issues
in each environment so first for the
application I worked quite a bit on the
smartphone privacy and risks risks so
back in 2010 it's kind of becoming the
Android system becoming a very popular
so one of the great thing for the
smartphone is not only android but
iPhone or Windows Phone it's great to
download any application from the
application market well we could enjoy
the functionality from the third party
applications it was pre unknown about
how the application use our personal
information whether they are just using
the phone or send the data so I
participate in the
10 droid project which is information
flow tracking system that reveals where
does the information i mean the your
location where any other information
goes to which which server so they can
say oh your location is being sent to
like being mad it's fine but it's also
being sent to the advertising server
based on this project I was also
proposing a privacy protection mechanism
to say selectively give application some
real or fake information or block run
onto the information packages also
worked on studying for third-party
tracking like advertising or analytics
in in the smartphone context and also
security vulnerabilities in smartphone
by combining static and dynamic analysis
so moving on to the next target have the
network can be untrusted or unreliable
fundamentally the current internet
architecture was not designed with the
security or privacy considerations so
what's looking into how we could
redesign the whole internet with the
principle that older network element use
very minimal information for the
communication so and finally there could
be a little more obvious adversary's at
the remote servers well adversary's to
the users which I will talk a little
more in detail today so in this toya
we'll talk about how we should design
systems when the remote service are not
reliable or not trusted with two example
systems the first one is code meta sink
which is a file synchronization system
across multiple untrust sister Edie
providers like a Dropbox or onedrive in
Microsoft and then I will talk about
something called pseudonym abstraction
where each application or user can may
use can use many many pseudonymous
identities to control over their
information exposure
and then I'll briefly introduce some
other work I did and future directions
so let's talk about the medicine first
so there are many different cloud
services now among them I was looking
into the file sync service so one of the
most popular service for the user end
and also many application rely on the
file synchronization services so the
service like Dropbox make it easy for
the users to access I mean to store
their files in the cloud and access from
many different devices also to prevent
of oh what's up interesting okay okay oh
yeah my proscan and also with your using
those services for sharing files with on
other other friends collaborators so
with this convenient that they are
getting much popular the last year the
the dropbox announced that the number of
their users which is four hundred
millions and there are also similar
service provided by many different
companies including microsoft and
recently chinese some of the chinese
companies started to provide like two
terabytes of free space so this sounds
great but the question is however can we
rely on a single service for storing
whole our files or for sharing files
with other friends while we the users
may expect those services to work well
fundamentally there is no reason to
trust those service providers so some of
the services may come from like smaller
companies so they may become unavailable
time to time and some others may be
provided by the companies which located
in some other country which we may not
really trust so in fact there have been
many incidents that I mean you may have
heard of news that your data stored in
those sync service at risk even with the
relatively trusted companies like
Dropbox or
Apple so we could think about building a
totally new system from scratch to use
those cloud services with minimal trust
and we've seen quite a bit of assistance
from the distributed systems research
but here in this product I want to
tackle this problem from a little bit
different direction so we are building a
fasting system by exploiting multiple
listing services so while its service
has its own unique feature to
differentiate from others they're cool
functionality is to allow the users put
their files into clouds and access them
so each is service has two pi AP is for
other application to build on top of
their AP is so we are going to build a
system upon those AP ice and by
combining them I can have better service
better service means higher available a
greater capacity higher performance and
stronger confidentiality and integrity
so and in addition to those goals I want
to we have we had two more goals in
medicine so we don't expect
communication between those service
providers because they are served by
other I mean different companies and we
are not relying on communication among
clients as well and we are not going to
introduce new servers from our point of
view so every implementation has done
and one in clients so from the goals I
just mentioned there are three key
challenges in the system so first we
need to maintain a globally consistent
view of the synchronized fall across
multiple clients I won't be explained a
little bit more about this and we are
using own leaders the service providers
unmodified api's we are not going to
tell them hey you should unify your aps
for us and finally the system should
work even with the presence of some of
the failing services
let's hope we design this so this is the
overview of the design there are three
sub components so first the object store
for maintaining files and there's a
synchronization and replication
subcomponent and it's connecting to the
backend API spec and service through
their api's and we define common
abstraction for the services so that we
can easily plug in the new service
whenever we needed and finally métis
tank also interacts with Lucas local
fuzz Paula system and there is a layer
between here which does encryption and
integrate check when they are sending
the files to the backend were
downloading files from the record and
the first thing that the object store
holds files copies of files and those
copies will later be replicated and
synchronized to the backend services and
this has a similar architecture with any
other version control systems like a git
or svn so they are using this system is
using content based addressing and hash
tree so by using content based
addressing we are naming the files with
its hash of the content so it can
automatically deduplicate if there is
some same contents in the different
vowels and all very simple integrity
check so we can check the weather the
name is matching with the hash of the
content when we are downloading the file
and finally but because file name is
unique it can modify or I'm not download
independently to each other client
what's the difference between just
having a cloud service implement you
know all this system stuff to make their
file storage more reliable versus having
the user use a bunch of services with
this thing in front of it right so it
said the end user it kind of close to
the full mark points so it's kind of
individuals running the system and we
are spreading the files into the
multiple different back-end services so
church it's a service provider can have
better reliable more reliable service
from their point of view but from the
users we don't we are kind of spread our
trust over multiple providers and it's
mentioned directories for hash tree so
what it means that the inside of the
object store would look like this so
directory maintains pointers to the file
and falls our chunk a file sizes to be
or files in a directory can be merge it
in a single object if file sizes are too
small and from this hash tree the hash
of the root is uniquely identifying the
current snapshot and when some of the
file is modified like here the large
thin is modified what happen is the
object store will create new plot for
the modified version and updates its
parent pointer recursively finally there
will be new new hash value which is
defining the updated updated snapshot
and then as mentioned the blobs here
it's kind of describing how i mean the
dis dis tree is describing the some
logical view of the object system object
store system and we are synchronizing
the blopps into the backend services
mentioned
and simply saying we are so it can
happen both in 10 minutes we have
defining some threshold so if file size
is too small then we can put the
multiple files into a single bob or a
file size 2 bay we can chunk down into
the multiple box yep so this is kind of
rapport cating the whole file system I
mean the directory dedicated for being
using the massing system so it's kind of
doubling the space and plus little
overhead for metadata and also we can
keep also the previous version as well
if the user wants so in that case it can
grow more but so it's possible like
because we can build the object on the
fly when it requires to for example
synchronize at the back end or
downloading from the back end it's
possible so it's kind of trade-off
between like computation and the street
and usually what we have target is like
several hundred gigabytes of
synchronization or several likes it kind
of depends on your vocation or usage
model for example some sometimes in in
the mobile device you may want to
download only thus some subset of the
files so there are several different way
to approach that but it's kind of very
nice first implementation about of the
design
so we are replicating the object
redundantly across the our storage
provider door is configurable number so
if there is two for example the blob can
be replicated like to us I will not go
over detail for thus the main idea is we
are using some sort of determines
mapping function so when a blob is given
we can calculate hash and we are giving
that hash into the function and the
function will say hey this blob should
be stored in onedrive and the dropbox or
the other blob should be stored in the
google and dropbox or as a try so
encryption as we have option to encrypt
so it can be encrypted before storing
and then the functions are kind of it
can it's it can I say it doesn't matter
where where it's calculated for this
specific function are you worried about
Dropbox failing and there's your data or
are you worried about drop-bys being
hacked and and someone looking at your
what's what you have stored under yeah I
think that we are trying to excuse me
address both issues so if you store it
in plain terms yeah we are we are the
again there is an encryption layer so we
can the users can say what we be
encrypted and it singleton before
sending so yeah I will talk a little bit
more about the synchronization itself
cuz as mentioned H flop can be
independently unload or on a little or
download it because they are different
if the names are different but if there
are two clients or more clients and they
are kind of each each of them is
modifying the files and what happens is
if they are claiming or concurrent
concurrently trying to update
what's the most recent version it'll be
a problem although the other many
services also looking into the same
problem so what let's look into what's
happening so at the beginning
everything's I mean there let's assume
there are two clients and they are
synchronized to the same point and if
the clients one as modifying files only
the plant one is modifying false then it
can update the global view by saying
next version is whatever it has and the
other client can catch up but if both
clients modify files and they are trying
to I mean concurrently say hey next
version of we want is my head not the
others then we need us some way to
determine which which of them should be
selected for the next version and then
the other clients can catch up I mean by
merging onto that master so this problem
determining orders and distributed
systems a traditional consensus problem
for example we can use app exes or a
two-phase coming for making agreement
for example the Praxis II is a multi
round non-blocking consents are prism
and it's known to be safe regardless of
failure and it can progress if as long
as majority is alive but the problem
here we don't have those api's I mean we
don't have pix SI p is we don't have to
to face comment AP ice and also we don't
have communication channels between the
servers or client so the challenge here
is we need to handle those concurrent
updates and potentially unavailable
services only relying on the existing AP
iced so how can you deal with this
really instead building our own server
they letting the Praxis we are trying to
find a way to simulate paxus given the
api is provided by the the current
services even though there is no pectus
api
we could devise a way to simulate what
it was it something called a panda
littlest abstraction here the client to
send the no more texts messages to the
servers and when the message arrives at
logically when the message arrives
services append those messages into a
list and clients later than can fetch
the list of ordered message to figure
out which a proposal is accepted so this
abstraction can be built in a various
ways for each service using their AP ice
so we built the append on the list with
the comment on a file in Google Drive
onedrive and box and in dropbox we use
revision list and if those aps are not
available we could also build this with
the files in a directory for we used for
the Baidu right right and you're
implementing Paxos by appending to a
list but the list already implies an
order so why do you need to actually
simulate axis because some of those some
of the service can be unavailable so if
we are using you we have a single single
machine that's actually a good point if
we have a single much of which we know
that it's always a vowel we can just
throw that into the service and it will
order the message and we can figure out
which one is correct but if some of the
service are failing or even some of the
service are doing some misbehaving we
need our way like Texas it's a kind of
same for even we even if we are building
from scratch so like your writing to a
list on each one of the services mm-hmm
yep I will explain a little further yeah
so this is what we called as a paso
texas because back-end service our work
as it is past acceptor and they just log
messages and clients can fetch the
messages and
the client I mean the except except errs
decision are made in client as if it
would have done in dock scepters so in
this diagram which client can propose a
new route for example say the gray one
saying did the new route is one and
green one is trying to say in the new
riches to and after fetching those like
list of logs it can climb that okay or
you can realize that accepted rich as
one so this is a simplified diagram an
actual actual algorithm this is done
through like this Marty round as like
prepared promise and propose except as
in as in the taxes actual packs of
sarcasm sure yeah although it again it
needs to be done through like prepare
stage it needs to be win winning there
and then it need to be actual winning at
the proposal and propose stage as well
not all the services are likely that's a
healthy yep no if buts so what you're
waiting a lot here on like to make
progress 22
for lightness right right the
termination property is that eventually
you'll be able to actually retrieve
these logs from the different service
mm-hmm but if you could retrieve these
logs from the different servers then you
can just say i'm just going to rut meet
the head of that log and then that's it
sorry and then that's it like skip axis
if I'm just if I'm waiting any way to
retrieve the logs from these different
servers then I'll just then I'll just
read the head of that law rather than
just going through all of them and
simulating multiple rounds I think you
can tolerate a minority of failures
right ya know right so you can tolerate
a minority of unavailable so it shared
the same same property with apexis
because we are actually simulating Texas
so yeah we can talk to little more
dependents so we implemented this but I
think the prototype of the Mara think in
Python because all the services are
providing their API is in Python it was
about like a thousand lines of code we
are supporting in five different
back-end services and we have a 2 client
I mean to front and a client one is
similar to the version control system
which is current line and the other a
synchronizing them on so you can
dedicate a folder to be periodically
synchronized to the backend for the
evaluation we check the penventon
performance we have another numbers in
the paper but for this we synchronize a
folder between two computers how what's
using the client from the services and
the medicine we present it to different
workloads here the 1s length scholar
source code which has many many small
files and directories and the other is
like about 50 photos and you can see the
medicine is outperforming quite a bit
for the synchronizing small parts
because we mostly merging the small
files into a single block and then the
many services have very poor performance
I mean through food when downloading or
uploading the small files and then also
we are using the pair
no para doughnuts the performance is not
really something very important top kind
of evaluation criteria but it's kind of
good to have to see that okay we have
some performant service for on top of
the IPX information somewhere else so I
guess right so since you're storing
everything at bombs mm-hmm you meet
looks like you need the set of unity
meta-information sit on the client side
so that you can access all those block
right right and then just put it
together right rightfully so do you have
a so either make there's a standard
solution on how to deal with that I'm
just gonna wondering like you know if
client is really just my computer it
breaks down then all the all these blobs
are completely useless them so um I to
joy to spend a little more what do mean
by break like you do and you can turn
your can't access show you right right
so this thing is yeah the meta
information is stored in the back end as
well so you as long as you can access
the back of service you can rebuild that
so my time for me is not restoring low I
think all right right yeah wondering
what level does its disruption to their
but yeah so I'm wondering i'll actually
do you have a measure of how much slower
or faster medicine is versus sending all
lobs to one service
right so we don't have measurement as
mentioned that kind of probably really
not fair comparison to the natives
clients also they are not really
optimizing to the performance they kind
of want to just correctly storing the
files but yeah and we don't have the
measurement for that so in summary the
medicine is kind of reliable and perform
enforcing service on top of those
popular cloud services and our to
achieve the constant update we devise a
new client base packs of surgeries yeah
this is a good question i was trying to
think but haven't found much yet so one
thing for this we after finding i mean
after dividing this algorithm was
looking into several literature and
found that actual import was working on
this similar problem contacts they have
something called disc texas and we have
comparison in terms of we have a little
little I mean it can be considered as a
team on optimization of the disc Lexus
and so there might be but I haven't
found some other vocation for the
specific one how robust is it if if
everything fails except one service now
recover or you need to at least two so
there are two different things so one is
how do we relate so in terms of the
blobs and how do we progress in
synchronization which one is the most
recent one so in terms of replication it
depends on replication factor we are
saying that the if R is to it can they
can hold up to just fell 1110 failure of
one service or our history into service
but for the path of terrorism at its
yeah majority need to be alive your
simulation what it's what replication
so we were using the our relation yet
using the Oracle to are you see ya that
means so it means for the file flop it
can be okay with a only failure one
service and we I kind of skipping that
but we also have a stable determine
mapping our poison so if you're
interested in please visit our website
there is a source code and a paper link
so I talked about the pricing service
with the unreliable or untrusted back
end and it also can prevent remote
service from licking or corrupting files
and next I will discuss how we can
prevent service from linking the unknown
to the uterus activity so this is
talking if this is togas about internet
tracking so as mentioned in the very
first slides of this talk there are many
different types of personal information
sometimes it is not really obvious to
see the privacy risk one example as
tracking user behavior so when we are
using the today's Internet we should
have shown that the most of our activity
on websites will be tracked by remote
service you may have experienced that
after looking into some of the closings
or shoes then the advertised just popped
up directly targeting that the specific
product so it's a one example of the
behavioral targeting and it's done by
tracking so there's some previous work
done by Russell and I'll saying like
along the top 500 websites 91% embed ns1
tracker and eighty eighty eight percent
have some sort of third-party trackers
like analytics or advertising and the
web services are well incentivized to
build a big user profile because they're
rebel model is strongly tied to the user
understanding the users behavior and
information collected from the tracking
may include from the users agh
gender or where the user leaves to
somewhat more sensitive information like
political opinion medical information or
sexual orientation so let's look into
how I'm in the tracking a little bit
more deeply so in this example there are
two people Ellis is sending a set of
courage like Microsoft or route to her
home address and Bob is sending another
set of course and the tracker Bay know a
the first set of course our is
coming from the some person and the
other set of course coming from some
other people the other person so what
does it mean to us so information
collected the tracker can create a very
detailed picture of you because because
of this we usually think or consider the
tracking as something something bad
something Humphrey to us Oh however on
the other hand we are getting some
benefit as well like tracking can be
considered as a tool for creating
relationship between users and the
services so it can enable
personalization like recommendation
service or it can be used for better
user security like in banking's and in
some sense the users we are also paying
for the service spine being tracked so
in terms of tracking the tram model is
not just tracking but I did say the
threat model here is that the remote
services are tracking users through
information in packets to correlate even
unknown to the traffic together so what
could be a better scenario so we would
like to have tracking look like this
picture so Ellis may keep her address
from being correlated to her other
queries and similarly Bob may want to
separate his queries related to
depression to the others so even those
two sets of curries are coming from one
endows trekkers cannot know whether they
are coming from
one host or two defenders so we are not
arguing I'm not arguing that we need to
get rid of the whole ability for the
trackers to link activities from the
server side instead we want to provide
users with more control over what can be
tracked or which activities can be
linked together so by giving users
control over what to be tracked we could
eliminate or even remove the problem of
privates risk and at the same time we
believe that we can still maintain the
positive side I was tracking before
jumping into our approach I i will
describe a little bit about how tracking
works the basic idea is a service truck
you just by linking their request and
multiple requests from a host can be
linked when there is a something shared
identifier so many websites are using
cookies in the HTTP header to find out
where the requests coming from and even
IP addresses by itself are still
effective main for the trackers to
figure out especially when combined with
other fingerprinting information so you
just we are I'm claiming that you just
should have control with an abstraction
covering not only just a single
identifier but all different identifying
features which will call as a pseudonym
and it a host manages a large number of
unlink of a pseudonym and the users or
up occasions can choose which one to be
used in which scenario which context for
example there to be a new female sue the
name to be using one-time purchase and
from the previous example like Alice can
be using a one pseudonym for medical
information and the other selenium for
her location related cars and sure
so if you see you enable users to create
these options and say there is a way to
create the nukes you then you simply
done like why wouldn't the user create a
new pseudonym and every session you know
assuming it can be easily instrumental
and that would just you know remove all
the benefits from having these cookies
in the first place so it's like now all
the privacy and you know on the left
side and none of the materials on the
right side so the question is you were
saying there should be a way to enable
some privacy while preserving the
utility on the other side yeah it seems
that from a user point of view they
would rather get all the privacy and
just make every session on items yeah
but the thing is yeah I mean it depends
on so whether you how much easier once
the user just want a privacy it makes
sense they just want to get more like
every requests have differences in for
example or some way to just protect but
as I mentioned it it's a little bit
control it could be a little bit
controversial whether there's really a
benefit by being tracked but there are
may like that's it's kind of for the
service providers they are getting good
benefit in terms of how they are
understanding the user right so if we
are just removing that factor that could
be disruptive for the service provider
side so we I want to kind of maintain
the relation well between the users and
services so as an overview let's see how
we want to use pseudonyms so when Ellis
is using the one like for medical
information she has a one student and if
she needs another another pseudonym it's
determined by the policy engine from the
OP occasion side
if excuse me and there's more like more
pseudonym it can locate that through
talking to the operating system by for
example locating more IP addresses and
the operating system in turn need to get
support from the truck like a dhcp to
get the new IP address and like lowers
to the route packets to the kroc
destination and then you can get the new
pseudonym to work with like sending
another queries to the trigger so we are
designing in a cross-layer manner so
we'll talk a little bit about how we are
using that in the application layer and
we want to the hell we are supporting
from the network layer right so it
that's a good question so we are trying
to say the pseudonymous abstraction
should also cover some of the pink of
printing information although this is
kind of lust really the cookies and I
peace so for example there are several
different finger printing method like
using the font in the operating system
or using the window size so ultimately
do the like in the web browser should
control that information as well for for
example they are just giving the same
information say infant with us like
average other people so there could be
different mechanism to build api's for
for the several different types of
fingerprinting information but currently
we are kind of luster above examples
so from the opposition side application
need to assign different pseudonym
difference to do them into different
activities so let's assume that there
are many many different pseudonym is
available from from the computer side
however how to use it as depending on
users and applications sometimes people
might want to have every packet bit
different pseudonym or they might change
it pseudonym for a different account
there are many variations so how do we
know which pseudonym to be used as a
system designer I would actually know so
what we do is we are trying to build a
flexible way for each application to
define their own policies for example in
a web browsing post can be defined as a
function of the request information and
the state of the browser like unique IDs
for each window tab or request and so on
so let's look into what kind of policy
could be possible although this is very
very simple policies proudly displayed
the by default every request has a the
same pseudonym so Facebook and excuse me
and here in this example face you can
know that this user is reading some
special article in the news website
because it has like button and then it's
matching with it the users previous
login to the Facebook and some extreme
case every request again have different
pseudonym but there could be many other
like policies in the middle for example
web browser can change so that I'm
according to the pages domain name the
user connected it means that when a user
visit new stockham every image or script
use the same pseudonym and it has a
different pseudonym when the user is
using facebook com so in this case
Facebook cannot know the user submitted
to news com so
I just briefly explained how policies
can limit servers tracking ability so it
can still but once you use it then it's
kind of giving that information to the
to the Facebook server so there is
another so it's kind of building some
privacy protection mechanism in our
policy engine so there are several
different proposals for example
separating / first party or disable the
social button until it clicked those are
can be implemented after its click then
they know but it but if you don't click
right they won't rev it so again this is
not something from us it's kind of weird
it's kind of demonstrating we could
build several other proposals in our
system so let's look into Metro players
because I'm running out of time I've
kind of briefly tried to brief in
explanation so to support student
restriction we need to consider
following three points in this the first
thing is we need to have I mean it just
need to have many IP addresses could
want to assign one IP address /
pseudonym and the other as those
addresses should be properly mixed what
it means if they are in the the IP
address in in a single host are
clustered it clustered together the
trackers can easily figure out okay
those cluster is coming from the single
single host or in the other hand on the
other hand if the addresses are just all
random then there's an issue with the
roar the roaring table could be just
exposing because they need to kind of
maintain all different entries to write
the packet so how can it do this so we
don't have currently many IP addresses
in ipv4 but we are moving toward ipv6
world so in ipv6 even a small network
can get this last 64 IP address
which is already much larger than whole
ipv4 space so with the ipv6 will have an
environment where it shows can have many
addresses and then if we are looking
into IP address what we can realize is
the first part is used to route to pack
it into the network in like a BGP
routing and the second part is being
used for routing the packet inside of
network so once the packet is coming
into the network the network can use the
second part as they want whatever they
want they can encode information into
the second part so what we did is we are
devising the dividing the second part
into three parts it's a subnet ID and
host ID and pseudonym ID and the first
tool are actually pretty same with the
current Intel Architecture and what we
do is we are using symmetric key
encryption to encrypt that three
together into the encrypted ID so after
encryption it will look like randomly
chosen from the whole I pee poo however
because it can be decrypted after the
Christian it can figure out I mean the
rowers can easily figure out which is a
next-hop for this packet the destination
so and those knows only the encrypted IP
addresses and roars use those
unencrypted part by decrypting the
packet when it comes to forward packets
and it uses longest prefix matching with
the the same information with the
current internet architecture so the
efficiency and the warring table side
will remain as the same so I will show
us example like how it can figure out
and when packet is arriving when packet
is coming from the destination it can
deliver the packet into the lectric by
looking the prefix with the bgp protocol
and when it arrives into the roller the
wrong
our nose is a key and it decrypt the
packet to see the the base address i
mean the decrypted address and it can
figure out what's the next stop and it
does the same thing until the packet
arrives door and loosed and no something
to note here is we are encrypting and
decrypting the packet only for the 64
vet which doesn't encourage too much
overhead and it also can be easily
delegated into the hardware so we
implemented a prototype as well because
we don't have the ipv6 and control I
mean we have ipv6 usually in campus
network but we don't have whole control
over that however there is a ipv6 broker
we can we could use for building the
prototype so for the policy engine part
we were using your building in the
chrome I mean the broader extension to
have JavaScript function to figure out
which pseudonym to use and we were using
the ipv6 tunnel broker which is
connected to our gateway server so if
there is a tunnel between them and IP
addresses can be assigned in the Gateway
so finally it's being used as a web
proxy so what had happen is the
extension as tagging the request was the
switch pseudonym to be used and the
proxy can assign the outgoing socket to
have the specific IP address which is
connected through the tunnel broker to
the whole ipv6 internet so for the
evaluation we were looking two different
things first we are trying to figure out
whether its expressive enough to
implement various policies so we were
looking into different papers and what
kind of protection mechanism was
proposed especially for the cookie side
and we are implementing it in a cross
cross layer manner
and we could implement too many
different policies many of them are just
straight forward and some of them are
very simple like every request use the
same pseudonym or every request use
difference to the name we could use a
request ID for that and there are some
other things using a little more
information to build and then we are
moving toward like whether they are
effective in preserving policies again
it's kind of testing the pulse engine to
see whether we could we could have a
mini different pulses and what we
checked is we were kind of collecting
the choices from 8 users for three days
and every request has some information
together with like a request ID and the
type ID and window ID and we are
simulating the policies to see how much
how many at how many activities are
exposed to the third party so there
could be a very different way to figure
out like whether it's exposed to the
first party or third party and this
specific evaluation is forced to see how
many activities are exposed to the third
party remote services and as you can see
from the red line there we could reduce
quite amount of activities observed by
third party while having not too many
pseudonyms in a system so introduce the
new abstraction close to the name out
kind of skipping a little bit because
it's running out time but so before
finishing out yep your pseudonym
compared to like incognito mode so
incognito mode as giving the litter
there are several different research is
actually looking into how what is
exactly the incognito mode does one
thing is they are kind of stripping the
cookie after a while so at suffocation
layers protection mechanism and then
it's a kind of separating into two
different types of
mode so one mode is kind of private and
the public so we can say that this is
one differences we are building it in a
cross-layer manner and the other is we
have more more fine finer grained
control not just the two modes but you
can do have whatever you want so before
finishing up I wanna kind of interest a
little bit of other work so most of the
most of the work was still some systems
research but with connection to other
fields like ubiquitous computing or
applied machine learning so I worked on
voice and the computer vision
interactions especially in the context
of the mobile devices so and then if I
was we are trying to enable the natural
language spoken natural language
interface for any of third-party
applications i was building in the
windows phone actually and we just to do
extension and and then I've been working
on how can we fix efficiently run the
neural network in the context of you
have the mobile device and a cloud and
what kind of schedule we need to have
for getting more efficiency so I can
talk anything about that in in the
offline and or in one of the meeting
later so looking forward I plan to
continue the research in systems and
security also in connection with any
other collaboration with other
researchers so one example I will
briefly talk about probably for the
second and third one so we many
researchers have been looking into the
neuron that in terms of how can we
better accuracy how can you get better
accuracy or how can we have a faster
training because training takes too long
but in the real application context
there will be many many because many
many applications
we'll use some sort of neuronic
classification then I could imagine that
there will be many application and
concurrent requests coming to the
service side like there will be many
users there will be many applications so
what kind of architecture system design
we need to serve those requests more
efficiently you'd be an interesting
direction for me and the last one as
combining from the system side and in
computer region side and the privacy
issues I've worked on so it's pretty
obvious like if everyone is using some
sort of computer vision application and
do is it okay to send the data to the
cloud and let them process it because it
will definitely some invade your privacy
what kind of architecture to protect in
those scenario as one of the other
direction I'm looking into so today I
present how we can give more controls to
the users in the untrusted and
unreliable environment so as examples i
talked about fasting service with
untrusted storage and the pseudonym
obstruction for the private control and
thank you very much and i'll be happy to
take any remaining questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>