<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Designing Mixed Reality Interfaces to Support New Forms of Social Engagement and Creative Expression | Coder Coacher - Coaching Coders</title><meta content="Designing Mixed Reality Interfaces to Support New Forms of Social Engagement and Creative Expression - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Designing Mixed Reality Interfaces to Support New Forms of Social Engagement and Creative Expression</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/g32VSvgz-kE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by microsoft
corporation may be used for internal
review analysis or research only any
editing reproduction publication
reblogged public showing internet or
public display is forbidden and may
violate copyright law okay okay we'll
get get started thank you all for coming
I'm really happy to introduce that
hunter who's visiting us here today Seth
is just finishing up his PhD at the MIT
Media Lab and I think one of the
challenges death probably has he has too
many interesting projects to share with
you in the time frame that we have so
we'll see some of his work but feel free
if you if you have time schedule to talk
with them I think he's probably had lots
of other projects that he's not able to
show today with that I'll hand it over
to Seth I do have a large variety of
projects but I thought out I thought I
started by talking about integrated
defense acquisition technology and
logistics lifestyle management april
fools so happy april fools day everybody
might what i thought i'd talk about is
just my current work so you could sort
of see what I'm working on which is nice
because then it gets sort of gets out of
the way and then I can talk about how I
led up to that I always hate waiting
till the end of a talk to see what
someone's working on now so and then I
thought I'd little talk a little bit
about my background it's a little bit
different than a traditional researcher
but I think that could be an advantage
here and I have to in-depth projects
where I'll talk a little bit more about
a full kind of spectrum analysis and the
process leading up to those projects
when is the mem table and the other is
something i call vision play which is
about using physical objects to control
digital characters with other people at
a distance and at the end i'd like to
just sort of touch on what what's next
for me in some of the areas that i think
would be great to grow so the
fundamental problem is i see it right
now in the current research I'm doing is
that we're separated we're in two
different when we're video conferencing
with each other in all these different
environments
he still have two windows you're not
really doing things from the same space
together and the other problem is that
children lose interest very quickly a
lot of Cory's research and research from
nokia has shown that especially when the
ages of like four to seven kids get
distracted easily by what's in their
environment and they hard times you know
knowing where the camera can see them
and maybe you've experienced this
yourself the Kinect and the we've really
brought families on their feet using
their bodies doing things together in
the same space and I find this really
powerful as a way of getting people
together and getting them also parents
involved in media new media experiences
so this is an artist named John clang
you may have seen some of his work and
these are just skype calls projected on
the wall right I think it points this
idea that we really want to be together
we want to be in the same space so so
what I've been working on where recently
is called was am this is six people
three in one space 3 and the other and
what is what Sam well what Sam is like
Skype plus connect plus your imagination
you take the Kinect camera right now and
you plug it into your PC plug the pc
into your TV and was am you're connected
to the other person so what really makes
the jam magical is that you can do
things in the same space together I'll
show you a little bit of footage from
the pilot study that I've done this is
too it's really rough footage but two
kids in two different spaces you need to
the air couple oh my gosh she was a dad
and a parent and two-time dad we give
them different faces a lot of goofiness
a lot of role-playing a lot of acting
things out you know this notion of like
pretending because it's not really the
real self but at the same time you can
do things you wouldn't normally doing
lunch the other person's the mother
daughter dancing is something that can
be really
you know fun to do together and I think
you've seen this with the Kinect camera
like some of those more popular games
are about imitation using your body and
interesting ways so so you know the next
thing I wanted to highlight is sort of
what is my design process and motivation
where do I come from for me interaction
design is really about people and I
always think about what it means to have
a face-to-face interaction with somebody
versus a mediated one so this is a piece
that I made it medium attic and afford a
hack and it's called staring contest and
I thought I'd highlighted as a way of
thinking about so what we did in this
project was to do blink detection
whoever blinks first loses and a seven
second video gets uploaded to a social
media second of their losing moment and
this is like super popular and also
hundreds of people talk to me about how
much they enjoyed like having this very
unmediated interaction with another
person where you're really staring into
their eyes and even though it's just a
provocation an art project to me as a
provocation to me it was a provocation
about HCI it's about what it means to
interact with each other can you have
technology facilitating that without
ruining the the feeling that you have
you know really making eye contact with
somebody else but this conversation
happens within a media ecology so I see
the the process of interaction design as
a systemic one we're really thinking
about information displays in people and
that we have a responsibility when we're
looking to 25 years ahead to think about
how we're going to interact with each
other and to identify question and
respond to technology trends that are
happening so these are inspiring people
who've talked a lot about how we
interact with objects and people and
I've worked a lot with sherry Turkle who
asked the question like does technology
serve our human purposes and this is
really what I ask myself all
time and it's why I'm interested in the
social aspects of our engagement
technology because I think to a certain
extent we can simulate our relationships
with each other or we can strengthen our
relationships with each other and in
this sort of transmedia environment
where people are participating in
multiple ways with media I think that
empowering them to be producers versus
consumers is another part of what
motivates me personally as a designer so
thinking about how we can strengthen our
social relationships and how we can be
more creative with media in a social way
if possible so scaffolding how children
learn socially but also how we interact
with each other when we're interacting
through a screen with each other so
typically the way that I I work is sort
of identify what my values are asked
really core questions about why I'm
creating something and then I like to go
through it more of an art based process
to your process where I sketch out
things role play them storyboard those
things outline develop test and revise
and the implementation the tech of the
technology I think for me a lot of times
it happens programming but really with
collaboration with other people so I
think it takes a vibrant community of
technologists to build things that are
meaningful to people not just one person
the the idea is like one percent of it
to me within such a complex ecosystem of
tools and methodologies it's really how
to understand that ecology and how to
collaborate with others that's important
to me so that's one of the reasons I'm
here is to find people really strong
people to collaborate with now looking
at my background you may ask like what
role do fine arts have an interaction
design what role would fine arts have at
MSR because I do have a background in
the fine arts coming into the lab so I
want to share that with you because I
think there is a thread it's important
and often unrecognized I started out by
making these really really large
projections of 1 inch square images in a
gallery space like the size of the wall
and there
to me they're just quite beautiful this
is a train texture these are pictures of
cement different pictures of rest and I
was really interested in the structure
of these things so i started making
algorithmic programs to try to simulate
this and exploring the sort of ephemeral
nature of those things the complexity
that you could get with the program i
started making prints and then printing
these things and selling them in
galleries for about a year and a half
but i did find that as you you know
learn to generate different algorithmic
forums they start becoming less and less
interesting because there's no social
component you're really operating within
the art economy which is more of a
commerce or i guess a way for people
have wine and cheese so i started
thinking much more about visualizing
something more social these plants are
part of a exploration called word garden
and word garden is a survey so it says
like mother father color sister brother
on the roots and then all the
association's people had are the sprouts
and they're organized by either negative
positive or neutral which people rated
after each association and the time that
they took to answer is the length and
the curliness of each of the plants so
looking at this one you can see the
person took a moderate amount of time to
answer and they answered in a variety of
ways mostly positive this person took a
little bit shorter except for the first
two may be the last one and answered
quickly as well this person was all
positive and answered very quickly so I
can see in this person took a really
long time was very thoughtful and had a
diversity of answers so you can begin to
see the character characteristics in the
plants of the people who are filling out
the survey and so using information
visualization as a way to kind of make
in our work and then share that with the
person who took the survey so each
person would get a print in the mail and
these things were all shown in a gallery
as well
thinking about this visualization of the
self became more and more interesting to
me so I started making portraits about
interactivity itself these portraits are
this was called stillness clock motion
clock so stillness clock would be this
clock it would tick when you would go
out when you're standing still in front
of interface and motion clock would move
when you're not actually paying
attention to it so you'd get something
like this is too sped up but what was
interesting about this was asking the
user to think about attention itself to
think about engagement and then the
interface is measuring that in two
different ways and what we got when we
showed this in six different locations
around the world we got all these
different portraits of people slit scan
portraits people interacting with the
system and this brings up this notion of
time so this is a picture that never
happened different times during a party
people came up to the camera took the
picture and then they were all
juxtaposed together I call this concept
choreographer and it's something that
I've been exploring in the media lab as
an art form the notion of remix in time
in some way so you're taking moments
from the past and mixing them with the
present using background subtraction
this is an exploration to kind of think
about this a provocation like of history
trails which eventually became an
installation in our lab so this is like
a slow glass kind of thing we're looking
down on the space you can see the
history of the space over time using
background subtraction in opencv so
throughout the day you could walk by
this monitor and glanced at it and you
begin to see different things that
happen in the space we also began to
explore time as a medium interactive
medium looking back in repeating time so
in this case you would see yourself at
10 seconds at 20 seconds at 40 seconds
in that kind of infinite loop and this
is an installation that we put in the
media lab sort of exploring this notion
of seeing not only yourself but other
people who've been in the space at a
time at the same time this is also
something i was talking to for you
earlier about this notion of the second
self what happens when you see yourself
repeated how does it change your
perception of yourself over time so a
lot of these portraits that I worked on
this is six years ago we're really about
seeing the self and seeing the self
overtime in relationship to other people
and I'm still exploring these ideas in
many ways still watching really was a
portrait of yourself that would trickle
in overtime so the longer you stayed in
front of it the more distinct your image
would be in a way this is like the
opposite of interactivity and I'd call
it a passively responsive interface and
so again these are provocations about
interactivity and they eventually led to
a project in 2007 that I worked on
called the meta dome meta dome is an
immersive space I know Andy's done a few
things in this area but it's an
inflatable dome with a spherical
projector in it and the goal of the
project for me was to use the universe
as a metaphor to draw people into
awareness of each other and themselves
and during an immersive cinematic
experience so people would go into the
dome for about four or five minutes and
they sit in these video chairs the
chairs would measure how much they were
moving and as a result the stars would
either come out of the sky and join them
or sort of stay in the sky depending on
how much how little or how much they
were moving eventually the stars would
migrate to your head in the space and
then join everybody else's at the apex
of the dome and the sound would go from
being a kind of static like
Shh to being more like something that
felt more like harmony or engender to
kind of we I worked with a sound artist
on it but engendered this feeling of
unity with others so and in part this
came out of the fact that in Chicago I
couldn't see the stars ninety percent of
the stars are occluded by this kind of
pink haze over the sky there and in part
was about thinking about how an
interface might engender social unity
and finally the last project just about
my background is I've done a lot of them
stuff with immersive projection in the
media lab so I built systems that create
really large projection with for
projectors thinking about how you blend
together different spaces and this is
really a platform for other people in
the lab to develop something so we made
sketches that work in openframeworks
processing ActionScript and what I was
interested in is what so what new social
possibilities exist between people when
they're in a space and what what what
new ways can people use their bodies to
interact with information what I learned
from this though is that in something
this large you really read it from
multiple spaces you read it from the
fifth floor the fourth floor the third
floor wherever you are in the space it
reads differently and so you have to
think about it in multiple levels
it has to be socially scalable but it
also has to be able to be viewed from
many different places I mean in a way
it's simple i'm just tracking people and
giving people that information about the
contours and the direction they're going
but a lot of people did magical stuff
with it in the lab and it's part of the
arts festival coming up so often in my
practice and institution I try to
provoke and think about artistic
possibilities as well as do more HCI
oriented research so now I'd like to
show you two projects that are more on
the HCI cycle or track the first one's
called the mem table and it was my
master's thesis at the Media Lab in 2009
so i spend about 10 or 15 minutes
talking about that what the mem table
was focused on it is again thinking
about the social interaction with each
other we're really thinking about how we
interact with each other in meetings and
in brainstorming and looking at how we
arrange spaces we use stuff right we use
large surfaces together to arrange
objects so I was thinking about this
when I was taking these pictures just
really looking at surveying how people
use spaces together I'm thinking about
how would an interactive table be in his
face like this one of the critiques that
I had a Microsoft Surface at least the
first one was that you couldn't put your
legs underneath Tina so I've seen a lot
of people using it in our space in
fairly awkward ways the display wasn't
really always integrated with the
objects on it we did use the surface a
lot to do prototypes I was also inspired
by a venerable Bush's original idea of
this sort of mimics table a table that
remembers a memory of what happens
inside it PR wellness work Rick moto
bill Buxton all of them about we're
about integrating the physical and
digital objects together and buren
Hartman's work here at this live I guess
it's not in the related work but I
corresponded a lot with yarn and other
researchers who had done was the four by
six table here
just thinking about how do you interact
on large surfaces together but still be
able to put your legs underneath have it
via an ergonomic experience so I began
as I began to think about it more and
more deeply we just tried to take a very
integrated approach at Chi in 2009 there
was this discussion about killer apps or
what was going to you know as
multi-touch to dry well and what I would
I my take on it was that the reason why
you didn't see a lot of large screens in
the workplace is because it didn't work
well for a number of reasons and so an
integrated approach was to try and try
and attack many of the different pain
points in terms of using tables together
and one of those is just being able to
work at it daily put it putting your
legs underneath so i worked with steel
case on this design and the primary part
of the design that's interesting is this
box in the middle which centers the
projectors and the cameras together so
that all the sensing can happen and you
can still put your legs underneath
because there's a border around the
table and that border supports the
objects and it's been it was in our lab
for about three years and what it does
is it saves the history of what you do
at in so i'll show you a little bit
about that so it not only did say the
history of what was happening in our lab
at a given time but we also did a lot of
user studies and so i'll show you a
little bit how it works when you touch
your face you get this menu that comes
up and you can fling the menu to to the
side kind of like a hockey puck and it
sticks to the edges and there's two
things that you can do you can either
take things out of the table from a
previous meeting or you can put things
into it so you have these two icons here
and then there's a heterogeneous set of
inputs that you can use so we try to
support as many different work styles as
possible and so let's say you start a
meeting and you want it to go back to
something that happened previously you
scan over the landmark events on the
timeline from a previous meeting and
then you could grab something from
within that widget and pull it into the
current meeting then it become part of
the current session
the next time you go back to that
meeting you would see that thing so
somebody could come in five minutes
early to a meeting and pull out a few
things just to remind you of what you
were doing the last time you met
together each of the keyboards is
associated with with the person based on
these menus and you could you could
enter things into the system that way
and then each of these entries would be
tagged so you could tag it manually or
you could tag it asynchronously offline
using google wave one interesting thing
we use is the anoto pens to synchronize
paper real time with a kind of virtual
notebook on the system so that way you
could take the paper with you but you'd
also have the digital version saved
there were overhead cameras to capture
objects and we eventually used IFI
cameras so that people could sort of
creatively take pictures anywhere around
the system and there were a lot of
features built into this I worked on it
for about a year and a half off and on
really trying to think about every was
really trying to make a system that
worked well and pretty seamlessly so we
had pc and mac ftp clients so you could
send a screen capture from your computer
to the system and in multiple desktops
and audio recording and a lot of it was
really about okay now what do we do if
we have a system where we can record all
these things i don't recommend virtual
keyboards that was just an experiment
and also if i'm developing on this thing
daily you know what utility could it
really serve in my life so the typical
scenario would be that we would meet
together after having a meeting with
physical prototypes and then we'd see
something about our last meeting there
so I bring a prototype to the table if
you sketched a little bit about it we
found that people did not use the audio
very much they would rather have the
audio and sync with another form of
input so if you touched like the sketch
you could hear what somebody said during
that time or you touch some other input
so so one of the things we did was
analyzed all these different forms of
feedback forms of entry into the system
so it's just giving you a sense of maybe
what a meeting would look like as it
built over time so the first two
components is to save a memory is an
interest really way to add utility to
make it ergonomic and the third thing
was to integrate it with an offline
review process where people could sit
tag so then you could search either at
the table or offline using google wave
so we integrated this with google wave i
worked with some great undergraduates at
MIT to do that and i think this there's
a lot of people people tend to make
decisions not during meetings but
asynchronously at and their desk or when
they're reflecting so into this
integration was really about engendering
that reflection process for people there
were a lot of different types of input
and output and integration in this
project but what did we learn from it so
we did a study where we compared people
using the table just with objects but
the table is completely off so they're
in the same environment but without any
of the capabilities of the table and
then we did studies with people using
the table at three of the group's use
the table on through the group's did not
in the study there's a paper base versus
an on paper based groups so you can see
the study here
but it would look what one of the groups
look like and one of the things I
noticed is that the table actually kind
of creates this formal space that you
really have to navigate a lot because
it's the the systems on but it also like
it puts you in the table itself is very
formal in some sense so it it really
made people remember more just because
when they were using the system I think
because of having the menus in their
seats and I'm watching what was entered
into the system what we found was that
people did not remember more accurately
but they remembered in greater detail
and with more rich in a richness when
they had the digital component as well
as the physical so just give you a sense
of overtime how these different meetings
would occur and subsequently I started
thinking about what could really work in
a workplace and why haven't we seen
these things and I have a few ideas
about how people use spaces i think that
integrating to vertical displays on each
corner would allow you to present when
you want to present and then the table
itself could be a sharing space where
you deposit things into the memory of
the system but you can also share assets
with each other across the table one of
the problems for for doing research in
the space is that in order to set up the
system there's so much work you know in
terms of keeping track of the memory and
making sure that people are enrolled in
the system you know you can get way deep
into just the temporal aspects of how
people meet together and you know it was
a new space for me and I was doing this
but we published a paper at Chi and it
was really focused on thinking about an
integrated approach and how do people
really you know use this within our lab
well I think they used it in in playful
ways and that's what I really liked to
see it became a kind of place for people
to leave message
for each other it became a space for
people to to gather when you know is one
of the few meeting tables that was
always open and on because it was a demo
so this is kind of how I would conceive
of like a much better version of this ad
remote capability and add two displays
on either corner in some way so you can
present but you can also incorporate
remote groups in some interesting way so
looking at the future of the space I
think something that might really work
will incorporate those aspects okay so
so this is the second project and its
really a series of projects that have
led up to the current research that I'm
doing isn't even seen ceptable zorno
about suitable I guess so so I worked
with David Maryland and office for two
years and what I was interested in with
suitable is making applications for
children because they have this
intuitive kids know how to use blogs but
they don't have necessarily I they
haven't used a mouse and a keyboard as
much so so I began working on an
application that connects the syph
tables to a larger screen called tell a
story like te le story and the idea was
that if you held up the Sun it would
become daytime if you held the moon it
become night time you change the
environmental parameters if he showed
the screen that the tractor and the
tractor would come in what I noticed and
you may notice this about this
particular child was that they would
show the screen something as if the
screen could see it you know this is
really a nice takeaway for me just on a
from an intuitive design standpoint this
notion that we want objects to
communicate with each other and so we
kind of signal to those object or those
kids think that the TV can see it so
we're working on TVs that can see us and
and so I started outlining what I call
vision play framework
and this is partly because I was working
for Hasbro at the time during the
summers and Hasbro was sponsoring my
research that might put it into
perspective why I'm so interested in
objects and puppetry and expression but
what can you do what are the playful
things you can do with computer vision
and how why is that interesting so
puppetry is one just real-time animation
is another way of talking about it
remote playing two people playing with
objects at a distance and then using
that to create content and mixed reality
scenarios where you see yourself in the
story so I'll show you I'll try and show
you examples of each of those but what
inspires me are components of creativity
so transformation social play
interactivity gaining ownership through
creating something storytelling and
fantasy when we interact together and we
engage in some way that transforms us or
engages us with each other or brings it
new gives us ownership of the content I
think then it becomes magical in some
ways and so imagine you know you don't
make your own drawing or kid makes their
own drawing and then they hold it up to
the screen and that's what appears on
the screen and they make an object or
they have their favorite toy and they
hold that up and it appears sorry and
then they call a friend and then that
friend holds their object up and that
appears on the screen so this is kind of
my dream is that people will start
making animations at a distance with
each other in many different ways and
I've been exploring how you would go
about doing that so the first way I
export it was pre connect this is like a
floating green screen concept I guess
it's a glove with a character in it and
then as you move the character up it
gets smaller towards the horizon line
and as you move it down it gets more in
the foreground so there's this loose 2.5
g mapping to the world the cool thing
about it you know the real-time
segmentation is that you can put any
object in there you can put an owl or
your hand or and puppets are especially
expressive in terms of objects so
so Hasbro was interested in my little
pony assets from their TV show running
up and playing with my little pony when
you hold up my little pony I think
that's very interesting as well that's
probably why they would take it but they
were also interested in action figures
so I started working with the puppeteer
and what makes puppetry interesting to
me is really the form of the character
is very similar to what you're
controlling on the screen so with a
Playstation when you press a key and
that makes the character jump it's not
the same as making the character jump
with your hands so I was interested in
this scenario where I would be holding a
puppet and you would be holding a puppet
I'd be controlling the samurai you're
controlling the dragon and we're playing
together in at a distance and how could
you accomplish this I tried a number of
different scenarios I tried using
markers I mean some of you've worked
with Rory I guess who's here using shape
description and ended up creating a
kinetic model in box2d a physics program
that could loosely correlate to the
physical model on the top left there
this is when it was so i was still
debugging it but eventually it started
to look more like this or you could just
hold a character up and then 30 frames a
second the the sort of costume version
of the character on the screen would
react the difference here between this
and the previous approach with the
floating green screen is that it can
interact with objects in the scene and
it can also have behaviors of its own so
there's a much looser correlation
between what you're doing and what you
see and the digital character limitation
is that you can't hold up multiple
objects right unless the system somehow
figures out what it is you're holding or
what the properties are that that action
figure are this is sort of how I would
costume it using Photoshop mostly with
alpha pngs so we did some pilot studies
with kids and
what we found is that children have
difficulty with puppets that have more
than three sticks two sticks is sort of
more much more ideal and there but
they're extremely interested in
controlling things on the screen and
also just discovering what the
affordances of those things are so
figuring out that that relationship
between the object and the thing on the
screen and the more closely correlated
it is the more expressive it is the more
interesting the engagement between the
characters but they have trouble seeing
where the camera is so one of the things
I've done is to build a stage that kind
of tells you where the camera is and try
to even put glass there so that you
don't go too far forward where the
camera can't see you anymore so once you
get over the novelty of something like
this what can you do with it it's a
difficult space to parse I've also tried
for a Hasbro again putting your face
into the story using hard classifiers so
you can kind of control your own
doppelganger I guess and and this is
really tricky because when you're trying
to do faces and move the character
around at the same time it's your mind
gets split into two different directions
so my takeaway from this is that it
might be better to record these things
in two different tracks or have somebody
else control your puppet while you do
the faces at a distance so a future area
I'd like to explore I'm going to skip
over some of the stuff but I've done a
lot of green screen theatres at Harvard
in a puppetry course thinking about how
can we be expressive real-time how can
we make real-time animations with
different objects and more flexible ways
learning things from the film industry
in a way about doing stuff quickly so I
still remember what it's like to be a 13
year old boy I don't know how many of
you do but I try to utilize that as a as
a I pushed that with my research so
yeah so I've done performances as Steve
Mobbs the muck from the Muppets and in
those performances the objects the toys
are advocating to be a part of the
digital experience again because they've
been left out so so you set up a little
stage of toys and then they're all
protesting and and he's speaking so is
it really doing the Occupy movement
thinking about how toys might become
part of our digital experience
eventually this led to what I'm doing
now because I was trying to link real
time segments segmented puppets together
but i ended up enabling more composite
environment for people and patty is very
good my advisor it helping me make
things more generalizable to our
sponsors not everybody's interested in
real-time animation or expression and so
I've ended up turning this into a much
more general platform and working on it
for about nine months now and it's been
I think to date one of the more
successful projects just to look at some
of the related work that inspires
telepresence these kinds of telepresence
systems many of you know Myron Krueger I
guess sort of legendary and some some
circles a nineteen eighty 1975 he was
working on systems like this and his
original vision was this notion of an
artificial reality where we would see
these versions of each other in virtual
space interacting and overlapping and
transforming in magical ways I found a
lot of inspiration from this work that
explored four different ways that
children could interact together and all
the different affordances that come from
from those different modalities and to
me it speaks to this idea there's a
really rich space of mixed reality
experiences that can connect children
and parents and children and children to
each other so this is a really
informative work for me and also Nokia's
work on storytelling at a distance
and Sean's a really good friend of mine
when he started collaborating with Nokia
I think they're doing a start-up based
around this concept now which is a
really interesting to see and I I'd love
to follow that work but the concept is
to see yourself and the other person in
the story during bedtime experience
experiences with children and you know
there have been compositing systems
prior to what I'm doing I think what
makes you I'll talk a little bit but
about what's new about what I'm doing
compared to these previous compositing
systems so there's one been one from our
lab if Stefan like a malice from 1997
and then there spend a lot of green
screening base systems for people to do
things together and shared environments
I think this one's called hyper mirror
BTW has worked a lot in this face is too
they have a initiative in 18 million
dollar european initiative on ticket you
know it called V connect which is about
engendering this feeling of being
together in spaces and i invited BTW to
the workshop is happening at chi so
they'll be there and we'll be able to
engage more with them on this but i'm
really interested in what researchers
out there are thinking about shared
experiences in composite video
environments and roy ascot and paul
sermon have also been working for 20
years and telematic art experiences that
happen in these sort of crazy
blue-screen sets where you can you can
think about how a narrative would take
place through real-time acting with
others at a distance so what we've built
so far this is in one space and that's
in the other is you know a client that
transfers the image real-time in the
depth image and then allows them to
composite in different ways so i can
either go to your space or you can go to
myspace or we can create a fantastic
background and one of the things i did
is to overlap the images to you know in
opencv so that you can become i can
make my body yours or you can make your
body mind and you can kind of build
these sets so the sets are layered PNG
files that are organizing the z space
and you can place them where you want to
and what I'm working on right now is a
set builder for parents and children so
they can design their own sets together
and then go in and then use them
together and so we're doing a study
where over a three-week period we start
by introducing introducing the system so
they can get over the novelty of it so
they can try it out together and once
they get used to it we will introduce
them to the scene maker and so the
parent will fill the will teach the
children how to make this scenes first a
fairly simple layout program and then
the children will teach the parents and
they'll work together to make
environments and we want to study how
they use those environments over time so
in subsequently two or three more
sessions do those environments take on
more significance the system already has
a lot of interesting things like you can
move characters people around as you can
transform their size a lot of things
inspired by my room kruger and there's a
the technical implementation i'll skip
over but we're working on the foreground
protocol the compositing techniques the
2.5 decent renderer you know i've been
writing all this all this code mostly in
c++ opencv to try and build the system
because i really imagine that people you
know especially parents and children i
would love to see them interacting like
this in their homes right now it's only
working in the laboratory so puppetry
comes back into this as a way of getting
of experimenting with how kids tell
stories at a distance so we make puppets
I do these workshops at Hartford in
Hartford with kids where we make puppets
and then we use them with the system as
well and it's actually the most
effective way of using puppets with the
system is just to set the near threshold
at a certain level so there's like an
invisible screen you place it in and out
of the screen and you can you know where
the care
is it's very intuitive you can learn it
in like a few seconds we tried tracking
the left in the right hand that was sort
of too much I think in terms of you have
to calibrate first and then sometimes it
would lose the hand and then the puppet
would disappear so that seems to be the
most reliable way of exploring acting
out different historical narratives and
things like that so just a little bit
about what my user study coming up next
week is and then so I'd like to study
what a couple things one traditional
versus composited environments so given
a choice between a traditional
face-to-face sort of thing and this
merge environment which one will parents
and children choose what types of
activities do you do in this environment
you know what kinds of free play how
does the engagement very compared to
just a regular video conferencing
session and what's the best means of
customization of the environment is it
the offline scene creator or is it
better to sort of stamp things in real
time from your environment so I'm going
to try to add these features and what
type of environment is best for the
parents and children you know is it the
fantastic background is at me joining
your space and you joining mine or is it
a custom space that you've made yourself
social dynamics or something that I'm
really interested in so we have some
metrics to rate attention and engagement
and then ownership as well does
customization give you a feeling of
wanting to go back to the space if
you've helped create it with the with
the other parent especially over
multiple sessions and then within with
Sam a lot of the things I talked about
earlier transformation the magical
things that they enable you to fantasize
and story tell and improvise with each
other how effective are those and
in terms of in you know when you're
measuring engagement and getting parents
and children to play together so I
definitely adding custom content is
something that I'm working on using
physical objects sort of like IO brush
in our lab where you hold the objects up
to the screen and they get they appear
or you can place them behind things by
moving them through the dub space and
then also thinking about how to map
different gestures to things like I'm
flying or make me smaller or make me
bigger like these are things that that
were working on now with some machine
learning and he probably won't get to
this in the thesis but I would love to
have it so that you could sort of see
different tracks that you've recorded
with the other person and decide whether
to keep those tracks or not using
gestures simple drag-and-drop sort of
thing okay so last two or three minutes
I just want to touch on what would I
want to do next or what are the broad
areas that I'm interested in the first
one is creative telepresence systems so
how can broad in a variety of audiences
really have shared experiences of
distance that's really what drew me to
come here because I like what Corey's
doing in her group and I'd love to work
in some capacity collaborating on that
so I've been working with some improv
artists to make some sketches of the
different types of activities that
people would do so acting things out
within our system to kind of create a
remote play together is one thing you
can do giving a guitar lesson it's a
shared experience that you can't do in
skype but you can do in our environment
co broadcasting together is something I
think could be quite compelling where
two people are you know sort of relating
to media and then rebroadcasting that
out to meet to to youtube and even like
asking a roommate if they want to come
live with you and maybe they don't do
they do but you can sort of get a sense
of their place so these kinds of even
negotiation seem fairly interesting I'm
also interested in New
depth sensors that are coming out that
might enable real-time animation and so
I've been playing a lot with the leap
sensor and trying to map these popsicle
sticks and felt pieces to different
birds animals mapping out how different
animals move and then thinking about how
we can control those animals in 3d space
not just so you trigger different
pre-rendered animations but so you
actually could tie into the skeleton of
the animal and you know have in a
physics world like the previous
explorations but more in 3d space it's a
difficult area because the physics
worlds and 3 3d creatures need to have
some behaviors but you also want to so
this is I think a really fascinating
area and one in which sensors will
enable new forms of creative expression
intel has a new camera at the time of
light camera has anybody seen this in
the perceptual computing group yeah so I
was just at it until last week and it's
amazing it's a really really high
definition beautiful camera and they're
trying to think about different uses for
it and so I've been signed up for the
SDK of this and I'm really interested in
using doing more stuff close to the
screen especially i did this since if we
have this thing built into the lid
that's what they're planning to do is
have it built into the lid and release
it in the next year or two so you start
to see laptops that have these def
capability based on stereoscopic
time-of-flight cameras and the third
thing is augmented play experiences in
general so you've seen a lot of my work
and maybe you get you get a sense of
what i mean by that we have a tumblr AR
play tumblr com if anybody wants to
follow it i'd love to it's where I keep
all my cool videos if you're always if
you're always looking for a new
researcher cool stuff please follow it
and we can discuss new videos together
and then you can of course find my work
at perspective calm so thanks so much
for your time and appreciate you coming
questions hey Jay at the end it seemed
like we were mostly talking about
parents and children is that yes it sort
of children and children or how do you
think about those groups differently
well I started thinking more about
parents and children because i saw the
imaginative play and the shared
experience is a way to kind of bridge
the differences between how parents and
children see the world and how they play
so if you imagine children more let you
know Allison got nibs idea that children
are like lanterns and they they take an
input from everywhere and parents are
more like very focused on one thing or
another the environment that i meant i
think it creates an imaginary context
for both people were willing to act out
something that normally wouldn't so I
saw it as being most beneficiary to to
that age group their children and
children when I interviewed the children
during the pilot study they said that
they want to play it with their friends
for sure their best friend usually they
would want to play it with when they
weren't in the same space together but
patty is also interested in I guess how
it'll be how our sponsors will respond
to the project and so I think it has a
lot of Appeal for us to to talk about if
you're on a business trip how you might
be able to connect you know if do from
divorced families it just seems like the
area that where there's the most need
and so that's why I've been focused on
that yeah one thing I like about your
double connecting the Philippines and so
forth is that it feels like you're not
really gunning for photorealism yeah all
the time I think that
well I was wondering if you could
speculate in sort of where that's going
to go you think that there's going to be
a place for this or the non-government
listening what's it going to look like
what's the new aesthetic of depth camera
imagery it's interesting because I
visited Cisco and polycom and I'm like
hey would you guys use this kind of a
system within your business model and
they're like no we only do business to
business like you know just critical
decision making get as realistic as you
can to face to face and then you know
thinking about you guys for doing more
consumer to consumer I feel like there
if you're with somebody that you're more
intimate with and you you feel
comfortable imagining as soon as you
cross that threshold between it needs to
be real and it can be pretend and all of
a sudden it opens up a whole new space
and that's the space that I'm interested
in is like when you're pretending
together what kinds of things will you
create you know what kind of you because
every I feel like I mentioned this
earlier I feel like every time we engage
in some sort of mediated interaction
together there is a bit of performance
happening you know you kind of arrange
yourself so you're in front of the
camera you know if you're if you're
doing a Kinect game there it's a bit of
a performance in response to stimuli and
feedback so I'm sort of interested in
crossing that line from gaming more
towards building our own worlds together
so where I see it going is more a
community of people who make these sets
together and they share them online and
they start to to be building their own
worlds like minecraft where you know if
you look at the gaming world like World
of Warcraft in Minecraft all these
people are building their own worlds and
they're so into it I can imagine people
doing that having if there's a lower
threshold to parents and children and
people who would normally skype having a
shared activity they can start building
their own worlds and sharing them with
each other and you'd start to see like
kids more creatively engaged when
they're at a distance so does that sort
of hint it where you're going or do you
mean more abstractly like
you're banking on sort of being an
emergent property of giving these tools
to other people and sort of see what
happens yeah so that's what I'm really
interested in is like if I give this to
parents and children what kinds of stuff
will they make it you know will they
really get into it or would they prefer
to have this kind of face-to-face
engagement I would think that they would
switch between it you know depending on
the context of what they're doing if
they want to you know go to into a
virtual space where they can see all the
pictures that they've shared with each
other over the last year or two that
would be I think are really interesting
immersive space because you could sort
of pin them on the your virtual space
and you know if you're look if you're
talking about more abstract data sets
like and that's work you know in the
space that many of us work in is a
simulated space so how do you discuss
that space with others at a distance if
you sort of enter that space together
then you can point to different things
and manipulate different things in the
space so I guess what I'm seeing is that
we are we are there's this merger
between the real and the virtual and
that merger is happening in many
different ways information is coming
into the world and the more augmented
reality space but in the augmented
virtuality space we can also bring our
world into the virtual so it's a
continual conversation where I think
there's these sub domains that are going
to be really interesting to explore one
of them being the more imaginary
possibilities but I think a lot of it
will depend on you know the social the
social relationships of the group that
you're engaging in so like I don't think
it would be appropriate for me to use
with zan with you guys necessarily it
might be fun as a demo but you know
definitely with my cousins and and with
my family so it really for me it's about
situating it within the social spectrum
and some yeah I can at least I par de
jour
you mentioned a little bit about about
the metrics good that you are using and
of course interviews and lots of
do you have any way but how do you think
about measuring things like measuring
things like the engagement with each
other the engagement when you add in you
have the picture of the tree branch
holding up what you can't real objects
or when you add in virtual objects or
because there is there a metric for like
that using your imagination to submit
disbelief like how I don't have you how
do you gauge yeah things well I mean the
way we're planning on measuring it is to
have two monitors one in each room and
those monitors have like a standard one
to seven scale but we have I guess seven
things that we're looking at so one is
like how much are they coordinating with
each other how much pretending is there
how much role playing is there how when
do they add things from the digital
world and when do they add them from the
physical world in a way that's when we
have assessing the features but also you
know so we also are going to interview
people but after the the three studies
not during up during them so it's really
observing what they're doing and trying
to observe it in a in a fairly
structured way and I've used papers from
actually from Lana yash to think about
what engagement is and so yeah I really
turn to to actually your group in
nokia's group to understand how to
assess these metrics tonight and I
usually try to also email somebody
outside of myself who's had more
experience Lana and I and Eric wrote the
survey of the values and motivation and
values that people have for the
interaction design for children
conference so last year we presented
that paper and it's surveys using
grounded research all the papers from
from the nine years to try and
understand what people's motivations are
and and how they do assessment what
theory informs their research so I've
tried to think more deeply about this
and I and also Mitch Resnick is one of
the people who is advising the thesis so
he's been
let me come up with some of these
metrics as well I know that when I
present it's like very visual and it's I
think that's partly because of my art
background but also that for me i want
to make the presentation like engaging
for people so they don't fall asleep but
they're also you know I appreciate the
depth that NHC I approach has to really
you know helping you grow as a as an
interface designer which is how I think
of myself you know mm-hmm you said your
stuff is very visual have you thought
that all we're playing with other
modalities to increase this yeah yeah so
I think sound is one that I've used a
lot I didn't show any of the work but on
my website there's a lot of work about
what I call sound forms there are
different objects that would have
different sound properties and depending
on how you lay them out and relationship
to each other you generate different
compositions and this is using microsoft
surface because you could get really
nice data about the shape of objects
from surface and so that was used in
more art therapy type of sessions for
children who are interested in learning
musical concepts but I am interested in
sound and I love collaborating with
sound artist or sound researchers I
haven't done anything with you know
localized sound or anything in in
telepresence systems but I've spoken a
lot with Cisco and polycom and visited
them ins and sort of learned more about
how they approach that to create sort of
a spatial sense of where people are
who's talking when so I do follow the
research in that area and I'm very
interested in and it's just a difficult
space to work in
ok
or the end of your presentation who had
two people in related
screen yeah would there be application
of projecting out out into a larger
space we have more as little
collaboration
two people in different areas of the
world yeah
dunning experimentation
multiple people in such a large
experiences
the inner setting hmm in
there's I think there are some people
have expanded with this i'm not sure
without a distance but there's been a
lot of people doing like using the
contours to generate graphics or to sort
of create an immersive theater
experience where there is digital
content that's mixed with real-time
performance and those are really
inspiring to me but one of the I think
interesting things about awareness
interfaces is it like you know I guess
you guys have a new Microsoft Research
New York like if you could connect these
two spaces together in a public
installation that was in the same like
in a central place in both buildings I
think it'd be interesting to see this
sort of time-based you know to
experiment with how you could make that
work because people wouldn't always be
standing at the same time in front of
each other but maybe you could build
something that would asynchronously mix
them together so so I really think I
think it is a very interesting space I
just not working in that space currently
but taking it to a larger scale probably
one of the things you're thinking is
like oh there's such a broad spectrum of
projects you know I think that's partly
the fact that at the media that we have
a lot of Liberty to experiment and for
me coming from an arts background it was
a place for me to gain technical
competency but also try things that I
hadn't tried before so I used it as a
test bed for a lot of the mixed reality
concepts that I was interested in would
like to chat further with Seth just
reach out to me kri my alias
yeah okay thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>