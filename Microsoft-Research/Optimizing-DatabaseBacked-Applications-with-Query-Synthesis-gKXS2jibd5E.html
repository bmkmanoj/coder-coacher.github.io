<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Optimizing Database-Backed Applications with Query Synthesis | Coder Coacher - Coaching Coders</title><meta content="Optimizing Database-Backed Applications with Query Synthesis - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Optimizing Database-Backed Applications with Query Synthesis</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gKXS2jibd5E" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
he'll Bernstein it's a pleasure to be
introducing Alvin shown today Alvin is
nearly done with a PhD at MIT and
working on problems related to both
databases and program analysis and
program synthesis at least part of the
work he's describing here was the
subject of a paper that got the best
paper award at the conference on
innovative database research cider in
January this year arm and he's the
winner of multiple fellowships
competitive fellowships NSF until a
national defense science and engineering
which is actually something like that
was actually a very competitive program
run by DoD I think they just total of
under 200 fellowships that are awarded
to in all in all science and engineering
fields um and Allen Alvin be spending
the day talking to a number of you if
you're not on the schedule and you want
to be let me know maybe we can W up with
one of the other one of the other
meetings or talked to him briefly at the
end of the day I'm fat let me give the
microphone to Alvin great thanks a lot
so um yeah so I'm alfin I am I guess I
III guess by now line ends year grad
student MIT oh and it's basically like a
number that I try not to remember I
guess the proper term they call it a
tenured grad student I'll let you figure
out what that really means 10 n plus 1
is what you get
yeah I hope like the count would
basically stopped counting her grandpa
fan plus one way so yes if it thanks a
lot for the invitation today so actually
originally I was supposed to give I was
thinking of giving like a 30 minute talk
of some of the work that we just
presented at a pldi this past week but
since phil was kind enough to actually
give me an hour slot so i decide to
change the topic a little bit to talk
about a broader piece of work that we
have been working up with multiple
people that have the pleasure of being
involved with so the general setting is
that we're basically trying to you know
use various program analysis techniques
to speed up applications that uses a
persistence data persistence data
storage and this is joint work with a
bunch of folks at MIT and also cornell
so to begin i'm just trying to let's
just first review a little bit about
like how these applications tend to be
written so in the original case we have
two servers one hosting a database in
this case maybe sequel and another one
that is hosting the application server
so these two machines tend to be
different physical machines although
they tend to reside in the same machine
room for that matter so these
applications tend to be written using
first of all a high-level imperative
logic I mean programming language if you
will a general-purpose one for instance
Java or Python and embedded within these
applications will be sequel queries that
gets executed on the database during
application when the application runs so
but at some point in time people figure
out like one way to speed things up is
perhaps to carve out part of the
application logic into what is known as
storage procedures I'm sure all of you
in the audience are familiar with that
concept so there's something wrong with
this picture unfortunately it was the
first of all the developer needs to
commit to either a sequel or imperative
code during development time not to
mention that it also has to learn like
what PL sequel and all that stuff is all
about and as you can imagine getting
that wrong and have a drastic
performance impact and on the other hand
they also need to worry up
about how or where is the application
going to be executed you know as I've
shown you know putting things on to the
database server has stored procedures
will make the application run as at
least the half of it that is in store
procedure representation to be on the
database and everything else will be on
the app server so being able to come
make these two choices tends to be a
little bit difficult at least during
development time because you know things
can change things can either both in
terms of the application logic and also
the state of the database and making
these decisions tend to be difficult so
in this respect we try to use program
analysis to help us solve these problems
so with that in mind we start a new
project called status quo funky name I
guess which is some programming
framework with two very simple tenants
in mind so first of all we want to be
able to allow the developers to express
application logic in whatever way that
they are interested or comfortable with
and with that regard we think that it
should be the compiler or the runtimes
job to figure out the most efficient
implementation of a piece of application
logic so notice that we're not coming up
with some new programming paradigm of
new program language and ask people to
please convert all your legacy
applications into that so on the
contrary we're basically saying that you
should be able to write whatever you
will and you'll be lazy you know just do
whatever you want and then we will
basically do order or the difficult
lifting for you so but so kind of as a
first step to achieve this vision we
have developed two key technologies so
first we have a piece of tool that will
automatically inverse equal queries from
imperative code and secondly we also
have a piece of technology that will
automatically migrate computation
between the two servers for optimal
performance and I'm going to talk a
little bit about these two these two
piece these two pieces in the net in
this talk today so first of all let's
just look at the first the first piece
of technology here which is we trying to
convert things from imperative college
of queries how does this work also hear
what have shown you is a piece of code
snippet from a real world open source
application that uses some
sort of ORM or object relational mapping
library for a persistent story
persistent data manipulation so in this
case what we have what we have here is
that this person you know uses a
third-party library which basically
abstract out all these things about
users and bros and then he's basically
calling these functions to return a list
of users and rose from some some place
and then he's he then goes on in the
nested loop fashion to filter out the
ones that he's interested in and finally
returning it at the end right so not so
unfortunately what he didn't know about
is the fact that these two functions in
the beginning when executed they're
actually issuing sequel queries against
the database in order to get get back to
list up which sucks that he's he that he
ended up a looping and looping across
and so what happens during execution is
that when the outer loop is encountered
the third party library in this case the
RM library is going to issue a select
start query because that's what you know
this this particular code snippet is
trying to do and likewise when the inner
loop is encountered now its database
people when we look at this we basically
say well I mean this sounds this looks
very much like a relational joint right
so in order to speed things up one thing
that you might want to do is to just
convert this entire code snippet into a
very simple join query that basically
folks in this predicate into the query
itself so the benefit is obvious right
because when we execute these two to
select our queries when the database get
large the application can slow down
substantially right whereas if we try to
write it as a simple query for instance
in this case we ended up having orders
of magnitude performance difference so
I'll go in this case is to basically try
to do this conversion from here to here
automatically so at this point you
should probably be you know calling me
out and say you know there's not just no
way you can possibly do this I mean look
at this thing is like in a declarative
sequel language this thing is in
imperative Java you know look at the
differences between these two is this
pretty restrained dramatic right so how
can we actually pull this off well so
to recap what we're trying to do here
formally speaking is to find a variable
in this case of results we caught in an
output variable and our goal is to
basically try to rewrite this into a
sequel expression and we are going to
basically do this using a tool that we
just build call query by synthesis or
QBs for short so you know this too it
does 3 sims 3 things right so first of
all we try to identify the potential
code fragments that we can possibly
convert into sequel queries and secondly
for all these what we were I was
referring to as output variables we find
try to find secure expressions for them
that we can convert them into and
finally being a you know good
programming language you know first and
I would try to know we should try to at
least show that like whatever secret
expressions that we ended up finding
better you know just preserve the
original semantics of the program and if
that works then we'll go ahead and
convert the code right so what do I mean
by you know try to prove you know these
things preserve semantics um it gets in
a little bit of background in terms of
program verification but if I do that
can I get a show of hands like how many
of you are already familiar with poor
logic program style no verification okay
well okay Alec yeah it was really fun
object-oriented programming languages in
chat rooms and how do you take that it
goes
oq economy seems I love the problem with
comedy yeah but except that in this case
from the from the users point of view
he's not sure what's really going on in
here right so it doesn't know that's
what the actual code end up doing or the
underlying implementation of the library
so this is for modularity reasons right
so the guy who wrote this code might not
be the person who developed these
libraries and when you know someone who
wrote these libraries he cannot possibly
imagine how the result said that he
actually ended up returning will get
used so in that respect we're basically
so you can imagine with these guys can
be met can be implemented using some so
okay well for instance but then from
that respect we still need to somehow be
able to fold all these things into the
object query language itself in order to
get the performance otherwise all we
ended up doing is just you know fetching
everything or database and then doing
the nested loop so that's not so
efficient as you can imagine okay so
just a little bit of background and
program verification so we in this case
we use for logic so which basically
comes in this form right so this is a
standard way of presenting this so we
have some sort of command that we want
to try to try to try to prove in terms
of a state transformation so we have a
precondition that we know is true before
this command was executed and then we
have some post conditions that we're
trying to enforce after the command is
executed in terms of changing program
state so as an example imagine we're
trying we have a statement that in your
simple assignment and then we want to
show that no x is less than 10
afterwards so we can go backwards in
terms of figuring out what must be true
before this statement is executed in
order to allow us to say that x is less
than 10 outdoors right so of course in
this case would better be the case that
a is less than 10 so a more complicated
example what if we have a if then else
statement in this case so let's say we
are also trying to enforce you somehow
we are asserting the fact that X is also
less than 10 afterwards so what what
needs to be true before this whole
statement gets executed well in this
case it better be the case that if B is
true meaning that we do get into the if
if the if clause it better be the case
that a was is
less than 10 or the fact that if B is
not true meaning that will go to the
else branch see in this case it's less
than 10 so there's a very routine
automatic process of coming up with what
is known as a verification condition
given a post condition that we're trying
to enforce ok so for loops a little bit
tricky so in so let's say in this case
we want to enforce the fact that you
know we want to show that somehow in
this case sum is equal to 10 I mean we
all know of course this is true so but
what is the kind of condition or
verification condition that we need in
order to establish that fact in from the
beginning of the program we also
involves this magic thing called a loop
invariant which of course as we all know
means something that is true during the
execution of the loop so in this case
suppose someone match that has come up
with you know this invariant ssome is
always less than or equal to 0 during
the loop so we need it with that in mind
we need to be able to establish three
facts about this program so first of all
we need to be able to show that this
invariant is true when the loop was
first entered in this case it is because
we know that some was set to 0 and that
course implies that you know is less
than equal to 10 so we also need to show
that this invariant is preserved meaning
that if we actually go into the loop and
we go through one iteration the
invariant better be preserved meaning
that it still remains true right so in
this case we have if sum is less than 10
and the fact that new this is the
invariant it better implies the variant
back so in this case is also reveal so
it checks and finally we want to show
that if this loop we've ever get out of
this loop then the postcondition
whatever that we are trying to prove is
all is we can establish that fact given
the invariant so in this case we want to
basically show that if sum is greater
than greater way than or equal to zero
meaning that we break out the loop and
given the look invariant we have sum is
equal to 10 which is the post condition
that we're trying to establish so this
case you can also see that this kind of
also checks out because right i mean
basically comes up with the the only
reads the only parts the only
possibility is SL miss equal to 10 ok so
this is just a very tiny very very short
introduction to program verification
then what does that have to do with us
right well so if you look back into this
example here
what we are trying to establish as I was
talking earlier in terms of these output
variable it's the fact that this results
variable better be equal to some sicko
expression right so this sequel
expression is precisely the post
condition that we're looking for except
that and and as I have shown you earlier
in terms of loops what we need to do in
order to establish this post condition
is the fact that we need some invariants
for these loops okay I'm in this case we
have two loops so with the barely two
different invariance so and given all
that we can automatically generate all
these verification conditions like the
ones that have just shown you in the
earliest life yes question seems like
you should also make some assumptions
that like no other module is monitoring
the database in fact right because
in principle I can imagine that someone
else is modifying the users and then
just some hope on to this program like
some other signal which is why we can't
rewrite this as a joint because that
would be complicated exactly what kind
of puzzle so in this case so for many of
these terrified libraries they can take
they can mark things as transactional
which is what happens in this case I
mean this whole thing is basically
sitting in a transaction yeah so getting
back to this so basically what we ended
up doing is we can now you can basically
see that we can automatically compute
these sort of verification conditions
that help us establish the fact that we
soaked equals to some post condition
except that there's one problem in this
case right so I I haven't really told
you what are all these invariants and
what are all these post conditions I
mean these are things that we're trying
to look for right and at this point we
don't really know well but as you know
good computer scientist what do we do
right we're just those abstractions or a
problem and somehow we'll go wait right
so what happens in this case is we just
say at this point that these guys are
just some function calls we don't know
what the body of these function calls
are but we just say okay here are some
you know some invariant function that is
a function of everything all the
variables are currently in scope and
then we'll just leave it out for now and
see what happens up later on right yes
question
so I will find this this output
variables i think that's a pretty tough
problem because as soon as you have
something like a sieve and point little
stuff finder
I imagined that this is nearly
impossible
so we actually run a bunch of analysis
to figure out that and I have to slide
to talk about that so hold on to your
question I don't understand I real I
don't answer that again please come
flying right yeah so that's a very good
point so how do we actually figure out
like what are the things that we can
possibly translate right so we'll get to
that in a second okay so so I was
talking about okay so we basically treat
these guys as some function calls that
we don't know how to how to express
right but before I talk about like how
do we actually generate the bodies of
these functions we first need to
understand that all these things I
actually written in some language that
is used to express these kind of logical
expressions right because you see
there's lump sum and things of
implication thing so we need to be able
to have some sort of language for us to
represent all these verification
conditions I mean notice that these are
not this is not like Java it is not like
the original program this is really a
logic language logical language and in
the original in the previous slide I've
shown you for the early for the simple
examples which involve things like no
integers and simple variables we can
just use very standard Neil a logical
language for that purpose but in this
case it involves like you nasty stuff
like queries and results s and all that
so we actually need to talk livid about
what is the language for us to express
these kind of things right so as our
saying whatever this language that we
ended up using is better be able to be
able for us to express all these
verification conditions for the
imperative code or is this which is the
source language in our case right and
more importantly we need to be able to
handle all these query operations that
happen in a code but because the code
that we're dealing with has like queries
embedded with within within within the
code itself right so whatever language
that we use we better be able to express
all the relational operations and in
particular the order of Records actually
matter so that might come a little bit
as a surprise but if you recall like the
the nested loop example that I shown you
earlier there's actually an ordering of
all the tuples that come out from that
nested loop and the ordering is
basically based on what the database
decided to return so if we but
unfortunately sequel itself does not
enforce a particular ordering unless we
put in an order by Clause right so in
order to preserve the cement
of the original program we somehow need
to capture the fact that the stuff that
is coming out actually has an ordering
embedded within it so whatever language
that we use to represent these
verification conditions it better be the
case that they preserve the ordering so
finally we also want any post condition
expressions that we actually come up
with is able to translate to the query
language that we have in mind in this
case their target is sequel and finally
it better be the case that you know the
function body is that I told you know
kind of like a mystery you better be
able to come up with you know what they
are otherwise we cannot establish the
fact and do the kind of conversions
right so what we ended up doing is use
something called ordered relations which
is very similar to a relational algebra
and with one caveat which is that the
relations themselves rather than
modeling them as the backs of tuples we
actually model them as an ordered list
so what do I mean right so we basically
say we basically mean the following here
are some examples we say that a in this
world a query result set is an ordered
list and a list we can construct that by
either like you know setting that to
some program variable where's basically
a query or we can construct that by a
concatenating multiple lists together or
concatenating with an expression and a
long with so these are basically
standard list operations that you know
most people are familiar with but on
besides that we also included a bunch of
database operations that can operate on
these lists for instance we say that you
know we can do joins we can do
selections on these lists which returns
other lists and this tough thing is
basically the familiar you know limit
clause that we have in sequel so in this
case it basically returns the top I
elements from this list where I is the
result of evaluating whatever this
expression E is this clones
yes points concatenation so I'm kind of
overloading this a little bit here these
start actually containing two of list
versus this is just appending something
so for expressions is you know what you
expect so for instance we can get
something out of a list we can you know
do some operation on two elements of a
list and then along with that we also
define a bunch of aggregate operations
that can return a scalar result right
okay so now we have some so far we have
a language where we can express all
these work yes because if you take the
original sequel application I learned
the same application twice I might get
this mythology so there's no equivalence
even between multiple mutations the same
program while you're trying to preserve
equivalence click on yeah because the
ordering of the topos can be arbitrary
from this point of result from the point
of the result set being fetched from the
database because even if around
application place the database can give
it and continue disregarded technique
because the sequel language doesn't give
you any guarantee a vote on yeah so so
the original application is fine with
this recording of cross even in
vacations where should you care yeah
that's because we cannot really enforce
that right so in fact we have seen
applications where they do rely on the
things that the ordering of the stuff
that is relied well so in that case for
instance the nested loop example right
so they know that like the underlying
database can return the ordering of the
to pose for however they want but then
we know that whatever the first the
first tuple that gets returned who would
then be joined in an inner loop fashion
with everything else right so there's
some implicit guarantee as to what the
result set would look like if anything
comes out of it you can't see what I'm
saying so because they have they have
explicitly written and nested loop right
so then the first tuple that gets
fetched from the outer loop whatever it
is will be joined across with everything
else in the inner loop right followed by
the second to post oh and so forth so
there is some implicit ordering that did
so you know we don't know where that's
like really what the developer has in
mind when he wrote that piece of code
the joining the same foods the order of
the job then that would take care of it
yeah that's why we ended up doing this
then since we have to be conservative
you know we have to preserve your ignore
things but i agree i mean for simple
like your selection it doesn't really
matter okay so now I I'm basically left
you with this kind of mystery where how
do we actually generate these you know
post conditions and invariance and for
that purpose we pull out this magic box
called program synthesis so you can
basically think of this as a search
engine over the space of all possible
sequel expressions right so how it works
is the following so given a program
synthesizer which is a piece of you know
code or basically off-the-shelf tool we
give it a symbolic description of the
search space so search space in this
case being the space of all possible
sequence questions that we can generate
and we come we will also put as we also
give as input a set of constraints that
we want to synthesize it to respect so
guess what right so this set of
constraints in this case is exactly the
verification conditions that we have
automatically come up with so given
these two things what the synthesizer
would do is it would do some sort of a
search procedure intelligent one using a
symbolic manipulation and what is known
as counterexample driven search what
does that mean right so that means we
try to come up with an expression that a
candidate expression that can possibly
fulfill the requirements that we want
meaning the meaning that is able to
satisfy all the verification conditions
and we try it out in terms of proving
where that's correct and if that works
out then we're good if not then it
incorporates that as a counter example
meaning that well you better not know we
turn this same expression again right so
that's kind of at a higher level how
this new the counter example different
search works so hopefully at the end
we'll get some example will get an
expression that satisfy all the
constraints or in this case what happens
near back to take us back to this
example we would basically want the
synthesizer to come up with expressions
for both the post condition and also all
these invariants right and to just give
you a sense of how this works in this
case let's say we're talking about the
postcondition the synthesizer will give
you as a description
of the search space right a bunch of
expressions meaning something like this
for so for instance we might try to
infer that results equals to some
selection of the users list you know
some top you know limit expression or
some more complicated things so and so
forth and of course we don't really
write all these out explicitly because
that would take forever so we actually
have a symbolic and coding of this
search space and because of the pairs of
time out of neo cannot talk about this
but if you're interested please come
talk to me afterwards ok so finally so
now you understand you know how we
actually do this do this kind of
transformation right so is an
interpretive loop where we try to you'll
find these expressions and it all works
out then we go ahead and transform the
program but you know as as being pointed
out we need to talk about how we
actually identify these code fragments
to be to begin with also we're simply we
can just yes question it seems to me
that you should also somehow model
contains a primary keys
which are the databases because that can
influence it can kind of limit the space
of expressions if you needed considers
so yeah exactly so I skip a lot of
details about like you know how we
actually efficiently and co2 space of
your things and all that but yeah that's
actually one of the things that we love
that okay so well for one thing we
probably won't start at you know where
where the code is actually fetching
stuff in the database as a starting
point right because we don't want to
know deal with all these other things
that all parts of the program that
actually does not involve any database
operations okay so that's a starting
point of where we want to look for these
kind of code fragments and then we run a
run point analysis in order to figure
out like where things escape in terms of
you know passing on to things that we
don't know what's happening so given
these two information this is it
actually sufficient for us to actually
determine where do these the persistent
data meaning that they stuff from the
database actually flow to in terms of
the program and that in turn allow us to
delimit the start and the end of these
code fragments that we try to analyze
okay so these are very actually very
standard a program analysis techniques
that basically no we just have to you
know do a lot of engineering to to
actually get to but to summarize this to
summarize this part of the talk so this
is the way that this whole tool chain
works right so it takes in the source
code of the application I'm modified and
will then try to find all these places
that uses query results from the
database and then we'll try to you know
find all these code snippets using the
mechanism that just talk to you about
and we'll ended up in something like you
know we'll be able to identify a bunch
of code fragments within the original
application source that we can try to do
these kind of analysis and conversions
and given that it will go through some
cell verification condition computation
it's a generate you know the kind of
explore gical expressions that we try to
enforce and then we'll try to do the you
know synthesis step to try to come up
with CQ expressions and if that all
checks out then we'll go ahead and
convert the code and put it back into
the original application source code and
this thing as i've shown you in the
early example is interprocedural so
meaning that we do a look into different
method calls and all that stuff and so
this is the entire tool chain and now
let's talk about a little bit does it
actually work right so the experiment we
set up in the following manner so first
of all we understand that there's no
standard benchmarks available for these
kind of transformations I mean there are
some ORM libraries you know there are a
lot of open source applications but
there's no standard benchmark available
so we did our best in terms of finding
to large-scale open source web
applications for this purpose in this
case this is these applications we're
written in Java using hibernate as the
ORM library so we want to measure two
things in foot for foot for to test our
tool first of all we want to know how
many code fragments we're actually able
to identify and comfort of the
application source code exactly we want
was that will also want to measure what
is the benefit that we get in terms of
execution runtime or do we actually get
any you know speed up in terms of
converting things into a sequel right
okay so for the first part so here is
one application that we looked at and
I've basically broken this thing down
into the types of different operations
that we were able to identify in terms
of the code snippet and also the number
that we were able to convert as a result
so you can see that we do we were able
to come were quite large portion of them
and they do come in a variety of
different types of sequel operations on
your joints and you know projections
whatnot and here's another one you know
a similar story so now in terms of
performance what actually happens first
so now we we start to measure what is
the effect of conversion in terms of
execution runtime so on the right here
we have taken one piece of code snippet
that we were able to transform in this
case we transform that into a simple
selection query the original application
just fetches everything from the
database and then do a filtering in the
inner loop fashion and then we turn a
subset of the result so in this case we
try out you know in with ten percent
selectivity and then we try to scale up
you know the size of the database to see
and measure the time that it takes to
load up the entire page not just running
the query right so this is both fetching
the stuff from the from the database and
also you know rendering everything
getting the whole thing from the
the from the web server and displaying
it onto the screen so you know this is
the original application the time that
it takes and as I've mentioned you know
it basically fetchers everything or no
database right and here is what happens
when we try to convert it into a
sinkhole selection query so you can see
this is basically an order of magnitude
difference right it's free office
because we've basically fasching a
subset of the things as opposed to the
you know the original application that
fetches everything and then doing you
know filtering inside the application
itself so now we also try it with fifty
percent selectivity so again this is the
original application in this case we
know we didn't scale as good because you
know obviously this is because the
application was fetching more stuff than
you know ten percent said activity so we
didn't we wouldn't expect me or the same
Kyle performance benefit but you can
still see kind quite substantial
difference in terms of time now the more
interesting case is actually the nested
loop example they are showing you
earlier right so this is the exact coke
snippet that way I just shown you so
here's how the original application that
I'm you know not so hot I mean as you
can see this is basically scaling up n
square because this is doing a nested
loop right and guess what i mean we
actually ended up scaling linearly
because we were able to convert from a
nested loop joint into a hash joint
because you know turns out that the
database already has indexes for these
for these tables so you know just by
converting into a sequel query we
magically get this kind of a speed-up
which is kind of good and finally say
you know same thing for aggregation
right so in this case this guy is trying
to do a count so it fetches everything
and then you basically you know sums up
the number of tuples that it returned
and you know this is the original
performance and again we have you know
not order of magnitude difference just
by converting things into an aggregation
and executing that inside a database
right so just very briefly i also want
to touch a little bit of fun of what are
the things that we actually fail to
convert right because as I've shown you
earlier we were not able to convert
everything so why why is that the case
right so first of all there's like a
bunch of cases where they use some self
custom logic to do comparison so for
instance they broke their own you know
they wrote their own comparison operator
that no compares themselves string
string value out of the database and
then sort the results at that way so in
that case since at this point at least
in this initial prototype we don't
handle store procedures so we're not
with so that those thing up so those
kind of expressions we're not able to
express instant a sequel so therefore we
fail to convert that kind of thing and
another set of things you'll use this
database schema information so these are
the kind of a more interesting cases for
instance in this case you know this guy
is basically issuing a query that
fetches things from the database and it
turns out that ID is the primary key
right and then he decided to sort things
out and then he decided to get like you
do this calf loop so look at this
carefully this is really just getting
the first 10 elements from the table but
unfortunately we're not able to convert
this into the sequel representation
because we didn't know that your IP is
equivalent is the primary key and
therefore this is really the equivalent
query in this case right so of course if
we incorporate that information and so
our prototype we should be able to do
better so but then that's basically
future work at this one yes related
queries which indofood medium school
at least in all the experiments that we
run we have not encountered a case and
that's because like you know things that
we convert are things like you know
selections or projections or joints so
unless you know unless the database
implementation actually ends up you know
slower than you know what the
application source go already written
otherwise you know yeah that's a good
question actually so okay okay so now we
just talked about this you know this
thing about converting thing census in
automatically converting things from
Java to to a sequel but as I've
mentioned to you in the first part of
the talk we are still left with the
problem of how do we actually execute
the application itself right so because
as I've saying some part of it we can
convert into you know sequel / store
procedures but then how do you make the
decision is to you know when do we
actually do the conversion right okay
again you're the high level go here is
to be able to be flexible in terms of
know how to execute a piece of code
right okay so for this power to talk yes
if you have nested loops in the
application program and there's
imperative logic in between investing
are there cases where that's going to
cause trouble in terms of reverse
engineering to query just because of the
expressiveness of query language we have
hips statements and procedure calls and
a lot about yeah that's a good question
so so the classic example that we have
seen for instance are basically people
putting lock statements inside the loop
so somehow you want to point out
something like your progress report you
know I have fat processing about fifty
percent so for those counting
unfortunately they cannot reverse
engineer because we cannot put like you
know the print statement not going to
bring back all the data yeah check out
of loop exactly exactly so I mean the
fortunate thing is we can indeed detect
those cases and bail out of it so we're
sound in that purpose yes you partially
concur such as so for instance you have
that application logic or something like
you need to return a list based on a
table and you need to filter out the
ones where the numbers a certain field
or prime or not and so you can certainly
propagate that logic i'm sure it's equal
but then can you kind of separate that
logic to do another filter within the
application language or visit kind of
fill and
yeah so for now we decide to bear out on
that on that particular case as well but
yeah I think that's an interesting point
where we can actually try to but then
that also gets into the question of like
how much we want to convert even though
if we can I mean we don't have to
convert everything and that's actually
part of this second half of the dock so
that's a quick lead intently okay so now
we want to talk about the way we want to
execute what piece of application logic
right so as a running example I'm going
to use this code fragment which is a all
familiar with tvcc so in this case this
guy is charged trying to basically do
some sort of a new order transaction so
as you can see here what happens is that
you know initially we execute some salt
query and then we know compute sums of
total amount and then we do an update
into the database so and so forth so
notice that when we actually execute
this piece of code what's going to
happen is that the first statement is
going to execute it on the database
right because this is a query okay so
but then the second line is going to
execute on the app server because this
is a piece of imperative application
logic and so and so forth for the rest
of the program okay so notice also
because of this that we actually get
some network communication between two
statements because either the app the
database has to relay the result set
back to the application server or the
application server has to tell the
database okay please execute this query
right and in this particular example
there turns up to be quite a lot of
these network communication network
round trip between the two servers and
these ones again turns out to be not so
good in terms of performance or it slows
things down so in this case our goal is
to basically try to eliminate some of
these round trip between the two servers
of course we cannot eliminate everything
because after all we do need to
communicate with the database to in
order to in order for the application to
proceed right so one standard wisdom and
you know in our community in terms of
speeding things up is to basically prove
things into a store procedures okay push
application logic to the server in
addition to queries so in this case what
we might want to do for instance is to
notice that in this case you know this
thing points out something onto the onto
the screen so it has to be on the
application server itself but then for
everything else we can try to group that
together
into a store procedure and push that
over to the database server and likewise
for this right now just doing this as
our experiment shows actually decreases
latency x 3 x 3 x so I mean that's
obvious why that's the case where
because we are reducing the number of
round trips right but notice and as I
have pointed out right so this in this
case this line has to execute on the on
the application server okay so what does
that mean so that means we need to keep
track of the ordering right because in
this case this is actually got applying
an if statement so this line is only
executed if the if statement turns out
to be true so in programming language as
well that means we have a controlled
dependency we have a control dependency
which of these two lines on this
particular if condition these two lines
are only executed depending on the
outcome of the if statement so if we
want to do this do this in your store
procedure approach we better know at the
end of this store procedure return
whether this is true or not because
otherwise the application does not know
whether it should you know go ahead and
print out stuff onto the screen or
you'll call another store procedure or
database queries for an instance right
and in addition to that and you know in
order to make this work we also need to
keep track of all these data
dependencies but why well notice that in
this case you know this guy depart
defines a variable that gets used later
on if we decide to go back to the
application server so that means at the
end of this store procedure we also need
to return the value of this variable and
forward it back to the database sir I
mean the application server if we decide
to go back to the application server
right so okay so now you think okay well
we just need to keep track of all these
things when we write the store
procedures just look be a little bit
careful and we should be no fine we go
ahead and you'll deploy this on a
database tests or procedures but then
your guess what right there's also this
problem with multi-tenancy meaning that
you know the same database server can be
shared across with a different
application and in particular if it is
actually under heavy utilization then if
we push all these application logic to
the database it actually is not that
beneficial after all so may maybe after
all we should go back to the original
version where we know we just encourage
extra network round trips and you know
that might actually turns out better
right so and imagine doing this kind of
thing for millions of lines of code
right it's just not going to be no
manual f
is not going to cut it so to count we
solve this problem what we ended up
doing is building a new system called
Pyxis and it does two things in
particular one is it automatically store
procedure arises if you will database
applications and pushes part of the
application logic to a database like
what I've shown you earlier and to
target this problem of like your multi
tendency we also adaptively controls the
amount of application logic that we want
to push based on the current load on the
database server right and we're able to
do all of these without any programming
intervention meaning that we able to do
all do automatically you always somehow
petition the program you have split
things up and we can turn it up and then
you if we can do different execute
different different things differently
so this point you're probably thinking
of like you know how is this like
possible right how do we actually do
this well let me show you how this works
so imagine this is the original
application which has basically some
sequel and you know imperative logic
embedded into point so what we do in
Pyxis is that we first create a and
first collections of profile data about
the application and given this profile
data we have a mattock petitioner that
takes in the profile data and charged a
petition the application into two parts
one part to be executed on the observer
in other parts of executed on the
database server has stored procedures
now during execution after deployment I
guess on the database server these two
kind of a petition application is going
to periodically jump back and forth in
terms of the application control and we
call that a control transfer and to
facilitate this adaptive property we
actually have a monitoring component on
a database server that keeps track of
the current load on the database now for
instance in a case where it turns out to
be you know under heavily utilization
our deployment tool will actually
automatically switch back to another
petitioning for instance in this case we
will decide back we'll decide to do the
original petitioning where we go back
and forth between the two servers
instead okay so how do we do this kind
of a source of source code petitioning
right so we take the original
application source code and then we just
know processes that Gil from beginning
to end now as I mentioned to you earlier
we first do
availing of the application and we also
collect some capabilities in terms of
how many cores or we need a
specification of the two servers that we
are targeting okay so for instance in
this case given like you know this piece
of code I've shown you earlier from tvcc
what we will do is we will collect the
number of times that is each instruction
is executed so is vic and we use that as
far as the profile information because
that is going to guide us in terms of
doing the program petitioning now next
the next step is to basically do the
petitioning and the way that it works is
the following so we can we basically
take the original program and we create
what is known as a program dependence
graph so for those of you who might not
be familiar with this so this is
basically a simple graph where every
node corresponds to a program statement
in the original program and it also
keeps track of control flow edges and
also dataflow edges so what I mean so by
control flow edges we mean like you know
there's control dependence between every
statement then we basically insert an
edge so in this case for instance we
know that you know this is the order of
the of the program and then since this
is an if statement we have control
dependencies with these two statements
okay so that's control so this will
recreate this graph and we basically
adds edges in this manner now for we
also each node as it turns out also has
a weight which help us decide on the
petitioning and the weight is at this
point we're basically just using the
counts that we have collected during a
profiling of the initial application so
now we also insert a bunch of a dataflow
edges in terms of talking about like new
where data flow from one statement to
another so in this case for instance
notice that this this count variable is
used on the second from the define in
the first statement and used in the
second one so we insert a dataflow edge
that talks about like there's a data
dependency between these two statements
and that's and and the thing that we
talked about here is this particular
variable and so on so forth for the rest
of the program right so we just create
all these data flow edges so this this
is like basically part of a part of the
process of creating this program
dependence graph okay so we use this
graph for petitioning purposes and in
particular we generate a linear program
to solve this problem we're in this case
we're trying to minimize the
this this expression here where it's
basically the sum of the edge wages I
mean the edge the edge wakes since each
of them represents basically the number
of bikes that gets to chant that needs
to be transferred should we decide to
cut the program in any particular way
right so in this case each edge both
data and control has an indicator
variable AI that is set to 1 if we
decide to cut the program at that point
and all these and so and this goal is
basically a subjected to a number of
constraints where we say that no II is
equal to 1 if we decide to cut the
program at that point and is 0 otherwise
okay so all of these we also have an
extra final constraint that talks about
like how what is how is the load on a
database if you will in terms of the
amount of CPU memory i/o resources that
are available and we want to say that
whatever positioning that we able able
to come up with better respect this
particular budget constraint because we
don't want to push too much stuff to add
a base right so you can imagine we can
basically solve this linear program for
different values of budget which
corresponds to different values
different amount resources that is
available on a database and that
basically gives us different petitioning
of the same programs itself so you can
think of this as we just generate the
various versions of the same program
except that they all differ in terms of
how much application logic we decide to
push from one from one from one server
to the another so solving this program
basically give us gives us a solution
where we assign each node in this case a
program statement to either the
application server or a database itself
right and the output of this program is
represented using something called pixel
which is a sounds like the name of a
drug and apologize for this stuff maybe
it is it actually stands for the Pyxis
intermediate language where worse so
here's an example I mean it looks very
much just like Java in fact like we can
actually program in this language the
only difference is that every every
statement is now annotated with either
the meeting that is to intend to execute
on a database or a which means it's
intended to be executed on the app
server so so you know as I've shown you
here this is just one example we can
obviously generate different type of
petition and give them the different
constraints that we have for the
database server well but now we still
have the problem right I mean how do we
actually compile this thing down to a
real program that we can execute so
that's what this compilation and runtime
component in pics it's all about so
again you know we want to somehow
compile this program in this funky
language into Java and again one half of
the program is going to be executed on
the app server and a half on a database
and I just want to point out that you
know we didn't change anything for the
photo for for in terms of in this case
it's a Java program so you just run it
on any normal JVM we don't we don't
require any special tricks or any sort
of a specialized runtime system in order
to deploy this meaning that we basically
take the program in this pixel pixel
representation we and we compare it to
Java and you can basically run anyway
okay so what the compilation procedure
is pretty much a straight forward except
for two issues one is how do we actually
do these kind of control transfer
implementation between the two servers
and also how do we sync up the heat
right because as I pointed out we have
all these data dependencies we somehow
need to be able to you know sync up the
two-run times if you will so again back
to this example right so how do we do
the control transfer for instance well
we simply try to group together
statements that have the same annotation
in this case you know they all annotated
with database okay so we know that these
guys need to be executed on a database
and then so basically what we do here is
take these statements compel them to
what we call code fragment and then
execute them on the database server
itself and then we basically keep doing
this until we encounter something that
we know has to be executed on the AF
server at that point we ought to make
the runtime system that on the on day
two servers will then basically go and
tell the other guy okay well I need to
do I need you to execute this next code
fragment which correspond to know for
instance code fragment number 110 for
instance so and so forth for the rest of
the program or so that's easy I mean
relatively speaking now for for for a
heap right what do we do well so during
execution right we actually keep track
of all the things that the all these
code fragments I
we actually keep track of all the state
changes that each of these code
fragments incur so for instance in the
co example damn show you will basically
note that when we first try to execute
this particular code fragment on the
database server hour run time will
ultimately figure out that we need to
forward these to the values of these two
variables over from the app server to
the DB server and that's because they
are used inside this particular code
fragment so a runtime system
automatically figures all that out and
it also keeps track of anything that
gets changed for instance when if we
decide if we if the runtime actually
execute this code fragment on a database
server will notice that you know we
actually define the variable credit so
if the if condition turns out to be true
meaning that we do go back to the app
server we afford it the value that is
needed in order to print out the
statement onto the screen and if we
decide to stay on the app server then I
mean the egg database server then we
don't we need to for aiming because
there's no change to the heap I mean
it's basically the same you so we do all
that during during an inside runtime
which is basically just another Java
program that sits on top of the JVM on
the two servers there's nothing special
about this and so and so far so we keep
executing that way right and again well
we have a monitoring component which
will basically tune two different loads
on a database right so if the load on a
database turns out to be too much we'll
simply switch to another petitioning
that we have pre generated when we solve
the linear program and then we'll just
execute as before I mean nothing really
changes it's just basically can think of
this as just running another version of
the same program okay so now let's look
at how do we actually do in terms of
experimental results right so terms of
experiment setup we have a TV CC
implementation in Java in this case we
eat we have a 20 terminals each running
simultaneously issuing new transactions
the most complicated one out of all of
them and you know standard a machine
room setting and in this case David
server has 16 core total and we along
with the one that we automatic generated
we also compare it against two other
implementations the first one being the
original application if you will where
everything is executed using jdbc so no
it basically encourage all these network
round trips and another one where we try
to manually push everything as much as
we can over to the database server so
that's what we call a manual
implementation so with all the cores
that available well in the beginning
where we did this experiment we measure
the amount of this is a standard your
latency versus stupid graph that we are
familiar with so the JDB is the
implementation as kind of a high latency
if you expect and it's also not able to
sustain very high throughput numbers
because of all these network round trips
data that have been incurred right as
compared to the manual implementation
where you can see here has a much better
latency and also able to sustain to
high-throughput because we push most
application logic to the babies and the
database is has a lot of course
available to run all these things now
for us so we automatically detect that
you know in this case there are
plentiful resources they're available on
the database server so we ended up
choosing a petition that is very similar
to the manual implementation or the
store procedure is the implementation
will push which I push as much stuff as
we can over to the database and that and
this makes sense right so basically we
able to do this automatically without
the programmer you know doing all this
manual process of of creating all these
store from seizures and whatnot so we
basically get a three excellency
reduction and we also get substantial
improvement in the throughput now let's
take a look at the reverse right so in
this case we restrict the number of
cores that are available on the database
server so we did the same experiment so
again you're jdbc implementation no
that's new cover Oregon a stable latency
across the port now with manual
implementation the interesting thing in
this case is that we anit so in this
case you know it's not able to sustain
to high-throughput numbers because you
know at some point is saturated the
entire database server I mean they're no
more course available so it just ended
up choking is not able to handle all
these extra extra transactions they're
coming in now in our case we're actually
able to detect that they're not enough
resource available so we choose the
petitioning automatically that is
similar to the J
babies the implementation so that this
again you know make sense right because
we basically want to use the jdbc
implementation if they are not enough
resource they're available on the
database server so finally in this
experiment we did a dynamic switching
thing we're in this case this is x axis
now is now time so we fix a particular
number of throughput and we measure the
official agency across the board the
only difference is that at some point in
the experiment we decided to restrict
the number of cores that are available
to the database server so initially it
it has access to all 16 courts but at
some time at some point into the
experiment we decide to cut some of them
off okay so you know jdbc performance as
this and then you know in this case the
menu implementation you originally it
did really well right because it has all
the course available and at some point
after this new account shut down it the
latency just skyrocketed because of the
fact that you know once again in similar
case as before you know there's no more
course available now for our
implementation the interesting thing is
we're able to automatically switch
between these petitions so we notice
that in the beginning we choose a
petition that is very similar to the
manual implementation where we push
things to the to the database and at
some point after we shut off all the
most of the course we decided to switch
automatically over to the JDBC
implementation so just for a record here
we also show the percentage of
transactions that served using the JDBC
implementation so you can see that
initially none of them were using that
particular version because they're
plenty of resources they available but
at some time we gradually converge to
this other mode of operation if you will
where we execute most of the things
using this JDBC implementation right so
in the summary in this case we basically
able to show that we automatically
switch to the most efficient
implementation based on what is the
current server load on the database yes
once we shall hundred percent wise if
not the same as
oh that just because of measuring the
way that would measure latency is that
average is a running average yeah okay
so that comes to the conclusion of this
talk where I basically show you this
umbrella project we try to use different
different programming and analysis you
know techniques to try to speed things
up so to go up which is to help
application developers write these kind
of database applications so in
particular we show you two things one is
you know the ability to convert things
from imperative code into sequel and
another piece of work that is able to do
automatic co partitioning and also
distribution of the application across
the two servers and we have a website if
you're interested in learning more and
this point I would love to take
questions thanks part of the talk how do
object relational mapping systems
because you're actually generating
sequel to run the server which of course
we are
yeah so in the traditional iron setting
most of the RM logic would be on the app
server right so we haven't do the if we
haven't done the integration yet but I
think we were very interesting where we
start pushing part of the ORM code over
a store procedures on to the database
and see how that would work out I think
that's a very interesting fallout work
because actually the updates because
they tend to the running in cash and
then they have to somehow take a dip of
the updated cache of your cash updates
and somehow package that up into updates
that get sent down to the server it can
be quite right so on one aspect the good
news is we already have the machinery
for all vehicles already keep track of
equipment blah blah blah but the
interesting thing is perhaps how we
formulate the linear program to also
take all that stuff into account so I
think that would be an interesting point
of our work
so if it seems the first part of the top
with the craziness is so if you mean
what you're doing is you're taking an
imperative code and you're turning into
a single parent right and then the
database afterwards turns the sequel
query into imperative code so can you
also think of a way where you can
actually take a normal vacation which
does not involve that communication with
the database and try to optimize it
based on something
relational
so I guess we probably don't want to
push like things that the database is
not good at doing into the database
itself right yeah i'm just saying forget
about the database just you know you
have your analyzing a program which does
any sort of processing of data which
does not sit on a database buts it's a
memory silver and you're just analyzing
this program creating a relational
algebra and then using standard database
techniques to optimize this into the new
code though can you think of a way of
using your work to do this kind of
optimizations you mean for other context
or you mean yeah so yeah exactly so in
fact we're looking at using similar
techniques for memory devious programs
so you can think of some how we're able
to you know it will be nice if we can
come up with a way to convert arbitrary
and Perico into the hive okay and
leverage off the query engines ability
right so what database systems are good
in doing is basically doing this kind of
a relational optimization if you will
break so it's very good at choosing like
you know that what is the best career
plan and so and so forth so from that
respect I don't think we want to go in
that direction as to bypass all that
machinery I think it's good that in your
database are good at doing that so what
we're trying to try to do here is to
leverage what they are good at doing
yeah right it's for a single user
existing database technology to put in
the sequel query give
let the database give you a more to my
skoda processing the same data yeah but
not actually communicating with the
database but doing the same thing inside
the program material so you mean like
actually do the reverse which is we try
to push some of the database logic back
to the app server oh yeah I think I
think that would be interesting although
i think i think in some sense having the
competition close to the data it's a
good choice right i'm talking about
situations where the data is actually in
there okay oh I said yeah yeah sure yeah
that that would be actually be just like
so i think that would get into some of
the work that we're trying to do for
MapReduce for instance because in that
case they do have we use you know main
memory for at least for temporary
storage so i think the interesting thing
in that case will be to model what is
you know how much data that we can
imagine we'll be sitting in the cache
and being able to being able to optimize
that way as opposed to right now we are
soon Daniel Kash does not exist or is or
or in other words we assume that you
know most of the data is sitting on to
the database and it's not cash on the
app server yeah but I think that's a
good one yes one leg but we are a
strange question is if you have
expression same day
which which look exactly like sequel but
they're processing marriage is within
you cannot see expression
any using younger program analysis
includes
yeah yeah yeah yeah that's a good one so
in fact i think the reverse question is
also interesting which is if we can push
things from from f servers with babies
why not also lift some of these things
back from the database over to the app
server right port you know for cash
locality for instance
fixed so I have a example in mind so for
example I have application written and
what it is doing is it's selecting two
tables in fact when I select star on two
levels a and B and then within the
application logic it's trying to do
something with those data and also those
of extra parameter say X now if we want
to convert this to a sequel query every
time you have to write a new way
depending on that parameter right but in
the previous case it was doing Civic
selects turn on a and B which is more
efficient in terms of using the database
cash so probably goes to expression will
be cash and it would be very fast and
the father processing is being done in
the memory so it would be very efficient
but in your approach it will be writing
a new seeker vary depending on the
counter and it won't be cast in the
database so it's loaded me in that case
the performance might vary quite a bit
yeah I think that's ok that's a good
case actually yeah yeah thanks for yeah
I think yeah absolutely yeah I think
that would be adjusting things little
bit it's just that like at some point
the linear program starts to get really
unwillingly in terms of being able to
solve so just all about like how much
tricks we can pull in terms of being
able to formally a very small program
that is able to solve yeah
thanks good thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>