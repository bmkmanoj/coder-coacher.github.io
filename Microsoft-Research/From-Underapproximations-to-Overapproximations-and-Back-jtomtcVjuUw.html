<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From Under-approximations to Over-approximations and Back | Coder Coacher - Coaching Coders</title><meta content="From Under-approximations to Over-approximations and Back - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From Under-approximations to Over-approximations and Back</b></h2><h5 class="post__date">2016-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jtomtcVjuUw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so it's my great pleasure to welcome
erigor Frankel from CMU and in a fitting
tribute to curiosity landing on Mars
he's going to talk about UFOs and the
state space explosion so take it away
okay hi everybody so this is a giant
work with ours is here in big letters in
Ely and Marcia chechik he's in big
letters because what he did a lot of the
work and also because he's right over
there so if you have any sort of
questions that you think about after I'm
gone down he's the one task I give no
warranty so any mistakes I have you can
to my employer or I have to do I'm sorry
ok so let me start so but this work is
about the sort of automated software
analysis I'm not going to spend a lot of
time or any time motivating why this is
interesting just sort of position where
where this work fits so from my
perspective and automated analysis is
box it takes a program and it tells us
where the program is correct or whether
it's intra and there's two major
approaches to building this box one is
pioneered by at Clark Island Emerson and
Joseph sifakas which is now called
software model checking of model
checking with predicate obstruction and
so on and another way to build this box
is for something called absurd
interpretation which was pioneered by
goose Anka saw and about at the same
time the reason why I'm showing you this
boss pictures is sort of my work
typically is mostly working in between
these two realms so doing some software
model checking applications with
abstract interpretation of some abstract
interpretation with software mobile
checking this particular works are the
fits more here and they follow up to it
fits my here if you interested about it
later I get a question why is this
picture this way and I just couldn't
find a picture of Roger that's the
picture shows on her web
and there no other now I know other
pictures if you go to Google Images and
look for so so here's the outline so
I'll talk about sort of the way we
classify approaches to software model
checking as over under approximation
driven and the key word here is driven
so both approaches use partial models
and things like that but we sort of
separate what's the primary what
secondary and i'll talk about you for
which is our way of combining the two
and then you've all talked about the
exploration strategy in the refinement
strategy which is it too important stop
there and then conclude and i know if i
have to say this but the stock will be
very informal so if you have questions
please stop and ask don't wait until
then okay so here's a picture of
something called sigir counterexample
guided obstruction refinement will say
it's another approximation driven
approach and this is how it works we
start with the program we start with
some abstract domain as some initial set
of Fred Achatz compute an invariant
check whether the invariant is safe if
it is but not if the invariant is not
safe we look for an abstract counter
example is an smt solver to check
whether it's visible if it is we have a
counter example we done if not we're
going to go and somehow refine our post
operator get more predicate using eyes
interpolation or weakest precondition
and repeat this process so we'll say
this is another approximation driven
approach because a lot of the work is
done sort of in this over approximating
part of it so we do all this work just
to get the right abstract domain and
then a lot of the analysis is done in
this abstract computation so I'll give
you an example just so that you'll see
exactly what I mean so we have this
program on the left hand side and has an
arrow location and we're trying to check
whether error is reachable so the first
question is it reachable in it
assuming no overflow founder flows I
guess wow it seems like it oh right so
is there is no overflow than there is
unreachable so let's see how will the
cigarettes work on it so the first thing
we do is we build an initial abstraction
where example will take no credit adjust
the control flow of the program and it
will look something like this where
stars mean the non-deterministic choice
then build the model out of this thing
which looks something like this and then
we asked whether error which is node 5
is reachable is it reachable here it is
ritual we have a counterexample now we
have to see whether it's a real counter
example so we're going to our visibility
check we mop this counter example back
to the original program we say okay from
one to two that's okay from two to four
is a problem okay so from 12 to the
program actually goes from location to
location too it doesn't go from location
to location for and the reason is that
we need this predicate this is what
blocks at execution so we take this
predicate we added to the list of
predicates build a new obstruction we're
now we'll have a boolean variable B's it
will represent this predicate and then
everything that can be obstructed by B
is obstructed by it as precisely as we
can so for example the loop condition is
just be and this statement says if Y was
less than equal than two before we
subtract one then it remain so other
words it's non deterministic we'll build
a model and now in this model is 5
reachable from one
I may be losing some people but from
watching there is no past 25 it should
be easy to see and so we know what we've
just proven is that there is in fact
unreachable we have an abstract proof of
it so this is a the Seeger approach I
will say it's another approximation
driven because a lot of the reasoning is
sort of to build the right over
approximation than do reach ability over
it and then conclude that the program is
safe oh there is a contract okay so
here's another approach which will call
under approximation driven an instance
of it is impact or lazy obstruction
within turbulence and this is how it
works instead of spending any time in
generating this abstract model lobster
counter-examples it says generate just
arbitrary pastors from a control flow
graph once you have a bunch of this pass
check what is a feasible you can do it
using anise empty solar if there's at
least one feasible pass and you have a
counter example you done if not you try
to explain in a uniform way why all of
this positive and you can use
interpolation or weakest precondition
for that once you have this explanation
of why is this particular paths that you
pick the safe you check whether this
happens to be an inductive invariant if
it is then you don't you just proven
that the program is safe if not then
there's some parts that you haven't
looked at in your program that it's safe
for a different reason or maybe unsafe
for different reason so you go and pick
more pass check if they're feasible and
keep going on in it okay so here the
approaches under approximation driven in
a sense that a lot of the reasoning is
in this part where you deal with a bunch
of concrete executions and you're trying
to decide whether they feasible or not
or general generalized things from them
so let's see how it works on exactly the
same program as before I haven't changed
anything error is still unreachable so
what we're going to do is first we're
going to pick a path any faster control
flow graph will do you can pick this one
that goes 1245 we then check whether
this process
visible of course isn't and then we get
a proof why it is invisible and the
proof here is written as this number as
annotations which basically say that
each annotation represents the set of
reachable States from the top it's and
over approximation of that and each pair
of annotations together with an edge
form a horrible they have to substitute
the edge with a appropriate action and
then it will form a horrible so here
we'll see this proofs tells us that five
is unreachable the over approximation of
ritual state is false now this proof is
not yet inductive because we have this
location to the loop had to and we
haven't seen it twice yet so we're going
to look for another pass maybe the one
that goes through through the loop once
and gets out of the loop and then gets
out and goes into an hour will check
whether this pass is visible it isn't
right how do we know it's not visible so
the program is safe we already know that
so they cannot be feasible
counter-examples and so we use for
example interpolations to general to
generate the proof that explains why
this counter example is invisible and we
get something like this it says so
initially we start with everything then
why it's less than two we subtract one y
is less than two we go into loop we try
to get out we can't there's not nothing
reachable at four in this case and
nothing is reachable at five so now we
have we also see that the annotation
here 42 is subsumed by the annotation
here too so we in fact have an inductive
proof of 60 right if you look a little
bit through the sort of whore
annotations you can now generate and
apply whore rule for loops and getting
it using the inductive in there and why
less than equivalent
so that's an example of another
approximation driven approach yeah if
it's another approximation that you
don't explode with infeasible pass right
between something else here again if
it's another approximation if you just
explore it under approximations so I
pick I pick a bunch of can bite your
possible execution through a control
flow graph without using any obstruction
or anything now they I don't know that
the physical not because I deal with
concrete executions so I actually write
the formal as it represent the exact
executions and then I check if the
formula is false and I've represented no
executions that have to formulate
something else then I represented some
executions so I deal with can create
executions if I find a counter example
if they can create counter example but I
deal with this symbolically and so in
this case i can write a symbolic
expression that represents what seems to
me many executions but really it
represents nothing but the meaning of it
is what it represents the meaning is
that it is under approximation with
respect to the program under the
execution point along highway it's just
a big Moloch exhibit
while we can debate the terminology so
you could say that I'm working on the
Sun relics of a control flow graph and
then rolling somehow over approximate
what the program does and I'm thinking
I'm working and they can create
executions and I'm just using symbolic
techniques to represent them and it's
just really a terminology different but
if you want to allow that step for me
then I can't say that well there's over
and under and we combine the two just
the story doesn't work is nice okay so
i'm going to show you the techniques
that we have i'm going to show it at a
much higher level than the example that
you so and so i want to show you the
things that you sell but at a higher
level where we don't look at the details
but we just look at how the exploration
happens where is over approximating
perches and wears on the approximating
part is so we're going to look at the
skeleton of a program i'm going to show
you the over approximating approach here
in sort of high-level pictures and then
another approximating approach here in
other pictures and now it should make
sense in the next slide so this is what
happens with an over proxy mating
approach we goes through this explore
refined Explorer phases where we build a
model we then refine the counter example
we build more models and the Explorer
phase will look like this we start with
a control flow graph node and initially
it's labeled by whatever is the initial
condition is so blue means it's labeled
by some formula over the predicate we
then make a step so we find a successor
or pick a successor successor is not yet
labeled we just picked it we then
compute the abstract transformer so we
get the label for that successor again
overall predicate and we keep doing so
we pick a successor will able it until
we find a successor that corresponds to
an error location in which case we'll
say okay we have a counter example this
one we have to go through refinement so
we have to analyze it see if it's
invisible and if it is get new predicate
and after we go through the refinement
step we go back to the very beginning we
don't always have to go to the very top
but it's simple if you go to the very
we now have more predicates and we
repeat our exploration again we start at
one we go to two wheel able to we go to
air and if our refinement was good
enough then this time an error becomes
unreachable that means we label it with
something but something will be false
well then go find another successor of
two so here it's in the loop so too is
it is accessor of itself and then we
check whether the annotation here is
subsumed by the annotation here whether
we've seen all the reachable states if
so we terminate if not we keep exploring
until we get new our new refinement and
so on engine that's sort of clear now in
the under approximating approach will
also have exactly the same stuff they
explore the refined explore accept what
they do is slightly different the
Explorer step just picks a pastor
control flow graph right we haven't
labeled it we don't know whether it's
feasible or not we just pick the pasta
which everything is labeled by dre we
then check whether it's visible and if
it's not we use interpolant in order to
get a proof or compute another
approximation of reachable states along
this path so I'll use the orange color
to indicate that we have labels they
also formulas over program variables but
they come from Interpol and of course if
this pass is invisible the error state
will be labeled by faults then we pick
another pass label that pass and keep
going on like this until I again as in
here we'll get that something at the
bottom is covered by something at the
top something at the bottom has a label
that subsumed by something at the top
so initially these things don't really
look very different because at the
beginning of something like slam you
only have a control flow graph and all
the model checker is doing is exactly
picking just a path arbitrarily error
right because initially the the abstract
transform it's just it's just the
identity right oh absolutely so the two
things are really really similar and I'm
trying to argue that they very very
similar and they should become mind I'm
going to show you how exactly for this
reason the difference is from what you
mentioned for example is what do you do
officer in the Interpol in the under
approximating based approach you take
the proof and you extract labels from
the proof and a predicate abstraction
approach you don't do this you take the
proof and you extract predicates from
the proof you forget the actual proof
that you had and then you go back to
your over approximating step and see
whether this new product that's a good a
good enough to rule out the product to
rule out the same problem happening so
what that means is that the over
approximating technique actually
computes stronger predicates than the
under approximating technique I mean it
could be because if you take if you take
the interpolant all right and you can
you extract predicates and then you run
a predicate obstruction pretty good
abstraction will compute something at
least as strong as those in 20 points no
blue label's will be at least as strong
as your arms labels like modulo various
heuristics but if you take this problem
sighs oh my god there's something you
take the the most didactic version of
pretty good abstraction that says
compute the strongest building in
combinations you complete the best post
condition using the using the front
sorry in fact if it doesn't compute
something as strong you're probably at
Rotten absolutely price so so really the
over proximity technique the blue labels
are actually stronger than our soils yes
because the orange thing was only good
enough to rule out does counter examples
where the blue ones may be good enough
to rule out future counter-examples it
look in a similar way so maybe about
under approximation alright other words
those in turbulence that you're
computing come from under approximations
of the program's behavior because they
come from just partial behaviors of the
program and yet they're really neither
under approximations nor over
approximations are they the the labels
and so they aren't labeled at the
Huracan those who are using generally
just traces infeasible traces so in turn
to get there in printer it in principle
so the orange labels trample them up you
generalize something I'd you have
something very concrete and you
generalize them into this label whereas
here you sort of come chop down now is
blast and over proximity or an under
resonating so can you hold this on for a
second so I'm going to get to picture of
our approach and then I can show you how
you get oldest points in a spectrum by
specializing just various parts in this
algorithm and I can show you exactly
where a blast fitted into this picture
so i think i'm quite close to that part
so the first thing so this is maybe sort
of the discussion we just had to some
extent so if we look at this two
techniques we can try and put them into
the space and this is an ideal picture
that they don't necessarily look like
this we have this number of refinements
here and cost of our exploration costs
of building the labels in an hour
approximation driven approach the cost
of exploration is high we've put a lot
of effort in computing that the
predicate obstruction in under
approximation driven mad at the cost of
exploration is very low but the number
of refinements can be very high because
we don't compute labels which a strong
so we sort of have this is two parts
where one has
maybe few number of refinements but very
expensive cost of exploration so if you
get the right predicates then you likely
terminate with a few iterations and here
you may need a lot of refinements to
combat the fact that your labels are to
John are too weak this doesn't reflect
performance it's not the case that for
example fewer refinements means that you
first right so it's not clear how this
affects performance but what we'd like
to have is an algorithm that can be in
between these two not necessarily an
algorithm that at any point but an
algorithm which is easy to control may
be dynamically at runtime to switch
between doing more of this or more of
this and this is what this work is so
this is you for this is a picture that
you should all be familiar with because
this is a infamous state-space explosion
which is a big problem in in model
checking it lists and the UF algorithm
sort of has this note on one hand it's
an interpolation based under
approximation driven algorithm it uses
orange labeled and on one hand it's a
predicate obstruction based algorithm
that uses blue label and what we have on
top of its on top of the salga rhythm
one of the things that sort of makes it
work as we have a novel interpolation
based refinement that makes this whole
thing work together so what I'm going to
talk about next is I'm going to show you
the algorithm and high level and I think
then I'll just concentrate and talk more
about the refinement word okay so this
is how you fall looks like in a nutshell
so this is exactly the same pictures you
saw before with blue labels and orange
labels and what I'm trying to convey to
you that will combine things so what you
should see is one picture that has both
blue labels and orange labels if you see
that then that means we've combined
something it's going to use exactly the
same steps as before there's going to be
explorer fine explorer so let's go so
first we start and exactly the same way
it's probably good obstruction
so we find some location L we label it
we then go and see what the successors
are al happens to have two successors in
our successor and some inner one we pick
an inner successor we keep going on
expanding and expanding and then we hit
elegant so l is the loop head of
something we find that successor of l is
also the cerro location we check whether
we've seen all the reachable states if
so we go and compute the label for their
allocation and now we have a possible
counter example so now we're going to go
to the refinement fit so far it was
exactly like predicate obstruction now
the refinements rate will be different
what we'll do in the refinement face is
we'll take this whole directed acyclic
graph and we're going to prove absence
of counter examples in it not one pass
at the time but the whole graph it wants
and from this whole graph at once we're
going to get a proof that explains why
there are no counter example since this
graph again all at once and this is
going to give us the orange label now
what can happen here so the orange
labels will be in some sense
strengthening of the blue label's why
strengthening because while here error
was reachable here it's not so it got
stronger but it's not necessarily
uniform strengthening its not uniform in
the sense that here's a set of reachable
states this location can now be bigger
than the size of reachable state or
dislocation so what we're going to do
now for the next exploration phase we're
going to find out all of the back edges
which are broken which they are no
longer inductive and then we can restart
exploration from that point on possibly
with a new predicate that we found
that's it
so let's let's see how do we get the
other algorithms so say we want to get
another approximation driven algorithm
then what we would do would say here
whenever you compute the blue label's
always use the most impress eyes post
you can use zero predicates always so if
you always use zero predict as here
you'll just unroll every loop once isn't
get Interpol and Stu rule things out and
see if you've converged if you haven't
converged you enroll every loop once
again check now if this bigger graph has
a counter example if it doesn't build
the labels that it doesn't check that is
inductive and keep going on in them now
say we want the other we say we want to
get the blast or something similar to
just probably get obstruction all good
well we're going to use all the
predicates we can every time we do more
interpret more proof somewhere into your
opponent's we're going to extract the
predicates and use them in the next
iteration but also why should we start
the exploration from this point we can
start exploration from any point here on
any point above it so in fact whenever
we go after refinement after we've
proven absence of a counterexample have
gotten this orange labels we can then
restart exploration always from the top
right effectively killing the orange
labels just using the predicate from it
and that will be a predicate abstraction
based whole group so how do we control
thus interplay between over and under
approximating driven well if we want it
to be more under approximating driven
then we throw away some of the predicate
we find out which predicates we don't
want throw them out the more we throw
the mall under approximating driven will
become because more in precise our post
becomes and if we want it to be more
over approximating driven than the
higher up we know tree will start higher
up in the tree we respect
so that's our two nums did that answer
your question about the blastoise should
again later so it doesn't really relate
to so you asked me where blusters and
how it fits into it so the way okay well
if you took a very didactic version of
blast all right what les would say is
what would you get a bad house and then
you are going to do credit obstruction
along that path to update the labels
right to the extreme version of blood is
the extreme lazy right where you're
saying do credit good instruction along
the path but don't propagate those
credit that's a long other paths right
do you do the refinement very locally so
W the extreme lazy version of us which
you wouldn't want to use necessarily all
right but if you think about that that
version of blast all right is actually
sort of a special case of impact because
all it's saying is I'm going to get the
interpolant by instead of taking them
directly out of my ass mt solver you
know I will get the predicates out of
the SMG silver and I will do pretty good
abstraction along that path that will
give you a stronger so this sort of like
starting higher up and that will give
you a stronger side of interplanetary so
what I'm saying is is then blast an open
approximation technique or an under
approximation technique if I would think
of it as a special case of impact
strength
so I would say it's another
approximation driven technique because
the main engine for reasoning is the
post computation of predicate
obstruction so you do a lot of things so
that then you can apply the abstract
post and
while it's computing a set of ritual
states it's not really what it is
computing because at the end of the day
anything that you compute would be an
interpolant for this problem right it's
a question of to me it's a question of
how it is computing it it is computing
it by looking at executions and
extracting and generalizing a proof or
whether it's computing it by doing
something else by first at the end of
the day what it computes as a proof
right so so so so this would be third
one from the proof I was sort of the
distinction is just do you take your
abstract post and iterate it to an
abstract fixed point thus computing an
entire row for us maybe and and so so
the blue clothes thing is is that right
right now now now eventually the some
other technique might do that but i
think the to me the over approximation
generally means not just computing the
abstract post via predicate abstraction
by pinner rating iterating to a fixed
point well yeah but ultimately we get
ultimately we gotta fix fun come on it's
easy if you're doing far far enough if
you saw it last predicate instruction or
not if you move far away from this then
you'd say all of those things that all
that they doing they compute a proof a
whore style proof of correctness of the
program right no matter which way you do
it and the first iteration of predicate
expression do you have an under
approximation or no
translation
no this assault sent you to read the
poster and so you only an upset of the
control tips I want so no no bebo does a
full reachable fixed point on the entire
let's do it let's say that you're doing
predicate abstraction so you had your
you just did leave psyche box justing
budging I've struck interpretation no
all right just think about your
iterating that abstract post all right
after a two-step see the abstract closed
do you know an under front solution or
ever processing so that's that's what I
don't want it's a discussion that I was
trying to prevent in the beginning and I
didn't succeed so when you look at this
techniques right and you stop a
technique at any point and you say i
have an object in the middle of this
technique what is this object and this
is a safe to think you could say is that
this object is a partial model of some
kind could be another approximation
another approximation of some it's a
partial model described some information
that you have so far and it is so
therefore it's both and if it's bounded
right if it's bounded it's under but it
could be associated as Charlotte blood
relations are absolutely so but what I'm
trying to promote here is the stresses
on the keyword driven so I'm saying some
techniques are driven by their over
approximating way of thinking and some
techniques are driven by the under
approximating way of thinking if you
pick any of these techniques and stop it
in the middle then of course what it has
is a partial model which is which is
neither another approximation another
approximation but if you look the way I
was I was maybe I won't go back just now
but the way I was presenting the two
approaches a cigarette or chant and and
the under approximating driven approach
then I would claim that what makes it
driven is what is sort of the most
computationally intensive box or do
other boxes work towards the sound box
or they just work on their own so I
could just stay well your honor
computing stronger and Turk ones are we
friends
alright you're computing stronger in
turbulence if you use more predators
your computing week or Interpol
insidious your practice so you're just
dialing the knob between strong and weak
interpolation strong call me buddy fix
my problem wait your song is looks fun
problem and everything well no the blue
part I run until I get the fixed point
and then the orange part they just run
on a bounded problem that I've generated
through the blue problem so it's not as
uh yeah right okay so that's right ok
there you're right that's something else
you know because they're you're saying
that so blue box generates an inductive
invariant that's maybe not safe the
orange one generates a safe set of
reachable states that may not be
inductive right then so that's the
interplay in one case you say what's
important in abstract interpretation you
say what's important is to generate a
set of inductive and inductive invariant
whether it's safe or not that's
secondary so you prove your widening
terminates you don't prove that you're
widening is safe whereas in an under
approximating driven approach is sort of
saying I want to prove why this bounded
version of a program is safe and then I
hope that this will become inductive so
that's a that makes sense or not is the
difference I huh I'm not sure I
understand why why one is over
approximating and one is under
approximating but it is it is it is a
difference if one is one is more eager
than than the other all right one is the
one that's going to you the one that's
going to a six-point and that's and
that's definitely right that there were
cases where that that's what you want to
do and you want to have some kind of
abstraction or you go to a first points
again the terminology sort of something
that made sense to us and it also made
sense to us but it sort of seemed like
it makes a nice story where you have
over and under and they come from two
sides and you combine them but perhaps
that's a bad terminology and something
else could be could be more effective it
really guided by to search the other one
is really guided by concrete example
search and then some general
to the one of the looking for a fool but
it's a proof / / approximation the one
on the Left never looks at the actual
program it looks at sort of an abstract
post what your predicates it's the pool
can be water rations whereas the one of
the right is really looking for come for
examples for which you have to complete
physical
yeah but I mean you can also think of
the differences being you know
essentially lazy emergency or deduction
and we're just saying you know I'm being
more eager when I'm taking a given set
of rules and I'm going to a fixed point
that's like sorry for the plain
statement
okay so here's algorithm if you really
want to know I don't really expect
anybody to read it but if you want you
can just want it to point out that
there's a there's this Explorer part
which is the function that expands the
control flow graph and there's a refined
part which is this one line and that's
the sort of more interesting part from
mind so that's the one I'll talk about
most of the rest of the talk so just for
the Explorer part whenever I show the
slides people often ask a question like
why do you go to a narrow state first or
what's the heuristic of unrolling the
control flow graph and what we've
decided to do is to use the weak
topological ordering and is there
anybody here who doesn't know what that
is oh ok so a weak topological ordering
is a topological ordering of the growth
of the nodes of the graph that also
indicates roughly where each loop starts
in it so for this graph this is the weak
topological ordering it's described as a
sequence of notes together with bracket
that indicate where cited the first
element in the bracket is a loop had and
then the closing bracket tells you where
this loop terminates okay the reason why
this is an interesting way to look at
this problem is that if you want to
compute a set of reachable states or
plastic interpretation instead of using
a work list you could do it in a
deterministic fashion where you go in
topological order iterating each loop
each inner loop until it converges
before going to the next one so here for
example the exploration would be you go
one two three four each rate for until
it converges then you go five six and
again to until this convergence and then
you go 17 and soon so you would end up
doing all the inner loops before you do
an outer loop
this but I knob creek interpretation has
this name weak topological ordering and
whereas the difference is that it's also
apply if you don't have reducible growth
so you could order a graph in the weak
topological ordering and the reason why
we picked this is because it gives the
deterministic exploration so it makes
managing things in algorithm a lot
easier but it doesn't have to be the
best exploration strategy okay so you
don't have any more questions and we'll
go to refine so refinement in our cases
back is based on Craig interpolation
that's a picture of Craig if you've
haven't seen him before so the crag
interpolation theorem basically says
that if you have two formulas a and B
besides that a and B is unsatisfiable
then there exists an interpol and I
that's implied by a and is unsatisfiable
together with be right and this is one
way to write it in terms of model
checking applications we typically think
about a and B being unsatisfiable then
the original trim it was a implies B and
you want to find something in the middle
I so that you can apply the transitivity
rule we know that we can build Craig
interpolant effectively from resolution
proof of answer this variability and
it's well known that we can use it for
over proxetil over approximate set of
financial reachable sticks so let's see
how it's used in mobile checking so I'm
just going to show you an example of how
it is used to have approximate ritual
states and now get to show how we use it
so if we write our I for the ISTEP of
the transition system and then we take
as a part of our interpolant the set of
initial states and are the zero time
step up to our to n steps and we'll take
be as a set of bad steps if a and B is
unsatisfiable that means there is no bad
execution
with n plus 1 steps and then the
interpolant is an over approximation of
reachable stops and then of states
reachable in n steps that does not
contain any bad stuff bad state all
right this is is that sort of clear just
from the definition of the interpolant
it will be only over the variables which
are common to the bad states and the
last step and it will be an over
approximation of a so it will over
approximately sell original state so
this is a picture so a is the set of
reachable states as in turbulent is an
over approximation of it that's
inconsistent with me now what we
actually using here is not this is just
how you would do interpolation to find
out a set of reachable states what we
want to do is given a pass in the
program build a horse style proof that
this passes invisible so we'll need more
than one interpolant and there's a
concept called interpolation sequence or
pass interpolation that does this and it
says something like this given a
sequence of formulas AI sides that the
conjunction of this formulas is
unsatisfiable an interpolation sequence
is a sequence of formulas I 1 to n minus
1 such that each I is an interpolant of
the corresponding traffic's and the
suffix and then if I pick any
interpolant it represents a prefix up to
k and I take the k plus 1 step of my
transition system then I'm going to
imply the next step the next interpolant
in the sequence so that's basically the
whole rule of the whore the whore proof
room it says this is the precondition
and I do this step I get into a post
condition so pictorial is this is how it
looks like we have this formulas a 0 to
a 6 that represent transition relations
we're going to get our interpolant
switch will be i0 to high-five each one
represents the prefix over approximates
the prefix and then we want to know that
the a 0 implies i 0 and we want to know
that a 1 and I
implies I one and A two and I one
implies I 2 and so on and so on and so
so if AI is a transition relation of
step I then the interpolant sequence
will be a whore style proof of safety of
that trees and this is the principle
that for example is used by impact in
order to build annotation of its train
rolling
and it is the same like you're thinking
about something so i don't know if you
have a question Oh thinking about that
talk about something else I'm sorry okay
maybe i said something that was not
quite sorry so this is the part where
that gets them an interesting part so
what so using pass interpolation we can
get rid of a single path but we have a
dog and so we want to get rid of all of
the class in the dog at once and to do
this we introduce this new concept that
we called a dog interpolation as opposed
to pass interpolation and this is what
what it is so what's what's in input to
the problem is okay so the input to the
problem is this graph the diagraph
together with each edge being annotated
by formula in such a way that along any
path a conjunction of the past formulas
is unsatisfiable and then for what we
want to get as an outcome is this
interpolation turbulence I that label
each node of the dog with a formula and
that satisfies the following two
conditions first if you pick any place
like say this one then this formula will
be an interpolant of any prefix to it
and any suffix from it so for example
here I to has a single traffics but has
multiple suffixes and I to has to be an
interpolant for each of the suffixes and
a second thing that we want is that if
we pick the formula say this one night
ooo and pick any formal of any edge then
they together should imply the
interpolant of the next node so here is
an example that for I to I do has to be
an Interpol and of pai-1 of pi 1 and PI
it because of the past 12 7 and also has
to be an interpolant of pi 1 and 2 3 6
and 7 because of that path and so on and
we also want this this local rule to be
true that for any an interpol and
together
the formula of an outgoing edge implies
an interplan the next name and I one can
be true an i7 can be focused if this yes
that's okay so the question is how do
you compute this how do you compute a
nagging turbulent so you could try and
maybe bring break the dog into a tree
and then try and compute an interpol and
every pass and then maybe conjoin
interpolant that came from nodes that
were joined in a duck or something like
this but that would not be efficient
because this would be linear in the
number of pass through the duct which
will be exponential in the neck so
somehow want to solve this problem in an
efficient way by efficiently I mean at
least linear in the size of that dog and
this is what what we propose what we
actually do is sort of not quite a happy
end for us because we reduce the dog
interpolation problem to sequence
interpolation problem with the step I'll
talk about this clean stuff that's
actually ends up being quite expensive
and this is something we're still
working on trying to figure out is there
a better way to to do to do this but let
me first explain to you what's actually
happening here so the way we reduce it
to a sequence interpolation problem is
for the following steps first we encode
this whole program the graph and the
annotations on edges by a sequence of
formulas a 0 and i'll show you how this
is done in such a way that every
satisfying assignment to this formula
spawns to satisfying assignments through
the graph we then get the sequence in
turbulence of these formulas so so i
want for example as an interpolant
between a zero and the rest and I to is
an interpol and between a 0 and 1 and
the rest and then this gives us almost
what we want I'll show you that this
also includes some of the variables
which we don't like to be in our
interpolant and we go through this clean
process that gets rid of those series
okay so let me show you step by step
picture it so then cod process
is really simple this is what if you
think about this problem for a minute
this is probably the first thing that
you're going to come up with the idea is
to introduce boolean variables one bull
and variable for each node in the graph
use the boolean variables to encode the
structure of the graph and then add
constraint saying that if you've taken
an edge then the condition on this edge
has to be true so if you look this
assertive what this looks like it says
initially we one has to be true as we
start at one and then if one is true
then 2 has to be true and the condition
has to be true and if I'm a 2 here I
have two successor side there I go to
three and then PI 2 has to be true I go
to seven and pie 8 has to be true right
because when I go to seven PI a test but
when i'm also going to do is I'm going
to do this encoding and I'm going to
order it in a topological order
according to the note to the topological
order of the nodes of the graph the
topological orders implement that and
whenever I'm at the node I've seen all
of its predecessors ready okay so now
I'm going to take sequence in turbulence
between this point this point this point
this point on this point okay so just to
show you what this means i'm going to do
an example of one in turbulent in the
sequence and try and explain what what
what this formal action has so say we're
going to pick this position a three all
right so say we're going to get I for
which is whether the force element in
our sequence so if we cut this
constraints here what happens if you
think visually what what is being
represented well the constraints up here
describes this part of the dog okay they
have the older pass together with all of
the edge labels and the conditions which
are left are the six it's effectively by
drawing a line in constraints here it's
like taking a dog finding a note in it
and then cutting it in such a way that
everything which is topologically under
it so either reachable from a joint
comparable to it goes at the bottom
everything else goes to the top and of
course there are some edges that cross
this boundary
cross this boundary means that in this
edge I'm using a variable say v7 and I'm
using the variable v7 here as well so
what I interested in is I want to get a
label of four but what will the
interpolant be well the interpolant will
be another approximation of this formula
that's inconsistent with this formula on
the common variables the described using
common variable so it will actually be
an over approximation of all of those
guys all right will be the side of
reachable States at four at five and at
seven that over approximate what you
could get at seven from here add three
from here and it had four from here and
at five from you and this is the
variables we want to somehow get rid of
and this is our clean stop getting rid
of those variables and it's very ugly
and it's very expensive so instead of
looking at the formula let me try and
explain what would that mean so if you
look at this formulas here what you get
how does interpolant look like well I
deal it will look like a clean formula
that will say v7 is true and some
constraint about 37 or before is true
and some constraint about before or with
5 is true and some constraint about 35
all right then if a formula would have
been in a nice clean form like that you
would just throw away the the seven and
five parts and you just keep the four
part but that's fairly easy to do even
if a formalized in a strange state
because we can just substitute truffaut
before false 47 and b5 and simplify the
formal but another part that we're going
to get is that any variable that say
only in scope of this location according
to interpolation could appear in here
and it does and it's often appears
inside here in the form of some
technology it can appear there in any
meaningful way because this has two over
approximate this other states reachable
here this variable is
this culprit cannot be constrained but
it can appear in psychologists and very
strange ways like this and the only way
to get rid of it that is actually sound
is to universally quantified out and
this is what this clean step is it says
substitute some variables by true and
then sometimes we substitute some
variables by false and then whatever you
cannot get rid of quantify things out
and this is where the big bottleneck of
this procedure is because even so we can
apply various heuristics to try and find
technologists and get rid of them in a
better way than by just giving it to
quantifier elimination procedure at the
end of the day that's what we do we go
to the three and we ask you to quantify
whatever is left out and in practice if
the algorithm ever gets to this point
that's more or less means we lost so if
we ever need to go to this tree and ask
for a new quantity for elimination
problem and the problem is not very very
quick then it's typically means it will
become gradually really really slow in
this situation the next one and then I
will not converge okay so yes the
samurais this whole procedure so we
start with a dog where edges are labeled
by formulas we encode the dog we encode
the dog in using this extra variables
with sequins interpolating sequence in
order to get the initial guess of the
labels and then we ask wanted for
elimination to make the labels what we
want so we use a single call to an smt
solver to do the refinement but we do
have the quantity for elimination stuff
and in principle I know how to phrase it
so I have we have a technique now so it
doesn't use quantity for elimination but
requires more empty calls and in
principle one can prove that you don't
need the additional smt calls that is
all of the information that you need is
in the initial proof but in order to do
this you need to sort of open the
interpolating procedure
and start dealing with it that has
changed the interpolating procedure
itself whereas so far we've been using
math SAT as a black box sort of fitting
things into it and then extracting them
and massaging them ourselves so this is
you find a natural we start with blue
label's we mix orange labels we continue
the labels of blue and orange labels how
many orange labels you have you want
will call under approximation driven how
many blue label's you have that's
another we call / approximation driven
and you controlled algorithm by having
more or less of those things right now
we don't put a lot of effort into it so
right now the heuristic that we use is
we use orange everywhere and then glue
it looks great so we don't we don't we
don't we do exactly mean exactly this
well so you were saying that you have
some some novel uses the choices you
could say don't restart exploration not
from the last place you left off that
got broken but restarted from other
places and we haven't we haven't tried
that we always research exploration from
the very bottom right so when you use
predicates to compute your view blue
label's how do you decide which
predicates to actually want to use we
use all predicates from the predicate
obstruction but then we use we often use
bulan predicate obstruction as a
cartesian product and obstruction as
opposed to movements or something that's
inexpensive to compute but we've really
been concentrating not on not on this
heuristics yet but extending this
further into other abstract domains I'll
mention a little bit about that so so
what I've told you is about you for sort
of as an algorithm but there's also
another story of this which is you for
the framework so this whole thing is
built on top of llvm as a front-end it's
publicly available including source code
so we'd like people to who interested in
this to maybe who interested in
different heuristics to try them out and
help us in terms of the architecture is
fairly straightforward we start with
allow the am front end we use llvm
optimizer in order to massage the
program to make it simpler for
verification so for example we don't
deal with memory at all we only deal
with integer programs but llvm optimizer
does pretty good job at inlining lots of
things so not just in lining functions
but also in lining memory reg memory
accesses into registers whenever it can
and then we build the cut point graph so
it wasn't apparent here but we always
work at the representation of a program
where a single edge is the longest loop
free pass instead of just a single
statement and we call this a cut point
graphics a control flow graph
representation and then we build the
abstract reachability graph and while
this is happening you can pick a
refinement strategy UK which is several
ways to use this dog interpolation
procedure you get to pick what abstract
post you want and we support predicate
obstruction but also now some of the
abstract interpretation domains and then
the expansion strategy which is how far
back of course you want to go and we use
these three and maths out together we
use these three mostly for
satisfiability and for simplifying the
problem
and then when the problem is simple
enough i use Mossad to generate the
interpolant to extract an on-set cur oh
so we found out that as the problems get
larger using masa to directly extract in
turbulence is just not visible so what
we do is we had lots of assumptions to
check with assumptions minimize build
the minimal unsatisfiable subset and
then take that part and give it to
Mossad to get interpret do you try to
meet so we don't necessarily get the
minimal support so what we actually do
right now have several heuristics being
implemented which we don't use but what
we actually do right now is we do it
three times so we say you put
assumptions everywhere check with
assumptions and it comes back and remove
the assumptions which became false
remove the sub formula that became false
we'll do this again and do it three
times and then anything about how much
or you get
three times now but it can give you that
I don't remember of any sort of house
try they should really talk to him so
you tried a few numbers and then three
stain okay so I'll just want to show you
some numbers just to see to show whether
the sinks work on it and sort of the the
takeaway point is that combining things
are good but we don't have a silver
bullet so we don't know how to combine
things that always works and so what I'm
going to show you is experimental
results for the following configurations
we have something which we call you d
which means you never have blue label's
you always use posters come true most
impress eyes one we have OD which means
you always restart from the very top so
you compute the orange labels and you
just take the predicates and restart
from the very top and you either use
creative in predicate obstruction of
bull and predicate abstraction and again
the abstraction is always over a loop
free program statement so even the
process of generating a predicate
obstruction is quite expensive it's not
a single simple statement and then the
two combined one UFO combined with
Cartesian and with boolean we've used
what we validated the song as a software
competition benchmarks from last year we
didn't compete because this work was
done for tacos and so the deadline for
the work and the competition was at the
same time and we didn't make it we also
have some of the pace mark pacemaker
benchmarks that I worked on before and
we've compared to just sort of compare
it with an existing tool the only one
we've compared it against is Wolverine
but since then we looked at for example
what cpa checker is doing which is the
winner of the competition and we do
quite well converted so here's the total
numbers and they're not very meaningful
but people often like to see like what
happens in total so you have that the
Cartesian predicate obstruction seems to
be the best as in it takes last time and
it solves more instances but the
benchmark is very uneven so it's very
hard to sort of look at the global
number I know what's a good technique or
not
so if we go deeper and look at some of
the examples and if you you've probably
seen this examples before either in the
competition or from prior work so this
is a token ring protocol and this is the
ssh server examples from blast that
sagar jackie has done a while back that
encode various handshaking protocol
verification part and so here we get
that as promised as you go down the
predicate obstruction part the number of
refinement goes down so the mole
predicate abstraction you do the last
refinements you have doesn't mean that
your time gets smaller but at least we
have that and then in terms of time it's
sort of a little bit all over the place
so sometimes like here it's good to not
do any predicate obstruction because
predicate obstruction just takes too
long and so you die in the first few
iterations and sometimes it's really
really good sometimes you just get the
right predicates and you terminate very
very quickly whereas simply unrolling
things and hoping that the interpolant
will converge those work you know and
I'm having just first covering at all
yeah okay i'm not sure exactly how you
would apply it the first cover the first
covering is a heuristic that would say
if i have something that is not
inductive check what happens to be an
inductive loop invariant on the side
Shannon 20 and to impact and its first
for the piles based in Paris it's very
important but something I don't really
understand
whether it makes sense right job our
sort of intuition was the predicate
obstruction step would do this force
rather they will generate strong
invariance are in it for the one without
credit good at this but not really you
know this impact by itself is really too
true lazy and if you wanted to get it to
converge on boobs you have to go a
little bit more yogurt so yeah to know /
don't don't do that at all and then this
is a look at unsafe so here of course
sort of what you'd expect again the
number of refinements is the same more
refinements here less here but it's hard
to see in this table because it doesn't
solve a lot but what you see here is
that if you have unsafe examples for
places where there is a counter example
then unroll ink is great because you
just under all give it to an smt solver
and that's it you don't waste any time
building something that you know will
not work so the positive part is that we
know that this note that we have a
useful that you could configure the
system in such a way that it solves a
particular example faster they're not so
good news is that only if it's good news
for our future and we don't have a
silver bullet that says do this
configuration so this is how you infer
them from a problem how any of those
things so this is more or less the
observations little
switch if we find time that would be so
what we find sort of the best strategy
just by looking at the numbers it seems
that you should try a couple of
iterations with just being very lazy and
then gradually bring predicate
obstruction because that's the cases
where you do really really bad if there
is a very clear counter example which is
at the very few iterations then you much
better off just unrolling and finding it
and then spending time building to your
set of ritual states so there's a lot of
related work to this is just highlight
some of the tools so of course ken has
this impact and impact to tools there's
a tool Wolverine by Georg Watson bar and
it implements an impact algorithm but
with a bit a level precision we've
compared to it we do a lot better but it
doesn't mean anything because we not
beat level precise we use a different
solver so that doesn't tell you anything
about the underlying techniques and
there's also a paper that came at vm chi
this year called ultimate which is
impact with large block encoding which
is in some sense very similar to an
instance of our system but they don't
have the predicate obstruction print and
they enter the refinement that they do
is still based on each individual pass
as a posture whole duck we've also
looked into interprocedural version of
this so we have a tool called whale at
vm crime that would use Interpol ins but
in a slightly different way to try and
get procedure summaries we haven't yet
combined the two together but that's on
our to-do list and there are several
small sort of technical issues because
the interpolation problems that we solve
a slightly different and but but they
should play well together there's also a
work coming up from natasha natashas
Regan is group on again using
summarization using interpolation to get
function summaries their goal is not
really to try and prove programs but
rather to try and prove that two
versions of the programs are equivalent
to some extent so they call it upgrade
checking it means
if you take a nap program and you've
changed some of its functions you want
to reuse the previous proof to prove
that the new version even with changes
is still safe so the difference is that
they don't look for the inductive
generalization part they only do a
single interpolation problem of course
so this was in the beginning of the year
I think we've collected this list in the
beginning of the year and there's more
recent work that's also related so there
is in this year's calf there was a
software model checking I see three
bites imagine Grigio and is really very
similar it's a large extent with what we
do in a sense of reusing the orange
label that's sort of the key intuition
in there I don't quite agree that
they've extended ic3 to software but it
leastly bring the orange tables and they
also show it's quite effective there's
work by can undo ality which is does the
interprocedural version of this problem
and Nicola has generalized probably
directed rich ability which is sort of
opens all of this happens as at least
one way I view is that it says let's not
just get interpolant from a proof let's
force the solver to work in such a way
that we get the interpolant wound and
there's several other papers here which
is sort of the space here because
they're related but maybe not as closely
related there's work by a revolt rancho
del on solving recursion three horn
clauses and this is really really
similar to the dog interpolation problem
we have so actually probably a
generalization of it but unfortunately
I've tried reading this paper I don't
understand it if anybody here can
explain it to me that'd be that'd be
great because maybe they already solved
all the problems and then there's this
whole other line of research and I put
one paper here by nishant which comes
from sort of program analysis
perspective but it's really solving the
same problem and in program analysis
perspectives they would say if I want a
reason about a program with lots of
functions while I can inline all of them
but that blows up so I want to have some
sort of strategy of how to inline
function and maybe
use the solver to guide me how to inline
back and first and so they have a paper
at curve this year where they do propose
a particular strategy that seems
interesting but they do it completely
outside of the solar it's a really from
program analysis perspective you build
bounded programs and then you feed them
to the solver and then the solver gives
you results in based on that you decide
how to unroll the boundary program
regular this really modular theories
it's not that thing so that's another
paper that could have been included in
this list yes yes so they have something
that they called stratified inlining yes
right so that's that that you first in
line just using uninterpreted functions
and based on satisfying assignments in
line forward the alternate part says
that you don't have to start from Maine
start from close to your assertion and
then go out and then and also use in
turbulence to learn summaries of
functions that you've already seen and
use those instead of instead of the
actual bodies if you can so if I'm
missing something let me know i'm sure
i'm missing a lot of more recent work ok
so if you interested so this is sort of
towards then if you interested in what
you for is is a search of the
nutritional label that's what you get in
the box there is some obstacles
irritation now which i haven't talked
about there is some verification
condition and cutting some sugar lips
I'm interpolation it's all mixed
together you apply it typically for one
second and it may work
you make it young so check it out talk
to us look at the papers so just to
conclude sort of our past present and
future so we started this work with this
tool called whale we're really just were
interested in extending Interpol and Stu
interprocedural analysis we've built the
tool it worked okay but we couldn't find
lots of problems for it because there
aren't that many problems with recursion
that we could get our hands on and so
but what we've invented and there's this
concept of state transition in
turbulence which is i think is still
quite an interesting concept to explore
further and so we moved to some other
domain we said okay well if we don't
have recursive programs we had the
Steelheads de link with dogs and dealing
with large with cat bone grafts and we
said well let's look at the software
competition bench works and what we can
do with them and this is where you fall
came from and after working on that and
looking where predicate abstraction
helps it doesn't help we said well we
should really bring up strict
interpretation into this picture as well
and so now we have this new work that
will appear in sus it's called winter
winter stands for what this VIN to stand
for verification interpolation
and maybe I'll scan at some point tell
you more about it I found out it was a
big surprise so what vinta is really the
meaning of inter that I knew is about
from the Philippines about right so you
have you have a whale inside the ocean
the winter on top and and you for hmm
the colorful boat was like sale but but
this is not a logger so apparently in
Telugu which is an Indian dialect vinta
means novelty or surprise so if you type
go to any translation and you say
translate novelty into Telugu you get
this this is their script and so
apparently that means center so what
wind tides to the picture is using
abstract interpretation which means we
need to figure out how widening fits
into the picture and we have an
interesting story there and also it made
our interpolation problem so much harder
just because after interpretation would
unroll the control flow graph much more
and it let us sort of rethink how you're
using information so if you look at here
we generate orange labels and then blue
labels and orange labels we never mix
the two labels together and so that
forced us to think about how to do this
and we have this new abstract
interpretation guided way to do Doug
interpolation basically where we would
take the inductive but not safe in
variance and bring them into the
interpolation problem so that the
interpolation is not give me the reason
why this program is safe but strengthen
the inductive invariant that are not
safe to be safe but may be loosened
activist and that was a lot more
effective in that in that space and
that's it
we're not likely be careful okay thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>