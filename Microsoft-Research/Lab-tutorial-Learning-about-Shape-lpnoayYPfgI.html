<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Lab tutorial: Learning about Shape | Coder Coacher - Coaching Coders</title><meta content="Lab tutorial: Learning about Shape - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Lab tutorial: Learning about Shape</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lpnoayYPfgI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
I think I'll declare as corot so welcome
to the the August lab tutorial I'm Nick
Benton for those of you who don't know
me and I'm the new Tsar for the lab
tutorials so after after today's talk
you will all be inspired to come up with
some talks that you would like to give
in this slot and when that happens do
come to me and and and discuss the talk
that you'd like to give because it would
be great to have more internal talks and
keep the frequency up so I'm extremely
pleased that today we have Andrew
Fitzgibbon he's going to give us a talk
on learning about shape and as he's a
local boy I get away without having to
do any great introduction but for those
of you who don't know Andrew his
principal researcher in computer vision
and winner of numerous prizes which it
would only embarrass him if I were to
list so I'm just going to hand over to
Andrew thank you very much so I would
like to talk a bit about some tools that
we use in computer vision and particular
tools we use for describing the shapes
of 3d objects so I'm also trying to
going to try and teach you a little bit
of maths but a very little bit and i
hope i'll give you a picture of you know
what are what the day-to-day life of our
researchers is there is some maths in it
but it's not very complicated they work
i'm going to talk about i'm going to
show examples of work and i'm going to
talk about work that I did with lots and
lots and lots of different people but
there are a few people in particular I
would like to sort of call out who
really helped me along this path mojito
was my PhD student at Oxford with whom I
continue to collaborator Microsoft Tom
Cashman was an intern who introduced me
to one of the key tools called
subdivision surfaces he's here somewhere
Richard Stebbing was another intern and
John Taylor's former intern our
researcher and all of these people have
helped me in some way to understand this
space
so what does a computer graphics
computer vision computer scientist mean
by shape well one thing I might mean by
shape is the stuff that's underlying the
stuff that's going on underneath this
computer graphics simulation and as I
move a slider around maybe I can visit
the the 3d meshes that a sequence of 3d
meshes that describe the shape of the
human face and this was work done as you
can see a long time ago 16 years ago
which first introduced us the idea maybe
that we could have spaces of 3d shapes
that we would we would we would learn
from data more recently people have been
able to build spaces of 3d body shapes
so by taking hundreds of 3d scans so
they get to get a person or several
people each to stand in front of several
Kinect sensors connected ensis didn't
exist at the time but the principles
existed so by getting hundreds of people
to stand in front of multiple scanners
they could again build a tool that would
allow them to visit the 3d shapes of
variety of 3d shapes and different body
shapes and different poses not directly
related but using some of the the same
tools is work we did just last year
where we took input from a kinect if we
ran that input through connect fusion
even though this person is only moving
is not moving very non rigidly if we ran
it through connect fusion we would get a
big mess but by using again some of the
tools i'm going to talk about we're able
to build a rigid model of the person
despite the fact that the person is
moving non rigidly in the input sequence
and again using the using the sorts of
ideas that i'm going to talk about
before that again using some of these
ideas I don't know how many of you seen
this but I think I rarely get tired of
it we did some work where by using the
Kinect body scanner to track the the
person the person could lock themselves
on to a big soup of polygons which here
the super polygons looks like a chair
and then you know create amusing
nations of the chair you can also apply
it to any mesh so the more literary
minded above you among you might be more
amused by walking bookshelf and if that
doesn't work you can get your friend to
do the back part and the two of you can
work together to to animate a horse so
that's a good thing and then work that
we're doing at the moment or what we've
been doing recently but sort of a
current areas can we model video so can
I take a 2 D flat 2d video with just
sort of color pixels no connect cameras
anywhere nearby and can I turn that into
a 3d video by taking downloading a model
of an Impala off the internet sort of
mapping it onto the 3d video and
learning that learning the motion look
we can and then practically this is a
diagram from another paper from this
year can we determine the space in which
hands live can we learn the space in
which hands live so that when we get an
individual hand we can pick it out and
track it and then when we could track it
will be able to make cool user
interfaces like this one where the tract
hand picks up 3d objects manipulates
them and you know paint stuff and so on
so that would be that would be great if
we could do that and one of the tools oh
I didn't check my mail sorry Danny ed
yeah well we'll be able to do that when
we have a better model of shape all of
the shape models I've described so far
have been constructed our hand model has
I remind me of the numbers but you know
50 people with sort of a few seconds of
connect video each the human body model
is hundreds of 3d scans very
painstakingly mesh together in the face
model something similar so I'm going to
present the last thing I'm going to
present is the hardest problem and yet
it's the one Tom Cashman and I started
on which is what if I had nothing what
if I wanted to build one of these shape
models these shapes paces how would I do
it
and our idea was that we could just type
the name of any set of objects of any
category of objects that we thought of
into a search engine the search engine
would give us back some pictures of that
category and you know we would look at
the pictures and if it gave me loads of
Miami Dolphins then I decided was that
the thing I wanted an editor them out so
somehow i define what i want simply by
picking the pictures that mean the thing
i mean so these pictures meant the thing
i meant when i typed in dolphins and
what we would like to do is then recover
from that set of pictures the same thing
as we saw before a sort of a set of
sliders that would describe the shape
that was represented in there so this is
a much much harder problem because
instead of 200 dense 3d scans we've got
32 flat 2d images but by using the kind
of tools that we that we now know about
we were able to so we couldn't solve it
from nothing but we were able to take a
standard dolphin and and learn the ways
in which you could change the shape of a
standard dolphin that you downloaded
from the internet to match to match the
set of input images so that's in some
sense a long-term goal would be to do
this from from absolutely nothing but at
the moment the tools we learned there
really helped us with with various other
problems and the hand tracking is as we
learned today it's going to work much
much better ah we told it eight you told
yes no um my what uh one slider will
probably have done scale in fact you'll
get a little hint because later on we'll
see the optimization in progress and it
actually goes through increasing the
number of sliders but my answer for all
of these problems will be there would be
some other parameters as well which are
sort of how nobly is each individual and
then how much variation is there among
individuals and my answer to all of
those parameter setting questions will
be look at it and pick the ones you like
better right because or it'll be go to
your downstream application whatever
that is and then pick the value I won't
try to use any statistical mumbo-jumbo
to produce
k equals 8 no you just say how many so
you try to try tree ah try three that's
tough for me see if it works if you
don't like it add another one if you had
too many it'll all go crazy so you go
back to the one that was sort of
unsatisfactory but not crazy right so
that's fine so if we know about shape we
can do lots of stuff let's see what I'm
going to mean by shape and what we what
you know what you shall think of as a as
a sort of a functional or a description
of shape that we can use in a computer
program and essentially i'm going to
look at three types of representation of
shape they're all really the same but
it's kind of a lift we're going from
easy to more difficult so many of you
will will have a good idea of how to do
this or know about this so my first the
first type of shape I'm going to talk
about yeah thingy sorry mm-hmm working
yes so the first type of shape I'm going
to talk about is a function where we
have an x coordinate along here and a
y-coordinate along here and we have some
equation y is a function of X and that
describes a certain type of shape that
must live along along the real number
line the second type of shape I'm going
to talk about is is curves so a curve is
a function which takes a real as input
and outputs 2d points ok so here's an
example of a curve that takes real
numbers let's say between 0 and 1 and
outputs X values Y values and plots like
that and then a surface is a function
that takes you to real values U and V
outputs a 3d point and this example here
costs sign and V returns the cylinder ok
so these are three sort of definitions
functional definitions that will give us
different types of shape but I'm going
to explore them one at a time really and
essentially what i want to get at is how
do i so now you have a picture of what a
shape might look like it's a function in
the computer what I'm really going to
have to do is take these shapes and fit
and fit them to some data I
that's when the computer graphics
becomes computer vision essentially when
they get some data from the world and
make the shapes match it so I'm going to
give you a little quiz ah because you
love that sort of thing um so I'm going
to ask you so I'm going to tell you
we're in this domain of functions so I
want a formula which is of the form y
equals something with X's in it which
describes these shapes does anyone want
to volunteer me a formula for the left
shape Fineman good choice good choice
yeah you want to volunteer a formula for
the middle shape did I hear an x squared
yeah I like an x squared and does anyone
want to volunteer me a formula for this
shape X minus X cubed better than X cube
X cube good generic one x minus x cubed
any others some people might say y
equals I don't know like maybe it's a
bit of a sine X oops sorry plus you know
3x minus 2 or something via sine X plus
a line you don't think it is all right
anyway you're all right anyway you're
all wrong and because today the formula
for this shape is y equals if X less
than let's say zero return X plus 1
squared else return X minus 1 squared
and I'll have to add some constants
that's probably a minus one thats probly
a plus one I haven't worked that out I
haven't checked even that they match at
zero do they match at zero no they don't
so so that's that's not edit any
constants do they match at zero now yes
they do do the derivatives match at zero
yes they do all good okay right okay and
why is this a better why am I good
claiming that this chapter on the right
is a better description than
x cubed right which is because as you
know there are polynomials that can
model any function so any function can
be expressed as a linear combination of
you know increasing X cubed x forwards
or next x 25 and the reason I'm saying
this is better is that this is going to
end up being much better behaved in lots
of way in lots of ways because I'm going
to do a generalization of this which is
if X is less than zero do that else if X
less than 1 do that else oops sorry
terrible writing else lalalalala and
this is what I mean what i meant in the
abstract by a piecewise function i'm
going to define my function with ifs in
it branches in it and it's going to make
it look horrible if you're used to the
kind of matic mathematics which has
closed form solutions and lake oh yes
it's terrible isn't it because it's a
it's it's all terrible yeah oh thank you
thank you yes and the derivatives were
right branching ah right well I didn't
say it there were any yet right but what
we should probably do so let's try and
do this properly what we should probably
do is make sure that at least the bit to
the left of 0 and the bit to the right
of 0 touch each other right that would
be a good thing and then we should also
make sure probably that the derivatives
are the same on both sides oh i see
sorry that yes it could be but that is
where things get a bit complicated and
it's best to make that as simple as
possible and it doesn't hurt too much in
fact you often don't even vary the 0 you
could you could make the 0 parameter or
but young Zuzu why don't you stop one
little if for each points
very good very good right so because if
I did that for every point really the
reason I'm doing this is because I want
to be able to predict what's happening
down here let's say or even in here
right so I want to interpolate or
extrapolate the point so yes so I'm
going to control the complexity of my
model by limiting myself to a small
number of segments so if i have a
thousand data points i might say i can
probably afford about ten segments okay
and that's a way of controlling you know
do I over fit or under fit with
polynomials I could do that by keeping
the order of the polynomial small but
they if I keep the order of the
polynomial small it's just not as
satisfactory a type of control which i
hope i will explain same as you have and
the degree the polynomials then you
could you could indeed so in the end we
will end up with about 500 segments and
fourth order polynomials for dolphins it
will and it won't matter it will in a
funny way and it'll turn out not to
matter yeah and if we won't have to do
not point variation but if we do and if
you know you know if you're asking
because you know that there's a thing
called variable not points we won't need
to do it but we could in the same way
I'll move on even though this is just to
give you a hint of what piecewise is and
then we'll too much of a hint obviously
right so I said there were a couple of
candidates for so this is more generic
form where I've got these parameters
under the curves and I said it could be
that or it could be a thing with an e
finish this one definitely oh this was
still isn't right blimey there we go so
that's right okay so what we're going to
do is going to take some shapes and
we're going to try and make the shapes
meet some data and when the shapes you
know are happy with the data will have
something useful with have something we
can use to extrapolate with okay so a
shape is a function it's a function from
here I've written as data type real to
data type real but
in fact it's very important that shapes
our are sort of a finite extent all the
shapes I drew were not I didn't draw an
infinite line and I didn't drawn in from
the parabola and I didn't draw an
infinite cylinder so in fact all our
shapes all these functions are mapping
from data types which are subsets of the
real so interval I'm just going to let
be a data type which is real numbers
between zero and one and again back to
your question about do any you know is
they are these fixed data points they
are and it's not going to matter so i
can i can pretend every curve is a
mapping from zero to one just by scaling
all the parameters for the bid i'm
interested in so they live in 0 to 1 so
the curve is a mapping from an interval
to 2d the surface is a mapping from
interval to 3d thank you ah yes it
should be what I described was an
infinitely tall cylinder it's still good
that I the interval for you because I
didn't visit the same points an infinite
number of times but yes he should have
been an interval thank you I remember to
fix that later right so we looked at
these functions y equals a function of X
and I try to argue the piecewise is
better without really telling you very
much why um now I'm going to look at
curves and I'm gonna look at curves for
oh it's gonna be at least 15 minutes so
I wrote a curve I said it was a function
mapping from a single number T and what
happens is maybe this corresponds to t
equals 1 we could try and do stick in T
equals 0 here that'll be the point 21 21
there we go t equals 0 okay I'm going to
stick in that worked fantastically well
so let's stick in T equals one that'll
be 31 that'll be that point do we agree
all right I know you can't see these
axes sorry that's 230 what so as I move
T equals 0 as I put in different values
of T my curve is going to move around
here if you like you can do t equals a
half and find out where it goes but it
seems a bit messy to me so a curve is a
for loop for T equals 0 to 1 it's on the
step size it draws out these points in
our two
of course stick it you know calling it a
function is not very is not very
computer science 101 E and so I'm going
to make a curve a data structure and
it's going to be a data structure which
has which has this the abstract data
structure curve is defined by only one
thing to begin with which is a method
called eval which again takes a tee and
returns a point to d so the conic curve
that we had there so specific type conic
which is an instance of a type curve has
the avowal t function which right here
which contains the function that I just
just drew out as I moved across here and
of course the reason I'm doing this to
make to make a sort of subclasses of
curve is that what I'm going to be
dealing with all the time is a
parametrized curve and a parametrized
curve has I intended to make this a has
a vector of numbers in it such that
different settings of this set of
parameters theta so in this case it's
six numbers give me different instances
of the curve class that I'm looking at
so the curve we looked at a minute ago
was a T squared mine + 0 TS plus 2t
squared minus T plus 1 and that was an
instance of this class conic that that
we were going to try and recover they
will be the sliders in this case they'll
be not very good sliders you'll change
one of them a little bit in the whole
thing I go crazy but later there'll be
good sliders but yes thank you these are
the sliders fita big cedar or the
sliders so I told you curves had only
one method on the avowal which takes a
tee and gives you the 2d point but there
are some other very important methods
when you're when you're going to
introduce curves to data and I'm going
to talk a little bit about the
implementation of those methods and the
sort of implications that it gives for
for what we might want to do so a very
important method is to be able to take a
point in the world so here's my curve so
this blue thing represents the curve an
instance of this class and given some
other point in the world
isn't on the curve X I would like a
method which just tells me how far it is
from X to the closest point on the 2d
curve equivalently you might imagine
supplying a function closest point which
takes a point in the world X returns me
a 2d point which is this blue sort of
blob here which is the closest point on
the curve and you would implement that
function for your curve and you know if
you do it well that might make other
things easier clearly one of these can
be written in terms of the other so the
distance function could be norm meaning
just 2d length of a 2d vector length of
the vector joining X to the closest
point so we make me am it may implement
one or the other when we when we do our
work we may also implement distance not
in terms of closest point but by
literally by writing down exactly our
definition of distance so what is the
distance well I have made an anonymous
function here lambda T which for every
value of T around the curve just reports
me the distance between eval of T and
the query point X so this definition of
distance says call a minimization
function and I'll do a little more
details of what this looks like so this
is a generic function is this a higher
order function it takes a function in
and yeah yeah and it produces a number
out so it takes in this function which
measures distance from an arbitrary
point t to the curve it takes typically
these things take an initial guess that
means the t value to start with let's
say on this curve that happens to be
here and it doesn't really matter where
it is so it takes this function in a
t-value to start with and what this
function will do is do some magic and
figure out what the closest value is and
so everything up here is all the stuff I
already said it's getting smaller but
it's there so you can remember it this
was the function i wrote f of t is
vector difference between evaluate the
function at t in the query point the
distance is going to be minimized fi
forgot to give it an initial estimate
and here is a very dumb version of the
minimize function so the minimize
function starts with an initial guess of
tea that might be some point
here so that's T my initial guess it
computes the derivative of this function
f of T now let me draw F of T F of T is
not the shape of the curve F of T is
something else ok so there's tea and
here's F so let's pretend T equals 0
here and as T increases we move around
the curve like this eventually landing
back here at T equals 1 so what's the
distance going to do what it's going to
start this is almost as high as it can
be right so the distance is almost as
high as it can be at T equals 0 so we
start up here somewhere and it kind of
goes down we down to tea is let's say a
half and then it goes up a bit and
actually despite these concavities and
so on it's basically steadily climbing
again until T equals 1 and then it goes
down a bit for T equals 0 so I was given
this class curve but my laser pointer
actually I'm try and use this thing I
hate these things all right ok I can't
see I use this hmm ok so I was given
this abstract class curve I defined a
new function f of T in terms of the
function eval on curve and this is what
F of T looks like and what my algorithm
is going to do is start from an initial
value X T equals 0 compute the gradient
of the function which luckily as I
change it tells me basically this
function is sloping down here and
appeared to it towards positive x i'm
going to search compute the gradient of
the function i'm going to sorry the
gradient tells me it's sloping up that
way i'm going to subtract a little
multiple we don't know what this is
let's call a point or one of the
gradient and i'm going to try again
whoops overshot back a bit maybe i
should reduce alpha ok this is a
minimization function a gradient descent
function which tries to
find the closest point on the curve so
this is a terrible algorithm but it's
exactly the picture that you should have
in mind for any algorithm which takes an
anonymous function and slides downhill
to get the minimum value and what you
should keep in mind that although this
is a terrible algorithm the good ones
are really really good and when you try
to run them they will finish before you
even thought about getting a cup of
coffee and I'll show that in more
complicated examples in a minute okay so
what is my curve oh but the crucial
thing about this algorithm is this
little dash here because this little
dash says compute derivatives and
derivatives of this function f will
involve derivatives of this function
eval T and so you are going to have to
supply with your curve one more method
which is this method eval prime which
computes the derivative of the curve
with respect to the parameter T and
again I want to remind you that
derivatives are not that scary so that
one of the reasons we were always scared
about these piecewise things it's
because number one there are no
closed-form solutions to anything and
number two derivatives look scary well
it takes a while to realize the
derivative of this messy function y with
ifs and things in it is just if the
derivative of Y with in if in it just
passes through the if so if you think
about it why is in two parts all right
so why is some function in two parts
let's pretend they don't even match okay
so this is y of T and the derivative of
Y to the left of where they don't match
is just the derivative of the thing to
the left the derivative right is just
the thing derivative of the thing to the
right obviously the else branch at the
moment includes the case T equals a
which is just some nasty undefined
derivative thing but all the curves
we're going to use are going to make
sure that this doesn't have a
discontinuity they're going to make sure
the derivatives okay so it doesn't
matter which side you go on and that's
the thing that suddenly makes it all
easy so piecewise looks crazy because
you naturally think well anything bad
anything could happen
the constructions were going to use mean
that it doesn't go crazy and that makes
everything super easy yes yep indeed it
is indeed it is and yet you'll see that
we hit them all the time but they're not
like millions of them in typical
problems that we look at so often there
are only you know tens of these minima
so it's so to draw if you look at the
closest point problem that I've left on
the top right there there is really only
one there's a local maximum sort of the
other way away if my query point had
been here there's X then that's a local
minimum that's a local minimum right
pretty much anywhere I can draw a
perpendicular there's another there's a
local optimum sort of out here somewhere
right so that's not a local minimum as
you move away from there it does
decrease that's it but it's if you
evaluated the gradient there wouldn't be
very good it would give you give you a
zero you need a better algorithm so yes
absolutely there are local minimum these
algorithms and and you'll see that
empirically we don't meet them as often
as you might worry and that even these
guys that yeah there are other reasons
why they don't matter very much but it
is a crucial message yes these things
have local minima just because your
function has two local minima does not
mean you go off and do something else so
a thing people might do is say well
blimey it's got local minima i tell you
what i'll do i'll call it a circle and
i'll do everything with circles instead
of the real shape well that that may be
much wronger then you could say that but
then you're wasting an awful lot of
compute power and you know you're
heating up the data center in a way that
you may not be able to afford if you're
trying to track a hand on a surface pro
3 or you might not want to expand you
know if you're paying their energy bills
so yeah so don't do that don't do
simulated annealing if you've got
perfectly nice smooth gradients just
sitting there right
everything here is smoother only two
local minima will sort it out later very
important message okay so I'm going to
talk about what we do with these
functions where we want to meet some
data so here I have got some from the
world some points these might represent
points on a connects can use of
horizontal slice through some connects
can and the red curve represents some
shape that I want to use to describe
those points in the kinect scan and the
parameters theta the what you go on the
sliders the control the shape are the 2d
positions of these 12-6 control points
here so so the unknowns in this problem
are 12 of these guys right there's the
unknowns of my problem and what would I
like to do well I'd like to adjust these
12 guys I'd like to wiggle these chaps
around until the red curve is as close
as possible to each of the input data
and what I'm going to do is express this
as yet another problem of minimization
minimize finally the 12 control points
such that when i call the curve
constructor with those with those
parameters and then evaluate closest
point it is their small of bother sorry
distance right so i want to minimize the
distance from the adjusted 12 parameters
to all the points and i think you all
agree that should do a better that
should be nice right that should be sort
of a description of the data we in our
group have a brilliant trick for doing
this which I will outline to you I don't
think we invented it but it's a good
trick so the function and this is a bit
of I'm going to prove you a little
theorem it's only going to take about a
minute and you should all be able to
follow it we the problem I setup was
minimize call a minimize function so
arcmin means min
finally the curve parameters theta and
spit them back out the end return the
parameters that were the minimum so
finally the 12 parameters corresponding
to the six control points such that the
sum over all the data examples all the
2d points that I had so these these X's
here to minimize the sum over all of
those of closest point so min over T is
Val of tea etc I'm doing it more
generically because this is a trick you
can use when you're not fitting to data
okay so I want to find the treasures
theta to minimize the sum of closest
points minimize distance so here's the
trick you can use so just to think of
this problem typically you might have a
million of these points right to be a
million terms in the song and you might
have let's say very easy problem you
might have 100 or 500 parameters in here
so we want to optimize 500 parameters
million terms in the sum so let's do
some manipulations so the first
manipulation is trivial to computer
scientists this variable T is bound in
this expression it's not visible outside
this expression right i can change T to
TN and nothing happened T was like the
variable in the for loop for T equals 0
to 1 check all the values returned the
minimum value so I've done nothing by
renaming T to TN except what i can do
now is I can store them all in an array
and I can throw them all in an array and
that means i can do a minimization
overall the unknown t values at the same
time so some of minima still some of
minima no change there now a min of some
and there's a little mnemonic here that
you can go through a might come back to
this slide if i can remember its number
so slide doesn't tell me so i'm going to
tell you that this is true for a minute
and then we'll go back to it if people
really want to and what's happened I've
taken a 500 dimensional problem with a
million nasty terms in the sum and I've
turned it into a 1 million and 500
dimensional problem so basically a 500
dimensional problem has been turned into
a million dimensional problem and guess
which one works much faster the one on
the bottom works much much faster all
right so that's
good trick I think so one on the left
only 500 parameters really slow one on
the right a million parameter is really
fast that's your message okay i'm going
to show you this happening once then
i'll show you a picture of some dolphins
and then we can go home so I'm going to
start again so even if you missed
everything you can start again imagine
it is 1801 and um you are in Germany and
a guest determining existing eating one
anyway you're around there and a guest
planet has arrived called series and
some Italian astronomers have been
recording the azimuth and elevation of
this planet for a few months it is the
talk of the courts across Europe and
they've been recording using they're
reasonably noisy measurements the
position of the planet and then it goes
behind the Sun takes a little while for
news to propagate in Europe at this time
so it a plan is going to come out and I
don't know two or three months time
everybody wants to know where to stick
their telescopes in order to be the
first to catch sight of the new planet
so your job is to take the measurements
taken by the Italian astronomers and
somehow figure out extrapolate those
measurements and make a prediction
should I stick my telescope here or
should i stick my telescope here and for
the machine learning people the way this
competition works is that the queen is
going to pay you with a quadratic cost
depended on your distance from the
planet in somehow start parameter space
but no one really cares about actually
that's not what's going to happen you're
basically gonna win if your closest and
you're going to be nobody if you're not
all right so you really want to be close
so you are hair doctor Gauss um so you
set up your problem and you think i'm
going to win this kagal competition of
18 1801 I have got my 2d samples I used
exes before I'm using 2 s's now I've got
my 2d samples SN and I've got you know
their XY values they're not really their
azimuth and elevation and it's a bit
complicated but you know essentially
this is the
and better still I know the mathematical
model for what's supposed to happen I
know this thing this celestial object is
traveling on an ellipse so I have a very
simple job figure out the parameters of
the ellipse this is the true ellipse
this gray value are intersecting with
the circle of the Sun report your
position everyone trains the telescope's
Fame so it's going to be good if you do
it in the way i just described minimize
the sum of the closest points of the
thing to the ellipse this green curve is
what you'll get I language route I'm
going to tell you no one else is closer
this is a good curve to get be so if you
do it the way I described you know this
is what you'll get if you look in the
literature you will find a celebrated
algorithm from 1999 which has a closed
format stores called direct but it's
kind of like a closed form solution to
this problem but it's not to this
problem it's to a slightly adjacent
problem which admits a closed form
solution and this is the answer that
will give you although you will have
computed it very quickly it'll give you
this very bad answer okay so let's look
what where we are so what do we have we
have samples i said SN's 2d points n of
them let's say million I don't know when
they were captured what times they were
captured it's not that the clocks
weren't very good I mean o'clock
probably weren't very good but and when
I said it's a Lamaze azimuth and
elevation and it goes it turns into some
other parameters it means that the
mapping from the true x to these T
values is not it's not known so
essentially we don't know what times the
points were captured so each point is
captured an unknown time let's go to
devalue and I do know this model and my
model is curve of T condition on sliders
and I have six sliders here T 2 1 206 if
you're thinking about it you'll think an
ellipse probably has five slider Center
two axes and an orientation it's more
convenient to do six here it doesn't
really hurt so you know it's fine to do
six so I've got six sliders that I want
to find and I've got all these pesky
unknown T values but I know the formula
for the ellipse right so now I'm copying
all that information over here so you
can still see it let's skip that so
I wrote this again we have a description
we are going to define closest point
we're going to talk about closest point
and I've written it down here again min
over T of distance of sample to the
curve so this is all the stuff I wrote
in code earlier and what I want to do is
find the shape parameters the sliders
the minimize the sum of the distances
from each of the samples to the unknown
point look for N equals 1 to number of
points add up to sum of the distances so
this is our matlab code that runs pass
it into f min unk which is a
higher-order function that takes
functions in so that was the equation
for a curve here was the look at this
closest point function I just do a for
loop stepping by point 01 radians right
and accumulate the minimum pretty dumb
closest point function but you know it's
probably going to work okay then my
objective function is add up cause 2d
city is closest point is over here at de
Courcy which is up here and shove them
into ethnonym and at this point
typically after typing in all this code
you will be thinking you're got actually
year after typing in how many lines of
code is that 10 um you will be thinking
well own coffee break coming up you will
hit enter and immediately it will come
back this is kind of like a hundred
millisecond problem and matlab today
most people don't even type in the code
because they think i'm going to hit
enter and it's going to take all weekend
right so another key message is these
sort of anonymous black box functions
are much faster than you think so you
can use them to do all sorts of stuff
you do that parade you've predicted the
ellipse so that was really good and then
here's the thing we just solved the
problem using know mathematics no
cleverness no nothing we didn't do
anything clever and the solution is fine
perfectly accurate and the only thing
that's wrong with it is that it's slow I
wrote a you know really expensive inner
loop I pass it into an anonymous thing I
didn't compute any derivative so how to
do six times as much work to compute the
derivatives but really the only thing
that's wrong with the algorithm is not
that it's mathematically an elegant it's
not that it's you know hockey it's just
that it's slope and
now what do people do people think right
I'm going to make it faster and they
come up with all sorts of little
strategies to make it faster um the
strategy that they most often come up
with results in the algorithm on the
left the strategy that I would recommend
results in the algorithm on the right I
will repeat those this is wall clock
time of these things converging this one
on the right of slope down 10x so the
strategy that most people come up with
is unbelievably slow right and what is
that strategy I'll show you that's right
this way this is Charlie to speed it up
it's a strategy to solve it I guess they
think they're speeding it up right sorry
I'm not over yet yes though people
people go back to their original problem
which is at the top minimize find
theatres to minimize the sum of the mins
over the tease okay so they go back to
the original problem they say I'm not
going to optimize the inner loop right
that's micro optimization I'm going to
back and have a think about what I need
to do so what they observe they have
some things they observed that um the
Thetas over here appear linearly so my
function has this form of a big matrix a
times a vector of unknowns and that
means that if I only knew the times the
tease I would get this in one shot one
linear solve of a tiny system Oh easily
so if I knew the tease I would easily
solve this chicken and egg but I end up
with a chicken and egg problem right if
I knew the tease I can easily get out
the teachers and given the theatres that
means given the be given their lips it
turns out there's a fourth order
polynomial you can derive their will
give you each of the tease so both of
those solutions you get in close form no
searching no nothing just you know
absolute close form solution to each of
the two steps solve for the Thetis off
for the t's right and that is the
algorithm that ran unbelievably slowly
right and why is it running slowly it's
running slowly because the guy on the
right the lsq nonlin is able to
simultaneously very the teasin
you're going the left I've got the
current theta well guess what
everybody's pretty close to their
closest point already so they're tease
aren't going to change very much so they
don't change very much and then the
thing is don't change very much and then
the t's don't change very much injustice
worse and worse worse of course and you
can see how much worse and worse and
worse and worse it gets by doing a
convergence plot alright so this plot is
saying the error on the left is what is
the distance of my samples alright so
that's that should reduce low is good
for that note the x-axis right is long
time right so you know whatever you know
milliseconds seconds days weeks
millennia okay because this is a super
easy problem if you're solving a hard
problem things that this is literally
you know weeks years decades um so what
happened d ah the algorithm that one
would think of start off okay right this
is kind of linear convergence
first-order convergence still not ideal
you would want to be doubling your
number of significant figures rather
than adding one each time start off
doing that and then around here it just
gets unbelievably slow how slow the
difference so a typical way you stop
these algorithms is you look at the
current iteration you say my function
value is 0 10 to the minus 1 point 3 2
or whatever and then you compare it to
the next step so at this point the point
remote where the cursor is the
difference between successive iterates
is 10 to the minus 13 all right so you
think this is definitely converged as 10
to the minus 13 every step I take
nothing happens at this point I started
just doubling I started plotting dots
only when the initial iteration count
doubles that's why this changes so
around here the difference between
successive function values is 10 to the
minus 16 so it's within machine
precision you compute two successive
function values they are exactly the
same all right and yet you should
continue on why should you continue on
when you can see that this curve is
still dropping right so here function
values 10 machine precision apart still
function value is dropping ones that
mean that means the theatres the shape
parameters on the T's are still changing
but the function but the function you
can't even see everybody
now you say but we are sensible people
and many people tell us that you don't
need to worry about these little tiny
differences in functionality this is
nonsense all right there's you know to
you and you're really trying to optimize
a hell of it what is the test data so
put in machine learning center the
ellipse the dots on the ellipse are my
training data and then the test problem
is going to be predict my gauss point
predict where where this comes out so
what I've plotted here on the same graph
is the value of the error all right the
value of the test error ie how close is
your prediction so the 10 to the minus
12 normal stopping point were miles away
low is good carry on down here tes
Arizona just really beginning to improve
when we get out here to the point where
the function value doesn't change you
know you can't even see changing the
function value as always happens the
test error there's actually if you could
magically stop early you could report a
better test error down here but you must
always just report the value you get a
convergence which is some value and it's
the same as the first second order
limited in no time so that's the key
message when you find yourself doing
this alternation chicken-and-egg
parameter one parameter to block one
block to expectation maximization
whatever it is you should ask yourself
am I solving the kind of problem which
is trying to extrapolate right this is a
hard problem okay it's like all my
data's over here and my job is to
predict some value way out over here it
feels a bit mean but this is exactly the
problem we get if we have a 3d face in
front of kinect and we want to predict
the back of the head right we need
strong priors and we need good up
optimizers to take a small amount of
data from somewhere near like the front
of the object and get a good answer out
the back of the object if your job is a
sort of machine learning job where
you're just going to delete em percent
of these data and then reap redic them
no none of these algorithms they're all
going to be exactly the same just pick
the one that's easiest to code all right
but if your job is to do an
extrapolation you may need to care about
whether or not the thing converges okay
so i said i would show you dolphins I've
already told you what a surface is but
I'm gonna jump past some stuff
to the tool that we use to describe 3d
surfaces I'll just give you a very quick
picture of what this is again it looks
like more like a computer program than a
piece of mathematics and yet we have the
tools now to treat it as mathematics I
would like to describe a smooth 3d
surface why do I want to describe smooth
3d surfaces one good reason is I've been
doing all this optimization with
derivatives and I want the derivatives
to be smooth across the surface so that
my optimizations work with my 2d splines
I was moving around some control
vertices some 2d control points and that
generated me a smooth red curve how do i
do the same in 3d and you can do
something like splines in 3d and it's
quite a messy and there's lotsa for
keeping here's a tool called subdivision
surfaces which are super easy they are
defined they are defined by a recursive
rule and the recursive rule is take a
mesh a polygon mesh which is not smooth
take every vertex in the mesh take every
triangle in the mesh so and that will
define this blue surface by take every
triangle in the mesh now replace every
triangle that so every triangle will get
split into four like this and replace
every new vertex by a sort of weighted
average of its neighbors so you can
imagine the vertices will all move in a
little bit repeat and if you curse that
infinitely the are finite number of
triangles you started with will turn
into an infinite number of triangles
describing the blue curve and it turns
out that we can do various things with
this blue curve that allow us to fit
dolphins to data and now I'm going to
come out of here and find some dolphins
and let you go
so what I'm going to do is arm I'm going
to start off some dolphins this is the
same one rigid fixed dolphin template
over lay it on the images and it and
what we're going to do is win and watch
this nonlinear optimizer instead of
fitting an ellipse in very small amount
of time it's fitting 500 1500 if you can
remember Tom tell me some large number
of parameters with all things it's
simultaneously discovering the sliders
as well as the fit of the dolphins to
the image you see these dolphins don't
fit very well for two reasons number one
their position isn't very good and also
they're not painted to write check so we
discover everything in one giant
optimization ok and again you might
worry about local minima well you know
if you look at this dolphin who's just
eaten a very large corn flake that's the
kind of thing that looks to to the
uninitiated like a nasty local optimum
but the because the neither your
optimizer is working very high
dimensions this is a hand waving
explanation but because it's working
very high dimensions things are very
easy and in figures and out now there is
there's a load of other stuff going on
here every time it pauses it stopped
doing this um you might be thinking how
would I solve this problem of closest
point on a spline surface if there were
lots of local optima and one thing you
could do is a for loop over the control
vertices followed by the non-linear
optimized annotation inside well
something like that is happening and
every time it pauses so would have
fallen into a local optimum if we
haven't done that but equally if we
didn't do the continuous optimization we
wouldn't be able to get to the answer ok
um I believe that there
MLP talk has been an unsettling lack of
mention of fires and other things which
i haven't scary dreams you're absolutely
right there are there are loads of
priors um I just didn't bother tell you
about them so there's a prior that the
coefficients the alphas so second last
row from all small there's a prior that
the points on the contour so we're using
silhouettes for this and silhouettes are
a nightmare to deal with because um I'm
a 3d object right and you were getting
my silhouette view so my face the part
of me that is giving rise to the
silhouette comes up the leg here and
then suddenly bounces onto the hand so
that's a nightmare to deal with so
there's a little prior down here that
says keep these guys close to each other
unless you count and a bunch of other
stuff there's a prior smooth basis that
says ah don't make the dolphin too
wobbly ah that's it so my point is not
look this looks like one of those light
switches look I did a load of
complicated Matt's right it really isn't
anyone who reads through this and those
whats going and nothing here is
complicated right it's you know it's all
exactly computer graphics all right so
I've just written down a load of
computer graphics and said throw it into
this optimizer it'll be fine and of
course it that's not strictly true but
that's the first order message to get it
was
oh sorry it was cows no one knows much
later when the method of least squares
was independently invented cow says uh I
that I do that how else could I have
made the prediction of Sarah's um uh I
don't somehow my guess I haven't done
loads reading on this Python a bit I
think he uh took random triplets or
quadruplets of points on the ellipse
fitted to them made a prediction from
each of them and then averaged all the
predictions right I my guess is that he
did is that called packing what's that
called someone who knows things I did he
I think he did it kind of had slightly
basye anything they both give an
equivalently good answer in the text
I've done wonders for the night adjacent
showed but the losers do you do have an
idea what I've good choice models who
just ah ah and uh you know for it for
the stuff that's just noise noise that's
fine write down what you like you know
calcium what really matters is the stuff
that isn't just know it's always IE big
outliers right so that's you know
essentially those are two things you
need to worry about and I everything I
show it had sort of squared things in it
which implies we don't think outliers if
you want to minimize a function with big
outliers in it so but i'll show you in a
second no it's like this so here's the
silhouette nicely drawn here can you see
my mouse no he can't so this is
silhouette going down there and imagine
I've got to point out here so there's
another dolphin nearby and I've got
points from the other dolphin as well
and I don't know which a witch right so
if i try to smoothly match to the truths
other end points and the guys over on
the left everything's going to go
horribly wrong right as when it we've
only got four such points out the
hundreds of these guys but nevertheless
it's going to kind of drag my shape out
here it's gonna be horrible and that's
because i'm paying x
where'd right so because of the shape is
not because the shape is not hugging the
shape is paying expert for these guys x
squared for these guys it's going to be
dragged out so what you do is you don't
pay x squared you pay a different
function so x squared as i plot it looks
like that and the further away you are
the more you pay well what you do is you
make the function flatten out like this
should go flap nut down again oh that's
called a robust colonel so now what
happens is you're paying Rex squared
unless it's just all got too much
alright and then you pay this sort of
constant penalty and that has the good
property that you know because there are
lots more true silhouette points there
on the inside it'll basically make these
guys just pay the flat cost until
recently that was a nightmare for
optimization simple test that it's a
nightmare for optimization is if
everybody starts in this flat region all
the derivatives are zero so you're not
going to go anywhere all right so that's
not good and I say until recently so
recently one of our former postdocs how
that paper sort of the end of a sequence
of papers where this is just nailed in a
good way and I'd love to tell you about
it but some other time but actually if
you do ever have a robust fitting
problem do come to me Oh Christopher
tack yeah it mentioned it's funny thing
with the history it's mentioned in a
paper in 91 by michael pike and not
quite done and then we mentioned in the
paper in 14 not quite darlin you know
but now it's nailed
so you're excluding skating computing
yes ah yes probably because you know the
rules should be throwing everything and
shadings really hard oh can you shady
can you use the fact that the dolphin is
moving from you know bright to dark as a
function of where the light is on him
and you know the solution is when you
throw in extra unknowns for the lights
and then you and you know if I believe
myself saying a million and five hundos
is better than five I should just do it
but by little we guys seemed hard Tony
bars in front of the picture indeed of
your that's a good word well it would
work fine providing let's say there
wasn't the same part of the dolphin
which is an important sticky out part so
included in every single view so if
every single view conspired to remove
this fin then then we would just fill it
in with smooth stuff well and you should
be able to get any smooth part um and
also if we think about it in some sense
lots of the object is occluded I mean in
3d sort of half the object is facing the
other way it sounds trivial but you know
you can't see every data point on the
object so yeah it deals pretty well
noodles</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>