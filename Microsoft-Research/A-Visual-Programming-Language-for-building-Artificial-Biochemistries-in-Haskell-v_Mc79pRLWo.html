<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Visual Programming Language for building Artificial Biochemistries in Haskell | Coder Coacher - Coaching Coders</title><meta content="A Visual Programming Language for building Artificial Biochemistries in Haskell - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A Visual Programming Language for building Artificial Biochemistries in Haskell</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/v_Mc79pRLWo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
um ok so I'm working in my long-term
research goal was sort of audacious I
want to build real artificial life and
by real artificial life I mean a
self-replicating spatial computation and
I imagine in the future it could be
hosted on something like modular
hardware so that it would be
indefinitely scalable and spatially
distributed and and and would use real
resources in a way that we I wouldn't
feel too embarrassed to call it real
life as opposed to simply artificial the
spike affected its embodiment is
electronic as opposed to biochemical so
I'm going to talk about self-replicating
programs and there's sort of a not a
huge literature on this subject but
there's some and and there are different
computational formalisms people have
used to build self-replicating programs
and we can come up with a category
categorization of the models that people
have used and we can sort of classify
them on two dimensions and the two
dimensions I want to work on our work
with are on the one hand expressiveness
which is a concept from the field of
programming languages and in the second
and verse for similar to what you're
going to talk about in a second so this
is a concept from programming languages
full ison has the big reference in this
mike i personally learned about it from
being but Paul Paul grams of paved paper
on the blood paradox which some of you
might have recalled beating the average
is fantastic paper but anyway in the in
the models used to sort in a life
research sort of very along this
dimension of expressiveness the least at
the lowest level of expressiveness we
have cellular automata which many of you
are familiar with I'll say a little bit
more about them in a bit and then it
sort of slightly above cas we have
artificial chemistry's which primarily
work with rewrite rules on symbols from
a finite alphabet and then finally we
have self-replicating programs written
in more or less conventional programming
languages which themselves range and
expressiveness from machine language on
the low end to Lisp and Haskell on the
high end
and then the second dimension I want to
categorize existing approaches on is
very similar to and by very similar to
die really mean an approach which in
some sense provides an interface which
has the same affordances as unnatural
physics the same affordances and
limitations as a natural physics so this
obviously makes the most sense in the
context of spatial computation but my
colleague in new mexico de valley has
written a very nice paper in what he
calls bespoke physics interfaces for
spatial computation and so i'm working
within that framework so we can we can
categorize existing approaches to a life
along the second dimension of physical
very similar to and at the low end again
I think we have programs written for in
conventional programming languages
because the random access stored program
computer is a fantastic thing but it's
not especially physical it's not
scalable its dependence on use of
addresses to randomly access in order
one time is certainly not a physically
plausible operation we will say that
though that models which do provide
these bespoke physics interfaces in the
limit of very high very similar to
defect to find virtual worlds they have
their own physics okay so this is what
cas look like you all know about this
I'm sure they what you may not know is
they were invented precisely to solve
the problem I'm talking about today they
were invented by well I guess I they
were invented by Stanislaw ulam but they
were their first customer was was John
von Neumann and his work on the
self-replicating otamatone and their
spatially embedded they're governed by
rules defined on local neighborhoods
they of a synchronous update most people
would consider the physical
verisimilitude of of CAS is quite high
in fact there's speculation that their
universe might be at a CA however um
their dependence upon a single global
update really means that they're they're
not really well that's not indefinitely
scalable I mean really the real universe
doesn't have a global clock it would
violate the rules of relativistic
physics so much more plausible is
something called an asynchronous CA
which is also related to things like the
gibbs sampler and Mark frenum fields and
things like that where updates are
performed asynchronously it's on sites
chosen at random and some not very well
known results and I'd like to popularize
them a little bit is is that these
asynchronous cas they dominate CAS in it
anyway you might want to consider they
can simulate CAS with negligible slow
down that's provably true and then they
have expressive power which is which
exceeds CAS so in that sense I think
that these new asynchronous cellular
automata are the gold standard in
virtual worlds because there really is
they really define or the affordances of
a real physics by virtue of the fact
that they use asynchronous update ok
artificial chemistry's um you know
ironically enough for these things also
very inverse some latude we have certain
models which are very abstract and
really have very low physical
plausibility because they involve
completely stirred reactor assumptions
and other things they're really no more
physical than a program written a
conventional language in some sense I've
cited some of the more prominent
references above but then there are
others including some really nice work
way back in nineteen ninety nine 1977 by
a guy named Lang on self-replicating
molecular tapeworms that was this title
which which are much more plausible
because the symbols that the rewrite
rules are applied to are embedded in an
actual physical space and all data
transport is done by diffusion and
interactions are local and you could I
think you can without too much
embarrassment say that these things are
very physical and in tims work from from
2004 fits into this category finally um
you know there's been work on
self-replicating programs and
conventional programming languages and
some of the most famous work in the
field of artificial life what I will say
about these this work is in some sense
the random access story program computer
makes self-replication almost a trivial
problem because of program data
equivalents so in some sense i guess
that feeds into but it's but the random
access stored program commuters I said
it's fundamentally non-physical because
of its requirement or its ability to do
random access so the game I find myself
playing and I guess and then this is the
only way I can describe it it's it's
extremely peculiar game because I get to
be the guy who designs a universe and
then I get to design self-replicating
entities in the universe but my question
to you is I've shown I submit a paper
for your consideration where I do both
things I design the universe I design
itself replicator how impressed should
you be that's actually an important
question um because I get to do both
things and so that leads to this idea of
what I would call semantic closure which
is we really have two kinds of
complexity we have the the
non-contingent complexity of physical
law so I don't know you know if you
wanted to write down every equation
governing the physical universe and try
to find the kolmogorov complexity of it
maybe you'd characterize the entropy of
physical law how how many thousands of
bytes would it take to parameter
characterize the complexity of the
physical universe we inhabit I don't
know I think it's interesting question
but then we have information that is
contained in the self-replicating entity
itself that this which is the the amount
of information contained in the genome
which is one source of information but
also the compositional information
because the genome and isolation doesn't
do anything it needs a context in order
to to do something so i would argue that
could be convincing solutions to the god
game have very simple physics very low
content non-contingent complexity with
very high contingent complexity we can
we see that or first work in the field
of artificial life the von Neumann
automaton kind of goes off the charts on
this it's it's this the ca that
it is based on is ridiculously simple
and that in the universal replicator he
built on top of it is extremely powerful
and and contains almost all all the
complexity of the feet is is this
contingent information almost none of it
is it's non-contingent so we should be
very impressed by von neumann's result
conversely programs written in you know
we can write coins in scheme that are 40
symbols lon we shouldn't be too
impressed by that scheme is simply too
powerful and random access toward
programs computers are simply too
powerful ok so what is my research goal
um well I want to have my cake and eat
it too I want to define a new model of
computation more or less which combines
the expressiveness of a conventional
programming language with the physical
verisimilitude and a synchronous
cellular automaton and then I want to
define a self-replicating entity in the
model and do it in such a way that I
maximize semantic closure so I I do an
impressive feat of bootstrapping by
using a simple universe building a rich
replicator I use tools that are have the
expressiveness of conventional languages
but can be in principle compiled into
something like an ACA and sort of high
physical for similar to so that's the
research goal a long range I've made
some progress and that's what I'm gonna
talk about today and I'll and you know
and then the progress I've made I think
is interesting or should I hope it's
interesting to people that do
programming languages and people who do
Haskell in particular I don't think I
would have been able to do what I've
done without Haskell so I credit credit
the developers of high school for some
of this stuff as well ok programs and
biopolymers you know both can be
considered sequences and so um but you
know there's sort of there's there's
some fundamental differences some of
these sequences are purely
representational where some of them
actually manifest a function
so on the program side you know we have
alphabet of binary alphabet we have a
ski and these things have are fairly
compact but on the functional side we
have instructions for a random access
stored program computer and again
because of this this this ability to
access any location and memory in which
can serve as the target for a jump or a
function call or location with data
structure we use these address operands
for many different purposes in a machine
language program and that means that the
sort of the fundamental building blocks
from which programs are comprised
they're not really bits they're really
these instructions and there aren't just
two of them or four of them or 20 there
are two to the end of them for machine
with a you know an in bit word now let's
contrast this with the situation in
biology and biochemistry there are four
nucleotides knees play a
representational role in in DNA they
actually also play a functional role in
RNA I mean many of you are familiar with
biochemistry you know that RNA has
enzymatic action and in fact rna-based
enzymes or critical to the solution of
the life problem in the real world
because they are the ones that underlie
the ribosome which is going to be a
theme of this talk is this is this
identity the ribosome which is the which
is a which is the micro mechanical well
microchemical assembly that converts
descriptions of programs in terms of the
nucleotides into active functional
programs which are constructed from
amino acids so the major contrast I want
to draw on this slide though is between
instructions of which there are two to
the end for in bit machine and amino
acids of which there are 20 and every
single protein in a living system in
this on this earth is constructed from
the same 20 building blocks not 21 20 so
how do we achieve such great functional
diversity from such a small nut with
such a small number of building blocks
and we can contrast that with the
situation with machine language where we
have these these nasty things operands
which prevents them from sort of being
reified as a small fixed set of building
blocks but instead requires sort of us
our ability to read and write these n
bit numbers these addresses now some of
you might be well the solution in part
is going to lie in compiling a
programming language not to something
like machine language but compiling to a
small set of Combinator's and some of
you are familiar with combinatory logic
I'm not going to do that I think
commentary logic is fine but it's not
it's cumbersome and not much more
expressive than artificial chemistry's
if it's any more expressive I'm going to
combine it to a I'm going to come I'm
going to show how to compile
non-deterministic comprehensions to a
small set of Combinator's which kind of
serve as the bike codes of a virtual
machine a stack machine and that's what
i mean by programs as polypeptides in
fact that's the the you know that's the
high level summary of the talk I'm going
to come I'm going to describe how to
compile comprehensions into Combinator's
which serve as the bike codes for a
stack machine there a small number of
them and then I'm going to reify those
Combinator's as actors and I'm going to
demonstrate programs that can build
programs from a small number of
components where the components are part
of a spatial computation and all data
transport is affected by diffusion ok ok
I think I may have just said all this so
that's the explanation of the of the
title programs as polypeptides
polypeptides are the sequences of amino
acids and it's a more general turn than
protein protein as after they're folded
ok and so I want to create a set of
small set of building blocks from which
programs can be constructed I'm going to
reify those building blocks as actors in
a spatial computation and then I'm going
to demonstrate programs assembling
programs from building blocks delivered
by diffusion in a virtual world ok
Reef I'd actor/model a lot of you are
familiar with the actor model is a very
old idea from the 70s I not being very
formal about it if you want to say agent
instead of actor I'm not going to argue
with you the extent that that word
matters in this talk I think they're
interchangeable but um but actors in a
refund original actor model wasn't
reified actors were processes in
abstract space than they were identified
by unique ID numbers my actors are going
to be reified as objects they're going
to have and they're only identity is
their position in a virtual world so the
extent that they can talk to each other
it's by based on addressing each other
within neighborhoods based upon the
relative locations not on any absolute
addresses that's what i mean by reified
actor model that's what i do i
distinguish it from an actual actor
model and on computations are going to
progress when these actors interact with
each other in their eight neighborhoods
after the subject to random 2d motion or
diffusion the diffusion constant is
inversely proportional to an actor's
mass and it's part of them like bid to
have high verisimilitude I assign all
actors mass and operations which combine
actors and for example to build programs
masses are summed and any other
operations which structurally merge
actors masses are some mass is conserved
in this model and the diffusion constant
is inversely proportional to mass and
this reflects the real cost of data
transport and some notional AC a
substrate if something is twice as much
information it takes twice as long to
copy at a given distance that's
reflected in the diffusion constant and
so that's what i mean by high physical
verisimilitude in part and that's one of
the ways in which I I intend to respect
that one of the other devices I've
introduced in the reified actor model or
bonds and bonds are like tethers they
they're short relative addresses an
effect that are updated as actors
undergo diffusion they restrict the
motion of action of actors which are
connected
by them and they permit you to build
working sets of actors which can remain
in constant communication with each
other and effect so they're very useful
they can be either directed or
undirected that's the other one other
little convenience in the model is
actors can be members of groups and
groups in effect are a partition of the
set of actors it's an equivalence
relation an actor is a member of exactly
one group if might be a singleton group
which contains just itself in the most
common case it is but we can group
actors and all actors in a group
diffuses a unit and again the diffusion
constant for the group is the sum of the
masses of the actors in the group so we
respect the real cost of data transport
they and one other less bit a you know
my long-term research go would be to
actually compile this to something like
an asynchronous cellular automaton so I
would be I could guarantee my
intellectual honesty throughout this
whole business at the moment though I'm
using something called the Gillespie
algorithm which those of you who've
heard of a chem are well aware of it
those are you done real simulation real
chemistry are aware of it it's a it's a
event driven simulation using a priority
queue and all the actors in a group
which diffuses a unit share a single
finite time resource and they they they
pay for the cycles they use and again
that my attempt to do something
physically plausible and it's one of the
places where Haskell really made my life
easy because I just instrument
ultimately the Combinator's with with
with with a a writer monad and use use
the writer to monad to compute the
number of real abstract machine
operations everybody uses and then the
scheduler respects that and schedules
that many steps later so that these
actors all pay for the amount of cycles
they use in addition to paying for their
data transport yes turns imitation or
debunk derivatives um no I think I'm
surprised that use the word limitation
because most people would say a hard to
defend the sump
I don't think it's a hard to defend
assumption in my mind I in my mind I
have a two dimensional world and I
consider there's a third dimension which
in effect has a large amount of storage
and so the idea that you know if you
look at the space occupied by single
atom vs the space we occupy I don't
think the idea i'm playing a funny game
with space that's the only place i'm
really not being physical in the sense
that i'm assuming space can be
contracted to essentially a point but
I'm respecting mass and respecting time
but I i I'm using space in a fungible
way but I would argue that that that
even that's physically plausible because
I would imagine an infinitely scalable
machine which is two-dimensional and has
a half of the the half space and the
third dimension could be a would be
storage you could even imagine light
falling on the open half space to power
everything but the amount of light is
pudgy is proportional to the area at
each site which explains my restriction
on time so I do think this this think
that this if this assumption is
defensible it's not non-physical it
requires a kind of curious machine but
it's not non-physical okay I think I
said I already summarize the top in
three sentences this is sort of my um
aha moment I was looking for a picture
of Archimedes in the bathtub and I
couldn't find what I liked and I found
one of dexter looking like using strike
extremely excited about something so um
yeah that's what I felt when I when I
put this chain of reasoning together
computations are defined by behaviors
associate with individual actors fact
what we're going to cheat and foreshadow
the next slide I see myself as having
designed in some sense an
object-oriented artificial chemistry so
we can consider behaviors like methods
and actors like objects on behaviors and
so what programming language are we
going to use the program these things
well you know I say I've teach I teach
Haskell and students Lovelace
comprehensions they really really really
love lists
engines I'm talking about sophomores I'm
not talking about grad students they're
really easy to use their natural people
like them so the language we're going to
use is not list comprehensions butts
closely related that we're going to use
non deterministic comprehensions in the
a and B monad if you're a high schooler
and and they're really nice and they can
be used in transformer stacks and they
play with every all the other components
of the transformer stack nicely and they
respect laziness the correct way I think
there's an article am T is list he done
right if you're a haskell or I apologize
if you're not nothing I just said made
any sense but um so I'm going to use non
deterministic comprehension is my high
level programming language and they're
going to be really natural and a nice in
fact i'm going to i'm not even going to
have a conventional syntax for them but
i'm going to emphasize a sort of a
visual i'm going to draw them as a data
flow graph so in some sense i'm going to
allow the human being to write behaviors
using visual programs which are data
flow graph representations of non
deterministic comprehensions and i'm
going to show how those comprehensions
can then be compiled into monadic
expressions and and just following the
standard practice that WOD ler outlined
way back in 94 how you can compile
comprehensions into monadic expressions
yes Mike talk is a little bit higher
level I'm going to show you some of that
yes and for people that don't know
Haskell that's going to hurt their heads
because they're not going to know what
the binds our and things but I'll try to
give you a little taste of that yes but
um but the basic insight is you know in
some sense the you can compile
comprehensions into monadic expressions
those Minh attic expressions can be
evaluated as by a stack machine the
stack machine can instructions our
Combinator's because they don't have
operands you don't have address operands
and therefore they're a very small
number of them in my current
implementation there are 42 and I've
been struggling to get it down to 32 I
think I can I
and but the most impressive thing is
this last bit the combinators can be
then reified as actors and so I can
demonstrate programs building programs
from Combinator's undergoing diffusion
and in fact the the thing I've been able
to do and I hope to show you before the
talk is over is a computational ribosome
which is a real spatial computation
which translates descriptions of
programs into programs which perform the
functions described okay I've three
kinds of actors Combinator's which can
be composed to form new Combinator so I
primitive combinators as I said of which
there are only a few types 42 but they
can be composed to form longer
Combinator's behaviors are simply
Combinator's which are repackage with a
different type constructors so that they
manifest the function that's just a and
then finally the third type of actor is
object and these can contain other
actors including other objects and here
I'm a little bit inspired by George pond
and membrane computing if you know that
except that this is all reified in his
is not so um and this is one of the
things I really think is distinguishes
what I've done from other things and why
I feel not embarrassed to call what I've
done in artificial chemistry because is
you know people who do real artificial
chemistry's like Tim might be skeptical
about what I'm talking about whether
they're willing to apply the name
artificial chemistry to it but my actors
have no persistent state apart from
these sort of physical things of
composition and containment and bonds
and groups I don't have integer
registers that can be read and written
and in that sense I feel like I'm
entitled to use the word artificial
chemistry to describe what I do because
all the persistent state that actors
possess is a product of these rules
which have these very simple physical
interpretations so no addresses
and I also there's no reason why any of
you should not know my any work I've
done before but I wrote in a paper last
year on something I called
self-replicating distributed virtual
machines and I compiled scheme into
bytecodes undergoing diffusion and
demonstrated self-replication of speed
scheme programs compiled scheme programs
but they didn't have this feature they
did read and write addresses so I didn't
call that an artificial chemistry okay
so so this is what I think I've done I
have an object-oriented artificial
chemistry commentators are like amino
acids which could be composed to form
behaviors objects containing behaviors
are like the molecular assemblies which
play the primary most important
functions in biochemistry they're like
the ribosome the rep letting called the
proteasome these are all very simple
sets of organic molecules that perform
the most important part of our
metabolism the transcription of DNA into
executable functions and manifested by
enzymes and then you know software
engineering so okay my objects are like
objects I argue and my behaviors that
are contained by objects in my model are
like the methods and an object-oriented
system okay I alluded to this this is um
this is what Watson called the
fundamental dogma of molecular biology
we have descriptions of enzymes encoded
on DNA molecules they're transcribed to
messenger RNAs they're assembled into
polypeptides by the ribosome from
transfer RNAs which are amino acids
tagged with nucleotides so that they can
be recognized and Watson uses the word
dogma and biologists repeat it and dogma
is usually considered a negative word I
think it's it is somewhat negative why
did Watson call it dogma well kids I'm
not completely sure but the most
important idea in his mind was he wanted
to emphasize that information is once
the once the enzyme is constructed all
information about its the sequence of
the amino acid
is lost in an accessible because the in
dematic function of the polypeptide
interferes with any possible
computational use of the information
that comprises it it's comprised of so
Watson's notion of dogma is that
information flows is inaccessible once
it's manifested is in a functional form
and I just lied like the contrast that
with the program data equivalents which
makes self-replication so trivial in a
random access stored program computer so
uh the model I'm going to show you today
is more or less maps to the real
biochemistry like this I'm not going to
show this whole model although I've
implemented individually each of these
components I've never really
successfully integrated them all there's
some other issues involved with their
integration but I've demonstrated the in
isolation their function and i will show
you this last bit of ribosomes and
factories and a symbiosis where the
ribosomes are building behaviors which
the factories use to build more
ribosomes and factories translating
descriptions of the behaviors which are
found as plasmids and everything reified
as actors in the world so I've gotten
that far I'm these slides are this is
like the second time I've given this
talk and the last time I gave it took an
hour and 15 minutes so trying to speak
faster but I don't think I'm going to be
able to go through all this in the
details might might need to but um one
of the things i did that i think is kind
of nice is that you know there's this
thing with transfer RNAs where
nucleotides are used to tag amino acids
to form transfer RNAs and that allows
the ribosome to assemble them using the
messenger RNA as a template it's a nice
hack in biology um but you know we can
do a little bit better in the
computational system and so I invented a
hash function for Combinator's and it
has the nice is more or less allows me
to skip the whole intermediate process
of transcription into messenger RNAs the
hash function is this my primitive
Combinator's there they have their hash
values are prime numbers and when I
compose to Combinator's and I use
closely composition to compose my
Combinator's that
the hash function of the resulting
Combinator is the product of the hash
functions of its constituents and so
what this is very nice it obviously is
hash function as collisions but it's
still pretty good and and it actually
you know in real biology you can break
down a protein back into its constituent
amino acids you don't have to carry the
sequence around in some external form in
order to recover the amino acids from it
use chemical processes to break it down
well I can break down my behaviors back
into into Combinator's again by prime
factorization and it is I that's what
the hash that's the information as
function preserves about the structure
which i think that's that's that's kind
of nice information equals mass I think
I mentioned this time equals energy this
again is this idea that i'm going to
instrument my Combinator's so that they
are keep account of the amount of the
number of abstract machine operations
they use and then the simulation will
schedule them based upon their use of
time so that time is a zero-sum resource
shared by actors in a group and this is
um I told you about comprehensions the a
and B was originally invented back in
1963 by McCarthy and it looks something
like this those things that angle
brackets i call superposition so a and B
of an empty set is an empty
superposition a and B of a non-empty set
is a superposition of those things and
so this is the non-deterministic choice
operator the empty superposition causes
failure so if at any point in expression
involves it evaluates to empty
superposition it the computation
backtracks it represents failure so this
is a non that this is a
non-deterministic comprehension for
primality so we
again this is the kind of thing that a
sophomore and computer science would
would be able to read and understand and
it makes perfect sense we have the two
factors x and y it's a dependent
comprehension so that we can see that Y
depends upon the value of x and then we
have this comprehension guard over here
which requires the two factors to when
multiplied to equal the number and so
this is a very compact non-deterministic
program which will return an unspecified
factor of a number if it exists and will
fail if it doesn't and this is the okay
monads um I suspect a lot of you know in
this room maybe as many as half know way
more about monads than me and it would
be insulting for me to try to give you a
monad tutorial so uh I think that this
is a reasonably good summary of what
they buy you they you know they are
useful in abstracting all the ways in
which functions useful in computer
science differ from mathematically ideal
functions and some of those ways are
multi valued pneus non-determinism
failure I oh okay and wild leurs insight
i guess was to realize that they're
closely related to set builder notation
which is this notation which is you know
mathematicians love and sophomores love
the intersection of those two things
that's very small so um it must be good
I'm not going to do this that would be
my contribution to the Monad tutorial
fallacy if you want to i'll talk about
Mona's with anybody all afternoon but I
don't want to I don't want to waste time
in it to understand what's going on with
this guard part of the Monad
comprehension though it's helpful the am
comprehension is very much like list
comprehension you can imagine it as a
nested for loop like this and what guard
is doing is is on the innermost loop
providing either an empty or non empty
body and since the size of the loop is
the product of the lengths of the ranges
if you put an empty innermost loop
inside of a nested for loops you get
zero if it's empty and if it's one it's
so you can see that this is a this is
more or less the meaning of this
comprehension if you had to translate
into c and the guard is complete
is translated into this guard expression
which produces a want an empty or
non-empty range in the innermost for
loop and this is the the expression the
gentleman asked about if you will this
is using wobblers rules to compile the
non-deterministic comprehension into a
monadic expression and so this is what
it looks like unit is that is the
constructor for the monadic type we have
bind for the a and b monad which allows
a monadic function to be applied to a
monadic value and so we can we can and
then we compile the guard expression
into a function guard which returns
either fail or non failed depending upon
whether its argument is true or false
now you might think that I'm already
there these are the Combinator's not
quite they're not Combinator's for two
different reasons one is they all return
different data types every single
different colored block on that slide is
a different data type and in order to
maximize modularity we'd like to have
functions which take the same data type
and return the same data type so they
can be sequenced in whatever order we
want so we'd like to come up with a a
single data type that functions except
as a value and return as a value and one
of the things I'll just observe is that
some of these functions where take
instant return ettes some of them take
instant return superpositions some of
them take sets and return boolean and
are actually integers or return boolean
there are lots of different data types
here but if we use the data type of set
of superposition of set of nth as the
single value then we find all the
different types in this expression can
be represented that way integers can be
represented by singleton sets bullion's
can be represented by empty and
non-empty sets sets can be represented
by sets so that one type is general
enough to handle all the component types
in this expression and so the first
thing we're going to do is just we
like that functions so that they return
this more general type and I'm not going
to explain the details of that but it is
in my paper and then the second reason
that this these things aren't
Combinator's is because they're there
are variables values being captured with
lambdas their closures involved and so
we see two different points we see
closures being used to introduce names
with values and at runtime those would
have to be looked up in an environment
of some sort and and that's definitely
not a Combinator so I'm going to solve
both those problems and the first
problem is just sort of unifying the
data types to a more to a least common
or most remote the type which is general
enough to express all the functions and
and put together with the wobbler rules
for de sugaring and that allows that cup
reinsured to be rewritten as a kind of
data flow graph because we usually see
data flows where a single every line as
a single data type and that's in fact
through here and every box transforms
that single data type into a new
instance of that single data type and so
this is sort of a visual notation for
that same comprehension then there's a
second stage which is compiling to the
stack machine and and the stack machine
is the accommodator has this data type
signature it takes a stack of sets of
values into a superposition of stack of
sets of values so sort of a
non-deterministic vm if you will and
what's the stack doing well i'm using
this in the way that you know people
been doing programming stack machines
since the late 70s with forth and things
like that i'm replacing closures with
values which are recently buried in a
stack and i'm using a dupe to save them
so they're not overwritten when I
perform my expression evaluations and
and that lets me get away with a very
small number of commentators for
accessing things which are not buried
very deeply in the stack instead of
using completely arbitrary addresses and
I in all the work I've done I've never
managed to need an operator
which digs anything farther than five
down in the stack so um so the the
stacks are actually very short and and
the then the common errors which access
the stacks are few in number this is
just an example of what a
non-deterministic evaluation looks like
for the stack machine for the Prime
ality comprehension so we have the
number four we want to know whether it's
a prime you can see the sequences of
combinators I've compiled into and what
we see are the stacks which are this so
that each Combinator non determinacy
transforms the state of a stack machine
and if we want you know the red
represents the non determinism and we
get all the way over here and lo and
behold there's only one of these non
deterministic paths which succeed it's
the one that recognizes that for can be
expressed as a product of two and two so
anything else I want to say about this
other than the fact that again singing
the praises of Haskell I defined this
stuff as having type am and um and
Haskell did the backtracking I didn't
write a single out in a line of
backtracking code I mean that's the
beautiful part about the language I set
up a set of monadic effects I wanted to
combine I did so and then the code do
you know the implementation did the work
so i define my type to be if i define it
to be list it would have done the same
thing more or less but it wouldn't have
backtracked ok so the actual leonard
nimoy I think we all love him I do but I
defy I was calling this language Spock
for the last couple years before his
unfortunate recent death so I'm not just
cashing in and I it was a loose very
loose acronym for spatial process
comprehension sore and then I compile
spa spatial process comprehensions into
spatial process com
or spatial prod process assembler which
I my working in for that with spasm so
um so Spock is the is the visual
programming language we've replaced the
integer type from the Prime ality
example with an actor type otherwise
it's it's all the same in terms of the
way it works and I won't I'm going to
really quickly go through this but just
this gives you an idea of the the 42
combinators I constructed a set of
Combinator's which function is
generators these access local
neighborhoods so they return things
which are in your neighborhood things
which are in your group things which
you're bonded to and they return them as
as sets of actors then I have my unary
guards so I have a s and n a introduces
the non determinism some fails if the
set is empty and fails if it's non empty
and I can use these guards in
combination with the generators to
construct some sense like the left hand
side of non deterministic production
rules you know I can say this rule will
only succeed if there's a neighbor which
doesn't contain anything in my
neighborhood or this rule will succeed
only if there's a neighbor which
contains something which has a directed
bond to itself in my neighborhood you
know i can write this extremely
expressive rich language for talking
about the configuration of or the local
persistent state of the actors in terms
of again composition containment bonds
and position binary relations I think
much need to be said about those so one
of the things in my moon a transformer
stack is the IO monad and that's because
my actors if you want to imagine the
comprehensions as production rules which
i think is fine the left hand sides are
purely functional but the right-hand
sides affect the persistent state of
actors in the neighborhood and so these
are my unary actions I can delete bonds
I can quick groups I can stick actors
inside of other actors I can I hope you
if you know the qui sleek impose I hope
you enjoy my little trigram therefore
closely decompose with the bang in the
middle I can break Combinator's back up
into their components using that action
and then binary actions including Kleiss
Lee composition okay that spinning wheel
of death is a gigantic animated jiff
let's see how long it takes I was really
scared about including this oh there it
is good this is from what the PDI
shamelessly stole it for those of you
aren't familiar with what ribosomes are
they work this shows the ribosome
collecting these transfer RNAs which
match the the messenger RNA which is
being threaded through the ribosome and
there we see the polypeptide being
constructed and being injected at the
top of the ribosome and so here we see
the the translation of a inert inactive
description of a program into an active
embodiment by means of a very simple
micro chemical machine the ribosome of
which there are tens of thousands of
them in every single cell and with their
billions of cells in your body this is
the most important machine on the
surface of the planet of the earth I
would argue and this is the
computational ribosome and uh I'll just
explain it very briefly um I represent
the inert descriptions of programs are
also built with Combinator's but they're
inert they don't do anything they're
real fight as closed loops of
Combinator's they undergo diffusion in
the world subject to the bond length
constraints I think I'll show you that
in a second the ribosome is an object
which contains four behaviors each of
the behaviors is a non-deterministic
comprehension the non-deterministic
comprehensions are compiled into these
plasmids
this that you these closed inner loops
and what the ribosome does is it
traverses the plasmid and it collects
the the Combinator matching the one it's
bound to from the neighborhood using
diffusion and it does closely
composition to build the stack program
up as an actor it carries that inside of
itself when it reaches the plasmid
origin it ejects the behavior and that
is free to be included in self
assemblies for higher-level objects for
those of you like functional programming
I couldn't help I love this idea I mean
the ribosome does a right fold of the
plasmid using closely composition as the
operator it's extremely economical
description of what it of what it does
computationally these are the four
behaviors which are used to define the
artificial ribosome there are non
deterministic comprehensions constructed
using the set of commoners I just
explained see if I could just to
highlight that the little blue region up
there that's a that represents the
constraint that the ribosome needs to be
bound to the plasmid origin so it's a
place where directed and undirected
bonder coincident so this one obviously
is the most interesting one this is the
one that causes the ribosome pick pro
along the plasmid when it finds a
Combinator which matches the one the
plasma in its neighborhood it uses
closely composition to to add it to the
behavior it's constructing and carries
within itself finally when the ribosome
finds itself back at the origin but on
the other side of it it ejects the
behavior and then hops across and then
detached itself from the plasmid like
that maybe three more minutes of talk
that would be useful to show you a how
do you test the system like this what do
you want to do with it well short of
building a full-blown von Norman
replicator which I'm doing but haven't
gotten finished yet what you'd like to
see is me
be the ribosome building the behave the
the behaviors of which it's comprised
but we can do that but um but we still
need a way to package them into objects
and so I've even built a another little
machine I call a factory factory is a
replicator of compositional information
so it uses a ribosome as a model and it
constructs things at object which
matches the model to its right and the
factory itself is defined by five
behaviors and those are what those
behaviors look like facts zzz a trivial
variation facts e-prime the trivial
variation of fact Z I didn't show it but
again these these visual company's data
flow graphs representing
non-deterministic comprehensions and and
that leads to this experiment which i
think is is kind of neat i hope you like
it because what i have is a ribosome i
put up five plasmids for the factory the
four plasmids for the ribosome nine
plasmids into the world describing
programs i put a bunch of ribosomes in
the world they actively translate the
caucus m beliy programs from the
descriptions that the plasmids embody
and then the factories use those use
those assembled programs to replicate
both themselves and ribosomes so this is
a kind of a ribosome factory symbiosis
all implemented as a distributed spatial
computation and it works I was told that
people want to see pictures I don't
blame you i would too i I don't have
that to show you it wouldn't be very
interesting anyway because the ribosomes
work is done not very conspicuously but
um I have implemented as I said every
single part of that fundamental Dogma
picture so i'm going to show you is a
replica of repli so mu replies ohms copy
in a plasmid hopefully it will cooperate
this is a live demo I put a bunch of rep
let's go play
amid one's already bound the second
spawned so these repla somes are copying
the plasmid using common errors which
are beans being directed to the source
of the computation by diffusion alone
okay so there it's it's it's it's
replicated it will replicate a couple
more times until the commenters are
consumed there's conservation of mass in
this world so so you know so I would
argue this piece I've just shown you the
replimat combined with the ribosomes and
the factories it's a it's the full
fundamental dogma of biology I'll have
to do is work out the coordination
problems of which I want to try to
trivialize them but it's close okay so
um let me get back to the slides and
conclude since you've been wonderfully
patient thank you yeah I wanted to shoot
that single jiff okay those are the
those are the two most important
behaviors that describe the rep lamai
just showed you working there's no need
to really study them but that shows you
that this this this one here is probably
the most complicated in the system and
if you tried to use that using you know
I wrote a parser for a comprehension
syntax it looks hideous you know it's so
this visual notation is extremely nice
for comprehensions okay conclusion I've
designed a visual programming language
for defining behaviors manifested by
actors in a virtual world the visual
programming language can be compiled to
sequences of Combinator's which can
themselves be reified as actors this
makes it possible to build programs
which build programs from fixed number
of small fixed number of components that
you're delivered by diffusion and I
would argue that this makes the whole
system the host resemble a chemistry as
much as a computation which is which is
one of my goals and um and I hope that
those of you came to see lots of haskell
are not terribly upset with me but um I
will credit the Haskell for this because
um honestly I didn't start thinking
about things this way of writing
Combinator libraries to 12 problems
before I started coding in Haskell and I
don't think I've ever would have come
with the solution except for the fact
that I've been you know I've drunk the
kool-aid so I'm going to stop here and I
thank you for your time and I'll answer
any questions if you have any
presa de buddy you've got this Oh mr.
new programming language you've taken
the these components so far it seems to
me that because that programming
language have used outside of this work
aimed at evolution I'm not a considered
myself a programming languages
dilettante if you look on my webpage i
list my research areas still his
computer vision probably and then i say
under hobbies i have charcoal grilling
and programming languages i wouldn't
claim to be a PL guy i would suggest
though that monads sometimes introduced
are known to introduce sequentiality
where it doesn't need to be there and if
you use wobblers rules to translate them
they certainly do I don't know whether
that needs to be there I don't know
whether visual programs which are sort
of least commit with respect to their
data flow diagrams there they make a far
they don't make any commitment with
respect to the relative order of
evaluations it isn't applied by the data
dependencies it's entirely possible that
this visual notation for comprehension
is is generally useful and goes beyond
this work that's that would be my sole
speculation about the contribution to PL
yes thank you also copying me that's a
while I wasn't that the white line was
the yes the demo was the toast to little
machines i call repli somes and they
copy the plasmid which is the
description of the program which is
inert which is just a sequence of
commenters joined by bonds so i can
create the inert description is a closed
loop of Combinator's joined by bonds the
active program is instead of bond
instead of joining the commenters with
bonds like i compose them with closely
composition to make a program it really
works and the nice that has the same
kind of duality as we see in the
biochemistry where we have the inert
description which is spatially extended
like the DNA molecule but then we have
the active protein which is compact and
that's this
composition of the combinators to form
an actor now in my system mass is
conserved so my compact thing the view
is the fuses more slowly than the
combination which is comprised but it
still sort of has that spatial
compactness like in fact the real enzyme
does after its folded for example and
what you saw was to rep let's hang to
the replication origin and then moving
our you know I'm a big star trek guy
fully in web style in opposite
directions replicating the plasmid
between them and then when they've
reached that when they when they hit
each other on the opposite side of the
plasmid they just perform the final bond
surgery and the replications finish
that's actually a fairly good legitimate
representation of weights actually done
in real biology there is a pair of
replication or forks that move in
opposite directions in exactly the same
way I mean I modeled it on the real
biology in that sense then we should yes
the graph you showed replication of the
actual functional ribosome some
fractures right so um I've built all the
parts of that artificial metabolism but
I've never I haven't quite demonstrated
everything working together in concert
so I emphasized in the talk mostly the
ribosome but because the ribosomes less
interesting in terms of visual interest
it doesn't you know it's constructing an
accommodator and carrying inside of
itself and when it's done it just eject
sit there's more to see with the
replimat as the demo yes yeah uh this is
a you know um thank you I keep expecting
this question I only gave this talk once
before to a group of people who were
interesting evolutionary computation
they didn't ask the question so I was
scared but you finally asked it um I've
you know I've I've tried to build the
Combinator language with an eye towards
evolvability and um and I I want to know
you know I guess there was a question of
whether I could create a natural non
contrived organic
error full ribosome or actually a
replicator replies ohm or whether I
would have to add that post talk in kind
of a contrived way I I think the
simplest thing for now would be to do
that to create a spontaneous
transmutation based upon a nice 32 by 32
Markov matrix which shows cambia
nominators transmitting to other
commentators and providing this
transmutation frequencies and in that
since I would be able to introduce
variation which would hopefully lead to
evolve ability that's the simplest and
first thing I would try with respect to
that there may be a more organic and
natural solution and then here's the
peers a little bit of a paradox and I
don't know how to solve this I think my
personal belief is that the higher-level
representations are more useful for
mutation because they explore more
abstract space of programs but yet we're
going to be forced to do mutation on the
compiled code not on the source code and
so that also kind of troubles me but you
know the only place the source code
plays a role in the system is the human
that designs it after it's compiled the
Combinator's it the source code plays no
other rule so I I'm sadly going to be
limited to permit a shin copy and error
on the compiled descriptions not on the
source code descriptions do you have any
question in part 10 equality um so I
have set a intersection and um and I I
write it as equality because for
singleton set set intersection is
equality in it but it's actually
performed set intersection it doesn't do
it doesn't do said equality it does set
intersection you only need to make you
an equality ever flew and oh oh oh oh oh
yes yes yes yes that's a really nice he
has potentially nice idea
um it's hard to say yes that would be a
natural place to introduce some
stochasticity of the thing if I made
thank you if I made the relations error
full perhaps that would be enough be
certainly worth trying see what happens
evolutionary programs before when
there's been difficulty in understanding
what they do when they've evolved is
that going to be the case here you'll
end up with mutated compiler programs
and it'll be hard to understand yeah I
think it would be interesting to try to
come up with a decompiler which would
move from the plasmids back to the data
flow graphs I don't think that would be
terribly hard the color is on the data
for glass grass for any of you who were
curious they're just for their almost
like comets they group things
functionally based upon my brain and you
know the human designer it's a natural
way of grouping them they don't pay any
actual role but a decompiler which would
identify which would produce the data
flow graph from the sequence of
Combinator's and then identify the the
natural groups like that would be a
useful tool to have but uh you know I
mean right now I want to work on a van
Minh replicator in this language and by
that I mean I'm not gonna I'm going to
step back a little bit from trying to be
more biological like I was in this talk
and I'm just going to do a nitty-gritty
honest-to-god everything von Neumann
replicator and I will sort a claim I
think I've it'll be if you believe my
argument about ratio of contingent
non-contingent complexity as being a
measure of how impressive that feat of
bootstrapping is it will be a pretty
impressive feat of bootstrapping by a
lie standards because I'll have achieved
a fairly sophisticated self replicator
with the very small set of atomic
elements and well-defined semantics the
common errors that you know the
implementations are really short each of
them
so any more questions that we found for
their time with that let's thank plans
okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>