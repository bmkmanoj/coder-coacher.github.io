<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Ziria: Wireless Programming for Hardware Dummies - Part 2 | Coder Coacher - Coaching Coders</title><meta content="Ziria: Wireless Programming for Hardware Dummies - Part 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Ziria: Wireless Programming for Hardware Dummies - Part 2</b></h2><h5 class="post__date">2016-07-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/A2Q-YmAJc6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so right so where are we so what
hopefully I explain you the heavy duty
of the programming language and it was
probably very quick and I don't expect
you to be able to program now but so the
takeaway points would be that what are
the difficulties there and I mean the
idea that you have the execution model
which has to be specified and did you
have lots of optimization have to do so
far we haven't seen what they are but
basically we came up with a language
that was supposed to that is hopefully
able to and I'm still appreciate it into
that i'll give you the case study in
Wi-Fi design to give you teach you a bit
of Wi-Fi in case you don't know it and
also give you an idea how we can
implement things like that in there in
the language but those something the
high level is that you should partially
believe me that you can implement very
lots of things that the language
flexible and it's easy to write and it's
easy to understand but you definitely
shouldn't believe me yet that it's going
to be anything like efficient right so
we just discussed that what you can use
to write it and hopefully understood the
abstraction levels right and how to
design control flow and everything else
but now what I want to tell you is about
how actually compile this and how do we
execute it and to persuade you that it's
actually going to be a fast as well okay
so so how to ride the compiler how many
of you have written a compiler okay one
yeah so I haven't done it myself either
before this so it was an interesting
exercise and the first advice always
good to have a programming language
person with you when you do it so you I
mean these guys they did the first
version in less than two months an
intern did it right in Haskell and i'm
sure you can use other libraries but i
was impressed i don't like you have an
intern for three months there's no way
he's going to write anything close to
the guy wrote in two months it was
producing code that ran companion see I
was just impressing so high school is a
good language for that I had to learn it
and it was a because I was working with
guys are actually
Don in Haskell and I'm now presented
that it makes sense if you write
compiler striding high school and it has
lots of support basically it's written
by programming languages guys that wrote
it partially that they are able to write
fast compilers and so have libraries for
parsing you have libraries for
cogeneration you really write almost
like C code in there and it just gets
replaced and it has these flexible types
and pattern matching it allows you to do
very efficient and I'll show you a
little bit of it very efficient in
smooth kind of operations in there and
it's actually nice because the way to
design the compiler now and this is
probably a topic for a PL program
language seminar is that anyone can go
and write an optimization partner and
it's fairly easy right so if you think
of a new optimization you want to do you
have this abstract syntax tree and you
kind of add the optimization there so
that's the nice thing about easily
extendable and then again what I learned
from here is that this is a compilers
can be useful useful tools right so it
actually does help and so still the
thing that I'm to explain you now is one
can write why didn't you write this in
Python or whatever so you know they
choose the language of your own right so
it's you can do much more things in the
compiler it's not very difficult to do
that you need somebody who is
experienced but this idea started so
that we started thinking about this year
ago we started understanding the problem
and we had a first version somewhere in
September okay men now we have our
release writing it happens I mean it's
kind of something we are not too ashamed
to get people to play with so it's not a
very long process right and there's them
we had three people for the first couple
of months and there recently it's just
the two of us so it's not and we did
other stuff as well so it's not too too
difficult and now so some investment
worth considering if you are ever going
to to coming into that bed area and it
was fun i have to admit i learned lots
of new things it was never did that is
either okay so so how do you how do we
do this compilation right so presumably
i'll give you a little bit about it so
there's passing and all this is standard
predict for the compilers so how do we
actually compile our language
where the challenge is there and what
what are the opposition we can do so the
expression language is the thing we used
to define the code itself we describe
f50 or the this kind of block thing and
that's as I said pretty much
straightforward see mapping right you
know you do arrays look you need to do
some mmmm copies and so on but there's
nothing much to think about there there
are some positions you can do on the
code and I'll show some of them but once
you have this code and when we do
optimization we do on all in our
language and the end of it we have this
important language we just kind of
pretty much straight forwardly map to
see code now the interesting bit is this
computational language this is again
that I as I mentioned this is the way we
execute these three that we have is this
composition of these blocks in a correct
and efficient way this is the
challenging part and as I discuss with
some of you this is really targeted to a
single core or maybe a few course right
but very partial course we don't know
yet how to do that on multi very
multi-core systems fpgas and so on but
we are interesting going there and
understanding that as well so the moment
I'm going to scribe is a crucial model
for pretty much a single core CPU so
this is what Sora and us are pins and of
the world do with the moments right and
then we can do numerous optimizations in
a way like vectorization which is
expanding the bus these sizes and so on
look up tables and lots of conventional
possession that many other compilers do
these are kind of specific to our
problem into our domain and I'm going to
explain them all so right so this is the
this is our Wi-Fi code Wi-Fi receiver
code hopefully now you understand a
little bit better what these blocks me
right so here this will just going to be
a down a horizontal thing this guy is
just a computer when it finishes this
guy's also computer when it finishes
passes on the controlling here so
essentially it goes this way right so
this is a transforming a computer
because they end where the header is
ended so both of them together is
computer this guy here is again a
transformer it embarrassed the channel
does all the OFDM channel equalization
and then the cold packet is at the end
also receiving the packet so as we
discussed before there's a question is
Wi-Fi a transformer or a computer
essentially why if I conceptually is
receiver is a computer because it
receives a packet and it gives you a
packet so but then if you want to see
more packets you can put the repeat
around this and you're done more bucket
so it becomes a transformer so kind of
that's that but the question is how do
we how do we now run this so we have to
run we get an input here so maybe we run
this function here then we run one here
then we run go and run one here then we
pass this here or you know what sorry
one has to go here but then if it's done
if you detected the carrier the next one
should go here so we're not supposed to
take too many here in case we need to
and if we over fetched and we never need
to go to the next one similarly like if
we have the the case here this guy
decides when everything stopped so we
shouldn't veg too many things in this
guy before that guy stops and so on so
this is the this is the main challenge
of the execution model so so as a
crucial model is conceptual at this
point and i'll tell you basically how we
do it after it so you can think of these
blocks as being some kind of small logic
entities which have certain operations
you can operate on them and again this
is this is this is specially designed
for a single core cpu or a few course
i'm not talking about large multi
courses on so what can you do you can do
tic and process so basically it's like a
box that reacts and you can call a
method thick or a method process and at
the end of this it can return yield
skipper done so basically skip means so
yield data value means i have a data
value to give to my downstream neighbor
so is if i have a link like this if this
guy returns yield says i have something
for me too okay if I have skip that
means you know you either called ticker
proc a process but I didn't have
anything to do so I just say skip I
don't do anything I return the value we
just keep
or the last thing I can do if you give
me something and I say I'm done okay
don't call me again ever I'm finished
I'm sending done and we're done i can
return some control value okay so
basically and then process is called
when you when you when you want to give
me a data from the upstream so for
example or you want to give me data from
side so for example this guy yielded
some data there so what happens then
this guy is called the process of this
data and it's roasting this data so it's
kind of not yet clear why we need all
that but this is the these are this is
the definition of this execution model
again very high-level conceptual so
quick question again I don't know if
you're able to answer anyway but why do
we need tick so tick basically I don't
give you any that I just probe you I
poke your kind of well this is single
CPU think of it that way for now it's
not sink recession because I ran only
one at the time so essentially i might
have a call like this I meet one me2 me3
so I'm just a meeting i'm not receiving
anything so i need to be flexible to be
to explain to an able to express any
code i want right so because of the
potentially arbitrary execution codec
give i need to make sure that maybe
before that i took i was waiting for
some element but now i can have lots of
elements to do right so i need to make
sure that the order of execution of this
is correct so kind of formally proven
that i will execute any code correctly
and so we I think we have even a kind of
a formal proof of this but basically
it's like you need to do a sequence of
things whenever you prosecco process you
need to call tick afterwards to make
sure that because this guy moved off the
process it did something inside does he
have anything to send now spontaneously
without even doing anything or he has to
give me another data so basically help
of first occultic and then if the tick
is returned nothing then you go process
if they take return something else you
then you can call tick again because
maybe you know we have three tix here
and so on I'm not going to go into
details of this
just to give an I mean this is just to
give you an idea how this is done in
general you don't need to understand all
the details right but the key thing is
that we have some kind of state machine
when all these blocks are in different
states and this state machine is
supposed to describe this execution of
this and should worry about so if you
remember one of the key things in the
first part was when I give you them the
language I don't want I don't care how
it's going to be executed right just has
to respect the semantics of the language
and the semantics is kind of clear maybe
I hopefully it's clear to you as well
but it's well defined what is going to
happen and it has to happen that way now
we have to make sure it's efficient as
well and so the goal of this guy here
now yeah we it's at this moment maybe
it's not clear yet why is defined this
way but if we call these sticks and
processes in the right order we will
execute code in a lot right order so let
the starting point but then what we do
we do lots of optimizations of this to
kind of make a code very very efficient
I mean as efficient as we can and the
key idea is that this thick and proc
really process model is really for the
very non optimizing but there are lots
of things in the code that will optimize
you can see that there is some that
could be a potential inefficiency
problem right you need to take in and
process and so on whereas this is not
our fast physical error code right I
mean no I was talking about these very
fast things and now you introduce all
these complexities intermediate layer
and doing some calling some things but
the key thing we need to be efficient
and correct obviously so this was given
to give us the correctness part because
now we know how to execute at least this
correctly no matter what cold you give
me and then now I'm going to talk about
optimizations right so yeah sorry with
this is the input is in process so if i
call kick I don't give you input if I
call processor give input and now
depends on which block you are this
process will be an input from a cider
from the top so but I not every time I
call you'll have an input but sometimes
you might not because of this right you
can can emit right so and it would be
functionally incorrect
if I give an input we need to do because
if I give an input between these two but
your first supposed to meet and maybe
some block downstream would react on
this and stop the whole pipeline and
this guy who came in would have been
incorrectly fetched so I'm not supposed
to give you an input before you do all
the arm it's because something can
change in the configuration so we need
to respect this semantics of the length
of the of the program and I mean it's
not immediately clear this is a I mean
again this is just to illustrate the to
illustrate conceptually how this is done
I don't think if I mean if you're
interested in language later you can
understand the details of this but this
was just to illustrate technique rather
than really give you all the details
right so so just to give you an idea how
these execute basically if you look at
the code like this so first of all we
start from all the way down so why do we
start from the way down because this guy
can emit something again we shouldn't
fetch data before we we check that you
have something to continuously going on
for example this guy should start
sending a preamble so you know will
first start sending before we start
encoding bits because something some
coding preamble might force my affect
the rest of you so we don't think of
this one so this one says I'll skip I
don't have anything to do so then we
don't think of this one because he's the
upstream he says skip I don't have
anything to do and test this by the way
is defined here so then I say click this
one so this is a special control which
is an input which always have something
to give us this is the general input of
the of the whole system coming from
radio or file or wherever you want so
then this guy says yield okay I have
some new item to give you this is in so
then what we do we say process we then
call this violent process so now this
goes this is a transformer define here
okay so we put this message inside so
here we first process repeat I'll skip
that is just basically very high level
so now it process take so take knows
what to do with process it will take the
process element and we'll all done it
will finish it's a computer the chest
just takes one element and if you
remember at this level so we have this a
little bit weird
distinction between a vertical and
horizontal vertical is datapath
horizontal this control pad so here we
are in control pad because that allows
us to do different control changes to
the once that if you can think of it if
the data element is in vertical partners
do not register go through once it goes
in a horizontal part there is a control
element in it so here it just takes it
but obviously there is nothing to be
done here so we could have done some
processing here some imperative code or
something like scrambler but done it's
just going to pass this value week's X
to the rest of the code in this block so
then this is going to call process with
this n on the next part and and why is
this n because this is the parameter of
this limit so that's the value it takes
and then this is going to yield down the
data path to the next thing as we
required and so now it's going to call
the process here and then it's going to
be so again I don't expect you to
understand why this is a correct way of
execution but just to give an idea what
is going on here right what is the kind
of order of these events how it's going
to be executed and this is the main loop
which is basically running these things
it's going ticking and saying you know
or you go here you go there you go here
you go there this is again conceptual
this is not how its implemented in the
real information is gonna be a sequel
that does all that is going to for a
specific for a specific code we're going
to create a state machine that is going
to jump around but this describes the
behavior of this thing so there is
something that is going to the the what
I illustrated in previous example I was
saying on I'm taking this num thinking
that this is this kind of main loop that
is doing it okay so this is enough about
the execution model so again the message
was just to understand how it how it is
done to be correct and now I'm going to
tell you how we can actually make it
efficient so you say so many tix
improxim why are you talking about
real-time fine I know you're never going
to do that so the first thing we can do
is now we can go doing lots of
optimization around here so and this is
what happens right so so basically what
happens is that we take this abstract
representation of this code and we go
through it in multiple passes I'll give
you an example how we do that
and we do transformations at this
abstract level that are certainly not to
violate the semantics of the execution
model so what does it mean so for
example if I look at this guy here now
this is a repeat and I can count the
input and output that's called static
analysis so I look at my three and I can
count and say oh this guy takes one
element and I'm it's 111 so if I have a
repeat that takes one element and it
meets one element then this is just a
map right so if i take this X plus 1 so
the whole thing here could be replaced
with this thing here so just one map and
by the way this is the output of a
compiler I didn't write this is just
cough it so this is the kind of
intermediate step so why is marked
better than then repeat taking it you
just saw repeat they commit has to take
this stick this dick this prop this
right but we replace this with just one
out of map there's nothing to pick in
proc just give it there's one tick for
that there's nothing else right and this
is the source level transformation sir
but the key thing is now we know this is
correct and we have a representation
that is correct and we are starting from
the correct representation which seems
complex and it is if you don't do
anything but then you start trimming
down and removing bits and replacing
with more compact bit and if you really
have some very weird code right then it
will still became ill remain complex and
that's why we are doing the
domain-specific language for wireless if
you start implementing big data
analytics in this it's not going to do
it right because you'll have so much
control flow that you'll have to keep
these sticks and rocks and it's never
going to be of any use but the nature of
our code that we want to write is such
then in many cases we've done Wi-Fi and
bits of LT and so on sorry it can be
actually very nicely optimized and so
all and this is the thing like if you
think of fft right fft is going to do
this takes of a large array vector it's
going to process the vector and emitter
vector and that's going to be nicely
converting automap on its own right and
so but you don't have to worry about it
right we have this execution model is
correct we optimized part of it okay so
now we have these two autumn apps so we
lost lots of these sticks and rocks
and and then we basically have to autumn
apps now if you look at it from high
level what happens is there is a tick we
know that these guys doesn't have to be
ticked because it's a map it can only be
proc and this guy cannot be ticked
because it's a map you cannot emit
spontaneously it has a very well-defined
thing so the C code we write is really
this and there's there's two goals in
addition I just removed for but this is
again from the compiled code you
basically get input from read you call
this autumn up so this same variable
this pass here you call it and copy here
then you call this thing as in anthem up
the other one and then this fraction x
plus one and then this one is being
called input so again there's just to go
tues in between these two which I don't
show but because we know lots of things
about autumn apt at it cannot be ticked
it doesn't have to be so we can simplify
further this model and actually make it
really execute only them now the smart c
compiler and all of them are smart
nowadays well actually in line this will
become X plus 1 in inline this will
remove the all the in directions and it
will really become just get X plus 1 put
so it'll be super efficient but there
are several ever so we do one thing of
the execution model the c compiler will
do amazing things with you know on this
in lining and if you run a see compiler
with debug or release beat GCC or Visual
Studio you have like at least an order
of magnitude difference unbelievable so
you need to make sure you compile in a
release mode so do all these sorts of
musician internally and you just get
amazing code right so of course this is
a simple case right so here's another
thing we can do so if I see that there
is a times for right and I take a
certain element and I repeat it right I
so I can convert these times into a four
in the imperative code and I think I'm
not going to go into details of this
code but the high level okay it's just
that this is a computational language
where I have to take this and I have to
take this inside and if I see that it's
simple code that could be transforming
an imperative
and an imperative code is a single block
of do which compiled straight into C
code and replace this time with a for
loop in this imperative code removing
all the internal control structures and
I won't have to do any ticks and props
so the lots of type reasoning
transformations we can do if you start
thinking about it that we can do once we
have this abstract representation and we
just prune and eliminate all these
overheads and again our original
execution model stays only for the most
complex pieces of code that cannot be
optimized efficiently otherwise and
hopefully and in most cases turns out to
be like that because we are doing
domain-specific language this is only in
a very extreme situations where for
example at a high very high level where
we do coding and decoding or sorry the
packet header processing and so on where
we pay some penalty but this penalty
aggregated over everything else is so
small that it doesn't matter so you know
you can always do a little bit more
matter you do better but you know you
would sacrifice this at the expense of
clarity of the code and all the other
nice stuff and I'll show you the results
that performance results at the end and
we don't think it's worthy so okay so we
get ya in this case we get three times
speedup because we don't do all these
sticks and rocks inside this one so how
do we do this transformational abstract
syntax tree so I guess since no one has
written or one of you has written a
compiler or something it was kind of new
to me and I guess I had that undergrad
course long time ago but basically the
days when when you get your code you
parse this code and you please represent
it is something like this right so it's
an abstract syntax tree meaning that
every single thing in a in a in a
program has amp is an expression can be
parsed and break down into something
like this so if you look at this one for
example what this says is y becomes X of
0-10 so this is notation saying take a
sub array of length 10 from 0 to 9 okay
from X and copy into I so I'm not even
giving y equals I only giving the sub
sub array read okay so this is going to
be in sequence with this guy here its
own sequency should be sorry should be
equal anyway I forgot that bit so the
array read has three parameters
there is an array from which we read
this is the branch here there is a
starting value zero and there's the
ending value 10 but then the array is
not simply an array we need to give a
type of array and here it's a type array
and if you put type in here it's wrong
it should be here the type checking
should fix that and this very still type
array and it's a subtype which I hit
here and there is this X this is the
name of a variable and so the second
parameter is a value it's not a variable
it's a value it could be a variable as
well we could maybe put here J instead
of 0 it would be evar in that case but
now it's a value and then this value is
type into any 0 right and this the
second parameter is value type sorry its
value int Joseph type in and it's it's
it's 10 right so this is a kind of
representation and so when we pass our
program we do type checking so tight
chapping to make sure that all these
types are reasonable otherwise it will
complain so we have this big tree and
that the nice thing of Haskell is this
you can do very easy searching and
pruning in this big 3 i'll show you in a
second and then we do all these
transformation in a tree and make this
thing more efficient and in particular
we do lots of things like on
computational optimization I showed some
we do this optimize tekin prox convert
to map some inlining all three I showed
and those vectorization which I'll show
this is the kind of an interesting one
and then there is the expression
optimization you can do look up tables
and again I'll show this one in more
details inlining calculate constant
expression and lots of things like you
know if you see that three plus two you
can change it into five right and you
can add these things and the another
interesting nice thing for us was there
basically once you have all this right
you can instrument the sequel to do
boundary checks so you don't violate the
rate constraints and when you're
compiling the debug mode you know you
see that you should run it and whenever
you have this boundary array it's
basically memory a leak you fail right
but you don't want this in a fast
version obviously these are techniques
that are well-known right but it's very
useful as a physical error programmer
you know when you ride this and you
don't have this tool right this will
give you this for free just a simple
instrumentation of a code which we
actually have it works now and many
times it helped like you know have a
memory overflow it just stops you always
run with this
which on when you test and when you when
you don't then you remove it so here is
a simple example so this is the little
bit of haskell code and that's the only
haskell code i'll give you is no more
and should be very easy so here is an
optimization you want to do so i'm doing
a sub array read from array x from 0 to
length x right so obviously this is the
rate i'm reading the hollering so i want
to remove this into x okay this is the
simplest possible optimization and so
this is this is this it's called sub
array in line step right and i'll give
you an expression okay so what these
things here is a pattern matching in
haskell and says only trigger so this is
the pattern and this is what you do if
you match the pattern so the pattern is
the following forget about it this
unexpressed this is something internal
but if II this is the input expression
is of this type so it matches this emat
is the e arrayed read eval see startling
I so if you think of this before right
this was this right if it matches this
this point right if it matches this one
then you go on but moreover you map the
values of what is was in there to these
variables right and you keep on matching
so now I map this evals 2x I'm up we
start 20 and I map this to something
which is called length of em so it's not
an integer its length of n so now if i
do that all that then I'm up the
particular starting point 20 and the end
to the star ending point 2 m and this M
happens to be the same as n then I just
rewrite this as evolves and he vows is
just our X so I won't hear what what's
what and there's like the kind of
matching in crane English but basically
it's kind of you know the whole
transformation is only this this much
code more more more more difficult
information be more but a basic thing
designers do you sit down and think okay
what can I transform right this is a
simple one and of course we didn't do
this randomly we just found places where
it hurts performance a lot so we just
went and said okay
and this is because you're doing some
bitter research or something when
because the beta rays we operate on bits
i'll show you later we have to work on
bit right and this is very expensive so
it's easy to add new transformation so
you know you can go and think of what
you want to add or you see a big
performance penalty and you you add the
transformation there right so okay I
guess any questions about this or this
is probably a bit ok so now I want to
talk about two specific position which
are kind of important for our particular
domain that this kind of optimization
was more generally you can do this in
any program if you care about it so now
when you think of this execution model
most of the times we and I think I had a
question from you like previously like
oh why don't you put the Rays and how do
you do these things here so the way we
write our code is we say take an integer
and then I meet integer or even worse
take a bit and I meet a bit right this
is hugely inefficient you want to take a
bite which is in cpu intel cpus it's a
bite so you have to take a bit out you
know it's incredible expensive and then
and so in this case we want to convert
this into debt okay so and then into
inside do some processing maybe so can
we do that so the first thing is can we
do that and so this is doable if we want
to do it so the second question is why
do we want to do it but this is in
principle doable because we have the
whole execution model which is not hard
coding the code right if you look at the
source code for example you either write
this or that you cannot change right and
you have to think when you write your
code okay what is the width of this i'm
going to right there so if you want to
change you have to go back and and
change the recalculate and but you first
need to sit down and think what should
be the width of my bus here is it what
is the optimal for the for the execution
should I pass 64 and I'll tell you why
this is not a trivial problem in a
following slide but you need to design
these numbers and you have to cart call
them so you can't really do that so you
need to do it yourself and it's
difficult to change whereas we argued
pilot should do it you shouldn't worry
you should just write this and at the
end it should be that if possible so why
do we want to do that so the first the
most important thing is look up tables
so the look-up tables are basically so
look up tables are basically converting
bits to bite so if we have our operation
bit like scrambler and I'll show that in
a moment if I have the look-up tables in
converting bits two bites I don't want
to do this in a bit right I want to
convert this in at least a bit and then
operate on a limit so here here I think
there is a bad I think typo but you'll
notice that should be take s takes and
emits because it's plural multiple right
but and then there's a lower overhead of
execution model because now if you think
we are ticking we're doing with sticks
and process and all that on this each
component right if we take sixty four
elements and then do a 50 right we do
one tick on 64 element then do a 50 then
do one process on 64 elements so we
amortize it right we don't have to do 64
times and and many many very often these
things are the overhead goes away you
won't even see it right and then there
is a faster mem copy simply and a better
cash locality this one I don't know how
to quantify but we can see that you know
you you're running the same operation
again and again so you have instruction
cache data cache everything is still hot
whereas if you go across the whole thing
and come back then you can have the you
can get your cash tail ok so why is this
a difficult problem can I just not boot
blast it to whatever I want to do and
then you know there's so here's the
thing so this is our this is our Wi-Fi
with bit more details this is actually
the transmitter now this is not receiver
so let me give you a bit more details
what it does so now here the input is in
bits ok so input is in bits and first
thing that comes in the header so I see
need to see the header and I know where
in the header is the data right right so
when I see the data rate then I and so
this is a computer which goes to the
bits and that it's actually wrong it
should actually process these bits there
is something here missing right
because these beats the header has to be
sent as well so it's just missing part
but but once this process is the header
right it then needs to stop and and send
the message here saying what is the
length of back in what is the data rate
okay and then the rest of the bits they
go either to this or to death so there
is this special if block which will
decide whether this thing goes here
there the design is alive I don't know
how to design this in blocks but
basically this block controls where this
one goes but it's also the control block
basically it's going to send the control
message either to this or that the
length of what is the length of this
package okay and now we'll run into this
block or that block so now if you look
at these blocks what do they do so this
bit is this block is crc calculate crc
so CRC is kind of state machine adjust
them source things and so on so
basically if you look at the specs it
pretty much operates on bit you do some
kind of maybe pipe i think it's bits if
you look at the scrambler we've seen
scrambler we see it again takes a bit
does some soaring and something around
there and that's bit one half encoder so
this is the encoder 4 but basically
takes one bit produces two bits so this
is to protect your data from
transmissions right and then you have
interleaver so interleaver takes 48 bits
and amid sport a bit so why is it 48
because it's in the level of an OFDM
symbol so nvm symbol takes 48 bits will
see that later but basically it takes 40
a bit just permute them around and then
it says and then it does bpsk so dpsk
does is basically convert this one bit
into a complex number which is n qs ok
so that's one to one but now this is for
six mbps the other one is I believe
54mbps right so if i look at 54 mbps so
crc is the same scrambler the same now
the encoder is treated for ok because
it's a different encoder I need to take
three bits and I need to do to encode
forbids the interleaver is now much
bigger so why is the interleaver bigger
because so it's does shuffling over that
but let's look at these is this
the modulated module to take six bits
and produces one complex number so as I
said in there on the interleaver is to
shuffle around bits that belong to the
same RDM symbol or DM symbol has 48
complex numbers so if i look at six x 48
it's going to be 288 right so that's how
these numbers came up and this is
specified in standard if you go to the
standard you'll see this is the way
interleaver works so the point being
here is that these numbers are not
something I came up with this is in
standard if you go carefully to standard
it's there so there's no optimization
and this is how it should be this is how
you should write your code shouldn't
think of anything else this is in the
standard okay you have to respect it so
you put these numbers that there are in
the in the code and similarly here now
what is the issue with that so suppose I
want to lift this okay so now I said
okay let's make this a bit make this
eight bits now this one for some reason
I'm going to do four to eight bits
because I want to do a lookup table so
I'll explain this later but I don't want
it to be really big and this guy I want
to do 48 48 bits and this guy would be a
bit 28 complex numbers so i want to
vectorize all this so that's something
you could do manually so you know I can
say okay maybe it's just easy as that
now let's look at the other one now the
other one then the other one has to be
8888 2432 288 288 12-2 ok so again this
is the trivial now this guy it has to be
it has to be now it has to be 24 right
because it takes three bits input right
but this guy has a bit output or at
least we decided so and why do we want
we need to have these guys to have the
same input because we we serve them you
know we serve them with the same data
there's something serving data from here
so this weed has to match the both of
them so their wheat has to match because
they get data from the same kind of
input but the output here should match
as well right so so the key thing is
that these things are actually limited
by something
Arnold things inside right so so let me
see sorry it's okay there's one more
thing here which I forgot to mention is
that basically if you look at this
interleaver right it has 288 right so
now do it so suppose we send two bytes
in there and it goes here so I have
eight bits and I bit 16 bits or maybe
three ok so I'll fill up this guy a fill
up this guy and I fill up this kind of
get 32 bit and then I stopped so what
happens I have a stale data some data is
left here without ready to being
transmitted so by the definition of this
I need to have enough data to flush this
guy right this guy is built to work with
288 bits so something should tell me
that you know if I if I vectorize in
twenty eight inputs right I need to have
enough inputs to make it work right so
how do I do that so this is also in the
standard as well so basically standard
specifies that crc will be padded by 2
16 bits so it's not trivial mean the
reason is sorry the reason is that if
you are if you don't send at least two
hundred sixteen bits there you won't
have enough if you do the calculation
through all this to fill the interleaver
yeah I didn't plug I didn't think I
didn't do that here they should come
before that it's not important in I mean
this is just for there is the
vectorization bit here right so so but
and this is important because we have an
rtm symbol so if you don't feel the only
people will know one send it so will
never receive the speech so then this
guy will actually tell us okay this is
how much we we should send their and
this is this also is the user input
because it's in the specs right and that
so now what I want to do and similarly I
need to have at least 24 bits here
because that's what I need for padding
there so I actually I move that one
there and so but at the end of the day
okay I need to make sure that the input
here is kind of matching the output this
kind of matching so in a sense that so
here we can introduce like the
conversion from two to eight and so on
but there's there's lots of rules we
have to do in this we have to we have to
check and I'm not going to give you too
many details and if you're interested
you can again we can discuss and so on
but bottom line is it's not an easy
process and the problem is that you need
to respect all these constraints that
will cause you to lose to not have
enough data in particular for example
even here if i take too much data in
this guy i will take too much of the
header and won't have enough to give to
this guy I might lose some data in
process so we need to kind of carrot
carrot carefully do this to do this
dimensioning for this optimization okay
so the second one is the lookup table of
musician I think Kuhn had mentioned it
last week so I don't know if you
remember so but i'll give you kind of a
slow overview of that one so the key
optimization that's the key optimization
they make sort of transmission works
right and it's quite important because
the transmitter works a lot with the
with a bit right and if you don't and
this is not the natural environment for
it's not a natural environment for four
cpus 32 64 bit cpas right so
the key idea here is that you you have
we have to identify block of expression
that is doing operations on data and has
limited input and output size so in
principle I can use it on any data but
if I have an integer that input sizes to
the power 32 is already too large right
so this really only focuses on on on
binary inputs on their own big inputs
right and so we want to find in our
abstract syntax tree you know you can go
to the substance in the scene look at
every expression in the tree and you can
write a simple function for this and say
okay what is the number of inputs what
is the number of outputs that we touch
how can we actually how can we actually
can we actually transform this in a
lookup table and I'll give you an
example there so and then when we
identify this then we create a lookup
table and really just instead of doing
this whole operation we just do a big
table we look at inputs and outputs put
it in a vector of reading in the table
and then read from a table that we pre
created and this is very similar to fpga
compilation if you think of it I mean
they do the same thing it's a different
language you write lots of things they
produce loads of look-up tables the
storage in FPGA and then that's how
again so the technique itself is kind of
well done but in this context it's
fundamental to make things work fast
enough and in particular for bit
operations and we absolutely need to use
it that's them okay so let's see the
example of the scrambler that we seen
before right so in particular here so so
again this is the scrambler code which
basically starts from this state array
and then it kind of it goes to the so
these are the internal states so then I
take one bit right and then I do this
operation of it and this operation is
quite clean from here and that what we
discussed before and hopefully this is
intuitive I mean you can see what it
works and you can map to this figure
from the from the from the specs and
then you meet one bit so the question is
how do we make this one to work better
so basically what happens is that first
of all
what we can realize is that we can make
transform this one into a vector that
will take eight bits and I meet eight
bits so that's what is done here so the
we make it and we make it into this Alta
map but then we do this for loop right
again we do the first transformation
it's just saying oh I can vectorize this
up to a bit so instead of taking one
bitten doing this I take eight bits and
then for each of these bits I do a for
loop and I do my own code okay and so
now I analyze this code here and I see
well okay this code actually showed up I
can make it look up table let's see if I
have yet so this code here it's short
enough I can make a lookup table so I
decide to do this whole thing here and
this is the output of a compiler
basically which it put this loot here to
set aside to be a lookup table so how
does it decided so look at this code
here so what's in this code here sorry
heaven and I'm a variable that goes from
0 to 8 and then there is a vector okay
which which is a size 8 bits right this
guy here has eight bits and for each of
the 8 bit element we calculate this
formula here so this formula here
involves this temp thing the Scrambler
thing and there is this becht this guy
here so we can look at all the variables
and this is what the compiler does so
this tempting is really a temporary it's
a local thing which never actually gets
used in anywhere else right so if it
doesn't get used anywhere else we don't
care right it's just a local thing and
then this scrambler stating it is
actually a state that persists
throughout the loops right it doesn't
get reinitialized so this is our input
because whenever we come into this
lookup table this this trembler can
change right it's not an input from a
stream it's something that can you know
every time I do loop the state will
change so it is an input if you look at
just this code this is really an input
to this code
and then the the the the vector of X
really is so this guy's an input as well
right this is the input it comes from
there and this input is then the whole
are the whole the whole this whole array
which is also size 8 bit right so we can
do a fairly obvious i suppose
calculation of seeing if you go through
this how many input variables and how
many output variables affect this code
so is this kind of analysis clear do you
know how i calculate this or do you want
me to go slowly so basically i mean see
that what are the variables we use here
we use this scramble state right because
this will do something in the code right
so this is an input variable right we
have to we have to change it but this
vector a this this Lou loop right it's
not an input variable it's only internal
right it doesn't get seen any way
outside of this code right this thing
here right and similarly this temp here
it doesn't really get seen anywhere
outside of this code and why it doesn't
get dragged this gets here this guy gets
there so they don't get seen anywhere
else so we don't come them but we count
everything else that was seen outside of
the code so we count the Scrambler state
this guy here the vecht X i-25 and we
count these two so now there's
difference between input and output
right so this guy backed why I 26 it's
just being written into right so it's
only the output we never read from it so
we can be claritin output variable okay
and then a scrambler state is also an
output variable but it's also an input
variable so we put in boat and this guy
here is an input variable okay so once I
give you these two inputs right you can
do this code at home and give me the
output I don't need to do know what you
did right just do it at home giving up I
give you another input you give me the
output okay so i can do it two ways i
can either run this code for when
whenever i have input output or i can
pre calculate the
the result of this code for all inputs
and outputs and just look up for the for
this right and so that's the key idea
and I think that's a so the key question
here is does it make sense to do it
right if I have a big cold right i mean
i could hypothetically I mean
conceptually I can do that for any
computation in the world but of course
only if the inputs outputs are small we
can do that but the key kind of thing
here is that really our the the fact
that we write the compiler so that we
have this abstract syntax tree allows us
to go through this and analyze and
understand figure out what are the
inputs variables what are the output
variables what are their types so we do
all this automatically right and we say
okay this is this is the so we can
actually do it and so we're looking at
this right the input variable are these
two they have 15 bits right so we need
to have to to the 15 inputs in our
lookup table right for every possible
input we can have we need to have an
input in lookup table so when you give
me or when I give you these two
variables right you give me this big
table and I just put them together merge
them together and I create an index
which i'm going to read into and then
the output is to bite so whenever I give
you one of these big once you give me
two bytes so the total size the lookup
table is to 2 15 x 2 x 64 kilobytes but
that's really not big right and it makes
things much faster again the thing is
that we can we have the code so we can
analyze this and we can just do it we
can do it fully automatically we don't
have to think what can be optimizing son
it doesn't have to be an obvious
expression right the compiler goes to
all possible expressions if this one
cannot be vectorized then maybe just
this one can be vectorized right it goes
through the synth extreme you can see
potentials that you can't even see none
of them will be efficient up so you know
it's not super powerful usually use you
intuitively feel some of these
expressions but yeah so that's the okay
so I'm thinking whether
okay let's try this one and then finish
with this for today um so yeah go ahead
at the beginning of that so we we had
two implementations one is static and
one is dynamic so static could actually
you know with the static one we had a
huge see files will be a static array
and now we have something that when you
start the code it runs out and crazed
the tables because it's it's a technical
detail right but either way it has to be
run loaded before you even started it
that's a that's a good question so it's
actually okay so one thing that is
interesting with all these architectures
we are targeting and I don't know if
couldn't discuss this in a solid
description but basically if you think
of fpga I kind of architectures your
timing is guaranteed right you can do
everything and you know if designing for
clock cycle you respect the Canseco with
PC kind of architectures all bets are
off in particular because it's real it's
not a real time operating system we are
running windows which is so we're doing
kind of tricks for QRS in internet right
we are under twenty percent of
utilization so we hope it's going to go
fine but if it comes to 90 we're screwed
I mean there'll be problems and so so
with this with respect to these tables
similar thing there is no hard answer we
cannot check that because the there is
no constraint we can say this much
stable can fit in the OS will accept 7
terabytes but it's going to be it's
going to be flushed in and it's going to
be spawned into the on the disk and we
clearly don't want to go there right it
just it's going to run but it's going to
be very slow so there is no clear answer
to it right now the thing is that what
we do is a kind of am as a heuristic
it's just saying the single lookup table
shouldn't be too large maybe 256k the
other problem lookup table is if it's
too large you will start missing missing
l2 cache and it's about two megabytes
plus right so if you make it more than a
megabyte you can see a big penalty of
actually because you're going to
randomly jump right so it's actually
been better to have smaller table then
very big one so you shouldn't be too
aggressive creating the size of each
table then in particular for them for
the ones we've seen here I guess the the
size the look-up tables actually repeat
so we do some caching and make sure
they're not too many of them and then
also we seem like I don't know 10 20
look-up tables in the code here as well
so it's not that much if you go wild yes
it can happen the other thing is also
then with respect to cache is right if
you have enough vectorization and here I
didn't talk about it but you can
vectorize it
multiple levels you can vectorize to
make lookup table so you can vectorize
around looking table so if you vectorize
so let's say we do you have a huge chunk
of data right but look up tables in size
eight so we take eight give it a QB
there eight give it a try what other
thing we can do we can take eight give
it there and pass it down the pipeline
and we do all the things come back up
they can add rate give it to look up
table and pass it so what happens when
you do this whole thing is that you have
a cache miss potentially every time
right I have a huge chunk I just keep
quoting lookup table while it's all in
the cache its then running faster so
that possession there is helpful but
again there is no firm guarantee we can
give you that's the biggest problem the
only thing we see is that we run we see
that we are sufficiently faster than PC
so works fine okay so I guess ok let's
leave this example for a to warm up for
tomorrow then I think is this yeah this
was an hour right so and then allah so
i'll give you tomorrow basically i'll
give you some code examples so the idea
is that we have a little bit more give
you some numbers on Wi-Fi and so on and
then i want to go through the Wi-Fi
design and on one hand show you how we
can express it in Syria language but
also really run through the examples
with you and and and show you why Wi-Fi
design is by design so we can run small
and you'll see how it's actually easy to
write this code write the code and show
what are the effects of multipath what
is expected of channel equalization why
do we do ofdm how what are the kind of
rationale behind choosing Wi-Fi and it's
really not the kind of state-of-the-art
Wi-Fi design but it's something that if
you want to play with these things you
should know and i think it's i don't
know it's a it's a maybe a good point to
to revisit that if you haven't heard if
you heard it before so yeah that's all
for today then and see you tomorrow hope
to see in the same number in particular
peter lely here afterwards so I wouldn't
sent you to come
yes</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>