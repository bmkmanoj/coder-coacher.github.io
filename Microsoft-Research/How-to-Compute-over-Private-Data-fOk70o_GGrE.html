<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Compute over Private Data | Coder Coacher - Coaching Coders</title><meta content="How to Compute over Private Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Compute over Private Data</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/fOk70o_GGrE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
hi hi it is my pleasure to introduce Zi
Cong from University of Pennsylvania Z
may be familiar to some of you since his
intern here with the theory group are
twice actually and z is also a recipient
of the Simons graduate fellowship which
believe it or believe it or not is
somewhat more prestigious than being an
intern here twice so he's going to tell
us about how to compute our private data
okay okay thanks Nick you and it's a
pleasure to be back so yeah what I'm
going to talk about today is about
competition over private data and I
realize there's some talk about data
pride and privacy in the building today
so part of my talk will fit well into
that theme so the plan is to first go
for the background define what i mean by
computation over private data and what
specific challenges that we're facing in
this problem and then i'll talk about
what my co-authors and i have done for
this topic and finally wrap up by
listing a few direction that i'm keen on
pursuing in the future okay so let me
get started I would like to start with a
brief I'll revisit of what is
commutation and what is algorithm so
abstractly each conventional problem can
be defined with a set of feasible
outcomes some input data and the
objective function which we use to
measure how good each outcome is right
so for example if you think about Max
way matching then the set of these by
outcomes are the set of matchings in the
graph the input data are the weight of
the edges and the objective function is
simply the total weight of all the edges
in the matching okay now given such a
computational problem an algorithm can
be view as the input output interface
where the algorithm designer carefully
choose some machinery in the middle
which take the data as input and then
choose the outcome from the feasible
range accordingly to optimize the
objective however in this model there's
a big
that is all the necessary input data are
given to the algorithm designer for free
it's that really the case in fact for
many combinational problems in modern
world especially those that arise from
the internet or electronic commerce
that's quite often not the case because
these problems usually rely on the
private data helped by self-interested
agents as their input so the picture
looks more like this where the algorithm
designer need to first gather the
information from a bunch of agents say
Alice Bob and Charlie as in this graph
and then depending on what these agents
report which may or may not be the true
underlying data the algorithm designer
need to choose the outcome from the
feasible range and as a result it's
natural to ask can we design algorithm
in the some specific way maybe sometimes
with the help of appropriate payment
scheme such that we can convince the
agent to share the two data so make it
to make a distinction with the algorithm
in the more traditional environment I
would like to refer to the algorithm in
the presence of private data and
self-interest agents as mechanisms which
is the standard notation in the
literature so in order to design a good
mechanism one need to take into account
only the usual limitation on
computational power but also some new
challenges imposed by the social
economic or personal considerations of
the ages so to motivate what specific
new challenges that we are facing I
would like to talk about two
illustrative problems the first
illustrative problem is about allocating
one resource to a set of agents say
allocating a new iphone five to one of
Alice Bob and Charlie and we will like
allocate the iphone to the agent with
highest value for the app so what we
might want to do is to run the famous
victory auction or the second price
auction we first let agents amid a bit
different ages might have different
values for the iPhone and then depending
what the bill is we were located iphone
to the highest bidder Alice in this case
and we let the winner Alice pay the
second highest bit 199 dollar and the
victory auction has many nice property
first of all encourage the agent share
the two valuation
are in the sense that that always
maximizes their utility defined to be
the value for the iphone if the agent
get it minus the payment that they need
to pay so clearly Alice has no reason to
lie because she's getting the iphone and
there's nothing she can do in terms of
lowering the price because that depends
on the second highest bid and also Bob
and Charlie do not have incentive to lie
trying to win the iPhone because in
order to do so they will need to pay a
price that's higher than their value and
secondly the victory oxygen maximizes
the social welfare which is defined to
be the sum of agents value for the
outcome and in this specific case is
simply the value of the Asian who get
the iphone so by definition we are
allocating to the highest bidder and by
the fact that we are encouraging the
agent who tell the truth we're
maximizing social welfare and finally
the victory oxygen has a very simple
format it can be implement in
essentially linear time because all we
need to do is to find the highest bit
and second highest bit not so far so
good but that's only for allocating one
resource in more generally we would like
to be able to handle multiple resources
and maybe more complication area where
agents have comunitario valuations over
subset of resources in the sense that
the value for self set of item may not
simply be the sum of the value for
individual items right so this is called
a complete horrible oxygen problem
arguably the most study program in the
literature and it also captures many
resources allocation problems arise in
practice for example the auctions
forever ties men slots or the FCC
spectrum auction between the government
and the companies and of course this is
a classic economic problem is very well
study by economist one of the solution
they propose is which always a locator
resource such that we maximize Social
Welfare and if we do so they exist some
payment scheme that will encourage the
agent to share their to value and this
is called VCG auction unfortunately we
also know that maximizing social welfare
is np-hard in general and therefore
implementing VCG is NPR in general this
work left to be done so for this kind of
resource allocation
problems other than the limitation on
computation of sorry for this kind of
resource allocation problems are other
than the resource the limitation on
confessional power we also face a new
challenge of the game theoretic
constraint in the sense that each agent
has some utility that directly generated
from the outcome of the mechanism and
therefore if they can lie or decide not
to participate are to improve their
utility that we wear out do so and this
game theoretic constrain has received a
lot of attention from the theory
community over the past decade and lead
to this very exciting field of algorithm
mechanism design which study how to
design mechanism that run in poly time
and take care of this game theoretic
constraint and the solution concept are
in this literature is to restrict our
attention to the truthful mechanisms
which always encourage the agent you
tell the truth by making sure that
maximizes they expected utility and the
central question are in algorithm
mechanism design is how to design
conditionally efficient and truthful
mechanisms with good social welfare
guarantee now as a quick remark there
also exists other interesting objective
in mechanism design such as maximizing
revenue or ensuring some notion of
fairness but for the purpose of this
talk I'll focus on social welfare
maximization which is the most study
objective in the literature okay so
that's the first constraint the game
theoretic constraint now let me move on
to the second illustrative problem
suppose we want to release on the
average salary of all the employees in
the company say in Microsoft so of
course this is easy to compute the
average but if we release the exact
answer that might be problematic because
by comparing the average salary before
and after Bob join the company the
adversary will be able to learn exactly
what Bob salary is which is considered
to be a sense the personal information
that should not be revealed to the
public so what we may want to do is to
release a noisy answer by running the
Laplace mechanism so we'll first let a
trusted third party called a curator to
solicit all the salaries of the agents
and then we compute the average we
sample a noise from the Laplace
distribution which essentially the
exponential distribution mirror in the
y-axis and then we sum them up and
release the noisy answer okay now the
point is if the Mercer again tried to
compare the noisy answer before and
after Bob join the company then the
estimations you will get where has the
error that's roughly n times the arrow
we are get adding to the average answer
so where n is the number of agents so
when the number of agent is large
there's hope that we can add very little
noise to in terms of the average answer
but but adding a lot of noise in their
various estimation so in other words we
protect the privacy of each individual
agents salary while providing reasonably
accurate answer in terms of this average
salary and finally it also has a very
simple form and can be implement in a
competition or efficient manner okay so
the example we're trying to give
reasonable skills in this is the error
you would add to the average if you're
releasing
to the average haha and release it seems
that seems in order to get to hide Bob
salary you just need to add an air of
scale down by the non-violence number of
P
yes also this is this is like adding a
huge error to the Africa the skills you
really ah so so in this illustrative
example I'm only writing like three
agents here but in you know in general
we will assume there are a lot of agents
describe one example of a large company
okay right yes yes yes so yes you will
make a very good point that if they're
only three agents in the picture then
probably it won't be very private for
the agent because essentially each agent
will has a substantial contribution to
the average but in general we would like
to consider large number of agent okay
very good point so okay now again that's
only for releasing one numerical query
and in general we would like to be able
to answer many many queries about the
same database so we would like to
consider one data universe which specify
are the possible sensitive types of the
agents which might be there their
demographic information or their medical
records or their salary and so on and we
like to consider a database that contain
the sensitive types of n agents what we
would like to do is to answer the
predicate queries asked by data analysts
where each product query is specified by
a predicate function mapping from the
data universe to real number between 0 &amp;amp;
1 and given such a query the exact
answer is supposed to be the average of
value of this predicate function taking
over all the elements in the database
okay so here I'm abusing notation a
little bit because when we talk about
predictive function usually we mean
boolean function better I'm allowing to
map 2011 ok real number so the protocol
queries captures many useful our queries
in practice to give you some example if
the data universe consists of numbers
between zero and one that we may ask
about the mean or higher moments about
the numbers in the database or if the
data universe consists of BB boolean
strings then we may ask about what's the
fraction of agents who sensitive types
satisfy some conjunctive boolean formula
or general boolean formula and if the
data universe are other points in some
magic space for example the D
dimensional
cube in the euclidean distance space
that we may ask about the distance query
where each query is specified by a point
in the metric space and what we like to
learn is the what's the average distance
from the query point or the point in the
database and this kind of query might be
useful if we want to pick a location for
building a new facility and we like to
learn how convenient is this new
location in terms of the average
distance to other citizens in the
database now for these kind of queer
release problems the agents has our
little or no utility that directly
generated from the outcome of the
mechanism but nonetheless are they may
still decide to lie about the private
type or design not deposit participate
in the survey if the curators answer
will lead to much information about the
sensitive type because they may worry
are leaking the leaking of such
information might hurt the utility in
the future so this is the privacy
constraint and it has lead to the very
fruitful few of differential privacy
which study how to design mechanism that
run in poly time and take care of this
privacy constraint and the solution
concept is to consider differentially
private mechanism that roughly speaking
whose outcome distribution is
insensitive to the change of one agents
private type okay and more formally are
by insensitive what we mean is that
suppose we fix the type of order agent
except Asian I that no matter what agent
I reports the probability that we would
choose a specific outcome changes by no
more than e to the absolute vector for
some small constant epsilon ok
essentially it's is saying that the
infinite divergence between the outcome
distribution for two neighboring
database are is bounded by epsilon okay
so are given the definition the central
question for differential privacy is to
study how to design competition
efficient and private mechanism that can
provide accurate answer for the queries
asked by the annals about the database
okay okay now so far i have defined what
is contained over private data and i
have specified two challenges the game
theoretic constraint and the privacy
constraint so before I move on to the
technical part is there any question
about a okay so now let me talk about
what my co-author and I have done so it
will contain of a consists of three
parts in the first part I'll focus on
purely the game theoretic constraining
and we'll talk about how to solve the
social welfare maximization problem via
the black box reduction technique and
the second part I'll focus on purely the
privacy constraint I will talk about how
to design mechanism for answering the
distance queries and finally I'll
briefly go over our result on how to
design mechanism that can handle both
constraints simultaneously so for the
first part I'll get into a little more
detail and for the attitude part i'll be
a little brief okay okay now let me move
on to the first part the game theoretic
constraining let me remind you the
central question is how to design
conditional efficient and truthful
mechanism with good social welfare
guarantee now suppose we take away the
truthfulness requirement for a second
then this is well defined optimization
problem and as computer scientists we
are trained to be able to design fast
algorithm for solving optimization
problem either exactly or approximately
and indeed our condo scientists have
developed very proud many powerful tools
for solving optimization problems in
party time now if we put back the
truthfulness requirement than the
problem of designing conditional
efficient and truthful mechanisms
despite of many exciting progress over
the past few years remain a much much
less understood topic so it is natural
to ask can we reduce the less understood
mechanism design problem to the
barrenness dude algorithm design problem
now this question has motivated me
among many other researchers to look
into the following sort of a holy grail
for algorithm a mechanism design which
says that can we convert any algorithm
into a truthful mechanism with
essentially the same social welfare
guarantee while the running time of the
mechanism is no more than a polynomial x
the running time of the algorithm if we
can give a thermal avancer to this
question that would be great because
that means that some machinery that will
automatically take care of the game
theoretic part and we can simply focus
on the optimization part which is a much
more familiar terrain for computer
scientists and our main contribution is
that for many problem the answer is yes
there exists such a reduction and in
particular we show that for all problems
in the patient setting which is the
standard economic setting are the answer
is yes this is John work with a shallow
bay and of course as computer scientists
we are also interested in private
setting and worst-case analysis and we
look into that as well so we show that
for one subclass for all single
dimensional and symmetric problems in
the private setting the answer is yes
the existence or reduction so here the
single dimensional means the private
valuation of a agent can be written as
in a simple form of a single real number
and symmetric means the set the feasible
outcome is the magic pick any feasible
outcome then no matter how we premiere
the identity of the agents it will
remain feasible so arguably a relatively
natural restriction to add so that's our
result so due to time constraints I
won't be able to talk about the
technical details about the private
setting but I will go over how we design
the black box reduction for the patient
setting okay okay now let me move on to
the patient setting let me be more
specific about our our setting so again
there's a set of feasible outcome and n
agents and each agent has a private
valuation function mapping from the set
of feasible come to real number between
0 1 which specify how much this agent
like each outcome and we make the
patient assumption in the sense that we
assume this variation VI is drawn from
some public known distribution F of I
which is public known and agree
across different ages okay and for the
sake of presentation I'll think about a
somewhat simplified setting I'll imagine
this a list finite list of possible
valuation each agent could have and the
prior distribution simply says that it's
equally likely each of the violation is
equally likely to be realized as the
true valuation for the agent okay it's
uniform distribution now for this
setting what we show is that any
algorithm can be converted into a
truthful mechanism or by using payments
and with no loss in Social Welfare and
polynomial overhead in running time and
the notion of truthfulness we consider
here is that telling the truth maximizes
the ages expect utility where's the
expectation is over the randomness of
the mechanism and also real a random
realization of our agents type assuming
the other agent how the truth okay it's
a base base nash equilibrium okay so are
now let me first tell you about the
basic framework of our black box
reduction so again the algorithm can be
viewers a input output interface where
in this case the input are simply the
reported valuation of the ages what we
would like to do is we would like to
decouple the report violation by the
agents and the relation we use this
input for the algorithm by using some
carefully designed perturbation
algorithm Sigma is one for each agents
and what we would do is use the
perturbed valuation as input for the
algorithms and then use what the
algorithm output as the output for the
mechanism so are in this basic framework
I haven't talked about payment yet are
and that's because by relatively
standard technique in mechanism design
once we fix the outcome of the mechanism
the payment can be derived automatically
so I ignore the payment in this
framework but i'll talk about out
precisely define what the payment are
when i get to the particulars so given
this framework it remain to our desire
how to design this sigma
is right so in particular I would like
to design a sigma is such that they
satisfy three properties the first
property i would like to impose is
stationary in the sense that if the
input for some sigma i really follow the
uniform distribution over the support
then the output sigma v i also follow a
uniform distribution over the same
support so in other words distribution
wise this perturbation algorithm is not
doing anything okay and the reason we
like to impose the stationary constraint
is that we allow us to the couple are
the correlation cross different ages in
the sense that from asian one's
viewpoint now it is as if the
perturbation for our agent do not exist
right so that will allow us to focus on
the problem of designing one
perturbation algorithm subject to this
stationary constraint now subject to the
stationary constraint i would like to
make sure the social welfare do not
decrease and in particular will make
sure the expected valuation of each
individual agent do not decrease and
finally we would like to impose the
truthfulness into the picture okay so
these are the three goals in designing
the signalized now let me go to the
particular is on of the sigma eyes so
the first observation is that are the
natural correspondence between our
stationary perturbation algorithms and a
bipod bipartite perfect matching in the
following graph i would like to
associate every possible variation in
the support with the two verses in the
byproduct graph one on the left hand
side we call it this replicas and one of
the right hand side recorded surrogates
essentially the replicas correspond to
the reported types of the agents and the
surrogates correspond to the perturbed
type output by the perturbation
algorithm now suppose we have the
perfect matching in this bipartite graph
I claim that that naturally correspond
to a deterministic and stationary
perturbation algorithm in the sense that
given any prototype I can look into the
replica find a correspondent replica and
see which rep surrogate it get matched
you a nap with that surrogate hype right
and since this is the perfect matching
if the input is the uniform distribution
of left hand
vertices then the output is the uniform
distribution of the right-hand side
versus so it will be stationary and it
is actually not difficult to show this
is one-to-one correspondence so it
remained to decide which perfect
matching to use and in order to do that
I would like to introduce the following
interpretation i would like to interpret
the replicas as virtual agents and the
surrogates as virtual items in the sense
that each surrogates from agent
viewpoint each circuit essentially
correspond to a distribution over alqim
sort of a lottery because once we fix
the perturbed type we use for age and I
than this well define distribution over
feasible outcome over the randomness of
the algorithm and also over the random
realization of our agents type so given
this interpretation we can talk about
what's the expected valuation of one a
virtual type T virtual agent for a type
T prime virtual item will define this
value or the weight of h TT prime to be
the expected value for agent I if agent
I has type T and we use T prime as the
petal type okay so essentially what we
are doing is we are using the Beijing
assumption to create a virtual interface
a virtual market for the agents such
that from each agents viewpoint it is as
if the agent is really competing in this
virtual market in which instead of
competing with odd agent the agent is
competing with other possible realized a
station of his own type okay and
moreover in this virtual market we have
the simple structure of a matching
market for which we know how to solve
the social welfare optimization problem
exactly so we can simply run the VCG in
this virtual market
is the algorithm that we are given as a
black box so yes so this expectation
will be over the randomness of a the
random coin flips of a and random
realization of VI v- I
ok
okay so um right the teeth you are using
he is the other piece there DCPD want me
to these are the possible type of
possible valuation of age and i and t 1
to t KR all the possible valuation in
the discrete support these are eligible
valuation violation functions it could
be a multi dimensional vector
but
so but what about the beer and then
the ice also functions PIR are the
collection of the validation function of
all age at exit age and I a VP msi is it
a collection yes as well yes
so beaten piece
different letters B and T are in the
same space yes I'm using key to specify
sort of the possible valuation of one
specific agent H&amp;amp;I but yeah they're from
the same space yes ok so again so we
have created this virtual market that
has the matching market structure and we
would like to run BCG so precisely what
we mean is that will find the max way
matching with respect to the way that I
just define ah we will use the
stationary perturbation algorithm
corresponding to that max weight
matching and then we will charge the age
and the price that equal the VCG price
in this virtual market now let me show
that we have achieved all three are
property that we are aiming for so
stationary is easy again since we're
picking one perfect matching and using
the corresponding perturbation algorithm
that's stationary uniform distribution
we match to uniform distribution in
terms of social welfare are it's
actually not difficult difficult to show
that the expected value of the agents
subject to this perturbation is
proportional to the social welfare in
this virtual market because if you think
about the edge that we pick incident on
the type T that equals the expected
value for Asian I condition on his shoe
value being key so when we sum them up
it's really the expectation expected
value of the agent scale by K ok now the
algorithm is essentially using a naive
identity are matching What's in equals
what's out and the maxim is doing
something more clever which using the
max way matching and therefore are the
social welfare in this virtual market
can only increase and as a result
expected value of the agent in the
original market can only increase and
since that holds for all agent the
social welfare in the original market
can only increase and finally we we have
imposed truthfulness because from the
agents viewpoint it is as if he's really
participating in this
virtual market and since we are running
vcg in the virtual market are we ensure
truthfulness for the agent okay so
that's essentially the whole proof idea
modular some details that will allow us
to generalize to marginal distributions
okay all right now let me wrap up the
plan black box with Dutchman part by
giving you a summary of what has
happened and where our result stands so
for the patient setting our work is
motivated by this very nice work by
hardline Lucia that solved the problem
in this restricted single dimensional
setting and we have extended to the
marginal multi-dimensional setting and
our result has also been independently
discovered by hardline climb very
mullerian and in the private setting of
things are more incremental in the sense
that the positive results are authors
are restricted subclass of problems and
we solve one relatively general subclass
the symmetric and single dimensional
problems and moreover our things has to
be incremental in the sense that for
both the single dimension and the
multi-dimensional setting there are
impossible in possibility result that
shows that it's impossible to get a
general black box reduction that work
for all problems so we have to utilize
specific structures of the problems to
get positive result okay all right so
that wrap up the game theoretic part now
let me move on to the privacy part so
for the products apart again the goal is
to design efficient and private
mechanism that can provide accurate
answer for the queries asked by data
analyst for this regard there exists a
very general positive resolve that allow
us to answer k predicate queries with
this error so let me say a little bit
how to interpret this error so first of
all the dependency on n is roughly 1
over root n so the larger the number
number of agent is the more accurate we
can get and also it's 1 over root end so
it's roughly the same error as the
sampling error and secondly the
dependency on the number of query k is
logarithmic and therefore we can answer
exponentially many queries while having
non-trivial accuracy small of one
accuracy unfortunately this very general
pulse result is inefficient and the best
running time per query is linear in the
size of the data universe which can be
exponential in the dimension of the data
universe and moreover that's not just
because we're not creative enough there
exists strong evidence showing no
efficient algorithm can privately and
accurately answer more than
quadratically many queries if we insist
on answering general our predicate
queries so given this very general
inefficient positive result and this
very strong lower bound result it's
natural to ask are there interesting
subclass of the predicate queries for
which we can design efficient mechanism
that can privately answer much more than
quadratically many queries right and our
main contribution is again provided
affirmative answer to this question by
showing that the distance query form one
such subclass and let me remind you for
distance query the database consists of
a bunch of points in some metric space
and each query is again a point in the
magic space and what we'd like to learn
is the average distance from the query
point to all the data points in the
database okay so specifically what we
show is that there exists a query
release mechanism who's running time per
query is nearly linear in the size of
the database and we can privately answer
arbitrary number of queries with the
following error if the magic is l1 or lq
we can answer with small o of one
additive error and if for we are talking
about arbitrary metric then in addition
to the small one additive error we also
lose a lock hey this multiplicative
distortions where case the number of
queries okay so that's our result are
now let me briefly sketch our approach
yep are you doing Eric singleton
ready ah yes the additive error is in
depending on where essentially will come
up with a sort of a proxy function R and
then we will answer all the query using
the proxy function without further
access to the database nearly exactly
but yeah that's for the first result and
for the second result are we where in
this batch model where we've given all
these queries and then we will design
our mechanism so utilizing the structure
of the query but for the l 1 and l q we
were in this online or offline model we
can come up with a offline proxy
function that can answer all queries
about the database okay so let me
briefly sketch our approach are at the
high level our approach depend on this
nice relation between query release and
learning algorithm that is established
by in a serious work so essentially we
can view the database as a function
mapping from queries to answers okay and
then we can first use some learning
algorithm to learn a proximate version
of this function called a proxy function
and then we will answer all the queries
as by data analyst pyar the proxy
function now in this picture the only
place we need to access the to database
is why this learning algorithm so
suppose we have a very good learning
algorithm that can learn this
approximate function using only few
updates that means we only need to
access the two database a few times and
therefore the total privacy laws will be
small so in some a good learning
algorithm with few updates implies good
quick release mechanism with small
privacy laws okay and in particular we
will design such a learning algorithm or
directly for some privacy friendly magic
namely the error metric so what we
utilize is therefore L 1 the function
that we need to learn can be decomposed
into a bunch of single dimensional
functions and also these single
dimensional functions are convex
ellipses continuous and we will utilize
all three properties to design them a
efficient learning algorithm that only
use a few updates okay so let me skip
the detail for how to design this
learning algorithm but let me talk about
how to are now handle arbitrary queries
our approach is to reduce the problem to
the problem for l1 via the match
embedding technique so the high-level
approach is
we'll first pick up a low distortion
match embedding from the given metric
space to the to some error metric space
and then we will embed all the data
points in the original database to a
proxy database with respect to l1 magic
and then we will run our mechanism for
l1 over the proxy database in the sense
that will embed any queries using the
same embedding and ask the embedding
query to the proxy database and get back
the answer ok
so I'm embedding all the points that's
in the original database yes it's a
case-by-case thing in some nice case
when they sell 12 l TTL one then it's
Universal but yeah okay so okay in this
picture the accuracy analysis is easy
essentially we lose a small additive
error due to running the l1 private
mechanism and also a multiplicative
distortion that equals the distortion of
the match embedding the tricky part is
the privacy analysis because although we
are running a private mechanism over the
proxy database the embedding step is
self my leaked information so we want to
avoid that right so what we observe is
that in order to ensure privacy is the
physis to focus on the low sensitivity
embedding in the sense that changing one
data point only change its own embedding
does not affect the embedding of other
points okay so if we can ensure that
then change in one point in the original
database we're only changing one point
in the proxy database now by the fact
that we are running a private mechanism
that will not change the outcome
distribution by too much so that will
ensure privacy but so now remain to show
that that do exist interesting low
distortion embedding that has low
sensitivity right so briefly speaking
from l2 l1 there's a classic result are
that has distortion essentially
arbitrarily close to one that's based on
random projection and therefore the
embedding is independent on the data
point and therefore we get low
distortion for free now when we go to
arbitrary magic there's another classic
result the Balkans theorem but the book
is theorem heavily relies on the
structure of the data point and does not
has low sensitivity so the way we get
around this problem is by observing by
observe that we don't need to preserve
all pairwise distance we all need to
preserve the distance between query
points and the data points and in order
to do so it suffices to use a ball game
embedding only with respect to the the
query point and that's in enough to
ensure we're preserving or the distance
between query point and data point and
therefore we get low sensitivity is
lovely lovely gateway exactly okay
didn't stand what do you do with the day
so what do you do with the data points
so you're interested in
from so I'm only interested in
preserving the distances between query
point and data point it's okay to have
the distance among data points or the
distance among query point will be
highly disordered and for this weaker
notion of distortion guarantee it
suffices to only utilize the information
about the queries like I can't resume
building the video point also I'm
embedding the data but also but the
design of the embedding function only
depend on the query point or just in
general you lose something yes yes it's
a very it's a variance of the pokings
theorem but essentially we can follow
the same proof structure with some minor
technical twist that's allow allow us to
show this low in it's not black box
production but from the high level it's
that's the idea yeah
okay so okay now let me move on to the
final part how to handle both
constraints simultaneously so this line
of approach this line of work is
motivated by the fact that for many
mechanism design problems not only the
game theoretic constraint is important
the privacy constraint is also important
for some problems this is because the
private valuation of the agents or the
companies might be regarded as business
secrets that they have devote a lot of
research in the market and so on to
realize this secret and they don't want
to review the secret to their
competitors right and is some other
settings maybe we would like to protect
the privacy of the valuation function
because this valuation might depend on
other sensitive information about the
agents for example if we think about
complaint or a public project problem or
where a government want to choose a
subset of public project to invest in
subject to some feasibility constraints
say we can invest in no more than K
projects then the ages value might
depend on their sensitive data for
example if the projects are locations
for building new hospitals then this
valuation might depend on their medical
records so that's the natural need to
protect the privacy of the agents value
so the central the open question in this
field before our work is that is it
possible to design truthful at
differentially private mechanisms with
new social welfare guarantee again we
are focusing on maximizing social
welfare and there's some previous work
that gave some positive results either
for achieving approximate truthfulness
all for getting both exact truthfulness
and differential privacy for special
cases what's been lacking is a general
technique for achieving exact
truthfulness and privacy for any
problems and our main contribution is
again a affirmative answer to this
question the answer is yes there's a
general technique for doing so and the
way we do it is by showing that the
well-known exponential mechanism in the
privacy literature which choose the
outcome from the feasible range with
property proportional to the exponent of
the social welfare of this outcome
scale by the privacy parameter excellent
divided by two is truthful when we are a
cup we couple this with some appropriate
payment scheme okay and AH let me give
you a one slice sketch of the proof many
of you are familiar with this may be our
the exponential mechanism can be
characterized as maximizing the
following free social welfare which is
defined to be the expected social
welfare over the distribution of outcome
plus the Shannon entropy of the outcome
distribution skill by two over epsilon R
this fact is known in different names in
different fields for example in
statistical physics it's known as nature
keeps measure minimizes free energy or
in learning it's known as regularization
with Shannon entropy on the way we
interpret this is that suppose we think
about picking a instead of picking one
outcome we pick a lottery of outcome or
a distribution over the outcomes and all
distribution are available on the market
then exponential mechanism is
essentially running the VCG mechanism
with respect to the original agents plus
one additional agent who is a pure risk
lover whose value equals the Shannon
entropy of the outcome distribution
scale properly by their privacy
parameter and therefore since vzg is
truthful we get that the exponential
mechanism is truthful by translating the
VCG payments back to the exponential
mechanism setting okay okay so now I
want to wrap up the technical part by
giving a brief overview of my research
so what I talked about today is my
thesis topic on algorithmic mechanism
design and differential privacy are and
specifically on social welfare
maximization via the black box reduction
technique and private Mac is a private
mechanism for releasing distance query
and truthful and differentially private
mechanism design i've also done some
work for mechanism design for revenue
maximization which i do not have time to
cover in this park but feel free to ask
me more about this offline
outside my thesis topic I've also done
some work in online algorithms during my
interns here specifically at work on
online scheduling problems and online
matching problems and finally outside
these two topics I've also worked on a
wide range of problems for example in
probability testings and generalization
of the sorting problem and so on so
again I would like to talk more about
this offline okay now let me wrap up
with a few future directions so for
mechanism design our black box reduction
technique among them with the results by
others and also the reason similar
result by Titus Caracas and Weinberg for
back box reduction for revenue
maximization indicates that algorithmic
maxim design in the patient setting is
easy in the sense that it's as easy as
the algorithm design program now on the
other hand there are strong negative
results showing that algorithm algorithm
design in the private setting is hard
it's much harder than the algorithm
design problem so it seems that if we
want to get positive results the Beijing
setting is the right setting to look
into however getting exact prior
knowledge is very difficult I mean in my
opinion it's unrealistic to get exact
prior knowledge
so yeah so this like a serious paper
showing stronger stronger harness
results
yeah essentially they are showing the
harness for a stronger and stronger
notion of truthfulness the original
results for deterministic truthful and
later for uniformly truthful and so on
okay okay back to my point although it
seems that we should look into Beijing
setting but getting exact prior
knowledge is difficult so I think it's
interesting and important to explore the
intermediate domain between patient and
private setting and there are many
interesting possibilities in between and
let me talk about one possible so maybe
we should look into the prior robust
mechanism in the sense that the troof
linux truthfulness is independent on the
correctness of the prior while the
performance in terms of social welfare
or revenue scales smoothly when we have
small errors in the prior estimation so
if we can get such prior robust
mechanism then we have more reason to
believe it will perform well in practice
right and there are other possibility to
explore this intermediate domain let me
skip that now for the privacy part the
theme I would like to pursue is to
design conventionally efficient and
private maksim building upon the many
exciting progress on the information
theoretic side over the past few years
and in particular the result that I talk
about in this talk show that for by
utilizing the structures of the queries
we can answer distance query in a
competition efficient manner so it will
be interesting to classify what
subclasses predica query can be answered
efficiently and what subclasses cannot
for example the convex predica query
might be one candidate you login to
where the predicate functions satisfy
the convexity constrained or we may look
into the conjunction which is another
wear while study type of queries in the
literature and on the other hand I feel
it would be important to develop
differential private version of
important algorithmic tools such as
linear programming and semi definite
programming which might be can be served
as an important building block for
designing
Maxim in the future and finally for
differential private mechanism design it
this is a much more open area so again
the first theme is to bring
computational efficiency into the
picture because the general positive
result that I just talked about is not
computationally efficient in general for
this regard I have recently makes some
progress are I realize that by combining
the convex rounding technique from the
mechanism design literature and
objective perturbation technique from
the privacy literature we can solve the
combinatorial public project problem or
in a competition computational efficient
triple and private manner and here comic
surrounding roughly speaking is the
technique in mechanism design that use
convex programming to design truthful
mechanism and objective perturbation is
roughly speaking a differentially
private way of solving convex programs
some specific convex programs okay and
it will also be interesting to look into
other setting for example maximum design
with our payments because for many
settings that's just voting where both
the game theory part and privacy part
matters its input inappropriate to use
payments and our technique crucially
rely on the use of payments so this is
another interesting direction and
finally I'm interested in this very
open-ended question what what's the
right model to capture both the game
theoretic and the privacy constraint so
our approach is essentially a by
criteria one where we would like to have
the mechanism that's truthful with
respect to the usual notion of utility
while we want to ensure the outcome
distribution is insensitive to the H
agents high but some may argue it's more
natural to model the privacy constraint
into the utility function in the sense
that we assume there's some disutility
that I'll capture how how much this
agent loss by how much this agent get
hurt by the information leaked by the
mechanism right but if we take this
approach and it's so far there's not a
very satisfying form of this utility
function that everyone is happy about so
this remaining a very interesting open
and the question
so okay although there are many many
many other interesting direction I can
keep talking about so let me take
question here and thank you
so for this last thing that you said
about the right model for privacy versus
so have you looked at in general maybe
you know this is hard to come up with a
disability function for privacy but a
lot of times the privacy I care about my
privacy precisely because I don't want
you to please me so I have some value
for a night under time by again and
again and again so if I reveal my value
in the first round so baby you can use
it this is so maybe for this subclass
you can come up with a reasonable
definition of privacy services being
considered
I see so that's a very good question so
basically what the point you raised is
that maybe for some specific setting we
have more reason to come up with a
precise form of this utility function
because for example this in this sort of
a repeated auction where your value will
play a role over and over again maybe we
can come up with a better closed form
yes I think that's an interesting
direction and to my knowledge I'm not
aware of any work that utilize this
structure to define the this utility
function yeah that that would be an
interesting direction to get you
gentlemen come back your very first life
this is an issue issue would be
truthfulness individual degree auction
just for only when viewed in isolation
exactly people exactly you decided
yeah its truthfulness in this one shot
game but if you think about future
utility the English option doesn't
suffer
the English auction the people who know
with higher have the exact language oh
please
shake it
I'm not sure that the English option you
don't get your value review which might
hurt your utility in the future you're
way above oh yes yes if you're way above
the second highest bid then you sort of
protect your value of aerie well yeah I
agree yeah I think differential privacy
is just one way of putting a closed-form
sort of a damaged bound on how much you
can get hurt in the future is in the
sense that your utility cannot get hurt
by more than one plus Absalom factor or
e to the absolute factor but I agree if
you have some better clothes form in
terms of what your future utility is
depending on what the outcome of the
current maximum maybe you should take
that into account into your utility
function and then yeah all these sort of
proxies for utility somewhere dangerous
because if you're claiming ok I'm only
epsilon off in this proxy well how do
you know the real valuations in any way
continued since
I'm not sure I get that nostril so
whenever you have a proxy for your
utility really utilities perhaps a
function of it right maybe it's not just
about fitment great if it is that then
you need to know how continuous is that
but I see ya yes yes everything I know
you know as long as you have an
approximate was also right right quick
its Harry
since
distribution of outcomes president
it's not that i know the unity with
utility of lots of times yes okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>