<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Northwest Probability Seminar 2014 - Sampling from the Fomin-Kirillov distribution | Coder Coacher - Coaching Coders</title><meta content="Northwest Probability Seminar 2014 - Sampling from the Fomin-Kirillov distribution - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Northwest Probability Seminar 2014 - Sampling from the Fomin-Kirillov distribution</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ZPcaBZlnJOw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so it's a pleasure to introduce our next
speaker been young then was a PhD
student at UBC graduated in 2008 and
then went on to postdoctoral positions
in various places McGill and in
Stockholm and at MSR I and for the past
two years he's been at the University of
Oregon and he's going to speak about the
sampling from the foaming kirilov
distribution so much of this is joint
work with andrew holroyd i'm here at
microsoft research and sarah belly
inability of Washington so in fact this
entire project began when I was a
postdoc at MSR I and under Holroyd was
visiting for one of our workshops there
and he asked me a very good question
about reduced words in the symmetric
group there's a certain well there's
several interesting probability
distributions on reduced words in the
symmetric group one of which is the
uniform distribution which is already
quite interesting these are the random
sorting Network cities I've been working
on for the past I guess nearly ten years
perhaps maybe load longer there and then
the second interesting distribution is
coming from an identity of MacDonald
it's a combina tourists which came up in
his study of Schubert polynomials and
then there is an interesting
interpolating distribution between the
two and I will hopefully at the end tell
you how you can draw a sample from this
interpolating distribution so the extent
to which this is a probability talk I'm
afraid to somewhat limited I'm a combina
tourist but i will try to highlight what
combinatory or what the probabilistic
content I can find in what I have done
as I go along so let's begin so first of
all we're talking about the symmetric
group so a group of permutations of an
object of course it is generated by
adjacent transpositions of items so here
so s1 is going to be the transposition
which flops item 1 an item 2 and so
forth all the way down to simple
transposition SN minus 1 and I'm going
to represent them as crosses like this
so I just have a bit of an idea maybe I
can turn off the grid of my graph paper
and then everything will become clearer
maybe only some things will become
clearer I'm going to leave it the way it
is rather than try to be clever now of
course generally what you're used to
doing with the symmetric group you
simply need to know that any permutation
can be represented as some product of
such transpositions I'm actually
interested in the number of different
ways in which this can be done and
actually furthermore in sort of looking
at properties of what a representation
of a permutation by adjacent
transpositions looks like here are here
are a couple so of course here is three
transpositions maybe s1 s2 and s1 and
what they are achieving is swapping
you're moving the first element down to
the end the last element to the top and
keeping the second element fixed here is
another one that's doing the same thing
but these are two different reduced
words so the maybe I should actually
define reduced word so I need just some
way of representing such a thing other
than the diagram and the usual thing to
do is to simply write down the indices
of the elementary right there times
positions which you are using in order
generate the reduced work so this is a
list of numbers this isn't an element of
the symmetric these are from numbers
from 1 to like n minus 1 know the word
reduced I suppose needs a little bit of
explanation so the point is I you know
this is not these so these are two ways
that you can represent the trans
position which interchange is every
I swaps every two numbers right the
complete reversal of course you can also
do it in many other ways serve for
example by adding four more copies of
this transposition on the end they are
redundant because they swap the same
thing I don't want those I only want the
ones which are reduced in particular the
number of crossings in this picture
should be the same as the number of
inversions in the permutation a number
of things which are out of order that's
what the word reduced means here so the
permutation 123 goes to 3 2 1 has three
inversions and here are three crossings
in a word producing it so these are
these are the basic data structure than
talking about and in the particular case
where you've got this permutation which
sends one to n 2 to n minus 1 and so
forth all the way down test sending end
down to one the reduced words for this
are called sorting networks here's a
sorting Network for the permutation four
three two one there are 15 others and
you call them sorting network simply
because you can viewed this as a rather
poor sorting algorithm for sorting
things if you imagine putting these
numbers you in and out out of order to
begin with and then walking them through
the wire at always sending the smallest
element up and the large settlement down
say then they'll end up in order at the
other end because every to have been
compared it's the same criterion so so
the question is how many of these are
there just a brief review so this was
originally computed by Stanley as far as
I'm aware in 1984 so in this particular
case of the permutation which is of
maximal length in terms of its number of
inversions let's call that length K it's
n choose 2 because everything is out of
order everything is an inversion then
the number of reduced words for that
permutation well I've just I've written
it like this because this is to suggest
something i'm going to say later is a
famous number it is a
a factorial over the over a certain
product of odd numbers this is also well
maybe particularly famous tiff their
representation theorists in the room so
this is the number of standard young
tableau which is an object which comes
up in representation theory gente y that
is happen alright so now what we're
going to do is ask for a by jective
proof of this so put on our combina
tourists ads for a moment here i have
two different counts of things here i
have a count of reduced words and trust
me this is a count of standard young
tableau of a certain of a staircase
shape so you write the numbers one
through n inside a staircase shaped grid
in such a way that one goes in the
corner and then the numbers are
increasing in both directions and
there's again this many ways to do that
i am worried that i have kaizen hands
and that formula i suspect they're
probably all supposed to be k's or
something along those lines there so
there should be a way of transforming a
standard young tableau into a reduced
word like this and indeed there is it's
a it takes is due to Adelman and green
and I believe 1987 and the proof is very
similar to this Robinson said instead
well maybe not with the K the Robinson
Shem stead algorithm so this is a way of
a similar problem in combinatorial
representation theory you know that the
sum of the squares is the degrees of the
characters of the of you know
irreducible characters in any group
representation theory is the size of the
group and in the case of the symmetric
group that says that n factorial is the
sum of all the dimensions of the
irreducible characters your reducible
characters are each counting the number
of standard young tableau of certain
shapes so there should be a way of
taking two standard young tableau the
same shape and turning them into a
permutations on my own vice versa and
that's precisely what Robinson chance to
algorithm does so this very first by
jective proof is a variant of that
sort of an insertion algorithm you you
basically take the elements out of this
this word one at a time the crossings
and sort of insert them into a tableau
and they're sort of shunted around and
you get to tablet where you get at a
blowout well you got to tableau out and
then one of them is always the same
thing so it can be discarded and then
there was a second by jective proof of
the same fact due to david little in i
wrote 1996 and realize they don't
actually have the faintest idea whether
that number is right or if I've just
made it up I can have to fact-check that
as well and this is the one which i will
show you because it's going to come up
in my work and i will show it to you in
just a second and then we had a little
bit later this paper of Homer angel and
her Holroyd dan Roma can be at Bragg in
2006 so it is a very careful study of
large random sorting network so they
realized that this Adelman green
algorithm was good and very efficient to
implement on the computer and you can
make a really big sorting Network and
and and just generate some big ones and
look at it and you see some remarkable
patterns in these random sorting
networks and I'll show you a couple of
pictures which I've pulled from their
paper in a little bit so that's that's
the sort of the beginning of this this
field so let's I want to go and show you
this david little bumping algorithm i
don't really have the time to sort of
prove that it works but no I've never
actually tried this without a fully
functioning laptop so let's let's just
hope this works here here's a reduced
word this so this is going to be David
littles algorithm that transforms one of
these into a standard young tableau so
you'll notice my program has decorated
this reduced word with some large red
arrows the large red arrows are
crossings which can be deleted
and still leave a reduced word here let
me try and delete one good so I deleted
that this word is still reduced there
then the permutation 3421 has five
inversions you can you know you know 42
for example those nets are out of order
so that's an inversion there are five
others and there are five things in this
work so I'm going to put that crossing
back this is the part I'm not sure will
work ah good okay so we say that the
word so this is a reduced word
independent of that we also say it is
nearly reduced to each of these red
places it's just where if i delete that
crossing it's going to be a reduced word
so instead of deleting what i can do is
i can take this crossing and shove it
over like that now sometimes when you do
this you don't get a reduced word says
bumping down there make this a little
bit bigger so if i do i stop and then
i've completed a little algorithm the
little the little bump if it is
introduced it is a theorem that there is
one place which is conflicting with the
crossing I have just moved and that the
word is nearly reduced there as well in
that case I take it then I push it over
in the same direction now sometimes this
makes you add you'll push a crossing off
the bottom of the word or off the top of
the word in which case you add another
wire for it to be on so that is one
instance of the little bump so this is a
reversible operation I can buy bump up
using exactly the same rules starting at
the crossing I stopped out and get back
to where I started so this is going to
be some sort of by jection between
classes of reduced words and other
classes of reduced words if you do the
bumping in a ingenious way I'm like
which I'm going to do it in an ad hoc
rather than an ingenious way and just
see if I can get it there okay so
there's a there is a certain sequence of
bumps which you can do which leaves the
word in the following state for one
thing there is only one descent the
numbers go to 46
and then there is a descent one is less
than 6 135 moreover so that that
characterized the sort of word it's
called a grass montien word for various
esoteric reasons moreover the wires are
monotone you'll notice they're either
going down these three or they're going
up such as wire six wire for and wire to
so normally I would do this on the
computer but my computer's not behaving
so what you can do the word the wires
here so let's let's have these wires at
our monotone down those are going to
represent rose in my standard tableau
and the wires that are up are going to
represent columns so going along reading
this word backwards you can translate
this into a chat below as follows so
this is going to be crossing one two
three four five and six so on the first
row I see 1 2 and 3 D and the second row
here I sea crossings four and six and
then that very last one I see crossing
five and you'll so you'll notice that
these numbers are increasing in both
directions and similarly if I take an
array of numbers like this i can write
it down in a transparent way to turn it
into the tableau like this and then
shunt all of the crossings back up i
hope i remembers to do this right and
they have a reduced road for four three
two one so that's how the little by
jackson works and that's how you see
that these two sets are equal numerous
the other thing to note is that it is
actually really very fast a sample one
of these there is a algorithm due to
green nine house and wealth which lets
you basically simp almost just write
down one of these in your computer as
fast as the computer can put numbers
into the grid so you can generate a very
large sorting network this way in the
Adelman green algorithm i think is even
a little bit faster than this
okay so let's see I think I've managed
to define the terms nearly reduced bump
and grass munyon i don't think i define
push but that is simply the operation of
just taking one causing and moved over
it's it's one step in this algorithm
which I described to you okay let's see
so that's one of the combinatorial
objects I want to talk about in this
talk the other one which is going to
come up our pipe dreams which are these
things this is an object which looks
very much like a reduced word although
it is a little bit different I've one
thing wire one is kind of shorter than
wire for here all of the crossings are
forced to be in the square grid and I
either have them like like sort of a
plus shape or two wires would pass like
this this pattern occurs in all of these
cells and if you like to imagine filling
the rest of this quadrant with more
cells like this and you just have
straight lines below this so why do we
care about these it's a little bit less
obvious but these are of interest in a
branch of combinatorics called schubert
polynomials which is somehow inheriting
from the Shubert calculus this coming
from algebraic geometry and rather than
really getting into why we care about
these let me just say that the Shubert
polynomial is a certain sum over
pipedreams you you write you write down
all the pipe dreams which are realizing
a permutation this one is I may have
replaced something with this inverse
let's just say this is the permutation
1432 I think that's exactly backwards
and the super polynomial is what happens
when you record the row that each
crossing appears in in the variable X
and it's a polynomial in many variables
X I don't really care too much about the
fine details of that at present because
what i want to do is state the mcdonald
identity so this is ender brought to my
attention at MSR I and 2012 it turns out
that if you instead so if you take the
following some over-reduced words for
mutation instead of summing up the
number one instead of just counting it
we're going to do a weighted count of
reduced words and the weight is the
following if I have these crossings are
these these yeah these crossings
appearing in my reproduced word I take I
take the product of these numbers right
this isn't concatenation this is
actually multiplying numbers together
that is going to be the weight of my
word and it turns out that if you add up
all of these things the answer is K
factorial times the number of terms in
the Shubert polynomial so it doesn't
really you can forget the waiting that I
said with the exes I just want to count
pipe dreams this is the number of pipe
dreams realizing a particular
presentation and in the case actually a
lot of the time this number here is one
there's only one pipe dream and in the
case of this this long permutation for
example that is one such and then the
right hand side is just K factorial
there's n n minus 1 and minus 2 all the
way down to one the one for sorting
networks so so what do you want to do I
mean ideally sort of want to give a
bijective proof of this I worked out
again by basically by complete fluke and
in some sense a way to start doing a
bijective proof of this because I was
thinking a lot about David littles
algorithm for other reasons and I'll
show you a little bit about how that
goes and so this is the special case
that it is precise of this one that I
just said when the shoe brute polynomial
evaluates to 1 so this does actually
cover the case of the sorting network
this is called a such permutations are
called dominant permutation so what my
the prepend on the archive of this of
mine is covering that case and and this
is this is in some ways my my the
cleanest example because this gives you
not only a sampling algorithm but in
fact a Markov growth rule for these
reduced words under this probability
distribution so what I want to do
I guess I haven't even said with the
distribution as imagine that number is
one take the K factorial across to the
other side so i have 1 over K factorial
times that some of this stuff is equal
to 1 this implies that there's going to
be a probability distribution on each
unreduced words where the probability of
selecting each reduced word is precisely
proportional to this and the constant of
proportionality is K factorial so that
is the distribution from which I want to
sample it looks like I should be able to
do it I want to know what a large
reduced where it is coming from this
distribution and so forth and it turns
out that the way that you get to do it
is by growing a reduced word you sort of
start with the reduced word with no
crossings in it and you put the
crossings in sort of one at a time
adding inversions one at a time until
you end up at the permutation that you
wanted very much reminiscent of actually
this I think coincidental but of Andrews
way of growing this one the pendant for
coloring of his by sticking in new
colors one at a time and spreading
things out similar kind of growth and
then Andrew and Sarah belly and I came
up with a by jective proof although no
longer easily interpretable as a growth
rule for the general case of this
McDonald identity I don't actually know
how to sample a random pipe dream yes so
of course when you have a
computationally efficient by Jackson and
you can sample one of the things on one
side of it then you can sample the
things on the other side of it by sort
of putting them through the bisection I
don't actually know how to sample a pipe
dream in general but there's an
interesting case in which I do so
hopefully we'll get to that by the end
of the talk I want to briefly say how
the growth rule works because I that is
one of the things which appeared in the
title despite this being only a special
case you do the following so you pick a
standard young tableau say that one but
this is for a different reason this is
going to tell you in what order I do the
insertions what wires I do the
insertions along and the algorithm is
going to be the following I take the
standard young tableau I see where the
numbers occur
so in which row do they occur so the
numbers one two three four five six in
this case occurs in Row 1 Row 2 Row 1
Row 3 row to row 1 those are going to be
numbers of wires on my reduced word and
i'm going to repeatedly do the following
thing i'm going to insert it crossing
somewhere on that wire and then i'm
going to immediately push it down until
i get a reduced word okay the first one
is boring right there's there's no
crossings there I stick a crossing on it
so that its feet are on top of wire one
and I push it down and now I have the
only reduced word for the permutation to
one it's got one crossing at it it just
flops there and that's that's not
interesting now I've got a reduced word
I find the next wire to look at in this
case it is to somewhere along wire to I
insert a crossing and I push it down why
does that make sense well when I've just
inserted a crossing the word is nearly
reduced there because I just had a
reduced word when the crossing wasn't
there yeah i mean really elementary i
can do a few instants of it so here let
me just kill a bunch of these crossings
so let's say i've inserted crossings 12
and one here so so now i'm going to
insert across and somewhere along wire
three i will just do this sort of a
random maybe i'll insert it kind of in
the middle here please work there okay
so I've just inserted a crossing on wire
three of course this word is no not
necessarily reduced but this new
crossing that I stick in I immediately
shove it down until I've got a reduced
word now my instructions say to insert
across and wire to thus and shove it
down and then a crossing the wire one
somewhere maybe up here this gives me a
wire zero that's okay I just ignore that
this is reduced now you see I without
paying attention to it at all I now have
a reduced word for four three two one
which suppose what I was aiming for this
is another this is a sorting Network and
that at the very least just sort of
generated it
it's straightforward if not completely
elementary to see that this is
preserving this probability distribution
that I was described just by means of
sort of convincing it to or convincing
you that this is doing the right thing
you sort of construct a graph I guess I
can zoom out a little bit and then get
this whole thing on the screen there so
here's all ways that I could have done
this insertion using using this pattern
of wires I stopped about halfway through
because for a different reduced word you
will if you count paths in this graph
you will see that there are six paths
which arrived at this reduced word six
which arrived there and 12 but to rival
there and moreover these are also the
mcdonald weights of these words so this
one for example here's crossings and
positions 1 3 2 and 1 and 1 times 3
times 2 times 1 is in fact 6 so this
McDonald identity that I showed you is
really counting path in this graph yeah
and here 12 for example three times two
times one times two is four real 12 but
it's also the number of ways I could
follow red arrows and get to this
diagram here and another thing that the
number of paths in this graph is K
factorial because at each level I'm
inserting a new crossing into a word
with like three crossings in it so there
are four ways to do that doesn't matter
where the crossings are I'm just putting
the crossing somewhere along that wire
so there are one choice here two choices
there three choices here four choices
here wherever I am and so forth so the
sum of these is going to be K factorial
in this case 6 plus 6 plus 12 is 24 so
that's 4 factorial moreover because of
this and this is the Markov growth drill
here it's really as simple as you might
actually like if I want to sample a
reduced word from this distribution I
don't need to construct this whole graph
that would take an exponential amount of
space and fun I want to do that instead
what I can just do is do simple random
walk in this graph I just randomly
insert crossings and you know in general
you shouldn't expect simple random walk
to give you the same probability measure
as uniform measure on paths in the
directed graph that's all but in this
case the outbound degree at each rank is
constant so in this case it those two
measures do coincide so this gives you
this way of growing a reduced word I
have some simulations now if I recall so
these are some wires and a big random
sorting Network I these are not the same
size this is this is taken this is a
uniform random sorting Network a
screenshot it out of ender and homewares
paper there are two thousand things here
being / muted if you draw a 2,000 wires
then you get at black square so I have
not drawn or they have not drawn all the
wires there's only only some of the
wires are shown and the paths that these
wires take are interesting i think
they're sort of sinusoidal e shaped
conjectural e well these ones certainly
are i mean that's at the fair statement
but this always seems to happen
conjectural e here is a visited here
over the summer and ender and i wrote a
pretty efficient implementation of this
algorithm which i just told you how to
do and this is a network of size six
hundred and once again you see a sort of
a similar phenomenal though it's by no
means the same I don't really know what
what shapes these trajectories are so
it's not it's not really quite as nice a
situation as the as in the uniform case
nonetheless I at least you can generate
large ones of these and it should be may
be possible to formulate some
conjectures about them the black
background is absent here this is where
the actual crossings are in the sorting
network and you can you can see that
there are there's you know some sort of
smooth
density presumably to which they are
tending and you'll be very interesting
to know what that density is but again I
don't know that yet haven't really tried
to do that part of the analysis yet or
not in a serious way I don't know what
conjecture to make the other thing you
can do is you can of course these are
sorting that works there for sorting
things you can see what it looks like
once it's halfway done so you can take
the product of the first few
transpositions in the sorting network if
you take a uniform sorting Network and
do this you take you take the product of
the first half of the transpositions you
get a picture like this it looks like a
uniform point cloud on a ball projected
isometrically onto a plane again this is
also conjectural we'd really don't know
how to prove this and there are many
other such conjectures about limiting
properties of these of these sorting
networks this is a you know the same
operation on the sorting network I just
showed you I thought it really my first
thought does it look like in a parabola
or an ellipse or some sort of other
conic and stuff sure wishful thinking i
thought this but then when we ran it on
a you know we had our algorithm so long
enough it became clear that this was not
tending to any sort of parabola or
ellipse or so forth so once again an
unusual and surprising shape for a
permutation matrix I certainly never
seen you know permutation matrices that
look like this come up in any other
situation nonetheless I don't have a
conjecture as to what that limiting law
is nonetheless you can make very large
ones and look at them which is just come
Frank
how am i doing for time five minutes
okay well let me just really quickly say
what our idea was for the general case
so here there is a so this was the
special case where there was only one
term in the Schubert polynomial of my
McDonald's identity niche said k
factorial on the right hand side in the
general case when your permutation is
not a dominant one there's actually a
Schubert's polynomial there and so what
the best you can hope to do is prove a
bijection of the following sort you can
take a reduced word for pie so your your
permutation and then a collection of
numbers which are strictly dominated by
the elements in the reduced word so this
will count something on the right on one
side and you can replace it with
something of which there is K factorial
so a permutation there a you know of us
k there's k factorial of those and then
a pipe dream so this is this is what the
Shubert polynomial is counting and I
don't have time to go through it but
here here's the interpretation so those
numbers bi you think of this think of
choosing your reduced word and then
after you've chosen the reduced word you
draw a little bit of a track above each
crossing and the crossing only runs
within the track if my if I'm if I've
done some sort of little bump that's
asking the crossing to pop out of the
track i deleted instead and what you do
is you go through the crossings in some
canonical order which again I think I
shall I met exactly the details of what
the canonical order are they do not seem
to be terribly important you can use
other canonical orders and this does
seem to go through how that we don't
really understand why and why not it
work sometimes and you start doing the
little bump and if at any time one of
the crossings is asked to be popped out
of the track you you delete it instead
of instead of pushing it and then
eventually if you keep pushing you of
have removed all of the crossings just
take very careful note of
what happens you write down the
permutations that occur at each stage
and if something pops out of the track
you write down where it happens and you
you write down what wire it happened on
the location this way and what wire was
on and if that doesn't happen then the
then the little bump terminates normally
the way I I said the original little
bump does and you write down the last
crossing which was pushed that's
probably slightly redundant information
but that's fine it doesn't matter and
then what you do is you run the whole
thing backwards so first of all you the
order in which the horizontal order in
which the crossings popped out that is
going to be your permutation as there's
those crate those cave crossings popped
out in some order just write that order
down that's the part that's contributing
to K factorial now go through everything
else you just sort of push into the left
hand side of the pipe dream and I have
my pipe dream application up here
somewhere and I wrote this and you do
the following thing there's a version of
the little bump which runs on pipe
dreams so for example I could push
imagine all of these crossings are being
pushed in from the left hand side so
when I bunny add a crossing it's always
coming in from the left so there I just
added the crossing and wire one if my
instructions say that the next thing I
did was add another crossing and wire
one I pushed that in from the left in
this bumps this one along and then
there's a new crossing here I might add
a crossing there and then maybe maybe my
instruction is to do a bump so it'll
tell me which crossing I'm supposed to
push I should just take that crossing
and push it along and it moves along all
the other crossings in the same rows it
so you might get this it's probably oh
yeah I guess that's possibility I don't
know I haven't prepared this part of the
talk I was hoping to do it with a set of
instructions and with my pen on my
laptop so I'm at sonic but the point is
that sometimes when you're doing a push
you may have this situation where the
where there is a conflict in the sorting
network that is not allowed for a pipe
dream and then so you resolve it in
same way that you do with the little
algorithm you just push the offending
object over as well maybe in this case
it would have been this one so there is
a way to sort of decomposed these
sorting networks into a sequence of
instructions and then recombined half
that information you know everything
other than the or the the horizontal
positions of the network into a pipe
dream and again since everything is this
is this little bump it's all pretty
efficient the only way which I know how
to use this for sampling is the
following in there is a slightly more
general distribution again if if if you
have a dominant permutation we have this
identity which is due to foment and curl
often 1997 paper instead of multiplying
the numbers a 1 up to AK together you
multiply these shifts together x plus a
1 up to X plus AK and it turns out that
when you when you do this you see k
factorial and then this really is the
super polynomial here but in the case in
this particular case it is you should
interpret this as a number of semi
standard young tableau just slightly
different combinatorial gadget so in
order to actually sample from this
distribution but this is a very nice
distribution because if you if you let X
get large say X is a million then X plus
a 1 is about the same as X plus anything
else so this is really tending to the
uniform distribution and if you put X
equal to 0 then you tend to the McDonald
distribution so this is really
interpolating between the two
distributions is you let X very also one
way to think about it is since we're
just adding the same number to
everything x is that that's sort of like
shifting the sorting network down by
that many wires so it is actually quite
possible to just derive this equation as
by jective lee as a as a corollary of
ours you just have to do the one little
bit of x jective combinatorics see these
semi standard young tableau is grass
money and permutations and that actually
is just David littles proof on ma
find the very first thing I showed you
in which you shunt crossings around
until you get a broader grasp on Ian
word saying is these very last things
you can sample from those I there is a
let's see where I just wanted to
highlight the name crowdin dollar
Christian cotton caller gave a proof of
Stanley's hook content formula which is
so by jective is to provide a ficient
sampling algorithm producing a random
semi standard young devil so haven't
implemented this yet but using our work
we should be able to sample from this
foaming care lab distribution and
hopefully have a nice kind of
interpolating series of sorting networks
which can go between the uniform ones on
the one side and mcdonald ones that i
showed you on the other side I don't
know whether all of this will help us
prove any sort of limiting properties
about this network at all but I can hope
so okay that's all I wanted to say thank
you very much are there any questions
who
you can also go in the other direction
with negative x right let's suppose you
could uh like if you had one in this
formula here well you can but the thing
is if you have a crossing at height 0
then this is a multiplicative weight so
that word is not contributing makes
between do n minus 1 yes that's true
there is a there is a sort of a Type B
variant of all of this in which you have
reduced words which are symmetric and it
also has a little algorithm and so on
and so forth so I also work this out
with sarah billion to Ben and colleagues
as that can occur in austin roberts I
don't know what to make of it and I
don't know how to use it to prove
anything along these lines like why
there's also an affine version of this
which you use the affine symmetric group
instead of the symmetric group and the
cross kind of go around it in a in a
circle when you push them but once again
I don't know what goes on the right hand
side I don't know that I don't know what
the find schubert function is or if that
is the right thing to go on the right
hand let's thank that again
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>