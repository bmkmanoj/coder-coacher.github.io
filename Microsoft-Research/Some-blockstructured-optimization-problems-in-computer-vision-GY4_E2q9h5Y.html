<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Some block-structured optimization problems in computer vision | Coder Coacher - Coaching Coders</title><meta content="Some block-structured optimization problems in computer vision - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Some block-structured optimization problems in computer vision</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GY4_E2q9h5Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay hi I'm Angie Gordon I'm I'm from
the probably the programming principles
in tools group so I've been looking to
inspired by the area probably sleep
programming we've been looking for the
last few years at how we can apply
programming programming programming
language ideas in machine learning and
in particular what we've come up with in
collaboration with folks in the machine
learning group here is this new
probabilistic programming language
called tabular which is intended to be
something that can be easily embedded
within spreadsheets in order to write
graphical models directly in in
spreadsheets and let's see the i mean
probably c programming so far has been
aimed at sort of more or less sort of
machine learning experts and like which
was a reasonable place to start at
initially and an infra Donette is is you
know uses this form of C sharp probably
60 sharp that John was talking about
that that surfaces within visual studio
within a full-on development environment
and what we're trying to do in tabular
is go beyond that to the larger audience
of people who are more comfortable in
things like spreadsheets and asked what
would a problem c programming language
look like if it was embedded within
spreadsheets so probably sick
programming however would are a great
many of you know about it so I won't
linger on this but just to sort of a fix
some terminology I mean a probably c
programming language is really starts
from some other programming language and
then add some features so we can
represent things like graphical models
or more generally just to find your
joint distributions over variables so
generally we start with a particular
programming language like a functional
language like Church which is based on
scheme or probably 60 shot which is
based on C sharp you add some way to do
random draws from distributions such as
coin flips or from gaussians and so on
and we also in some way to constrain the
execution of the program to actually
condition it on observed data so if i
donate as an observed statement and as a
similar thing in church and then somehow
you need to save which variables you
want to infer which is great and it's
much better than a writing code for
graphical models from from scratch i
mean that used to be the work of a PhD
and now you can still write a program in
infra net or church and
and get a reasonable and sometimes very
performant inference algorithm from the
compiler and there's a bunch of systems
out there the granddaddy is bugs
invented in Cambridge twenty years ago
which has inspired Stan from galmans
group at Columbia and dessert there's a
bunch of different languages and the one
that we're focused on is inferred or
neck and we did a functional version of
internet using the F sharp system here
to drive and fro donate but that's not
and the tabular languages are descended
from that but it's a little different
still when you look at the actual
graphical models that are the common
graphical models anyway they're really
rather simple programs and they don't
need the full control structures that
you have in languages like C sharp so
you maybe have loops but very often
they're just straight loops over a data
structure akin to a map in functional
programming terms require you're
generating a sort of you whether the
data structure is seen as being I ID and
and you often don't have complicated
while statements with with with
complicated conditions and you don't
have exception howling there's a whole
bunch of stuff you haven't full-on
programming languages that a
professional programmer would you know
about that you don't actually need so we
asked ourselves you know we're aiming at
you know large population users who we
can we could expect would know about
relational schemas for their data you
know you kinda machine learning without
data so you at the very least if you're
going to do machine learning you you
have data in a database so we could
assume they know something about the
schema of the data we said what happens
if we just take that as a sort of
outline for our probabilistic programs
and sort of markup the schema with
prolific expressions to define the model
and that's where we're tabular comes
from so intent is that the new domain
specific language to help you know
end-users get insight from their data
and where we're aiming I mean there's a
kind of spectrum of users I think
everyone in this room is sort of on the
right machine learning PhDs and we love
machine learning PhDs but maybe you're
already well served with with other
tools and then there's data scientists
to a more sort of relatively
sophisticated people there's a
reasonable number of them and then
there's machine learning developers
people who kind of by accident or chance
they were developers anyway and machine
learning is becoming important so they
learned a bit
but their people are comfortable in
things like visual studio or eclipse but
then there's a really large group of
people that pat hanrahan of stanford
calls data enthusiast's these are sort
of business people on a mission this is
like a doctor who wants to know why
certain class of patients keep on
returning my car salesperson who wants
to figure out you know if you know which
car is a good to buy auction and so
forth these kind of business related
questions there's an awful lot of these
people and we like to and we feel
they're comfortable and things like
spreadsheet so we want to see if you
take the benefits of graphical modeling
and prob lista clan which is to that
population so our principles we want to
design the language on the annotation to
the schema we won a you know inference
you know deciding which variables to
query we're going to use a spreadsheet
paradigm and illustrate that in the next
few slides and thirdly we want to
actually auto-suggest models based on
that the the the structure and that is
something we're not finished yet but
that's in progress so we have a proper
paper pople is the ACM principles of
programming language conference and we
had a pop up with a paper about this
last month that poeple and and it was
about points 1 &amp;amp; 2 &amp;amp; 3 you might have
seen work that torah tours in the room a
trattoria led some work i'm called
inferno DBA a couple of years ago where
he was automatically inferring graphical
models from the structure of a
relational database and we really
designed tabular to be able to write
down those sorts of models and i'll say
a bit about that towards the end okay so
to introduce it we let's think about
true skill and i'm assuming people
broadly know that the true scale model
this is a sort of binary version of it
where you go to population of users and
then you've got a this there's been
matches binary matches between them in
each case there's a plus one winner okay
so the data might be here as your users
and then you go to a table here of
matches so this is saying that Alice
meets Bob and Alice losses and then Bob
meet Cynthia and Bob Bob loses okay so
then the schema for the data would look
like this so no we've transposed things
which often happens so that the data
sort of goes downwards but the butt butt
over here they transporting so the
columns over there have become rose
alright so my skimmer for the players
table just says there's a name column
that's a string and the matches table
has got player 1 and player 2 columns
these guys that
foreign keys over to the players table
okay the index is to the players table
and then and then there's a boolean that
says for the player one as has one or
not so that would be the schema so the
idea is we can define true skill by
marking it up as follows okay so this is
my new this is an example of a tabular
program okay and it generates this
graphical model up here so the players
table we've invented it with a skill so
as you as you remember in true scale the
ideas that every player has got an
unobserved skill and the prior on it
would be that it's a Gaussian CA with me
in 25 and this is the precision so
standard deviation 10 okay and what
we've done is we've just added a new
role to the the schema which is labeled
as being latent so and colored grey so
this is a idea is that this is we're
saying that this column doesn't exist in
the actual the real data set but it's
something we want to infer okay and then
on the matches table we've added the
couple of other latent columns for the
performance is if you remember in true
skill the idea is that when two players
meet the winner is the one who doesn't
have the highest skill but the one who
is the highest performance but the
performance is a noisy copy of the other
skills so that the two performances are
noisy copies of the skills so here we
say player one skill which uses the
player one in each row is it uses the
player one field to get the skill and
then we had a bit of noise and similarly
for perf two and then we just ask
whether perform is greater than perfect
two so look so notation I'm sure you
probably more familiar with these
notations this is the sort of plate
style notation for for this and so you
see that each of the each of the columns
in the database and also the latent
columns have all become random variables
in the in the factor graph right the
circles and we've got the color coding
so the blue ones are ones their input
sort of covariates that we do not try
and predict and the orange ones are
outputs things that we're trying to
predict and then the gray ones are
latent random variables and then these
factors I've actually labeled these
factors with the probabilistic
expressions explicitly the factors
connect the random variables and
describe a generative flow and you see
that each each table over here has
become a plate so
this plate here is iterating over all
the players in this table and this plate
over here is iterating over all the
matches okay so you see there's a
there's a direct way of synthesizing
these plates these graphical models with
plates from the the shape of the the
shape of the schema so then what about
creating we have two styles we have
created by late in column and I'm going
to have query by missing value and the
idea create about late and column simply
is that if we take a data set and a
model we can just infer from from from
that data by conditioning the model on
it what the columns are so in the case
in my example you'd get these that we'd
fill in the skills as a new column and
also the performances and you're getting
what you'd expect that simply is beating
Bob who's been Alice who are getting
this skill is Cynthia it's probably
larger than the the skill of Alice and
then query by missing value the idea is
that in the output columns the orange
columns we're going to we're going to
allow missing values okay because we're
predicting them so we so here we say all
right some is offering me a bet on
whether Cynthia is going to be Alice or
not so what does the model think how
likely is it that she'll win so we can
just go ahead and fill in a probability
from observed from the model so the idea
here is a good very simple sort of
interface that we've marked up the the
skimmer with the model and then in order
to be query we just these get really
gaps in the output columns and then
tabular can can fill it in so here's a
slightly more slightly more complicated
model that illustrates another feature
which is that we can also have variables
random variables that set outside the
plates so it didn't happen in true skill
but this is a very simple model of
linear regression where I've got a and B
so it's the equation you know that Zed
is a times X plus B and then the
observed why is a Gaussian of of Zed so
a and B are sort of static variables
outside the place and they are given in
this case these particular priors so
that the corresponding factor graph
looks like this where a and B are
available sitting outside the plate and
they have have these factors on them as
a prior and then this is a plate that
takes each input X and produces
an apron why okay so that's pretty much
all there is to least the core form of
tabular and so we have a particular
recipe the ideas you'd start with a
skimmer I'd layton columns right models
and then we learn the columns and
parameters or we can use the crib
emissive are you to predict missing
values and tabular is is meant to be a
sort of independent of particular ways
in which you might visualize data and
it's also to some degree independent of
the particular back end so we're
targeting in Frodo net of course but we
think it could also be we're not really
doing anything here on you know on
inference so any any benefits that John
&amp;amp; Co add to infer donate hopefully
tabular would inherit but equally we
could also you know tiger on the back
end so in bangalore and msi there's a
sampling based backend being developed
for in fro net and we don't target that
also and so we can so this is a
screenshot of this embedded in inside
excel this is actually done by Danny so
he was our first user so it's great to
have a user but he's an MLP HD so he
said a little bit on the high end for us
but it's great we're looking for it to
start with some users so this is a
variation I'm not going to try and
explain this but it's a just to give you
an idea of what it would look like in
Excel where you'd have your data in
these leagues teams and games tabs here
here is your model we can actually auto
generate a model that's sort of
completely empty with or maybe has some
default modeling expressions in it from
the schema and then the user could edit
them and you know we do syntax checking
and syntax highlighting and so forth you
see there and then you see there's the
results been dropped into the sheet and
then we just use the visualization
features of Excel to to do a plot okay
we did a we wanted to show in the paper
we want to compare it to the best
available alternative which is directly
doing a model in infra net so we took a
model already been done it was complete
before we started that was led by your
own Bacharach and others john guyver was
involved in that and he'd written the
c-sharp so this is sort of like best
practice c-sharp model info donate and
this is the equivalent thing in in in
tabular and we grant some numbers but
the higher the thing is we get the same
answer so statistically these numbers
so each of these so this is three
different models right and the two rows
here are tabular versus directly doing
it using the current info don't net API
and then the same for another model and
the same for a third model and you see
these numbers are all the same so we get
the same answers we've got what few
lines of code as expected and
performance wise of inference where we
take a little hit but but only a
percentage or two so it seems entirely
viable to go this way do consider
downloading the paper it's a programming
language style but i have to tell you we
worked really hard to make this paper
accessible to a machine learning
audience Danny gave us a lot of useful
feedback there was a lot of iteration on
it so I think you'd find that you know
even if you don't have any background in
programming languages give it a shot you
know it's I think the first few pages
are pretty readable and gives you an
idea of how you would explains you know
tabular here's the full syntax we have
various theorems I'm standing between
you and coffee I think I officially have
five minutes i'll i'll try to do i try
to get this finished another five
minutes so there's various theorems but
what i really want to say is automatic
model suggestion so this is our current
work and maybe this is related to some
of the work zubin and others of you have
been doing on the automated statistician
so this is if may have seen the work
that's that's Torah did with a an intern
Sam you're seeing a couple of years ago
um the idea was you'd start from a
relational schema and generate a model
in this case it's like a user movie
recommender where you've got a table of
users with some demographics a table the
movies with some features onion you've
got some ratings where for each row in
the ratings table you've got a user ID a
movie idea in a score and they came up
with this model they came up with an
algorithm for generating models and they
coded this up in Visio this particular
model and in a way a challenge for
tabular from the start was like what
does this mean how can we describe this
you know it seems this is kind of
getting kind of hard to write down you
know if I witnessed a mural in torah in
a bitter argument about the right
rotation and we thought you know this is
a nice programming language question
actually you know what sort of
annotation would naturally let you write
down models like that so i'll just
quickly go through that so
let's start with this that what the
model does is that for the users table
let's see it it adds a custom variable
so essentially it costs as the use of
the users it clusters the the movies and
then uses the clusters here to build it
the scores and the way we can write this
entire builders like that where we we
have a new latent column called the user
cluster this has a discrete distribution
and there's four possibilities and then
the gender and the age are the conjugate
Bernoulli distribution Zhanna so they've
got a prior that's a beta in that case
and in this case a dish like prior sort
of outside the loop and we and but
they're not a single one that the point
is that indexed by the user cluster so
we have the syntax here which says that
using it so there's four different user
clusters so what this says is make four
different parameters for this conjugate
Bernoulli distribution and then
depending on and in a row depending what
the user cluster is use use the
appropriate parameter okay so it's a
nice compact description notation and
similarly for the movie cluster there's
a sorry for the movies you know
statically we are outside the table we
have a sari-sari an each row we have a
we do a draw of a cluster and then use
that to index the models for the genre
and the year and then finally when we
predict the ratings in any raw we have a
user idea in a movie and we look up the
cluster of the user and the cluster of
the movie and use the pair of them to
index distribution over ratings so for
example you know the different
distribution for when I say an old
female sees an action movie versus say I
either a young man Cesar an action movie
for instance that's the kind of
intuition so that's it that's all I have
we have the paper you can get it on the
web remember research microsoft com /
fun we try and keep the fun in computing
go there there's various papers
including the fool talk about this and
also well other papers are and i'm very
interested to discuss more thank</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>