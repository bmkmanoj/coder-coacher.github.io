<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Nonconvex optimization by Gaussian smoothing and continuation with applications to image alignment | Coder Coacher - Coaching Coders</title><meta content="Nonconvex optimization by Gaussian smoothing and continuation with applications to image alignment - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Nonconvex optimization by Gaussian smoothing and continuation with applications to image alignment</b></h2><h5 class="post__date">2016-07-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_L_2mmatYnM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi it's my pleasure to introduce Hussein
Baba he he is joining us from UIUC his
advisors e ma he's currently actually
visiting us here at MSR about once a
week so if you want to talk to him at
any point let me know he's hanging
around and doing research here because
his wife is currently actually working
at Microsoft as well so the Saints done
a lot of interesting work he's done some
work in image segmentation he won the
best student paper award at a CCP and
has a public paper at I JCP on that work
he's done face recognition when my
favorite works that he's done is on deep
learning using temporal coherence you
should check that paper out and today
he's going to be talking about someone
was more recent theoretical work which
he submitted to CBPR and i'll let you
different ok Thank You Larry hello
everyone and welcome to the talk so I'm
going to talk about non convex
optimization with Gaussian blurring
technique and the continuation and I'll
discuss some of its application to image
alignment as well this is joint work
with my PhD advisor in MA you are you CN
msra and Larry's ethnic from building 99
at MSR so the talk cons of two parts at
the beginning I will just give you some
basic definitions working definitions
and then some preliminary results from
theory side and then the second half of
the talk will be more about application
to image alignment ok so talking about
optimization we need to address a
convexity and non convex v we all know
that non convex optimization in general
is not tractable and because of that
there is always a pressure on engineers
to try to model the problem as a convex
one even if the actual process is not
very similar to a complex process or
write it down as a non-convex objective
function and then try to relax it to a
convex function
does want one way to deal with it but if
the actual objective function is far
from comebacks of course this is where
this is going to be very crude and not
very useful but unfortunately a lot of
real-world problems are non convex so we
cannot ignore this class of functions
and one good news is that real word
problems usually have some kind of
structure and regularity and they are
not random this means that even if they
are non convex there is a possibility
that if you exploit that structuring in
your problem right then you can solve
that problem efficiently there are even
examples like even integer programming
examples that if you have some
conditions on the problem then although
it's although it's non convex but it can
be solved efficiently there is actually
a vast literature on these people trying
to exploit different features in the
problem you can see someone with squares
or difference of convex or many other
but today I'm going to talk about one
specific approach that it also tries to
exploit some structure and that's the
smoothness of your objective function
and it has been very popular people have
been using it in practice but
surprisingly there's little theoretical
understanding about fundamental issues
with this method and I have some
preliminary results for this I'm working
on this theory so this is an this is a
presentation based on an ongoing war so
it's by no means a complete theoretical
framework but I think even the pieces
that I have so far is interesting to the
audience do you know whether this
technique has used neural network
yes yeah there is an author as a thing
gorse I don't know how so G 0 rse that's
a very old paper i think around 80 s so
yeah let's be precise about what we mean
by smoothing so smoothing happens in
nature and in physics perhaps a
representative example is from heat
equation heat equation is simply a
partial differential equation you can
see the definition of this a partial
differential equation so if you set the
initial condition and if there is a
boundary if your space has boundary then
you set the boundary condition and then
it gives you a solution so you can say
ok let's say that let's be concrete here
let's say you have a bar and then there
is some distribution of temperature
along this bar right at time zero now
you leave this bar on its own and this
heat starts to propagate and spread
across the bar right and eventually it
reaches a quill abrir the entire
temperature on the bar is the same so
let's define this function G in two
variables X and T where T is time and X
is the location on the bar and let's say
the initial distribution of temperature
on this bar is denoted by F X so that's
become your that becomes your initial
condition now what this has to do with
smoothing you need to look at the
solution what the solution looks like if
you solve this problem for the case that
your space is unbounded that gives the
simplest form of solution the solution
will look like this so this is
essentially a convolution of your
original function and a Gaussian kernel
if you just replace T with Sigma squared
become more familiar to you probably so
I have a video here actually which shows
that if here this is like the location X
and here
the temperature and this is the initial
setting I just ran that differential
equation to show how it starts to smooth
this function so very simple idea but
how can we use this in optimization so
in order to see how it's useful for
optimization let's play this video
backward in time so we start from a
highly smooth function but what we
additionally do is that we find its
minimizer and then try to trace this
minimizer back to the original function
at each point ok we are in a local
minimum and then by the next infinite
small change in the function we try to
follow that minimizer and basically
follow that path up to when we get back
to the time zero so and remember this
was the original function and this red
point is showing the minimizer you are
tracking so this function of course is
not convex that this has two local
minimal that you can see and one of them
is the global min but when you do do it
like this you trace the minimum it
actually finds the global one for you
okay this idea as I said it t
erratically is little understood but I
can tell you it's very popular even
across different disciplines for example
in computer vision which is my field
it's called graduated optimization you
can look it up there's some explanation
in old book by Z sermon and andrew blake
i think it's called visual
reconstruction or something like that
and in chemistry people call it
optimization by diffusion equation in
scientific computing computing it's
called by homotypic continuation and in
engineering sometimes it's called
deterministic anything there are slight
differences between them but the core
and the essence is the same they start
from a smooth function and then trace
the solution so surprising that despite
its recognition there is not much known
about this problem and here are just
some of the interesting questions yet
very fundamental that you might want to
ask yourself when you work with this
kind of algorithm for example the idea
is that we want to make the objective
function is smooth when is it useful
when when you smooth it enough it
becomes convex right of course it
doesn't happen for any kind of function
so you want to know for what function if
you push your Sigma the amount of
blurring in your Gaussian toward
infinity it starts to look like a convex
function so that's the first question
the next question is that assuming that
your function asymptotically comebacks
you want to find its convex minimizer
right now that's your start point for
this process but as the problem gets
smoother and smoother it becomes almost
the objective function becomes almost
like a flat curve and highly unstable
numerically very unstable to apply any
kind of numerical techniques for finding
the solution even for a convex function
so it's not it's not the best way to do
it but we hope that there is a closed
form for that asymptotic
minimizer that we can just get it
explicitly without running any numerical
procedure the other question is okay
what is the size of this asymptotic
convex functions are they large relative
to convex function if so how large and
then because we are tracing the path
from the smooth function back back back
to the original function where we want
to know that this path is traceable what
if in the middle of pad you see a
bifurcation and then you don't know
which way to choose right I'm assuming
that this is the deterministic algorithm
non-recursive so you don't want to
branch you just want one direct path
back to the solution and again I would
like to emphasize that this setting this
approach has very deep roots it has
connection to very fundamental forms of
differential equation and fundamental
processes in physics so there should be
something out there I believe it's a
very fertile unexplored ground and
hopefully something will come out of
this research led not yet the one you
show what the machine yeah that's for
visualization for Biggio but yeah health
emergencies
another concept is the same nothing
changes about the conceptual level it
was just for visualization purpose now
we address some of these questions along
the top but before again starting we
have to be a little bit precise about
what we mean by asymptotic complexity so
loosely speaking that means if you
smooth your function by smoothing
remember I mean convolution with the
Gaussian and has a sigma parameter that
the larger the smoother if you push this
Sigma to infinity then the function
starts becoming comebacks but more
rigorously what we mean is that for any
radius end that you pick there exists
some blurring amount Sigma star such
that for any pair of two points that lie
inside this ball and for any sigma that
is greater than Sigma star it satisfies
the convexity condition within that ball
this is just a definition of convex
function G is ok it's the equation yes
so G is the in other words is the smooth
version of your original function FX so
in f you it was only depending on X but
4G it has two parameters one is x1 is
Sigma so when Sigma goes to zero it
gives you f kind of the solution for
everyone yes smoothing could be done it
equal or better mother yeah but for this
talk it's the same so basically for this
talk all this moving I'm talking about
is just convolving your f with a
Gaussian kernel and that's the solution
of heat equation but you can you can
explore other kinds of smoothie hippie
question it just happened that
it says you have that particular phone
exactly yeah if it's an unbounded domain
yeah like you're supposed to vision low
heat pushing you will be just melted
very caution yeah so yeah so this
actually getting back to the heat
equation so here you have laplacian
operator and that acts on multi
variables all right now a couple of
simple propositions so any convex
function that you have under very mild
conditions is also asymptotically convex
very simple you write down the
definition of convexity for F and
because you're Colonel Gaussian is
non-negative it doesn't change the
inequality so you can multiply both
sides and again can integrate and you
get the definition for G so from from
this we know that at least the class of
asymptotic TIFF convex function is as
big as convex function under mild
conditions now the other thing that is
again not very difficult to figure out
is if you are talking about twice
differentiable functions then you know
that the Hessian of that function at any
point needs to be positive definite in
order for function to be convex right so
here for asymptotic convexity again you
have similar definition it says that if
your Sigma is large enough larger than
Sigma star then everywhere within this
ball outside of radius M is positive
definite now let me give you a very
bizarre example as to my opinion it's
very bizarre example so consider that
function it doesn't matter
mathematically what it looks like
visually it looks like this so it's
almost flat and then goes down very
quickly and then comes back up why it's
important it's very close to l0 norm so
people interested in sparse
representation recognize that now from
convex convex to the point of view
what's important about it as you choose
Sigma as it is epsilon smaller and
smaller everywhere on the entire domain
becomes concave funk
except a very tiny region around this T
and now I mark the regions that are
concave by pink so here you can see that
it's almost like it doesn't exist
because I mean discretize by pixel so
it's like it doesn't exist but what if
you start smoothing your objective
function it changes to this and now
there is a tiny region you can see white
that is convex right and as you increase
the amount of Sigma the amount of
blurring this region of convexity starts
to expand and it just has no bound so
that's why it's called asymptotically
comebacks you can just make it complex
for as largest large domain that you
like but the important point about this
example was that your initial function
it was concave everywhere so this seemed
like very difficult for a convex
relaxation type of thing but it's
actually asymptotically convex function
okay that was a very good news i'm going
to give you a couple of more good news
about these functions so how is there
any sufficient condition easy to check
that you can say a function is going to
be asymptotic come back the answer is
yes you just need to integrate the
function the original function no
smoothing at all and look at the value
of this integral if it is bounded and if
it is strictly less than 0 then its
asymptotic big comebacks so it's very
simple condition and it's derivative
free so to me it was a very interesting
and as I mentioned earlier in the talk
because asymptotic as in when you
approach the asymptotic convex function
becomes flat so it's really difficult to
find its minimized by numerical
procedures so is there any closed form
solution for the minimizer of that
function again very to me very
interesting closed form expression
exists for it which tells you that it's
just the center of mass of the function
so is that if you want to derive this
madman
have to be like a little bit informal
because if first there's no time to go
through all the details and second is to
become dry so but my arguments here are
very high level they are not like you
cannot consider them as complete proof
but if there was any question about more
rigorous argument please feel free to
the solution happens to be the same as
well actually we know that this is the
solution for new movies for error
estimate the full of signal processing
applications haha so decision making any
bearing ah so if you want minimize mean
square error of another function another
the solution will be just a second if
the material is square which is negative
comments uh-huh no I I didn't know about
that yeah I'm not sure maybe there is
limited ocean right the girl should just
totally company to look with memories is
kind of like your kind we must
nice yeah I say that maybe the
connection is it but you just kind of
handling the proof of the top thing
everyone presents oh yeah so so the way
you can prove that is you you write down
okay you write down the definition of
gee-gees convolution of f x y or
Gaussian kernel now you take the second
derivative of that and you know you can
do it within in F or in the Gaussian
kernel we do it in Gaussian kernel and
then what comes out of it is a something
to terms that depend on I think it's
something like this so there are two
terms that one is over okay I think it's
like this
I think it would look something like
this and then again you're Gaussian
kernel so if I want to be complete you
have this F of T here and then k of x
minus t sigma and dt okay so when you
differentiate this Colonel you get this
now as Sigma gets large you can ignore
this one right and also this one is like
a non negative thing right so you can
ignore that and it just tells you it's
negative of and again as K goes to
infinity becomes like you're integrating
over F long right but with a negative
sign so in order for this guy to be
positive you want the and the integral
of F to be negative right so this is but
you should work out the details of
course because yeah but is it clear how
are they
yeah enjoy it no first time ya Zig there
so one thing about your necklace it
seems that if you can shape the doctor
back constant then you have yes the
internet function has a fun and Ichiro
could actually we want the function to
have a finite integral because otherwise
we cannot we cannot amazing if the
jeweler's planet with positive then it s
Authority come back Kincaid oh yeah
because what if your monthly just
subtract the constant yeah you're just
subject no no but then it's not
integrable on the entire domain see what
I'm saying oh yeah so if you add one to
a Gaussian and then integrated it's it's
no longer a bounded but remember here I
explicit mention that we want the
integral to be banned found and this is
a sufficient cunning so you can't find
asymptotic convex functions that do not
satisfy this but this is handy so you
can easily test some of some class of
functions and here's a concrete example
so again suppose X is that function
again this form is not that important
but it looks like this red curve and it
has one minima here one minimum here one
min room here and maximum there right
and for this problem based on the things
that I just told you you can easily
figure out it's asking the other big
convex right you compute the integral
even it doesn't have to be precise you
see that it's negative so its asymptotic
it come back and where's the asymptotic
minimizer again use the definition you
get it it's there so the yellow bar
shows this point and now here it shows
different plots so this is the original
function and this is a little bit
smoother and this is even more smoother
you see that the minimizer is moving
toward this one and it's also looking
more comebacks met back the original
media myself
yeah we yeah we haven't got there yet
yes this is yeah so if you remember
there were a couple of question listed
the first one was sm product convex to
your own talking about that right now so
for now i think based on the proposition
i gave you earlier you have this know
about this undermined condition but i'm
going to give you even more good news so
again these arguments are are not
rigorous for this talk but this is
should communicate the idea but the more
rigorous proof is available for those
interested so the measure of functions
that are convex is zero if you want to
be concrete we can limit our class of
function to this one so it's just one
very classic function twice
differentiable and then you know that
the second derivative vanishes at
infinity and the second derivative
bounded by capital F everywhere now the
argument is like that because it
vanishes at infinity so you can find
some radius Delta that captures most of
the signal you can make Delta as large
as you want and then anything outside of
it you said 20 you don't care so you can
make this or this approximation to the
original f double-prime as small as you
want the error as long as you want which
is in larger Delta right so we'll work
with just this one now this gives us how
this a bounded support of this function
and everywhere of course on this
function we have also this inequality
now let's divide this bounded support a
region into n cells equally spaced now
the chance of ok what is what is the
situation when this function becomes
convex when all of these cells have
positive value right but if you look at
each sell it sell is just one evaluation
of the function so because we are
talking about second derivative its
convex if at all these cells is positive
right the chance of seeing a positive
number in each cell is a half right
because we are saying that there is no
preference in the sign we just say the
space
it's magnitude is bounded right so it
can choose either pal so overall the
chance of seeing a convex function
meaning that all of these are positive
is half to the power of n right now as
we increase this end to get closer and
closer to the actual function this
density approaches 0 right so you can
say that from this rough argument that
the measure of convex function is 0 it
is on this function class but what about
asymptotically convex function well very
good half of the function that you pick
from this pace or asymptotic comebacks
and why is that because you're here here
it needs to be double prime adding yeah
you need double prime here in this
because again there is no bias in our
assumption in the class of function so
half of the functions have their second
derivative less than zero they're
they're integral and half half positive
and you know that as you make the
function smoother by the same argument
it becomes more closer to its integral
so it's like half of the function or
asymptotic comebacks so these are I
think very good news one other thing
maybe somewhat related to your question
is that now suppose we have asymptotic
comebacks suppose we found it's a
minimizer asymptotic minimizer now the
procedure required us to follow the path
back to the original problem right how
do we know that we can do this because
if somewhere along the path there is a
choice then we are confused we don't
know which path to take and we don't
want to branch as I said so we need to
avoid this kind of situation and
mathematically what that means is that
on the smooth function we don't want the
Hessian to be single or anywhere right
now
so again you can do that with some
manipulation here first you can derive
the path of minimizer is it's very
simple to drive this one I think it
should be clear just write down the
equation for points that satisfy the
stationary point and they differentiate
that with respect to Sigma which is like
time here and then you rearrange their
terms and you get that right now in
order to make sure along this path you
don't see any singularity you you need
to make sure that your haitian remains
positive definite along this path right
and asymptotic minimize that we already
know that we the Hessian if the Hessian
at that point is strictly positive
definite right I mean all the
eigenvalues are strictly greater than
zero right so you want to maintain that
situation you want the evil and let's
say okay lambda here shows the smallest
eigenvalue okay you want to see what is
the evolution of this eigen value over
time right and then see if it's getting
smaller or larger how in which direction
it's moving you don't want it to go down
right given the eigen value itself can
there be said anything is that is there
any relationship at all between this
eigenvalue and its evolution in time yes
there is I cannot get into the details
because of time but here I just say you
need to use two things one is the
property of heat equation that relates
this operator to this operator so
differentiation in time becomes
laplacian in space and therefore you can
read this again if I have sec
information about second derivative the
eigenvalues can I say anything about
fourth order derivative and again yes
you can if the function is smooth enough
just use the negative definiteness of
laplace operator and just to give you an
intuition for those who are not familiar
with that why is that the case so if a
function is very smooth let's say it's
just consists of 10 sinusoids right
let's say it's sign sinusoid sine of X
right
so this is your f double-prime now i
differentiate this twice more and what i
get is minus sine of X right so it's
just the flip version and so there is a
very couple rich but as you add more
terms to this like high frequencies then
this is not quite the case but as long
as your function is this move so these
terms are dominant then you can relate
these derivatives so by taking yeah I
wish your previous life you have this
nice animation that showed that this
little kind of concave up magically
appears exactly where the minimum of
initially synthetic the convex blue
thing is and this is why you got this is
branching behavior you're trying to
right now it seems like if you had just
added a little bit of noise this is a
singular point you could have made
another innovation where the bug just
shows up a little bit to the right of
left and you would not have ever had
this company yes branch yes that's a
perturbed analyst III using good good
sophistry yeah I get your point but that
but the goal here is not to just
randomly pick okay in this maybe it's
misleading because both of these are
similar let's say one of this actually
becomes deeper eventually right so you
want to follow that path and this one
stays like a local minimize so if you
want to like choose one direction by
chance then maybe you choose the wrong
one right so let's take the back
following so proving that your entire
trajectory has no branching points
mm-hmm is weaker than the creaming that
you'll actually converge the minimum of
the non convex function right I mean you
would have something that appears very
very far away from where you are which
turns out to be the global so that's
that's a separate issue so all we're
saying now is we're asking for a lesser
thing we're not actually trying to find
the minimum of the non convex function
we're just trying to prove that as we do
the smoothing thing we never hit a
conflict or a fork in the world that we
have to choose and I'm saying just to
avoid that it seems like a perturbed
analysis mainly showing that this will
happen with visuals here
a little bit a little bit noisy function
to prevent this seems to do that right
yeah yeah but yeah but as I said yeah
this is not the entire goal so this is
one condition that we want but we have
we need to have some control over it so
we need to basically say which which
path it chooses so that it gets to the
global moon so I haven't discussed that
yet but there is a there are different
ways that you can control and prevent
this one is that but what we really need
for making sure that this path leads to
the global minimizer we need something
more than like local perturbation or
adding noise you know because by by
adding noise that you are not you're not
using the assumption that which which
direction is better for leading you to
the global optimum right it's just noise
but we can discuss that later if you
want because I think I need to get to
the application part actually I'm done
with the theory so if there was any
question I'll be happy to answer after
the time but now let's get to the
application of this idea so its image
alignment it's a very fundamental
problem computer vision if you do a
structure from motion viewing Varian
recognition or tracking in videos you
usually have to hit this problem now
there are two major approaches actually
if anyone wants to read a little bit
more about alignment there is an
excellent tutorial by ricks dallas key
here and all the details are there but
there are two major approaches that you
that you can use for alignment the first
one is feature-based so you select a
bunch of sports feature points and then
try to make a correspondence between
them and then use that to infer what is
the geometric transformation between the
two images and the other one is called
intensity or direct method and that's
you just subtract the two images all the
pixels get involved and then you get a
residual and then you try to minimize
this residual so find the alignment that
minimizes this
the job so intensity based method seems
more tempting because it uses all the
information in the image but in the
first one you are throwing out a lot of
information and so this one seems to be
richer in some sense but unfortunately
when it comes to practice usually you
you have a lot of local Optima so it
doesn't help that much now again to get
you familiar a little bit to the setting
let's say we have a very simple problem
alignment so f1 and f2 or two different
images and then they're different by
displacement D so the task of alignment
we can just format it like this minimize
these such that minimize this objectives
to get the optimal d right now this is
non convex because f is out of out of
our control it's an image and it can
look a very crazy function and therefore
d can look very crazy function right so
you need to somehow get get away with it
one way is you linearize your f with
respect to this optimization variable in
this gate happen to be d and the first
order taylor you get this and then plug
it in there now it gives you a convex
quadratic function you can solve it even
in closed form and then you get some D
hat it's in just an estimate and then
apply this to D to the image but
remember there is an approximation here
so if this approximation is poor then
this is far from your true solution
right and then according to Taylor's
remainder theorem you can bound this
difference so this this one is obvious
because you are here we are linearizing
around the origin so the larger d the
worse it gets and this one is depends on
higher higher order term actually it's
the largest eigen value in magnitude of
the hessian so you want that to be small
as well well that depends on the image
and what if it's not small what you can
do
you can smooth your image you can
actually blur your image and the effect
of this is that that lambda capital
lambda will become small and helping you
so the estimate of do you get is closer
to this star right but again there is a
there's a problem here because as you
blur your image you lose some of its
details right but you can't do this
iteratively so this is called Lucas and
kannada algorithm so you start from a
very coarse blur and make the alignment
and then apply that alignment to make
things a little bit closer now your D is
now reduced a little bit because now
you're putting in a smaller domain so
you can reduce the reduced amount of it
because we want this total thing thurs
previously so we want this total thing
to be small so as you optimize over D D
and D get smaller and smaller to the
desired value then you can you are
allowed to increase this one and that
can happen by like making it less blur
the image ok there is even a proof that
this idea works well it can recover the
correct displacement as long as we are
talking only about displacement but I
have seen people using it even for
motion models that are not displacement
and that is mom and it's easy to say to
see that I mean by wrong at this it's
not optimal so let's say that we change
the problem setting now instead of a
displacement we are talking about
scaling so f1 f1 now ok we have f1 s X
so this is the objective function we
have f1 s X minus f2 and then we square
this and then integrate
so again we can linearize it we get this
form and okay we can find a closed form
solutions convex quadratic and look at
the error bound this is this is very
important now in the error bound you
still have that capital lambda you still
have the deviation of this variable from
the linearization point but this term
appeared here which shows that this the
quality of this error depends on the
location in image that you do the
linearization as well so in other words
as you get farther and farther from the
origin this approximation becomes poor
so suggesting that if you want to do any
kind of blurring it should be more
intense and aggressive four points
farther from the origin right so
remember this point here because we will
get back to this I just wanted to
mention look US Canada algorithm so we
need some kind of blur that's especially
variant but in Lucas Canada algorithm
what it does it just blurs the images
with a isotropic Gaussian so every every
region is treated equally but let's look
at the day I human eye let's see what it
looks like they're so there are some
color receptors called con if I'm
pronouncing it correctly and this is the
density of those palm points this is the
center of the eye and as we go towards
the periphery you see that the density
rapidly decreases the implication is
that whatever you see at the center of
your like in your phobia it has a the
highest quality and then as you move
toward the periphery then it comes
blurrier and blurrier right so at least
from biology there's an evidence that
you need this kind of spatially varying
blur also people envision have heuristic
they come up with ideas like Berg and
Moloch based on their intuition they
develop some blur blur kernels that are
not specially in very
but it's just heuristic but today we are
going to derive these kernels in a very
principled way for the first time so
again to be concrete and illustrative
let's take the same example it's one the
scale alignment that's the actual task
and what traditionally people envision
do is that they smooth the signal so
this convolution is over space X and
then try to solve it by Lucas and Canada
algorithm but what I am suggesting today
is to smooth the objective function
because that's where you want the
minimal local minimum to disappear right
so this should be really your goal and
let's look at the landscape of this
optimization objective to see what it
looks like so the signals are these one
blue one red I hope it's visible very
simple functions and they are just fit
Miller mirror of each other ok so the
optimal scaling is minus 1 so that you
flip them now by signal smoothing you
get this picture now what is this so
this is where you have the highest blur
and this is your choice of scale factor
so it has two local minima here so as
you make it the blur enough you still
have two local minima so you have to
choose them choose one of them randomly
right and then if you trace the path of
that back to the original by reducing
the blur there is a chance either you
hit the global minimizer or you hit the
local this is for this one look US
Canada but if you blur the objective
function then there is only one start
point and for this particular example is
actually the one that leads to the
global mean there is another path that
start somewhere in the middle of the
road but we never get that because we
believe the other way
the other side what do you mean by the
other way here when you trace it down
here I just have to trace on the left I
suppose that's due to the same problem
that you mentioned earlier about
replication makeup probably have
misunderstood well no bifurcation
happens here either on this one or that
one there's no bifurcation
oops applied by digital under what
condition does it respect to the wrong
okay so that that's the most difficult
question so if you remember I was
listening a bunch of the theoretical
results that we have for this problem
and that is something that I'm working
on still I don't have concrete results
to present but I really hope that we can
also get at least some conditions on
that as well to connect really that
theory to the application to the brewery
and you find the global to my destiny
miracle yes yes we forgive an example in
the show yeah yeah okay now what is the
the practical challenge here well if you
want to blur your objective function
let's say your transformation is home
ography on plane so you have eight
degrees of freedom that means you need
to evaluate an eight dimensional
integral right because this convolutions
or going over the parameter space now
right and that can be expensive so the
question is that is there any
alternative two dimensional function
that if you compute this integral
transform into D it becomes equivalent
to this eight dimensional integral for
smoothing right and fortunately that's
that's the case at least for most of the
transformation we care about and I call
this guy the transformation kernel and
how do I derive it well you use a free
analysis and get two very simple
proposition here and based on this
proposition if you plug in tau 2 tau is
your transformation model so tau takes a
point X and then returns another point
by for example so if you plug in your
towel here then you get at least a
four-year form and then you need to
convert it back to the spatial form and
the proof of this proposition simple you
use just for your presentation and then
for parts of all theorem and if you do
that for these transformation you derive
the corresponding colonel so
hope for example translation is x + D
and this is the colonel you get also you
can see for whom ography this is the
transformation and I didn't put these
because these are long expressions but
this is some exponential form and this
is a some rational form and this is a
visualization of some of these kernels
so these two are for a fine those two
are for homograph II now again that the
point here that I want to emphasize is
that these kernels when you want to
compute the integral transform they are
2d integrals not eight dimensional
integral but they have the same effect
as integrating your function over that
eight dimensional space so bring some
efficiency and of course I cannot go
through the details of the derivation
here but I can at least tell you two
things that you can check the
correctness of them to necessary
condition to check the correctness of
them one is that because original
intention was to smooth by a Gaussian
kernel so it has to obey properties of
heat equation right so first it needs to
satisfy the relationship between
laplacian and differentiation in sigma
and second you want with as the
smoothing amount goes to zero you get
the original transformation and if you
test that on this table you see that
it's the case okay so now in general if
you are not talking about just the
particular transformation model you can
write the correlation so correlation is
another measure like l2 error that you
can use for alignment you try to
maximize it so if this is your original
correlation objective function you can
start smoothing that objective function
with discussion colonel in the parameter
space and then use that kernels to make
it an integral over the space of X this
is the important note the important
point here so now this became
two-dimensional and then there is a
simple algorithm that just follows the
path
dr. minimizing or maximizing now perhaps
a we're getting close to the end 11
point that is worth mentioning is again
getting back to lucas and kannada
algorithm and see how it compares with
these kernels so it again shows that for
translation only what you get if you
plug in the translation colonel then
what it looks like is that you are
actually convolving your image with an
isotropic Gaussian so again this is
reinforce izing that if if motion is
just translation then yeah using just a
isotropic Gaussian with fixed Sigma is
ok but as long as but once you move to
other transformations say a fine it
becomes an integral transform that is
not necessarily a convolution and you
need to do that and it's spatially
varying so experiments very limited
because these are really preliminary
results but here you can you can see the
result of alignment so these are the
images we use for alignment and this
axis shows how much the transformation
was drastic then the transformation
class was homography so this one was the
most difficult because it had them the
like the largest tomographic change and
these curves show the correlation
coefficient that the algorithm converts
to after alignment so the bigger the
better right and you can see that for
nobler red or Gaussian blur they do
almost similar and they are way below
when you blare the objective function of
course all of them become worse as you
make the problem harder but the point is
that this is always doing better than
others so that was all and I just want
to acknowledge batam and John for their
help and thank you very much I think we
have five minutes if there is any
question
any additional questions there
yeah you something goes other than
Gaussian no and the reason is that I
really use I really I really leverage
the property of heat equation for that
if you remember that discussion about
for instability so I convert the
evolution over time to laplacian and
then that's very important because now
everything becomes static you don't care
about time evolution now and then you
can use that to say something about how
come backs you're losing convexity over
the curve and stuff but of course you
can you can consider other but that's a
that's probably more difficult i suppose
suppose these other krilova me will be
able to get such a simple solution has
been set up girlie
50 the solution for missing pally
the center of gravity solution uh-huh if
it's other colonel yeah other kilo for
example it is my pleasure these herons
are not gumption this can talk about i'm
talking about this i mean i want to be a
solution you have 40 I synthetic
commerce among you the result is the
center of gravity point so you oh you're
talking about that that example you
ok this one yeah uh-huh so if you use
the other kind of kerla photo to the
smoothing uh-huh you probably won't get
there well I I'm not sure as I just said
that I only the Explorer gaussian and
the reason was that it has a lot of nice
property that makes the analysis easier
yeah but I think yeah you can but bill
be more difficult obviously if you use a
different kind of Colonel empirically do
you show the maybes of different
solution ok I didn't try
yeah you derived some of the kernels for
particular types of transformations but
then there's a very large range of
possible transformations and some of the
difficulty of private rice so how about
trying to learn these kernels from
example divinities
we will rock you know you know the
alignment if the image is given to you
is supposed to fight kernels that would
have the optimum at the right point
right well i think in principle that is
doable but but i believe it you have to
do it like by some numerical like
procedure I don't think you can do much
by closed form because because because
it is highly depends on the form of your
data and if you cannot make that much of
assumption on your data then it can be
anything step back because you're not
going to be anything it's still just
learning procedure but I'm just
moderated intership does that make for
examples that you can derive things with
the learning procedure get the same
criminals anyways and then for some
other things
where you can't drive things very
particular give you something reasonable
haha that's a that's some experiments
that is very interesting to do
especially like the first one to see if
we cast this problem is a learning task
and then limit the transformation model
to those that we know they're colonel
then we'll there Colonel converts the
same thing so that way because they're a
little bit different I think in terms of
their objective so if you use learning
one I think the goal is and the goal is
eventually do you want to do
classification I mean it's the
optimization criterion optimized for is
for for reconstruction or by up whatever
you whatever function was right on you
trying to find the blurring colonel
that's going to be my departure right
point aha right but you've given
examples of
english with ground food yeah that's
definitely a very interesting experiment
to do but I know a lot of like through
informal chat with people including
Larry and with you you all have this
observation that based on empirical
results you got something similar to
this blur kernels so but but doing I
think a very conclusive experiments on
that is very interesting ready like in
practice you really want to know there
is eight degrees of freedom in apocrypha
right and you want the standard
deviation amongst those eight degrees to
be all the same probably not you know
like translation might have a water
variance and scale etc so I think
through training data you'd actually
learn standard deviation of those eight
parameters and then use that plug it
into the same model and that will give
you the right Cardinals for that so you
want to do it truly nonparametric you do
it it up you know you really just under
this bit small subset of grammar
yeah I think you're referring to
realization right yeah so also in the
city PR paper we don't know yet if it
gets accepted but if it gets accepted
you see so we had one more thing called
regularization of the solution and that
just adds some prior but we use very
simple part just identity transfer so no
special bias but we use that just to
prevent converging to like very weird
transformation and I think what Larry is
suggesting is that now with learning you
can more accurately model that prior
because that's specific to that data but
because of time I couldn't talk about
regularization here
I thank thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>