<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning; Emily Denton | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning; Emily Denton - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning; Emily Denton</b></h2><h5 class="post__date">2016-06-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bJwGr2bWVUg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by microsoft
corporation may be used for internal
review analysis or research only any
editing reproduction publication
reblogged showing internet or public
display is forbidden and may violate
copyright law
alright it is my pleasure to introduce
Emily Denton emily is currently a
colleague she is doing internship at the
Facebook a research lab she's a PhD
student at NYU with Rob Fergus and she
has done a lot of work on a variety of
topics for instance complexion of CNN's
and traditional hashtags and here she's
going to talk about how to turn down the
numbers into beautiful images all right
thank you very much for the introduction
and so yeah I'm Emily and this is joint
work with sumus Arthur and Rob at
Facebook AI research so what I'm going
to be presenting today is a parametric
generative model of natural images the
motivation for this work is the
observation that it's very very
difficult to generate large natural
images in one shot so if current
modeling approaches for images have a
very difficult time scaling past sort of
low-resolution simple images so what
we're going to do is exploit our domain
knowledge that we have of natural images
in particular we're going to exploit
their multi scale structure so the basic
idea for this work is that we're going
to break the problem of image generation
down into a sequence of much more
manageable subproblems so first we're
going to care about just generating
small low-resolution images so this is a
very simple problem four by four eight
by eight resolution is something easy to
work with then we can learn a bunch of
conditional generative models that
generate a slightly higher resolution
version image conditions on a lower
resolution image so we do this by
combining a generative adversarial and
network learning framework with a low
class II and pyramid representation so
I'll now describe those two parts in
turn so generative adversarial networks
are recent generative modeling framework
proposed by a good fellow at all at last
year's nips and the idea here is that
we're going to learn a generative model
that learns to map from some noise
distribution into image space which I'm
referring to his ex and the interesting
thing about this model is that it's
trained by introducing a discriminative
model and the two are going to be
trained in opposition with one another
so the discriminative model in our case
will be a neural network and it's going
to be trained to discriminate between
real samples sampled from the data set
this is depicted on in this column here
and fake samples generated from our
generative model the discriminative
model is just a you know binary
classifier and then the generative
network is trained to fool the
discriminator so it wants to generate
images that the discriminator thinks are
real so there's a recent extension of
this work whereby an additional piece of
information is introduced to the
generative network and the
discriminative network so for example
you could condition the generative
process on a class label in which case
the generative network is asked to not
only generate realistic images but
generate realistic images consistent
with that class label and you can
condition on a variety of other things
as we'll discuss so laplacian pyramid is
an invertible multi scale image
representation it's obtained by first
constructing a gaussian pyramid which is
illustrated in this top row here and
then computing a difference image
between consecutive scales of the
pyramid so the result of this is a
sequence of band pass filtered images
here and low pass filtered images the
laplacian pyramid is then given by this
single low frequency residual image and
these band pass filtered images and then
the original image can be constructed
reconstructed exactly by simply adding
in the high frequency information into
the low frequency images so what we're
going to do in our work is we're going
to learn a conditional generative model
for each scale of the laplacian pyramid
we're going to train a model to take as
input a low-resolution image and produce
high frequency structure that's
consistent with that image so as I said
we're going to train this with this
conditional generative adversarial
network framework so this image here is
depicting training of one scale of the
pyramid so for all of the images in our
data set we're going to downsample them
by a factor of two to get this low
resolution image we're then going to
just blow it back up so it's the same
size as the original image we can
compute the difference between those and
this gives us a ground truth sample a
positive example for our discriminator
we then have this generative network
which takes as input a noise vector in
this case we have it be the same
dimensionality as the image and we also
give it the coarse resolution image and
it's trained to produce some
high-frequency structure that hopefully
is going to be consistent with this low
resolution image the discriminator takes
in either the real high frequency
structure or the fake high frequency
structure along with the coarse
resolution image and has to
terming whether it's real or fake so we
trained this model for each level of the
plastine pyramid and they're all trained
completely independently so this means
that no gradient information is
propagated from one level of the pyramid
to another so sampling in this model is
very very simple and it's akin to
reconstructing an Alaskan pyramid so we
take our first level a generative
adversarial network it's not conditioned
on anything because it's the first level
it takes in a noise vector as input and
produces a low-resolution image as I put
we then pass that low resolution image
into this next generative adversarial
network which produces high frequency
structure that's consistent with this
low resolution image we then add those
two together to get a higher resolution
image which then becomes the input to
the next general retro style network and
this procedure has continued until we
have an image of the desired resolution
ok so we train this model in a variety
of different data sets the simplest
experiment that we did was on c far
which is a small data set of ten
different classes we use convolutional
neural networks for both the
discriminator and the generator and
these models were quite small because so
far is a pretty small data set so we
also conditioned in these models on a
one hot encoding of the class label so
this means that we can then sample from
the model for a particular class so
these are some examples of ship samples
from the from the CFR model and these
the visual quality of these samples
compares favorably to other sort of
models trained on these data sets we see
we get sort of sharpened edges some
images look like plausible boats other
ones you can see some artifacts again
here are some horse samples and
similarly you see sort of sharp object
like structure but there's you know
clear ways to go before we have perfect
models so then we also trained a couple
models on the l son data set so this is
more interesting because this is a much
larger data set of scenes and so we were
able to train quite large and deep
convolutional neural networks so these
models have five convolutional layers in
the generator and three in the
discriminator and so for this we trained
different models for different scenes
i'm going to show you some samples from
models trained on towers and churches
so this is depicting here is the course
define generation chain so the way you
read this is this first column here
shows a four by four sample from the
courses level generative model and then
we condition the second generative model
on these low resolution images and we
generate something of resolution eight
by eight we then condition and get 16 by
16 and so on and you can see that this
is this is just one example of a high
resolution image that could be generated
from this low resolution image because
there is the stochasticity and the
network's we can generate a variety of
different images given you know a lower
resolution one so we can look at what
these samples look like so this is these
are a bunch of random samples from a
model trained on churches and you can
see that there these are 64 x 64 so the
i should say these are these are larger
resolution than previous models we're
able to achieve and you can see you know
there's a fair amount of variability in
the images and there's a lot of sort of
detailed structure and from far away
they look like churches if you look up
close you'll see little warped morphed
images but they're fairly they're fairly
realistic images so another thing that
we might want to do with our model is
sort of probe you know what kinds of
variability the model has learned and so
to test this what we did was we sampled
a single low-resolution image from our
coarsest model and then we conditioned
the generation process on that image so
that's what's shown here in the leftmost
column and then all subsequent columns
here show different samples from the
model so different random noise vectors
are injected into the model to get
different courses or different high
resolution images that are all
consistent with this low resolution
image and what's interesting here is
that you see the network has learned all
sorts of different you know structures
about towers and churches so if our
model is simply learning a lookup table
for example you would see you know very
very slight variance of the original
image but we do in fact see sort of
Tower is being added and removed you
know in different sort of variance of
semi-realistic church images so another
thing that we can do which I'm going to
illustrate in this
video which it might have a little bit
of trouble buffering initially but bear
with me so what we can do here is see
what kind of manifold of images our
model has learned so what I'm going to
show you is I in this corner here we're
going to have we're going to be
traversing a path in the space of four
by four images and then this this
section here will show a 16 by 16 image
generated condition on that four by four
and this shows the 64 x 64 version of it
so give it a second wild buffers it will
start to look more realistic but this
can what you should be noticing here is
that the air guess the images are sort
of varying smoothly and we do sort of
see Church images at every point we see
sort of you know different churches
morphing into different churches but
it's varying smoothly as we as we
traverse this this low resolution space
and you can do different sorts of
variants of this and we have we have
some demos online that show different
sorts of ways to probe these models so
okay almost done so generative ever sail
networks are wonderful powerful models
but they they're very finicky to train
and there's lots of instability issues
and so very recently I in the past
couple weeks or so what papers come
online I redford myths and chintala and
this is a really nice paper and it
proposes a bunch of tricks to stabilize
the generative adverse I'll network
training process and so they use these
tricks and they train very deep models
and these are not our conditional
laplacian pyramid models these are just
standard Jenner driver sale network
models and they get quite high quality
samples so these are just an example of
bedrooms they trained on a variety of
other data sets but the samples look
very very nice so something nice about
this is that the techniques that they
propose are orthogonal to our work so
you know some future work for us will be
to combine those tricks into the
training of our generative ever sail
networks at each level of the pyramid to
hopefully produce even higher quality
and higher resolution images so to
summarize we propose a very simple model
that is able to exploit our domain
knowledge of images and there's a
variety of sort of ways this this model
could be used for example could be used
as a decoder in an auto encoding
framework for unsupervised learning and
as I mentioned there's a lot of future
work to be done to make these models
more stable and easier to train but
people are sort of looking into this so
if you want to look at our code try it
out or see some more examples you can go
to this website here thanks
diamond thank you this is a very elegant
a combination of two solid ideas I like
it a lot I'm wondering if they are
sufficiently orthogonal indeed that you
could replace the the generative system
by for example a conditional energy
based mobile or some other generative
systems what are your thoughts yes so I
don't think that a generate viber
cellular network is the only generative
model that we could use here it's the
only one that we sort of thoroughly
explored and it sort of made sense to
try out because generative address
Eiland networks produced these sort of
nice sharp images that you often see
other sort of generative models blurring
things out and in our case we want to
really make sharp images so so general
better cell networks with a nice
approach but that being said you know
any sort of really powerful conditional
generative model should be you know able
to be plugged into this into this method
and that would be a very interesting
interesting thing to explore okay thank
you any other question hi thanks for the
talk so I feel like the success of the
Jeff model depends a lot on the
discriminative model and so to train it
you need real images and generated
images but then you need the generative
model to train to generate the synthetic
images so it's that kind of a chicken
and egg problem or um sort of and I mean
that's that's kind of the way that it's
trained so initially the generative
model is going to produce you know
garbage images it's taking a random
vector as input and it's you know it's a
random randomly initialized neural
networks will produce total garbage and
the discriminant at work's work overtime
starts to learn okay you know this is
the structure of a real image this is
what is a fake image and then the
generator has to get a little bit better
and so they really do sort of you know
cycle back upon one another and there
are lots of you know interdependencies
between the two if you're discriminators
you know too powerful early on that it
will be very hard to for the generator
to learn anything interesting so
definitely is a very very strong and
important interplay between the two of
them during training Thanks any other
question okay so let's thank Emily again
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>