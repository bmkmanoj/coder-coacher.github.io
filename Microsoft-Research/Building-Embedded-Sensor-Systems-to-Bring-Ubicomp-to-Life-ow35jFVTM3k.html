<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building Embedded Sensor Systems to Bring Ubicomp to Life | Coder Coacher - Coaching Coders</title><meta content="Building Embedded Sensor Systems to Bring Ubicomp to Life - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building Embedded Sensor Systems to Bring Ubicomp to Life</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ow35jFVTM3k" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
Gabe cone doesn't really require that
much introduction he's been around for a
while hanging out with us I still
remember first meeting with Gabe young
superstar student out of Caltech coming
out you know specialized in embedded
systems vlsi computer architecture over
the years have been great hanging out
with Gabe watching him grow into you
know take his skill set and grow into an
amazing ubicomp researcher first
internship I you know Gabe's push the
boundaries in various ways I used to
have this standing challenge for all my
interns to try and break as much as they
can in the first week here until Gabe
came in the you know Scott's a bonus now
with the group held the record for
taking a part of forty thousand dollar
EEG device in his first week and you
know I walked in and he couldn't put it
back together first weekend Gabe
internship he called me he goes hey I
think I broke your house so I stopped
doing that challenge son that's didn't
seem like it was easy to top first
internship Gabe set the bar really high
ended up with three papers two best
paper awards won best paper nomination
which made it really rough on our
subsequent interns if you look at his
portfolio you know an NSF graduate
fellowship and MSR graduate fellowship
multiple multiple best papers startup
company that's gotten funding in the is
in recent series a round that's out on
market and that it looks like he's got
prototypes of rather than standing away
let me hand the mic over to Gabe thanks
a lot designee so I'm going to talk
about bunch of my work on building
embedded sensor systems to bring you be
comp to life and since a lot of this
work was done here at MSR you might
recognize some of these things so first
what is you become so you become for
ubiquitous computing is this idea that
was started in the late 80s Early 90s by
Mark Weiser and his colleagues Xerox
PARC the idea was that instead of having
users interact with a single personal
computer they would instead interact
with multiple computing devices
simultaneously as they go about their
everyday lives and these computing
devices will not only be you know
sitting on your desktop as shown here
they would also be worn on the body in
the case of wearable computing or mobile
computing or off the body and seamlessly
embedded into the users home and work
environments and in order to enable
these kinds of ubicomp applications
requires building these embedded sensor
systems now embedded sensor systems can
generally be broken down to four main
parts there's the human interface the
sensing the computation and the
communications and developing these
kinds of systems actually requires
expertise in nearly every sub domain of
computer science and electrical
engineering luckily in the last 25 years
since wiser had this vision of ub comp
we've actually seen exponential growth
and improvement in nearly every single
one of these subdomains and as a result
of this progress we've actually seen our
first major victory and you become and
that is that mobile computing truly is
ubiquitous today so from our smartphones
and tablets and laptops we've really
become accustomed to having information
always available our fingertips and all
this is a huge success for you become we
still have not yet realized many of the
original dreams of wearable computing
and enabling smart environments however
this is still a really exciting time
because we are just beginning to see
what these kinds of applications might
look like but in order to bring many of
these ubicomp applications to life we
need to continue to do research not only
in each of these subdomains of computer
science and electrical engineering but
research that crosses the traditional
boundaries between the human interface
sensing computation and communications
and this multidisciplinary research is
required in order to reduce the adoption
barriers that are currently limiting
widespread use and the problem as you
can see here is that sensing is still
very invasive both in terms of the
number of centers required on the body
and off the body as well as the way in
which these centers are used and often
the problem is actually power
consumption so the high power
consumption of wireless sensor systems
typically limits their their battery
life and therefore their usefulness and
so my work is focus
on trying to make sensing more
non-invasive by doing a tightly
integrated hardware software development
with a focus on ultra low power indirect
sensing more generally I look at
identifying new opportunities for
sensing building new embedded sensor
systems and then finding new application
to application domains for this sensing
and I do this work for both on body and
off body sensing and so this slide gives
an overview of most of the work I've
done in grad school and in this talk
I'll only talk about a subset of this I
won't bore you with everything I've done
so i'll talk about a little bit of work
that i did here actually on on body
sensing to enable a low-power
human-computer interaction I by
leveraging the conductive properties the
body and then I'll talk about some off
body sensing where instead of leveraging
the connective properties of the body
I'll actually leverage the existing
infrastructure again to reduce the
number of sensors required or reduce
power consumption so let me first talk
about this on body work and so the focus
of this work is actually to enable human
computer interaction and so as we move
to more ubiquitous interfaces we have to
move away from the traditional mouse and
keyboard paradigm of interactions
computers and find more natural ways of
doing these kinds of interactions and so
one thing has become very popular is to
use whole body gestures so this is
something we're all very familiar with
using computer vision and depth cameras
like the Microsoft Kinect now
unfortunately these camera based systems
actually have some drawbacks so one is
occlusion they can only see directly
what's in front of them line of sight so
if you have a second user they might
actually block the line of sight path
from the camera to the other user in
addition to occlusion there's big
problems with lighting so anyone who's
been you know upstairs to Andy and
bengkos lab sees they all work in the
dark and the reason is because lighting
actually is a problem for a lot of these
camera based systems this is actually
from the Kinect support page and you see
confusing things like make sure the room
is
really lit and avoid direct sunlight and
so but I see the actually the biggest
issue with Cameron bae systems is their
limited field of view so if you want to
interact using whole body gestures in
your living room you can do that you can
use a kinect and that works great but if
you want to do this kind of interaction
everywhere in your house you'd have to
instrument your entire house with
cameras and of course this is difficult
in terms of the installation and
maintenance but it's also not practical
to put cameras everywhere in your house
so you know this is still a really
interesting way of doing whole body free
space gestures so I want to do this kind
of interaction as well I don't want to
use a camera so I don't want to be
limited to doing this just in the living
room I want to be able to interact with
my computer anywhere so I could interact
in the kitchen in the dining room or in
the bedroom and so I'm going to talk
about a project called human antenna
which allows you to do just this it
senses whole body free space gestures in
real time but it does it instead of
using a direct scenting approach where
use a camera it uses an indirect sensing
approach where we actually use the human
body as an antenna and I'll describe
what that means in just a minute but the
real advantage of this is that there's
no instrumentation to the environment
and only minimal instrumentation on the
user's body so you can think about it as
connect like gestures without the
connect now I talked about using the
human body as an antenna so let me
describe a little bit about antennas so
you might recognize this this is a
typical TV antenna it's called a bunny
ears antenna because the way it looks
but it's not the only kind of antenna
this in addition to me and my brother is
also an antenna this is a human body
antenna it's called a teenager again
because the way it looks but it actually
wasn't designed to operate at a fixed
frequency like the TV antenna it's
really just a dielectric with a complex
geometry which works fairly well as an
antenna between about 40 Hertz and 400
megahertz and this is nothing new is
actually known as the body antenna
effect and it's actually a source of
noise and interference in body area
networks and anyone who's looked at
analyzing signals on the body so ECG EMG
like a lot of people here have done and
so in this product I'm actually going to
use this noise or this interference as
my signal so let me show you how this
works here's function cartoon form this
I think the only embarrassing picture of
anyone i have in this room and the slide
deck i just realized and so here's our
human body antenna and in this project
we're going to look at frequencies below
about 200 kilohertz and in this band the
signals of the body picks up are the
electromagnetic noise radiating off the
power lines and appliances in the home
and so we can actually sense this very
simply just by measuring the voltage on
the body and then applying some single
processing and machine learning in order
to enable this gesture interface so what
does the signal look like well if you
take a look at in the time domain you
see basically a distorted sine wave at
60 hertz this makes sense 60 hertz is
the frequency that powers delivered to
all of our appliances this is that noise
that's rated not the power line the
amplitude of this signal actually varies
as a function of the user's proximity to
these noise sources to the power lines
and appliances if you look at this in
the frequency domain again see this 60
Hertz peak and you see all the harmonics
of 60 Hertz now the harmonic amplitudes
vary as a function of the user's posture
and this is because as the user changes
their posture they're changing their
antenna properties so essentially the
transfer function of that antenna is
changing so using a machine learning
approach where we pull out some of these
time and frequency domain features we
can actually you know train the system
with the user number of different
postures and then classify which
postures they're in if we look at higher
frequencies up to about 200 kilohertz we
notice there's these peaks and these
Peaks are the noise generated by the
switch mode power supplies all these
power bricks that we have plugged in all
over the place and again the amplitude
of these peaks is a function of the
user's proximity to those noise sources
to the appliances that generate them so
again using a machine learning approach
and taking these features as well we can
also determine the user's location so
this is really exciting with no
instrumentation to the environment just
looking at the voltage on the body and
applying some signal processing a
machine
turning we can determine the user's
posture and location of course I promise
more than just posture and location I
said we can do whole body gestures so by
gestures I mean the user is actually
moving not just standing still so let's
take a look at what the signal looks
like when the user moves so you get this
voltage waveform like this the first
thing we want to do is actually segment
when the users actually moving so to do
this will take a low-pass filtered about
10 Hertz and will notice something
really interesting if you look at this
green curve you see that when the user
is not moving the line is pretty stable
around zero volts on the user moves it
deviates away from zero volts so for now
I'm going to ignore why that's happening
i'll come back to that in a few minutes
but we're going to use this for
segmentation so we can simply set a
threshold on this green curve and figure
out when the user is moving the next
step is we want to do some feature
extraction to determine pull out some
features to use for classification so
we'll take a high-pass filter at 40
Hertz and here we can see the AC
amplitude of this voltage signal on the
body you can see that during the gesture
this amplitude changes so in order to
capture the dynamic nature of the
gesture I'll actually divide their
segmented gesture in 27 feature windows
and over each window we'll use a number
of time and frequency domain features
and then use all these features in a
support vector machine classifier and
this will allow us to classify between a
number of priests trained gestures so in
the evaluation i'm about to show we
which many of you went around homes and
did many times we use 12 pre-trained
gestures so this involves things like
waving your arms moving your body from
side to side and then series of punches
and kicks because you know we're
comparing to connect so we have to do a
bunch of punches and kicks and so we did
an evaluation with eight participants in
eight homes and found this actually
works with about ninety three percent
accuracy so again this is really
exciting there's no instrumentation the
environment just looking at the voltage
on the body you seen signal processing
and machine learning we can determine
what kind of gestures the users doing
three percent accuracy yeah you have to
train per person per location to get
this level of accuracy you could
potentially make a model that works
regardless of person we you know we only
had 12 people or eight people and so you
know we definitely got much better than
chance with that but with eight people
we can't really answer the question of
whether it will work in general so
because we're using the noise in the
environment it's definitely going to
change as the noise changes over time
right so if you change the setting of
the lights or turn on into appliance and
the noise around will change and so yes
how well it works will change over time
depending on the features you choose you
could actually choose features that are
more or less sensitive to that yeah you
have to correlate the performance
envelope for the gestures so people are
inconsistent we didn't in here but
that's actually kind of an interesting
thing to do and it depends you know on
the gestures and how they're confused so
what's actually interesting is what's
confused most is not kind of slight
variation to the same gesture but things
that are symmetric but completely
opposite someo moving your right hand
first year left hand and the reason for
this is we can really only tell that
apart if something about the noise you
know is different on one side versus the
other so that's actually more of the
issue but it totally depends on the
noise environment yeah i got my motto
for my house say AJ has a fur model and
in her house I happened to go there is
any anything reusable from those two
sets and two sides of features so what I
think and this is kind of just
speculations we haven't done that exact
test but I would say that if AJ has her
train set and you go to her house you
could use her model and it won't work as
accurately as if you had trained it
yourself but you could maybe use that as
a starting point and then bootstrap to
kind of build a personalized model so I
think you can definitely have
location-based models that are people
agnostic there will be some differences
on different people particularly if
they're different sizes right so you
know might work fairly well because you
and AJ are about the same size but AJ
and AJ's kids might not work quite at
nearly as well yeah benga varying with
how your body is hydrated
I think somebody is looking ahead in the
slides uh so you know we didn't control
for how people were hydrated I won't
expect that change much I would actually
expect the humidity in the room to
matter more and then how well hydrated
you are mostly because the frequencies
were looking at the body is pretty much
a conductor at you know 60 Hertz or so
all right any other questions all right
well so let me show you a real-time
implementation of this so here's a video
I'm going to perform a gesture and the
TV will then show you which gesture I
perform so unlike connect it's not
building the skeletal model in real time
there's actually 12 pre-recorded stick
figure videos in here it's going through
the whole process that i told you in
determining which of these 12 gestures
i'm performing so i went to this
location did each gesture once as
training and then film this video so as
you can see there's you know no
instrumentation on the environment and
just this simple training now one of the
interesting things about this is we can
get away from some of the problems that
existing camera systems have so for
example i can turn around as i'm about
to do perform the same gesture and it
will still work because we don't
actually have this occlusion problem
yeah first you're wearing into
that are on you when he talked about how
like battery power was one of the
problems with sensing I don't see any
wires so I assume that that's battery
power so does this have that scene
shoulder challenge so I've never heard
someone called a purse but let me let me
explain what's in the what's in the
shoulder bag so so what's in the
shoulder bag is basic so you can
actually someone mentioned there's a
wire so there's actually a wire going to
the back of my neck so I need contact
with the body here I'm making contact
with the back of the neck it doesn't
need to be the back of neck we really
wanted a location that isn't going to
move around as I do gestures there's no
compounds but it could be on your wrist
as well or anywhere else in the bag is
basically just an analog-digital
converter so digitizing the signal
that's on the body and then there's a
wireless transmitter sending it off to
our server it doesn't need to be a large
bag you could simply you know reduce
this into like a small wrist watch form
factor power consumption could be a
problem depending on how quickly you're
sampling and if you're sending a
wireless signal so in this project I
wasn't concerned with power consumption
I'm about to show you unlike the next
slide what you can do a power
consumption though yeah well can you not
in terms of the device size that it
shows of the gesture these are all
really large body movements can you
he detects a wave gesture so I think the
real issue is is basically the noise in
the environment so you could train the
system with like small finger movements
and I will probably work for some time
but as the noise changes that will stop
working and so it's really a question of
what's the variability in the noise and
not necessarily you know how fine grain
the gestures can be if that makes sense
so yes I think you can you can train a
classifier that will work with like some
very small gestures but it won't work
very long if you want it to work
robustly over time you need to use
larger gestures and actually while we
have this i think you know an
interesting way of making this actually
you know realizable is you combine this
with a vision based system where you
actually stand in front of connect and
use that as your training you know you
perform some actions in front of kinect
you train the system and then you can
walk away and the system can keep
working perhaps now because there's
drift over time you might have to
periodically walk in front of your
connect again to update the model but I
can imagine some like that working but I
do consider it practically to be more
you know I think you could do waves like
we actually had waves in our gesture set
but I don't know if you can do like
finger move motion yeah you'll head of
joys that you would consider just
plugging in the wall exactly so um so
you know one of the one of the goals
here was what can we do with ambient
noise but you know if you really want to
make this work and you're willing to put
one thing in your wall what would that
noise starts look like and we haven't
really explored that but you can
definitely do a lot better if you
control the noise and one of the things
you can do is actually get around some
of the issues that we have right now
with you know what happens when someone
turns on a light well if you're making
your noise and you don't worry about
that so that's an interesting thing to
explore yeah we're on carpet is
service so it does matter what your
grounding is and this matters you know
what shoes you're wearing and to some
degree what the surface you're standing
on is so yeah that does matter because
it's going to affect you know the
amplitude of the voltages on your body
for example yeah also ratings that
you've mentioned power several times it
didn't work how you came open for energy
and distort our Z salt is all about
movement right so I haven't done Network
there's actually been a lot of that work
in the community looking at how do you
harvest kind of energy from the motion
of people and it you know obviously
depends on where on the body you want to
harvest this so the feet are actually
really good you know there's actually a
lot of energy that can be harvested from
your feet other things don't actually
move that much it turns out people are
learning this when they have fitbit's on
now they actually sit around most the
day unfortunately all right so I move on
all right so the one thing I skipped was
you know I said when the user moves
there's this voltage the DV its way from
zero and i said i'll ignore why that's
happening but let me actually talk about
why that's happening so it's actually
not obvious and i spent about six to
eight months trying to figure out what
was going on there and what it turns out
is that this is caused by the static
electric field between your body in the
environment and this voltage happens as
you move and change the static electric
field so turns out this is useful for
more than just segmentation for human
tena and it actually spawned a whole
nother research project around static
electric field sensing and the real
advantage of this is that it's ultra low
power and enables whole body motion
sensing so before I talk about what it
means to do static electric field
sensing let me talk about traditional
electric field or capacitive sensing so
this is something that's been done for
many years in the HDI community and the
idea is you actively produce a time
varying electric field and then sense
how that field changes as a function of
user activity and this is what's done in
you know the mid-90s with a single
frequency more recently it's been done
with swept frequencies but all of this
work
you have to actively produce a time
variant electric field and then sense
how that field changes static field
sensing is different and that you
passively sense the existing static or
DC electric field that already exists
between our body in the environment so
I'll try to explain this with this field
diagram here so these red lines
represent the electric field the closer
the lines are together the strong of the
field so its strongest the feet because
you're really close to the ground and I
represent the environment around the
user as ground so if I put a sensor on
the user's wrist there's two new
electric fields here there's one between
this local ground plane that's on the
sensor and the body and between at local
ground plane in the environment so I can
represent this with a simple three
capacitor model represent the capacitive
coupling between all these nodes so
there's the capacitive coupling between
the body and this local ground plane
between local ground playing the
environment and between the body in the
environment now if I measure the voltage
between the body and local ground plane
I can see that it's a function of the
charge on both sides as well as the
capacitive coupling on both sides to the
environment now this is interesting
because if the user for example lift
their leg they're going to change that
capacitive coupling which is this
parameter CB and therefore this voltage
will change so essentially there's
changes in this voltage whenever the
user moves and so this is a really easy
way a low-power way of sensing whole
body motion and kind of be nice thing
about this is the hardware is quite
simple and therefore can be made very
low power so we need contact to the body
some gain stage and then a low-pass
filter now the reason we have a low-pass
filter is because we know from human
tena that there's signals at 60 Hertz
and all the harmonics we want to filter
all that out we're only really
interested in this very low frequency
signal less than about 10 Hertz and so I
built this into a wristwatch form factor
which I can pass this one around and you
know we began to explore like how how is
this useful and so I'm going to show you
a video in which we actually compared to
an accelerometer and give you data
that's very similar to that
seller ometer so in the background here
you're going to see the top trace is the
output of the static electric field
sensor and the bottom three traces are
the three axes that make seller ometer
and when you'll notice is as I move my
wrist you see the sinusoidal wave
pattern on both the static electric
field sensor as well as the
accelerometer traces so it can't give
you the fidelity of data the next seller
ometer can and that it can't tell you
you know your motion and three axes it
can't give this in real units of
acceleration but it can give you some of
the same kinds of data about how much
you're moving and maybe where you're
moving and so one of the real advantages
why you might use this over an
accelerometer is power consumption so
this is plotted on a log scale and
you'll see that the static field sensing
device is actually about two orders of
magnitude or a hundred times lower power
and some of the best commercial
accelerometers for this application of
sensing human body motion and it's even
an order of magnitude lower power than
the best research accelerometers right
now and what's even more impressive is
that this was built just using
off-the-shelf discrete analog components
if you were to make an integrated
circuit like it's done for these
accelerometers you could bring that
power consumption down another two to
three orders of magnitude yeah I see all
your demos are in front of the big TV
rate and in environments where there are
you know likely to be strong electric
fields you go off into the middle of a
wet field barefoot ready you think this
work I did just that I went into I
wasn't barefoot I guess but it was a wet
field it's 60 acres over in redmond i
went to the middle of the field and
there's no power lines anywhere around
you don't see 60 hertz there you're far
enough from power lines but you do still
see the static electric field sensing
signal so basically this is happening
because your body and the environment
are some different potential so there's
going to be some field and you're just
sensing changes in that field so it will
actually work regardless of the
environment I also did some interesting
experiments you know in screen rooms and
anechoic chambers and trying to suspend
myself from the air doesn't he has
videos of me hanging from the ceiling
you know trying to test you know what
matters is your grounding is it you know
the environment and it actually doesn't
matter it's always there so barefoot
will change things and that'll change
the amplitude right if you're still
going to be at slightly different
potential if you would truly have you
know an ohmic contact a ground then yes
you won't see much that's a little
difficult to produce but yet the
amplitudes are significantly less if
you're barefoot then if you're have
shoes on as you'd expect yeah misleading
so when you integrate into a sensor it's
not the accelerometer or these sensors
that dominates the energy consumption
right is the radiative the
everything else so optimizing this part
to like three order of magnitude cheaper
we not give you much to the end device
benefit so it depends on the application
actually in a few slides show you a use
case where this actually has an
advantage so you can ask again in a few
slides Peter if you're still confused
Elaine move on so one of the other
advantages in addition to giving data
that's similar to an accelerometer is it
can also give you data the next letter
armor just can't so for example if you
wanted to use an accelerometer to
measure not just how much my arm is
moving but how much each limb is moving
right now you'd have to use a number of
accelerometers and this can be you know
rather cumbersome so with the static
electric field sensor you can actually
do this from a single device so here I'm
going to show you another video and I'm
going to hold my arm steady but move my
legs so of course my arm is held steady
so you'll notice this accelerometer sees
nothing the static lotion field center
still sees a strong signal because I'm
still going to change the capacitive
coupling between my body in the
environment and to answer your question
the reason this might be useful is
actually to use it in combination with
other sensors like accelerometers that
people have begun using for activity
recognition and to use it for ultra-low
power wake up so you can imagine you're
using your accelerometers for some
application activity recognition or
whatever and you want to turn them off
to save power when the user is not
moving but you don't know what in turn
them back on and so you could use this
sensor and do the threshold and hardware
with two comparators and this whole
thing to generate this wake-up signal
and this whole thing consumes only 6.6
microwatts so about the same power as a
microcontroller in sleep yeah for
comparison again with the static fields
do you always require the machine
learning and training session and credit
understand lets me know so I actually
haven't talked all on this project about
machine learning so I'm not I are
actually don't have this in the slides
but i actually did say alright if we're
going to use machine learning can we
classify different types of activity and
you can you know course different types
of activities so you know no motion
verse maybe hand and finger motion or
arm motion then whole body motion like
walking and you can do that with machine
learning relatively simply what I was
saying is you can actually forget about
the machine learning you can actually
use this as you know for some of the
same applications you know people are
using the Fitbit and Nike FuelBand just
as a pedometer and you can do that here
without machine learning yeah oh no okay
all right all right so let's move on so
I've talked about some of these on body
applications in which i'm going to
leverage the conductive properties of
the body in order to either reduce the
number of sensors required to enable
human computer interaction or to reduce
power consumption and now let me talk
about some off body sensing in which
instead of leveraging the conductive
properties of the body i'm going to
leverage the existing infrastructure in
the environment and i'm first going to
talk about a project called gas sense
which is actually the first thing i did
in grad school and the point of gas
sense was to measure the gas consumption
at the device level so this is in your
home all your appliances that consume
gas which ones are consuming gas and how
much gas are they consuming now the
reason you might care about gas
consumption is is actually guessing
sometimes quite important so there's
been a big focus lately on electricity
monitoring and people have developed
ways of doing this kind of disaggregated
sensing for electricity but it turns out
that if you actually look at the average
home the majority of the energy is
consumed in natural gas and not an
electricity so just like electricity we
want to get gas consumption at this
device level so just like the
human-computer interaction work there
are direct sensing ways of doing this
you could actually put an inline gas
sensor
on each of your appliances the consumed
gas there's a few problems with this if
you have a lot of appliances it could be
difficult to install these but the real
issue is we want something at the end
user can install and you can't have the
end user running around their house
cutting into gas lines it's really just
not safe and so we need to find a more
indirect way of sensing this and so
we're going to utilize the existing
infrastructure take advantage of the
fact that all these gas appliances are
connected to each other on this gas line
so if we sense something about the gas
line we can figure out what's going on
at the endpoints now we still have this
problem that we can't just cut into the
gas main that's even more dangerous so
we needed again take an indirect sensing
approach and so the approach is to
actually look at your gas meter so if
you ever walked around the side of your
house and walked by the gas meter you
may notice that it makes a sound
residential one makes a hissing sound
and a commercial one makes somewhat of a
low roar and so I realized there was a
sound I studied what was going on so it
turns out the sound is produced by this
disk here that's your gas regulator and
let me describe briefly how it works so
here's a cutaway of the regulator so gas
flows through this pipe and as it does a
sound is produced by this large resonant
chamber so this is similar to blowing
through a whistle as you blow air across
the top of a whistle a sound is produced
by that resonant chamber below and
what's nice about this is the amplitude
of the tome that's produced is a
function of the flow of gas it's
actually a linear function of the flow
of gas and so we can pretty easily sense
this simply by putting a microphone
outside the gas regulator so similar to
some my other work I'm gonna go through
this pretty quickly you know this is a
noisy signal when you can need to use
some signal processing to figure out to
pull up the signal we want so this is a
spectrogram with frequency on the y-axis
time on the x-axis and the color encodes
the amplitude of the audio data you'll
notice there's lots of noise sources
here so we have cars driving by wind
noise even an airplane flying overhead
and we care about is just the signal
right here that's produced by the
regulator when gas flows
so we can you know filter some of the
signal out and then apply some machine
learning again to determine when each
gas appliance turns on and off and we
actually show that you can do this about
ninety-five percent accuracy to
determine which gas appliances are being
turned on and off at what times so I
went through this really quickly because
it's using a lot of the same signal
processing and machine learning
techniques that I used with human tena
but the idea is that instead of
leveraging the conductive properties the
body we're going to leverage the
existing infrastructure in the home in
order to enable in this case
disaggregated gas consumption now this
technique is is quite nice and that we
can you know get a lot of information
about what's going on in the gas
infrastructure by putting a single
sensor somewhere on the infrastructure
the problem is we can't always rely on
this technique but that for everything
we want a sense in the home we can't
always take advantage of existing
infrastructure so sometimes we actually
have to put sensors everywhere use
what's called distributed sensing and
for this people typically use wireless
sensor networks so imagine for example
you want to know the temperature in
every room across your house so the best
way to do this is to put a temperature
sensor in each room across your house so
let's say this is your house and you're
going to put these sensors all over the
place so you'll typically make these
things wireless and have them
communicate their data back to the space
station receiver now people do this
because it's really easy to deploy you
put the sensors out there you turn them
on the system works the problem is it's
really hard to maintain and the reason
it's hard to maintain is because all of
these wireless sensor nodes have
batteries and for any decent size
deployment the vast majority of time and
resources are spent replacing batteries
so we really want to you know reduce the
power consumption so these batteries
last longer unfortunate there's this
well-known trade-off between the power
consumption and the range of a wireless
system so imagine this is your home and
you put the space station receiver in
the center of the home and you're going
to put a sensor node in this corner
bedroom here so you can turn on at high
power the signal will make it to the
base station but you're
battery won't last very long if you want
your battery to last longer you can turn
down the power consumption and now your
battery will last a lot longer but the
signal won't make it all the way to the
receiver so your network is broken so
there's this trade-off between power
consumption and range and so you know
any wireless sensor network kind of
tries to find a sweet spot in this in
this trade-off so I'm going to present a
project called Snoopy which actually
finds a workaround that doesn't have to
deal with this trade-off between range
and power and Snoopy's action acronym
which stands for sensor network
utilizing powerline infrastructure and
it's an ultra-low power general-purpose
wireless sensor network and unlike
existing wireless sensor networks and
similar to some of my previous work it
actually utilizes the powerline
infrastructure not the gas lines in this
case but the power lines and it uses a
technique called powerline coupling in
which the receiver is actually plugged
directly into your wall into the power
lines and uses the power line
infrastructure as a giant receiving
antenna and so your your sensors your
wireless sensor nodes can still be
Wireless and you can put them anywhere
but instead of sending their data
wirelessly over the air all the way to
the base station receiver they
wirelessly couple to the nearest
powerline and the signal moves through
the power line to the receiver so let me
show this graphically so again we're
going to put this base station receiver
in the center of the home but no longer
has those two little antennas on top now
we're going to plug it into the
powerline infrastructure and use all the
power lines in the home is a giant
receiving antenna so again if we put
this sensor node in the corner bedroom
we can turn it on at very low power not
nearly enough power to reach all the way
over the air to the base station but
enough powered a couple its signal onto
the wireless infrastructure and the
signal will move through the power lines
to the receiver so in this way you can
put sensor nodes all over the home and
have them all communicate to this base
station in this star network topology
now the reason you might do this
is that you know you still get whole
building range because power lines go
everywhere in the building but you can
dramatically reduce the power
consumption at each sensor node because
it's wireless range is now much shorter
so here I'm doing a comparison between
the first research version of snoopy and
existing sensor nodes including zigbee
and Bluetooth nodes and again this is on
a log scale and the first thing that you
notice is that the total power
consumption of the snoopy system is
about an order of magnitude lower power
and the existing nodes what's even more
interesting is that the communication
power the power consumed by the radio is
about two orders of magnitude lower
power than existing sensor nodes and one
of the reasons for this is that we're
using this power line coupling technique
but the other reason is that we're
taking advantage of an asymmetric
network so these sensor nodes are
transmitted only they can't receive and
so we can push all the complexity of the
network to the receive side and this way
we can produce simple low-cost and
ultra-low power sensor nodes at the
expense of a single complex base station
receiver now there's a number of
advantages of this in terms of power and
simplicity but also number of
disadvantages in terms of the
reliability and robustness in the
network so one there's no receiver on
the node but this means we can't get
acknowledgments a node will never know
if the data has made it to the receiver
there's also no coordination between the
nodes so no synchronization no
scheduling no routing but also if the
data doesn't make it it can't
automatically retransmit because it
doesn't know the data didn't make it on
the plus side there's no overhead to do
all this coordination but there's two
big problems here one is that we don't
know that our data makes it to base
station and if it doesn't make it we
don't know to retransmit so to address
this we use multiple retransmissions for
important data so if the data is
important that it makes it will transmit
at multiple times and we'll use forward
error correction again to increase the
probability of the data makes it so
we'll never know for sure the data has
arrived at the receiver but we can
actually achieve an arbitrary level of
reliability yes
physical proof now using this power line
coupling channel also has has a number
of advantages in that it's actually very
complementary to existing wireless
systems so you know an existing
over-the-air wireless system actually
works best in an open field where
there's nothing around to attenuate the
signal in an indoor setting this means
it works best in the center of a large
room this is actually the location that
Snoopy works the worst because it's
farthest from power lines but if you
take a scenario where you want to put a
sensor for example under a large
appliance like refrigerator or maybe
even inside the refrigerator
over-the-air wireless systems don't work
very well because they're inside a metal
box or underneath the metal box this is
actually the location that Snoopy works
the best because it's right next to a
large appliance that's plugged into the
power line so in that way they're very
complementary but this new power line
coupling channel is is unexplored so
there's a lot of questions that come up
in terms of how do you design and build
a system that works in this way that's
partially wireless and partially using
the power line as a transmission line so
my thesis is focused a lot on trying to
explore this channel so I did a lot of
background noise and interference
measurements around homes around Seattle
actually I didn't bug you guys about
this but these are other people I know
in Seattle and did a lot of path loss
measurements and homes as well and
although this is relatively
back-breaking work crawling around
underneath people's sinks and putting
sensors it was actually very useful in
trying to understand the system in terms
of the frequency bandwidth and so on
that you can use this network so I'm
going to go through some of these really
quickly first there's the frequency of
operation the this powerline coupling
actually works best in the HF band so
between 33 and 30 megahertz this is a
wavelength of 10 to 100 meters and the
reason for this is because in this
frequency band the size of the powerline
infrastructure is actually roughly an
efficient antenna so it's in this band
that the power lines more efficiently
pick up or you know receive these this
coupling signal from the nodes also in
this band
power lines don't attenuate the signal
very much they work well as a
transmission line now operating in this
32 30 megahertz band has a number of
limitations in terms of bandwidth so if
you look at the unlicensed is M bands
that Snoopy can use we have only about
10 to 100 kilohertz of bandwidth
compared to the tens to hundreds of
megahertz of bandwidth that traditional
wireless systems have now this means is
we can't divide our channel into
sub-channels so all the sensors share
the same channel and again they don't
have receivers on them so they can only
transmit so we have to use pure Aloha
where each sensor just sends data as
soon as they have it what this means is
collisions can happen so in order to
minimize the probability that collisions
will happen we want to keep the transmit
time as short as possible so each node
is occupying the channel as little as
possible we also need to vary the time
between transmissions so since a lot of
these things happen on a schedule we
don't want a number of sensor nodes to
end up on the same schedule and always
collide and then like I said before we
can use multiple retransmissions to
increase the probability that important
data gets through and use forward error
correction again increase the
probability that data can be recovered
if there is noise for example now
another challenge is the antenna design
because we're operating in this 32 30
megahertz range you know an efficient
antenna is on the order of 10 to 100
meters in size so when if you want to
make a device that's this big you're not
going to have a very efficient antenna
and so I did a lot of work trying to
make as efficient as we can a small
electrically small antenna and so I
actually built an engine that actually
estimates the antenna parameters using
Ultraman X theory and then you can
actually solve a constrained
optimization problem for a certain size
and shape of the node and it will tell
you what's the most ideal antenna either
with wire wrapped antennas or PCB
antennas and the last oh so then the
next thing is actually the transmitter
itself so because we're really
interested in making this as low power
as possible
to optimize the power consumption of the
transmitter so we actually partnered
with an integrated circuit lab an analog
integrated circuit lab at u-dub to
produce this custom integrated circuit
and the advantage here of doing this in
full custom analog is that we can reduce
the stray capacitance and therefore
reduce the power consumption and so we
could actually achieve whole home range
with this sensor network while consuming
only 65 microwatts of power while
transmitting so this is this is that two
orders of magnitude lower power than
some of the existing sensor networks now
the last the last challenge here is in
terms of the receiver design and this
forward error correction and this
depends a lot on the channel itself so
because we're using the power line as
this receiving antenna we actually have
some challenges in terms of the receiver
design and that is this antenna was not
designed to be an antenna and it
actually changes over time so as people
you know flip on light switches and
things the impedance the power line
changes there's all kinds of noise
sources on the power line because of
appliances that we need to deal with and
this really affects the forward error
correction so we want to develop forward
error correction that works well in this
noisy environment which is not a
traditional you know additive white
Gaussian noise or even rayleigh fading
channel you actually have you know power
bricks that are producing noise
synchronous to 60 Hertz the noise floor
changes largely all the time because of
appliances and trying to produce air
crashing codes that can handle this and
make the system robust has been another
focus of my thesis now once we
understand all these things the next
question is what are the applications of
snoopy well first we need to consider
the limitations so for one there's it
requires power lines so this is not the
sensor network to deploy in the Amazon I
won't work it really needs to work
indoors so it's best for home and
commercial applications but like I said
before that what's nice is this is
actually a problem domain for
traditional wireless sensor networks so
walls you know traditionally attenuate
wireless signals and so they're
typically a problem and our case walls
are good because within the walls or
those power lines that we need for
network the other limitation is a low
bandwidth I talked about before because
it's low bandwidth this is not the
sensor network to use for streaming
media you know audio or video it's
really for event detection and low rate
monitoring and in this application
domain we can actually achieve greater
than 10 year battery life in fact that
ten-year figure is the limitation of
coin cell battery so the shelf life of a
coin cell battery is about 10 years so
we the battery will actually corrode
before we pulled all the energy out of
it now because this works best for you
know these low rate indoor applications
it's really best for in home monitoring
so home environmental sensing smart home
applications and home security well you
can use these low power simple centres
like temperature humidity moisture and
so on to get an idea of what's happening
inside the home so you know to enable
these applications you know some of my
co inventors and i created this startup
company snoopy technologies in which we
actually released our first product
wally home about three or four weeks ago
now and so one of the nice things about
this company for the research point of
view is the large data set that we have
achieved so now we've deployed these
things all over the US this is not a map
of where we were deployed snoopy this is
actually just what it looks like base
but we put them all over the US we now
have several hundred systems out there
and we've actually gotten a lot more
data about what this noise looks like on
the power lines and homes all over the
place and it's really informed a lot of
the design and in terms of how do we
deal with this noise that we couldn't
see in the ten homes we tried in Seattle
so you know in summary Snoopy is this
ultra low-power wireless sensor network
let me actually pass around two of these
so this is this is the original research
version of Snoopy this is the
commercialized wally sensor known i also
have one of those Wally's that you can
take apart you can come up afterward
play with that if you want there's also
the receiver but it's not packaged you
can look at that too
alright so I've talked a little bit
about you know some of my work and with
on both on and off body sensing but
looking forward I want to continue to
you know identify these new
opportunities for sensing build new
embed sensor systems then apply the
sensing systems new domains and in
particular I become very interested
recently in a slightly different domain
of on body sensing and that is the
domain of health and wellness so this is
work that I did here last summer on
continuous non-invasive hydration
sensing which doesn't he captured my
excitement about hydration with this
wonderful picture here on my last day of
my internship last year and the reason I
become really interested in hydration
sensing lately is because there was a
study last summer which actually showed
that seventy five percent of Americans
are chronically dehydrated and this is
actually quite a shocking number and
what's even more surprising is if you
actually look at the symptoms of chronic
dehydration the symptoms are things like
allergies low energy depression hunger
and digestive problems and so you know
these things are often masked as other
things but it often is caused by chronic
dehydration and one of the things that
people don't understand is that a lot of
the beverages they consumed throughout
the day actually dehydrate them more so
things that are loaded with caffeine
sugar and alcohol actually have a
dehydrating effect so obviously be very
useful to have a device that monitors
hydration the problem is right now the
best way to do this is blood tests or
urine tests this is both invasive and
cannot be done continuously you could
also imagine you know tracking flow so
they actually make these water bottles
that tell you how much water you've been
drinking the problem is to accurately
monitor hydration you need not just in
flow but also outflow and this is
actually quite difficult because there's
a number of ways in which our bodies
lose fluid throughout the day so it
would be very useful to have a sensor
which continuously and noninvasively
monitors hydration so similar to some of
my other work on body I'm going to take
advantage of the fact that the body is a
conductor and use that to sense
hydration so the approach I'm taking is
using bioimpedance now
is this a sign that's been done in
clinical practice for quite some time
but for a different application for
actually monitoring body composition so
you can actually buy a scale now that
tells you not only how much you weigh
but what percent body fat you have and
if you look at the clinical studies
using this bio impedance analysis they
say it works fairly well for this
assuming constant hydration and so my
hypothesis is that if we instead of
looking or taking these measurements you
know daily or a few times a month's we
actually look on a time scale of minutes
to hours and changes in bioimpedance
should be a function of changes in
hydration rather than changes in body
composition so in order to test this I
built this large circuit which does this
bio impedance spectroscopy to monitor
hydration throughout the day and we've
started doing some studies this is my
internship last year where I would
continuously monitor my bio and penis
throughout the day while very closely
monitoring my hydration as well and you
know this is ongoing work so I don't
have any exciting results yet but you
know the idea is that we could make like
a wrist-worn device like an armband that
can continuously monitor hydration just
for average consumers to get an idea of
how much howdy hydrated they are we've
also talked to some physicians about
using this during surgery to monitor
hydration or something they're very
worried about during surgery and right
now they basically guess and I think
would also be very useful for medical
researchers to study chronic dehydration
so that seventy-five percent of
Americans number is actually somewhat
debated because they can't really
measure chronic dehydration so with the
device like this people could actually
study chronic dehydration and learn you
know what are the effects of this so you
know in addition to monitoring a
hydration I want to continue to work in
this space of continuous non-invasive
health sensing but I also plan on
working on other applications of abetted
sensor systems including technologies
for accessibility and improving health
care in the developing world so by
continuing to identify build and apply
some new embedded
sir systems we can reduce these current
adoption barriers and hopefully truly
bring ubicomp to life and again this
requires not only doing more research in
each of these subdomains but doing
multidisciplinary research that crosses
the traditional boundaries between the
human interface the sensing the
computation and the communications and I
hope to be able to collaborate closely
with the experts sitting in this room as
I've done for the last several years to
help develop these sensing technologies
of the future so I'm going to thank
everyone I've worked with many of which
are here over the past few years on
these projects and open it up if you
guys have any other questions Thanks
smartwatch in my office that does
hydration sensing but frankly I don't
think it does it very well like it's
just measuring
brightest and ice skaters obsessed can
you comment on sort of how pad for it
yeah so so what I'm doing is a little
different I'm not actually looking at
the skin hydration so by doing this by
ohm impedance analysis and at the moment
anyway across a larger area of the arm
or actually looking at the hydration
inside the arm and the other thing I'm
doing is instead of looking at a single
frequency by doing this bio impedance
spectroscopy and looking across
frequencies we can actually tease apart
the difference between intercellular
fluid and extracellular fluid so it
turns out as you might know hydration is
actually rather complicated there's no
you know medical dehydration we really
care about is the fluid in a number of
different compartments inside the body
as well as the sodium of potassium
concentrations and by doing this
continuous monitoring of both inner
siler and extracellular fluid we can
also see the shifts in the fluid between
those compartments which can give us
some idea of those ion concentrations as
well so I think with with such a device
you could actually get a lot more you
know medical relevant data about
dehydration as always the time it takes
replenishing and it's showing up some
distance exactly so she left leg and I
think that's also something that it
would be kind of interesting for the
average everyday consumer to understand
you know like when I drink how long is
it take before my body actually gets
that hydration yeah horse awesome
applications of embedded sensors to
I just wanted to expand a little yes so
I mean if you look at kind of a CI
community in general right now we've
done a lot of interesting work on you
know using you know hands-free
interfaces and things like that and you
know I think it'd be really interesting
to take a lot of these technology we've
developed for HCI and move them into the
accessibility room where you know the
the problem is a little different
dealing with errors is a lot more
difficult and you know trying to
actually take a lot of this new research
and produce devices that can actually
help an accessibility so I haven't done
you know too much kind of diving into
that yet but I kind of see there's this
big potential there to enable a lot of
technology for accessibility to be motor
your picture showed real yeah it could I
mean could be it could be vision as well
I mean there's been a lot of work you
know in the community on ice for
interfaces and so can some of those be
applied to accessibility is one big
question and you know the design
constraints are different with blind
users
yeah the microwave power that was you
were at sauber stimulus list the Benwick
we're talking about so rough David
ceiling at peace isn't only 50 megawatts
it right so the the bandwidth it depends
on you know you're partially limited
legally buy you know unlicensed bands
but if you kind of ignore that I would
say it's around 100 kilohertz 200
kilohertz hundreds of kilohertz
basically it's like roughly you you uh
full ones it but you know I'm to show
you a list of the kingdom you can move
over the wire you know what I mean like
um you're then I think yeah you can move
a string every minute so I think you're
gonna be more I'd say on the order of
you know one kilobit per second but if
you were to do that so the part of the
problem is the medicine how many sensor
nodes you have right so you can maybe
have one that's doing that continuously
but if you have 10 of them maybe you get
a tenth of that rate for the network
oh how effectively is your power line
working with the jump between phases
residential hold it as two phases in
commercials of history so one of the
nice things about the hf band 3 230
megahertz that actually couples quite
well so 3 doesn't couple quite swell but
basically above 10 megahertz couples
very well across the phases so that's
actually not a prom so a lot of the you
know existing work on power line
communication had that problem initially
like x10 for example and they were using
125 kilohertz so that was their problem
that the newer systems like in some of
the new instance systems actually use
the same band 3 230 megahertz and they
don't have that problem anymore
would it be putting XP on scooby-doo so
so you know I mentioned the Ford error
correction and and I'll you know because
we're making a commercial product one a
lot of the challenge is how do we make
it work with insteon with these existing
systems and it does work actually quite
well alongside that there are is more
packet loss but we handle it yeah I mean
yo I I remember as a kid you know using
X 10 devices in my house to control my
neighbor's house well in a home it
doesn't go very far because it typically
doesn't make it through the meter
there's enough inductance typically in a
meter that it doesn't couple across it
certainly even if it does go through the
meter it won't make it across the pole
top transformer in you know an apartment
building or a condo then yes it will
your neighbors will see your signals as
well so when you calculate your
bandwidth then you have to take into
account all you in there they're part of
the same network yeah exactly
going once
good boys
thank you so I have</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>