<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introduction to large-scale optimization - Part1 | Coder Coacher - Coaching Coders</title><meta content="Introduction to large-scale optimization - Part1 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Introduction to large-scale optimization - Part1</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AYcfpq5hH5g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so it's a great pleasure to introduce
servlet Sarita he is a faculty member at
MIT right now and before this he had a
couple of small short stints at CMU and
Berkeley and before that he was at he
was a research staff member at the MPA
of England and before that he did his
PhD at UT Austin within the U tilde and
okay thanks pratik for the introduction
and thanks to all the organizers for
inviting me first time I am I have now
the pleasure to be at ISC Bangalore
really nice to be here and I'm going to
talk about the first lecture that I'm
going to talk about we'll cover more
fundamentals related to this is
basically to establish some of the
notation that we will show we'll see
again in the second lecture related to
large scale optimization so the first
lecture is just giving some concrete
background many of the things may be
familiar to several people in the
audience so just bear with me there is
repetition of knowledge some many of the
things may not be familiar to however
everybody so I'd like to first spend
some time establishing that background
knowledge and then later it could easily
happen right now because of some
miscalculation in my mind that my
lecture instead of ending at exactly
12:30 I may have to spend 10 to 15 extra
minutes but hope hopefully not more than
that but I'm warning you in advance in
case you know you had urgent lunch plans
or something so the course material I
will put apart from the summer school
website they will have links to all the
material I will put the course material
related to my lectures on that website
that URL is not yet functioning but all
this
material will show up there and these
are hyperlinks you can click them in the
PDF and some of the standard reference
books and the full semester long courses
based on from which this material has
been derived they are linked here the
lecture slides and material there is
much more detailed in case you want to
look at related material so essentially
this is my only slide where I list
explicit references I am NOT going to
have a list of references at the end of
my lecture slides anywhere so you may
want to sure interested visit this these
URLs and check out the recommended books
and papers and other things on this
topic there's a lot of information there
and the kind of things I'm going to talk
about they lie many of these things lie
at the foundation of optimization
related work published at the top
machine learning conferences so I just
listed some of the venues this is not
all-inclusive like I have say for
example forgot to write kdd in there and
so on but these are some of the venues
where the material that I'm talking
about today if you are interested in
what's the cutting edge of research
related to the material that I'm talking
about today you will find many of those
related papers in these venues so that's
kind of the background so the plan for
today is the first lecture is mostly a
super-fast kind of recap on some basics
of convexity and convex optimization and
those basics are important so that later
I can just use them without having to
explain them and after we've gone
through those so the red thing is what
I'm going to talk right now and some of
it may hopefully I know it doesn't
overflow more than 15 minutes then
because of that there might be slightly
more material in the slides then I'm
going to fully speak about but I decided
to leave that material in the
for the people who like to look back at
the slides for reference so the slides
are sort of they have all the
information there for you
and later I'll move on to first order
optimization methods proximal methods
etc those are the first our first brush
with simple large-scale optimization
methods but still not totally
large-scale and tomorrow I will talk
about the currently popular truly
large-scale optimization methods with
leading on to maybe a lament to speak
some words about methods that then also
work in parallel and distributed
settings if I get time unfortunately
there is not enough time to talk about
everything I will try to tell you about
some some words on non convex
optimization so the bulk of the material
I'm talking about is focused on convex
optimization but that's because it's
easier and more convenient to get some
deeper theoretical understanding of the
material but algorithmically the
algorithms that you'll see they are not
limited to work in the convex setting
you can also apply them to more general
problems and people do that for example
in the current popular deep learning
business the kinds of optimization
techniques that I'm going to talk about
now
very similar techniques are the ones
that have been programmed for those
things and of course the interesting
theoretical interesting thing is many of
the theorems and proofs that we see
today and tomorrow can we have similar
or related theoretical understanding for
those more difficult problems a special
important case of such convex from non
convex problems where you do have
theoretical proof so pratik has already
covered there but worst of a rich world
of problems so okay let's that was
basically the introduction so let's dive
straight into recalling some basic
concepts and feel free to ask me a
question in between but it may also
be even better for you if you really
interested in the details to catch me
later maybe during the lunch break if
you want to talk about more details so
super fast I'll go through some basics
of convex analysis and some other
concepts that come up moving from convex
analysis to convex optimization so this
is just the mathematical background so
we begin with concept of a convex set
convex set and we are going to limit our
attention to convex sets in Euclidean
space so just in vector space are to the
end and they're essentially a convex set
is a set which contains all these line
segments and that's just what the
picture is saying that's the formal
definition but if x and y are in the set
and the line segment between x and y is
also in that set interestingly is this
the standard definition an interesting
thing to know is that convexity maybe
people thought about it as a
generalization to the idea of linear
combinations because people started
looking at vectors and doing say linear
algebra with those objects and then when
you have vectors you take a linear
combination that you see in first-year
undergraduate when you study linear
algebra I take linear combination and
the scalars that which I combine the
vectors those scalars can be anything in
the base field which is real numbers if
I put additional restrictions on those
scalars the amount of algebraic power
gets reduced but somehow more refined
geometric structure appears which we can
try to talk about so if you put the
restriction that the scalars combining
coefficients are non-negative and add up
to 1 you get convex sets if you drop
this restriction that they have to add
up to 1 but you only require non
negativity that's called a conic
combination so just saying that I'm just
giving you predigested concepts but
if you wish to think about how these
concepts may have risen or how you could
generalize them if you wanted to if you
want to essentially think of whatever I
am talking telling you today if you wish
to approach it with the research
mentality that you want to break the
axioms and the rules with which we are
constructing this analysis and
optimization where are the important
things that you could change to discover
new structure but any of that's that's
just the spirit of it so I'll accelerate
soul and some very important theorems
related to convex set so we define what
is a convex set and starting with one
convex set you'd like to construct other
convex sets and already in advance I can
tell you the reason why we are
interested in studying convexity is that
it's easier sort of easier to solve
convex optimization problems and that's
the reason we like to understand
convexity further easier and practically
useful of course so this is a basic
theorem intersection of two convex sets
is convex and with this theorem you can
verify convexity of a vast number of
convex sets that you see in applications
just the simple theorem which you can
prove in one line I'll show you an
example of that
so these are some sets like the interval
or the line some kind of polygon or some
other polyhedron with in hyper planes or
a cone of positive definite matrices etc
there are some convex sets other
examples and during my talk there many
times you will see the word exercise so
at least for all the students in my
audience I encourage you to try to solve
that exercise on your own once you solve
that exercise on your own you'll
understand everything way better so I
marked out some interesting exercises
for you to try out in case you haven't
tried out before and I'll already give
you an answer
to say this one this is when you're
doing linear programming for example or
quadratic programming like in support
vector machines you have constraints of
this form linear inequalities and linear
equalities this set is convex as long as
you as soon as you've shown that a half
space is convex to show that just use
the definition what is this this is just
an intersection of lots of those half
spaces essentially and by the
intersection theorem that is convex
so already linear programming with such
constraints or falls within your ability
to analyze right so that theorem the
intersection theorem is by far one of
the most important distinguished classes
type of convex set is called a convex
cone it's just maybe I'll just draw it
for you here a convex set which
essentially it contains all of this so
it contains non-negative multiples of
all the vectors in the set okay here is
a challenge for those of you who think
convex sets are usually easy to
understand here is a challenge for the
more advanced listeners in the audience
a and B are symmetric and my n matrices
the couple of those real numbers
generated is a compact convex set so
it's a subset of the plane and to prove
that it's a compact convex set is
non-trivial exercise it has been subject
of several papers back in the day it's
just closed and bounded so just because
we are in finite dimensional space or
whatever just think it's closed closed
means it contains all its boundary
points and it is bounded
no see this interval well okay
see this interval zero to infinity it's
not upper bounded but okay it's not
closed either so
oh I'm just naming that set I will just
give that set a name
yeah I'm just I just want you to give
that set some name
so if you look at it all that said all
that does is it contains of numbers of
this form so that set contains
X transpose ax is a real number and X
transpose BX is also a real number so it
contains of pairs like that for all X as
X for all X that have in a product equal
to 1 so have an infinite number of such
X's you look at all possible pairs that
arise and the collection of all those
pairs is a convex set
ok anyhow this is a challenge problem
let's not spend time solving it right
now because but I encourage you to think
about it it's a very dis challenge
problem lies at the heart of a lot of
very important optimization problems so
once you have convex sets then the next
important concept for us is that of a
convex function convex functions are
defined over convex sets so essentially
for for us to really talk about a convex
function the domain should be a convex
set so that's why we started with the
convex set and this is on an interval we
just say our function is midpoint convex
if it satisfies this inequality so the
way I like to read this inequality is
function f at the arithmetic mean of x
and y is smaller than the arithmetic
mean of f at x and y that's why this is
called the arithmetic mean convexity and
more generally this is the definition
that not only with X plus y by 2 but
with all possible fractional
combinations you have that inequality
that's the more general definition of
convexity and if this this is usually
called Jensen's inequality and Jensen
proved in 1905 in his famous paper that
if function is continuous then it is
convex if and only if it is midpoint
convex so I wrote this version here
because many times if you are trying to
prove do by hand and
my convexity it's kind of turns out to
be easier to do that so I usually like
to just verify that and ensure
continuity and you're done so that's our
definition of convex functions and I'm
going to mostly give some examples of
some very interesting convex functions
that come up in convex optimization and
for the those of you who like to see
pictures here is a diagram of a convex
function which you may have seen before
convex function essentially that's the
arithmetic geometric arithmetic
inequality that at the line spanned by
the endpoints the function always lies
below the line that's one way to look at
it an alternative way which will
actually come back to after maybe 20
minutes is not through just definition
in terms of the value of f of X but in
terms of tangents at different points so
convex functions are curved upwards like
that so that at every point they have a
tangent so they are always bigger than
some linear function at every point I'll
make that more precise later on and
there's a third geometric view pictorial
view of convex functions which is also
useful so all these three are useful
when trying to verify convexity or think
about it so the third one is that for
convex functions the slopes increase
monotonically as you go from one end to
the other
so here PQ has this negative slope when
PR has higher slope and then QR has even
higher slope so think of slope as a
signed number right so the slope here
will be some so it just monotonically
increases as you move along this curve
so those are just three geometric views
of convex functions and monotonically
increasing slope for differentiable
functions is the same thing as second
derivative being non negative so that's
standard well-known way to verify
convexity so this is just a picture of
that
okay one of the most important ways of
constructing convex functions is this
theorem or this example because remember
the reason I am talking about convex
functions is because we will see later
or soon enough for many machine learning
problems or for many statistics problems
the problem of estimating or solving a
model involves solving a convex
optimization problem so we'd like to
understand these creatures and we said
okay we somehow talk about convex sets
but I challenge problem already shows
showed you that is not always trivial to
verify that a certain set is convex we
usually just construct them to be convex
similarly we define the convex function
but just because I defined the concept
of a convex function it won't help you
so much until you have access to a bunch
of tools that allow you to detect convex
functions and to construct them
numerically you can never guarantee that
a given function is convex because it's
numerically you cannot verify even
continuity right because computer works
with finite precision continuity is a
real number concept so we won't worry
about the numerical version but I've
given you a class of functions which I
claim is nice for optimization but any
nice class of functions that you
construct is nice only if we know how to
construct members of this class and this
is one of the most important ways to
construct members in that class is if
you have a function f which for each
fixed value of y so f is a function of
two variables I'll show you an example
of this soon enough if F is a function
of two variables for each fixed value of
y as a function of the remaining
variable X it is convex then you take
the maximum over all possible choices of
Y then that function remains convex
by hand verifying this is pretty direct
because all you have to do is just try
to verify the standard inequality so you
can just try to verify this and use use
the fact that this is the max so you
should be able to verify this pretty
quickly another thing is if you have a
function written in terms of some
vectors and if you make a linear
transformation linear transformations
are friends of convexity they don't ruin
convexity so these two things are kind
of very basic and very important and
pretty much the cover 50% of what we
need to know how to construct and VAX
functions for the purpose of these
lectures more non-trivial result is that
if you minimize function of two
variables even under minimization this
is a very nice property so minimization
is like eliminating some variables so if
you have a function of two variables and
it is convex in both variables and you
eliminate some by minimizing them out
then what remains is still convex and
I'm showing it slightly abstractly now
pretty soon you will see an application
a very simple application of this
powerful looking theorem so I the proof
is on the slides you don't have to worry
about it I'm just leaving it there for
future consumption when you refer to the
slides but it's a very important
property because what it means is if you
have a function of several variables and
it's convex in all variables you can
reduce the number of variables by
minimizing some of them out and maybe
the remaining and then working with the
remaining object so that's one of the
benefits of this that
doesn't destroy convexity but it's
crucial that it be the original thing
had better be convex in the pair
together otherwise this doesn't hold as
you may have seen from an alternating
minimization example that those things
are convex not in the pair just
individually so this is making us much
stronger assumption but giving a
stronger conclusion yeah yeah yeah
that's the so the previous one I wrote
with Max but actually it works with soup
yeah yeah wise arbitrary that's the
beauty so this thing as a function of Y
F can be crazy this one requires f to be
well behaved with both x and y so this
is a difference yeah
the first I'll show you a nice
application of this thing also we are
coming to that I'm looking at some
interesting convex functions so this
harmless looking or harmful depending on
your perspective looking function is one
of the nicest convex functions in my
opinion so this function allows us to
associate a natural membership function
for every convex set so you say that I
have an indicator function if for a
convex set this function outputs zero if
evaluated at something that lies inside
the set otherwise it outputs infinity so
the trying to minimize such a function
what does trying to minimize an
indicator function mean trying to
minimize an indicator function means
being able to pick one point in your
convex set any point will do so that
already shows you that convex
optimization problem can have infinite
number of solutions if your set has
infinite number of points in it which it
has to then minimizing this will any
feasible point will do but this is a
very important function here it's only
for the notations of henceforth please
I will use this notation few times and
this is a very important function okay
so here's an example of the infimum
theorem in action so if X is a convex
set so if so this is script X this is
the convex set you want to find distance
to that set so X happens to be some
point which lies outside your convex set
and you want to find the length how far
is this X from the convex set so the
value of this distance which as you can
geometrically see you will have to make
an orthogonal projection I will also
write that formally again the length of
this distance that is called the
distance function to a convex set that
distance function is convex proof the
proof follows by using the previous two
results X minus y is jointly convex in X
comma Y and if you want to see it super
explicitly X minus y so if your original
vector is Z is X Y then X minus y can be
obtained by multiplying it with this
matrix so this is a linear
transformation and we saw that under
linear transformations things remain
convex of course I formally didn't yet
prove that the notation of a norm is
convex but you can believe that
so it's jointly convex in x and y and
then that's and we are minimizing
simultaneously hence by our previous
theorem the distance function is convex
so this way to use that theorem it's a
very this is a very basic object that
pops up in convex optimization the I
should have shown this earlier but a
class of convex functions that you will
encounter again and again have probably
already encountered several times
our this distinguished class of convex
functions called norms so function that
satisfy these properties you know if
it's non-negative and it is positive
definite that means it is zero if and
only if it's argument is zero if if to
this function you send in an argument
that is not exactly the zero vector it
will output a positive number and it
satisfies this positive homogeneity that
is if you scale the vector then the
value of the norm just gets scaled in
absolute value by that scalar and the
most important one it satisfies sub
additive 'ti just like a triangle
inequality type inequality so if you
have a function that satisfies these
properties we are just thing we are
investigating functions that satisfy
these properties such functions are
called norms and they are extremely
important functions they even happen to
have that's why their own notation we
usually don't denote rather than using f
we use this double bars and you can
verify these are convex by just the
definition that Valley
you can check as an exercise which of my
axioms it violates if you want the
answer already I will I don't want to
make it a spoiler but it violates one of
these axioms maybe more than one you can
check which one
so they abuse that notation so one
should be careful and call it a quasi
norm it sort of looks non like H that's
why people call it a norm later you will
see I think in a later lecture you'll
see much deeper insight between why
people may still call it a quasi norm
but it is not a norm it's not convex
either so because otherwise it will
violate this theorem that I wrote here
norms are convex which you should try to
prove ok some norms you may have seen
Euclidean norm LP norms P equal to 1 is
probably the most popular and sometimes
P is equal to infinity
is obtained by taking limit of this
thing as P goes to infinity and you can
check when the limit of P goes to
infinity the contribution is only of the
largest guy in there so that's called
the L infinity norm so these are defined
for strictly for P less than infinity
and for infinity you take a limit the
other popular one which you may have
seen by now few times is the Frobenius
norm
it looks at matrix as a big array of
numbers and treats it like a vector and
takes the vector norm more for matrices
there is another norm called the
operator norm which is the largest
singular value of a matrix that's
another norm and verifying this may
require some effort but this is like
some standard convex norms that we
encounter now and then in machine
learning so the next very important
convex function which is motivated by
the max theorem so I told you that the
max of arbitrary family of convex
functions is a convex function here is a
special case of that theorem the
so-called Finchel conjugate this was I
forget the year but where nothing
essential wrote a very influential five
page long paper in which he introduced
the essential conjugates sometime I
think in the forties and it's an
application of that max theorem because
it's taking point wise supremum over X
it says F star of Z is convex function
and the nice thing is because of that
max theorem actually so this is just the
definition okay because of that max
theorem the F in here can be anything
this F doesn't have to be convex for the
f star to be convex because in the max
theorem just as you pointed out in the
max theorem as a function of Y it the
thing could be arbitrary so here we are
taking maximizing over X so the function
of X can be crazy but what comes out is
just point wise maximization of convex
function of said because it's linear in
Z hence the
product that comes out is convex but
this is one of the most important convex
functions that exists and it's very
important because it opens up a dual
view a different way of looking at
convex functions and that different way
we've actually already looked at but I'm
going to come to it soon example plus
infinity and minus infinity are
conjugate to each other the most trivial
probably not so interesting conjugate
function but it's setting the boundary
lines I have left another exercise in
here just to show you how to exercise
some of the depth developed don't worry
about absorbing the proof right now but
I have left it in there when you later
hopefully look at my slides to see that
up up till slide number 20 the concepts
that have been developed how you could
use them to prove these examples couple
more interesting potential conjugates so
if you have a quadratic function X
transpose ax where a is a positive
definite matrix
then it's conjugate is just given by a
inverse that Z transpose a inverse a and
that's an exercise worth solving this is
the hinge loss kind of thing that you
see in SVM's for that we have a very
nice conjugate and I'm just writing the
examples there but for those who have
not seen such material before because
I'm going slightly fast maybe for them I
really encourage you to verify go
through and try to prove the things that
I'm stating here except maybe for the
log theorems because that will take more
time but things that are listed as
examples those you should definitely try
to do
because it is positive semi-definite
that means it's invertible hence i can
take its inverse
so let me that's why i was maybe some
people may call it strictly positive
definite but so for me okay let's use me
use a different color that one okay I
can use that so suppose a is a symmetric
matrix a a is a real symmetric matrix so
a IJ is AJ I and it is n by n in size
then we say it is positive definite if x
transpose ax is strictly bigger than 0
for all nonzero X and such matrices are
invertible if this is bigger than equal
to 0 for all X not strictly so then the
matrix may not be invertible and these
are called positive semi definite so I'd
like to reserve the word
definite for things that are 0 if and
only if the argument is 0 because like I
said norms are positive definite several
other functions are positive definite so
yeah
and the last one is just our friend the
indicator function its conjugate because
of course that's the most we can do we
cannot solve it further if it's that's
why it gets a separate name of its own
it's called a support function you may
see reference to support functions you
may be in some other lecture also but
these are like some very classical basic
convex functions with which we play when
doing optimization here is another I
cannot resist challenges in the
beginning but later on I'll have to
actually talk about work but this is
again for those who like to exercise
their convex analysis skills that you
have seen here or this is a nice
challenge exercise X Y Z etcetera these
are all positive numbers scalars and you
can generalize this by inclusion
exclusion to be a function of n
variables try to prove that all of these
functions are convex it's it's an
interesting task and this is one of
those tasks where things like second
derivatives etcetera if you feel greedy
to take second derivatives will pretty
soon show you that you know even for
verifying convexity of some functions no
matter how many powerful tools with
conjugates indicators whatever we see it
may not be easy okay so now very closely
related to the idea of ventral conjugate
which is essentially coming from the max
theorem that we had is the idea of sub
gradients and the idea of duality these
two are together so whenever you hear
the word duality there are several
different kinds of duality that exists
for us we may just think in terms of the
seneschal conjugate we can just call it
the central dual function that is one
thing we call duality
at other times when I talk about duality
you may think that originally we were
talking about f of X when we talk about
duality we may be talking about the
gradient or sub gradient of f of X
that's roughly the idea what those nouns
may mean but let's look at sub gradients
so as I mentioned for convex functions
you can make these lines as tangents
which underestimate them so important
point is that we have this function
curved up like that at every point we
can find all a bunch of lines in fact an
infinite number of lines that are global
that globally underestimate the function
that means that are globally smaller
than this function right so you have
lines going all the way down there and
you keep coming up the tightest such
line is of course given by the tangent
here which is defined by the gradient so
that's for differentiable function so
already when I said the tightest such
line you should think in your head some
kind of Max is happening in there and a
line is just defined with the linear
function and you already saw that when
we created the central conjugate there
was a linear function or something in
there so that's like high level how
these are concepts float together the
nice thing that happens with convex
functions there's one of the nicest
things that happens even if the function
is not differentiable so this is a
smooth looking function it's
differentiable everywhere we work with
convex functions that need not be
differentiable they may look like that
they may have corners so wherever it has
a corner it won't have a derivative it
may it will only have one sided
derivatives as you seen maybe in high
school and those one-sided derivatives
have been very nicely and thoroughly
generalized into the language of what is
called a sub gradient so once again the
same idea even at a corner now instead
of heavy
a unique tightest under estimator you
may have an infinity of under estimators
which are all global and estimators at
that point so the important part point
being we are trying to get a dual view
and gradients prove so useful in
ordinary calculus and one of the cool
things about convex functions and convex
optimization is that many of the cool
things you can do with gradients we can
extend those ideas to even non
differentiable functions as long as they
are convex we can extend them with some
with suitable notation so here G 1 G 2 G
3 are three of those tight lines that
pass through there so they are called
sub gradients and that's a very that's a
concept intimately related to the
essential conjugate because each of
these things you could think of as a
line and it's kind of the tightest
possible line at that point and some
basic facts I'll tell you some most of
important stuff about sub gradients and
maybe I have too well let's not worry
about acceleration so much because sub
gradients are going to be important for
us today and tomorrow so some important
facts if F is convex and differentiable
then its gradient is the unique sub
gradient and a vector some vector G is a
sub gradient at a given point if and
only if this linear function is globally
smaller than f of X that means for any
possible choice of X so so u of Y so
usually the nice thing about the sub
gradient is that typically if we can
compute f of X it's usually not too hard
to compute one sub gradient of f of X
and even though as you've seen from my
diagram the sub gradients are not really
unique the nice thing is because they
satisfy this global underestimation
property that they give you this linear
function that is globally smaller it
really doesn't matter ultimately usually
which sub gradient you pick when you try
to use them and many other things that
I'm saying right now they will become
more concrete once we start looking at
actual algorithms that consume this
convex objects so determining like I
said you may be able to pull out one sub
gradient but if you want to characterize
all possible sub gradients at a given
point that is quite a difficult task and
usually we'll never attempt it so we
don't have to worry so much about that
and the development of sub gradient
calculus which extends the rules of
classical calculus that we by now take
for granted either the single variable
calculus one sees in high school or
multivariable calculus that you may see
in undergrad all those chain rules and
compositions monotonicity etcetera the
things that we take for granted almost
all of them not all of them get extended
to non differentiable convex functions
and that is one of the major
achievements of modern convex analysis
is to create that calculus and this is
essential Young inequality which
actually just follows by definition of F
star so I will just rewrite F star in
case it's no longer in your buffer that
f star of s was given by supremum of X
so clearly by this definition this
inequality holds and this inequality is
also used repeatedly when doing
convergence proofs and theoretical
analysis of several convex optimization
algorithms and if this inequality is
really just a by-product of the
definitions and this inequality helps us
prove things that if you want you know
things like holders inequality and all
sorts of things you may have seen in
other places okay so quick example of
sub gradients for those of you have not
seen such an example before so I have
two convex functions F 1 of X F 2 of X
I'm taking the max so clearly by the max
rule the combination is convex assume
now that both F 1 and F 2 are in fact
even differentiable so say I have F 1
that looks like that and I have F 2 that
looks like that I take their max which
is then given by that part what happened
after we took the max a kink appeared
it's not smooth at that common point
anymore so we had two nicely behaved
differentiable infinitely differentiable
functions when we took their max at the
common point there is a possibility of
non differentiability showing up it does
show up because because ultimately of a
simple kind of reason at a common point
when you're taking max of two functions
we don't have a unique way to tell
whether the max is due to F 1 or is due
to F 2 that's pretty much what happens
here
so here at other places you may have may
be able to define gradients but at that
point you have several such lines which
act as sub gradient hence in the portion
where F 1 is strictly bigger than F 2
then clearly the max is F 1 and F 1 is
differentiable so the unique sub
gradient is just the
relative of f1 where f1 is strictly
smaller than the unique subgradient is
just derivative of F 2 because I said of
the property that if a convex function
is differentiable its derivative is the
unique sub gradient and at the point
where they are equal you have
essentially all these lines that turn
around that point they those slopes
which are here just real numbers those
happen to be the sub gradient so so
that's showing that we do like to take
max but max is in some sense one of the
most non smooth non differentiable types
of functions that we have yeah I will
talk about that in a few minutes that's
a very important question because that's
actually what you need if you want to do
anyway
programming with these creatures so I'll
just mention a brief theoretical thing
here again this part I will just leave
on the slides for summary I thought many
times should I keep it in should I leave
it then I said okay for the benefit of
the students I leave this material in
even if some of it may be unfamiliar so
because we don't have a unique sub
gradient there may be many sub gradients
infinitely many that at a given point
all possible sub gradients the set of
those sub gradients is called sub
differential and if F is a convex
function then the sub differential set
is nice and in for example if it's
differentiable then that sub
differential set is a singleton
containing just the gradient and vice
versa so let's look at an example so if
F is the absolute value of X this
function is differentiable everywhere
except at zero where it has a kink so it
will have lots of sub gradients there
and in fact this is such an easy
function we can fully characterize its
sub differential at zero right so this
is the sub differential set when you're
strictly small
than zero derivative is minus one
otherwise plus one and when you are at
zero all possible slopes and here we
know actually what the slopes are from
minus one to plus one all possible
slopes are our sub gradients so you have
so we managed to fully characterize that
this is one of those lucky circumstances
where one can do this typically you
cannot do this it's it's too hard to
determine that here is another example
I'll just leave it here because I'm not
going to use it but for this one
actually when have the proof but
whenever it says an example I actually
am encouraging the students to please
try to derive the proof yourself to
answer the so okay before I answer your
question about how to compute these let
me just give you mention one thing
typically for convex functions we do
have sub differential set does exist
means it's non-empty but there can be
circumstances where your function is
defined but the sub differential may be
empty which means there may be no sub
gradient which basically means to say
there's no global under estimator here
is an example of a function because if X
the norm of X becomes bigger than equal
to one essentially you will end up
getting a divide by zero or you'll end
up getting an infinity so you the sub
gradient set is empty sub differential
set is empty so to answer the question
how do we compute sub gradients there is
a little bit as I said one of the
achievements is creating a calculus to
do sub gradients so that you start with
something for which you know the sub
gradient then you know that how to
combine these things to get sub gradient
of the combination and you develop
addition chain rules and so on to be
able to figure out so I'll just
summarize that list I'm not going to go
through that list but I put it there for
reference in case you need to compute
sub differentials later on for fun
so here is the summary of several of the
rules a star on those means that you
know because these rules are for full
general convex functions they don't
always hold as nicely as the ordinary
rules of differential calculus but for
most of the convex functions that you
will be working with in machine learning
these rules work without the star and
some of the most important rules are
actually if you as we saw getting a new
convex function by taking a max over
convex functions was a very important
way of constructing convex functions so
one of the most important calculus rules
is if your convex function is created as
a max as happens when you have a hinge
loss in SVM's or something how do you
construct sub gradients or you actually
can describe the full sub differential
so there is a rule for that but I don't
have time to go into these rules but I
am leaving this here because these are
very important chain rules to help you
show how you can use this calculus to
construct to figure out how to do some
gradients I'll show an actual one
example which is interesting and crazy
at the same time so ordinarily so that's
the star so if you had two
differentiable functions the derivative
of the sum will be sum of the derivative
we are happy fine for convex functions
it can happen that the sub differential
of the sum need not equal the sum of the
sub differentials this is a set
summation by the way so it's one set
plus another set so which means combined
all make all possible combination so it
can happen that this fails but like I
said these are pathological cases but
one has to keep in mind and if you've
ever heard the word constraint
qualification in optimization that's
essentially trying to ensure this
doesn't happen but here is an actual
example but rather then go into the
example again I had I'm compressing for
time because I want to tell you just
couple more interesting things
this inclusion always holds though the
creature on the right hand side is
always included in the left-hand side
but there's an important theorem
accessory rockefellers theorem so even
though so typically a lot of the
expected calculus rules do hold many of
the times these rules may break down
sometimes these rules may break down in
the some of the times when these rules
may break down happens usually when
there are convex functions involved that
can take the value plus infinity so
that's one of the common cases when this
could happen or there is or the sub
differential set of one of the guys
happens to be empty or something but
most of the time you can just blindly do
the subgradient and another practical
advice if you are looking at a function
mostly you'll be the one who'll be
constructing the function just
differentiate it as usual using your
ordinary differential calculus and then
worry about the boundary case to figure
out if you did it right so that's the
most practical way to get sub gradients
so here is an example of the max rule
which uses several rules this is the L
infinity norm so at 0 it has gigantic
number of sub gradients it's we have
this sub differential set which is the
convex hull which I described long ago
on slide 3 maybe of basis vectors the
canonical basis vectors which are just
columns of the identity matrix right and
to prove that that this is the sub
differential set just apply those
calculus rules that I showed you f of X
can be written as it's the maximum
absolute entry of X so for each entry
you can pull it out by multiplying it
with canonical basis vector and taking
max of those well this is just absolute
value and this is a linear
transformation so you can use the chain
rule and the max rule and you saw that
the partial the sub differential of the
absolute value function what it is
putting those three rules together you
can get the full
some differential here means this is
just an exercise showing you that even
for this trivial looking function I had
to actually invoke three of those rules
or theorems but fine so I'll I'll let's
let's just do a concrete example of that
so suppose X F is defined as a maximum
over a fine linear functions finite
number how do you want to pull out a
subgradient this is pretty close to
essentially you know if you had that
hinge lost type of thing and you want to
compute a sub gradient because you are
trying to do optimization how would you
do it well this is the max over some
finite number of terms the max rule says
let me actually be in fully point out
the max rule the sub differential is
convex hull of the sub differentials of
all the active functions so when you
have a max over several functions one of
those guys will end up attaining the max
as we saw in the max example and this is
just trying to say how to combine their
individual sub differentials to get the
net sub differential so this is a very
important theorem in its full generality
it is still a research topic to fully
characterize this theorem that's why
there's a star there so this exists but
in full-blown mathematical generality
it's still non-trivial activity anyhow
so we so this is one of the functions F
K suppose that f of X suppose K K some
index for which f of X is this that
means the K F function is active well
here actually the KS function is
differentiable so it's sub differential
is just that singleton set so you
collect all those guys take their convex
hull that is the sub differential set
but we don't want just the whole set is
too difficult you just wanted to pick
one sub gradient so just pick some
member from that set and a K would be
one of those members right
the I don't know exactly what dance and
theorems refers to but the max rule is
for finite index they might be a soup
there and you may have uncountable index
that but even with that things work out
but there are some other subtleties that
happen so this allows you so what was
the plug-and-play here you have a max
over several functions see which of
those functions attain the max
take its derivative or sub sub
differential pick one of those guys and
that's that's a valid sub gradient so
that's a very easy way to pick sub
gradients another thing which we'll see
actually tomorrow is if f of X is given
by summation over infinite number of
things which is called integration it's
written as that integral and each of
those f of X comma U is convex in X for
every u you will you varies over some
space whatever is just you add those
things up then one way to pick all of
these things require rigorous proof ok
and I am NOT going to do any of that
here I'm just telling you that these
things exist and most of the time the
thing that you would intuitively expect
does hold with the caveats
so for each you you can pick any sub sub
gradient of this function so we are just
applying the summation rule of sub
gradients here because this is just a
summation then the integral of all of
those separate sub gradients is going to
be a member of the sub differential so
basically that means you can even when
you have a sum of an infinite number of
objects you can still pick out a sub
gradient from them as long as we can of
course compute that expectation and this
thing is kind of abstract right now
tomorrow I'll show you how this thing is
at the heart of very profitably doing
optimization in machine
learning okay so now I have because I
told you in the beginning I'll take some
more time I will use maybe 10 15 more
minutes finally we have managed to after
constructing basics of convexity reach
optimization problems and I just want to
mention one important concept within
optimization problems and that is of
duality so let's quickly go to that so
I'll just give you some notation right
so you have some this is a standard
non-linear optimization problem cost
function constraints and domains of the
function so for us whenever I say domain
of a function by that I mean the subset
of R to the N over which my function is
finite
that's usually what is domain so we so
I'll just drop that there are domains
you know you those are implicitly in
there but there are they are there so if
if the f is are differentiable then it
is called a smooth optimization problem
there's just the nomenclature we are
using if any of these F is is non
differentiable then scorn on smooth
optimization problem so one more
difference to pure math in math when
people use the word smooth they mean an
infinitely differentiable function in
optimization and machine learning when
we say smooth we just mean once
differentiable big difference but for
optimization that suffices
if all the FS are convex we have convex
optimization otherwise you have non
convex optimization pretty simple right
and if there is no cost function or if
there are no constraints so there is no
cost function is called a feasibility
problem if you just have the cost
function no constraints is unconstrained
problem but this is just the standard
stuff that you have seen and if you are
feasible so if X is the feasible set set
where all constraints are satisfied then
the optimal value possible over that is
called the primal optimal value denoted
as P star I am following notation Boyden
vandenberg is book and other some
interesting things to note about
optimization problem the reason I
mentioning this here so
it has happened to me that I start out
with an optimization problem and it
turns out it's really hard to tell does
this thing even have a solution most of
the time for machine learning models or
models and statistics people don't worry
about existence of a solution because it
follows rather straightforwardly
but when you are exploring new
mathematical models creating new cost
functions you should worry a little bit
about first being able to say does my
problem even have a solution before I
try to do anything right here's a quick
example so if if the feasible set is
empty the problem is infeasible there is
no solution you have contradictory
constraints right could happen and by
convention we said say the infimum is
plus infinity for infeasible problems
it's a important convention for example
if you can have problems that don't
really have a solution that means you
have an ins but you don't have a min
there is no actual vector or scalar X
that actually attains the solution for
example if you are trying to minimize X
there is nothing else there is no
solution to that problem right it's
unbounded below so sometimes minimum
might not exist one has to think about
it anyhow so the thing nicest thing
about when doing optimization with
convex functions is one of the nicest
things is that for a convex function
given the way it is curved up just
looking locally around you suffices to
tell you how the function behaves
globally over the entire space that's
what makes gradient based optimization
and sub gradient based optimization the
kind we are looking at very easy and
popular because a gradient by its very
definition is a very local first order
concept so for convex functions that's a
rare distinction that local information
suffices to do global optimization okay
so some of these theorems are easy
I want to let me actually rather than
show the easy theorem let me show you
let me show you I'll show you an
application of again the sub gradients
so if you have constraints you have a
feasible set X and you're trying to
optimize you need some way to detect
have I solved the problem right so that
means you need some way to characterize
optimality and that's a very big topic
how to characterize optimality using
gradients to characterize optimality is
pretty much what we will do so if F is
convex it satisfies that inequality by
definition so if this holds then X star
has to be optimal by construction the
other direction and quickly show you on
the next slide and if this is
non-negative at X star and alleged
minimum for all feasible Y well if there
are no constraints that means the entire
real space is feasible then the gradient
had better be 0 for this inequality to
hold so you recover the ordinary
condition that gradient has to disappear
for unconstrained problems to have
optimality if the problem has
constraints then of course clearly the
gradient need not be equal to 0 but it
has to have this has to satisfy that
inequality and let's prove that
inequality using something that is
called famous rule he didn't write it in
this notation in 1600 something I'm
giving him that credit so this is
usually called famous role and this
yields for us that optimality condition
as a by-product of just our definitions
that's the nicest thing about it so
suppose s is a function convex function
let's say here it need not be convex but
say it's a convex function which can
take the value plus infinity also so we
say the set of minima of F the actual
X's that give you that minimum value
that's called the argument set is the
set of X's for which sub differential of
X f at that X contains a 0
which is another very nice thing
gradient having zero was given was our
standard way of detecting optimality for
differentiable functions sub difference
sub defusing sub gradients rather than
gradient we have the entire sub
differential set if zero happens to be a
member of the sub differential set at a
point then that point is optimal so it's
very naturally generalizes that's the
beauty of it so here's a proof of this
by definition right so if X is a minimum
so FX is less than FY for all Y right
that means FY plus FX is bigger FY is
bigger than FX plus zero hey but this
looks just like the definition of sub
gradient so zero is a sub gradient
vice-versa if zero is a sub gradient
then by definition you have that
inequality so zero belonging to the sub
grade sub differential is characterizing
global optimality for convex functions
proof by definition right I did I didn't
prove anything I just wrote down the
definition the only thing that we proved
here is used here is that zero
multiplied by something is zero but okay
that's easy so the benefit of that
notation the previous proof which is
usually given using all sorts of
geometric arguments which are good for
people who can do geometry I cannot I
liked this simpler argument here is
suppose now we are looking at
constrained problems you're trying to
minimize f of X over a set X one way to
do write that problem as an
unconstrained problem is to use my
favorite function the indicator function
FX plus indicator of X because this
function expresses severe displeasure
when you're not in the constraint set it
becomes infinity the only way to
minimize this is to make sure that a
point X that you pick lies inside the
set X hence this is another way to write
that unconstrained problem as an
unconstrained one and now the
probably you may guess what comes up
next I showed you that optimality is
characterized by 0 belongs to sub
differential I took a constrained
problem wrote it as an unconstrained
problem now just compute its sub
differential so minimizing X has to
satisfy that and there should have been
F naught F naught and that means you do
so here is where some kind of constraint
qualification comes please ignore it for
now the the real thing to appreciate in
this proof is I took a constraint
problem wrote it as an unconstrained
problem using some indicator functions
and now I want to characterize an
optimality condition for this
unconstrained problem this unconstrained
problem involves F plus an indicator
function so using my sub differential
calculus I try to characterize the sub
differential of the sum of these two
functions and so we assume we know what
is sub differential of F it's whatever
and then we need the sub differential of
the indicator function which is also a
function sometimes plus infinity so to
construct it sub differential I cannot
give an explicit form of that because
that will depend on what the constraint
set is you just invoke the definition a
vector G will belong to that sub
differential if and only this happens
well so belonging there means that X
belongs to the constraint set and 0 will
be upper bound because you know if Y is
in the constraint set the left hand side
becomes 0 so that's really just
exercising definitions and because we
don't have anything else so usually this
is the common trick in mathematics right
if you don't understand the concept
further give it a new name and carry
that name along so we give it a new name
it's called normal cone it has Dimitri
behind it there's just some differential
of the indicator function fine with that
jargon let's look at an application
getting an optimality condition for
differentiable convex functions you want
to minimize f of X
F is differentiable that means zero
should belong to sub differential of
that which is just the gradient plus the
sub differential of the indicator
function which is called normal cone and
you loop sorry you do plug and play the
normal cone is defined by that right
equation so you end up recovering the
optimality condition of differentiable
convex optimization as a by-product of
merely exercising the definitions so the
only non-trivial thing that happened
here is the one that I didn't speak
about is something some assumption that
authorizes you to do the rest of the
calculus so this may appear obtuse or
maybe not the obvious way to detect
optimality to everybody but I think it's
an achievement of being able to define
good concepts and notation so that
something which would previously be a
theorem is a just a by-product of the
definitions so I think I should stop now
I will actually then use the use fifteen
minutes of the next lecture to talk
about duality before moving on to using
all those concepts to actually start
doing optimization</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>