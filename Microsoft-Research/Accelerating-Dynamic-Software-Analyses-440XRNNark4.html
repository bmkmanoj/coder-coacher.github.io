<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Accelerating Dynamic Software Analyses | Coder Coacher - Coaching Coders</title><meta content="Accelerating Dynamic Software Analyses - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Accelerating Dynamic Software Analyses</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/440XRNNark4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
look
great pleasure to introduce Joe great
house Joe's a PhD student from the
University of Michigan who works for
Todd Austin he's gonna be talking today
about accelerating dynamic software
analysis I just want to say a couple
things about that we know at Microsoft
how important static and dynamic
analysis is for finding bugs and
reliability problems and programs and
one of the key problems with dynamic
analysis has always been it's very slow
relative to static analysis and they
overhead that you have doing it
sometimes makes it unusable so today
we're going to hear more about how to
make that dynamic analysis fast and
usable thank you thanks so um you'll
find you'll hear some ways to make that
more fast and usable I hope that I hope
I can get across that this is not the
only way to do it if anybody else has
any ideas please you know stop me the
middle talk chuck things at me tell me
that I'm wrong and that you have much
better ideas I would love to hear them
because I don't think that this is the
be-all end-all of it I think these are
some interesting ideas so as I was
introduced I'm Joe a great house and
talking about accelerating dynamic
software analyses so the reason I'm here
talking about dynamic software analyses
is kind of as you mentioned software bad
software is everywhere right so just as
an example in 2002 i believe the
National Institute of Standards and
Technology estimated that bad software
cost the US economy a little under 60
billion dollars per year and that soon
from things like software crashing and
you lose a couple of man hours here and
there corrupting data files that are
worth a lot of money etc and mind you
that was about 10 years ago so besides
things like like software crashing all
the time and losing money you also have
things like security airs that come
about from bad software so this is
another example of how much that can
cost in 2005 the FBI computer crime
survey estimated that computer security
issues cost the US economy about sixty
seven billion dollars per year we're
more than a third of that is from things
like viruses or network intrusions or
things that you can probably trace back
to bugs and software bad programming
practices had to set up files etc and so
I mentioned that that these are from
2002 and 2005 that's that data is a
little bit old but what this graph shows
right here is
vulnerabilities over time so this is the
data from two different bug databases
cve candidates for the common
vulnerability estimates and and the US
sir computer crime people the cert
vulnerabilities that are released
publicly and so as you can see over time
these numbers are at the very least not
going down and you can kind of see a
general uptick from the 2002 2005 time
frame to 2008 the last year I could get
data for these in from both databases
but the point here is that soft bad
software is everywhere and actually it's
probably getting worse over time we're
writing more software it's harder to
program complex hardware so we're adding
more bugs into our software etc so I
just want to give you an example of a
modern bug like this is one of my
favorite bugs that I love to talk about
because it's really interesting to me
this is a security flaw that was
released a little over a year ago in the
open ssl security library it's actually
the open TLS version of that library I
believe but it's an example it was just
a small piece of code in this library
that is used to use to secure web
servers so the idea with openssl is that
if you go to some website and it says
you have an HTTPS connection then you
know you have a secure connection that
web server and that servers running
openssl so the idea there is that
there's smart people that are programmed
this they worry about security all the
time right and still these little four
lines of code ended up biting them and
having a really nasty security
vulnerability that in fact allowed them
to have remote code exploitation on an
open ssl server so what this bug what
this little piece of code does is it
checks to see if some pointer is no and
if it is it allocates a buffer to it and
copies data into that buffer it's a very
simple operation in fact in the single
threaded world this piece of code works
perfectly fine it if there is no buffer
it puts one there that is the correct
size and then puts the data into it but
the problem comes around well and you
have some point right the problem comes
around when you run this in a
multi-threaded world so in this case
openssl would use some shared pointer
between these threads and then it's
possible that two people are connecting
to this ssl server at once and
they each want to allocate some
different size buffer and so in this
case you have these things might happen
at the same time this is just some
example dynamic ordering of how the
instructions in this this program might
run where time is going down here and as
you can see in this ordering the first
thread checks to see if that shared
pointer is null and it is so it's going
to start trying to allocate the buffer
and put copy data into it however
because this is on some concurrent
machine maybe there's a there's an
interrupt in the second thread gets
scheduled or the second processor is
trying to do this at the same time the
second so I can ask the exact same
question before anything happens to that
pointer so now both threads are going to
try to make a buffer here second thread
wins the race and allocates some large
buffer and gets ready to start copying a
large amount of data into it the problem
comes about when the first thread starts
is scheduled again and starts working on
this it still wants to put a buffer in
there so it creates this small buffer
for its data and just destroys the
pointer to the first to the to the large
buffer so the first thing to notice here
is that large buffers been leaked and
that's bad enough that might end up in
some type of denial of service where you
run out of memory and the program
crashes but the worst thing happens
after the small the first thread copies
a small amount of day to the small
buffer the worst thing that happens is
when that second thread is then
rescheduled and starts copying data into
whatever that pointer is pointing at and
in that case you end up with a buffer
overflow because it's trying to fill a
large try to stuff a large amount of
data into this small buffer so what this
is is that the data race that has caused
a security error in a program that is
programmed by very smart people and that
worried about security all the time and
still in get bit because of just small
little errors that are pretty difficult
to find by looking with your eyeballs so
one way that you can try to find these
things is with dynamic software analyses
there are static analyses out there and
other things that you can do that look
at the program offline and try to reason
about what kind of problems there could
be but what I'm going to focus on for
this talk is dynamic analyses where you
analyze the program as it runs and you
try to see you try to reason about what
what state the program is in it if it's
in a bad state or not so as an example
on any executed path you would be able
to find an error because what you do is
as a developer you have some
program maybe you throw it through some
type of instrumentation tool I chose a
meat grinder here because valgrind kind
of sounds like that but the idea is you
would end up with some program that also
has analyses as part of its state as
part of its code and you run that
program through some type of in-house
test machine you spend some large amount
of time grinding on it you throw tests
into it and this dynamic analysis looks
at the it looks at the program as it
executes and sees if any of those states
are wrong or bad in some way after some
amount of time grinding on it you send
back your analysis results to the
developer and you know you say ah the
states that you checked we're good or
the states that you checked we're bad
the two downsides to this is that this
has an extremely large runtime overhead
on average I'll get to that in a slide
about what those numbers are but in
conjunction with that dynamic analyses
can really only find errors on paths
that you execute because they're looking
at the past that you're executing and if
you have very large runtime overheads
that can significantly reduce the amount
of paths that you can test before you
have to ship the product stop your
nightly tests or you give up because
you're sick of waiting on an answer to
come back so these two negatives here
actually combined together to make
dynamic analyses a lot weaker than we
would like them to be so when I say that
the runtime overheads are large what I
mean by that so this is just an example
of a collection of software analyses you
have things like data race detection
where intel has a product on that son
Google they have products on that and
those range from anywhere from 2 X 2 300
x overhead depending on the amount of
sharing that goes on in the program the
particular algorithm is the binary
instrumentation tool etc you have things
like Tate analysis which are mostly in
the literature right now rather than in
commercial tools but you have things
like tank check which was about drying
tool that did taint analysis is a type
of security analysis and that's anywhere
from two to two hundred times slower
than the original program things like
men check which is perhaps one of the
most popular dynamic analysis tools out
there it's a biggest bad writing tool
that people use and that's still
anywhere from five to fifty times slower
so that limits the amount of times that
you can check to see if you might have a
memory leak or an uninitialized value
being used and then things like bounds
checking and symbolic execution can also
be pretty nasty so the point here is if
you're
200 times slower than your original
program and it takes you know a day to
boot up windows instead of a few minutes
you're never going to run these tests
over all types of things that you want
to test it on because eventually you
have to ship the product so then the
goal of this talk is to find ways to
accelerate these types of dynamic
analyses and so I'm going to talk about
a little bit of background information
before I go into my two methods of doing
this and this background information is
demand driven dynamic data flow analysis
I'm going to talk about what dynamic
data flow analyses are and then what i
mean by demand driven but suffice it to
say we're going to use this background
information to inform the decisions in
my proposals so when I say dynamic data
flow analysis I really mean an analysis
that associates metadata with the
original values in the program so it for
instance you have some variable you
might have a piece of metadata that says
whether you trust that variable or not
and as you run the program it forms some
dynamic data flow and meanwhile you also
propagate and clear this metadata to
create some shadow data flow that goes
along with the program so if I didn't
trust a source value I shouldn't trust a
destination value so you propagate that
untrusted pneus alongside the original
data flow of the program and eventually
you check this metadata at certain
points in the program to see if there
are errors in your software where with
this untrusted thing perhaps if I jump
to an untrusted location or if I use a
pointer that's untrusted in dereference
it that might be a bad thing and I raise
some error and as I mentioned what this
does is it forms a shadow data flow that
looks very similar to the original data
flow on the program and so that's why we
talk about dynamic data flow analysis so
as an example I earlier I was talking
about taint analysis so in this taint
analysis example anything that comes
from outside the program anything that
comes from input is untrusted it has
some metadata associated with it says
that I don't trust it and so as I read a
value from outside of the program I put
that value into X and I have some meta
value associated with ex did I associate
with it and say I don't trust X then as
I use X as the source for further
operations i propagate that tainted
value alongside the original
to flow in the program so because Y is
based on X I also don't trust why and
you can continue to do that for multiple
other operations now it's also possible
to clear this maybe I have some type of
validation operation because even though
x came from the outside world I I
validated it through some software
method and now I trust it and so I
should be able to do dangerous things
with it so we can also clear these
tainted values and then if you use X
after its trusted as a source operation
you don't propagate metadata alongside
of it because now W is also trusted and
then eventually you can check these
values so I went to dereference w I
check it that's fine I trust it however
if I want to jump to Z aurorae I checked
them and they are untrusted that's a bad
thing I raise some air so this is the
idea of dynamic data flow analyses in
this talk so again the problem with this
was that these analyses were extremely
slow 200 times slower than the original
program which means no users ever going
to run these to try to find a buffer
overflow on their system instead they'll
just reboot the thing and it'll be done
before this program ever comes back but
one way that you can accelerate this is
to note that not all of those values
needs to go through all of the slow
dynamic operations if I'm working
entirely untrusted data on data that I
trust I want to be very specific with
that then I don't need to spend any time
an instrumented code doing propagation
rules right because if there's nothing
to propagate why would I spend time and
software trying to calculate that I'm
not doing anything so in that case you
can take two versions of your
application your native application that
doesn't have any of this large
instrumented code to do this analysis
and that runs at full speed that's your
original program and next to it you can
have some instrumented version that does
all the propagation clearing and
checking and what you'd like to do is
only have to turn on that slow version
of the application whenever you're
touching metadata whether it's a
destination or a source but if you're
not if you're doing a trusted value plus
a trusted value goes into a trusted
value say there's no reason to do
anything different than your native
program so what I've added down here at
the bottom besides these two programs is
some type of tool some utility that
tells us when we're
Ching shadowed values touching metadata
and I'm going to leave this a little
nebulous as to what this is for right
now but suffice it to say that it'll
immediately tell us whenever we touch
out tainted value so we run some
instruction from the program and this
metadata detection system says this is
not shadowed data this is completely
trusted everything in this instruction
so we can immediately go back and update
program state there's no runtime
overhead with that as long as this thing
doesn't have any overhead next
instruction can go through here and
maybe it is touching shadow data it
touches something that's tainted that we
don't trust in that case we need to flip
the switch and turn on this instrumented
version of our code and spend some time
doing this analysis we go back to this
this slow runtime overhead before we
eventually also go back and update
program state and we can then continue
to send instructions through this for
some time until we see that we're not
operating on metadata in which case we
can flip the switch again and go back to
running full speed on native code so the
benefit here is that if we're very very
little time is spent touching tainted
data then very little time is spent in
the slow version of our application and
this was originally described by Alex ho
and Steve hand and Andrew Warfield etc
so the zen guys described as in euro sis
2006 so to be able to the next question
then is how do we find that metadata how
do we build that thing that was at the
bottom of that last image so you'd like
it to have no additional overhead right
we'd like to say there's pure run
there's zero runtime overhead until we
start touching tainted data so to me
that implies that you need some type of
hardware support do those checks for you
and so what that hardware should do is
cause some fault or some interrupt
whenever you touch shadowed values so
the simple solution to that and that's
this is what they used is virtual memory
watch points we're here it's an example
of three pages where virtual memory
watch points work like this regular
virtual memory lets you access a value
and it does a virtual to physical
translation for you the TLB gives you an
answer back with there's no miss and
there's no runtime overhead and that
happens on any page that is mapped in
your virtual memory space however if a
page has tainted values in it if one of
the values in this page is shadowed in
some way what you can do is Mark the
entire page as unavailable in the
virtual
memory system the translation still
exists but what happens is when you
touch something on this page the
hardware will cause a page fault because
it thinks that translation is invalid
and then the operating system can signal
the software that now is when we should
turn on that analysis tool because now
is when we're touching something that's
tainted while any other pages in the
system still do the really fast virtual
to physical translation so this allows
you to have the hardware tell you
whenever you're touching tainted data
now one thing you might note here is it
also gives you fault whenever you touch
things around tainted data that's the
granularity gap problem and it's
something that I have some other work to
solve something like that that's up at
this next upcoming ask plus i recommend
everybody read that paper but so this
was the results they showed so the nice
thing that they show here is that with
Ellen bench benchmarks just tiny micro
benchmarks that don't have any tainted
data they were able to reduce the
overhead of the system from over a
hundred X to just over or just under 2 X
overhead because the vast majority of
time they're not within this slow taint
analysis tool and so there's no overhead
at all unfortunately the bottom part
here is is where things kind of
breakdown if everything that you're
touching is tainted in this case network
applications networks throughput
applications because anything that came
in over the network was untrusted if
everything that you touch is tainted you
never turn the system off and so you're
back to your 100 or more X overhead so
it doesn't give you any help at all
which means that even if you ship this
to users and most of the time it was
fast some of your users are still going
to be really mad because they're running
some app input set that really breaks
the system so that's where my stuff
comes in so I have two things I want to
talk about here and the first is is
demand driven data race detection where
I'm going to do something similar to
that demand driven data flow analysis
except I'm going to do it for a
different type of analysis one that
virtual memory watch points doesn't work
for and then I'm going to talk about
sampling as a way to fix that last
problem i mentioned where we can cap
maximum overheads and keep and in and
basically keep your maximum overhead
under some user-defined threshold and
just throw away some of our answers and
get it wrong sometimes but I'll get into
that in second
so when I talk about software data race
detection I just want to make sure we're
all still on the same page here what
this does is it adds checks around every
memory access in the program and what
these checks look for are two things
first it looks to see if any of these
memory accesses are causing inter thread
data sharing and if so it sees if they
are appropriately synchronized in some
way there's multiple ways to do that you
could use happens before detection
lockset detection etc but I'm going to
leave that a little nebulous for now and
just say that if there is not
synchronization between these two inter
thread sharing accesses then there's a
data race so let me give you an example
of how this would work this is the same
example I showed earlier where the
openssl security flaw exists except this
is a different dynamic ordering in this
case there's no obvious error in the
program when you run with this dynamic
ordering because the first thread
allocates its buffer copies data into it
the second thread sees that that buffer
already exists and doesn't do anything
there's no buffer overflow in this
dynamic ordering so what the software
data rates detector does is it checks
around on this access and says there's
no inter thread sharing this is not the
second access in an inter thread sharing
so there's no data race in fact it does
that for every other thing on this on
this page 2 or on this every other
instruction in this thread as well
however when it gets to the first
instruction of thread to it asks those
questions again it says first is the
value that this instruction is accessing
shared is it right shared between
threads is there a right and a read or
write in a right etc and in fact in this
ordering there is its pointer is written
by thread 1 and then is read by thread
to with its instruction so that's when
we get to the second question if there
is this entered thread sharing this
movement of data between threads is
there some type of interleaved
synchronization and I didn't add one in
this example so in fact there is a data
rates here and I think what's important
to note here is that this is pretty
powerful right there was nothing obvious
with this program obviously wrong with
this program and yet the data race
detector was still able to tell us that
there was a problem that we need to fix
great i really like data race detectors
they're fun and pretty powerful the
problem is as i mentioned before they're
really slow so this is a collection of
multi-threaded
marks from the Phoenix sweet and the
parsec sweet and the y-axis here is the
time slowed down of each of these
benchmarks over running them without the
data race detector and this is in Intel
inspector XC it's a commercial data race
detector that you can go out and buy
right now and these are actually pretty
decent numbers if you look at Val grinds
Helgrind tool I believe there may be 1.5
2 times worse than this depending on
specific settings but the point to take
home here is this dashed line that is
purely illustrative in that you're about
75 to 80 times slower on average running
this data race detector then running
your program with without any detection
at all so while you can find errors you
have to spend a lot of time trying to do
it so I'd like to find some way to speed
these up and and so one of the things
that you should note about data race
detection and data races in general is
that inter thread sharing is really
what's important with these things so
netzer and miller kind of formalized
data races a bit in a 1992 paper and
what they said was that data races are
failures and programs that access and
update shared data and that's the
important part here so these were the
five times you ran the data rates
detector on this example before well one
of them is working into one of these
instructions is working entirely on
thread local data so you're copying this
thread local Milan into Len one which is
a thread local variable so there was
absolutely no reason to run the day to
race detector there there can never be a
data race on that there's no sharing on
a slightly more advanced topic there are
also instructions that access variables
that are sometimes shared but in this
dynamic ordering they are not
participating in sharing their not the
risks the second instruction in a
sharing event so they're also the
database detector will never declare a
data race on those instructions in this
ordering so we didn't need to run it
there that was wasted work so what you
can see here is that of those five times
that we ran the data rates detector
before we only really needed to do two
of them maybe one depending on what the
first check the pointer is I'm going to
leave that there though so forty percent
of our work was useful work sixty
percent was useless in fact right it's
actually much worse than real programs
so this is the same benchmarks I showed
before and the
I axis here is the percent of dynamic
memory operations that are participating
in a right sharing event and you'll see
that this only goes up to three percent
and that's for one benchmark everything
over here in the Phoenix sweet that is
these are basically data parallel
benchmarks very little data sharing
there's maybe three hundred operations
in a few billion that are participating
in sharing so the vast majority of the
work that we're doing in our data raise
detector is completely useless and in
fact even in deduplication the the where
you have three percent of your dynamic
operations are participating James still
ninety-seven percent of the time we're
doing work we're not really doing
anything useful we're not going to get a
useful answer out so what that leads me
to say is that we should use
demand-driven analysis where we turn off
this tool whenever we don't have to be
doing anything so rather than doing it
on metadata however what we want to do
is look for inter thread sharing so
that's where this inter thread sharing
monitor the bottom comes from rather
than some type of metadata checking
utility in this case much like before
you send some instruction through it and
it tells you whether this is local or or
participating in sharing if it's a local
access great update program state frag
dudes and quake three no problem at all
your next instruction comes down and if
it is participating in sharing then
that's when we need to run the data race
detector flip the switch spend time
grinding on this instruction and
deciding whether there's a problem here
and eventually update program state and
then the next instruction can then just
go through the sharing monitor again and
most of the time ninety-seven percent or
more of the time you're just going to
update state immediately you won't have
to spend time in the tool the question
then is like before how do we build that
utility at the bottom that tells us
whenever we're doing this sharing I mean
we could try virtual memory watch points
just like we did pertained analysis one
way you could do this for instance Emory
burger does stuff like this for phrase
deterministic execution engines is Mark
everything in memory is watched in both
threads and as you touch data as you
touch the data that your thread is
working on you'll take faults on it and
what that fault handle will do is remove
the watch point from that value and
eventually you'll carve out a local
working set so anything that's in that
page right there that no longer has
watch points in it is thread I touch
that data last
if I touch it again it's free it's it's
there's no sharing going on however oh
right and that takes no time sorry if
another thread touches that same address
it will still take a fall upon it and
that is indicative of inter thread
sharing because it was owned by thread
one and now it's being touched by thread
to sew great we can find internet
sharing that way the problem is that
this system causes about a hundred
percent of accesses to cause page faults
which significantly reduces your
performance there are multiple reasons
for that the first is the granularity
gap so let's say that that system worked
the way I just said then after that
inter thread sharing event was caught
now all accesses are again watched
because there's one bite on page one
that is watched in thread one and one
bite it's on washington thread too well
you can't change the granularity of the
page table system such that it's one
bite so now everything's watched again
you take a bunch of faults on data that
you still own but worst of all page
tables are processed not per Fred so
even if thread one has nothing watched
on that page if thread 2 is using the
same virtual the same page table same
virtual memory space then it's still
watched because some of those bites are
watching a different thread so what that
means is that basically everything that
you access in this program calls the
page faults so virtual memory watch
points don't cut it for finding inter
thread sharing unless you play some
tricks and do and and do say data rates
detection at the page regularity rather
than at the access granularity but
anyway so what I'd like to say is that
there are better ways to do sharing
detection in hardware and so what I'm
going to talk about is hardware
performance counters let me give you a
little bit of akron on those and then
i'll tell you about how we can use them
so harbor performance counters kind of
work like this you've got a pipeline of
cash and some performance counters that
sit next to all these what these are
normally used for is to read events in
the processor and count them so that you
can see where the slowdowns in your
program are coming from I might have had
500 branch mispredictions and a thousand
cache misses so those are things that I
need to try to fix in my program so as
events happen in the pipeline these
counters increment you take two events
in the pipeline the current the counter
now says two and there's no overhead
with that this is done in
hardware for free similarly something
happens in the cash you have a miss you
counted in the performance counter so
you know if we can find some event that
has this inter thread sharing going on
and we can count it great now we know
how many happened what we'd like to have
is still have the hardware tell us about
it right well you can do that with
performance counters by setting the to
say negative one and when that event
occurs whatever it will be and I'll get
to that in a second it's going to cause
that counter to roll over 20 in which
case you can take some interrupt now one
of the downsides is this is not a
precise event and so we have two adds a
little bit more complexity here because
otherwise you take that fault on an
instruction that might not even have a
data access in it that's where we add
even more complexity so Intel processors
in particular have this thing called
peps precise event based sampling and it
works like this when you roll that
counter over 20 it arms up ebbs a piece
of a piece of the PABs hardware
associated with that performance counter
and then the next time that event
happens you get a precise event of
exactly what instruction did it the
register values at that time and you
take a fault and as soon as that
instruction commits you're now ready to
send a signal to the data race detector
that it needs to turn on now some people
out there might note that means that
we've missed a couple of events before
we turn the data as detector on oh I'll
get to that in a second but great so we
can have the hardware tell us when
events happen the question now is is
there an event that we can actually use
to find sharing between threads and
that's where another little Intel thing
comes in that's this event that I'm
going to shorten to hit em but if I try
to remember the full name and something
like l2 cache hit em other core or
something like that hit em what that
means is that there is right to read
data sharing in the program let me give
you an example you have two cores in
this chip and each of those cores has
some local cache associated with it so
when you right into the first cache line
it sends that cache line to the modified
state rather than invalid or shared or
exclusive and then when another core
reads that value it needs to get that
cache line from it when core two reads
that all you need to get the cache line
from core
one and that movement of data is a hit
em event because it means that you hid
in a cache but it was in the modified
state somewhere else the reason you
normally count these is because that's a
relatively slow proposition it means
that when you're sharing data between
threads you have to move a lot of data
around the caches and that's slow but
for our purposes that means that we can
find out when there is right to read or
read after write data sharing now if we
wanted to use this to turn on our data
race detector at the right time there
are of course as always some
difficulties there are limitations of
the performance counter first of all it
only finds right to read data sharing it
doesn't find right to write because an
rfo that hits in another cache or read
for ownership that hits in a modified
cache line does not cause this to
increment and it also does not find read
to write it only finds right to read
that might have said that wrong a couple
sentences ago but it does not find read
to write even though that's a different
dynamic ordering it doesn't see that
that would require a different
performance event entirely so we can
only find one third of the events that
we'd like to see similarly hardware
prefetcher things are not counted so
this only counts instructions that
commit that cause a hit em event so
we're we very well may miss a number of
events that we'd like to turn this
system on for and even if it did work
perfectly because we're counting cash
events we might still miss some things
for instance if you have two threads
that share the same l1 cache they can
share data all day long and we would
never see an event if you write a value
into the cache and it eventually gets
evicted and you read it later there's no
cache event it's in main memory then
other things like false sharing etc so
just slice it to say that this is not a
perfect way to do this so what I'm going
to go through here is an algorithm that
lets you try to do this demand driven
day to raise detection in a best-effort
way so the idea here is the hype of the
hypothesis here excuse me is that when
you see a sharing event you are in a
region of code where there is more
sharing going on because a good parallel
programmer will try to not be sharing
data all the time you'd like to load in
some shared data when you have to and
then work thread locally as much as
possible because that will significantly
reduce your overheads forecast sharing
reasons etc so what we'll do here is
we'll start by executing some
instruction now you know
execute the actual instruction on the
real hardware but what the analysis
system will do is it will check to see
if it's supposed to be turned on or not
if the analysis system is enabled then
you just run everything through the
software data race detector it's slow
but you may be looking for errors and in
the software data rates detector you can
precisely keep track of whether you're
sharing data between threads in fact the
tool already does this that 300 x 80 75
x overheads i showed you before that
tool is already checking that stuff so
that it doesn't have to run the full
algorithm if it doesn't want to but if
you have been sharing recently great you
just go ahead and execute the next
instruction this circle right here is
what the tool already does this is where
we sit right now when we have slowed up
the slow tool that we already look at
however if you have not been sharing
data between threads recently where I'm
going to leave recently is kind of a
nebulous concept but in the last few
thousand instructions let's say then you
can disable your tool entirely because
you're probably in some region of code
where there's no sharing going on in
that case when you get back to this
center diamond all you do is you wait
for the hardware to tell you if there is
a sharing event going on if there is
great enable your tool turn on your
software data race detector go back to
your life and the slow lane but well
we'd like to see is that in ninety-seven
percent or more of the cases you just go
ahead and execute the next instruction
because the hardware doesn't interrupt
you and you continue on full speed ahead
basically the same speed as your program
would originally run again what we'd
like to see is that ninety-seven percent
of the time or more maybe the vast
majority of access is out of billions
are up in this corner here where there's
no slowdown and maybe only three percent
or less is down here where we exist
right now in the slow lane and so I
built this system added it on top of a
real system there's no simulation going
on here real Hardware commercial data
race detector etc and what we see here
is the speed up you can get over the
tool that's on all the time so this is a
tool that does that algorithm I just
showed you as you can see here the
y-axis is number of times faster it is
to turn this off and whether we don't
need to be on and so for data parallel
benchmarks like Phoenix we can see
almost a ten times performance
improvement on average and in fact in
some really nasty corner case benchmarks
like matrix multiply
about 51 times faster parsec has more
data sharing going on it's not as easy
to turn it off all the time it's not
data parallel in most cases so you see a
slightly reduced performance gain where
it's about three times faster which is
in my opinion still slightly still
respectable and in fact in freak mynheer
you're about 13 times faster because
much like Phoenix it's a data parallel
benchmark it's an open MP benchmark
there's very little data sharing going
on so great the tools faster next
question is does it still find errors
because if it's infinitely fast and
doesn't give us any useful answers it is
a completely useless tool so there's not
a great way to display this data I
didn't want to bring up a giant table of
all of this but the these bubbles are
all of the data races that this fault
that the regular tool can find in any of
these benchmarks and that's the number
on the right so for instance the
always-on tool that you can go out and
buy in the store right now for k-means
it finds one day to race for face sim it
finds for etc the number on the left is
the number that my demand driven tool
finds and so you'll see right up here it
only finds two of the four data races
static data races in face sim in fact
the reason for missing those two is one
of the reasons I mentioned earlier the
right and the read are so far apart that
the right is no longer in the cash
whenever the read happened so there's no
event to see there it misses it sorry
but one thing I do like to brag about is
the rebar or the the anything that's
highlighted in green here data races
that were actually non benign where I
know benign is kind of a bad word when
you start talking about data races but
not ad hoc synchronization variables etc
these were races that we reported the
parsec developers and they will be
fixing and well my patches will be
fixing in the next version of parsec and
my favorite story about that is in fact
freak mine because it was 13 times
faster I was able to run the benchmark
the first time see that there was a data
race recompile it with debug symbols on
run it again try to hunt down exactly
where this is around a few more times
and find out exactly what the problem
was all before the tool ever came back
to give me the run times for the full
always on raid array stir sector 13
times faster is quite a bit faster so
right and I also ran this on some
benchmarks that I don't list here this
was the rad bench sweet
the race atomicity violation and
deadlock benchmark suite which is a
collection of nasty concurrency bugs and
this was over all the ones that had data
races in them and over all of the static
data races in a these programs this
demand-driven tool is able to find
ninety-seven percent of the ones that
the always-on tool is able to find the
only the three percent comes from those
two that I missed in facing question
then all these raisins are right before
we and then there are no other right
alright so the question because I don't
think there's a microphone out there is
does that mean that all of the races in
these programs are right before beat
data races no in fact let me let me see
if I can blow ahead to that table
sorry there we go this is the actual
table of all of that junk where the the
rows here are the type of data race and
the columns here are in which particular
program so what this shows is that this
still finds all kinds of data races but
it kind of supports our hypothesis that
even say right to read or write to write
data races they happen near other right
to read accesses they happen these
sharing events all happen in Satan
basically the same region of code so
that you can use this one event to turn
on the race detector at the right time
and leave it on for some long amount of
time and you'll catch all those other
data races to accept and face Sam where
those were the only two accesses and
even though they were the right kind of
accesses they were so far apart we still
missed you know when you turn it off
it's going to determine its his trade
off between yes and yes you're right
there is a there is a performance versus
accuracy trade-off if the first time we
see a sharing event happened we leave it
on for the rest of the program will
probably find more stuff like a still
can't guarantee you'll find all of it
right because the data race might be the
one want the one at the very beginning
and there's no more data races so I'll
say is that I didn't look into that
deeply I understand it that's true and I
absolutely agree this was done on a time
a pretty tight schedule so what I did
was the the amount of time that I had
the system turned on after data race was
kind of intrinsic to the tool itself it
just so happened that after something
like 2,000 accesses 2,000 instructions
in that range it was easy to turn the
tool off at that point so but yeah I
found that it only needed to be a few
thousand to get these kind of accuracy
numbers I found that if you made it
really long like if you left it at a
million it was almost always on because
for a lot of these programs the shared
memory access is relatively frequent I
mean you know maybe every 500,000
instructions it turn it would turn the
system on so in that case it might never
turn off it is definitely a knob that if
you were going to do this in a real
product you probably wanted to tweak
that number rather than just do exactly
what I did here
okay so i think i'm going to spend a lot
of time talking about that and I'm sorry
because I haven't gotten to fixing the
other problem here which is great that's
a demand-driven tool but what if it's
always on what if you know I'm sharing
data all the time or what if my
demand-driven and data flow analysis
tool is always touching tainted data
well in that case what I'd like to do is
use sampling to reduce the overhead and
let the user say how much overhead they
want to see or let the system
administrators say my users are okay
with ten percent overhead so what we see
here is a graph of the left side is
where we have no analysis and there's no
runtime overhead and the right side is
where our analysis tool finds every era
can find but the overhead is really
nasty and those are really the only two
points that exists in a taint analysis
system right now what we'd like to do is
fill in the middle here where you can
change your overhead to whatever you
want and what you give up is accuracy so
I might say I'm okay with ten percent
overhead I can find ten percent of every
air that happens that would be ideal
because what that gives you is an
accuracy versus speed knob and and it
also allows you to send this out to more
people so for instance developers right
now sit at the always on always find
every error realm they turn on Val grind
whatever they want to find the memory
leaks and they get whatever it finds but
if you have this column and most users
sit down here at zero in fact the vast
majority sit down at zero they don't
find any air until the program crashes
but if you have this this knob that
allows you to trade off performance
versus accuracy maybe your beta testers
can sit at twenty percent overhead and
find a bunch of errors for you maybe
your gigantic base of end users can sit
at one percent overhead and sure they
only find maybe one percent or one of
they be one out of a thousand errors
that happens but because you have so
many users that are testing it so little
overhead they don't notice it in
aggregate you can find a lot more errors
because they test a lot more inputs than
you could possibly think to try and they
and then there's just more of them even
if they're all running the same input
you know you'll see an error more often
because there's a lot of them so we'd
like to do is do that type of sampling
word you know you have that knob
unfortunately you can't just naively
sample data flow analysis and by naive i
mean the classic way of doing sampling
is to maybe turn on your analysis every
tenth instruction so you have ten
percent over head that way give or take
that works for some types now sees it
works for sampling performance counters
for instance but if you do that for a
data flow analysis things fall apart so
the gigantic knob here or the gigantic
switch here is going to tell us when
we're performing propagation or
assignment or checks in this program so
it's we're on right now because we're
not over some overhead threshold and we
do assignments and propagations like we
showed before in the example quite a
long time ago however we go over our
overhead I don't want to spend any more
time analyzing this stuff so we flip the
switch turn it off and so now when the
next instruction reads an untrusted
value why is untrusted and we're using
it as the source for this that's we skip
the propagation instructions because
that's overhead that we can't deal with
right now so now Z is untainted we
trusted implicitly however similarly
this validation operation also gets
skipped so when I show validate X up
here the first thing you might think is
well just you know don't skip those but
validations are not easy to find any
movement of data in the program can be
an implicit validation maybe the source
of a move instruction of a copy
instruction is untrue or is trusted and
I copied over some untrusted value so
now that value is trusted again so if we
skip that instruction that does the
validation for us now in the future when
we turn the system back on because we're
under are some overhead threshold we
start on we don't trust values now that
we should so W is comes from X and we
never decided to trust X anymore so we
don't trust w now and that means that
when we perform the checks we get very
different answers than what we saw
before so sure we get false negatives on
Z I mean that's implicit in any sampling
system you're going to miss some errors
but the bad part here is that we now
also get false positives we thought that
what W is supposed to be trusted here
and we say there's an error there so now
we can't really trust any answer that
the system gives us so I mean that's
probably a bad way to ingratiate your
developers you give them a giant bunch
of errors and say some of these are
right in some of these are wrong have at
it so we'd like to do then is instead of
sampling code instead sample data
so what that means is that the sampling
system needs to be aware of this shadow
data flow and instead of being on all
the time and having this metadata flow
look like this instead what we'd like to
do is over multiple users look at
subsets of that data flow and anytime
you want to turn the system off rather
than just skipping instructions what you
should instead do is remove the metadata
from that data flow and just not
propagated in some way and that should
help you prevent these false positive
problems while still reducing your total
overhead so just as an example of that
in this case again big switch doing the
same example I've showed a few times
systems on do the initial propagations
go over your overhead the system turns
off and you skip this propagation into a
you skip the data flow of this
propagation now this looks very similar
to the sampling instruction case right
sure but you also skip the movement of
the data flow from X into X here and so
therefore when you turn the system back
on w is now trusted as it should be and
so yes you do get false negatives any
sampling system is going to have that
but you no longer have this false
positive problem of course the question
is how do you skip the data flow for
this validation I just said earlier
finding these validation operations is
not easy I can't just say of course turn
the validation system on so instead what
we can use is this demand driven system
I mentioned earlier to remove data flows
that the system is too slow so in this
case this is the same setup I've showed
many times before where your metadata
detection your virtual memory watch
points are down here at the bottom and
as you send instructions through and you
update program state eventually you hit
some metadata and you turn your
instrumentation on and maybe this time
your inspiration is on for a really long
time eventually you hit some overhead
threshold the user says I don't want
more than five percent overhead I don't
want this program to be too slow it
makes me mad I'll close the program I'll
go install Linux or something so once
that happens you chuck you basically
want to flip a coin you don't want to do
this deterministically because if you do
this deterministically every time you
run the program you get the same answer
and that defeats the way you do sampling
but if you win or lose the coin flip
depending on what you want to
call it you clear the metadata from that
page you mark everything on that entire
page is implicitly trusted and now
whenever you run operations that touch
that page they work in the native
application or if they are still
touching metadata you would eventually
clear some of that so what that does is
it removes metadata from the system and
lets you go back to operating at full
speed and it does sampling in that
manner and again continue to frag dudes
in quake 3 so built a system that did
that this is kind of a complex prototype
so let me only try to explain this here
this was a the way this demand-driven
taint analysis worked is you have
multiple virtual machines running under
a single hypervisor the hypervisor does
this the page table analysis the virtual
memory watch points and if a virtual
machine touches that touches tainted
data the entire thing is moved into qemu
we're killing you does taint analysis at
the instruction level the x86
instruction level and then eventually
you could move the entire virtual
machine back to running on the real
hardware so what I edit here was this oh
hm this overhead manager that watches
how long a particular virtual machine is
in analysis versus running on real
hardware and if you cross some threshold
then it flips a coin for you and
forcibly untain stings from the page
table system and that then allows you to
more often than not start running that
virtual machine back on real hardware
and your overheads go down so there's
much like before there's two types of
benchmarks you can run on this the first
is does this actually improve
performance can we control the overheads
that's one axis of that of that accuracy
versus performance knob however the
other one is do we still find errors and
if so at what rate so there's two for
those two categories I want to just talk
about the benchmarks a little bit so
because anything that comes over the
network is tainted the worst
applications that i showed before were
network throughput benchmarks ssh
receive is just this server constantly
receiving data over an ssh tunnel and
throwing it into dev null so everything
that it does is working on decoding this
this encrypted packet that is entirely
tainted and so vast majority of your
work is is tainted and the whole system
slow is 150 times slower
and what we'd like to see is that as we
turn the knob we can accurately control
that overhead and then there's these
real-world security exploits so these
were me digging through a list of ex
like some exploit database online and
trying to get these to actually work
these are just five random benchmarks
that our network based and that have
either stack or heap overflows so
there's well first let me start off with
the performance analysis so the x-axis
here is our overhead threshold the
maximum amount of time we want to stay
in analysis without turning the system
off while the y-axis here is total
throughput where that is analogous to
performance in a network throughput
benchmark the blue dashed line is when
the there's no analysis system at all
how fast does this run in the real world
when you're not doing taint analysis as
you can see here as you go from the
system always being on where your 150
times slower as you turn this knob and
reduce the amount of time that you're in
analysis you can basically linearly
control the amount of overhead that you
see in the system so when you're down at
ten percent overhead you're about ten
percent slower so great that's nice and
in fact this worked for the other
benchmarks that I don't show on this
talk but so right we can control
performance what about accuracy well
first things first if all you're doing
is receiving these bad packets that's
going to that are going to exploit these
programs even at a 1-percent maximum
overhead we were always able to find
those errors but that's not fair most
servers are not that underutilized so
what this benchmark does is it sends a
torrent of data through ssh receive all
of that is benign it causes no errors
however at some point in that torrent of
benign data you send the one packet that
exploits the program the bench the
benchmark program and the y-axis here
then is the percent chance of finding
that error from that one packet finding
seeing the exploit and having a taint
analysis systems say AHA caught it I'm
going to report this to developer that
they have a problem and then the x-axis
here is five different bins of total
performance so when you're up at ninety
percent threshold where you know your
performance is still pretty bad ninety
percent slowdown say you can still catch
the air most of the time but I think the
interesting part of this graph is over
here at ten percent we're like I
mentioned before your performance is
only ten percent below what you can get
without doing any analysis at all and
still for four of these five benchmarks
you get to find the error about ten
percent of the time which means that we
do look quite a bit like that bar that I
showed way back at the beginning of
course apache is a little bit more
difficult because its data flows are
very long and so it's much more likely
that you will cut off the data flow for
performance reasons before you find the
air however even in something that's
pretty nasty we're still able to find
that air one out of one out of a
thousand times at only a ten percent
overhead so you know great we have some
type of sampling system doesn't assault
that and I think that's the end of the
talk I just sit back up slides so I can
take any questions or arguments maybe
somebody doesn't like this maybe
somebody loves it how general are these
results so you doing this cutie of you
Malaysian were you looking for
particularly exploits here you know is
it can you do other kinds of analyses
yeah I guess the question is and this is
just for ssh receive right yeah sure so
the question there for the microphone is
is how general is this so this is a
taint analysis system a very particular
type of change analysis system in an
emulator for some very specific
benchmarks so actually when you said it
was just for ssh receive i think that
any type of benign application would be
would work for you earlier yeah so
actually we found out that ssh was
really nasty right as performance is
really really bad for other throughput
benchmarks that didn't have as bad a
performance these go up you have a
higher chance because there's less the
systems on less so you have a higher
chance that it's on when the error
happens now we're the last one of the
last parts of my dissertation is to
actually look at this for dynamic
balance checking things so i think that
it will work but i can't give you any
quantitative data but those are i would
wager that on the whole for applications
that are this type of dynamic data flow
thing you'll do pretty well unless your
dynamic data flow is really really
really long because extremely long data
flows do poorly with the system like
this because you have to have the system
on the entire time and if you turn the
system off anywhere in the middle you
don't see anything below it one thing i
will mention is this is kind of a bad
case for this because the taint analysis
system here is extremely inefficient as
i showed way back at the beginning they
found it was a hundred times slower he
has 150 times slower when it's on all
the time there are tools out there for
instance mini mu is the big one right
now that was released maybe six months
ago they say showed that for a very
specifically designed dynamic analysis
engine they were able to get about 5x
overhead for taint analysis and so if
your baseline overhead is much lower
than you'll turn the system off less and
again your accuracy will go up what I
can't guarantee you is the accuracy for
of these benchmarks I think that these
are representative of the type of errors
that you see in the real world I got
them from real-world exploit mailing
lists but uh you know this might not
stop Stuxnet you know that might have
been a really really nasty air I don't
know such as the
life of security when you're not doing
purely formal analyses you kind of have
to go with what you have sorry to
explain again how you got from that ss8
to receive numbers to kind of projecting
them on together five benchmarks um so
do you mean so the question was how did
I get from the SSH receive members to
project them on the other side you mean
these numbers or so this this blue this
blue bar is not real data right this is
just you know do we get some type of
linear ability to reduce overhead and
still find errors but if I take that off
does that make does that make a little
more sense or I guess what do you mean
by that question so how did you measure
or populate this percent chance of
detecting it
so you'll see here the way we did it was
doing these tests a lot of a large
number of times turning the system on
waiting until you go outside of the
overhead the window that we set so
basically turning it on for a while
sending in a whole bunch of packets that
are not going to cause an X point
sending in the one exploit packet and
seeing if we caught it doing that a
thousand times or 5,000 times so the the
error bars here are ninety five percent
confidence intervals in the mean of
detecting it over the number of tests
that we ran your actually your results
not just along yes this is this on a
real system what is ssh receive running
in background how does that relate so if
the it ssh runt d running in the
background relates insofar as if you
don't have all these benign packets
coming in that aren't causing errors but
are still performing tangent you have to
still perform taint analysis in this
demand driven system if there's nothing
going on in the system and i send an
exploit packet in for every one of these
benchmarks I always find it even at a
one-percent overhead because the system
is off for all the time because it's a
demand-driven analysis system the one
packet comes in and it exploits the
system in a tenth of a second so even
you know at a one-second overhead we
still find it so but I thought that that
wasn't fair right i mean i put that in
the paper i could even make a table for
because it was just yes we win but the
idea here is that in a very bad
situation where you know your server is
really really busy and then one exploit
packet comes in this is this is still
the chance of finding that air in this
really nasty system
know anyone else otherwise sounds like
I'm a backup / hardware any hardware
support for the stem right so you know
clearly you could do better with Hartley
so funny you should ask the sampling
data rate or the the data flow sampling
system originally came from a paper that
we wrote actually dave was on that paper
to back in micro 2008 where we did it
entirely in Hardware where the way that
we did sampling was we had a cache on
chip that held your metadata and if that
overflowed you randomly picked something
out of it and threw it away and that in
such a way you could do the sub setting
of the data flows but I also have the
thought that you know one of these took
virtual memory one of them took
performance counters and i think that
there's hardware that you could add that
would work for everything in fact like i
said i have a paper comin up in less
than two weeks at asp loss called a case
for unlimited watch points where if you
have a particularly well designed watch
point hardware that allows you to have a
virtually unlimited number because it
stores them in main memory and has a
cache on chip for them you can use that
to accelerate a whole lot of systems not
just taint analysis or data raise
detection but deterministic execution
transactional memory speculated program
optimizations etc i'm trying to make in
other talks that i get the hardware
companies i try to make the case that
they should pay attention to that
because it's not just one piece of
hardware that accelerates one analysis
but it's one piece of hardware that
works for a lot of people life laggards
I guess
right so you could use it for that as
well it could relate to lifeguards OE so
I see what you're asking you you mean
the guys at CMU yeah right so I think
that if anyone built a system that
allowed you to have any type of fine
grain memory protection that would be
great where you can use lifeguards you
can use mondrian memory protection you
could use mem tracker there's a whole
bunch of other systems in fact I
compared four or five of three or four
of them in the paper itself in
particular I think that those systems
are not designed in such a way to be
generic for lots of different alyses
that aren't just data flow analyses the
lifeguard stuff and and forensics mm
tracker out of Georgia Tech is very
optimized for taking a value you know
seeing its metadata and propagating it
if you're instead worried about setting
a watch point on all of memory and
carving out working sets those work much
less well because most of them store
watch points as bitmaps so if you want
to watch a gigabyte of memory you have
to write a gigabit of bits rather than
just saying watch the first bite through
the end and then break it apart though
yeah if somebody ended up throwing
fine-grained memory protection on a
processor you could probably figure out
how to use it to do all this stuff and I
you know wish someone would do something
like that people have been citing
laundry memory protection for a decade
now and it's nothing built up so my
argument then is if we can get enough
software people to say we need this then
maybe they will build something like it
rather than just saying it only works
for memory protection it should work for
everything thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>