<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>TechFest 2011: Applied Sciences Group: Smart Interactive Displays | Coder Coacher - Coaching Coders</title><meta content="TechFest 2011: Applied Sciences Group: Smart Interactive Displays - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>TechFest 2011: Applied Sciences Group: Smart Interactive Displays</b></h2><h5 class="post__date">2011-02-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QVhgUs3_RGU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is steve BTW SH and I manage
the appliance repair and Microsoft and
one of the main areas of research for us
is working on smart interactive displays
today I'm going to show you about five
different demos all the way from
capturing light from the user to sending
light to the users eyes here we'll start
here here we have a research project
where we simply ask the question what do
we do after touch and you know as you
know mostly touch screens today they can
only see the things that are touching
directly on the screen that's why
they're called touch screens but we want
to explore the area above the screen
right above right over here and so you
can see what we've done is done this
front projection system we have a
projector up there and a camera right
next step from production system and we
have a very special screen here it's
actually a retro-reflective screen with
this mesh on top of it to diffuse the
light that comes from the projector what
the retroreflective screen does also is
send a lot of the light from the
projector back out to the camera and
thereby any object in the path of that
retroreflection is a really strong
shadow allowing us to pick up those
images and apply computer vision
algorithms to them computer vision
algorithms that allow me to for example
do this paint application and draw right
above the screen without really touching
it doing simple gestures like the closed
loop so one of the main areas of
research for us is actually this some
fundamental areas of research for us is
building this wedge optical component
and it's a very special flat lens that
allows us to put it behind the display
very much and capture images very much
similar to what you just saw in there
but the images are actually traveling
through the display and you can now we
can see things that are right above the
screen and and right almost on the
screen so just to give you an example of
how those images may look like this is
an example of another wedge that we have
and I'm going to hold it up to the
camera and and capture my hand through
the display and that's exactly what's
going to happen here in this coming
prototype as you can see here here's a
transparent OLED and a wedge underneath
it and we have a camera looking through
the display and we're capturing images
not all that dissimilar than what you
just saw over there in the really bulky
from projection prototype so you can see
I can actually in this prototype I'm
relating a mouse and one of the things
that we're able to do is also a
guesstimate how far we're away and
thereby also incorporating a Z dimension
to the interaction and I can move and
move the mouse back and forth using
gestures right above the screen without
touching the screen so so in this in
this interaction we're able to
investigate gestures that are on and
above the screen in a much more
practical fashion and a much more
thinner form factor using the wedge
component what we're doing here in this
demo is use the wedge optic and reverse
and actually put light shining light
down the wedge and controlling and
steering where light goes and if you put
an LCD right on top of that wedge you're
able to actually steer a left eye and a
right eye image to create an
autostereoscopic 3d display and I'm
really excited about this because it's
actually never been done before in this
form so let me show you a little bit of
the basic principles behind how that
actually works so again using the same
wedge optic which is not exactly the
same it's actually something that more
looks like this without this overhang
but nevertheless using the same wedge
optic and I take an LED or a flashlight
and you can see that you can see that
narrow strip of light that's coming out
of display well that narrow strip of
light is actually headed towards the
camera which you can imagine if your eye
and if i move that narrow strip to the
right with by moving the flashlight to
the right i'm addressing the left eye
right i left eye right eye and if i do
that really fast and and at the same
time putting the right image on the LCD
i can create two separate images one for
the left eye one for the right eye and
that's all you need to do to actually
get a depth perspective and create a 3d
image and so if I turn now here and what
happens is the Kinect camera that I have
a bear tracks my head and see where I am
and and immediately turns the display
towards me by simply addressing the
right set of LEDs that are down here on
the along the edge of the strip and one
of the neat things we're doing we're not
just creating a 3d display but because
we're tracking the head using Kinect
camera relative to the display we're
actually able to reorient or actually
change the view of the display as if
you're looking through a window at that
3d object that's inside the
play so if I move my head left and right
left and right you can actually see I'm
weary rendering the 3d scene as if
you're looking from the left side and
the right side of the display and even
if I move back and forth it look like
I'm putting my head in through the
window and out through the window and
all the while delivering a 3d auto to
scopic image without glasses in this
demo we're going to do something very
similar but instead of shooting a left
on a right eye image we're going to
shoot a person one and a person to image
thereby you can have two people looking
at the same screen but looking at
completely two different images and so
I'm looking here at and I'm actually
seeing a cheap pot and most my buddy
over here is person to what do you feel
most I see a skull yeah so easy come
something completely different than I do
and even if we got up and moved and
switch positions because we're actually
tracking the person and sending the
light you I will still see the teapot
while my buddy will still see the the
skull so one of the known exciting
concepts and virtual reality is to
digitize a pane of glass give the user
of the sensation that they're actually
looking through a real glass window and
we can do that with some of the pieces
here we have a Microsoft using a Kinect
camera on a 3d display we can track the
user's position in relation to display
in 3d space and then we render the image
as if they're looking through a glass
window and so here I'm going to turn and
look at a look at my position you see
the Kinect camera that you're tracking
me and if I move my head to the left and
if I move my head to the right as if i'm
actually looking through a frame and you
can see here is that you know imagine
looking through a picture frame if i
move my head to the left and right you
can see the relationship between my head
the frame and the person i'm looking at
or the object i'm looking at actually
changes and if i move up and down and
that is actually what's happening here
so if I look I point down you're going
to expect me that I'm going to be
looking at the ceiling if I lift my head
up I'm going to be looking at the floor
if I move closer I've also going to be
looking at more of the scene because my
viewers increased and you can actually
see exactly what's going on by that 3d
rendering of what's actually going on so
you can see if I move left my view
changes to the right and if I move right
let me you changes to the left so
putting these pieces together along with
3d input and 3d output you can start
heading towards some of the
magical interactions that happen in the
envisioning video where the kid walks up
and in the classroom and puts her hand
on the wall and give their the sensation
the person she's talking to and
interacting it is on the other side this
is one of the core components that you
need in order to do so</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>