<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keynote - Predicting the Future of All Life on Earth | Coder Coacher - Coaching Coders</title><meta content="Keynote - Predicting the Future of All Life on Earth - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Keynote - Predicting the Future of All Life on Earth</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/QA5Hw_h7erU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
hi I'm very pleased to introduce to you
dr. duper's he's the head of the
computational ecology and environmental
science lab at microsoft research in
cambridge UK and a little bit of his
background he studied the College in
Cambridge and went on to get his PhD in
ecological modelling at University of
York correct how was it wasn't sure
about that one and after that he was 46
years postdoc fellow at EE be in the
apartment in Princeton and besides his
many publications in very important
journals and supervision he also
lectures at Cambridge University and he
acted up he acts as a treasure of the
British Psychological Society which I
learned just turned 100 years right the
bridge ecological society not not true
okay so he's talking to us about a very
exciting field of computational ecology
thank you to all right how hi everyone i
know some people were probably here
yesterday we had an afternoon shoot well
I was I took an afternoon tutorial
yesterday so I'm for those of you that
would come back you know thanks again
for sticking with it hopefully there
won't be too much there'll be some but
hopefully not too much overlap between
what I'm going to say in the next hour
and and what we did yesterday afternoon
so however this is one of the area's
well it will overlap a little bit i just
want to show you the web page route for
our group here it is and i think
actually i need to zoom in a bit like i
did yesterday as well so we have this
strange group i suppose of is called the
computational college in environmental
science group and we are all people with
backgrounds in ecology and yet here we
are within Microsoft Research in
Cambridge surrounded
mostly by computer scientist and so
that's not something I ever expected
it's a big surprise to me that Microsoft
started that group and I join when I saw
that they were advertising for people to
join but the work we do has as the name
suggests this computational flavor and
in particular we're interested in trying
to make quantitative predictions about
various aspects of the natural
environment and as I'm sure you
appreciate that's not an easy thing to
do the natural environment is very
complex and it's not very well
understood is very it can be very hard
to do experiments and very difficult to
get the data sometimes I joke a little
bit saying that the reason physics has
been so successful is it's because in
explaining the world such as because
it's created little worlds that it can
understand it can predict you know so
you create a pendulum and you put it in
a room with no airflow and etc etc and
then you go hey presto I can explain it
which because very impressive but we
don't have that luxury we actually have
to look at the real hot nasty difficult
world out there of trees and animals and
the oceans and the atmosphere and all
the rest and so traditional ecology has
not really been able to and you could
even say as perhaps often not not tried
to try to make quantitative predictions
it's typically split into three
different camps if you like there's pure
theoretical ecology so there lots of
where we'd have equations that represent
how we think the world might work and we
analyze those equations to get some
insight into how things might work in
reality but those traditionally that
wouldn't have any connection with data
we'd have I'm in two forms of empirical
ecology one out in the field we can
think of kind of like natural history
but but obviously more sophisticated
than that and then finally there would
be controlled experiments maybe in a
greenhouse or so you create a little bit
of ecology to study and and it's been
fantastic and it has we just heard you
know the British ecological society has
just turned a hundred years and we could
look at all kinds of interesting
findings about nature that those three
approaches gave us but what they haven't
given us is what the world
is now asking for which is these
quantitative predictions about how
various aspects of ecosystems might
change in the future in response to
things like climate change land-use
change altered co2 concentrations
invasive species pollution
overharvesting the list goes on and on
and of course combinations of all of
those so that's where our group comes in
we try to build those sorts of models
there are of course other groups around
the world that do that but in addition
we have a second part of our mission
which is to try to develop software to
enable a much broader range of ecologist
and other scientists to become involved
in this kind of predictive modeling and
to share the results of those models
with decision-makers so that's that's
you know that's the group I wanted to
show you some example projects so here's
one for example this is my scientific
focus before I joined Microsoft was
mostly about trees and forests and in
particular trying to model how the
structure and species composition of
forests emerges from the biology and
interactions among individual trees so
the individual trees grow and die and
reproduce and compete with each other
for light and over top each other and
somehow what emerges bubbles up that of
all of that is the variation in forests
across the world that we see and the
forest in this region in Brazil look
very different to the forests in Britain
for example so here's some some example
modeling we've done where we've taken
about one and a half million also data
points these are individual trees that
have been monitored so we know how
they're growing whether they died and so
on and these maps are showing the and
then we've put this through that they're
kind of Bayesian type modeling that we
do a lot of and you'll hear a bit about
that in a minute to generate these maps
so this this one here is showing
northern temperate hardwoods so we've
aggregated several species together and
this is how their growth rate varies
across the eastern US this is the
mortality and this is the recruitment
and this is the same thing plotted in
climate space and we can look at
different species like southern
temperate conifers or be real hard words
and then what happens is we can then do
simulations where we spread all of the
trees equally and at low density and
they're very small all over the whole
country and let them fight it out and we
see what happens and on the right hand
side here you can see if we look at
northern temperate hardwoods this is the
real pattern of northern temperate
hardwoods and on the Left will see what
the model predicts and so as this as
they fight it out that this particular
group starts to lose in the south and it
does fairly well in the north and you
can see that and then it eventually
starts to lose out in the north and ends
up adopting a midlet a mid latitude
range which is what we see now it's not
perfect the model hasn't been fit to
this data this is an independent test so
it's pretty good and we can look at
other groups to like here's them no the
northern conifers for example as we go
forward we can see that they end up
adopting a northern range like we see in
reality and so on certain work that my
postdoc or marc van de ville he's moved
on now is the University of Florida did
but but for me that was almost like the
culmination of years and years of really
trying to and this is the first time
that's been done in ecology to my
knowledge taking multiple species and
looking at the individual behavior and
biology and then explaining how those
interactions lead to the geographical
distributions that we see so something
I'm very excited about here's some
different modeling that another one of
my postdocs Tim newbold has been doing
this is for tropical forests and here
where this is in terms of the model is
much simpler it's um a more sort of
correlative statistical approach but
still done very rigorously again within
a bayesian context and this is showing
the projected impact of deforestation on
four different groups of birds I'll
sorry this is the overall diversity of
birds and this is herbivorous birds and
the prediction here is that although
deforestation reduces the diversity of
bird species in the Amazon in this case
in the Amazon region
and to a lesser extent in the seasonal
dry forest here the impact on
herbivorous birds is very small whereas
the impact on frugivorous so that's
birds that eat fruits and insects birds
that eat insects insectivores is much
larger so we're able to by gathering
lots and lots of data together and
applying these methods were able to make
predictions about how deforestation
might affect bird biodiversity and you
heard from Tony hey earlier about you
know the impact of similar methods in
other areas like medicine and so on
right you know nowadays we can take
large amounts of data and put them
through Bayesian or other machine
learning methods to make these kinds of
predictions and on very different end of
the spectrum and actually this is work
that Tim newbold has also been involved
in along with two other post lots Mike
half foot and direct it and saw we've
tried to build well I'd say uh I'm going
to be a bit stronger we have built what
we're calling a general ecosystem model
so this is certainly not a correlative
model this model actually tracks every
individual organism and I need to
qualify that everything multicellular so
even the very very tiniest multicellular
organisms like the tiny rotifers and so
on that you get in soil and up all of
those individuals in an ecosystem so
typically it may be 10 to the 13
individuals in a grid cell and what
happens is individuals go through
processes like metabolism so where we we
burn fuel and they then go through
processes like predation so if you're a
predator you go and eat other things and
if and whatever kind of animal you are
there's always something trying to eat
you so we simulate things eating each
other and if you put on enough body mass
then you have spare mass to reproduce so
you make copies of yourself so little
copies of you that then go on to
metabolize and and eat other things and
develop things mutate and evolve in the
model so when you reproduce the traits
mutate and find you this dispersal so
the individuals can move between grid
cells are actually tracking every single
organism within each grid cell and when
we simulate at the global scale
simulating every multicellular organism
on earth now for those that are
interested in computation it won't
surprise you that we don't actually
simulate every single individual because
there are too many but what we so we use
some computational tricks so we group
individuals into cohorts that are
similar in their properties and that way
we can approximate that individual based
model but the model is written for
individuals and that's just a
computational step 2 then approximate
the behavior of that of that whole model
and we had an article arguing for that
approach recently in in nature and you
can actually run the model for one grid
cell just on a on a laptop I was going
to do that in front of you but it tends
to lock up my laptop a bit it's a bit
old this laptop so on but it you can run
it and if anyone wants a copy then once
we publish the model it will be open and
so if anyone wants to alter the model or
play around with it you'll be very
welcome there we go live demo here so
here's some of the the output that can
emerge out of a model like that this is
what we call the trophic pyramid maybe
secondly here we are and so we end up
with this is the plant biomass then we
have the herbivore biomass that's
animals that eat plants then we have
omnivores animals eat plants and other
animals and finally carnivores the only
other animals and we can see this this
this pyramid building up where we have
more plants and it goes goes down like
this and this is the transfer of energy
between them but I remind you that this
this is not the model this is an
aggregate view this is an emergent
property of the model this is an
aggregate view over it this thing is is
emerging from the interactions between
trillions of individuals and things like
the body size distribution and then when
we run it for the whole globe we can
look at correlations like this so this
is the along here and I know there's no
text but is then the net primary
productivity so this is the rate that
carbon goes into the ecosystem and this
is the equilibrium biomass of all
animals combined blue is the ocean and
green is on land and then this is
separating
again according to her befores omnivores
and carnivores so we are able to it's an
interesting scientific challenge
obviously to try to simulate every
organism on earth so we can explain how
it is that the structure that we see in
ecosystems emerges from those individual
interactions but also we hope that it
will be useful for understanding how we
can look after the world's ecosystems
better so here's a simulation where
we're allowing the model to settle down
for a while and then we hit it with a
perturbation and in this case it's
called hamp so this is when you you
starve the ecosystem from below in
effect so you remove plant matter and
you can you use it for human purposes
and therefore there's less plant matter
to feed the animals and although you
might not be able to see it here if we
look at the equilibrium biomass of
animals against hamp is what we call a
tipping point where up to about here we
have very little impact so the system
are equilibrium in the hamp and we get a
similar biomass of animals but suddenly
hear it drops off a cliff and the
ecosystem collapses and it's those sorts
of nonlinear non-intuitive patterns that
you can get from this kind of process
based model that you tend not to get
from the more the more correlative
statistical models and then here's one
of these where we're combining two
different pressures so along here we
have the this is the hamp again the
plant plants removed for human purposes
but up here we have harvesting of wild
animals so this is people going in and
harvesting mammals for example from the
ecosystem and then the color scheme here
is the proportion of simulations in
which the ecosystem collapsed and you
can see that if we have harvesting of
wild animals then we can see an
ecosystem collapse with much less hamp
so one form of pressure on the ecosystem
makes it more sensitive to another form
of pressure now that ecosystem model
itself is actually fed by this carbon
cycle model so to get you to spin up
that whole ecosystem model you need to
produce that you
simulate the dynamics of leaves and
carbon because that's what ultimately
feeds the ecosystem and that was another
one of our major projects this is by
Matthew Smith in our group and what we
did was we we do we defined a model for
each location on Earth of how the carbon
cycles through that place so the carbon
comes in from the atmosphere through
photosynthesis is then allocated to
leaves roots and stems those three pulls
decay at a rate that goes and they go
down into the soil and then in the soil
it goes through two or three different
pools fast and slow pools I think
salman's talk about the century model
yesterday so this is like a simplified
version of the century model and
eventually makes it back into the
atmosphere but the point is that each of
these rates and there's fire involved
but each of these rates is is dependent
on the climate and what we did was
instead of instead of invent those rules
we got lots and lots of data about the
carbon cycle from across the world and
we threw this exact model into the our
fills back tool this is our metropolis
Hastings sample of it some people saw
yesterday so we you saw some very simple
examples but it should be just through
this thing into the same tool and then
we have the world's first fully data
constrained model of the terrestrial
carbon cycle so with that we're able to
use that to feed their madingley model
the gem that the ecosystem model I
showed you but this is important in its
own right too because the the behavior
of the terrestrial carbon cycle is one
of the largest sources of uncertainty in
the future of the global climate and so
now and the reason is that there are
lots of models but they haven't been
constrained against data and therefore
they disagree so we have this huge
uncertainty about the carbon in the
future and now with the model like this
we can at least have a model that is
constrained against data so we can make
rigorous predictions and i also have a
movie that matthew made explaining that
and this is um using worldwide telescope
and i know some people have seen that
before but you also had a tutorial from
Rob fat man yesterday and it's just here
I want to try this can anyone guess why
I decided to put some Joni Mitchell
music to go with the tour on this i was
running it's a song woodstock oh that's
right so why would I pick that song for
this can anyone get it right okay now
the only thing is this is being videoed
right so I'm a bit worried about the
copyright on this song so I've been
really torn about how Dyl torn about
whether i should instead sing the song
because i think if i sing it i'm getting
a rigorous head shape from carol and not
much reaction from anyone else so i
think that the opinion in the room is
against me singing which I'm quite
relieved about so we'll leave it so also
joni mitchell's really hard to say if
you've ever tried so I think we'll put
it in and if it has to be quite a does
better so there is some obviously a more
important point here which is that we're
able to this is looking at the
individual data sets and then we'll see
the model predictions in a minute but
there isn't a more important aspect to
this a serious aspect which is as we
heard a little bit from dan Maffei
yesterday to as scientists we tend to
shy away from this kind of stuff because
we think why would I spend time working
out how to do some groovy graphics and
even think about the music to go with it
right but there's but especially now you
know that the world is really interested
in ecology and environmental science and
if we want to reach out to them and
explain our work we might need to move
outside the PDF article and to think
quite radically about things like this
so things like this ever do have a
potentially important role to play in
them in the science as well so it's not
just a bit of fluff but it is early in
the morning so I think you deserve
did you hear that the lion is we are
Stardust billion year old carving it was
the only song i could think all that had
carbon in it and say so she is amazing
sushi and it says that the next lines go
we are golden but we're caught in the
devil's bargain and we have to get back
to the garden ok good old Joni Mitchell
it's written a long time ago but is
still true so where are we we are ok and
we've got something I've got some more
work to show you so what we've showed
you so far has been about modeling the
natural aspects of them of the world
right so the carbon cycle things that
are we're if we are perturbing and
affecting them but but it's important if
we're going to make a joined-up decision
about how we look after the world that
we also model human processes so I've
just got a couple of those well this one
semi semi human so this is some work are
we starting to a model global
agricultural productivity and its
potential response to climate change I'm
just looking at this in one of our tools
here so we'll do slice it my crop and
scenario and what we can look at then is
in this little tool is the potential
yield of wheat across the world and how
that might change in a climate change
scenario let's go crop five here is
wheat so you can see that when we run
the model now we capture the the fact
that we yield czar highest in Europe and
then they're also high in China and
Europe and eastern North America sorry
but as this what we're doing here is
doing a 4 degree warming scenario and
you see that thing responding and if we
zoom in a little bit on somewhere like
China let's say we should be able to see
that see the red is a higher yield so in
this in this particular grid cell for
example you know five point two tonnes a
hectare but under a 4 degree warming
scenario we're looking at something like
4.6 so we've lost about a fifth of the
wheat yield according to that coded that
model and so we it's obvious that we
need to think about that because it's
important to know whether we're going to
be able to feed ourselves in the future
and two things are happening climate
changes occur
ring that that's what this model
addresses it's also important to
remember that every plant on earth is
experiencing a co2 level that none of
them have experienced in their recent
evolutionary history so we really don't
know actually how plants will respond to
high co2 you may have seen the headlines
that we've just gone over 400 parts per
million for the first time in incredibly
long times in so we really need to work
out actually whether we are going to be
able to feed ourselves but equally
agricultural productivity or the lack of
it is the ultimate driver of land-use
change was one of the major drivers of
land-use change of global scales so when
we're thinking about simulating
deforestation in a region like the
Amazon or African tropical forests for
example then the rate that rate is going
to depend heavily on what's happening to
agriculture so you know again it's it's
about moving a little bit outside the
traditional focus that we would have in
ecology and think we can study the
natural ecosystems as much as we like
but if we really want to project the
effect of human activities on the
natural world we have to think about all
of these different aspects including the
human aspects and as I show you in a bit
we're also modeling deforestation in the
Amazon for example so I know that was a
very long as kind of half of my talk but
i just wanted to to give you a flavor
for the variety of of modeling exercises
that we're doing and of course as again
we're only one group among several in
the world that are doing this kind of
work so the rest in the rest of my talk
I just wanted to talk a little bit about
what it takes to to do this kind of work
and especially I think where things need
to go in terms of our overall approach
to the science and the tools and as I
want to talk just a little bit about say
actually why do we need these models I
don't think that's going to take very
long so I'm going to skip through that
but then more importantly how can we
build them and how can we share and make
use of models like this when we come to
how can we build and we think about this
pipeline here from data through models
to predictions actually back and forth
and this idea of open modeling which I
think people there'll be several people
here that have thought
about oprah modeling but it gets hardly
any coverage compared for instance to
open data and yet it's at least as
important and how can we make that how
can we share and make use of them and i
want to show you a couple of our tools
there the fetch climate to tool and to
talk a little bit about what i think of
as defensible decision-making so the
need for i forgot to put my picture in
look predictive model is very simple i
mean to make any joined-up decision
about anything in life we have we make
predictions and if you're buying a house
you would think about many different
aspects i'm going to inform that
decision all of which are about
predicting about the future and we do so
and but the reason you would not usually
use quantitative modeling for that it's
probably because there are too many
factors and they're too personal but
also we have very good instincts about
most of those things so you've got a
good idea about whether you'd like a big
house or a small house or cetera but we
we don't have very good instincts about
the behavior of ecosystems they're too
complex they can do things like these
tipping points of course we already do
predictive modeling for various other
things that we have very bad instincts
for like aerodynamics the global climate
system or the economy it's all we're
calling for words to do that kind of
predictive modeling for eco systems to
enable us to make a joined-up decision
but it's important to to realize that if
if models like this really are going to
inform important decisions like taxation
policies and juice change policies and
so on that those models can be defended
so here we've got the scientist
defending his model this is called the
defense this picture I found it
somewhere so the idea is that you know
actually it's the very real possibility
as a scientist that if you do build
these models you're going to have to
defend them to people that matter and
this says is going to become much more
common I think in the future and so how
can we do that how can we build these
models and make them defensible and this
is what i call the defensible modeling
pipeline and the general general idea
here is that we have the models are
really hypotheses about how the way how
the world works they may not be the
usual yes no hypotheses that we're
trained to think of in school
but there might be that the mathematical
laws that we think relate various things
but they're still ideas and then on the
other hand we have data that pertains to
the natural world too and if we put
these together appropriately in a
bayesian inference step then what this
gives us is two things it gives us a
refined idea about how the world works
so we and this is the most important
thing in the long term is that we
increase our understanding of the
natural world but at the same time we
get parameters for the model so each of
these mathematical objects comes with
parameter values so we get a reduced set
of objects with the parameters to go
with it and then this gives us and with
those two together we can go and make
our predictions with uncertainty so in
general we know how we know how we
should be doing defensible modeling and
we can extend that picture of it to to
think about well once we have this we
can then feedback from these results to
work out which data we should be we
should be collecting next you know what
what's that what which which bits of
data would have the greatest impact on
our understanding and on the parameter
values and therefore on our available
ability to predict but while we're doing
that while we're improving the models in
the science all the time we need to be
involved in a two-way dialogue with
decision-makers some politicians here
from Britain who themselves need to be
involved in a two-way dialogue with the
citizens that put them in power and the
truth is that's the messy world that
we're in if we want to do work that's
relevant environmental work that's
relevant that's the way we need to think
about it so if we go through that
pipeline there are several technical
challenges I think and I just thought I
would just step through a few of those
now and i wanted to show one of them
which is thing called fetch climate and
again i know some people saw this
yesterday but this is our attempt to
take so so one of the main challenges is
in doing environmental modeling the
models always depend on environmental
factors like the climate temperature and
precip and so on and so when we when we
come to do that pipeline we need to take
whatever
data we have and supplement it with
environmental information and that one
step can be incredibly difficult and
time-consuming again and again so we've
tried to build a tool to two huge I
accelerate that I can show you here and
this is this is open now it's called
fetch climate so it's fetch climate to
cloudapp net it's an html5 tool well
actually fetch climate is really a
back-end service that sits on the cloud
on as your and then one way to access it
is through this UI here so it's being a
bit slow on the network so we'll see how
we do that's the slowest I've seen it
yet yeah I'm connected to the Wyatt with
a Wi-Fi Syria and this that demo I
showed you earlier was over the internet
so I'm definitely connected away oh here
we go so what we get is the idea is we
ask it what we want so for example that
we could have a look at air temperature
but then notice that we don't ask for a
data set here that's the traditional
thing you see is it's a data set I asked
for actually the information that I
really want which is air temperature and
underneath here you can see a set of a
set of data sets that in principle could
fulfill queries of our air temperature
but they're different some of them
pertain to the past some of them are
predictions about the future and some of
them are climate ology data set so these
are things that are supposed to
represent an average condition and they
have different spatial resolutions and
different temporal resolutions and
different error structures and so what
fetch climate is going to do is
depending on the details of my query is
going to choose the appropriate data set
and that actually the way it does that
it has a set of rules so it eliminates
some it then runs the query on all
remaining data sets calculates the
uncertainty and returns the fetch with
the lowest uncertainty so it's doing I
like to think it's doing the kind of
thing that a lab assistant would do if
you said can you get me a grid of
temperature for this particular place in
time they would make a judgement and
it's making those judgments for you or
you can override those if you want so
then we choose a time horizon
so we could choose an average let's say
over this this period of years this is
or we or we can step through the years
let's say in individual steps and you
see that so if we do that we're going to
get data that's indexed by year whereas
under this option it's going to just
average over that period same same
through the year so we can step through
month by month or we can average over
the whole month and same for our of the
day so we can potentially do some quite
complex fetches here like we can get a
maybe a seasonal cycle for so that is 12
monthly values for each year over 30
years you see things like that or a
diurnal cycle for each day of the year
tho those sorts of things and then we
pick a region in on the earth somewhere
so given that I'm here we may as well
pick somewhere around Sal Paul dough
which is somewhere in south this is well
there we go I knew it was here roughly
there we go so we put our grid there and
we say and this is going to give us a 30
x 30 grip but we could change that and
finally we hit fetch and all of that
stuff's going to happen in the
background now the the fête cheese can
be a little bit slow there because
there's so much going on in the
background but let's say this thing I
would guess would take 30 seconds or
something obviously that compares to not
only how long it would have taken to do
it normally which would be a huge amount
of time but also chances are if you did
this the manual way you would have
compromised on something because if you
had the data set it wasn't quite right
but there's another better dataset but
you'd never downloaded it and never
learn to use it what are you going to do
you're going to use the one that's not
quite right right practice so the idea
is also the quality of the data this
produces information should be better
but so does a bit slow but we can come
back to that later so that's fetch
climate and I encourage you to give it a
go if that's at fetch climate to
cloudapp net and we but we had a lot of
time with fetch climate yesterday right
you guys and
and actually I wonder if I've got
interested me because it does some fetch
climate does server-side caching so if
you do the same query wonder if this one
here is going to know all the query is
included in the URL and if you repeat
the same query it will be very fast so I
wonder if this one's going to work see
there we go that's nice so this is this
is one of the queries that we did
yesterday and because we did it
yesterday was stored on the server so
when I just run it again because it was
stored in my browser it was very quick
and so we can just hover over there and
have a look at how the precipitation
varies across the country according to
that particular fetch okay and I imagine
we've got some other ones in there see
ya here we go quite a few of them what
about some bum ball is that the one we
just did let's find out okay and here
this is looking at them a ten-year time
slice for air temperature over central
brazil so here we can look at how those
temperatures vary through time and if we
hover the mouse you should be able to
see we can look at the time series and
you can do as many grids as many points
you can make that a high res grid index
than by year by day of the year or by
hour of the day as much as you want so
that's fetch climate so that's one of
our technical challenges is the idea
that that makes it very easy and quick
to go and get the environmental data
that you need to drive your models so
the next step and this is something that
I personally don't think our group has
thought enough about and I know there'll
be some computer scientists here and
some more generally scientists something
I would encourage you to think about and
perhaps contribute to ecology which is
how we can best define models the
traditional way of defining a model is
through a PDF article and that's a
really bad way isn't it well I mean I
guess it has its purposes but and so the
normal way that I would use someone
else's model is by reading a PDF article
and then coding it again from scar
match myself which seems a bit
inefficient I think we would agree but
how else can we share models well we
could use generic imperative languages
like C++ that's my kind of home that's
the one I'm most comfortable with but I
recognize the fact that that's not
really a very good way to share models
either reading C++ code doesn't really
tell you often very obviously how the
models really works and a lot of the
code will tend to be quite specific to
the environment that you're running it
in we also have generic functional
languages this is some F sharp which is
what's in our distribution model at all
and I think that languages like this
have a huge potential there's the
computer scientists out there will
realize that the elegance and value of
functional programming which is a really
incredible thing and and so and for the
kind of work that we do is probably much
better actually to use functional
languages often than imperative
languages but nonetheless these
languages have still not really been
designed to for environmental modeling
let's say they're very generic languages
on top of functional languages or any or
different languages we can develop
domain-specific languages here's an
example from our sister group which
studies computational biology in
Cambridge so over colleague Andrew
Phillips and he's developed several of
these this is one called spin and you
can see in in here that although it
looks kind of similar to the F sharp
this has actually got some specific
constructs for the domain that it works
in so if you look there's RNA and DNA
and they're actually special words in
that language so this is a language
that's been designed to specify a
particular kind of model for a
particular domain in this case
interactions between genes we can also
have visual languages this is one this
is a an image from a language called
simile which allows you to appointing
click and build a model just visually
but I think in the end probably what
we'd want is some combination of all of
the above and what that might be i think
is hard to say so I'm just I don't have
anything to show you if I my group for
that I just want to point out that it's
a challenge
so but on technical challenge three is
saying like so now you have your data
and you've been able to specify your
model somehow now you need to train the
model to the data and this is where the
Bayesian inference comes in and we
talked about this yesterday in the
tutorial and the main thing I would say
I would stress again is that it's
becoming possible now to constrain much
more complicated models to data using
Bayesian inference so at one time you
have to tailor the model to the problem
so that you could train it efficiently
in a computer but it's now becoming
possible to specify a model an arbitrary
model of how you think the real world
actually works that model will tend to
be mathematically and computationally
inconvenient because the real world is
inconvenient but nonetheless we can now
fit those models to data just like we
used to with the generic models so I was
having a chat earlier about someone with
someone doing species distribution
modeling and so this is modeling the
relationship between the environment and
species presences or absences or
abundances biological species like and
the models that are used in species
distribution at the modeling at the
moment are these more generic models
that have been developed by computer
scientists and statisticians by and
large to be mathematically convenient
but nowadays there's no reason why we
couldn't do species distribution
modeling but where the model at the
center is a much more ideas rich
representation of how we think the real
world actually works interactions
between species and non-equilibrium and
time lags and all sorts of things those
way to show you that here we've got a so
one of the techniques that makes it
possible to fit very complex models to
data is called metropolis hastings MCMC
sampling this is the idea you have your
modeling your data and you do the
sampling and you get your parameters
outs as simple as that and also i should
say if you have alternative models then
you're able to also compare different
models as well as parameterizing one
model so you can make a choice between
things and
way increase your understanding of how
the real world works so if we just zoom
into this thing this is a little sampler
to help people understand it's not this
is not really a working tool but you can
choose a model here you can read about
it have a look at the code that would
implement that model in C++ can have a
look at the data so we've got some exact
example data to have a look at but then
if we run what happens is this this
method it's very very generic and it
goes on a random walk through parameter
space I know some people will know this
already but it goes on this walk and it
settles down to a distribution which is
which is centered on the the most likely
parameter values but then has a cloud of
uncertainty around it so we never just
get the best parameter values that's
very important in the Bayesian world we
always get a spread of possibilities and
that's important because we're then
going to propagate that spread of
possibilities through the predictions so
that our predictions have uncertainty on
them which is very important to decision
makers and so if we go and run this
thing we can see it coming in from the
cold so it starts out here but the best
values are down here somewhere off the
off the screen and you can see that it's
it's hunting out and it's finding the
best parameter values but after a while
so the black points are the most recent
so many points it settles down on this
kind of banana reshape and this thing
here is what's called our posterior well
this is these are samples from the
posterior probability distribution so
the most likely parameters for these two
parameters is here most likely
combination but this represents the
spread of uncertainty notice that that
spread is is highly correlated and is
nonlinear both of which mean that a lot
of traditional methods would not be able
to deal with that but it these methods
are extremely robust so that's kind of
fills back in action as it were and
there are other alternatives to phils
back though it's stress so this feels
like you're just one of several very
generic mcmc samplers now so
traditionally this this kind of work
required you to do a lot of clever and
tuning of the algorithm to make it work
but nowadays we can just throw a model
at it and the thing can tune itself and
sort of an adaptive mcmc as it's called
and they're as fills back is one of
those but there are two others that
we've tested that we're very impressed
by one is called Stan and one is called
a DMB so I encourage everyone to have a
look at all of those so we've been able
to get the data specify a model fit the
model to the data to get parameters so
what do we get next look oh that's right
I'll show you that in a think we'll
finish on that one I just want to show
you that obviously the things I showed
you where in separate pieces and so
we're now trying to work on how we can
join up the whole thing end to end and
we have a thing called distribution
modeler which we tried yesterday and I
think I'll finish on a quick demo of
that so I'll come back to that so now we
have the model parameterised we can now
go and take that and make a prediction
and that might be a prediction for a
place that we've never visited before so
it might be finding potential places in
a country that might be reserved for a
particular species or it might be
projecting the potential yield of wheat
in a place where wheat has never been
grown that's one form of prediction but
another form of prediction is about the
future as I mentioned so how can we
share these models and again I think
that this is only the first step but we
can I showed you our fetch climate to
earlier I just want to show you this
which is a version of fetch climate to
that we built for this conference so we
can have multiple copies of it but in
here with this doesn't just include data
sets so remember before you might do it
fetch for air temperature and then it
would find the data sets that could
potentially fulfill that query about air
temperature well we've now made it
possible to put in models that are
driven by variables that are already in
fetch climate so this model here for
example is or not that one sorry we want
the one called pred soy which would be
here pred soy you see that that's a
simple model that predicts the yield of
soybeans as a function of temperature
and precip so when we call that variable
in fetch climate it does a two-step
process it looks at the model and it
sees that the model needs temperature
and preceptor run we could do this and
so then it goes and does the fetch for
temperature and precip however we've
asked it sort of whatever grids whatever
grid wherever in the world whatever
years whatever days of the week or
whatever it is it goes and gets that
information and it then runs that model
to make predictions and then you and
then you get the prediction bag so what
this shows us is we can actually push
models into these sorts of tools so not
model predictions we're not actually
taking the output of models and sharing
then we're actually sharing the models
themselves so they can be run on demand
anywhere so if we go over to a Brazil
for example we could do this and that's
what's happening there why that why that
spins and again it's hard to predict how
long that might take now that particular
model is very simple just a correlative
model that relates temperature and
precip what predicts the yield of soy
from temperature and precip but there's
nothing in the system here or in general
that would prevent us from using much
more complicated models so we could be
spinning up you know very complex model
here now there are areas of course
weather kind of thing already occurs
like the way we spin up hydrology models
to predict floods in disaster situations
and so on I hope that we'll come back
and hopefully the one we did earlier
will also be there there we go there's
the air temperature around Sal Paulo
remember that fetch so we'll come back
to the soybean one in a bit but also if
we look at some of the other things down
here we have bird species richness for
example so these are things that pertain
to this region and we've got some
deforestation predictions as well which
are where's that one maybe it's called
predicted deforestation let's see
just bear with me just a second and then
maybe I'm going to give up because it's
daddy it's definitely there somewhere
I'm just missing it okay boom boom boom
well we could have the road density
network instead so this is now fetching
effect you can fetch multiple things at
once you can go over them so well here's
the predicted soy yield then which is
which has come back you see so there's
I'll predict a predicted pattern for the
yield of soy then and so yob that that
model had never been run for 2012 on
that grid before it would just run on
demand through that through the browser
and we look at this is a prediction for
the road density network in 2012 and the
bird species richness for example for
that region now if we go and expand this
fetch to go out to 2030 to let's say
then again that will take some time and
i will have each of those on a time
series and will have the predicted yield
of soy for each year 20 years into the
future you'd want to treat those with
some caution of course but it will give
you an idea of the potential
year-to-year variation in soy yields and
will have a prediction for the
development of the road network in the
amazon over the next 20 years so in
principle you could imagine that going
through this pipeline from data and
models to predictions and then actually
sharing not just the predictions about
the model so they can be run as and when
they're needed it could be really quite
transformative because you can pretty
much go through this end-to-end scenario
now live thanks to all of the clever
technology that we have whereas still
most of the decisions that that decision
makers have to make are made on PDF kind
of articles now you know someone runs a
model produces a scientific figure of
some form and it's a kind of dead object
from then on and it's typically out of
date and it may not be quite the the
view of the data that the decision maker
needs and we can completely transform
that with this with it this sort of
end-to-end technology
and then just a you know two or three
final points i meant i showed you this
video already it's important to remember
that what for us is tends to be the
endpoint of our work making these model
predictions available to decision-makers
is the start of someone else's work an
important aspect that they're going to
need to do is to tell a story about how
they've made that decision and how the
different model predictions are fed into
that decision that they can share with
the world and finally we shouldn't
forget of course that all of this
depended on having the data in the first
place and there is a huge shortage of
truly ecological data we hear about the
the data deluge and it's true actually
that we have had a transformation in
ecologically relevant data things like
temperature and precip or even things
like them the phonology of leaves for
example recorded from satellites all
kinds of amazing things like that but
ecology is really the science of
interactions among organisms and we
don't even have that many data on the
presence or absence of organisms in
different places really we're starting
to get some but not as many as you would
think and we have almost no data on
interactions I mean I can't go on to the
web for instance and find all known
observations of a fox eating a rabbit
you know so maybe we just don't know and
yet that is actually the stuff that
really drives ecological models but with
new technology and I think a combination
of new hardware machine learning methods
but also social kind of crowd sourcing
we've got the potential to truly
transform that and actually create you
know kind of orders of magnitude more
information about the natural world the
presence or absence of different species
and even interactions among org and
behavior of of organisms so just that's
just a final point to say you know you
could get all of this pipeline in place
but ultimately you do need that data to
make it all work now I have five minutes
and I was going to show you our
distribution model at all but i'm a bit
torn as to what to do i think i might
not
if you do if you do want to see it there
is a video on youtube anyway so if you
search for a distribution modeler just
felt like distribution model I guess I
can do it here I should be able to put
some text on there but I can't work out
to do it those distribution modeler
spelt the English Way which is 2 l's
distribution muddler then you can
actually see the demo that I would have
showed you I think there wouldn't be the
best use of my time to give that demo
here so and so just you know just just
to backtrack a bit then you know we need
to be able to make predictions about the
natural world to do that reliably we're
going to need to employ some quite
sophisticated process based models of
how we think the real world works but at
the same time we need to nest those
process based models within a pipeline a
rigorous pipeline that goes from data
through bayesian inference two
parameters with uncertainty to
predictions with uncertainty and then we
need to be able to share all of that
with others and if we're going to
improve those models enough we need to
be able to share these models between us
challenge them modify them extend them
mutate them and compete them against
each other and so on and that's what we
mean by open modeling but I've shown you
a know very much I don't want to pretend
that our group has it all down we don't
we have a few prototypes for a few parts
of the at the end to end challenge there
but in general we know it would be
possible to completely transform the way
we do this sort of work and I guess with
that and you know I mean a lot of people
in here most of you they've got a long
career ahead of you you know and working
together we can completely transform the
way we're able to predict the natural
world and therefore the way we're able
to to look after it and with that I just
say thanks very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>