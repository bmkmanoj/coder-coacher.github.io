<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probabilistic Programming the Future of Machine Learning? | Coder Coacher - Coaching Coders</title><meta content="Probabilistic Programming the Future of Machine Learning? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Probabilistic Programming the Future of Machine Learning?</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YloAjSIsRJc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
first research parallel section way to
introduce John win who's the principal
researcher machine learning group
actually a John just told me he was the
number one PhD scholar of our then not
official PhD program started in 99 so
five years before the official launch of
our PhD program when everything was
really informal and in the money
well there was budget available career
in Microsoft no principal research and
he will tell us a little better balance
research in machine learning okay so
this I'd like this to be an interactive
session there's quite a few of you but
if you have questions if anything you
want to ask then please do so and if it
gets super hot you know and you need a
water break and run out and get one okay
so what I want to talk about today is
probabilistic programming this is
something that I've been working on
since 1999 even before that and although
I didn't realize it at the time it's I
think it's a really exciting sort of new
way of thinking about machine learning
and any way of thinking about
programming so if you're interested in
either of those things you're in the
right place
so what said what we're gonna look at in
this hour so those of you don't know
what it is no explain what is
probabilistic programming and why it's
important if you have a machine learning
task you want to solve and I'm going to
dive in on a couple of real examples for
using it to interpret user behavior
using it to half and structured text and
the last section is really going to be
more technical on some challenges on
getting promising programs to run
sufficiently fast
okay so let's get started um so here we
have some code I'm afraid is gonna be
quite a lot of code in this talk and so
what we do is we have this nice piece of
source code and we're going to create
some strings format them together and
then print them out to the console so
hopefully this is fair enough to most
people except that unfortunately our
lawyers have been on the case and
they've redacted some of this source
code and so I can't actually tell you
what Tim needs two black areas here and
happily you can buy our compiled code
and run it yourself and when you do that
what you'll find is that it prints out
hello uncertain world so you're all
smart people you can see the source code
what were the strings under the black
boxes anyone killed brave this afternoon
what's under a two possibilities yes
absolutely
if you have no reason to favor one
string over another then you might say
this 50% probability of hello 50%
probability of hello uncertain and
similarly of B world and uncertain world
like full marks the space is the
constraining factor here so they two
spaces in this strength this space has
to be one or the other
I'll leave you to work this one out for
yourself okay so this sounds like a fun
thing to be able to do well we'll put
some black boxes in our programs and
this is with some essence of
probabilistic programming so let me
write this problem again as a
probabilistic program so what I'm going
to do is I'm going to write in a
language called probabilistic C sharp so
C sharp is obviously a microsoft
language who codes in c-sharp a few
people it's very like Java but the
problem is dixie sharp and we sometimes
call it c soft no joke is is just like
c-sharp except it has a few extra bits
and one of them is this thing called
random what random does is it takes a
distribution I'll be talking more about
this later but it can return uncertain
values so what this says is the result
of this is some unknown string equally
likely to be any string and so if the
most point in the program a has that
value it doesn't have the value hello
you know my favorite string it's equally
likely to be any straight and the same
for B and then we can format and then we
can work with these uncertain values
just like we work with normal values so
we can format them together we can know
if statements you can with loops we can
do all the sorts of things you're doing
normal programs but now we're doing it
with uncertain values make sense yep
defined are they constrained to man the
master very excellent well good point so
the set of strings is infinite
and this is an improper distribution
over that infinite set you may want to
consider if it makes you feel more
comfortable the fact that for the set of
strings if not in fact in because the
memory size of your computer is finite
and the most programmers will actually
put some practical level but it is
actually quite convenient to be able to
work with improper
tribution so when you're working the
straight okay so um so that's an
improper uniform distribution of strings
and then that's an unknown string now we
need to be able to have the equivalent
of running the program and observing the
results so we have another operator
called observe which says that I ran
this program and this was the result
okay not assignment it's a constraint
that says once I did all this
this was the output all right so in this
case I'm saying once I pick a and pick B
once I I have my unknown ni unknown B
and I did this and the result was it
make sense and then the final piece of
the puzzle is that if that's true is
that each mentally insert and I actually
an explanation so we only have to get
back the new uncertainty
once we take into account these
additional observation and so we had
this construction thought that this was
supposed to infer which even about a
variable which has an uncertain value
returns you a distribution that captures
that uncertainty so in this case it's
going to some distribution they captures
the fact that were 50 percent uncertain
and similarly so this is prognostic
programming is very powerful for
programming and almost all kinds of
machine learning but all that I'm aware
of can be expressed as a promising
program and we'll see some we'll see
lots of examples of that
let me just dive into there more
precisely what we're adding to these
shots and make it probabilistic so as
you've seen we have random go
so all the variables you'll ever have
worked with in your programs
I have a thing fixed single value an
integer had length of six or a boolean
variable was true and what we're adding
now is the ability to go beyond strict
single values to uncertainty so an
integer may be uniform between 0 and 10
or a boolean may be visible with
probability at 80% it just means it is
distributed as yes you see the same no
it's very very different
well I'll come back to your knowing good
question so we have observations and
these are just boolean statements to
just say this is true at this point in
the program and so that then has to
propagate backwards up the program in
order to influence the thing for the
board and then finally our in first
statement says given all of our
distributions and all of our
observations what is my uncertainty in
is variable now so here's another
example I wanted to make sure you up you
get this one so here we have an integer
and it's uncertain back on certain value
between 1 and 10 uniformly on each bar
ok and now I'm going to say we have
another variable which is that number
squared what is that greater than 50
it's true if it's written 50 false
otherwise
so this is now a man in variable as well
right because it's just to be 23:07 and
so if we inferred back this distribution
we would get all the answers on the
slide so shout it out yet 30 percent of
the time this is going to be true in 72
yes really good quality so is I is that
a run aside the distribution law is it
value that is get set at that point
based on the distribution and upon
record size is just a variable like an
ordinary variable on a program what is a
variable
it's a named quantity right then you
would pick something out of the
distribution
no it is just an uncertain quantity
right this is a new way of thinking this
does not have it I just not have a fixed
value it has an uncertain value we doing
computation with that on separate are
not equal but they do like distributive
like yeah say bugs has it distributed as
we just use right
so it means take this distribution which
represents some uncertainty and turn it
into an uncertain value and assign it to
us yeah do correction think appeasers
having it like a sampling semantics or
under the something semantics in a few
slides yes absolutely right so I really
want to push on the fact that these are
uncertain values because one of the sort
of disconnects are in my opinion between
computers and people is that people are
continually happy to deal with
uncertainty and express uncertainty well
as computers always require precise
values and often when we're interacting
with and that's at a point to disconnect
and so that's much more natural when
you're programming to be able to program
with uncertainty right how many times do
you retina pregnant that I have to put a
number in here I don't want that number
in so I may point out well wouldn't it
be better just to actually say that I
don't know what that number is okay so
one thing to note is that even if B is
random the output is a distribution that
captures the uncertainty in V is not it
so you can think of this as gating the
randomness in your program all right so
let's look at a standard machine
learning that a question
and that's not going to standard sort of
statistical machine learning problem
expressed as a publicity program so
everyone familiar with linear regression
no one's gonna admit that they're not
it's good so and so linear regression is
you have two variables x and y and what
we want to do is we want to predict Y
connects and the shooting with a linear
relationship between the two a linear
relationship has two parameters a and B
the slope and the intercept so we don't
know what those parameters are so I'm
just gonna pick them from some really
broad distribution okay so that's just
like a can be anything between you know
some - sort of three thousand saying B
who just really brought girls in
distributions and I'm gonna iterate
across some points I'm assuming that
I've got an array of X isn't an array of
Y is that someone has given me so some
scientist doesn't experiment here's my X
isn't it my white and Y need to do first
of all is make my is the equation of a
line so where X multiplied by a that's B
he's a clean version with one this is
not going to match perfectly the way
that I've been given from its experiment
because lines never get exactly few data
points so we need to add some noise to
simulate that process so we're gonna add
some noise with unit variance and then
observe that that is equal to what okay
so this is linear regression easier than
you aggression in one two three four
five lines of code
and then we can infer that a and B and
we fit the line to the point so it's
just a very very very powerful way of of
doing analysis for doing machine
learning very compact question how do
you bones nice one
I just did say they would fit on one
slide and if you didn't want it to be
one supposing you didn't know right and
you can make it another variable until
that variables from sometimes yep
something but the team of you there's no
effect on amb no observations right
observations are very unusual thing
because they have effects that propagate
batches of the burger this observation
constrains tells you something about the
clean one which in turn tells you
something about a and B okay oh if he
were somewhat interpretation of this
shortly that will make make more so yes
please correct me if I got this wrong I
see observers emitting something and
then infer runs expectation-maximization
it's not quite right um so I'll get I'll
skip straight to the fact I think it's a
next slide something interpretation okay
so you're confused about what these
programs will do all right let's work
out a semantics it'll tell you what they
will do this is not how we run the
program this is how we define the
semantics of the program so what you do
is you run the program an infinite
number of times
okay that's important and so you're
going to very hard on the times in some
cases it has to be infinite and random
now does sample from the distribution
notice sample some of the solution
observe will just throw away the run
maybe if if the constraint is false it's
if you hit and observe and it doesn't
apply then you just throw away
everything that you don't start to get
and infer X stores the value of x in
some memory and then when enough axis
has been stored to characterize the
distribution of values outputs that
distribution might be infinite them okay
so let's apply or lots of questions
okay well we can't discuss because so
we'll be talking about this model yeah
so let's go to that process for this
moment okay alright so we pick some a
and B right there so then I suppose we
picked by magic the the actual you pick
some a and B and then we compute a clean
Y and then we add noise to that and with
zero progress with vanishingly small
probability will actually hit the actual
data okay
that's why we have to run this infinite
number of times the ones that we do pick
aids and B's that fitted the data well
they were close enough of the words we
were likely to get some noise and so if
you actually run this you'll get back a
distribution over a and B which are not
quite values around the line because
there's uncertainty in what that line
was but which cat
certainty appropriate I'm gonna have to
me wrong because otherwise I will well
run out of time but then get me
afterwards if you have more questions
okay so we don't actually run
probabilistic programs by running an
infinite number of times we even a very
large number of times there's two
general approaches to many public
programs because I've interpret them
line by lines or you can compile them to
generate sort of machine learning
algorithms to compute the outputs that
they would give and in this building or
in this lab we've been working on a
compiler called infinite net where you
can take a probabilistic program and
solve it for you from wide range of
problems to programs by far from all
probabilistic programs with a wide range
a useful range and it scales and we've
used it a lot and you can get it here so
I won't talk much about how it works but
it gives you that language to give you
that expressivity that you can sort of
Express your program and they're just
they give me the distribution for these
for these variables in the program okay
so why is it important let me talk about
something that actually happened so this
is a ways back now two thousand five
thousand six and Xbox Live came to us
and said we've got a problem
we've got this game which is quite
popular called halo you've heard of it
and at that time well this is actually
2007 there are all these millions of
people playing millions of matches and
what they wanted to do was give people a
great experience playing the game and
what the problem was that they had to
match players coming online with other
players online of similar skill because
if you play some of these much better
than you or much worse than you then you
have a terrible time and not to do that
they have to work out how good people
we have to work out how good 12 million
people were continually every hour of
every day
and so some researchers in lab worked on
this for about six months
wrote an algorithm which was sort of
hundreds of lines of code and and what
it would do is it would take some
Gaussian distributions that estimated
the players skills and then it would
take a particular game and it would
create some new estimates in my skills
this is obviously quite a lot of work
and took quite a lot of time let me show
you example of what it might do so
here's a game and here are the skill
estimates before the game is played so
we have three players Sully he's a new
player we didn't know much about their
skill at all
so we have a big wide distribution then
we have sniper eyes he's an experienced
player played a lot and we're very
confident that his skill is placed at 30
and then we have dr. so play through
some somewhere in between he's not
played as much there's no cry he's not
as good now this game happens and what
happens in this game is that Zoey comes
first so those probably comes second and
dr. slow-play comes third so what might
you expect to happen to these curves
given that outcome what might happen to
Sully yeah shift to the right and get in
get right so here's what happens
and here's what happens to sniper all
right Hey he's down very slightly
because we're already pretty confident
his skill so here's what happens to dr.
slow play he also gets down a bit more
and so the computation is to do that as
I say six months of work with a
researcher and lots of effort and or
this much code in probabilistic mode so
this is a promising program for that
system which is called true skill and so
what we do is we assume that we've been
given the means and variances of the
skills to start with and then we have a
number of players and the assumption of
it is that everyone has a skill
and when you play a game you have a
certain performance you may play better
than you normally do you may pay worse
than you normally do so your skill is
like your average performance and so
whoever wins the game we the person with
the highest performance make sense so
you want to simulate a game what we do
is we say the skill of the player is an
uncertain variable with this mean and
this variance which we took from our
database and then we're going to add
some noise which is like how much your
performance can vary from from the
typical and add that on to the skills
that performance is skill noise then our
observations come in this work can
strange the skills so but all players
after the first one we observe that the
performance of the previous player was
higher than my performance player the
ranking order okay infer skill gives you
the new skills pretty powerful stuff for
that much code and this is being running
on xbox live not using pugilistic
programming since 2005 I think this I
think
infinite last time imagine it is about
8,000 skill updates a second it came to
a point where the beta loading time and
dominate okay so that was one motivation
as to why promise new programming is
important and I just solved these big
problems and small notes okay but um I
would argue that machine learning is
becoming much more common right we've
all got we hear about big data all the
time I hate the phrase but there is a
lot more data around these days everyone
wants to get very useful information out
of their big data sets and increasingly
they're also asking more complex
questions of that data when to build
more complex systems speech to speech
translation self-drive car
personal assistants these are not simple
system to the highly complex systems and
their largest scale okay this is another
interactive set okay so you're all
working on project so I want you to
stand up if your project involves data
okay that's all the theorists like
alright I want you to remain standing if
you want to do some sort of analysis or
machine learning on that data
well that was oh okay and I want you to
remain something if your data is bigger
than 10 megabytes a hundred megabytes a
gigabyte hundred gigabytes very
impressive stuff guys ok thank you very
much so the point is you're all trying
to sell cheap one not all like 90%
eternal self machine learning problems
the significant number of yielding in a
large scale I didn't have a way of
asking you how complex your problems are
but I'm assuming they're more complex in
the previous generation of problems
otherwise you wouldn't be getting PhDs
out of it so all of these things
therefore are true demonstrated in this
room so how can how compromise do
programming help with these three
questions with with addressing or
helping with these three aspects money
ok so my argument is purposely promoted
cause less expertise possibly much less
expertise and it certainly does we still
require expertise but you don't need to
know about all the algorithms that run
to provide the answer you just need to
know how to pose the question you're
still a task in itself I'm increasingly
one of the challenges we face is to make
it easier and easier to use these
program orders you think about
programming back in the sixties or
fifties it was done by mass P with
and that's ordinary program and if they
if you were to ask one of those PhDs
back in those days can you know
programming these computers become a job
that anyone could do you they would say
no you need to have must be issued and
the reason why that's no longer true is
because languages have got easier to use
tools have gotten better and all the
support has gotten better documentation
books training the whole ecosystem if
they're helping people to do it we are
still with machine learning of the stage
we kind of need a PhD to do it and it'll
be great to move away from what I mean
no--don't one opposed out of a job that
there be more PhD and by being shorter
and being written in a standard way
obviously program at programs a
transparent you can look at one so I'm
gonna give you one sake
here's my program here oh yes I can see
what assumptions you're making about the
data I can see what you're doing rather
than handing you in 2001 to the
algorithmic ID twins and then a program
and because they're short you can play
with them as you know I'm sure the
faster the cycle of experiment results
the faster you man the better results
you get so because that's sure you can
say well I'll just try this thing I'll
just do that thing our goal with infant
Nick was to get it so that we could go
from the white board description of what
we wanted to do to actually getting it
working in a day when it used to take
three months and we do that melody
complexity to some extent programming
hides the complexity the program might
be quite complex but the the inference
algorithm that runs behind the scenes is
usually an order of magnitude more
complex so some of it is is hidden away
and also as we start to look at program
languages programming languages are sort
of experts at hiding complexity we had
libraries that higher complexity someone
else built it and knew about that domain
so again all of the tricks that software
developers and programming communities
have developed over 30 40 years
fifty years we can steal and useful
machine with the actual inference
engines are doing hairy mouths even the
best people in the world make mistakes
when they write these algorithms if
they're reusable tested multiple times
they're more likely to be right and
therefore you can build more complex
things and as I said we need to use
tools and support infrastructure to make
managing complexity better
and finally for large scale obviously
programmers say what the problem is not
how to solve it so take that linear
regression
it says dear linear regression if I had
a billion points do aggression only I
could imagine in executing that program
but I'm gonna execute it not on one
machine but on a thousand the change may
be pretty a dumb thing to do because
then the regression but you get the
point right you can execute it in any
way that you like and in doing that I'll
skip over these ready but you can do it
in a parallel way you can do it an
online way very easy all right let's go
to a couple of examples yes is there any
danger of writing this program thing
potentially ignoring complete general
defense works absolutely but that's true
of ordinary programs as well right when
you're writing an ordinary program you
have to be aware of how it's gonna ask
you to some extent right but anyone's
problems may be doesn't run fast enough
or even after maybe I don't know
it's the same here as much as possible
we'd like to make it so it just runs
we're far from that right now we can do
that for some cases but but that one
also true traditional programming as
well at one point so yes having a more
understanding of how the underlying
machine any algorithms work is useful
and but you don't actually you have to
have it you don't have to have it as
much debt yeah
debugging distances to expose so we have
some things this is still very early
days for this there are essentially no
tools I'm very keen on building a
debugger the edge break we don't have
any of that but we're similar notion
will come tasty right that's not a
question I can answer quickly um it will
depend on what algorithm you're using to
execute the program we again we look for
them Phillip method things like if you
tell us the program and the algorithm we
will tell you get Big O notation of of
it but getting that sort of more like as
you're writing you know again unexplored
ground I mean the paradigm example you
can imagine something like this
clustering and we also wanna estimate
bastard and maybe these pastors have all
sorts in the properties
yes so and the distribution complex the
Stratton can be a desert and as well as
the quantities yes so you can define all
these problems that promise
reprogramming I'm not saying we can
solve them yet there are programs out
there that do something that concerns me
so much that they don't need funding
samples I'm gonna I love these questions
are great questions I can chop off the
last chunk of torque and take more
questions so I'll do that okay I think
the church guys did something very cool
they did at PJ's or executing from the
State Farm Aid um and the husbands and
working Microsoft meeting FPGA excuse me
wedding but not I'm sorry a field
programmable gate array it's like
hardware that you can configure on the
fly to do particular things dedicate
other rather than the CPU generally
faster what's GPU was any question yes
yes yet we haven't done yes
so how are they skipped over on the
previous slide but if you know the
program that tells you the full
structure of your of your modeling any
little graphical model which tells you
all the independence and so actually
what we get in the middle of Internet is
a little cooler logical inference
algorithm it's an inference algorithm so
the algorithm that you execute to
compute your inference results but it
expressed a logical way in the sense of
weeds do this computation from this data
and then pass this data to this other
thing and then do this computation so
forth I mean it's exactly it has
parallel structure already so if you
want to execute that on a parallel
Hardware you can we actually do work to
schedule that on a single CPU write it
so currently we have a parallel
algorithm that we don't schedule back on
to a single CPU okay so let me give
someone just says one meter data point
maybe 1 million points is too much but
1,000 points is the program paper to say
this generational distribution or
something I didn't want to get a couple
of examples okay that's scary some real
examples so this is big
it's like Microsoft Google and then we
when people type in a query um they get
some results and rather handily what
will happen is they will click on those
results then I click on the result and
we can track that so we get a quick
table where we get a little true
happening when they click on the result
maybe they didn't then come back and
click on the second one but perhaps they
then came back
on the third and we can track that and
these clicks are gold right
they tell us everything our ranking
algorithms couldn't do so it could
people and so we'd love to be able to
use them to improve our search engine um
and so the naive thing you might think
is well if you click on something that
then we should boost it right but the
simple use a couple of problems with
that you might think of them yourself
one of the problems is you're more
likely click at things at the top and at
the bottom this is a great result of the
button you want to click on it and now
the problem is that you're judging
whether to click on the basis of of
these little snippets here and if we
have a snippet that's that's incorrectly
alluring you may go to that website and
then be disappointed or if you have a
snippet that's that's incorrectly
disappointing you may skip a result that
actually would have had what you wanted
all right so or so if you just count
clicks then you can make these various
kinds of mistakes so how can we correct
that correct for both of those effects
and well we could use a probabilistic
program now here's the thing about
probabilistic programs notary programs
your program in a computer to do
something right doing a program it does
something in promisee programs you're
building a simulator of the world okay
because what you're going to do is you
go attach data from the world at the end
then you're going to infer back all the
things that happened so in public
program already program your program
computer and public program your program
in the world right so here we're
programming a user when writing a little
program which defines how a user behaves
when they see some search results okay
so here's a user and he's gonna look at
some search results they just plugged in
a query you look at some search results
and he's gonna examine the first result
and he's going to decide based on the
snippet
he sees if he's going to click so we
have we assume that each slip it has
some appeal which is a random variable
and so it's gonna be the number between
0 &amp;amp; 1 which is your probability of you
clicking on that snippet for a given
query I'm gonna create the click random
variable using the appeal random
variable in this way and the Bernoulli
distribution is true with the
probability given in the brackets okay
so if appeal is one you'll always
clicking if it's 0 you medical taken
somewhere in between you'll click that
proportion at the time and he's going to
go and look at the website and now he'll
find out if it really was relevant to
his query or not ok so again while
snippets had appeals web pages have
relevance which is the probability that
you will find it relevant to your query
the other place he's unhappy he didn't
find a relevant page despite the fact
that the snippet looked good what's he
gonna do well there's two possibilities
he may give up or he may continue so
here I just hard-coded the probability
that it's 90% likely to commit so it
goes to the next the assumptions and the
small he goes to the next result down
the set of 10 blue links and looks at
that one and again he'll decide if this
snippet appeals to him and he'll look at
the web page and it will have some
relevance and then um this time it's
relevant even if you find a relevant
result she may still choose to go back
to the website to look at some more
results and perhaps that's much less
likely there's any twenty percent let
you down
and so if not we're done so that whole
process a little simulated simulation of
the user can be written in very little
code this isn't the whole code but this
is the important so we have
here we have our unknown appeal and
relevance for each document the Biggs
distribution is a sensible distribution
to use a number between zero and one and
then we this carried below the each user
in document just says if I looked at the
previous document then I have a chance
of a cute this one only if I didn't
click on the previous one and the
problem and this variable which is true
I'll go on if I didn't click I did click
on another variable will I go on if I
did put and then so on for whether I'll
click if I examined it and whether it's
relevant if I click OK then to attach
the data you actually have this now this
log to mail for many users
I think this iterative eases and just
observe the data on to the program
alright so let's see we see it's in
action so here it is this is actually
running so what I have here is the thing
that simulated dataset and I can control
how many people did each of four things
clicked on both of the first ones just
the first and didn't click on the second
skip the first thing click on the second
didn't click on either of them
I'm just looking at T links right now
and what we can see that's the pose for
example that lots and all users in fact
clicked on back what does that
intuitively tell you they click on the
first link then we come back and click
on the second link
exactly so but it was appealing enough
to click on right so what you see what's
happened is the appeal is one of his
first lengths has gone to almost one and
the relevance one to almost zero so
we've learned despite the fact they
clicked on it all the time that it's not
actually a relevant document if a few
more people had not come back then its
relevance would sneak upwards okay if
I'm gonna have more people skipped over
this first document then its appeal
where they've gone down and if what
people skip over both of them its appeal
goes down further so that's already
quite a complex relationship even for
just two links you know ten links it
gets even more complicated and yet using
this program we can compute these
quantities and we can understand what
assumptions it's making about either
behavior you may not agree with them
either might go one two and then skip to
sit right fine change the program to
represent that at least you know what
assumptions are being made when you
analyze the data okay one more
so um I'll finish at the end of this
section those strings are fun with
publicity pros because they're so sort
of much more informative than numbers so
listen this is an example and where we
have a string which is any capitalized
strength that the new capital letter
followed by some lowercase letters and
we're going to format it into another
string
there's a string format so to substitute
this string in where we have this
placeholder here and then we're going to
observe whoops we observe that this
results are equals my name is John
alright
so if you do this and infer name you'll
get back a distribution which is a
hundred percent job excellent right this
is fairly boring you can do this with
regular expressions or even simpler
things so let's do something more
exciting let's learn the template so
this thing here I call the template the
thing with a placeholder in it let's
learn that let's make that a random
variable as well so now I need there's
something more bit more complex as the
prior for the template it's gonna have a
placeholder in it so I'll have any
string and then some non word character
like a space then my placeholder there's
another non word character and then any
string um and actually the only string
is car include placeholders so now I'm
going to insert that of my template and
now I rather than throwing a name I can
infer the template and so I'll get my
name is vital so you can perhaps see
where this is going
what happens then
sorry if I change this strength of my
name is John - hello my name is John I
clicked ahead he was observing so what's
what's the distribution of a template in
this case for the way you saw it right
I'm sorry
so it's either hello my name is blank
well how they Bank thing is John because
both mine and John are capitalized this
is a very dumb program it doesn't have
that name so it says that three strings
together so how can we solve this
problem how can we learn the right
template well I could build with a
fancier for again I could build in some
knowledge about names I could take
census date okay these words are likely
to be names or I could just throw more
data at the problem let's throw some
more data the problem there's not
there's not actually a shortage of text
so we can do that so here we just take a
second name
and a second piece of text but a common
template the template variable is now
shared between the two and another piece
of text hello my name is Andy okay and
now if we infer back the template
there's no ambiguity so not only is the
Nate the name is now John and Andy and
the template is hello my name is blank
this is actually a really useful thing
if you trying to learn tape instructor
extract information from the internet
there's lots lots of text it's quite
easy to find text which is the same text
which with value is changing and it's
very easy to learn templates in this way
you might wanna give one stage further
and say well what are the things I want
to work with are not strings what if
their dates then I want to be able to
with uncertain dates and on certain
strings I need to convert between the
two so this is any date I'm gonna have
to format it into a string and I'm
familiar with how to do that I have date
format commands in my language but I can
take a format they're just gonna pick
but one of these formats
I'm gonna format it to a string and now
I need a template with two placeholders
to it
now if I give it the text fred was born
on 6th of May 1963 and I run the program
then I can pull out the template 0 was
born on one relates train sets of 963
this format the date and the name all in
a handful of lines of code you can start
to see the power of the system build up
complex models of generating tech taps
and real world text and invert it so
let's look at a final example so who's
working on biological applications
anyone a few people great so you might
be funny with this this is a sequence
motif and the idea is that in DNA for
example and you find sub sequences that
have particular biological meaning
and but they're not fixed sequences
they're probabilistic sequences so
certain elements of the sequence may be
very likely to be certain bases and
other ones might be one or the other
another very uncertain indeed so here
are some example sequences of match on
to this sequence motif well here's
another interactive part of the talk I'm
going to show you some data I want you
to spot the motif that is present in
this data put your hand up when you see
it anyone yeah it's a joke you can't
actually do this but his'n is a program
that can and it fits on a slide so the
software you can download to do that
task and here's a slide
it doesn't make key finding probably not
as well but and so what are we going to
do we're going to say we have a motif we
don't know what of this is gonna have a
probability at each character of each
value drawn from some suitable prior
here a deletion a distribution then we
have the set of sequences that you saw
on the slide so we're going to generate
from that Sigma T for particular motif
instance that's going to appear in each
sequence and and we do that by drawing a
an integer format for a build
information and then casting it to a
character and then we're going to choose
where in that sequence the motif sets
and then we need to generate some
background sequence I decided the motif
which we're gonna draw from some
background distribution that we've been
given that's left and right background
and finally observe the result so take
this program take the data I just saw
run the program and this is what you get
pulls out and in fact this was synthetic
data so I knew what the ground truth was
in this case and it pulls out all of
these
sapin says it makes one mistake there
right although that this is the most
probable volition that is shown in the
emit and the gravity does have a quite
high for about me and then it learns
this motif which is essentially
extremely close to the the ground truth
witty so very powerful stuff okay I'm
not gonna do this last section because I
may run out of time I will skip to in
okay so probably sick programs can solve
complex problems you've seen that they
can be very quick to write hopefully
you've seen that too and they can be
fast to execute they can also be very
slow to execute so this is a really huge
area for research so what where do we
need more work this is a new area speed
fundamental thing it's very easy to
write program promise lis program is
very handsome it and run fast
in addition speak it really is if we we
have lots of exciting programs that we
would love to run but we cannot so apart
from that there's also ease-of-use
reliability debugging training examples
books you know build up of experienced
people and all this kind of stuff but I
think we're at year one of year three or
four of you know the of a hundred years
of probabilistic programming and it's a
very exciting time so I really encourage
you to either learn about it get
involved or use it for your applications
and and my hope is in the future every
programmer will be writing Kabbalistic
programs and therefore doing machine
learning thanks very much
my question is indeed secret but
actually I don't see why we need a new
programming language because can it we
wrap all these formalistic things into
something like Mona's and run it on top
of existing we're gonna manage this will
give us exist in wealth reusable
infrastructure such as debuggers
profilers and so on that's a great
question I'm all for that
publicity shot is see shot with just
these three things added the thing is
that because you're executing in a
different way the standard totally the
standard profilers perhaps or some of
these buggers aren't you can use them
but they aren't well-suited
they don't map really nicely because
they're running on me so the generated
algorithm rather than the original
program so there's some but the more you
can use an existing language the more
you can take advantage of people's
knowledge experience of all the wealth
of of tutorials and and libraries out
there and all that kind of thing but
that said making a library that's a
written for c-sharp
run as a promo burst it right there's a
whole other ballgame I'm not aware of
any language that can really do that
because they're generally written to
into complex away but that's something
would like to be able to do and how the
year is working on a way in which we may
be able to do that and that's the part
of the talk I skipped from the phrase
which is how we might be able to get
library like code where we can't
actually get into it to run efficiently
inside a fantastic program
it seems that there there's a high
effort for someone creating one of these
programs to figure out what kind of
model to create and you can imagine that
there are many things he could tweak
okay do i model the click with this of
this variable or doing all of with that
one doesn't forgotten that have
capabilities to compare models using say
cross-validation argue some complexity
penalty or something like that yes so
yes yes in a public program if you have
two programs that you want to know which
one is better explaining your data then
you just say if some random variables
like the program a is better give it a
50-50 distribution and say if a then a
generating the data else be generating
the data and then infer the posterior
distribution and so you can compare
models within the within the
infrastructure of Kabbalistic
programming itself you know actually you
can place it companies built into that
guarantee or since you get yoga reasons
yeah yeah so so I've talked about
obviously program we haven't talked
about how we execute them and everybody
agrees approximate methods and the
approximate methods may be different
than the accurate for two different
models it might be that you give them
the approximate estimate of the evidence
one model may be worse than the other if
you compare two mothers then you may not
know if one is better because because
just a bit so you chose yes but they are
not soldiers in the same oh yeah that is
an open question right I mean most of
machine learning that happens is using
approximate inference and right now he's
known for said yeah so very few of those
algorithms come with any guarantees
yes so infirm that word comes with a few
algorithms general-purpose I was built
in that you can choose between the
expectation propagation which is a
generalization of belief propagation you
may also notice some product there's a
variational Bayes original message
policy may select no it is eeehm
and then there's something give
something lot of good but um there's
three there's three options you have you
can it will actually generate some code
you can actually see the code doing that
algorithm that's running you can then
tweak it in various ways so you have you
have a fine degree of control and over
the way which inference actually
executes or you have a fine degree have
ability you can really inspect what it's
doing you have less controls actually
does that you can inspect what it's been
quite a degree you can step through it
in a debugger machine a workshop on that
next year will it bring probabilistic
programmers and quantum programmers
together because they think or in both
communities think we can learn from the
other so I'm no expert on quantum
computing but it does seem to have some
of the same primitives right it has this
uncertain Louie Anderson's qubit and you
can bind them together and then collapse
those and certainty of other variables
and essentially do us to take a sample
at the end which is very similar to
inference so I'm very excited about the
potential for quantum computing fit so
do you money
that's about as far as my understanding
goes so I think you'll be a really
exciting area to explore</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>