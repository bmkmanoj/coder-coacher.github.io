<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deep Neural Networks for Speech and Image Processing | Coder Coacher - Coaching Coders</title><meta content="Deep Neural Networks for Speech and Image Processing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deep Neural Networks for Speech and Image Processing</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/63_l-wNfemE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
muchas gracias esta mi primera vez en
cancun en el estado de Quintana wrong
que esta de mexico varias veces es un
gran placer para me visited esta zona
muy bonita me gustaria poder estar mas
tiempo pero por lo menos SE podia ver
algo de la selva so i will be talking in
english so I'm sorry about that i
thought i was wondering how to translate
some of the terms and i realized that i
didn't know so i figured this would be
easier plus there are some people that
benefit from it so the today what I'm
planning to do is try to convince you
that if you're trying to use build a
speech system image processing system or
maybe other machine learning system that
you give serious consideration to deep
neural networks and I will try to
hopefully convince you why you should do
so so I will initially start I start
talking about just an introduction to
neuroscience so I'm trying to assume
that you don't know necessarily a lot
about this if you do you may get a
little bored then talk about artificial
neural networks they've been around for
a while and then ah the latest
generation of neural networks which is
called deep neural networks I will
explain why it's called away and the
application to speech recognition so
first let me start by showing that was a
picture this is me in 1990 this is an
office in the basement of one of the
carnegie mellon university buildings and
why am i showing you this because i want
to give you the biggest evidence for you
to believe me that deep neural networks
is big and the reason is because i was
doing my thesis at that time on noise
robustness for speech recognition how to
build speech recognition systems that
are more robust to background noise and
one of my office mates yoshiaki oshima i
was trying to work on the same problem
but he was looking at using a different
set of techniques while i was using more
like what i would call now traditional
machine learning he was looking at
neural network like systems are modeling
the human auditory perception
system and at that time I graduated that
year and he we start at the same time he
stuck around for a few more years
eventually graduated probably because he
had to graduate not because he had
solved the problem made much progress
which meant that from that point I say
I'm not going to touch neural networks
this is not something that works it's a
problem and now I'm a convert so I hope
this is the biggest piece of evidence
for you that you should pay attention to
this because back then I did not like
neural networks I didn't think that they
will work and the reason is because I
saw him crying almost many times
struggling with the learning algorithm
is trying to build the systems as well
this is not aware this is too
complicated by the way if you use some
of the speech systems today in some of
the phones or even connect you will
realize that we still have not fun
solved the problem of doing speech
recognition in the process of background
noise it's still a problem and maybe
this is there is a correlation because
the papers that i published on this
topic were accepted whereas the paper
that we try to publish on canet was
rejected yet that thing worked so maybe
there is how a pattern here I'm starting
to get worried but hopefully now 20 20
some years later we will figure out some
way to to make the systems work so let
me start by describing um the how
neurons work since that's the foundation
for neural networks and the human brain
has about a hundred billion neurons in
each Nero has about 7,000 on average
synapses so this is a diagram of a
neuron this is the body of the neuron
and all these things are the dendrites
they are kind of like the inputs to the
neuron and then here is the action and
here's the apple of the neuron so one
way to look at this would be saying we
have a system that takes all the inputs
which are the connections from other
neurons put some weights which is
essentially the synapse or the
connection between one neuron and the
next with different strengths in
some turn and then they go through a
sigmoid this stands for the sigmoid
function which is this type of function
and this type of function what it does
is that if the signal is much the
combination of signals is much bigger
than the threshold it will produce a one
and if it's smaller it will produce a
zero and in between it's kind of like
slowly ramping so it's trying to produce
a non-linearity either one or zero and
that there is evidence from neuroscience
that that's how neurons work there are
many in the brain and that's something
that you will see is different in and
the systems that we build the artificial
systems but it's interesting that they
are slow I mean we are used to thinking
okay we need fast compute power
gigahertz one takes about a minute
second often to produce a system an
output so how is it that they can be so
powerful we use them for lots of things
and we can is because we have a hundred
billion of them and lots of connections
between them they're also
non-deterministic this is not like a
computer program that will or the same
inputs will always give you the same
outputs there will be some random
components like spikes firing in and out
at different times and you will get
different results so that's something to
keep in mind because that's not
necessarily how our artificial neural
networks work so why I mean I became
interesting neuroscience after we
started getting good results with these
deep neural networks but I can imagine
that there are reasons why you may be
intrigued in learning more their
mysteries here like what is the
difference between the brain of a human
and the brain of primate a monkey we see
the evolution well we have a larger
brain capacity like about three times
bigger is that it it's just because we
have a bigger brain can be just added
because whales have bigger brains that
humans they don't seem to be a smart or
even elephants maybe the number of
neurons well elephants has have as many
neurons as we do so what is
it that it makes us intelligent and they
don't that's kind of an interesting
question also there are like things of
interest in medicine can we cure
Alzheimer we often know someone in our
family extended family perhaps that has
this disease and many others so there
are lots of interesting things that
maybe we can learn by looking at the
problem differently not just on the
doctor medical aspect but by looking at
it from the computing point of view so
what do neurons to well neurons are
built to pick up patterns they see
something that happens frequently and
they memorize it the heavier rule
created by head back in the 40s s
neurons that fire together wire together
means if the input is on and the output
is also on at the same time the
connection between those neurons is
going to increase the weight the weight
of the synapse is going to increase and
that appears to be from neuroscience how
our human neurons work how we learn one
thing that is interesting is the number
of synapses of connections you can see
as the wiring of our brain when the
babies are born we'll have a number of
them we get the maximum after two years
and after that we get fewer and that's
because there is constant creation of
synapses which is connections between
the neurons and also destruction so what
happens here after it stabilize after
four or five years old of age you create
as many synapses as you destroy on
average so it's not like you you have
the same forever you create new ones and
you destroy someone so you learn
something and you forget something
basically so this is the motivation from
the neuroscience point of view so then I
rosenblatt back in 1958 proposed that
perception and that was the birth really
of artificial neural networks so what is
the perception so the perception is
basically a linear classifier that's one
way of looking at it let's say that you
have points if your feature space has
two dimensions in this case you have
feature points here and feature points
here represent
two different patterns may be like
circles and triangles for example and
what you want is to find a line that
will divide and classify both of them so
this would be in this case that line it
would be maybe w 1 times v1 plus w2
times v2 equals V and that's the line if
it is on one side of the line you say
well that triangle if it is on the other
side of the line and then you say it's a
circle or any other well you could also
build this classification with a sigmoid
function you have this term which is
this and if it is larger then you say
it's a one maybe it's a triangle if it
is smaller is the circle this is exactly
the function that the sigmoid function
done neurons use so how do we learn how
does the system find those weights that
do the classification again we have here
the example where in this case we have
three inputs with different weights go
to this neuron and produce an output age
so the way we learn is if we are given a
few samples um where we have some inputs
V and the corresponding label what we
should what the system should do then we
can compute the error the system
computes the difference between the h
and the value of the neuron and the
label and you can square them and add
them up over a number of samples and
what you want is to find the weights
that will minimize that error so H is
the sigmoid function of this so what you
can do is gradient learning the sample
the weights at that iteration equal the
weights at the previous iteration minus
some constant times the derivative the
grain of the end the error over that way
and if you do the math take the
derivative of this you get this function
here ah and this is this the derivative
of the signal which is has this form
what this means is that in this region
here which is up there the gradient is
basically zero so you can really learn
anything same thing here so the only
thing the only time where the gradient
will be non zero and the weights will
change is in the region in this region
here so perceptual learning are is
trying to find a local
maximum is doing hillclimb bit so
imagine that you have a surface say
these are the two dimensions if you
start here you will hopefully get to
this point if you start here hopefully
well it to this point but it cannot it's
not guaranteed to find that global
optimum it will find a local optimum
this is just an illustration in two
dimensions but typically these systems
use thousands or even hundreds of
thousands or more inputs so this surface
is like in a very very high dimensional
space and it's going to have lots of
local optima and whatever this alliance
will do will find just the local optimum
not a global one there was a paper in
1961 by Minsky and Papert that
essentially started the winter of
artificial intelligence and the winner
of neural networks what it did is is
they in that paper they say well there
are some functions are very simple
lightly like the xor function which
cannot be modeled by a single perception
like this is an example where you have
circles circles and the triangular
angles there isn't a single line that
will classify both of them they did not
say that neural networks would not work
they just said that a single perception
would not work but the community read
this paper and stopped working on neural
networks for like quite a few years
because they misinterpreted and Minsky
was one of the founders of artificial
intelligence so he had a lot of
credibility so artificial neural
networks the ideas will not put just one
perception put many of them so here we
have many inputs here we have many
neurons and we have different layers not
just one but many if you do that then
you can learn the XOR function and many
other functions here I use a notation of
one to determine to observe the term be
that was in the question before so it's
kind of like an input that is always
said to one and you learn all the
weights interestingly enough Alan Turing
already proposed new artificial neural
networks back in nineteen forty eight
but he
have not done all the mathematical on
derivations so how do you train these
networks so there is an algorithm called
back propagation and let me explain
intuitively what it does so this is in
this case one year and we have another
one so the output of this one is the
input of the next one so if we look at
what this produces and we compared with
the true label what we like is to adjust
the weights of all of our network to
minimize the number of hours and the way
we do is similar to before we complete
the error function as the sum of the
squared terms and now we take the
gradient and we take the derivative but
when we take this is easy right but when
we're trying to learn one of this we
need to see what is the impact on the
error here in here we back propagate the
air and then from here down and that's
essentially using a very simple idea in
math which is chain rule so you take the
gradient is what we have before plot
times this derivative which is this term
here this again will find a local
optimum will not find the global optimum
but this surface this functions here can
do an arbitrary difficult classification
problem at least in theory assuming that
you don't get stuck into a hill climbing
local optimum so this is an introduction
to artificial neural networks and they
were used mostly in toy problems and the
community started using it for speech
recognition back in the late 80s and you
see a few examples there was a lot of
activity in the late 80s and early 90s
in using artificial neural networks for
speech recognition but then the second
winter of artificial neural networks
came and this time it was not sudden it
was not like a famous guy published a
paper sent this is not going to work
this was what happened is that there was
another technology called hidden Markov
models sure HMMs which became the
dominant technology in the 1990s mostly
because at that time the accuracy of the
systems an hmm or artificial neural
network was about the same but HMMs were
faster to train and there was more and
more data available during that time so
the artificial neural networks guys
could not train with all the data so
they had to train with less data and
therefore they started doing worse
whereas the hmm community could train
with all of the data and they did better
so that's why artificial neural networks
fell out I'll fill out of favor in the
90s but then there was a Renaissance
again this is like the cycle and it
happened around 2006 when an expert in
machine learning famous person called
geoff hinton invented deep belief
networks or deep neural networks which
is going to be which is the new
generation on your networks and i will
try to explain what they are what he was
trying to look at is the fact that a lot
of the times when you're learning
training these networks you get stuck
into a local optimum in which in some
cases may be very bad and very far away
from the global optimum that you want so
it was very important to get a good
initialization so he says well I'm going
to initialize running initializing their
weights randomly as many people have
done before they are he decided to come
up with a new algorithm called
restricted Boltzmann machine rbm which
had been proposed early on but now was
rediscovered and use that to do a better
initialization and once he initialized
that he did back propagation as before
and he tried that on a task call amnesty
which was a set of handwritten
recognition deeds things like this and
God the best results published at that
point so one of the researchers in my
group came to me in 2008 insane Alex I
would like to work on this problem in
the world but you're in the speech group
this is image processing you know
doesn't make much sense
and that's where one of the things that
we value about ms are you need to trust
the intuitions of your researchers so I
said you know not sure I'm convinced
plus I have bad memories from the neural
networks days that is ok you can go
ahead and explore it so he started
playing with that it and became excited
and started getting great results mostly
can do to the good initialization and
then he started applying them to speech
so eventually if you start doing playing
with speech so what are these are BMS
and why I all of a sudden became much
more excited and a believer in these
deep neural networks so imagine that V
is the input and h is the output of a
network if you have a probability
density function that looks like this
that's an exponential model or a log
linear model where E is the energy
function which is a dot product of a set
of weights be and the visible v weights
see and the hidden values h in a product
without matrix waits here it turns out
this is a normalization context it take
turns out that if you compute the
marginal what is the probability of
seeing the hidden values to be 100 0
given that you've observed is visibles
you can do this and normalize if you
follow the math it turns out that you
get this where this term is a sigmoid
function and that's why I said aha this
is interesting one of the reasons why I
didn't really like neural networks
before is because there was the sigmoid
function that I thought that was just
coming because that's what our neurons
use but I didn't know what they meant
there were all these learning rates all
this initialization I didn't understand
but now what we see is that this
function is not just a coincidence is
what you get when this is your
probabilistic function between the
inputs and the outputs it's still the
same function but now you can interpret
things differently we can bring to bear
all that we know about our probabilistic
processes machine learning to this
problem so now if we can formulate it
this way
we can say well we can try it better
initializations other types of of
systems and that's what we started by
the way this has the property that the
posterior polity of the binary abusive
all units is also sigmoid so you can go
this way and that way too and it's the
same function interesting and this is
true even know when the when the inputs
are binary but also when they are
Gaussian same thing hmm so this had like
very nice foundation which on its own
has not improve our accuracy or anything
but allows us to look at the problem
differently than before so one example
is we can say how about if we use
maximum likelihood estimation a very
typical technique for estimation used in
machine learning so what we like to do
is learn the parameters of our system
see B&amp;amp;W that maximize this probability
and well we can try to do that that may
be like a good initialization better
than random weights the only problem is
that this is highly nonlinear but at
least we know what we're trying to do
and we can use some other techniques I'm
not going to go into this other than say
that there is one method called
contrasted divergence that will let you
go iterate back and forth and learn
through maximum likelihood those
parameters I will only mention one
equation here and the interpretation
what this is doing is iterating with the
product of the input and the output of
the neurons from the data and what the
model says and you want this to be 0
eventually if you think about this this
is back to the heavier rule if two
neurons is the input of a if the output
of a neuron that is the input of the
next one and the output fire at the same
time they're correlators like a pattern
there that's what this is measuring some
hmm everything seems to be feeling
together what the neuroscience did back
in the forties hab when he proposed his
rule the sigmoid function that the early
guys Rosen blood and others had done
early on and this in a prolific
formulation so that was kind of
interesting
so what we do now is we do this rbm
restricted Boltzmann machine training
and then we do the back propagation from
that point and within that that provides
a better initialization so how do we use
this for a speech recognition so while
we in speech recognition we have still
hidden Markov models which is a sequence
a network that have states where at
every time frame you can go back to the
same state or transition to the next one
stay in the same state or transition to
the next one and when you are in that
state you emit a symbol this is for
instance a spectrogram which is a time
and frequency representation of speech
that's the model that we use hidden
Markov models that we use typically for
speech recognition so here the output
probability was model as a mixture of
the sum of Gaussian density functions
now what we did is say well let's
replace that by a neural network a deep
neural network like that like what I
just described and everything else is
the same I'm not going to go into the
details of all the parameters suffice to
say that we did this with a
state-of-the-art system with all the
bells and whistles that you can imagine
pretty complex system and there were a
bunch of experiments that my colleagues
frontside it don't you and gangly did on
switch work and what you could see a
switch word is a standard database that
the Department of Defense has set up
that contains lots of people talking
casually with one another and here what
we have is the performance of the system
the best system for this task and after
we do we use the new deep neural network
we go down this much which is
thirty-three percent error relative
error rate reduction this is another
test set thirty-two percent normally
this is unheard of in the field speech
recognition we rarely see from one
technique getting such a big improvement
so we were very excited
so when leading who's the first person
that was working on this told me this I
said check you must have a bug this is
too good to be true but you know had
several people validated and in fact it
was working that well we try on
different tasks to see if he was just
something peculiar for that task we also
got twenty two percent error reduction
26-28 so it was just helping all across
the board so why is it that that this
type of techniques work so well why what
was new I mentioned the restricted
Boltzmann machine the initialization was
that the only thing that we did and I'd
say probably not I think the most
important thing is the increase in
computing power we know about Moore's
law and in 20 years since people for God
about neural networks Moore's law has
grown dramatically right so now the
computation that is available is much
much higher than before and what happens
is that these algorithms were are very
computationally expensive to train the
run time is fast but the train is slow
and now we have a lot more than we had
back then so we can go and revisit old
ideas so that's by far prolly the
largest contribution that alone is not
sufficient what that allows us is to run
more experiments so now we can try many
more experiments different combinations
and many of them don't work but some of
them do so sometimes don't get
discouraged if there is some technique
that you are fighting with that seems to
slow now well maybe at some point in the
future on the computing increases and
all ideas are all but not necessarily
bad that reminded me when I was talking
to Vishnu at all who work at bell labs
for many years and he was the inventor
of the kelp coder speech coder which is
by the way using every cell phone that
you have today and at that time he told
me well you know I never find a patent
for this because when I first came up
with the idea it to compress one second
of speech
e to me for four hours so I said well
this will never be practical never so
you never know these kind of things
sometimes computation is just
intractable at that time maybe it's
going to go beyond your PhD thesis but
it will be a chance to revisit it later
so even despite the fact that we've made
a lot of improvements are on accuracy
like twenty-five thirty percent in
reduction in error rate training is
still slow we still need GPUs which are
very powerful lots of processors to
train this and we can still get stuck in
a local optimum so this is another
problem that we still haven't solved
there are since we started publishing
results on speech recognition a year and
a half ago there was one paper the
following conference that were like five
papers half of them hours and then last
year there was like 20 papers and just a
month ago there was like 40 this field
is growing like crazy so this could
really be an inflection point and it's
not just in speech also a lot of other
applications in image processing as well
so that's why I hope that you will give
serious consideration to this kind of
techniques so this brings me back to
thinking our neural networks there's the
natural ones and there's the artificial
ones are perhaps artificial neural
networks better than natural neural
networks and normally I would say no way
because we have natural neural networks
and we do a lot of experiments like that
much better than machines but the other
day I was looking I was reading
something about the results that test
results of high school students in the
United States and and I was starting to
get some doubts that the natural are
always better maybe on average or some
cases for example i saw this problem and
everyone in this room of course knows
the answer to this
yet our prototypical student this is
what you did find X here it is
unbelievable right so maybe artificial
are not so bad or another question when
they were asking them what is the
language spoken in Latin America our
bright high school student answer Latin
so it may be okay planes don't flap
their wings so maybe they did way back
when and they can fly faster than Birds
so it's not always true that we need to
copy or mimic nature to to build these
artificial systems but it surely has
some come but in excellent dis high
school students by large machines too
much worse for these tasks than humans
so human intelligence in particular
artificial neural networks might do some
day better and there are some folks
predicting that's going to happen one
day but but not yet and perhaps not in
my professional career but for now
artificial neural networks have a lot to
learn from nature and since we've been
getting these great results I've been
learning about neuroscience which I
found fascinating regardless of the fact
that we're doing this for for speech
recognition and found out that there are
few things that our systems don't do and
I wonder is it just because they're
flapping their wings like this or flying
and we shouldn't copy that feature or is
it because it's there for a reason I
mean we look at evolution Darwin taught
us that there are many things that
happen but they are not an accident
there are many accidents and the ones
that work well there are those mutations
that stay so the randomness is one
example so randomness we see that all
these neurons produce random results is
not deterministic but our systems if you
put always the same are inputs in you
get the same output you think that's a
desirable property why is it that human
natural neural networks have this
randomness I wonder perhaps it is
because they
our way they don't get a Cecily stuck
into a local optimum when they're
adjusting or local learning and there is
evidence to set to say that in our
nearest we do not have back propagation
all the learning is done totally local
meaning each neuron is learning
exclusively by looking at its neighbors
so a neuron looks at the inputs and
looks at its output and determines the
synaptic weights that way it has no idea
about anything else but that's not how I
we're trying our systems so I think that
there is a lot of work that we can do
and I hope that some of you will be
motivated to work on this problem to
borrow some of the features maybe not
all about at least explore some of the
features of the natural and the human
neural networks to build our artificial
ones and close by saying that this still
gets me a little bit worried because a
lot of these papers that we've been
publishing have been accepted so maybe
we still haven't figured out what is the
crack the right problem but I hope that
will happen soon thank you very much
thank you very much Alex I think we have
time for one or even two questions you
can ask in Spanish if you want any
questions okay there's one plz mike is
there any question is with the deep
networks as there is sometimes with the
normal back propagation or perceptron
about having too many degrees of freedom
for some problems for simple problems
for Cassandra convention that's a good
question the actually i'll answer one
that I neglected to answer before deep
why is this deep what is the issue with
this deep refers to the fact that there
are many layers typically in the past
when people have built artificial neural
networks there were a maximum of three
hidden layers two or three so but just
calling deep because he has more simple
at first to me a little bit presumptuous
like just one more was a big deal what
happened is that as I mentioned before
the gradients that propagate quickly
turn becomes zero but not here in this
case this is the first time that we can
learn networks with many layers and
still learn them and that's because of
this new discovery this rbm so that's
one thing that I forgot to mention what
you mentioned then is like the number of
degrees of freedom what happens if we
put too many layers interesting enough
what we found for the data sets that we
looked at is that it's actually is the
performance it doesn't get better but it
doesn't get worse typically so this
systems appear to be robust they don't
overtrain we would have for a lot of
machine learning systems they would /
train when you do that and there is some
of these to some extent but by and large
they are much more resilient to
overtraining than most of the neural
network systems that we've built I mean
traditional machine learning system we
built before
okay thank you very much Alex</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>