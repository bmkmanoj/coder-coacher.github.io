<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Panel: Can Projects Coordinate? | Coder Coacher - Coaching Coders</title><meta content="Panel: Can Projects Coordinate? - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Panel: Can Projects Coordinate?</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Dv7nX3sXClI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so I'm on the on the program I've got
this on the program that the subtitle of
the panel is can these projects
collaborate so are planning three
questions to ask this so the first one
is something about software because a
program or software is something where
you the developer tells the user you
don't need to understand this I'll give
you some capability that you can use and
you can leverage my work basically and
that means that the capabilities is
offering must have a clear specification
the clear specification can go to
optimizing a certain mathematical
problem true it just learns which is a
big week and I think all the products
are different because there are
different backgrounds on that respect
and therefore I would like to know for
or each of your project where how you
basically specify what the functions are
doing and how do you verify it works
because then so maybe I should start
with chicken so how much time do I have
like I don't know we already ten minutes
late so oh okay so as we can see from
the presentations that are deep linear
isn't a smallest sing like a in the
whole list of packages so the way we
position live linear is like solar core
part is those optimization algorithms a
result they may actually from our
research results in the after lat then
we have a kind of training and
prediction interface so let go is to
hope that most users lay they somehow
they can easily do the training and the
testing but because we don't have time
to do any to spend too much time on
interface so we don't expect a lot no no
we expect them to prepare data in a
reasonable leave well
patience so then use as a research group
we cannot do it too much yeah so busy we
position our service we do a research on
on the algorithm and to provide a simple
interface and we have the ability to to
maintain a code OLN that's roughly the
the way we do the software ok so so
should I understand that basically you
have an optimization problem you tell
the user I'm going to solve this
optimization problems well a little bit
like okay I go over to John was the next
i guess and i'm going to try two of the
same older which is you feckin so I
guess my ideal of how you specify a
problem is that you don't specify any
representation you just specify sort of
the what should be optimized and then or
what should be predicted in the machine
learning sense so there's things like
cousins to multi-class classification
contextual bandit learning structure
prediction where you can specify what
you want without referring to the
representation and then you know the
hope is it we can figure out through
research how to make that happen in an
automatic and effective fashion so that
that is kind of the interface for that I
strive for towards n VW I don't think we
always succeed and there's certainly a
lot of options that allow you to tweak
representation because we don't know how
to automate them yet that's what where I
want to go so I think Holly of the same
advice well I guess I can do one other
thing yeah so I guess one difference
between the learning to search stuff and
core VW is that maybe the targeted user
base is slightly different so you know
sort of the targeted user base of
learning to search a sort of domain
experts in some other domain who want to
use machine learning and I think the
nice thing that we have now is a very
limited interface that sort of requires
three functions and at least in the sort
of version that's sitting on my laptop
and not push to github yet there's a
fairly well defined you know sort of
semantics like if you give me this this
is what you should expect
out but I think you know the the
interface is also changing because we
don't know the right answer and so this
is going to change over time so I think
GU ha ok so I think my job is easy
because we mainly focus on deep learning
you get no guarantee of what server but
of course I think they're like two two
two two parts to the question one of
them is you get some sort of software
interface that you know that it is going
to be stable and that like I'm going to
answer this question in terms of not
torch but in terms of the neural network
package and the optimization package
which basically what it means to I think
in the context of the question in terms
of neural network package it is designed
for gradient optimization and what we do
how to make sure that when they give
users something there's an intensive set
of tests which basically test the the
Jacobian and the gradient right and
because when you do know networks you
always rely on the chain rule and then
we can test each module individually you
can verify that the that the gradient
computations are always correct so that
is that is one way and the interface has
been fixed for like ten years or so
right now I guess so in terms of
interface stability it is there in terms
of the optimization package which you
can apply any type of a gradient based
optimization into any kind of neural
network we have again a fixed interface
for the optimization which is basically
you take a function which it turns you
the evaluation and the derivatives and
then and then some parameters specific
to that optimization method and we have
a set of small standard optimization
tests to verify that each one of these
optimization methods are actually doing
what they are supposed to do but beyond
that like torches mainly built to enable
people create their own algorithms and
so I don't know how to go beyond any any
of these so it's basically you can call
unit tests at research level everything
is they're going to give the microphone
to ya one thing I'd like to add
Nicholas is not here from the point of
your Facebook is that Facebook obviously
we believe a lot in dog fooding so
whenever any of these packages are
conceived in any way they're like
internally they are available internally
for employees you can use as much as
possible and that helps a lot in sort of
debugging the correctness not just after
at the unit test level but even solving
landscape problems for instance I
actually cleaning the model on the data
from the Tendo point of view the user
specified a mathematical function that
they are no compile and optimized so for
the machine learning it's not on the
piano side we put a very much man we put
much time on the quality of the software
because people rely on their compiler a
scandalous a compiler we want to have a
very high level of reliability we do it
with unit tests but we have also add a
liberal but and we also have a bill body
on get up on each pull request so before
we merge the new pull request there have
been a pretty good test coverage before
Evan we merge on modification but we
went one step further than that for the
grades and when we implement entiendo a
new operation and the financial aid then
we have made automatic a maxim function
that will automatically test that the
great then do the right computation like
what they do in torch and I probably
other software to to debug the Tendo
optimizer itself we have created a debug
mode we'll see what it do is that it
tests all values before and after
optimization it's very slow we don't run
it and get up for each pull request but
we do it in the deliberate so we know if
there's an optimization that trigger a
bad result or that change the precision
of the result we will find that
maybe birth can talk about the firing to
interface yeah so at least for par learn
to is mentioned the presentation it is
partially made for researchers not as
much kind of for for the layman user so
I think although it is possible to kind
of use the llamo files to to start a
like an MLP model and train it with
relatively few lines of code I think if
you want to build any sort of serious
model and pile onto its strength is is
more an its adaptability so I think we
we do require the user to know a little
bit about machine learning and a little
bit about understand the model that
they're trying to code it's not
particularly made for just being able to
press a train button so I think that is
kind of a slightly different vision and
then some other packages yes soon in
sugar and we have all these black box
methods that contain machine learning
algorithms from different families and
so it's very important for us that we
somehow have a unified interface to
combine these things so I think in terms
of what you offer to the users you want
offer something that is really flexible
in terms of mean it was said before in
terms of data representation in terms of
optimization algorithm in terms of
evaluation of your methods I think it's
really important that that it's kind of
flexible to plug these things together
to be able to plug these things together
so that's the first part of the question
and the other one is how do you make
sure things work so we also do lots of
lots of unit testing and we actually
like our whole development process is
spaced its test-driven development these
days because we've had lots of bad
experiences if you don't do this and
especially if projects grow over a long
time we get lots of problems with this
we also will do this Travis stuff on
github and wheels of a boot pot because
we're offering all these different
language bindings on all these different
operating systems so we have like 30
computers constantly building compiling
tests but one thing I'd like to add is
you shouldn't just be doing unit testing
but also if you if you have a framework
that can be used to build pipelines of
you know data some processing doing
something with it and so on and so
fourth you should actually test the
whole pipeline also in this so we be
called this integration testing so we
have we have like examples of pipelines
that we that we run and then we dump the
state of all the objects to file and
compare to it so we have a fight every
patch we have a exact notion of what
states of which object changes and that
turns out to be quite useful you want to
answer this one Daniel Daniel is the one
who does all of this for us because we
started with just me Daniel and Matt in
the office and at that point it was like
we all designed our own little pieces
and sort of spun around in our chairs
and asked people how was going and at
some point I think we went where
everybody else went I mean we started
with extensive unit testing but we took
away the keys from everybody to just
push merges off to our server so
everything's done through pull requests
everything's code reviewed everything's
unit tested extensively mainly on
windows because it's the one machine we
don't develop on but then the developers
all run the tests on Linux and Max and
we have a combination of both unit
testing and functional integration
testing for models where we know the
answers I would strongly recommend if
people are testing gradients that use
finite differences we found more and
more of that being useful for our
complicated gradient calculations just
in terms of tests but we've got all
kinds of crazy testing going on and the
other comment that I think is worth
thinking about if people are going to go
out and build their own project is by
test-driven development I think the
important part there is writing
functionality that couples being easy to
document and easy to test those two
things are very closely related and what
you'll find is people without strong
programming backgrounds and by that i
mean people who aren't used to writing
public api's maybe their grad students
or scientists or something it's very
important to get them into the mindset
of actually writing specifications for
things that are testable rather than
writing these things that are bristling
with controls and have lots of
combinatorics so modularity I think is
key for for testing I just wish I could
convince the rest of my developers
other than Daniel let me meet you in
testing it's very important I think any
significant codebase just doesn't work
unless you have constant testing oh yes
sure but I mean I'm more interested by
the specification part what is the
guarantee that you're making to people
who are going to use the software but
something which is all about these also
what you're supposed to test the bsd
license says there is no guarantee i'm
not sure the point I wanted to make is
its following a bit this finite
differences so if you have well-defined
interfaces for your objects that you can
combine you can actually do some kind of
automatic test generation on them and
that's also what we what we do in
children for all interfaces that are
defined we kind of feed it with like
civilization we with two civilized
objects so we we can do this for all
objects evolved written it's
automatically added to a class or if we
have gradients we we we also do this
finite difference thing we have a check
for this so whenever you you have this
it's added automatically to the list and
I guess that's very important actually
because it's hard to keep discipline up
otherwise so let me try to summarize
what I understood from the point of view
guarantees and you tell me if I make you
wrong I saw three day very different
levels one is just likely be linearly
best vm and maybe stand in fact is you
guarantee the goal the goal is
optimizing a certain problem or
computing certain probably stick values
and the other exact algorithm is is your
freedom as long as you would do it like
Matt can do all these things in the way
you want as long as it computes the
right quantity and children can do
anything he wants in linea as long as he
finds the optimal which is testable
there is another group of software like
us I put VW there and also shogun where
you guarantee that you implement a
certain algorithm pretty much I know if
it's true or let me continue let me
continue in combat so there is a certain
specific algorithm and
you guarantee that you implement this
pretty much the way it was described or
slightly improved in ways that are
described clearly and there is the third
level which is the deep learning code
where you basically you guarantee that
you're going to implement a particular
model and you're going to compute the
current gradients of the supposed to use
the right way is that a good summary of
the situation or somebody think is wrong
I think that's not I mean you can think
about it that way that I don't think you
should think about it that way for what
we want to do and we didn't know so that
this kind of there is a particular
algorithm right now but that I'm making
no guarantee that algorithm with that
that flag will have the same exact same
algorithm in the future I would try to
guarantee that if you have a multi-class
data set you'll try to minimize multi
class class right that's a kind of
guarantee which I think you can rely on
this is something you can verify yeah
you can verify that how you get out a
bunch of predictions in your computer
yes it can verify for a particular
problem you cannot verify that your code
does that always so one of the things we
want to do and in your future actually
is get a very large really different
data sets the test against so what what
I mean here is that the what do you have
an example of software that does do that
rate compile compile our promises that
it's going to actually maybe maybe it's
right okay that's right a compiler
promise that is going to translate your
C code into reasonable assembly code
that does the same thing yeah so so VW
promises that the complex thing we're
congratulating the simple thing says
that you optimize the complex thing
database from a sequel database promise
that it's going to give you the data
that satisfies certain criteria you
don't care it does it and we haven't
reached all this at the same level in
machine learning there are domains that
are more mature like probabilistic
modeling whether the framework is more
material a probabilistic modeling go
or SVM optimization driven things where
it's pretty clear domain was a limit
less mature which is what John trying to
do to solve the problem with
computational running addictions and the
domains were it's still very open like
deep networks accuse me you know the
they still work they still do things so
let's go to my second question so my
second question is about if you want to
collaborate you have to share goals and
I can see Gore's very different in magic
in open machine learning tools from
documenting a particular paper proving
one particular point supporting a
research agenda or taking over the world
so why do you put yourself in that
spectrum so we're going to go in the
same order and just chillin okay so this
is a good question just to ask like why
why we we want to spend time on doing
doing that okay so well so let me go
back to like how I got started to
develop the best view in the year of two
thousand so I my big run wasn't being up
in machine learning okay my PhD was in a
numerical optimization but for some
reason after I started a teaching I
decided to move to mission then and i
found out that it's not easy to write
Michelle to use machine learning
software so at a time I i look at the
court of us vm papers and if I and i
found out that well why labor results
are so good but when i try the software
somehow it's not easy to generate the
same result turns out that most experts
lady the data scaling but they didn't
write that in the pay from it i think
that's too easy for okay visiting their
papers they only right advanced
algorithms or something so I saw world
is not very good visitor time I didn't
even know what cross validation is as
they okay I want to write something that
is useful for me but also for for some
at least four other people who are like
me and
so those are roughly how how do we have
been doing since Lent but but we also
know our comes chance visiting we the
visitor also from my optimization
background I do live as Madiba linearly
behind a lot they optimize Asian
algorithms so so we develop algorithms
to solve them and they put them in a
package and available for users but
there's a smoke group then we cannot
like it to spend time on interface or
something so busy we just try to see
what we can surf and if up and every day
we got males from users and the some of
them they say all because of this
software then then then that helps them
a lot on their their work and then we
feel happy so that's how oh why we are
here okay let's go to John and out so a
VW has primarily been kind of a vehicle
for research so his various research
that I and other people have been
involved in and I guess there's a
particular taste in that research
oriented around things being
particularly fast or overcoming big
obstacles so that's what it has been but
my research program is solving machine
learning and so I think it's actually
taking over the world yes I think kuhar
was next so i guess like for us it's
also similar the main point like four
for the main three of us and i think for
everyone else's we want to do research
and then there are certain
particularities the way you think about
problems and the way you think about
your solutions and you just don't find
something that is suitable for you and
you start writing it and then I think we
also sort of enjoy the fact that if we
start if you write these things in a
general manner others also who would
like to think about problems and
solutions the way we think about those
they would use these
same actually software and it's a cycle
it's going to improve because like more
people use it we are going to learn
others learn from others so I think
because I mean the main motivation is
basically being able to do your own
research the best you can at least like
I think for all the research hope that
is here that is the main motivation
tanda was also made with the goal to
help the research we wanted to try much
more a different variation of models and
we find that it was hard to implement
all of them not to implement all of them
at a high level but to implement all of
them at the eye level with efficient
execution so the goal of the endo is
mostly to try to optimize as much
optimization as it can and that's its
force the support for the research that
use a numerical computation more in
particular what we do in our lab machine
learning as a research job at a
university what bring money is a mostly
grant and the research itself and not
the software so that's what we back up
and partnering to a the enzyme you know
I think it's very important to talk
about reposted reproducibility when we
talk about goals and also think that all
these projects fall in certain clusters
so one cluster is a probabilistic
programming languages so what would be
great i think to have as would be some
kind of system where you define some
standard tasks or problems that i well
suited for a certain class of tools
algorithms and then all these like code
from stan code from ims pmc based on
piano code from anglian or whatever
tries to solve this particular
probabilistic models say and then you
get some notation notion of how the
results compare in terms of time terms
of speed and in terms of accuracy and
you can do the same thing for for black
box black box maze machine learning
boxes so you could have you could have
some kind of framework where you define
okay here's the data set here's a task
on their data set now these projects can
upload their scripts to solve this task
and then you know some there's some
neutral comparison I think this would be
actually a super nice to have to compare
goals yeah our project at least from my
perspective was not started for research
it was started for actually solving
practical statistics problems so what we
really wanted to do was expand the scope
of models that could be specified by
users and solved so it wasn't so much
that we had a particular research
algorithm that we wanted to test it went
the other way around we started with the
problems we wanted to solve started
building it and realized that certain
things wouldn't work and that led to
research so that research is kind of a
spin-off of the project I think the main
thing that keeps people going is that if
you work on a well-organized project
that has decent infrastructure everyone
can put in something and you get out
more than the sum of the parts or at
least something where there's not too
much loss on the contribution so I think
a lot of our users are a lot of our
developers are coming in because
developing and stan is easier than
developing stuff from scratch I don't
have anything to add okay so basically
what all kinds of goals exist so now we
go to the collaborating path so these
are open projects so i'm pretty sure
that anybody is willing to borrow piece
of code that works well if it's good so
let's look another aspect in an open
project you have the code and you have
the community and we are tough question
is are you willing to share communities
we need to promote some another tool kit
within your own community which is the
real litmus test for the collaboration
so let's let's do some of the kitchen
well I think for evil a goal is to help
users whatever the best for users we
would do I think that's just me I need
the answer ok so then then drawn I think
the answer is yes ok so in general
there's a lot of there's a lot of stuff
around the core algorithms and to the
degree to which we can amortize all that
stuff across a bunch of different
projects by having a shared community I
think that's fantastic yeah I mean I
also completely agree and we we sort of
do this by like wrapping up bunch of
stuff like the base vm the linear I
think there's a port of La pop level in
Lua we can call Tiana stuff so yes if we
can share your users if you can share
anything then we should I mean because
none of the projects is a big commercial
undertaking right it's basically people
volunteering their own time and then
like hoping that there is going to be
some advantage to doing this so of
course if there's anything to show you
reach it it's the same i think everybody
agree on that I can I tell more that in
the case of torch and can do that is in
the same feeling of deep learning we
have case where we collaborated on the
same project part of the big project was
in torch part was entiendo depending of
the straight of the project at that time
and I know people in both community that
you said both softwares so there's a
communication between different members
I think the core developer stay on their
side but the user switch more frequently
between the those two different software
Michael yeah so also absolutely yes and
I think there are two sides of this
thing so one side is you integrate other
projects codes into your into your one
so in sjÃ¶gren we have lots of lip SVM
linear stuff and we have actually lots
of people are using here toolbox through
sugan which i think is great and there's
also the other side where you as a
project if you are generally enough you
try to and I think this is actually not
happening that much that projects
actually make an effort to make it easy
so that they're their own tools are
usually usable from other projects so
this is maybe something that there could
be some more collaboration on like
talking about okay what would we need in
order to use the cool stuff you've done
in our project and vice versa I guess
I'm a bit of a pessimist in this regard
and I'm not going to say yes right away
it's very difficult we have difficult
enough time integrating software from
our own contributors in our own projects
when you need to go try to take in
another library it's it's very very
difficult we started we're using the
eigen matrix library we're certainly
using everything in boost all the
templating all the parsers things like
that from boost that we can but i'm not
sure what else we could use from other
projects like how easy it would be to
pull little bits of projects out and
implement them so you know it thinking
of like all the things we're working on
going forward we run into either
licensing problems like we might have
used Doug Bates's stuff or FML but it's
all GPL it's all tied up with the our
libraries so finding things that are
actually modular enough to use we
certainly would if we could find them
but at the level of things like random
number generators we can do that at the
level of like could we incorporate vw's
updates right in our model I'm not sure
how that would would actually work the
algorithms we can definitely share and
re-implement but sharing at the code
level if you're not doing something like
wrapping up a bunch of components is
actually very difficult now having said
that I always recommend people to go use
whatever the right tool is so I'm
perfectly happy and have publicly
recommended that people go use VW or
svm library or something if that's what
they want to do in our software won't do
it so I think most of us are pretty
happy with that I think the people who
actually build these projects tend to be
less true believers than people with a
little less experience good I just
wanted to add that aside from just
wanting to share there's also kind of an
issue of exactly how to a governance
right so how is the check-in process
controlled and i think that's that's
pretty non-trivial actually to settle a
most existing projects when you're just
joining a project then you just go with
whatever that current project does but
if if you're trying to join two existing
projects that's it's a question yeah so
I guess following up on what Bob said I
mean I think so I guess I probably of
anyone here maybe I have the least
ownership over any of these so I don't
really care about sharing communities
and in fact some of my students used VW
for stuff some of them you just live
linear for stuff it's sort of a matter
of taste but like one thing that
definitely struck me during Bob's
presentation is that I I think that
there is space to sort of take models
that are declaratively specified as
probabilistic models and try to solve
them using sort of an underlying
prediction framework rather than
probabilistic inference I think this is
sort of an obvious place where I you
know I think code and communities
potentially could be shared and probably
other people of other ideas mol comments
yes
awesome other people told sharing code
at the low level the implementation
right now there is the benchmark that I
show in the presentation under
convolution I think it's an level where
it is easier in theory to have
collaboration but right now there's many
technical difficulties that make it much
more other that's why one of the goal of
Liberty period if we share the same base
object we can reuse much core much more
code because we don't need to translate
between one object and the other object
there's also another part is if we plan
to make the code to be reused by other
system most of the time it will ask us a
little bit more time as a first
developer and we not always know if
someone will want to use it so maybe
it's too much so as to the original
developer to plan right ahead to do it
but I think something can be done it's
the first second user calm that go see
the projects the code refactor it a
little bit too is the implementation and
if the original author agree to accept
those type of modification that don't
bring new software bunches is the
reusing it will help the turn and forth
and the other people and it will also
help those two user because if there is
update to the code they will be able to
share the new update one way to share
the cottage with a command object live
lipsy period but it's not always easy to
move from the current object we have
something else that can be done it just
like Blass where you have a pretty drab
interface with pointer shape and
dimension and from information like that
so if you improve all the code into such
an interface that make it very reusable
with other
systems so I think it's so different way
to he's the calibration on the code so
somehow the consensus that the sharing
is good but it's easier to share your
little things and high level things and
one questions yet done in addition to
sharing code what about having a uniform
place to share how different different
versions of the code work on particular
data sets right so if I'm somebody who's
trying to choose a machine learning
package and i have a problem that i want
the missionary problems i want to solve
it might be nice to see well on this set
of problems which are similar to my
problem this package performs like this
and this package performs like this and
the spanish performs like this is there
something like that i mean so this is
one slide that I showed we have actually
a benchmark place where we benchmark the
promotional no cafe and so anyway and
since we agree that we all want to
collaborate we're now going to break out
in separate sessions each year microsoft
research helps hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>