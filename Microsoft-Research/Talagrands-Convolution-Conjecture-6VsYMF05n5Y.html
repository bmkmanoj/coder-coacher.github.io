<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Talagrand's Convolution Conjecture | Coder Coacher - Coaching Coders</title><meta content="Talagrand's Convolution Conjecture - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Talagrand's Convolution Conjecture</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/6VsYMF05n5Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright good afternoon everyone so we're
now happy to hear the second installment
in the talk this week and we'll hear
about the telegrams convolution
conjecture or regularization of l1
functions please run it Thanks okay so
yeah this is more or less a direct
continuation of James's stock yesterday
and James was talking more about the
discrete space whereas today stock will
focus on the gaussian version of the
conjecture james stated so just to set
up we're talking about Gaussian space of
RN with this density and we consider the
convolution operator which just says
take function and to evaluate the new
function at X we take the expectation of
F at this this is just a rescaling of X
we add a Gaussian to the point and take
expectation over this Gaussian so this
is just convolution with the Gaussian up
to some rescaling this is sometimes
called the orange tie Nolan back
operator and another way to define this
operator is just to see that this is
actually the expected value of F at a
Brownian motion at time one conditioned
on the Brownian motion at time 1 minus T
okay and as James yesterday yesterday
this operator admit some smoothing
regularization properties so if we take
a function and apply this operator we
expect it to become more smooth in a
sense and one sense is this cyber
contract
every property that just says that if I
know that my function f has some LP norm
then for this P and for any tea I can
stretch p to some Q which is bigger than
P and estimate an have an upper bound
for the lq norm which is a bigger of
course than the LP normal function by
helder given only that I smooth this
function with this operator yeah this
behind else you have gamma is the
Gaussian measure its LP over the
Gaussian measure ah and okay this is a
by now a very fundamental fact in
analysis and has applications to
concentration and isoparametric
inequalities and a question that
telegram raised is whether so so this is
a quantitative smoothing ah result but
somehow it completely fair I mean we
can't really say anything if we only
know that our function is in l1 but note
that even for a delta function there is
some smoothing going on if i take a
delta and convolve it with a little
Gaussian I do get something kind of
regular and it's not clear what the
correct statement or the correct what
quantitative statement is for just l1
functions and telegram asked a very
specific question so the question is the
following also James mentioned it
yesterday so let's let's assume just
normalizer function to have expectation
1 gamma is a standard Gaussian vector
and we know that of course this variable
F of gamma admits Markov's inequality
the probability to be bigger than alpha
is smaller than 1 over alpha
and what telegram asks is the following
is it true that after i do the smoothing
I can improve over just Markov's
inequality by just saying that I get
some see over alpha it depends on on
this convolution on I mean how big the
Gaussian I convert with this but times
some function that goes to 0 as alpha
goes to infinity so I just want to get
some demonstrate some slight improvement
over just mark of and basically the only
result so as James said the telegram ask
this in 1989 but in a discrete setting
the only result known in either discrete
and Gaussian more or less that doesn't
just follow from what you get from
hyper-connectivity which is not much at
all is the result by these are Five Guys
five or four five guys in 2010 which
basically give a bound that depends on
the dimension to now it seems as I'll
try to convince you later that half
spaces should be the worst examples that
the sharp examples in the best
inequality you can find the ER and I
mean this is a typical thing for the
Gaussian measure most estimates we
expect them to be dimensionless so I
mean did this dependence on the
dimension is kind of bad it's also
exponential yes the tiny but I hope is
looking for
oh right so there is also a title but i
don't okay i'll try to i hope you
understand the talk nevertheless this
change is personalized it changes first
slide yes so this slide title is the
letter gene but but ya know but it's ok
yes you you won't miss much so so this
is the result James and I show basically
it says the following given a function
which I know is not tulo concave if i
take if i consider the hessian of the
log it's bigger than some minus some
constant times the identity a good way
to understand this thing is is this is a
function if i do some gradient
optimization and ok if if if it
increases that it has to keep increasing
for a while the gradient cannot turn
from increasing to something that
decreasing very quickly if you imagine
instead then this set cannot be very
very narrow it can't be that I in
climbing up and immediately climbing
down again ah then we have the following
result so we assume that the expectation
of F is one but if we take the
expectation of F restricted on some
level set of this sword somewhere
between some value s into s then this is
not only smaller than one but it's
smaller than something going to 0 as s
goes to infinity so basically what you
should imagine is that such functions
cannot have constant mass on a very high
level set it cannot be that half the
mass of the function is between 1
billion and 2 billion ok it has to to be
pretty small on
every such a multiplicative scale and in
case you need a calculation error no
this is just the log log it's so that
the power here doesn't matter okay the
focus of the lecture is to demonstrate
little of of one so you don't want to
have an S know as well ah where there is
an S on the left because s is s yep I'm
not sure I understand the question f of
gamma is s in this yeah f of gamma is
typically us and we market inequality
will give you a 1 over s no no no no no
so this is just okay yeah yeah this is
just without this this is just one I
restrict it to level set it becomes
little old one oh and I claim that this
is equivalent to an improvement over
Markov's inequality and the reason is
that I can just say that ok so i guess
this this thing is more or less s
because they restrict it to between s
into s so this means that s times the
probability that f of gamma is between s
and 2's is little of one so if i move as
to the other side and this is little 01
/ s and then this just means that the
probability that f of gamma is bigger
than alpha or okay some alpha is just
the sum k goes from 1 to infinity the
probability that f is bigger than is
sorry in alpha times 2 to the K
to alpha times 2 to the k plus 1 and by
using this this thing is smaller than 2
to the minus K times little one and then
I sum them all up and I get little I
mean 1 over alpha little one okay so
this is and also the other implication
is pretty easy but we'll just need this
one together with this which I'll
explain in a second to show that this is
actually stronger than than the question
that I introduced earlier so what else
do we need so we know that this implies
something better than mark of and I
claim that this is implied by taking the
convolution with something so know that
everything that's convert with the
Gaussian is just a mixture of translated
gaussians every translated Gaussian is
just an exponential function times the
standard Gaussian right and basically a
mixture of exponential functions it's
known to be a log convex this is called
the Arden's theorem it it's just
basically in this setting is just
koshish words so it means that well
everything convolved with the Gaussian
cannot be too low concave and we have
exactly this condition all right so okay
this is a bit annoyed not ready but so
let's go over an idea for how one could
prove such a thing
let's first of all so we had the
Gaussian measure gamma and let's now
define a new new measure which called
which is called mu so it's a new measure
mu define just F D gamma we change the
measure with F we fix some a big value
as let's just imagine this is a billion
and we consider the level set
corresponding to s so all of the this e
will be all the points where F is
between s and 2's and what we need to
show is basically that this measure moon
which is probability measure cannot have
a constant mass over this level setting
so how can we try to prove it what I'm
what I'm going to do is I'll try to take
in perturb it in a way such that I'll
try to discover new points let's say
that s is a billion so is where F is
between a billion and tubulin i'll try
to perturb eat to get to a new set where
the values of effort between two billion
and four billion and i'll try to find
another perturbation where the values of
F are between four billion and eight
billion so I try to find some sequence
of sets a 1 e 2 etc that are disjoint
there corresponds to they correspond to
different levels of F but if I try if I
manage to find the super constant number
of such sets whose measure is roughly
the same measure as that of e it will
contradict the fact that the measure of
e is constant right just because the
integral of mu is one so what's the net
throw such construction to do I can so
let's take a point X in E and just
follow the gradient a look at the
gradient of the logarithm of F in this
point I'll normalize it somehow and i'll
just take delta x this thing to get to
some point why now remember this
property of f that if it's increasing it
cannot begin decrease in too quickly
this exactly says that if i take the
stellar expansion of the log of F then
the log of effort why is at least they
stand good I mean the log of F at X
which we assumed to be S Plus this Delta
this is just we take the gradient of the
log x this this is exactly one plus some
something which is small if Delta is not
is not too large it's small if Delta is
small relative to this thing yeah well
it's actually minus but it's Big O so
absolute value of this so it cannot that
the second order cannot contribute too
much now for those of you who are
familiar with these things this thing is
is usually rather hi this is the
expectation of this is the Fisher
information so we might it's not
important if you do not understand it
but there there is an obvious reason to
expect for this thing to be small so
basically the only missing ingredient
here is so so we do know that the values
of F here will be rather large if Delta
is not too big but we don't have any
idea as for what the Gaussian measure of
this set is maybe we took the set ian
the gradients look like this
and this one already looks like this I
have no control at all over the measure
of this perturbation so we have to try
something more clever and what we're
gonna do is the following instead of
perturbing the point X will take a
Brownian motion which ends at X and will
perturb this Brownian motion in in an
adaptive manner so this has to do with
what James talked about yesterday and
basically the main tool I'm going to
need in order to estimate my new set is
called your son of theorem so let's take
a few minutes to understand what this
thing mean what this thing says so we
have a Brownian motion we consider a
standard Brownian motion beating and to
each point at bt we add some drift V sub
T so you can think about this drift is
just a jump that predictable so we know
exactly which way we're pushing the
Brownian motion given the past and we
get this new process WT which is just VT
plus the drift and your son of theorem
says that the following so if we
consider BTW as some distribution over
the space of paths then there is an
explicit change of measure between BTW
and WT namely if you take this
distribution and multiply it by this
that change of density then WT becomes
itself a Brownian motion let me try to
explain to you why this formula makes
sense so if we just think as of BT as
distinct Gaussian jumps then one
jump with a drift V can be imagined like
this so it I guess this is the density
up to some and normalization normalizing
constant of the Gaussian which we just
translate in the direction fee but this
is actually this can be written like
this so it's e to the minus W square
over 2 plus W dot V minus v square over
2 and if we think as B which corresponds
to bt as just w minus v then this dot
product is just B dot v plus v square
over 2 so what we get is the following
we get e to the minus W square over 2
which is just the Gaussian density times
e to the B dot v plus v square over 2
this is all of these together which
means that if we multiply by the inverse
of this plus size not have I'm sorry v
square of course yeah so we see that
basically w is a Brownian motion if we
only change of measure but may apply
change of measure which is the inverse
of this but if you look at this this is
this is exactly this formula only we're
multiplying many many infinitesimal guys
like this right we're just summing up B
dot VT and minus one-half VT square so
you can also for some to get some
intuition about this you can think the
pez just so if v points in one direction
in order to make my thing a Brownian
motion again i want
seemed to be large I want my bt to
cancel out this drift okay so this is
your son of formula and what's really
nice about it is that it implies more or
less the following thing it says that if
I have some set in Gaussian space such
that okay can you see what am I doing
here if I i if i have stepped in
Gaussian space such that i can take a
Brownian motion and force it to go in
this set without applying too much of a
drift then basically this change of
measure is not too large which means
that the Gaussian measure of this set
cannot be two smaller so it's a very
nice way to lower bound the Gaussian
measures of a set i just have to
construct some drift that goes inside it
which is not so too strong now that it's
very important for this drift to be
predictable you cannot just do something
that relies on what happens in the
future i cannot cheat okay so this is
your son of theorem and the next thing i
wanna define or actually remind you from
yesterday is a so-called formers drift
so this is that the particular process
VT that James defined yesterday i'm
going to write these formulas because i
need them for later so again i have the
Brownian motion BTW and i define the
process WT with this equation DWTS DB T
plus V T DT they take just Brownian
motion plus this drift increment where
VT is the following it's the gradient of
log of P 1 my
t f at the point WT so this is exactly
the formula you saw yesterday which okay
so I guess you remember we had the set a
and we want to go in the direction of
the gradient of the log this drift
doesn't exactly go in the direction of
the gradient of the log of the function
but it somehow goes in the direction
that it expects the gradient to be at
time one right so that kind of makes a
sense moreover if we define empty to be
just that the expectation well the
convolution of F with the Gaussian at
our current point which means this is
more or less what we expect the value of
F to hell to be when the Brownian motion
reaches time one then this is going to
be the only like heavy calculation done
in this stock so I'm going to go over
this quickly if you don't understand it
it's not so important i'm going to give
you an intuition about what's going on
here later basically if i differentiate
this process empty I get so I just
differentiate this formula i get the
partial derivative of this with respect
to T and then because WT is the
diffusion i get the laplacian of these
thin this thing it's not hard to see
that these two things exactly cancel out
by the definition of PT and then i get
the two terms that there are a result of
basically the we r WT is going so I get
the gradient of this dot dwt which is
exactly these two terms and if i take
the law
rhythm on both sides and use Ito's
formula again I get that D of log of
empty is exactly this thing and if I go
to the previous slide for a second you
see that I have exactly the same formula
in gear San oafs formula so what does
this mean let's take T equal to one here
I get this formula and it means
according to your son of theorem that WT
is a Brownian motion under the measure
whose density is 1 over F of 1 this
exactly means in in to put it
differently just says that BTW is
distributed according to the gaussian
measure WT is distributed according to
mu basically f of WT x the gaussian
measure so James already kind of proved
this yesterday in the discrete setting
that this drift VT exactly gives us the
terminal distribution of F and this is
the proof of this thing so somehow some
of this drift is very very natural also
there's this minimality think that James
talked about yesterday that's going to
somewhat help us later so okay so now we
have a very strange way to recover this
distribution mu this F D gamma and we
can finally try to understand how one
can perturb this thing and the
perturbation will be the following so we
fix the parameter delta which you should
imagine as the delta we had before we
take in the end will consider multiple
values of delta which will give us many
different perturbations of an initials
and now we take this process WT and we
add some extra drift to it so d XD Delta
will be DB T plus 1 plus Delta V T DT so
this is the sadism the James talked
about yesterday what can you use a
different Padma yeah sorry I have a
difference
so this is exactly the sadism that James
talked about yesterday WT is the process
dt with some pain induced we give it
some with push it in some direction and
it suffers a bit or exactly enough to
get to the distribution of f and here
we're being really sadistic we give it
even more pain than what we need to get
to f so basically you can imagine so we
if we have the Gaussian measure this is
the origin we have some set and we have
some drift that we we have to apply in
order to get to the set so now we we do
some over shouldn't we give a little bit
more of this drift so okay I guess this
picture was pointless and now I want to
try to analyze the change of measure
that this process induces using gusanos
formula so let's see your son of formula
tells us the following I have an exact
formula for the change of measure from
the measure according to which B's
Brownian motion so maybe I'll actually
draw a little thin here so we have the
following processes we have the process
bt WT and X T Delta this is a Brownian
motion
this is a Brownian motion with the
measure P this is a Brownian motion with
the measure q and this is a Brownian
motion with the measure q delta and we
already saw okay so so I just plug this
thing into your son of formula and I get
this but remember that if Delta is zero
then what's written in here is exactly
the change of measure between Q and P so
sorry so I can just factor out this one
here and one here and I'm only left with
the Delta terms which basically says
okay this is the energy I have this is
the measure I'm losing by pushing BTW
into WT but i'm going to also lose the
energy of this push now i want to
somehow approximate this thing if we
look at it for a second this thing so
that the variance of an increment of
this process is exactly VT square right
the variance of VT dbt is VT square and
here we have the integral of VT square
so we expect we we know that the
variance of this thing is basically this
so the standard deviation of this thing
which is a martingale is much smaller
than this which suggests that maybe this
whole term can be just neglected
moreover if Delta is small then and
let's say that it's little oh 1 then
this Delta square let's also neglect
this energy small and so integral is
no no that actually the integral of V T
squared is super constant because we
know if i go back to or the previous
slide that log f of w 1 give given that
f has large bar so this is large meaning
that this is much smaller this can be
neglected okay large because because the
variance of this is this yeah typically
but the whole thing is large because the
left hands are right exactly oh yeah
good point so right so I'm going to
neglect this thing and this then gant
roughly I'm going to say that the only
thing I'm pained to change the measure
between this set Ian in Delta is
something like this e to the minus delta
x ah this energy and this is given the
Delta is small enough forget forget this
exact quantity what why can you rescue
too small that as I said that in the end
you won't resist isn't
says right so here here I mean that the
scaling is different so so it's okay
we'll soon see that small Delta suffice
because a little change of Delta means a
big change in the value of F okay we
will see that actually in the next slide
so so at this point we want to use our
Hessian estimate remember we know that
the Hessian of the log is not too small
this exactly means that F at the point X
1 Delta this perturb process is at least
F at a non perturbed process times and
now here we we consider the Taylor
expansion of the logarithm so the first
derivative of the logarithm is just v1
you remember that definition of VT was
just the gradient of the logarithm so we
get v1 dot whatever the drift was this
is just the integral of the grief this
is just X 1 minus w1 minus we have this
quadratic term that ah well it's
something times delta squared and this
thing is it's not so hard to see that it
won't be so large let's forget that for
now but and assume that we can just
approximate by this thing go only ok so
this is what we expect to gain in the
increment of F by the push okay and at
this point it'll be helpful to recall
that the process VT is a martingale so
this is something James said and did not
prove if I have time later the proof is
just a straightforward calculation but
I'll say something about it later if if
I have time
highslide not that which is Martin Gill
I don't okay so okay what we have is the
following we we do this push we get a
change of measure which was equal more
or less to e to the Z and we get right
now we get a change of measure which is
equal to e to the minus W where this is
W and the the gain we have in the value
of F is e to the plus Z ok that the
previous slide exactly says that the
change of measure is e to the minus this
thing and here we have e to the plus
this see the 0 0 Delta they both had had
Delta of course thank you now the fact
that Vicki is a martingale if you look
at these definitions for a second you
understand that the expectation of the
difference between Z and W which is what
appears in the exponent is just 0 right
because v day okay I guess I'm for each
t I'm taking the scatter product with v1
but the expectation of v1 conditioned on
time T is just VT so I get that the
expectation of this is also the integral
of V T squared which doesn't which make
sense because recall that I'm pushing in
the direction where I expect the
gradient at time 1 to be okay this is
actually more or less also the
explanation why VT is Martita okay so at
least in expectation this this push
should that what the contribution i get
from the incremental of f should exactly
cancel out with the
change of measure the problem is that
this is only true in expectation I have
no idea where the gradient is actually
pointing it could be that I expect the
gradient to point over there but when i
get to taiwan it points like in a
completely different direction okay so I
it's not so clear that this is enough
but we can look at this thing like this
so we know that the expectation of F
over a Gaussian is one meaning that
under this measure Q Delta the
expectation of f of X 1 Delta is one now
in we can instead take expectation with
respect to the measure would okay that
that makes BTW a Brownian motion and
then we get f of X 1 delta x this change
of measure which is exactly what I wrote
here now so we know that expectation of
the exponent basically the expectation
of all of this is one and the
expectation of whatever is in the
exponent is zero this means that the
variance of Z minus W cannot be too
large right otherwise the e to the Z
minus W would be aa more than one so as
long as Delta is not too small this
variance is not too big and finally
going to the room as long as Delta is
not too large so this yeah which which
means all our estimates from before port
yeah so finally we can write something
like this the expectation of so now we
consider exactly the same thing as here
so this is just the integral of F with
respect to the Gaussian measure but now
let's just restrict one level set
of course it's Logan w1 thank you this
should be look I so let's let's just
consider this integral but restricted to
this one level set so we know that it's
at least this then we just again change
this by the expectation but now ah look
so we know that this thing is quite
concentrated around zero we just
established that so even if we restrict
to some subset whose measure is not too
small it should still be kind of close
to zero right so if we remember we
assume by negation that this whole thing
thing is not little over one it's just
the constant so if it's just the
constant it means that we restrict to
some something with probability 1 over
10 so this thing cannot be too small
under this restriction which means that
this expectation is of the same order as
the probability that F of W one is in
this ah same interval just meaning that
this thing is pretty close to one
again log fw1 yeah sorry okay so this
basically is not too small and then we
just get the probability of this okay so
let's I know you're confused let's try
to understand what we achieved so far so
we consider this bed level set where log
F is between one and two billion 1
billion and two billion or 1 billion and
eat billion we looked at the location of
this perjured process given that w one
was in ESO ah no no es is a pitiful so
we add the Brownian motion that ended up
in this set e we look at sorry this is
WT it ended up in in we look at this
perturbed thing x so this is w 1 this is
X 1 Delta it ends up somewhere and what
we saw is that given that WT Anthony the
value of effort at X 1 Delta is quite
large it's at least f of WT x this arm
thing and we also know that Z is large
so we know that we actually get some
multiplicative gain by going from w 1 to
x 1 and we know that when we integrate
over the pads such that w 1 is an e we
still get a pretty decent measure this
exactly means that if we look at okay so
it doesn't it says something about the
measure of pads but intuitively what it
means is that if we look at the set
where X Delta terminix given that W
terminating
II then this set is roughly the same
measure as the 10 v this is more or less
what this equation says it it doesn't
say something about so it says something
about the measure of paths that end in
this set but well this the measure of
Brownian motions which end here is just
the Gaussian measure of this set this
equation also true if the party is very
small because I agree we are right so so
you get some dependence right there is
if when the probability goes to 0 then
this estimate goes to infinity somehow
of course but we're just trying to get a
little of one not going to be disparate
it'll give you one where s again no no
no no no it's going to be something like
1 over log s to some power don't worry
when you change the measure you get rid
of this one rice so now 1 over s like
epsilon RS is now absolutely but yeah
but you agree that this contradicts just
the constant of course this you have to
do something much more delicate to
understand exactly how dependence that
works okay so now we know that Z is more
or less w which is more or less this
thing and recall that recall that F of W
so we add this formula that says that f
of w 1 is roughly they spend so we get
that this thing is roughly log s and if
we plug the fact that z is roughly log s
into this formula we get that f of X 1
Delta is s but we get some
multiplicative gain like this so as long
as Delta is bigger than
think like 1 over log s we already get
some ah multiplicative constant gain and
that's almost it so we know that that
this thing is in a set where the values
of F are bigger but using markov
inequality we can also this is pretty
easy but i'll skip the details we can
also know that the values of F cannot
increase too much just because the
change of measure wasn't too small so it
cannot be I can just gain probability
from nowhere so just by Marcos Oh what
that is is loveliness x 1 plus 2 Delta
to poverty one no no so both of these
things are only with probably so this
depends on on on this easy on this
variable Z which just typically is close
to 2 w but not deterministic so from for
most of the paths that end up here the
value of F ear is indeed different than
the values of F here and well as i said
before by assigning now to delta
different values taken from a pseudo
suitable arithmetic progression i can
take this level set e and discover new
level sets a 1 e 2 e 3 so it delta 1 e
delta 2 e delta 3 such that they are all
disjoint and they all have a measure
comparable to that of e and this exactly
demonstrates that movie is little o of 1
how much time do i have i have to finish
it for 30 or now oh wow okay so i won't
even need so much okay yeah so so so
this exactly means that we created these
sets and
this kind of finishes the idea of the
proof and if we optimize over everything
we get that actually this this is the
dependence we get up to a log log factor
okay so i'll just talk about some
possible future directions of research
related to this and then maybe i'll try
to explain why VT is a martingale
because i think it's really a central
point of what's happening here okay so
first of all um are so the theorem just
so note that the the main theorem didn't
have this convolution in it it just
talked about functions which are not to
log concave and these functions are they
can be defined on on any basically
romanian manifold and even they make
sense on remaining and manifolds with
densities so maybe it's reasonable to
expect that this kind of result origin
like a more general setting of spaces
satisfying this by Creamery curvature
dimension condition ok so i guess if you
don't know what this is just ok a
natural question this does this thing
hold on the sphere for example or on any
positively curved romanian manifold
hopefully ah so so just that the measure
you get from the romanian metric
I'm serious even matter yeah yeah just
your hair gasps you're measuring
appearances right but if it's a
compactor okay ah yeah so positively
curved is yeah yeah strict equality yeah
ah right no negative and compact right
yeah yeah and I guess like the correct
normalization so we will need to know
something about the diameter I'm not
sure compaq you just you i mean Fred
we're all talking about she's not
involved yeah why find annoying so
what's the measure ah you need you need
a probability measure and it should be
stationary for some kind of diffusion
process and then you need not for the
Brownian motion on the man so just uh oh
yeah that I don't know if it has like
it's the usual measure on our Romanian
manifold on a compact remain in man okay
yeah okay so so okay so what I'm saying
is maybe this is like this type of
inequality holds in a more natural
setting okay one obvious direction we
get log to the minus 1 over 6 and well
at least it's natural to expect that one
dimensional thing will demonstrate
demonstrate what the shark dependencies
and for just translations of the
Gaussian we get log to the minus 1 over
2 so is this the correct exponent this
is just oh this is like an optimal
really just mean f is constant on a
space
yeah of course there's the discrete
version of the question that James
mentioned yesterday so the convolution
operator is just just rear and amaizing
some bits on the Cuban taking
expectation and the main reason this
proof fails there is that we cannot just
take a small perturbation of a point on
the discrete cube so we can consider
this these two processes these two
analogs of BTM WT which james described
yesterday but it's not really so so we
can do it we can basically okay it's not
clear what this point x1 Delta should be
right maybe you can get some random
point that but ok so for if n is not too
big you can apply this previous result
of working friends aha and then if n is
very big then the gaussian thing is a
good approximation so shouldn't that get
you a little ol whatever is very big
then it's not clear to me why the result
the eca was in the galaxy soaping so it
doesn't invite the cube at all I so it's
if you look at the cube but but fix the
demand down the dimension but ok then
and it's true trivially then its future
really and yeah you can only go up so
high if n is very large then you know
coupling to the Gaussian should I don't
know this is this is true under some
smoothness conditions of the function I
mean the function is not smoothie just
know it's completely yeah but not not
not your money earning my analysis of
functions
discrete cube they don't look even in
high dimensions they don't apply
Gaussian space they can be they can
depend very heavily on a few out small
number of coordinates or think about
tribes for yes again if it depends very
good yeah it's back to it what okay i
guess i guess this the type of
smoothness it has 20 20 told you tribe
it's a symmetric function which doesn't
like anything else in space right ah yes
you can't just go to a subkey and you
know this function 1 so this for those
of you who know how to prove a hyper
conductivity using those semigroup
proofs they basically only use the
second variation at the first variation
of what's happening there he take the
derivative with respect to the
semi-group and what we do here kind of
looks also at the second variation so
this on an intuitive level when we try
to analyze so so when we went from
w-want to x1 we had this expected
gradient but we also had to scrutinize
what happens with with the variance of
the gradient and this can be this is
ideologically you so you have to look at
second derivatives of what's going on
and of course an obvious question is
does this give anything more so should I
take the five more minutes to just talk
about this process VT or or maybe we can
do it offline change of measures
sign right yeah you know now we put the
change me yeah but but they don't want
to readjust the calculation even I don't
understand it what you know something
that actually gives you an intuition of
what's going on oh so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>