<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Data Visualization, Transformation and Feature Selection | Coder Coacher - Coaching Coders</title><meta content="Data Visualization, Transformation and Feature Selection - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Data Visualization, Transformation and Feature Selection</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eSc-hogggaI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so they get much more interesting and
complex as we go on so in this case
we're going to do a data visualization
transformation in feature selection and
if you remember earlier the workflow
that I had described in the introduction
we're kind of more or less following
those steps that I've collected the data
and now I'm going to look and visualize
the data and kind of identify problem
errors or things that I need to do to
get the data in a state where I could
potentially feed into a model so we'll
cover data insights I mean we briefly
looked at the inline visualizer we're
looking at that a little bit more detail
and some of the descriptive statistics
and how we can kind of infer some
information about the data by looking at
some of those statistics will scrub some
data some of the data will probably have
some missing values will make decisions
about whether or not we should add
delete rows will do some transformations
we'll start applying some math
operations will actually utilize our
script our is very common and so so will
utilize our script for example to do
some of the data transformations then
finally we'll talk a little bit about
feature selection and in this time what
we're going to do is again part of the
idea of scoping out the problem with the
objective what we're trying to do in
this example we're going to predict
flight delay now I want to preferences
real quick we're not really predicting
flight delay but we're going to in this
exists in this sample we're going to
just work with flight information like I
mentioned earlier lip after lunch will
actually build a classification model
and will actually have some kind of
output but you know just set the problem
up you know approximately twenty percent
of flights are delayed or canceled every
year and you know really many factors
affect delays can be whether mechanical
issues or a traffic control and really
what we want to do is is is you know
leverage past flight and weather
information to predict future flight
delays so we're making an assumption
here that
weather has a direct effect on flight
delays and there's a paper reference
here called predicting flight delays
where we've extracted this kind of
experiment so a lot of the data and the
data sets that were utilized for this to
support this paper that was written like
these two fellows over in Stanford um
will utilize that and so the data sets
that will utilize come from the Bureau
of Transportation Statistics and the
National ocean-atmosphere administration
for the weather information and just for
this exercise we're only going to use
july to october 22 2013 so um and will
download the data in a few minutes but
let's take a quick look at the data so
this is kind of a snapshot of the CSV
file for the flight on-time performance
data and what we're trying to do is
we're understanding you know what we
have and also determine like you know
what we need to do to process it so this
is the kind of the first step and you
know you can see if we scan across here
we have some data information the
airline carrier I see like dl that must
be for delta flight information of going
from into the parking time of how long
it basically sat on the runway or sat
basically at the i guess at the hub you
know i also see if it was delayed or not
so if it's a negative value on the
flight left early now we also have a
blind binary field that communicates if
the flight was delayed and it's like yes
or no so it's 0 or 1 and we have the
arrival time with the same kind of
information so we have date information
we have the origin airport ID the
destination airport ID destination
information if it was delayed and
arrival information if it was delayed as
well so you know we look at this you
know what are some of the observations
that can be seen and we see that for
example there are some categorical
fields so carrier is one of them and you
know category are usually feels that
where there's a finite number of unique
values and each value unique value
represents some item it's not numerical
and we don't want to infer anything from
the value so origin destination IDs are
also category of fields as well so these
are airport origin and destination ID
the next thing is um hours and minutes
so they're concatenated in one field and
that potentially could be a problem when
we want to join and do some interesting
information with weather information so
we might actually have to go ahead and
uncontaminated maybe we're just
interested in just the hour as opposed
to the out or in the date and the other
thing too is that you know the arrival
delay that's the thing that we want to
predict right we want to predict whether
or not it's going to arrive early or
late or on time and then we also have
multiple target leaks so we have it you
know the departure delay also a rival
delay whether or not was cancelled and
we don't know really whether or not that
data will have some meaning towards our
modeling effort or experimentation
effort so we probably want to kind of
eliminate them and clean them up to just
kind of get rid of some of the noise if
I looked at the weather information
again we can could do a quick scan at
the weather observations data set it has
again your month day it has an airport
ID will assume that that Airport ID even
though it comes from two different
bureaus is this comes from the same
source as the flight information but it
may be different we don't know so if you
look at this time again is in hours and
minutes but one thing I know about the
data set that it's expressed in UTC so
it really doesn't match with the flight
information time unit so we're going to
have to do something about that but the
really good thing is is that
that we also have the time zone and so
we'll be able to actually adjust that
time value because we have a new teasing
at the time and we'll be able to
normalize that to a local time the other
thing too is that we have fields with
missing values so if we look at whether
type for example here on lots of missing
values so what we're going to try to do
is tackle each one of those problem
areas and or enhance the data sets such
that they're in a statement which we can
go ahead and feed into an experiment so
the first thing what we'll do is we will
go ahead and secure those data sources
and kind of pull them into the system to
work with now yesterday this took an
awful long time to upload and it might
be worthwhile to see if they already
exist in some of the sample data sets so
let's take a look at that real quick and
let me go ahead and switch over to hear
a quick
alright let's take a look okay so let me
open go back to my workspace here and
let's just take a look at the data sets
here to see if my time performance so
this is a this is from October this is
the weather data set so I'm not sure if
this is the subset or not let's just go
ahead and let's just go ahead and upload
it so let's do a new data set from a
local file and browse and again if we
navigate to that folder that was in your
zip file you'll see this folder called
data visualization transformation and
feature selection just go into there and
you'll see them so we'll do the flight
one first and we'll just keep the name
there I know that the flight information
has a header so I'm going to keep the
default here and select ok and that's
going to start uploading down there
actually it's much much quicker yet
today so it must have been load event
Kenji let's go ahead and and also load
up the weather information so we'll do
the same exact process here whether it
has a header file and select ok Wow look
how fast that is
yesterday we have to do something very
different so um you know what so this
particular session actually what we'll
do what we do is actually you know have
a plan for all the flight information
than we have a plan for all of the
weather information and I think we're
doing okay with time so we'll do both
and then we'll do a joint at the end so
now that we have the two in the system
let's start working with the flight time
information so let's go ahead and create
a new experiment you experiment and
let's give it a name we'll call it
flight delay prediction even though
unfortunately are not really doing any
in this experiment here and it save what
we'll do then is go into your data sets
here and look for your flight
information do I pass it yeah there it
is and make sure you pick the right one
if you hover over it that was the
default name that I had picked so that's
the flight on-time performance 2013 and
just drag it and drop it right on to the
canvas and I'm going to save it Oh can't
save a draft without modules that's
interesting so everybody caught up
yeah don't worry about the safe yeah
well it will get to the second but y'all
got there
and I should have asked did folks want
to take a bio break or anything like
that before we get started we seem to be
going at a quick pace we could do that
if you'd like five minutes or so you
guys good yeah okay we'll keep going so
you're all you're all here now okay so
um one of the things that we're going to
do first is ingest and set the missing
values to a question mark so recall that
when we looked at the data set earlier
we found that some of the values we're
missing right so we want to kind of put
some value in their search that it
doesn't mess with our experiments so
what I'm going to do and I'm going to
and again what we're doing is we're
building upon a foundation so right now
we've been kind of clicking and
navigating through the menu to find
modules you can keep doing that if you
want but I'm going to use the search
window so this is a really nice thing
and the first thing we're going to do is
convert it to a data set gotta spell it
correctly first and I'm going to drag
and drop that and connect them so what
converting to a data set does is it is
actually taking it the raw CSV file the
wall the rate raw data input and
converting it to a data set with the
schema as well as type values so we'll
go ahead and do that here and you'll see
as part of converting it to a data set
we can actually have a couple of actions
we could do here we could replace values
as we're doing the conversion sparse the
output or set the missing values to some
value so it's actually defaulting to the
question mark and it's kind of what we
want so when it does this we say you
know yeah let's go ahead and set the
missing value to a question mark you can
go ahead and run that
okay and as I mentioned earlier you know
you can always visualize the output and
you know it's always good to actually do
this every once in a while to just kind
of look into this here and there's a few
more missing values here but we'll come
back to those later another handy module
is descriptive statistics and this is
where I had mentioned where there are
some utilities within the service that
actually provide additional insights
into the data to kind of give you a
notion of whether or not there's for
example the data is balanced in
particular columns or fields if this
missing data and just basically what the
range of the data sets look like so
here's a module that I'll just go ahead
and drag and drop here and i'll connect
the convert to data set directly to that
and if i go ahead and run it will just
go ahead and see some of the statistics
about the flight on-time performance
ok
let's go ahead and visualize it okay and
as you can see here what it's generated
basically for each individual feature
like your month day of month the carrier
um how many unique values there might be
if there's any missing values min max
mean on the mean deviation and so on so
I can actually go ahead and scan these
things and I can also take a look at for
example you know visualize that
information so it kind of gives in a
histogram so it kind of gives me a
really good way to take a look at the
data to kind of see if it's complete and
well distributed so if you recall
earlier we also identify that there were
some target leak leak fields in the data
set we want to go ahead and eliminate
those so we have another module called
Project columns and it basically does on
some manipulation on the data during
some data transformation tasks so we'll
go ahead and drag project columns on to
the canvas and drag and drop that there
and what we're going to do is introduce
a new idea or concept so as you remember
there were a number of fields that we
did not want to include in the data set
because there were target leaks and
those included the departure delay the
arrival delay whether or not it was
cancelled and so on and so forth so what
we're going to do is we're going to
select what's called a column selector
here whoops let me just cancel out of
here so this launch column selector
basically what it's doing is it's it's
informing you know what let me just do
one second here I have this this Dropbox
hang in here let me just refresh my
window real quick see if it cleans that
up there you go okay so I'm going to
launch a column selector here and it
provides me with a user experience where
I can actually select the columns that I
want to work with more kinds of actions
so what I'm going to do is I'm going to
start with all columns because i want
all columns to kind of cascade down and
what i want to do then is I want to
exclude columns by their name and enter
those column names so one is the
departure delay right here the other one
is the departure delay team which I
don't know what that one is the arrival
delay and the last one would be whether
or not it was canceled and what you're
seeing basically when that drop-down is
and one of the also benefits of hit and
run all the time is it kind of cascades
the schema I found that sometimes I'm
the scheme will if I don't hit run
sometimes it will show up and sometimes
it won't it really depends on the
operation in the module so everyone
should have something like this
and let me hit OK and run it and
obviously when we run it we probably
should no longer see those those columns
or those variables
okay let's go ahead and take a look at
it and if we do a quick scan you can
actually see how the columns and the
tables are much shorter now over other
fewer excuse me okay so the other next
task that we want to do is um we also
want to you know tackle the categorical
fields specifically we need to kind of
change the metadata and we don't want to
change the data but we want you to
metadata about those fields so we have
another module here called the metadata
editor and I can Greg drag that and drop
that here and connect them and
specifically we want to tackle those
those fields that we identified earlier
so if I hit the launch and basically
kind of include my column name it was
the carrier it was the origin ID and the
destination ID and the destination
Airport ID it was those particular three
fields what we want to do is we want to
make sure that we set them as
categorical if you remember that those
were three fields that were categorical
when we did the initial analysis of the
data set so once you have those three
fields selected will go here and then
we'll say it's categorical and we want
to say yeah it's categorical so we want
to set those fields two categorical
we'll go ahead and run that
and then the next thing that we want to
do is remember we have that time
component that have the hours and the
minutes and what we want to do is you
want to extract the hour from the time
print we're only really interested in
the our piece so for that what we're
going to do as soon as this is done
running will drag and drop obviously a
math operator right because what we'll
do is we'll do a division and divide by
100 to extract the our portion of it so
let's just do a search for apply math
and drag that and drop it and then
connect them okay now we have to tell
which column to operate on so I want to
do the launch column selector and
include by column name and there were
two columns the departure time and the
arrival time that both had the hours and
minutes minutes concatenated together so
let's specify the departure time and the
arrival time and then you'll see a
number of different math operation
categories there's trigonometry some
basic compare operations rounding well
we'll do for this one is let's we'll set
this to actually oops two operations and
we'll do a division and we'll divide by
100 right basic math got we're assuming
that we have a four digit field for the
hours and minutes concatenate together
we'll go ahead and divide by 100 and
then the other field that we want to set
is the output mode so really the output
mode is basically saying what we want to
do is do an in place so really what
we're telling it for this particular
module is hey for the departure and
arrival time let's go ahead and divide
that value by a hundred and then the
result of that
just do an in place just to do just
replace the value right in place let's
go ahead and run that
okay and then we'll go ahead and
visualize the data and confirm that it
did the division correctly so we have
the both here the departure and arrival
time I'll do quick scan and it looks
like my assumption that the values you
know where four digits were incorrect
you still see some decimal points here
so we're going to have to round this and
take care of this real quick so let's
just do another math operation drag and
drop that here and then connect the two
and then this time what we'll do is
we'll just repeat the same process we're
going to launch the columns Lecter we're
going to select it by name we're going
to tackle those two the departure time
and the arrival time this time what
we'll do is we'll do a rounding well
around by for constant one and well
again will do in place here so we're
getting rid of basically that decimal
the decimal piece and we're just really
focusing and extracting on that hour so
if i go ahead run that again
we should be done with the flight
information so well next one we'll do is
we'll tackle the weather information in
parallel okay let me take a look let me
make sure my works did you select the
columns you select the right columns ok
let me visualize it quick
and and if I scan it sure enough it
cleaned it all up so they look good are
you okay okay so metadata editor let's
see you should have you got that and it
yep and you got all columns okay and you
have excluded all right so let's go to
the math operation so the math operation
you have operations divided content 100
and then the selector you have crs
depart DP time and CRS our time and you
have begins with no columns include
count okay
yeah that's a you why that's very
confusing to me
um did this have the name CRS depth time
okay so so so your project column should
be all columns exclude column names
departure delay to Portugal a 15 rifled
delay and cancelled that looks good and
then the metadata editor you have the
launch you have no columns include
column names carrier origin airport ID
and destination Airport ID and you have
data type is unchanged categorical set
the categorical fields unchanged then
the apply math operation you have
category operations met basic operations
divided up raishin argument type this
constant and then the constant
operations argument is 100 and then
output modes in place and you have begin
with no columns include column column
names CRS DEP time and CRS arr time
okay well I'll tell you what why don't
you why don't you just kind of wack just
delete that module from your work space
such that it will actually run a compile
and then let's continue on with the
weather observations and then because
that's actually a really good one the
weather operation because that's where
we start using our will introduce bring
in our and you just won't be able to do
the joint at the end is that ok we'll
just keep progressing all right yeah
yeah yeah so if you delete the one is
giving you the error you you know you
should be able to run it successfully
now so so now let's take a look at the
UM the weather one and we can kind of
pick it up a little bit pick up steam a
little bit because you've probably done
most of this stuff already now so let's
see whether data set let me just find
mine there's it's the NOAA weather july
through 13 and we'll just drag and drop
that onto the canvas so i'll put it next
to and parallel to the flight on-time
performance and we'll do the same thing
if you recall we had missing values so
will utilize the convert to data set and
while we're converting it to the data
set we'll go ahead and take care of that
missing value in this case i'm going to
set the missing value to em and there's
why i'm only setting it for em it sounds
arbitrary but the original paper for
that data set they set it to em so
without going into great details of why
they did and stuff i'm just going to
follow what they did in the paper so i'm
going to head go ahead and set that to
em and then the next thing and then here
of course if you wanted to you could add
the descriptive statistics to look at
the data again the next thing we want to
do is remove some unnecessary fields
through the data set if we remember we
had some fields that were just kind of
noise in that it was a very large data
set so let's go ahead and bring over a
project columns
and try and drop that and connect that
and then let's go ahead and launch the
column selector and what I want to do is
select with all columns begin with all
columns and then exclude and it's not
going to show up so let me cancel this
real quick let me delete this real quick
so this is where the case we're for
example sometimes you need to run in
between modules because as you could see
when I when I went into that edit
control I didn't get the auto sense kind
of it didn't kind of bring forward the
schema I could have typed it but I know
that some of these names are a bit long
for me to remember so we'll just run it
real quick you could type it in there
directly yeah yeah you could that's
correct that's correct so let me just do
that again I'll pull over to project
columns drag and drop connect it then
launch the column selector and begin
with all columns and I want to exclude a
few of them so some of the ones that we
wanted to exclude for example that that
really didn't have anything to do with
the prediction of weather included for
example the value of wind character the
wet-bulb both the fern height and the
Celsius there's a station pressure here
this is also a pressure tendency
pressure change and sea level pressure
I know it's here somewhere
there is
yep
I look good so here I'm utilizing the
project columns as a way to kind of
exclude columns by the column name or
exclude data by their column name I can
also exclude data by their type as well
so to do that what i can do is select
this little plus thing here and it's
going to give me another option to
exclude things and this time what we'll
do is we'll exclude by column type and
we don't really need any of the the
column types that are type string in
those column types would not have been
projected unless I ran to convert to
data set so that's where some of that
it's kind of fuzzy about what the value
is of a convert to data set but that's
probably the one thing that I've kind of
extracted value is is applies kind of a
data type to the column so I can't go
ahead and select ok and run this I'm
exclude yeah
and that worked good
so if I look the data set real quick I
could I should see some of those columns
removed
yep they're gone ok the other thing too
is that there were some missing values
and I could I could come up with a
really complex scheme of how I might
want to tackle that but for the purposes
of this conversation is this this
exercise as well as showing you a bit
more of the breadth of the application
in the solution let's go ahead and just
remove the value the rows with missing
values so any place where there's a
missing value will go ahead and remove
the row so there is also another module
called missing value scrubber and I can
drag and drop that there and that's
doing a manipulation on on the data and
what we're going to do is for missing
values we're going to tell the system to
remove the entire row and we're going to
keep the columns and what we're going to
do for this column indicator here we're
going to do note do not generate so
basically the MV indicator column is
just it depends an additional column
that's he'll tell you what it did for
example for those for this task and
we'll go ahead and run that whoops I
didn't connect it sorry you go
and now we're going to this is where it
kind of gets a little bit interesting so
this was actually if you recall call we
had that time field and that time field
had two problems one was just like the
other one of the previous one for the
flight data we had hours and minutes
concatenated together so we want to take
care of that and then the other thing
too is that it was expressed in UTC so
we also want to correct that to local
time and we're fortunate enough that
have to have basically a column in the
data set that includes the timezone so
will utilize that as well so to do that
just as we did earlier we have these
math operators and I'm going to go ahead
and do it apply math operation and drag
that and drop that there and do that and
we're going to select the column
selector and by name and we're going to
select time and just as we did earlier
we're going to select it to operations
and we did divide by 100 and we're going
to set the output mode to in place and
then I'm going to do the same exact
thing this time I'm going to drag this
and do remember we did the rounding to
get rid of that decimal will connect
these two here will launch the column
selector column names and it doesn't
show up but we'll do we'll type in time
and earlier what we did again was the
rounding we did a floor constant one and
in place
so the same exact operations which is
right to the left of you on the flight
data and we can hit run so so at that
point i mean the data still in UTC so we
have to fix that I'll be curious if
yours works this time does it work in
this time that's funny hey you know what
is its it just a slight like you saw
earlier when I was like I had a space
for example in the account name and it's
just hard to see so now to adjust the
time from UTC to local time we're going
to take advantage of that time zone
field and we'll just yet do another
apply operation but this time what we'll
do is a subtraction yeah I guess you
could do an ad as well do that and this
time what we'll do is we'll select the
operations and we'll use a basic
operation we'll just do let's say kind
of a subtract select and what we'll do
is this time the argument type will be a
column set so what we're doing is we're
saying we want to specify we're going to
do a subtraction operation and we want
to select the column to subtract each
other from so in this case we're going
to select the first argument and in this
case we're going to select no columns
include column of column name time zone
right
and here we're going to select a column
name time so we're select or subtracting
time zone from time and the output mode
will do in place basically when you're
done with the result replace it with
that column
okay so you can go ahead and click on
the results and visualize it and we want
to look at the time value and we can
scan down here and did look pretty good
you know 24 24 25 that's weird because
we have a value here at with an hour of
25 which doesn't make sense right so
we're going to come back to that and if
I keep scanning here I see another 25 25
I just see some some weird values in
here you know what I've done this in the
past I've seen 27 and 28 here's a 26 so
obviously there's there something wrong
with that really what this means is that
we need some more context around a
daytime operation and what we're going
to do is we're going to replace these
three tasks with an hour function that
we had written an our script that we can
actually go ahead and interject them
there but so but we'll come back to that
real quick let's do one more one more
thing let's remove the duplicate rows so
if you remember that there were some
duplicate rows so just through intuition
when we looked at the original time that
we extracted the hour from there there
were a bunch that had a minute of like
56 and so it's likely to get unique hour
when we set but we don't really know
that what the data is like so what we do
know is that we want to kind of have a
unique hour we don't have multiple
weather observations for the same hour
so to tackle that what we want to do is
get another module called remove
duplicate rows and we'll just drag and
drop that here connect them
Oh
should work now there you go remove
duplicate rows and again we want to
select which column here so really what
we're saying it here is that begin with
no columns and we want to select
year-month-day airport ID and that one
field here which we should see no I
don't see it hold on let me back up a
little bit here let me just go real
quick here do it when I did this I
actually should have selected the output
mode to append not in place so let's
just do that real quick let me delete
this and did you see what I did here the
output mode i did append i actually want
to do in place i want to actually kind
of append the result set basically tell
the system create a new column and
appended to the end because we're going
to use that value is kind of a key when
we duplicate we eliminate the rose so go
ahead and run that with that correction
and then this time when we go ahead and
visualize the data Oh at the far side of
the road you'll see a unique column that
was generated by the system and it
should say something like you know
subtract time zone comma time kind of
give you an indicator the operation that
I performed
and then this time let's just take a
look and make sure we got that right
this time because when I was setting up
the index to remove the columns I
noticed that was that field is missing
yeah so you see it right there so
subtract time zone it's got that there
so then so then now let's go ahead and
remove the duplicate rows and I'll drag
and drop this connect them what we're
trying to basically say is is basically
this is the filth we're specifying the
filter expression to to basically key
off of so so these are the fields
basically that we want to utilize when
this is for the system determine whether
or not there's a unique row or not or
duplicate row so again we'll go back and
select year-month-day the airport ID and
that subtract field see down on the
bottom here subtract time underscore
time zone so those are the keys that we
want to use when evaluating if there's a
duplicate row or not and then the other
thing too is I want to retain the first
duplicate row so what we're doing there
is we're telling the system that hey
when you choose to delete a row always
retain the first one and then eliminate
the others so let's go ahead and run
that one and then this next step you
won't be able to do we'll do a joint and
then we'll do we'll do a joint because
now we want to join the two data sets to
kind of get a result set because you
didn't get the left-hand side running
but just follow along and then we'll
come back and the last step is will
replace those things with our script so
that would kind of complete everything
that you need to know about doing all
kinds of different data transformations
and stuff and then after we'll break for
lunch do come back for lunch to me I
think that the the best presentation the
meat of it where you're actually doing
some experimenting and modeling is in
the afternoon and then you're also doing
the deployment so this is kind of like
the basics and we're also considering
potentially consolidating the workshop
to do
kind of extend the experimenting the
model to include a little bit more of
this when you guys are done at the end
of the day if feedback on that just let
let us know because this could be
tedious sometimes but you're getting a
good view of the product by kind of
going through all these things so let's
now removing duplicates was
year-month-day airport ID and the
subtract weather got them okay so now
what I'm going to do is I got two data
sets but really what in the day I want
to join them together I and I want to
join them together in a specific way and
and and if I was to kind of build a
model off of that it would be that join
data set that i would start working with
so um as you can imagine there's a
module called join so we'll take that
and we'll put that down here on the
bottom between the two and we'll take
the output of the flight information and
the output that we have so far of the
weather information and then the next
thing that we have to do is basically
describe how we want to join the data
together so the join columns for the
left and this would be the left which
would be the flight information will
launch the column selector and we'll
select by column names and we're going
to select year month day of month the
origin airport ID the departure time
that's what that should look like
and click click ok and then the join
columns for the right side and that's
the weather information I want to launch
the column selector and I want to select
year-month-day the airport ID and the
subtract time zone down here so again
i'm actually matching on the index is
basically into both of those tables are
year-month-day airport ID and the time
and select ok i want to do an inner join
so i can specify what kind of join type
that i might want to do I'll do inner
join and I'll keep the right columns
right key columns in the joint able so
it's going to bring over those sets when
I complete the one set so let's just go
ahead and run this
and this is basically joining the two
data sets for editing for the weather
information at the departure airport you
know it might be interesting also to do
something very similar to let the
arrival airport to see for example the
weather at the arrival airport affected
the prediction so what we would do it
that in that case is more or less repeat
the steps so we can do that here again
just let me finish this running
okay so let me just slide that over here
and select join again drag and drop that
over here and I'm going to do again the
math operation here and rather the
flight information on the left hand side
and the weather information on the right
and this time i'll just select different
columns so for the flight information
i'll go ahead and select again the year
the month the day of the month the
destination airport ID and the departure
time this time and then on the other
side i'll go ahead and select the year
the month the day the airport ID and
that's abstract time zone okay do the
inner join keep the right and then we
can go ahead and run it now of course we
have to kind of go back and take care of
that problem where we have the time
values that were greater than 24 I could
have done that before I did the joint it
probably should have but you know in
this case what I wanted to show you is
how to bring our script into ashram ml
and in this case without going to a lot
of detail on the our script about what
it is it does basically some data
transformation on some of those columns
that are within the data set so let me
just let this finish running
it's working now ah so you can kind of
act oh it did alright great that's
perfect well it could have been the
system to I don't know so um so so what
we want to do is replace the NOAA
weather observations data processing
with an R script specifically those
apply math operations and we do have a
module called execute our script and I'm
going to take that and I'm going to put
it to the side here let me just slide
that over because really what we're
going to do is this is the this is the
weather workflow here and we're going to
replace these math operations and what
we're going to do is as you can see in
the properties window it takes our
script that you would cut and paste them
there and also kind of a random seed if
you go back to that handy sheet of paper
you'll see the our script and what it's
doing is basically it's taking the year
the month day the time right and it's
basically then concatenated the date
fields and applying a proper time zone
difference using POSIX so and then it's
doing some extracting it and then it's
basically then extracting some of the
other columns and then binding it so let
me go ahead and grab that and hit copy
and then what I'll do is go back into a
jamel and this little window here which
which should expand out for you folks as
well just go ahead and do a shift insert
and you'll see it all there okay and
then what we'll do is we'll come back to
this and then we have to connect things
so again we're going to circumvent these
math operations these were the math
operations that did the division in the
rounding if you recall and so I'm going
to take this missing value scrubber here
and draw this into here so that's the
input to the data set
then we're going to take the output here
and put that into the remove duplicate
rows and there's a couple of other
different inputs here as well as a
secondary data set that if you want to
input into your our script there's also
a script file bundle so if you're our
script for example has some dependencies
on some binary code you can actually
bundle it together in a zip file and
then have references in your our script
code to those and so what it will do is
when it runs execute this it will
actually go ahead and unbundle that zip
file and then resolve the references so
that you can go ahead and run some of
the code so we'll go ahead and do this
and we'll hit run
okay know what we could do to is remove
at the end of this our script let's just
take a look at this and visualize it and
just tickle a quick scan what you'll see
is adjusted date year just a month
adjust the day these are new columns and
just an hour these are new columns that
were created by the script okay they
replace basically month hour and day and
if we took a look at tinta yeah that you
look good okay and what you'll notice
here is the duplicate rows failed over
here and the reason why is because the
column names have changed so if i go
back here i can go ahead and fix these
and get my handy-dandy sheet here sorry
I forgot what they were okay so so you
want to remove those because again the
our script had replaced them and then
specify a year I just in months let me
get rid of this one just month adjusted
day the airport ID and the adjusted our
and then that chin twist work
and then we'll just do one more module
and then we'll break for lunch then
again i do encourage you to come back
out for lunch it's but the rest now we
start getting into some real modeling
and experimentation and and then John
will presenting those two is a great
speaker and then afterwards we'll do
also put into production now this one
failed to know what I didn't clean this
one up either sorry but you get the gist
here we go beclan it's this one so boom
boom boom get rid of this one and then
we'll just do again we'll just you let's
say year just month adjust the day the
airport ID and the adjusted our and then
that should work sorry about that i
missed that one and that's because those
columns were referenced on that and
actually I probably didn't even I didn't
take care of the other joint either
yeah see I did I felt to do this one too
sorry about that okay so we did just
among adjust the day the airport ID and
the adjusted our there you go
and then the final the final one is just
basically suppose maybe I wanted to
isolate data set a data part of the data
set so for example if I oh I know that
this data set I think goes from from jun
2013 to october 13 and suppose I want to
work just with the october2013 data I
can actually go ahead and split the data
so if i do a split if i search for split
s plit and drag and drop that i could
take one of these joints put that as an
input there and then basically what i
can do is i have different splitting
modes I could do you know split the Rose
a recommender a regular expression or a
relative expression I'll do a relative
expression and basically I want to do it
by month so and actually I think it's
justin month so let me look at this real
quick now it is month yep so let's do
pie so a month is less than 10 so what
I'm saying is just basically split the
data and I'm only interested in the left
side will be the things that are oops go
get the expression correct less than 10
and then the right would be 10 so if I
ran this I could split the data and then
kind of work with it just segments of
the information in the data so this kind
of really concludes a lot of the data
manipulation in the visualization aspect
of it you know you got a chance to take
a look at different modules for doing
transformation and working with data
including arithmetic and statistics some
of the visualization would be kind of
like for example that's the statistical
function where it would generate the
statistics across the data set such that
you can take a look at the normalcy of
the data
or or problem areas and then kind of
tackle it that way there's also the
visualization window to from the output
and you can utilize a number of the
heuristic windows there too after lunch
what we'll do is John has a short talk
on predictive models it's only about 15
minutes long it's a really really great
talk it kind of sets up on building a
classification model so and he'll spend
about an hour to an hour and a half
building a classification model and
comparing for example in SB mile SVM
model to maybe a logical regression
model working with some data and then
after that I'll just jump in and spend
about 15 minutes or so showing you how
to polish it to a REST API and then
we'll be able to kind of call that REST
API will use the browser in this case
but as you know from a REST API which is
fairly standard today it will be hosted
as a service up and Azure and you can
call pretty much either from any
application or web service so it's a
quick way to kind of build your model
once you're satisfied with it publish it
right out so more exciting stuff and
after lunch I promise and thanks for
sticking sticking with me</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>