<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>RARE: Rethinking Architectural Research and Education | Coder Coacher - Coaching Coders</title><meta content="RARE: Rethinking Architectural Research and Education - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>RARE: Rethinking Architectural Research and Education</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1JoulZbONL8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it's a pleasure to be here today this is
actually my first time
doing it already and I hope you enjoy it
more today I'd like to tell you about my
views about rethinking architecture
research and education and I chose to
talk the title of this talk really
carefully based on an algorithm that has
been used for many many years while my
friend David Patterson had bit ly days
real is very simple you find four letter
acronyms that begin with the letter R
and this has worked for Dave very well
and when it has not worked it's because
he violated his own rule you all know
about risk you all know about raid not
too many of you probably know about sore
and even though it forms the foundation
of the way we build large data centers
today not too many people know about the
now project so Dave when he was let's
see if we can make this work very are
off when he was president of the ACM
wrote two very influential columns which
he published they've had as president of
the ACM he had the ability to publish
without peer review and he did this and
the two papers that impressed me the two
columns that oppressed me were to the
first was called seven reasons to shave
your head and three reasons not to the
bald truth now the second column was
computer science education in the 21st
century which is actually the subject of
this talk but to go back to the first
talk um one of the things that Dave said
in his column was that if you shave your
head it makes you look younger and
tougher and I thought this would be
great because I probably could use both
of those things but fundamentally I'm an
engineer and I believe in the power of
simulation before taking any irrevocable
steps so
so I actually wound up not doing that
but the points in their 2nd ACM column
were more interesting there were only
three of them and the first laws use
tools and libraries that is do not try
to write all the programs yourself
because a lot of people have come before
you and have built valuable tools and
valuable libraries and you must must you
ought to just use those things he was
talking about things like Ruby but in
fact the part of this discussion that
struck me most was the little quote
there he said for many CS courses a
dramatic change would simply be if
students first really clear
specification the final thing that he
said was build your own supercomputer
very odd thing to say and what he was
basically doing was laying the
foundation for an enterprise called ramp
which has actually led to my latest
projects and the thing that I've been
doing over the last few years lamp
stands for research accelerator for
multiple processors and the idea was
spawned at a highway meeting at the
international symposium on computer
architecture in 2005 I didn't get a
didn't become aware of this project
until about nine months later but it was
a consortium rather unusual consortium
between six of the top universities in
the u.s. that do architecture research
Berkeley Stanford CMU MIT University of
Texas at Austin and university of
washington and these guys had some ideas
about how to help in computer
architecture today in the 21st century
and the problem for computer
architecture today is that as with real
architecture that is architecture that
creates built wonderful buildings that
around us and the bridges and the roads
and all that ultimately it's about
building things um and of course the
things that are built are the computer
systems which we were programmed and
these things have to be functionally
functional elegant and cost-effective
those are the three tenets of
architecture the problem with this is
that academic departments haven't been
able to actually build computers in
since about nineteen eighty-two um the
reasons are very simple in order to
build a real computer system you have to
build a real integrated circuit and the
price for building a single integrated
circuit has escalated exponentially over
the last twenty years it now stands for
a chip that would be competitive with
with the microprocessors that you could
buy from say intel or AMD about 40
million dollars this is more than even
the NSF can spend it is more than
Microsoft can spend hi and secondly a
chip design has become too complex for
small student teams if we look back to
nineteen eighty-two when the risk and
the and the and the MIPS architecture
were being developed at Berkeley in
Stanford that was not true the teams
were about 10 people and they could
actually build computers that work those
days are now gone and the result of this
in my view is that for about the last 20
years architecture research has become
quite informative what happens is people
studying architecture will take some
small element of an existing
architecture and proposed changes to it
and simulate those changes using a
standard set of simulation tools that
pervades the academic community on a
standard set of benchmarks that pervades
the academic community and that's a
beast publishable result and in my own
view that is fairly boring we don't see
big picture papers anymore you can't get
the bubbler
so the ramp idea was very simple it was
to provide a field programmable gate
array based platform for architectural
research now field programmable gate
arrays are fairly new thing in the world
and when I described them I do it as
follows think of a sandwich there are
two layers of things that are happening
on the top layer is some raw uncommitted
logic memory and wires and on the bottom
layer there is a large number of static
Ram cells that reach up onto the top
layer and configure it and teleport to
do there are no computers involved
whatsoever in this so far so the way one
actually makes a field programmable gate
array do something interesting is to
write a program in a hardware
description language typically Verilog
or VHDL and compile it just as you would
if you were writing a software program
and compiling it to run on some
architecture accepted in this case what
is produced is not executable code it's
the thing that is loaded into that
configuration establishing layer when
you do that and you load that thing in
and start the chip running it takes on
whatever personality you gave it in the
Verilog code or vhdl code that you wrote
I was initially quite skeptical about
this and I said to dave i made the two
objections that you see on the slides to
Dave one was that fpgas were not big
enough and secondly that design tools
would not be up to the job and dave said
how long ago has it been since you
looked and I said about five years he
said they look again and I was wrong I
was absolutely flat out wrong and he was
right I was right in it this project
which was to produce an engine for the
ramp program is not a good thing to be
done by graduate students because the
graduate student spends a large fraction
of his or her time
Lynn encounter on arcane CAD tools which
will be fleeting at best they will be
improved they will be changed the
student will wind up in an environment
for those tools don't exist and it's not
a good use of a graduate education so we
at Microsoft offered the lamp folks a
deal we offered to build them a platform
called B 3 and we spent three years
doing it now III has fear of those large
field programmable gate arrays a large
amount of memory and a lot of
input-output no computers yet so here
are the subsystems and it's a very
regular architecture the great things
are the field programmable gate arrays
the green things are ddr2 memory a lot
of it and the blue things are the
input/output so you can both have a lot
of input output on the same board
between the FPGAs or you can go to
external interfaces which allow you to
plug those machines together into a
larger complex the Berkeley folks wanted
to build a thousand core mini core
machine with this platform and they have
done so so the project was a little
unlike many of the projects that we have
done at Microsoft Research in the past
we didn't actually provide funding for
graduate students what we did was we did
platform for them we can we collaborated
with Berkeley to write a detailed
specification engaged one of our
business partners celestica to do the
implementation we thought that this was
much better than burning out graduate
students and we thought they could do a
lot better then graduate students can do
in building this platform and we were
right um the actual layout of the
printed circuit board was done here in
shanghai by a celestica engineering team
the Signum take
he work to make sure that the printed
circuit board would actually work when
it was fabricated was done in Toronto by
two groups of people that I never met
whatsoever all interactions were carried
on with email it worked flawlessly the
resulting board worked the first time
this is the first time in my career
something that I have built actually
worked the first time usually you spend
a lot of time correcting your mistakes
so we licensed the design at no charge
to a third-party firm called B cube
which was set up to distribute in solid
support systems and they've shipped 75
systems to date all over the world some
here to China some to Europe are quite a
few in the US and we also have supplied
some of the basic intellectual property
for this system in particular controller
for the Rams which I guarantee is
something you never want to write
yourself and what this meant actually
was that both academic people and
industrial people could buy them and had
this been founded by an NSF grant that
would not be the case I went to the to
the project originally and I said I
would like to have one of these
predecessor machines the b2 how much do
I have to check for and to whom do I
write it and they said we don't know so
in order to make it more generally
available through the world we have
licensed it as I say about to enter to
any to anybody for research purposes um
this is good for a lot of people if
you're Berkeley or Stanford or so on and
you have a lot of money then it's a nice
platform for doing very aggressive kinds
of things but as a teaching platform for
teaching students about architecture it
has the problem that it is very pricey a
b3 costs about fifteen thousand dollars
us and that's too much for many people
it requires a toilet to infrastructure
that is pretty complex and so we wanted
something simpler and we have been
looking at the
project as a whole that is the ramp
consortium and we discovered something a
little bit interesting which is that
although they purport to be about
research and multi-core architectures
they didn't actually have a multi-core
machine and so I thought well we know
how to design computers so let's do that
and that led to a project which has
occupied about the last year and a half
of my time and a time of some of my
colleagues at MSR silicon valley called
beehive and what bee hive is is an FPGA
on many core system 13 risk scores
running at 100 megahertz with two
gigabytes of memory attached to it it
has a display controller and ethernet
controller it's about six thousand lines
of Verilog code now this is a computer
that is competitive with a PC of perhaps
eight years ago it's not as fast but in
aggregate it probably is as fast as that
eight year old machine so you can do a
lot but that's not the major point the
major point of a system like the Beehive
is that a student can understand it and
modify it using only the basic tool set
supplied by xilinx we did not depend on
complex CAD tools and so we also used
for it a very low cost development board
that xilinx applies to academics for
seven hundred and fifty dollars
curiously enough because we are not
academics they charge us two thousand
dollars it comes with a software tool
chain AC compiler based on GCC an
assembler a linker all you need to write
and run real pilgrims comes with a small
but growing set of libraries for
frequently needed things like printf and
malik and the other friends that we all
know and love from the sea systems like
the beehive it's like the p3
licensed it for academic research use
with no strings here's the word on which
it runs this is a xilinx xup v5 board
xilinx built this board actually to run
a copy of the open spark system that is
released was released into the open
source community by sun microsystems you
can get one open spark or on this board
you can get 13b through the beehive
course so it's this is hardly a
multi-core platform if you want to use
open squad that so here's what the CPU
looks like you haven't seen a picture
like this since an architecture book of
perhaps 25 years ago it's very very
simple it's a three stage pipeline it's
32 registers to free instruction pipe
simple caches and there's only one
slightly curious thing about it which is
it's a decoupled architecture that is
memory references are decoupled from the
memory system itself by those cues that
you see the ad rescue the right cue in
the week you are the lathe the core
communicates with its external
environment the external environment is
two things one it's a local set of i/o
devices including a very fast multiplier
based on the digital signal processor
the dcache itself and a couple of kind
of interesting things a messenger unit
which can use be used to send short
messages that is up to 60 words long
between cores without using the memory
this is something that people haven't
done for quite a long time that we
believe it has consider the promise for
simplifying the way people use such
systems and then there's a lock unit
which does the same thing for a set of
64 binary semaphores that can be shared
between
the corrs without going through memory
ok so the instruction set is very simple
it's the sort of thing you learn about
in computer architecture 101 but we
wanted to make it simple enough so that
students could understand it and get the
basics of how computers actually work
and it has essentially no surprises
except that the way the memory access is
work which is to decouple the generation
of an address from the consumption of
the data and the support for constants
one of the interesting things about this
system is that it does not use a bus to
connect the 13 cores to its memory and
the reason for that is if you implement
a thing like this on an FPGA you find
that if you use a lot of buses you run
out of wires because there aren't enough
wires on that upper layer to carry all
the signals that you need so what we did
about that is we used a token ring which
passes through each of the cores the
display controller the ethernet
controller the dram controller and the
model for this is a train and the train
contains a token which runs around
that's the locomotive and it goes past a
number of remote stations and at each
remote station the locomotive declares
how long its train currently is and the
remote station says how many things it
would how many cars it would like to
hook onto the end of the train and then
the remote station counts down on that
number hooks its things on and the
locomotive updates its count and this is
all very simple it does work very well
but it does have one little problem
which in fact we missed completely note
that in this memory controller which is
the thing down on the bottom there's
this thing called mq that's a large
queue
waiting the whole the train that is
coming around the ring but which is not
terminated yet and you must not start
sending things into the ring until that
until the end of the end of the current
train is reached because otherwise you
could get a collision between a new
train and an older train this was a
perfect example that if I ever write a
book about design I will cite this is an
example of grabbing on to an attractive
metaphor too early and what happened
well as you're here in a moment this
this system is now being used as a basic
basis for an engine under graduate law
of course at MIT and one of the MIT
undergraduates when they stuck up her
hand and said to the instructor why is
the engine at the front of the Train why
is it not at the back of the Train and
if you do that and you K through
implications of that what you discover
is that you make every one of the cores
that is the remote stations on the ring
a simpler design by quite a bit and you
eliminate the need for that cue so
there's a perfect example of not
grabbing on to what you think of is an
attractive metaphor before you've
actually thought through all of all the
consequences it's also an example of
never underestimate the power of a smart
MIT undergraduate okay the architectural
curiosities in this system are it does
not have coherent memory I give another
talk in which I argue that coherent
memory is something that we should leave
behind now in the 21st century it does
not have bite addressing by the dressing
was something that was introduced
originally on the pdp-11 it's been with
us ever since and it causes a lot of
problems we have to fudge it because the
compiler infrastructure that we use
doesn't know how to compile for a non
byte address machine so we must fake
this it has no protection
that is a given a single process can
smash any other process now our view
about that is that we have raised in
software in the 21st century to get this
effect without adding complex hardware
and therefore adding more energy and
slower performance and so we ought to do
that in software it also has no virtual
memory system virtual memory was a fine
fine 20th century invention well it
served as well it's been used for a lot
of good things in operating systems and
as a protection mechanism but we also
have ways around that in the 21st
century so we actually argue that
perhaps we ought to rethink a lot of
those things it has no kernel mode
kernel mode is another way it's another
form of protection which you don't
really probably need anymore so the uses
of the thing well as I mentioned it is
being used in an architectural log
course and the nice thing about that
that at MIT is that the boards are
sufficiently inexpensive that every
student can have one or 15 student
course can have one and shared among
teams the very is simple enough that
students can make changes and try new
things this is much less and why much
similar to a very much like another
program the net FPGA program at Stanford
which is was started a few years ago by
a fellow named Nick McEwen who produced
a board and some coke courseware for
teaching networking design so the
students got a board and a very simple
ethernet switch and they evolved that
over the course of a semester semester
into a full blast internet router and
they were really
able to learn an awful lot about how
networking works by building things the
tool chain and libraries are very
familiar to academics they come in for
both of the major operating systems and
the initial results of this endeavor
into education on our part are pretty
promising in January of this year we
taught we help them teach a two-week I
AP course now at MIT that on semester
system and the students go away for a
month between semesters in the dead of
winter in Massachusetts some of an elect
to stay behind and take not for credit
courses which are pre volunteer they
just take them to learn things 14
students signed up for this course none
of them dropped out it was sufficiently
successful that they decided to do the
necessary work to teach a full semester
course which is called multi-core
systems laboratory at MIT and that's
running now and it looks actually fairly
good so the website for that is double
double web MIT edu six dot 173 and one
of the things we found as outsiders that
if you want to start a new course at MIT
the most difficult thing to do is to get
the department to give you a number
because once you have that number you
can teach anything you want but until
you have that number you can't teach
anything so the other major use for the
beehive that we believe will be pretty
interesting is research this is a simple
platform that provides a lot of the
things that you need not to experiment
with instruction set architectures which
probably have been studied to death over
the last 50 years but to add various
features to the architecture in order to
see how they work a couple
sibilities use message passing instead
of shared memory for can inter process
communication this was an idea that was
around in the 50s and 60s which got
abandoned pretty much in favor of shared
memory and we're not quite sure that it
should have been it has a lot of nice
properties that shared memory does not
have which make it much harder for you
to make the kind of errors that caused
today's 21st century programs to
misbehave the one that were interested
in at this moment is transactional
memory now the idea of transactional
memory is to this is something that has
been around for probably two decades but
has gotten a lot of interest in the last
decade there are only 500 papers in
journals describing various kinds of
transactional memory systems the idea
and the transactional memory system is
to build a system that has many of the
transactional properties that database
systems have that is atomicity
consistency isolation and durability you
can't have durability because the art
the thing that's being acted upon tis
main memory and if the power goes away
you've lost it but the other three you
can have and what we're interested in is
not so much designing transactional
mechanisms for their own as an indignant
selves but to explore whether this is a
better paradigm for programmers to write
correct concurrent programs programmers
today have a lot of difficulty with that
and in particular the programmers that
we see coming at us out of universities
have a lot of trouble with it there are
a lot of problems in writing correct
concurrent programs and we have examples
of how to do it written by experts and
it's still hard and I used to think that
this was a failure of the educational
system but I no longer do the problem is
that this is just in
parently difficult area of endeavor and
you can't really blame the educational
system when it tries to produce students
who can do it well um it's also the case
that transactions or I beg your pardon
that the kind of lock and thread based
programming that we have done to date to
solve these problems does not compose
that is if I try to build and
abstractions that's a composition of two
underlying abstractions that use locks
and threads I would have to know what
the underlying implementation of those
two low level abstractions are in order
to reason about the correctness of the
composition this violates construction
and if you are computer scientists you
know that abstraction is one of the most
powerful tools that we have to keep
ourselves sane and this gets rid of it
so we don't actually like that we would
like to find abstractions that do
compose possibly based on transactional
memory and experiment with them by
writing large programs and seeing how
they work the other problem with
transactional memory is if there aren't
very many implementations of those 500
papers they mostly describe
software-based implementations which
have extreme slowdown factors of 2 to 5
slow down over a lock based program no
one is going to going to use such a
system so we have actually implemented
in our laboratory a full blast full
hardware transactional memory system and
we're beginning to use it in order to
attack this high level problem of
whether transactional memory can form a
basis for better abstractions which we
think are the key to moving forward in
producing better programs and
simultaneously better programmers in the
21st century so we're looking at
questions like do we really need a lot
of those things that came out of the
20th century coherent shared memory
interrupts all computers have interrupts
well not always it turns out that
interrupts were invented precisely when
computers were extremely expensive and
the idea of leaving one standing idle
when it didn't have anything to do was
terrible because you were wasting a lot
of money because computer time actually
cost money in those days now a given
computer today in a particularly in a
multi-core system costs a few cents
maybe it's better to leave it Idol and
let it just look and wait for more work
to arrive virtual memory well I
mentioned that earlier we probably don't
need it an operating system operating
system well many things don't need
operating systems a lot of embedded
systems that don't arm they're good for
a lot of things you wouldn't want to try
to do what you do every day with Windows
without an operating system but for me
for many things we believe in you rid of
it the thing that we did not have the
goal in the design of beehive were these
we did not want to emulate particularly
want to emulate an existing instruction
set architecture the main reason for
that was not because we don't like them
but because they're not simple I gave
you the argument of the description
earlier of the open spark thing running
on the xup v5 very very complicated and
in particular architectures that were
designed for implementation in a six or
in custom silicon do not map well into
fpgas so the result of this is that we
can't do direct comparisons with
excellent architectures with the Beehive
system all we can do is a bee experiment
so the form if I have this mechanism
versus not having it how much faster or
different is my program oh we did not
have any plans to run real operating
systems we wanted primarily to run small
test programs big test programs
benchmarks things like that but a group
at our Cambridge
who's working with the Swiss Federal
Institute of Technology in Zurich ETH
have been building a experimental
operation operating system called
billfish which has turned out to be the
exception the oil fish is a system that
very much depends for its functioning on
message passing rather than shared
memory and it also does not rely on
virtual memory so in a sense billfish
was written for the beehive or maybe the
beehive was designed for Belle fish oh
so we're looking at that as a porting
target for the Beehive and who knows
maybe we will have a real operating
system running on it we have performance
as a non goal and the reason for this is
you cannot have high performance with
FPGAs anyway because the fundamental
logic is slower than it would be if you
built the custom silicon chip so all you
can do in an fpga-based system is try to
do research that can inform people who
design for real implementations you
can't you probably shouldn't think about
building competitive applications on
fpga yourself unless you have a very
specialized thing that doesn't do well
on a fundamental von Neumann
architecture likes a crypto arm or
certain kinds of signal processing
because single processor you very
efficiently implemented on fpgas but we
didn't want to be fast enough to run
real programs faster than a simulator
much of the work in architecture over
the last 25 years has involved a
tremendous amount of simulation and a
number of people have built very complex
systems for
or simulating things and for twiddling
the parameters of the simulations and
doing a lot of things without ever doing
any design unfortunately the programs
that you can run are pretty short and if
you want to run them on a multiple
processor system you can't run more than
a few seconds of execution unless you're
willing to spend weeks and weeks and
weeks so we wanted something that would
allow you to boot real operating systems
if you had them and be fast enough for
that and as I say the machine is about
as fast as a 10 year old or eight year
old pc whoops so the next step in this
project are to put it back to the b3 and
use it for larger things use it in our
own research at MSR we're quite
interested in architecture these days
because we're getting to the point where
we can no longer leave the hardware on
which our systems depend to external
people we need to be able to talk to
those people on their own ground and so
the first example for that is the xbox
where we were intimately involved in the
design of the fundamental hardware um we
do it carefully we do it probably slowly
but we're interested in it as I
mentioned transactional memory and gave
a few examples that's being done in our
silicon valley lab by my team the
billfish operating system i also
mentioned is being done in cambridge and
eth and we want to make it more widely
available for academic use and if you
want license you can just send me email
and i'll send you back a license for
research purposes
so i will run slightly under time but
i'll give you some final thoughts my
belief is that computer architecture
research has been in the doldrums for 20
years we've been waiting for the new
winds to blow our ships in some
direction and it hasn't happened now we
actually have not so much wins but waves
and we need to figure a way to get
around those waves or beyond them and
those waves are basically the fact that
we can't build faster single processors
in the 21st century we just cannot do it
present silicon technology has not yet
run out NORs law is still with us but
limitations on power and the
communication of signals around the chip
will require very fundamental changes in
the way we architect future systems and
so for the first time in a couple of
decades we have new on approaches to
teaching and research in architecture
and that is your job so i hope this talk
has helped you for have to think about
that in another way thank you very much
wait a minute you're the minis child who
has a yeah Chuck who has a 10 minutes
for question you feel you are like you
feel has a question to chop these razor
said it's possible microphone to to the
professor yeah microphone yeah
dr. Satcher thank you for a wonderful
talk and we have been watching your work
on p high for for some time and i was
wondering can for instance a graduate
student using your beehive to build a
deal type of a web browser within a
semester web browsers are ordinarily
application programs and so i think the
answer is yes but that's what you would
ordinarily do in the programming course
not in the architecture course now of
course if you had some new idea about
how to use hardware to accelerate some
act somewhat based activity then sure I
think they could but I think that you're
talking about is primarily something
that would ordinarily be done in a
programming course as it as it is today
no I actually wanted men too I suppose I
already have Wendy browser ready but I I
need you to optimize the unlock teacher
I think today's arbitrary is bad can I
use your beehive platform to to engineer
a and you are testing so I mean there's
no there's no reason that you can't pick
up that core and replace it with an
entirely different core it has a very
very standardized interface to the rest
of the system so yes I think you could I
mean we have examples of that in the
system itself there are specialized
processors that do things like we're on
the display and do high speed block
copying and a few other things calculate
ethernet check some mundane things but
those are examples of specialized
processors for particular things and if
you had something like that that you had
in mind and a good idea yes I think a
talented undergraduate could do that in
a semester okay thank you very much yeah
such a session to the questioner Pisa
tell us your name under your
University's first before I ask a
question thank you next one
thatÃ­s I okay yeah please
so as we know as multi current system
that becomes pervasive as we know as
multi courses we become pervasive so
there is some challengers for for
operating system and also the
concurrency program models so my
question is so in order to efficiently
utility the multi-core systems so it is
necessary for us to develop some
complete new operating system or
restructure or or based on the existing
operating system to handle the
multi-core system is it is it is it
necessary to have entirely new operating
systems I doubt it yeah those operating
systems have evolved in an ecosystem of
hardware / about 50 years and is it
necessary to make huge changes probably
not but the interesting question is to
look at today's operating systems and
ask what are the mechanisms that they
use that the hardware is not
particularly good at doing and I'll give
you an example our hardware is not
particularly good at digging out the
last bit of instruction level program
parallelism in a program that the
program we thought about is being
sequential it sends a lot of energy to
do that and one of the new things that
we have as a problem for our field is
the consumption of energy because
consumers are are consuming a larger and
larger fraction of the world's
electricity so we need to do computation
more efficiently one of the ways to do
that is to rethink our underlying
architectures does that help okay yeah
thank you yeah professor you tis a
beauty salon yet
acting is our University of Tokyo I'm
not an expert at architecture but so
you're in your slide that you listed up
the many sort of the features are the
tactic sure you are a design you are
between design and among that the list
so that such as a fpga-based or multi
core or transactional memory or and
message passing and so on so which of
each other then are so that how should I
say are designed for for the future in
the sense of the you of course you will
using fpga you you designed machine for
for convenience overall for the
lightness in some sense easy to publicly
easy to make but some of the features
you mentioned that they have a
transactional memory or hard core
message passing are sort of the looking
for the future aligning the episode the
thing you like as an active so i would
like to know that the web salute which
saw the peaches are most dancing in your
perspective okay well of course the
reason that i designed the beehive was
to be a vehicle that that students could
use so that was entirely apart from the
set of features that i added i added
some low-level features like the message
passing system and the way to memory
system worked looking forward two ways
that i thought we might use it in our
own laboratory for research i'm quite
certain that anybody who is in the
architecture game would pick a different
set of features have they been doing the
same thing but i was doing it and so I
got to make the choice okay we have a
ton for I lost the question yeah yeah
please that's the question okay
okay professor so thank you for your
talk and my questions it seems that to
the p-series not compatible for the
existing is a architectures so I wonder
such kind of training can such kind of
training how to help to the students who
will finally working on other eyes they
architectures well so far the b3 that is
the larger platform has actually been
used to implement of existing
architectures one of the major projects
that's been done with it at Berkeley is
to build a mini corps SPARC architecture
machine this is part of an effort to
build a thousand for multi-core so it
does it can be used to implement extant
architectures that wasn't what we were
trying to do so we we didn't want to use
an extra architecture for the reasons
that i mentioned that is that those
implementations tend to be very very
complex and therefore take a lot of
space within the fpga and reduce the
number of course we were interested in
the many aspect of many core research so
we concentrated on that but we had to
pick very simple chords in order to do
it that helped okay thank you yeah thank
you ok we wrap up this session yeah and
then another processor to chuck for your
great presentation thank you thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>