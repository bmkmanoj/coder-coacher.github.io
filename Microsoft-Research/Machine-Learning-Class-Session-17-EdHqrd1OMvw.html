<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning Class (Session #17) | Coder Coacher - Coaching Coders</title><meta content="Machine Learning Class (Session #17) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning Class (Session #17)</b></h2><h5 class="post__date">2016-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EdHqrd1OMvw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
my name is Chris Bishop I'm machine
learning researcher from MSR in
Cambridge which is the the real
Cambridge the oldy Cambridge over in
England and this morning in for the
first part of this afternoon we have a
series of three lectures on if you like
a slightly different perspective on
machine learning not so different from
what you've heard before but different
in some important ways they call this
model-based machine learning and give
you a little sort of roadmap of where
we're going we have these three lectures
and the first one is called a gentle
introduction and really the idea is to
assume no prerequisites so you may have
you know read about machine learning you
made the experts on machine learning but
this talk is really aimed at people who
are coming at this afresh and we'll go
over some very basic ideas there's a
little bit of overlap with some previous
talks I think that's fine I think the
basic ideas are very important it's
always good to hear it several times
sometimes good to hear it from a
different perspective so in this first
talk we're going to discuss some very
basic ideas the idea of reasoning
backwards and why that's a very
ubiquitous problem that we have to solve
we're going to talk about computing with
uncertainty and how we're going to do
that using probabilities we'll introduce
this idea of factor graphs in the second
lecture that's after the coffee break
we'll go a little bit deeper and well
understand what models are how we build
models and how we do learning in models
and learning I will call inference when
I say inference that's the equivalent of
training and learning and then after
lunch my colleague John Braun skill also
from NSR Cambridge is going to show you
how to turn some of these ideas into
practice using a platform called
inferred net which we've been building
over the last five years and which makes
this sort of vision of model-based
machine learning a reality so he'll be
giving you samples of code and talking
you through some case studies I also
have a little icon if you see that
little icon on a slide it's just a
little warning there's a little bit of
maths in there so especially this first
lecture in the first two lectures
actually there's there's almost no
mathematics but just occasionally I
can't resist
a little bit of mathematics because it
makes something so clear or it's so
beautiful I just want to share it with
you so I think there are maybe only
there maybe two slides in you know one
slide in each talk where there's a
little bit of mathematics so you see
that I can't just be prepared a couple
of little equations but for the most
part we're going to do this all without
using mathematics okay so our goal then
is to build intelligent software in
other words software which can adapt
which can learn and which can reason
about the world so let's look at some
examples of where we might want to build
intelligent software so let's consider
Xbox and people are playing games and
one of the things we're interested in is
the skill of the players oh we care
about the skill of the players because
of course the players want to compete
with each other so we need kind of
leaderboards who's the best who's the
second best and we also care about the
skills because on Xbox Live we need to
do real-time matchmaking so we need to
match up people of similar skills so
that they have a good gaming experience
now we can't actually measure a person's
skill there's no way of measuring a
person's skill what we can do though is
to observe the results of that person
playing games that say games of Halo for
example so we we observe the outcome of
the games then the outcome of the games
depends on their skill if they have a
very high skill level they're going to
win a lot of games another example might
be a recommendation systems the
recommendation systems are very
important the Amazon CEO claimed that
something like 20% of Amazon's revenue
comes from their recommender systems a
nice application of machine learning
let's take the particular case of movies
so we care about people's preferences
for movies now people's preferences
movies could be quite subtle quite
personal to them not just that they
always like action and they hate
romantic comedy it could be more subtle
we can't measure their preferences for
movies unfortunately what we can do
though is look at ratings people said
well I liked that movie I didn't like
this other movie clearly their
preferences for movies will influence
which ones they rate highly or which
ones they give a low rating to just a
third example imagine we're putting
words into a computer using a pen so
somewhere in the users head or some word
the words they want to input into the
computer we can't measure that directly
what happens is of course the user makes
gestures using the pen we observe that
electronic ink and the ink of course is
determined in part by the words that
they have in their head now in each of
these cases we can build something
called a model to describe what's going
on now explain a little bit later more
precisely what we mean by model but for
the moment when I use the term model you
can think of it as a mathematical or a
computational description of this
process the process by which players
have skills and those skills give rise
to gain results that's what I mean by a
model now the problem that we have to
solve is effectively the reverse problem
so you look at the the skill problem
what we observe are the game results
what we actually want to know are the
players skills so we have to reason
backwards likewise with the movie
preferences what we observe are the
ratings that people give to movies and
what we'd like to do is to infer their
preferences so that we can then
recommend movies they're going to like
likewise with the inputs what weari care
about of the words the person has in
mind what we observe is the electronic
ink we have to Rhys and backwards you
have to go from the ink to work out to
infer what words they had in there in
their head so this is the idea of
reasoning backwards and it's pretty
ubiquitous another very central concept
is the idea of dealing with uncertainty
so again if we look at that that example
of somebody playing Halo on on Xbox Live
we don't know a player skill we're
uncertain about a player skill we don't
know what it is
we have some idea but we don't know
exactly what their skill level is but
every time they play a game and they win
or they lose we gain some information
about their skill some relevant
information but even after we've
reserved several games we don't know
exactly their skill level so we're
constantly having to deal with
uncertainty we need to reason in the
face of uncertainty so what we need is a
principled way rather than an ad-hoc way
of dealing with uncertainty
and again this is this is pretty
ubiquitous uncertainty is is all over
the place which movie should the user
watch next what word did they write what
did they say which web page they're
trying to find what link are they going
to click on what products they're going
to buy and what gesture are they making
and so on so computers fundamentally are
deterministic they're logical things the
the chip manufacturer is good a lot of
trouble to make sure that each
transistor is either on or it's off it's
deterministic but more and more
applications today of computing involve
interacting with the real world
interacting with users operating in a
world of uncertainty so we're going to
use a kind of a calculus of uncertainty
and that's the the calculus of
probability so probability theory
probability theory actually in essence
is not it's not very complicated set in
the level that we need for machine
learning applications so probability is
a a way fact a unique way an optimal way
of quantifying uncertainty now you know
when you're at school and you're
introduced the idea of probability you
might be introduced to probability is
the idea of a the limit of an infinite
number of trials if I say that a coin
has a probability of landing heads of
0.5 then we can formalize that by saying
well if I take a very large number of
coin flips and I look at the fraction of
times that it lands heads that fraction
in the limit of an infinite number of
trials will tend towards 0.5 so the idea
of repeated events when we're going to
use probability in a much more general
sense probability is a way of
quantifying uncertainty I just give you
a little example supposing we have a
coin our motion to coins the bent coin
and let's suppose the physics of this
coin is such that 60% of the time it
will land concave concave side upwards
and 40% of the time it will land concave
side downwards okay so in a repeated
infinite number of trials 60% of the
trials that will land concave side
upwards now let's say one side of this
coin is heads the other is tails you
don't know which it is and I ask you
what's the probability of landing heads
next time round
well the rational answer is 0.5 there's
no reason to prefer one or the other so
the rational answer is 0.5 it doesn't
mean that you think that if you
flip the coin an infinite number of
times that 50 cent of the time it will
land heads you know that will either
land head sixty percent of the time all
of the land heads forty percent of the
time you're uncertain which so applying
probabilities here to a one-off event
which side is coins which other the
coins head which is tails
you can ask know we're the dinosaurs
wiped out by meteorite or by volcano and
you can express your uncertainty using a
probability even though it's a one-off
event even though it happened in the
past so many of you'll have come across
a lot of techniques in machine learning
and the field of machine learning as a
research fearless sort of half a century
old or more thousands of machine
learning researchers have been
developing lots of techniques lots of
algorithms they've given them names and
here's a list of just a tiny fraction of
them I'm gonna tend to call this
traditional machine learning I'm
struggling to find a good word for this
I'll call it traditional machine
learning it doesn't mean that it was all
developed in the last century much of it
was but I mean things like deep networks
which you'll hear about off to lunch are
quite a recent development this is
traditional machine learning so they
have a whole bunch of techniques and now
you've got an application that you want
to solve and in in this frame what you
do is you try to map your application
onto one of these techniques you try to
find a technique which you think is
going to be good for solving your
particular problem and not only that you
may be sort of influenced by the
availability of software you may not
have software implementations of all of
these so you may actually have a rather
restricted set of things you have to map
your problem on to a rather restricted
set of algorithms which you have
software available so in these in this
little series of three lectures I want
to contrast that with a slightly
different philosophy of machine and
entry called model-based machine
learning and the key idea is sort of
very simple the only is just to have a
single development environment which
supports the creation of a wide range of
models and those are going to be bespoke
models so the traditional view you map
your problem onto onto one of the
standard tools which you have software
the model-based approach you're going to
say what is the model which describes my
particular problem and you're going to
build a bespoke model
now there's some potential benefits if
we can achieve this vision the first
benefit is that your solution can be
optimized to your particular application
you're not shoehorning your application
into some predefined framework you're
developing something specific and
customized to your application so
potentially it could be a better
solution because it's optimized another
nice advantage is the transparency of
the functionalities you'll see in the
particular case of info net the model
can be specified by some cases you know
10 or 20 lines of code so that specifies
the model rather than thousands of lines
of code that defined the traditional
method so be quite easy to see what the
code is doing quite easy to modify it
quite quite easy to pass it over to a
friend who has a similar but different
problem who can take that model and then
modify it to the application another
nice advantages there's a clear
segregation between the model definition
and the training code I shall go to the
inference code we'll see what that means
later it means we can build
general-purpose inference engines that
apply to a wide range of models when we
get smarter at giving inference that
smarter infant is available to a whole
load of different models equally as a
user you can build a model for your
application you can it have to worry
about the inference engine that should
take care of itself another possible
advantage is for newcomers to the field
I think even for people in the machine
learning field there's quite a buil
during variety of different techniques
around and there's a vast literature and
getting your head around all those
different techniques is pretty hard here
you can learn a single modeling
environment within that environment as
special cases you can recover a lot of
those standard techniques so it might be
that you've got a particular application
you build a bespoke solution and it so
happens that your solution is pretty
much equivalent to something developed
thirty years ago and called the blog's
algorithm
well you didn't wreak air about that all
they care about is you're building a
solution for your application you don't
have to know all about the the blog's
method another I think very important
point here is the potential to avoid
what I call ad hoc solutions and we'll
sort of see some examples of this as we
go through the lectures but very often
you you know you're a domain expert in
your particular application you have a
lot of intuitions about how things
behave you know well you know any
sensible solution to my problem if if
this thing gets bigger this other things
should get smaller okay you kind of you
know if it doesn't happen there's
something wrong you know you know you
have this intuition you could try and
code that up you could say wow I could
make one thing the reciprocal of the
other so if one goes up the other goes
down but should it be one over should it
be one over there thing or should one of
the things squared or you know so when
you're in a sort of an ad-hoc
environment the lots of different
solutions it's not clear which one you
should choose for me my background is
theoretical physics quantum field theory
and one of the things I love about this
framework is that it's tremendously
elegant you simply describe your
application as a little probabilistic
model and then the rules of probability
will do the right thing automatically so
if one thing should go up when another
thing will go down that will happen
automatically in your model you don't
have to code it up you don't have to
figure it out it happens automatically
and for me that's one of the most sort
of compelling aspects of this view of
machine learning this course is sort of
a vision an idealization what we have is
Infonet is a platform that's still in
the development that it's already very
usable you'll see quite a few
applications mentioned during these
talks it's already available for
download and you'll hear a lot more
about that later on in the day okay so
how are we going to do all this in
practice then well they're really three
key ideas that we need to think about so
the first one I've encountered already
and we'll learn a lot more about this as
we go through the idea of using
probabilities as a quantification of
uncertainty the next day that I didn't
go to introduced is the idea of graphs
to express or models now we don't have
to use grass or grass or rather nice
people like pictures it's often quite
easy to see from the picture what it is
you're expressing so we're going to
introduce a particular type of graph go
to factor graph and we'll use that to
describe and the models in these
lectures and then finally we need to use
the model to make predictions and that
process will call inference so this is
this is analogous to the sort of
training or learning in some of the
traditional methods this is where all
the computation happens this is the
computational expensive part this is the
others just as computationally costly as
traditional methods and so we care about
making that efficient I'll say a few
words about
how we make less efficient okay so in
these lectures you'll see quite a few
real applications but in order to
introduce some very basic concepts I'm
going to use a toy problem it's sort of
like hello world for model-based machine
learning it is a toy problem but we can
introduce about 70 or 80 percent of the
important ideas using this very simple
example so this is the murder-mystery
then so fiendish murder has been
committed and we want to know who done
it
and there's our sleuth now we suppose
that there are only two suspects we've
got of course as always the butler but
we'll get the butler perhaps it was the
cook so we'll suppose that either the
butler done it or the cook done it will
also suppose that there are three
possible murder weapons that could have
been used as a butcher's knife there's a
pistol there's a fireplace poker all
right so let's introduce our first
concepts the idea of a prior
distribution so we have some domain
knowledge we always have some domain
knowledge and in this case we know that
the Butler fine upstanding Butler he
served the family for many years the
cook on the other hand was hired pretty
recently and there were various rumors
about a dodgy history and we don't we're
not quite sure about the cook so you can
represent this information
probabilistically so we'll say that the
probability as far as you can tell at
the moment the probability that the
butler was the person what done it is
20% and the cook is 80% we think it's
much more likely that the cook was
responsible for the murder than the
butler given the information we have so
far notice the the notation the notation
here probability that culprit equals
butler is 20% so P stands for
probability culprit is an interesting
quantity it's a variable but it's not
like the variables we you normally use
we normally think about sort of integers
and billions and and double-precision
floating-point numbers and so on those
are all deterministic variable
this is something more general this is a
random variable so if you think about a
boolean variable that's either 0 or 1
well in its stored in memory and either
has the value 0 or it has the value 1 it
has a particular value here where it's
in a two state variable called culprit
and culprit can either take the value
Buttler
or it can take the value Cooke we're not
sure which but we do know something
about it we know that it's 80% likely to
be the kirk and 20% likely to be the
butler so this is the probability that
the random variable takes on a
particular value and you'll notice the
values add up to 100% because we're
assuming in this model that either the
butler did it or the cook did it and
nobody else we can now represent this as
a graph so this is our first example of
a factor graph so a factor graph sir are
quite simple really
what you do is you have a circle for
every random variable so we only have
one random variable at the moment the
random variables called culprit so
culprit can take the state's Butler or
cook and it's represented by this circle
and the thing above it which is called a
factor so this little square represents
the probability distribution of that
random variable so that square
represents P of culprit so P of culprit
is just a summary of these two lines
here just encapsulates both of those
statements this thing sort of factor
graph we'll see a little bit later why
it's called a factor graph so that's our
first factor graph now of course so far
things aren't very interesting what we
need now is some some evidence so let's
look at the the murder weapon what do we
know about the murder weapon
well the Butler before he was our Butler
was in the army and he kept hold of his
nice British Webley revolver and he
keeps it locked away in his bedroom so
the the button has got a gun
well the Cook has accessed lots of
knives because the cook works in the
kitchen I will suppose that the butler
is fairly old he's getting rather frail
and perhaps using the fireplace poker is
not so plausible because that's quite a
physically demanding weapon the cook on
the other hand is young very fit
potentially could have used the poker
so what we're going to do is to capture
that again as a little probability
distribution so first of all let's
suppose it was the cook what done it so
we know the cook was responsible what's
the probability of the cook choosing
these different weapons well we don't
think it's very likely that they cook
would have used the pistol because the
pistols locked away by the butler good
chance they would have used the knife
they're working the kitchen lots of
knives possibly they used the poker as
well now these probabilities again add
up to 100% because if the cook was the
murderer then we must have chosen one
and only one of these three weapons so
the probabilities add to 100% on the
other hand let's suppose that it wasn't
the cook let's suppose it was the butler
what done it then we might have some
different probabilities the butler has
access to the pistol so let's say 80%
probability they would have chosen the
pistol and some small probabilities 10%
for the knife and the poker and again
these add up to 100% so these are called
conditional distributions because
they're conditional on knowing who
committed the murder okay so there's one
distribution if the cook did it in a
different distribution if the butler did
it and we have a notation for this so
this variable this is a random variable
which we'll call weapon and it has three
States pistol knife and poker so we have
P of weapon but the probability
distribution of the weapon depends on
who the culprit was so we have this kind
of notation P of weapon then with this
vertical bar and on the right hand side
of bar we have culprit it's called a
conditional distribution the way to read
this is probability of weapon given
culprit
it means the probability issues over the
weapon if we know who the culprit is
okay so this represents these two little
tables
so now we can extend off actigraph to
combine the prior distribution with the
conditional distribution so this is the
the prior distribution the culprit and P
of culprit and now we can introduce this
random variable weapon which is a three
state random variable together with its
distribution P of weapon but P of weapon
P of weapon depends upon culprit so
you've got a line joining the culprit
random variable to this factor because
this factor depends on culprit so that
dependency is shown by this extra link
in the graph so you call that the
conditional distribution we call that
the prior distribution
so in this case we have arrows I won't
dive into too much detail I want to keep
this fairly high-level but essentially
those arrows denote the fact that this
is a probability distribution so it's a
distribution over the variable which the
factors arrow is pointing at yeah it
means it's a normalized distribution
yeah so what we have now is a joint
distribution so what do I mean by the
joint distribution well I can ask a
simple question I can say there is
stirreth there are two possible
murderers and three possible weapons
there are six combinations of murderer
and weapon I can say what are the
probability then it was the cook that
committed the murder and they did it
using the pistol okay I can easily
calculate that because I know the
probability it was the cook is 80% and
conditioned on it being the cook the
probability that the cook could have
chosen the weapon is 5% and so the
probability of it being the pistol and
the cook is obtained by just multiplying
those together okay so you can you can
think of it this way time to call this a
generative you imagine repeating this
situation many many times 80% of the
time it would have been the cook that
did it so matter was a rolling biased
dice to to draw these random numbers 80%
of the time that would have been the
cook that did it on all those instances
where it was the cook five percent of
those the cook would have chosen the
pistol so overall it's 80% of five
percent which is four percent of it
being the cook using the pistol and
again we're a little bit of notation so
if you see P of weapon comma culprit
that's the joint distribution of the two
variables bonus to be read as P of
weapon and culprit obviously five other
combinations that we can do the mass fer
for all five it's very simple we come up
with this table so this is called the
joint distribution so each entry in the
table if we take sake this entry here
for instance this represents a choice
for the culprit and for the weapons and
this probability that the butler did it
using the knife and that's 2% again all
of these numbers add up to 100% because
it must have been one and only one of
those six possible combinations
so here we have a little a little rule
for calculating with probabilities we
call this the the product rule it says
the probability of weapon and culprit is
given by multiplying the probability of
the culprit with the probability of the
weapon given the culprit okay and or in
general for two variables x and y the
probability of x and y is the
probability of y given x times the
probability of x that's called the
product rule of probability there are
only two rules that we need the product
rule an equally simple one called the
sum rule we'll come to that in a moment
so those two rules of probability that's
all we need so here's our factor graph
let's just hide the variables look at
the factors well we've just seen that
the Joint Distribution
is obtained by multiplying the
distribution that this factor times the
distribution of this factor and in
general that's what these factor graphs
means the factor graphs tell us the
Joint Distribution of all the perhaps
millions of variables in our problem can
be expressed as the product of the
distributions over little subsets of the
variables each described by a factor
okay so there's just the product rule of
probability so it says the Joint
Distribution of everything described by
our model is obtained by multiplying the
factors together hence the term factor
graph
so so far we've kind of been reasoning
in in this direction okay so this is a
bit like going from the player skills to
the game outcome what we're going to
need to do is to work in the reverse
direction to reason backwards just what
we do though let's just have a look at
one final concept is the idea of a
marginal distribution so this is our
joint distribution table and we could
ask so each of these entries is the
probability of a particular culprit with
a particular weapon so could ask the
question what's the probability that it
was the butler that did it irrespective
of which weapon they used so let's say
we don't know what the weapon was we
don't care what the weapon was we just
want to know the probability that it was
the butler well all we have to do is add
up the probability for each possible
weapon used by the butler okay and we
get 20% and same for the cook we get 80%
and that's a relief because that was
what we fed into the model we've got it
back out again okay so so we haven't got
the math wrong we can look the other way
round though we could instead of adding
up the rows we could add up the columns
oh by the way so this is the sum rule so
remember this is the probability of
weapon and culprit and if we only want
the properties of culprit we simply sum
over the different values of the weapon
random variable or in general if you've
got P of X and y we just want P of X we
sum over the thing we're not interested
in Y all the thing we don't know so
that's called the sum rule and that's
that's all the probability theory you
need the product rule in the sum rule
and that's it
so instead of summing the rows we could
sum of the columns what that tells us is
the marginal distribution of the
different weapons so this is the
probability 20% the probability that the
murder was committed using the pistol
when we don't know or we don't care who
committed the crime
it was either the coconut butter we
don't care we just want so what's the
chance that was done by the by using the
pistol that's obtained by adding up the
the columns and again these numbers all
add up to 100% because it must have been
done by one and only one of those
weapons
now we come to the interesting bit okay
this is the bit that we really care
about which is when we reason backwards
to find a the thing that we were
interested in so we have noticed some
evidence we make an observation in this
case our sleuth has discovered a pistol
lying next to the body that's surely
pretty relevant to this crime what does
it tell us well let's look at that that
joint table this is the these are the
six possibilities that could have
occurred but we know it was done with a
pistol so you can just rule out these
two columns okay we know that they
didn't occur and we're left with these
two numbers 4% and 16% they don't add up
to 100% but what they tell us is the
proportion of if you like in this
repeated sample generative 40 experiment
the fraction of times that it was done
by the cook using the pistol the
fraction of times it was done by the
butler using the pistol and we could
normalize those fractions to 100% it
says that 20% of the time it's done by
the cook and 80% of the time it was done
by the butler that's the reverse of the
probabilities we started with it started
out we started out thinking was that
dodgy cook but having found a pistol
it's changed things around it looks like
it's the butler what done it so things
are pretty bad for the butler which was
obvious because it's a murder crime we
knew that all along so what we're doing
now is reasoning backwards so here's our
little factor graph this is the culprit
this is the the weapon and what we've
done now is we've made an observation we
now know the value of weapon so weapon
is going to be a bit like data in a
machine learning applications we're
going to build a model and then we're
going to fix certain variables that we
know the things we know that's our
training data and the third step then is
to reason backwards and to work out the
updated distribution of a culprit that's
the thing we just did by crossing out
the columns of that joint distribution
table so we can formalize that in a
little piece of mathematics called Bayes
theorem so here it is sort of in words
first of all what we have is a prior
distribution that was the initial
probabilities of Butler
cook based on their sort of history
after we make the observation that the
weapon was a pistol we could update that
distribution and we get the distribution
after seeing the data we should call the
posterior distribution what happens if
we now have more data supposing some
more information came along in some kind
of application
well the posterior distribution what it
really represents is our current state
of knowledge of the world taking an
account all the things we know so far
all the prior knowledge and all the data
we've seen so far if more data comes
along we can just apply the same
machinery so if you think of the
posterior distribution as being like our
prior distribution for the next
observation we'll see lots of examples
as that of that as we as we go through
notice that's intrinsically incremental
so I think increasingly a lot of machine
learning applications are online or
online in the sense of real time
interactive so a lot of traditional
machine learning algorithms you collect
the data in the laboratory you train up
your machine learning solution you chill
it all up and get it working really
nicely in the lab and then you give a
million identical copies of that to your
to your million users okay and it's sort
of a frozen solution and that's great
for a lot of things I mean that's how
the skeletal tracking system and Kinect
works or tuned up in the lab and then
everybody's got a Kinect got the same
trained decision tree classifier but a
lot of things we we want to solve
problems we're trying to make the
computer intelligent or a real-time
sense data's constantly being collected
the community making decisions its
quantity making inferences and we'll see
examples of that again as we go through
these lectures but this framework is
intrinsically incremental it's
automatically online all the information
you've got so far you use to compute
your current distribution your current
uncertainty expresses probabilities that
forms the prior distribution for any
future data that you receive okay so
warning little bit of math coming up
here so remember it's not that hard
actually remember the product rule of
probability P of X and y is P of Y given
X times P of X but by symmetry I could
equally well write as P of X given Y
times P of
I so I just applied the the product rule
twice to this joint distribution now if
I divide through by P of X what I get is
this it's called Bayes theorem P of Y
given X is P of X given Y times P of Y
divided by P of X it's a way of
reversing a conditional probability and
the reason why this is so fundamental to
us is that supposing we're interested in
the quantity Y Y might be the skill of
the player the thing would like to know
but we don't we've expressed our
uncertainty in terms of a distribution P
of Y along come some data X that's
relevant what we need to do is compute
this thing the likelihood P of X given Y
we multiply it by the prior this thing
is just a normalizing constant and what
we get is the posterior distribution
it's a new distribution for Y taking a
can to this new data X okay and if
another data point comes along X prime
we just take this P of Y given X
multiplied by the new likelihood and we
get the new posterior and so on so what
we've seen in in the murder-mystery
examples that there are kind of three
phases to solving a problem in this
model based framework so the first stage
is to build a model now to be a little
bit more precise about what I mean by a
model now by model I mean a joint
probability distribution over all the
variables of interest in your
application and a convenient way of
doing that is to express that as a
factor graph it's not the only way not
in this general way that for many
applications is sufficient so that's the
first stage to build a model the second
stage is to incorporate your observed
data so set known variables to their
known values they cease to be random
variables they become fixed to their
known observed values that's like our
training data and then the third stage
and this is where all the computational
grunt comes in is we have to do
inference and what inference means is
that we have to update the distributions
over the variables that we care about
okay we saw that with we really updated
the distribution over the culprit once
we knew what the weapon was and again
we'll see lots more examples as we go
through now if we're in a sort of real
time scenario we can simply iterate
steps two and three so we've done some
inference we now observe some more data
we incorporate those new
observations and we do some more
inference all the time our probability
distributions are evolving reflecting
our improved understanding of the world
all the computers improved understanding
of the world so that's what learning
means in this context so learning here
means the computer is updating its
probability distributions which quantify
uncertainty in light of data than it's
received and another thing we can do is
that if the domain changes or somebody
wants to ship version 2 and it's more
complicated we can simply extend the
model as required according to a
particular application perhaps by adding
some more variables and some more
factors question building DeMorgan
okay it's a great question I'll come
back to the question at the end if I
made that the question was and what if
you've got thousands of variables you
don't exactly know how they relate to
each other it's a great question and
generally speaking you know something
about your problem domain I think we
should seen some specific examples
you'll see what I mean by sort of
typical graphs and you'll think of your
application agai I can begin to see how
this this works in extreme cases you may
not be sure there may be some
uncertainty in the model should it be
like this or should it be like that well
you guys know what to do if you're
uncertain about something you quantify
your uncertainty using probabilities so
you allow both models to coexist you
might have an additional variable which
is the truth is model a or it's model B
you put a prior distribution over that
you run the whole thing through your
inference algorithm and you get a
posterior distribution say I'm not the
data says I'm 98% sure it's the right
hand model okay I'm pretty much done
with lecture what I'm going to now show
you a demo and then we can have time for
questions so the demo that I'm going to
show you is called we call this the
movie recommender demo so this is a
little demo that we actually built for a
public exhibition I guess it was was it
last year it was the three hundred and
fiftieth anniversary the Royal Society
that a huge exhibition in London on the
song River Thames on the south bank and
we built this as an interactive demo for
people to play with to try to convey the
basic ideas of machine learning from
this sort of model-based perspective the
demo was a failure in the sense that it
recommends movies and people loved it so
much we couldn't prize them away from
the demos because they want to know
which movie to watch next and that was
kind of hard to explain machine learning
but hopefully we won't suffer from that
problem today the engine behind this is
something called matchbox and matchbox
is built on Infonet and matchbox is used
for large-scale recommendation
applications what we've done though is
put a simple demo front end on just to
so I can use this to explain the idea of
of really of probabilities
so the system is already seen I think
the data came from Netflix so there are
100 movies here the database has more
movies than this but these hundred
movies we have hundreds of thousands of
recommendations from tens of thousands
of people and the system has already
seen that that data and what we're going
to do now is a bit of personalization so
it's going to customize to my movie
preferences now in a real recommendation
system and in Matchbox itself you know a
lot about the movies and you might know
something about the user you might know
the gender of the user or the age of the
user for each movie you know that's a
romantic comedy or an action-adventure
and so on so already from known
population correlations between features
of the user and features of the items
which are movies you can already make
recommendations out of the box purely
for the purposes of this demo we're not
using any of that information right so
as of now each for this demo each movie
is just movie 127 okay and I'm just the
new user so the system there's nothing
at all about me so we're just going to
use collaborative filtering I'm gonna
make recommend watch movies I'm gonna
say I like this one I don't like that
one and it's gonna combine that
information with the likes and dislikes
taken from the from that database so
just to prove a point we're not going to
use any of the the features but match
box itself which is described by a
factor graph which uses inference to to
make these recommendations can use both
features and collaborative filtering and
this is a nice example of I guess the
avoidance of ad hoc solutions which I
mentioned earlier so out of the box well
you know nothing about the user or
you've got a new movie you know nothing
about the movie in terms that we have no
recommendations that is then the only
thing you can use is features right I
like action action movies and this is an
action movie so the chances are I'll
like it but once you start to see
recommendations from an individual user
you can start to tune or customize the
recommendations an author I've made
thousands of recommendations you want to
base it mainly on recommendations not on
these features
so you've got to sort of gradually fade
from initially using features get to
give more and more weight to the
recommendations as you see more and more
recommendations that happens
automatically in Matchbox just because
of the summon product rule of
probability you don't have to code that
in in some sort of ad hoc way okay but
for this demo then it just knows about
recommendations have to find the cursor
okay so initially then it knows nothing
at all about me when I say I've watched
a movie let's say I watch pretty woman
what I'm gonna do is drag that across
into the green area which tells the
computer I've watched the movie and I
like that movie what it's done now is to
arrange all the other movies on the
screen in a particular way now the
vertical position on the screen is
irrelevant
we've just spread them out vertically to
make them easier to see what matters of
the horizontal position
the horizontal position of each movie is
the probability that the computer thinks
I will like that movie so for movie is
up against the right-hand side here
that's probability of one the computer
is certain that I'm going to light that
movie if the movie is down the left hand
side that probability zero it's certain
that I'm not gonna like the movie movies
down the middle of 50/50 now at the
moment what is it no it's got tens of
thousands of people and hundreds of
thousands of recommendations but as far
as I'm concerned all it knows about me
is that I liked pretty woman but already
is enough to start to make
recommendations because people who like
pretty woman also liked other movies and
hated certain other movies and so it can
already assign a probability to each of
these movies but what you'll notice is
there sort of clustered around the
middle most of the the movies are sort
of near the middle there's a little
white space down the left and right
after all all it knows is I like this
one movie it hardly knows anything about
me so it's pretty uncertain about which
movies are like which ones I won't like
so lets and carry on let's give it some
more information let's say I've watched
another movie so I didn't like that one
even after just two movies you'll see
what's happening as things are spreading
out there spreading out towards the
right and towards the left or they're
moving towards zero and one the system
is now a bit less uncertain about which
movies are like which I won't like so
that's what learning means in this
context it's a reduction in uncertainty
as a result of seeing data and it's
intrinsically online because I can just
carry on and give it more examples of
movies that I like and movies that I
don't like I keep losing the cursor
because some sort of dual screen there
we go so let's say I'll pick another
movie that I don't like again there's
sort of some rearranging but generally
thick generally things are sort of
spreading out to thee or maybe I do like
that movie gave me ABS of different
results you can play with this all day
but even even after just three examples
or maybe just four examples
okay so there's four examples two that I
like into that I don't like and you can
see now what's happening there's now a
lot more white space down the middle a
lot of movies are crowded down the the
sides nothing's right up against the
side it can't be certain that I'm not
going to like a movie but it's it's
pretty confident that I'm not gonna like
these movies it's pretty confident that
I will like these movies and they're
ones down the middle it's just
completely 50/50 about whether I'm going
to to like those ones we just illustrate
one more point let's suppose let's take
a movie write down the right-hand side
oh yeah somebody likes there's work like
that other movie you said it doesn't
think in the garden that meant either
like monkey toys
I think okay I think the question was
basically how does it work and I haven't
really sort of explained how it works so
the question really well there's no
metadata how can it know what's going on
really what it's doing is just you know
your intuition is that if there was
somebody else in the room that lights
pretty woman like Chicago they hated the
sound of music and they hated elf and I
asked them well what did you think about
closer and they say a great movie okay
well you know I seem to be like that
person and so maybe I too will like
closer so that's kind of the intuition
so before the lecture when we built the
demo we already you know trained it in
inverted commas on a database I think
it's Netflix data where we've got you
know hundreds of thousands of ratings
from tens of thousands of people so you
imagine there's sort of big big matrix
of sort of movies and and people and
it's a sparse matrix but there are
entries occasionally as an entry where
somebody said like or an entry where
somebody said dislike so it's kind of
that the intuition that you know people
like me will like future movies that I
you know will have similar taste to me
but we haven't done it sort of code up
that intuition because are lots of ways
of doing it and how do you know how to
do it it's just it's so it's an ad-hoc
mess instead we built a model which
describes the relationship between these
variables express probabilistically are
you showing this okay so this afternoo
you actually see John Bronk is going to
show you the factor graph thought for
how this works there's afternoon and
property some infidel code for it as
well I'm just going to show you one more
thing let's take a movie down the
right-hand side so that's a movie that
the system is very confident that I'm
gonna like I just pick one of them so
let's say I've watched that movie and
let's say I do like it so watch what
happens when I let go of the of the
mouse button watch what happens the
other movies we're not a lot
okay it's really confident I was gonna
like the movie and I said yeah I like it
okay
hasn't learnt very much because it kind
of knew that already
let's do the other extreme let's take a
movie that's down the left-hand side now
here's a movie it's really confident
that I'm going to hate that movie let's
say match yeah I watch that movie and
actually I like that one so I'm going to
drag this across to here now look what
happens when I let go of the mouse
button okay that that was hugely
informative in fact you know information
theory and defines information as the
degree of surprise okay so towards the
right hand side you might have surprise
in saying I like that movie goes to zero
across the left hand side it goes to
infinity so there's much more
information in telling it something
surprising that it wasn't expecting then
selling that sum it kind of already knew
question was the error and the noise
right great question so the question is
well could this be affected by noise
could it be affected by mistakes
it could be affected by things like
mislabelling you know somebody watched
the movie they really loved it the only
big Harry and they click dislike and
then they carried on they didn't notice
or the system wouldn't let them change
it or whatever so we could sort of label
error and so on so generally speaking
the answer when somebody comes along and
says oh this is all very well but in my
application domain it's different
because in my application domain I have
users who make label errors right they
occasionally flip the label is it great
you've just told me how to extend the
model for your domain so in your domain
there's a label error so we'll put a
label error variable so what we might
have is if you like the true variable
which we can't observe what we actually
observe is the label the user gave and
that's a noisy version of the truth
right we have a little probability a
little prissy table it says well 99% of
the time the the label they give is the
thing they meant to give and one percent
of the time they a flipped it okay
so what we do is we just model it and
then the rules of probability all do the
right thing yeah
so do you need that in that case you're
actually doubling the number of
variables but because one of them is if
the actual state yeah otherwise because
they you have survived the question was
am i doubling the number of variables do
you mean in the little example I gave if
the noisy yes you're introducing extra
variables yes actually two people are
the users and they're very different
rates because the model said there's one
user is there a way to quantify that you
model it like I've seen so much did I
was not able to learn anything I'm just
not able to successfully predict
something so I want if I this
information is saying okay the model is
wrong maybe should because we're okay
I'm not sure I understood exactly that
scenario I think the question was and
can i quantify the fact that I may have
the wrong model so some you give us a
slightly general answer to I which was a
model miss specification so what you've
done is you've written down a model of
the world and what happens if that model
is wrong that's a very general question
in machine learning okay so it applies
equally traditional methods or two to
model based methods if you assume if you
use a linear regression system you model
well as a linear model and the world is
highly nonlinear then you can get very
wrong answers if you make some
assumption out the world this one will
be violated then you can make
arbitrarily bad predictions and that's
true in in any approach and that's
certainly true here as well what you can
do though is allowing for the fact that
the world may be more complex than you
thought so it might be that there are
other processes going on we've had a
couple of examples sort of label noise
and so on and you can model those you
can model those causes of miss
specification if you can anticipate them
and maybe you come back to the earlier
point maybe you're not sure whether you
should include a particular effect or
not I don't know whether my users are
flipping the labels timber send at the
time or they're actually there they're
all completely correct and so you can do
model comparison and a very nice way of
doing model comparison that's how you do
model comparison Infonet
you
to have one model represented by graph
over here another model represented by
graph over here and now you construct a
sort of uber graph where you have a
switch and the switch switches between
the models and that switch is a little
binary variable that says model a or
model B and you put a prior distribution
on that maybe 5050 because you you're
not too sure maybe it's 6040 whatever it
is that's now your model that that big
model contains the two sub models now
you do the second step which to
condition on the data you observe the
data and you run inference and what you
get is inferences made by model a
inference is made by model B and a
posterior distribution over which is the
the right model so question is there a
New Year's or a new movie can it handle
it yes I mean what's essentially going
on in in here we'll look at the factor
graph I guess there's afternoon there's
a very general technique or a quite a
wide spread technique or matrix
factorization so you take that big
thoughts of a matrix and try to
represent it in a low dimensional space
so so matchboxes if you like a
probabilistic version of matrix
factorization ok so what's going on if
we have some low dimensional agents
patient five dimension or ten
dimensional and the users a map's down
into that space and that mapping is one
of the things we learn so there are
parameters governing that mapping there
are prior distribution server those
parameters there's another mapping from
items down into that latent space again
governed by a bunch of parameters again
they're distributions over those
parameters and we have some notion of
affinity or closeness symmetric within
that space which represents how you know
the alignment between the sort of you
know the vector of the user and the
items so whether a user tends to like
particular items tend to dislike other
items and to users are very similar
we'll have vectors that are quite
closely aligned uses have very different
taste will be far apart in that space
and again all that is represented by
probability distributions expressed as a
factor rough
okay so I think the question I'll repeat
the question and tell me if I've got it
right so the idea is supposing we've had
a million users or a billion users and
along comes little old me and I'm the
billion and first user isn't my data
gonna be completely swamped by the data
from those billion users and it will
take four I'd have to rate a billion
movies before it even starts to
personalize to me absolutely not again
if you construct the model the way you
want to construct the model we're gonna
have a look at a nice example of
personalizations after new context of a
V mailer we can talk a little bit more
about that then again it does the right
thing so it's making the right
trade-offs between sort of community
predictions versus personalization
predictions and it's starting off out of
the box with the community prediction
because it knows nothing about you and
then making appropriate adaptations as
it starts to know more and more about
you and that that trade-off that
gradually fading out the effect of the
community and fading in the effect of
your personal data happens automatically
from the sum rule and the product rule
of probability okay you don't have to
think I'll make it one over T or
something you know it just happens
can differ from the attraction for
multicast learning kind of methods like
you know we saw that I think yesterday
how does that difference is there is
there an edge for this model over that
one how does it braid against other
traditional methods I'm gonna confess so
I you know I've only just flowed in I
haven't listened to all of the other
lectures so I I am can we what we may be
do is take that there's also an email
list around this you know so I maybe
have a chance to watch the lecture and
give you an answer I'm very happy to
sort of make points of comparison
between this a very tackle a challenge
in this approach versus some more
traditional methods but I wasn't
familiar with a particular piece of
jargon you used and the so I will I'll
defer that if I may offline yeah take
one how to select priors yeah okay so
you know this is a gentle introduction
all right and we've you know there's
more to come so you know hopefully in
the next lecture you may get some
insights into into how we select priors
and I'd say I've used the term prior and
posterior because you know it's commonly
used and it's one way to think about
these things but I tend not to think too
much really about prize and posteriors
but just about models and distributions
and their relationships and it's really
back building a model of the world now
in the next lecture you'll see some nice
examples we're so in the in the in the
murder mystery I just pulled those
numbers out of thin air I just said well
okay the the butler's more likely to do
it than the the cook I'll make it 80% or
so the cooks more light so in the butler
I make an 80% cook and 20% blunder why
80% 85% we're not seventy five percent
so quite often we have distributions the
distributions have parameters and we
don't know what value to set the
parameters to well we know what to do
right we model the uncertainty in those
parameters by using random variables
which themselves have distributions and
that needs Latin that leads naturally to
hierarchical models so it's we have
distributions with parameters those
parameters uncertain we want to learn
them from data we don't a handcraft them
so we put distribution
over those parameters but those
distributions ourselves have other
parameters might call them hyper
parameters and we have to stop that
hierarchy at some point the answer in an
engineering sense is well just look at
some of the examples I think the best
thing to do is just look at a dozen
examples of the applications that and
you'll kind of get the flavor for how we
build these models I guess the the more
sort of philosophical answer is that in
machine learning no matter how you
approach machine learning you can't
learn anything purely from data those
are some fundamental mathematics and
machine learning that says you can't do
this
you only learn in the context of
assumptions or a model or prior
knowledge or background information call
it call it what you like so you assume
something about the world sometimes
those assumptions are quite general you
might assume that the output varies
continuously with the input or it very
smoothly so if you model it by a neural
network you put a regular Iser on the
weights you're saying I don't think the
output is going to vary too much if I
change the input a little bit okay
that's a form of prior knowledge you
might have much stronger prior knowledge
you might say the output is a linear
function of the input with some Gaussian
noise or something okay that's a very
strong form of prior knowledge roughly
speaking if you constrain the world very
tightly you get a lot of juice out of
your data you learn a lot from each data
point so that's good news provided your
assumptions map to the real world if
they don't map to the real world all
this if you assume the worlds linear and
it's nonlinear then not only can you
make bad predictions being leaves me
very confident about those bad
predictions so that's not good and the
other extreme if you make almost no
assumptions about the world so you have
very very flexible models in the
traditional paradigm you hit a major
headache it's called overfitting and
supposing I've got a hundred data points
I say oh I don't I don't assume anything
about the world I just want the data to
tell me everything so I'm gonna I'm
gonna fit a hundredth order polynomial
to my ten data points good 900 of
polynomials really flexible if your
model all sorts of different things what
happens you just tune up to the noise on
the data because in the traditional
methods you're typically optimizing
parameters or making point estimates of
parameters you can to overfit to the
data so that that's that's one of the
challenges that you face and there are
ways to deal with
of course I'm sure you've heard about
them this week to deal with overfitting
in that traditional framework in this
framework there isn't really overfitting
overfitting is a sort of a pathology
that arises when you make point
estimates what happens in this domain is
that if I have a very flexible model
with very broad distributions when I
observe data my distributions get
narrower and I learn stuff about the
world but I still have a lot of
uncertainty so I'm hopefully still
encompassing the truth we're not sort of
very confident about it so if we get
time I don't think now is quite the
right minute we probably know a little
bit more about this but one of the one
of the nice things in a probabilistic
model is you can get the data to choose
between different models for you I
mentioned how we can do this in info net
with a little switching variable and we
try to give you some intuition behind
this we're sort of zero math it's sort
of like this imagine I've got three
models the first model says is a very
rigid model right it's very it's very
imposing a lot of prior knowledge that
the world is just linear very
restrictive model I've got a second
model which says well it could go up and
down a little bit but it's kind of you
know one or two oscillations is fine the
third model says Oh hugely flexible if
you go up and down a million times we
have step functions it can be a frack -
all sorts of things right a very
flexible model if you simply fit those
three models to the data by optimizing
the parameters then you'll always favor
the most complex model because it will
just tune all the data it will fit the
date point exactly all over fit it'll
say it's the third model so you can't
choose the model by tuning by optimizing
the parameters all you have to do
instead is divide your dataset up into
into two train on one half and then see
how predictive it is on some holdout
data okay that's that that's the
standard technique and widely
established in this probabilistic
setting let's suppose that the truth is
actually the middle model okay the data
you know the real world is sort of goes
up and down a little bit but not too
much let's look at the posterior
probability of the three models so I'm
uncertain about which models I'm going
to keep all three models I'm gonna have
a prior probability of 1/3 1/3 1/3
what's the posterior probability of
those models when I run inference
while the first model the rigid model
will have a low probability of a low
probe is basically can't fit the data
the lathe is going up and down it's
trying to fit it with a straight line so
it's a really bad mismatch between the
data and and the model so that model has
a low posterior probability the middle
model does a lot better because it can
fit that data beautifully okay so it's
got a much better data fit the third
model can fit the data just as well in
fact fit the data even better because it
can tune to all the little noise but the
problem is that the the model has a sort
of a unit remember all the properties
add up to 100% so each of these models
has got a unit amount of predictive
probability which it can spread around
so the first model is piled all its
property all its predictive probability
on just straight lines and none of them
fitted the data so that was bad the
middle model kind of spread its bets a
bit more and it said well it could be a
straight line it could go up and down a
little bit or down and up a little bit
and so the probability which actually
assigns to the data is higher because if
can assign a decent amount of providence
the actual data you observe the third
model can can explain the data you know
perfectly but it's unit amount of
predictive probability mass has been
spread incredibly thin because it can
brick straight lines it can bricks
things which go up and down a little bit
things go up and down a lot things which
have steps and so on and so the amount
of probability mass that it assigns to
the observed dataset is actually lower
than for the middle model so the
posterior probability Peaks around the
middle model okay that's the mr. old
model and that was without having done
any holdout data that's on the training
data okay now you're saying at this
point well who cares you know I've got a
big computer I'll run it what's the
problem is running on my training data
and compare it on a test set well
there's nothing wrong with that in fact
you should always do it no matter what
method you're doing before you ship
something to the customers I strongly
recommend you test it on some view data
right that's just good sound engineering
the thing is supposing it's not just one
thing you're trying to tune if you're
just trying to tune a regularization
parameter sure I could run it ten times
with 10 different regularization
parameters on my training set compare
the ten models on the test set and pick
the best what if I've got a million data
points and I've got one regularization
Hammad appered / data point over a
million parameters to tune
I can't run all these different
combinations of a million parameters and
keep testing them I have to be able to
learn the parameters and the hyper
parameters from the training data and so
that's where some of these methods can
be very powerful with a very long-winded
answer to a short question but you've
never seen of you sir and I understand
differently okay so I think this
question is sort of about your specific
application a particular issue that
you've encountered and I think my
experience with these questions what how
it happens I'm gonna have to ask you to
expand on it and then you and I'm gonna
have a half-hour discussion at white
board which I'd love to have but that's
probably not so that's quite a specific
question so maybe we can talk or
exchange email and discuss that
particular question but it's obviously
not it the question was to do with cold
start problems I think in an advert and
situation and you've already thought
about it very hard it's obviously hard
problems there probably isn't a
10-second answer so we should we should
discuss that offline I think
maybe last question
like all many juicers judgments
give up the second one is the gravity
could be very large
is that like a certain way to control
the size like you know you know may have
many connections and actually have
foundations let's just do with that
second part first then so the question
was if the if the if the underlying
graph we haven't sown yet becomes very
large was the question then what's the
problem
okay so there are lots of design issues
in terms of designing the graph I mean
again can I give you a general answer
rather than this with a very specific
answer I think one of the one of the
advantages of this this framework is
that I said we have to make assumptions
you cannot do machine learning just from
data alone is data in the context of
some assumptions and one of the nice
things here is that you you make the
assumptions very explicit that you're
forced to make them explicit because
step one is to write down your model so
you really have to come clean and tell
the world what you believe about the
world you know it can't be buried away
in some implicit sort of in the training
algorithm somehow but it has to be in
the model you have to make your make
your assumptions explicit in the model
and part of those assumptions has to do
with the structure of the graph and you
know again that comes back to the points
we made earlier where really this is the
domain knowledge that you're encoding
but sometimes you you know I think you
were talking about skip level
connections between parents and children
of other variables are they present are
they not present again one thing you
could do is just to compare the two
models if you're genuinely uncertain you
could look at both models and see which
one the data prefers what so you'll go
back to that first what was the first
question
and okay a lovely question how many data
points do I need to get good performance
on this application or any other
application and you know the answer is
42 and
the answer is I don't know it no it's so
dependent on the problem right I mean
that's not there's there's no there's no
magic all right the answer is it will
depend upon the you know the particular
application that you have but I think
the nice thing about this framework is
that if you only have a little bit of
data you can still use your full model
you don't have to adjust the model the
amount of data that you have there's a
funny thing to do say I've only got a
hundred data points I'd better only fit
three parameters otherwise we'll over
fit well hang on if you really think the
world has 127 parameters surely that's
how you should model the world
okay so you can use your you know your
full-blown complex model that you really
think describes the world and we only
see a few data points that's fine you
won't have any overfitting what you will
have of course is still a lot of
residual uncertainty I mean only seen
three data points there's no again
there's no magic here I've only made a
you know after a couple of movie ratings
it knows something about me doesn't know
everything about me are still quite
uncertain I was told to an hour 20
minutes for a break so we'll take a
break now and then we'll have another
and we'll just go a little bit deeper
into this topic and starting at 11
o'clock</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>