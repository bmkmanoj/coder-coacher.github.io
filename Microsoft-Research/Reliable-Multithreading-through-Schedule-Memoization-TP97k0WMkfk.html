<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reliable Multithreading through Schedule Memoization | Coder Coacher - Coaching Coders</title><meta content="Reliable Multithreading through Schedule Memoization - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reliable Multithreading through Schedule Memoization</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TP97k0WMkfk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi everyone I'm modern Maserati from the
research in software engineering group
and it's my utmost pleasure to introduce
June fengyang today he is an assistant
professor at Columbia University and we
go long way back we met in graduate
school so he worked on model checking as
well and he applied model checking to
find lots of errors in the Linux file
system and then he moved on to apply
those techniques to distributed systems
and recently he's been working on
reliable multi-threading you know how do
you get deterministic semantics to
multi-threaded programs he recently
received an NSF Career Award for this
work and shall be exciting to hear more
about it sure thing thanks for the
introduction and thank you guys for
being here the since this is a small
group if you guys have any questions
feel free to interrupt me right and I
actually tend to explain things better
if it's more interactive so this talk is
about our recent work on making
multi-threaded programs more reliable
and you know the key idea here is called
schedule memorization which I'll explain
in detail in this talk and this talk is
based on the work coming from two papers
osei paper and the system is called turn
and another paper as its paper the
system we kept every and this is joint
work with my students elementary junior
whoo John Gallagher I on go and judges
hi these are great students I like
enjoyed working with them if you guys
looking for internships look pretty
intense right actually on the talk to
these students okay so let's look at a
few trends that shape our computing
today the first Trent is a hardware
trend the machines are getting more and
more cords so this slide shows the
number of course for AMD opteron
processors as you can see you know in
2010 we have talked horse and the
magny-cours no processor how do we use
all these course developers are rating
one multi-threaded code the second trend
is a trend in software the coming storm
of cloud computing so we have more and
more users connect
to the cloud of servers there are more
and more devices connect to the service
as well and this creates lots of
computation at the same time the
commutation actually is aggregated on
these no sores in the data center array
so how do we get good performance in
this setting well for performance
virtually all these servers employee
multi-threaded programs so at the same
time multi-threaded programs are known
difficult to get right right they often
contain no so tricky hazen bugs right
data races for example that sometimes
show up sometimes these peers it's
really hard to write test and debug
these multi-threaded programs and the
key reason i believe and also my other
researchers also believe that these
programs are not into music right we
will run them it's like you're doing a
coin toss sometimes you get has some
time to get tails right success or
failures specifically today when we run
the multi-threaded programs even when we
run this program on the same input right
we run it repeatedly this time we may
actually use a difference reading the
leaving or schedule right this rectangle
represents a input any time we run it we
may get a different schedule essentially
there is a one-to-many mapping from
improves to schedules so this 90 terms
them actually complicates a lot of
things for example no testing becomes a
lot of less assuring right lots of these
many of these schedules actually good do
not contain bugs but some of the
schedules contain your tricky areas such
as your databases are these concurrency
errors and when we test a program we may
run into these good schedules right
there for the bugs did not show up in
the testing lab but once we ship the
code and users when they run the program
the material is rare in the leavings
where the bugs show up right get crashes
similarly debugging becomes very
complicated because in order to not
track down this bug right maybe how to
reproduce the same bugging the living
which can be changing
so recently researchers have proposed a
great idea called eternity is
multi-threading which conceptually
forces a program to always use the same
schedule on the same input so
essentially there is a one-to-one
mapping for existing dmt systems you
know we run the program on the same
input regardless of how many time please
run it each time no we always run into
the same schedule ray so this idea is
great it solves a lot of issues caused
by not eating them but at the same time
this existing systems actually suffer a
limitation if you basically make the
schedule tightly dependent on input if
you change the input slightly let's say
you just go change the input by one bit
for example and these systems may force
the program to run into a word different
schedule which may also contain box
right there is this tight sensitivity
input sensitivity the Tadzio input
dependency for existing the empty
systems and you at as it just mentioned
right so some of these schedules can
also contain bugs and this will
complicate testing as well because you
know it can test some improves in the
testing lab rep I cannot cover all the
inputs but when ship the program to
end-users and they run out some slightly
different inputs they may actually run
into bugs ray assimilate debugging
becomes challenging because in order to
reproduce this pack execution we have to
reproduce exact the same input right of
the input coming from the environment
you know other bids have to match which
can be hard you know for no tagging
reasons or privacy reasons and by the
way you know actually did observe this
behavior if you change impulse lightly
the bug show up if it's an input you
know more about these peers right with
existing the empty systems so to address
this instability problem and it really
reduces and stable behaviors we propose
the idea called schedule memorization
the idea is to you know memorize the
schedules that you know works in the
past right and then the future input
comes we can try to reuse these
schedules right therefore can avoid but
potential and known schedules and also
buggy schedules and we call this your
stability right so you know we hand out
to the goose schedules well test your
schedules in your future you know if new
input comes we'll try to reuse
these schedules that are shown to work
therefore avoid bugs in there are no
schedules you guess questions so i guess
you a typical question i got here is you
know if you do this right sort of leave
with the program which contain bugs
right because you know you'll hand out
to the schedules which do not contain
bugs and the program itself is not very
correct right and my answer is uh you
know this can be turned on right this
technique can be turned down for
production systems right we actually
deploy the system will ship the code to
users you can hand out to the goose
schedules ray and why the schedules we
have not tested right when testing you
can turn this technique off and use
techniques such as chess to actually
explore different schedules and get a
set of crack schedules right there for
you and then ship the schedule together
with a program to another's question
right so I'm going to explain what the
same yeah I'm going to explain that
defined schedule what schedule is right
next to your slice so let's recall was
just the first system that implement the
schedule validation idea urn because you
know this idea actually matches our
natural tendencies writing animals and
humans no we repeat familiar rods and
avoid errors he and unknown Ross this
side shows the migration Ross for porous
race but basically the migrant birds
they follow this fixed Ross they don't
run into random laws and no our season
the first system the implements get
memorization is called turn which is you
know after this acting turn word and the
word species that migrates along is
among all know animals as feature of
Arctic Tern
okay so now we can you reuse schedules
for different inputs right but I pick a
key challenges you remains which is you
know from the trimming them or
efficiency right your fruit note you can
only pick one you cannot pick both I'm
going to explain you know what I mean by
it you turn them are you finish to see
in the next few slides and also define
what the schedule is so at that language
level where does not eating them come
from it may come from mainly two sources
first you know we have not eternity
signalization for example locks right so
the logs can be acquired in different
others this slide actually shows a block
in a party that's caused by not eternity
synchronization the first wed acquires a
lock and a science use these objects
shared object and the second thread
raised this object and they both your
computer for the same log if the code is
running this other code is correct
however if he is running the reverse
other way because you know we have this
not eaten anything other in terms of
Locker condition and the code will run
into a user after three crash so here at
this piece of code crashes or runs
correctly depending on simulation order
another source is not interment source
is a data race this slide shows a
database example from one of the
benchmarks we use FF implementation in a
splash to a popular a parallel benchmark
to hear this first red thread 0 prints
out some results and threaten one
actually compute the results right
there's computation there is a print
right if the risk is result this way we
get crack results however if the race is
filled out the other way actually print
out wrong results right but here this
piece of code prints out correct or
wrong results right depending on how the
reeses a result right other of memory
accesses to an email you know this two
types of not eating them researchers
have proposed two types of schedules
right the first is called sync schedule
basically is a total order of decreasing
order of civilization operations such as
log and unlock operations the second
type is a determinist other of shared
memory access operations right reinforce
the other around load and store
operations to
memory location the both perhaps of
schedules have pros and cons so sync
schedule basically there for this
project example if we just enforce this
all the way or we enforce this other
either way right we can make this code
is music right bug always show up at the
park always not show up right so the
advantage here is is actually very
efficient right you can force the total
others in addition operations the most
of code does not control his meditation
therefore they can see Orion parallel
overhead reported is averaged sixteen
percent but downside is if there are
data races right this approach won't
work right now let's look at this race
again we can enforce the T term is the
other on the barriers innovation right
but at the same time this risk can still
be resolved in different ways therefore
you can still have not eaten Idzik
behaviors the second way to your result
to make programmed into music into is to
enforce this memory access schedule ray
and you know for this particular example
if you can always enforce this other ray
or this other either way right we can
always enforce the same consistent other
we're going to make the behavior
consistent right either the but the bug
off it show up or the bug always not
show up the problem is that this is
deterministic way that's the advantage
but the problem is the normal program
does lots of memory accesses will run if
I shared memory accesses if you enforce
these others you can slow down the
program but a lot raise the number
reported in the previous system is from
1.2 to 10x slowdown question that's
right
so there are two kinds of overhead right
slogan is the instrumentation or just by
having to do some extra work each memory
operations right you're going to pay
supposed to slow down things right and
then there is this other cost of
actually enforcing the Trentonian
software and the hardware as more
palatable but you're not able to use
that because we break bread rado how we
can hope you submit them away that's a
good question i should not have specific
breakdowns for the instrumentation or
had for your memory access way but for
the for the synchronization other
overhead right like this so right here
you know if you enforce this simulation
slow down right and this or had actually
comes mostly from waiting right because
they're just too little to fields
irritation operations in code right here
so from ram access you know I think the
connotation alone gives you maybe like 5
X 10 X slow down right it's reasonable
the waiting time may not be that
critical here okay
so that the challenge here is you know
either way pig sync schedule reinforce
the signal to other already enforce a
memory access other but if you using
other you know we do not get full
determined em right because if their
databases is not into music at same time
you know the code it actually runs
efficiently right if you pick memory
access other we get to determine them if
their database is there is a result you
can basically write at the same time you
know we get this efficiently problem
because the slowdown can be quite a lot
so can we actually get both so this
paragraph actually get boats where you
can get both determined Amanda fishes
and explain how actually computed that
as the monkey idea in Paraguay is no we
can enforce peppery schedules instead of
you know ma'am schedule or sync
schedules the inside here is that Reese
is actually not really you're correct
although most program have Reese's
either pinay are harmful but these
series is impractical actually do not
occur that often in QT lleve if your
program has lots of races right not you
run it in testing lab right you probably
have detected these races already
empirically in we actually 16 programs
that contain racist and we run some
standard workload such as no compressor
file for a parallel compressing utility
right and there are millions of memory
accesses you sort of simulation
operations but you know we detect it
only after 10 races right so the reeses
actually do not occur that frequently so
if you look at left this is an execution
in the most part of the equation is
actually fine you know do not contain
traces I mean the mana potions every
container is this way containers which
means other concurrent memory accesses
right flip their order right using
happens before happens that using
happens before using have the verizon
access isn't me I have what access here
another access right until if you look
at the absolute time right there not
concurrent for it but they could help
you order if you run in the game so
Dana 10 happens before races right and
have a little race Israel with respect
to the signal Titian other we r attract
ray and i'll show you more details when
i talk about the example right there sir
it's not you run a regular dynamic
detector can you have a lot more races
right here you know we assume that we
enforce most stringent signal deja other
which have you print a lot of races
so based on this idea right we can piss
on this inside we propose to actually
use hybrid schedule to combine the
benefits of posting schedules and man
schedules now the idea is you know for
this portion is right which do not
contain racist let's just use sync
schedules right enforce the total
sanitation other we get determine them
to get efficiency and for this portion
right the manor portion that continues
is between force a more expensive memory
access schedule here we have more
overhead right but if this portion is
only a small portion of the entire
solution or head won't be that high
and we implement this idea in system
called Peregrine this future officials
the pen fall camp which is a fat it's
flying board specifically how do we
actually compute hybrid schedules and
the idea of schedule memorization
actually makes it very easy to compute
hybrid schedules the first when I run a
program on the input write a new input
we have not seen in the past we will
record accident rate which contains
boasting additional operations and also
memory access operations rate that we
have to put their other we do that
because we do not know if this actually
will run into racist or not and once
we've done that we have this action
trace we will run some offline analysis
on the trace to relax these trees into a
heavy schedule and this schedule have a
schedule contains in addition operation
for the ridgeway part way and memories
the excess schedule for the greasy part
and with the schedule in future if
there's an input compatible with this
schedule comes we can reuse the schedule
on this new input with both determined
evaluations so what I can actually use
schedules right we actually asked this
question you know think of a simple
parallel program such as parallel
compression rate gives you to our
benchmark it split so far into multiple
blogs and then comprises vlogs with the
multiple threads as eyes you make sure
you know the number of blogs and the
number of threads remain the same you
can compress the file a file using the
same compassion schedule regardless of
the file contents right often the case
you can actually use these schedules and
your evaluation we actually found out
that for a program such as a party you
can reuse schedules 90 or ninety percent
of time for many programs not just a
party
and also this basically this part that
we use part by required some analysis
and in the power point system we made
this part automatic it does not require
user annotations at question images so
for the depending on what we buy new
improved right so once you figure out
one schedule ray we're going to compute
okay for this set of inputs you could
totally use this schedule with without
introducing your races at runtime ray
therefore these inputs will be covered
by this schedule if there is some new
schedule that is not covered by your
existing edgell camera pans right invest
in put requires this new atlantis okay
you're gonna have to get some right
everybody show you example like
explaining how this water thing I should
probably go talk about it later buddy
what did you get interested in trying to
do punchy for party the input comes from
the network actually hooked the receive
method write the review system call to
receive network data right all right
right right I'm just wondering like what
sort of maybe probably issues can do
request how are you generated those
requests so we generate the request by
using two methods my master is actually
want this synthetic testing tool right
which launches a bunch of a TV request
right refresh different URLs right and
the second type of second workload we
got is from the trace from the Columbia
web web site right which is exactly the
like Mama's trades from website look at
all the HTTP requests you shouldn't be a
CS lifestyle right and then your
evaluation we actually launched this hv
request to our system right and the
figure out the reuse wait does this
answer your question you're very mostly
static we're studying it's mostly static
those 80 request
so our system also handles future
innovations running Linux and also the
fur deploy BG we actually made made our
system running user space instead of
modifying the colonel and you know also
works with super program like a pair she
right so we're going to show you the
summary of results right before I talk
about the details of the system we
evaluate Peregrine ever set of 18
programs including a program such as
apache web server parallel compression
upppp to i just talked about and also i
get parallel file downloader and also PF
scan a parallel our scanner it also try
a roughly evaluate our system out 13
scientific programs write programs
implementing scientific algorithms and
from the popular special to benchmark
and three from popular parsec benchmark
we also tried a program called ricci
which contains tons of reese's and this
program is actually a stress testing
tool for deterministic replay and
determines execution right because if
any risk is resolved differently you'll
get different results right this breezy
benchmark stress testing tool and
Peregrine can't eternity to resolve all
the receipts in these programs so we get
determined them and the overhead is it
sometimes can actually speed up the
program by up to 50 / four percent and
overhead no it's up to forty nine
percent and also frequently reuse
schedules for nine of the 18 programs
the speed up the patient law okay so so
there are two key scenes were we
actually speed things up right the first
is must be enforced in addition other we
can replace expensive in addition
operations with cheaper weds ray that's
business app for example other
operations such as barrier weight right
which calls the unconditional contacts
which right that can cause a lot of
overhead right but in the one sitting
for solder you can use cheaper ones just
no do not know connects way just being
waved right that can be make it faster
and also you know some of the benchmark
actually use mew sleeps for simulation
right synchronize do not did not use
explicit invitation they actually use
mew sleep to sleep for well and the
synchronize right but once you've
enforce the order you can actually skip
all the slips right so that's why we can
spacing stuff okay
okay so let me show you where we want
then like talk about how the system is
implemented using a detailed example
rendered show the evaluation and
conclude so para gradually use both
runtime components and compile time
components but given a program my first
we're going to instrum the program using
our instrument which runs in the air vm
compelling for structure and the runtime
we maintain this key data structure
called schedule cash which contains a
set of tuples see constraints right as
scheduled but this is a heavy schedule s
is heavy schedule and see are the
preconditions required for us to reuse
this schedule on new input so just talk
about this parallel compression example
where you know if we maintain the same
number of file blogs and the same number
of threads we can reuse as the same
schedule all the time right the highway
you know if the input a few changes
right for example we want to compress a
file using no more threads where or less
fewer threads we need to determine that
this schedule is not compatible with the
input we need to use a new schedule how
do we do that well actually capture
these constraints in these preconditions
rate so when I get a new input we can
check the precondition determine whether
or not we can review the schedule let's
say in the input comes right refers to
do this look happy in the schedule has
to figure out if input matches the
preconditions if they do not match right
before this input into a component
called recorder which will record a
detailed execution trace including
simulation operations memory access
operations and then we run this offline
analyzer to extract a hybrid schedule
and hybrid schedule and the precondition
required to reuse these hybrid have
reschedule our new inputs not attract
this new to bow and then put it into the
schedule cash and if the input actually
matches this schedule cash right now is
simple just forward the input and
schedule to the repair and the replay
will run this program well enforcing
this schedule s and because the analyzer
can compute correct preconditions we can
have we can be sure that this implicit
always be precise by the program by
enforcing this schedule is
so okay so I'm being should dismiss
sounds like were abstracted just a bunch
of conceptual ideas let me show you how
this works using a real example so this
code is taken from the PVC tube tool and
also FFT programming our benchmark
raised its simplified to fit within this
slide and its first reason input right
and then it spawns a bunch of worker
threads to process some data set if you
look at the work as well it does some
memory allocation and read data and do
some communication right so this is
simplified right so the real code is
more complicated than that and they
update results by grabbing new tags
updated shared variable result and then
release the new tax rate and the main
straight also participate in this
invitation it cost worker as well and
optionally the main thread also update
this result based on the third argument
at v3 and then it prints out the results
right so this code actually contains a
bug okay I see the bug here right so
there's a missing a piece by drawing
your disco catcher is running parallel
with this update code right so therefore
therefore we have reeses you know right
right races or read read receipts right
as my example so given this piece of
code will first prepare it for use at
runtime by running it with instrumental
instrumental first you annotate
intercept all these lines that actually
read improves right for example the
lines that access RV write command line
arguments that are considered inputs to
the Perl program and this my rate
function calls the system called read to
refile data we also instrument this
rating system call to mark that data as
input and given this input data at
runtime we can track how the input data
is used therefore we can compute the
preconditions require for reusing some
certain schedules and this instrument
also actually instrument other thing
additional operations such as lock
operations this pc i create so that we
can record schedules let's say no after
instrumentation i would gather in from
the program let's say we run this
program
with this particular set of arguments
weigh 220 which means we're going to
spawn two threads we're going to process
the data set of 2 by its ray and Theo
means we do not actually update this
result optionally ray a recorder the
recorder will record a detail accent
race you know we're going to record the
longer the statements that raise inputs
we record the execution of this loop as
well since the number of thread is 2 for
the first time this is compared to and
thread we get this a true return right
the second time we compared to to enter
ever get this derivative right so this
code Christmas with the execution of
this loop and we run this worker thread
which also we also record the other in
statements actually the instruction
activity right also this gray area
corresponds to the loop here similarly
we do the same thing for the workers you
call cut by the main and then this main
function will update the result the
grading this log and the child's read
the workers driver also do the same
thing and we require the output of this
comparison red flag to RV three then the
last statement is to trade up to another
result once we get this trace I'm going
to show you how we can actually extract
hybrid schedules and also constraints so
first we're going to copy all the
simulation operations to the hybrid
schedule and we also enforce their
authorized if the other execution trace
is at this right in the future we use
the schedule we're going to enforce the
same other and next we're going to
detect reese's these roots back to
digital edition our creations right and
three access is to share variable result
if you look at the first pair they
actually they're not a race right
because the recess in addition all the
country here making them not concurrent
right but here I know you keep these two
threads can told Rick web different
locks right ever would not flag this as
a race as well right now even though the
logs are different we're going to
enforce this total other simulation
operations at runtime therefore these
two accesses you never happen
have not concurrently right therefore
they are not a trace a this is a zero
present okay let's look at the the other
two accesses write these for access is
there no signal additional appreciating
between they can happen actually can
country right there for those that
happens before we detected as well and
to resolve this rate we're going to add
two memory accesses into the schedule
and will enforce an order between these
two accesses right so that in the future
maybe we'll use this schedule is totally
deterministic so once we get the happy
schedule we need to compute the
preconditions required for reusing this
schedule how you do that one naive
approach is we can okay so the bantha
charges here at first the preconditions
need to ensure that all these events are
rich when we run this program on the
fusion input right enforce feasibility
of all these events right that the
events can be reached at runtime and
also you know for determine them where
we use schedules right we have when you
want to make sure that we don't get new
data races right because if there is is
the execution results can be different
so this slide I could show the example
of a race that may show up if we just
reuse this schedule ray let's say
waiting for this schedule but this
argument right this art v3 right becomes
true right so that this becomes one
right and this flag is one no this
particular check right satisfies
therefore going to run the true branch
of this statement we're going to access
result right which actually Reese's with
these result access is right the
tech-heavy new races coming up if we
reuse the schedule on new inputs right
so these are the things we want to avoid
as well what about new races so how do
we do that right so what approach is you
can look at the condition notes ray
activity in the trace and the if the
conditioners depend on input right that
means if input changes the value the
result of the conditional may change ray
we can grab up this condition dollars
ray and use these condition notes at the
preconditions so that in the future if
input satisfy this condition does occur
right we can wear ganti that authorize
will go down the same path right
following your
the executioner a pressure as the input
here because the input as in the
arguments passed to the command line
right I also input street from the
network and also input read from file
signal goes off during execution right
ray ray right so the second apart you
currently actually do not handle the get
hempstead part we currently also do not
handle rise if the code actually a COS
get time of day right get back to value
and that value effects simulation
operations right that that's something
we do not handle and the scenes we
handle are you know for example the
random returns right so if the program
cause random gets back value right and
we can just mark it as an input and do
the same thing right and forget time of
day you know you could have used the
same approach ray but the things you
know if the get hammered a tweet when
weather is not injured right actually
cannot be tracked by our power
constraints our rights as an imitation
of our system okay set the same random
value right you said the same random
seed right like you get the same value
but you could be reading scenes from dev
/ tiles that random right I run time
right so it can be totally random
depending on the system setting ok so
the detail or constraints if input
matches all these constraints we go down
the same paths right there for you know
we address all these challenges right
and these concerns actually can be
further simplified to be this right so
this is a synthetic estrellas the
problem with is naive approach is is
actually confused over constraining
preconditions for example let's look at
this size is to can constrain right it
says you know in order to reuse this
schedule right the hybrid schedule just
computed you have to make sure that the
data size is to Ray but not actually
this schedule so that this simulation
schedule a look at the pc i created all
the memory accesses right you can should
we use it a lot of different data sizes
right even if data size is now to
actually doesn't matter so in some sense
this says is to constraints actually
were over constraining right it
precludes a lot
the chat opportunities where we can't
really use at the same schedule and one
way to solve this problem would be to
throw away the constraints that do not
matter race but how do we actually
figure out what constraint matters and
what constrains does not do not matter
ray that's one of the challenges when
you sell here and turns out this problem
is very hard to solve observes of most
our efforts in this project and then we
come up with some program analysis
techniques and the first technique is to
flesh out instructions that do not
matter do not affect schedules and
second technique is to improve the
precision of the first technique right
we actually need to simplify the program
toward a schedule therefore analyze the
simplified program so that we get better
precision so now the details I feel
described in our paper and also i'm
happy to discuss the techniques video
guys offline but it's just too
complicated to include in the top and
the intuitively know the tilting
intuition impurity we may look at this
commutation loop right it concerns only
sweat local variables right local data
for example this data is allocated
locally right stamp in some sense is
private data for this thread race on a
private peep and these commutation right
raise files I do the competition but yes
she does not pass the data accessed by
other swear so it's local competition as
well these local commutations reckon I
should be slice out okay what what makes
a relaxation appropriately
so if I relax the contract or something
right how do you know that that
relaxation is still okay does it mean
that you know for any state in there
just this particular schedule that your
computer is still feasible is that what
you want it's still feasible and does
not include introduce new races who
conditions not introduce new resolution
right because I remember there's this
condition update of the results right
depending on the third arguments right
if you run it on a new input and there's
a new race coming up right and the
results meet in an eternity depending on
how the race is resolved by so those are
the two conditions that other humans are
feasible right at same time no nervous
is coming up okay so there is a sunpass
slicing work right and now that the
algorithm can be used to solve part of
the problem reading a sequential
execution right here you need to look at
inter threat dependencies right if I
read a particular variable here that's
defined by another thread right you know
they can be diffused change across the
head way they can make things
complicated right so you know that's
your part of the problem we sell here at
make it concerns your where ray right
present we do this analysis statically
in the sense that you get the program
you get the actuation trace right and
then do the analysis right and it's
offline right but you look uses dynamic
information because we have this dynamic
trace right okay so you also combine
dynamic and static analysis okay up
front as part of the training field so
when the rain Graham is actually
deployed all this stuff is not being
that they always calculations so you can
imagine that we can weekly have that we
could do this also at runtime as well
and updating the schedule cash rate but
right now the analyzer runs for long
time right so do it online does not make
a lot of sense because it's low right
the idea what we that you know even if
you after deployed right deploy the
system is concealed class schedules
right but you still run the analyzer
offline to update schedule cash instead
of updating your line
ok
so long partner
ha whatwhat's hella symbolic execution
yeah so what includes effect what
condition so basically once you slice
the program out like once this statement
of stress out we get this smaller slice
right actually runs the ball execution
to get the constraints right so we look
at improve dependent we track how input
propagates within the trees we track you
know the conditionals and the input rate
at the clock constraints way that part
is done by it's about execution things
will every small execution ok ok so much
we slice things out right like the all
these no statement sir there you average
right to the schedule we slice them out
we get the preconditions we simple at
the you know these are the final
preconditions ray this is a hybrid
schedule we learn from the trees and
these are the preconditions we computer
free using this schedule and if we run
this program on the new input let's say
202 rights as we want to spawn two
threads a processor data sets the side
of a hundred animals and then the third
argument III ray and these input data
right the arguments will match the
preconditions therefore we can reuse
these schedules in for the schedule
ready to get determined them so there
are a few benefits of this approach the
first we have to determine C result this
is right like this recent different
missing result and also the
preconditions computed being sure that
there won't be new reese's coming up
when we use the schedule right so get
determined them and also it's very
efficient as you can see you know in
force and other on this in addition
operations class only two memory
accesses right and the major competition
part right cuz you'll run in parallel
and also this schedule can be reused
across a bunch of different inputs right
we don't care about the data contents at
all right and we do not care about data
size whereas i can give give me
different data set because you review
the same schedule so questions so far
access so we actually instrument the
program right so when there is access
here right we put a assemble our patient
up here right before this a success we
put the central operation down there
right so they form a constraint right
it's like you can write what right oh
what's scheduled to use brettly's you
share in the program right that's rude
so mother made this point that if you
instrumental programs they write
accesses right but due to do nothing
just a no op right right if you
automatically start being five to ten
times over it right so how are you
avoiding that so if you do that for all
the load and start so you get five to
ten slow down and maybe even more here
we just instrument this specific access
we know right because these to access
area involving races and all the memory
access it here they can totally run in
parallel without an instrumentation
because they do not involve me any races
right but this to access right you get
some small bit of slow down there but
because it just needs someone to write
just a few memory accesses right to get
away with a slow little smaller overhead
bay okay okay this thing conservative
data racetrack right exactly that's like
you meant only those accesses that
participated data rates right because
we're getting some of the effective
right now even though the result that
particular program point to a facility
right see you guys because you're
instrumenting a gonna pay the cost
recommendation is a kiddin right even
less it went on to become an access to
need to get over it right actually do
kids have good steady busy taxes so you
know this this is some idea Ref you or
you she's in pursuing the future right
you can do static voice detection and
figure out the respawn points right they
schedule them together with the signal
asian operations rather forget determine
is one spreading and efficient and well
right but you know we check the one of
the our recent actors for C programs
right
it has a really high fastball to race
it's like fish function you get maybe a
hundred reports right so you guys have
like static good steady grease detectors
we can we can leverage we can use but ok
an adaptation based vegetation I see so
that's a magnification it averaged over
and over facebook on Isaac's right maybe
you can clever it yeah well it would be
interested in using such a risk factor
right right now another operation we're
looking at is not just for C program for
java programmers there is a receipt
Hector developed by I can and his
students right and you know they have
good precision and also I think they're
the second version of the system is
sound right we're looking at whether or
not we can actually do this for java
right with that power for wrist act
array if we can get the steelwork or
else it has hard work that'd be a great
thing to do it's a bit yeah right he
just to memory
so if you just do memory right you can
get determined oh right yes let me know
that right can you 4shared the detainees
access for shared memory operations way
by the same time high overhead because
you have the examiner had internet
issues in store you have the weight
overhead because you're not to a memory
access if other ones prior to the access
are not been right there is a weight
overhead there as well right and the
overhead can be absolute and x 11 x
right based on previous papers but this
login all look this one's it okay it has
been over head because you have to after
if that log comes first you have to
create Matilda all of these networks so
if you order that result between the
locking search on the left me two
seconds on the right then you won't need
unlock and lock so uh okay first of all
the there are two questions here right
first question is that the overhead as a
challenging and controlling other of
sanitation operations like the second is
if we do this in for this memory access
other right we get roughly the same
overhead right and for the first
question usually in these intercepting
simulation operations tend to be cheaper
tends to be cheaper right because these
are already library cards right easily
hook that right and you self hook load
and store operations for each load
optimized code with that contain loading
store operations you do a fashion color
you do a tradition that right you're
only doing that for the first for the
first 1i right first probably do that
right but for the future are we don't do
that right so that we can avoid overhead
for the future right the first time the
overhead is as much as existing tools
that enforce memory access other
but he's gonna need those right do not
give you did not give you a lot of
overhead right the first time a second
know if for this particular access right
if you enforce this constraint and you
probably get roughly the same overhead
as importing this constraint right but
at the same time if there are lots of
memory accesses here as well right and
how do you know whether or not you want
to enforce other for those accesses
where memory accesses if you're doing
for others you get slowed down right if
you do not you between dollars all them
resolve down there can't you figure out
the rest of them out the same way so no
we actually here we know that there are
no races between these two piece of code
their focus lies the mouth right so
you're suggesting that you know for this
particular access right this without
access it without access we just add
this ad instead of adding this diatribe
but this tool access actually did to not
raise right if you using your algorithm
they do not raise right there for you
will not add an edge here right there
fer can get nonny to music simulation
right the only love edge fresh which
means that they would be the race if
that student
right so we do this right actually to
resolve police and the lock right so
this guy wears one lock this guy grabbed
the same log right they can't grab the
locking tiffin other right sure you can
get different results to add this edge
to say okay this guy always get the lock
first rate therefore you have we do not
have this non deterministic lock
contention right right now it doesn't
matter telling you all these two
accesses are you agree but when I'm okay
to say is that what you're doing there
is fundamentally basically trying to
have an edge between the memory location
of the law itself right I know like that
so if you didn't have like a toboggan
you had custom synchronization right
what you had to do that you had Waverly
Brown have the lock memory and they up
one of these arrows right now maybe a
better way to look at this would be that
you know it starts the word thing right
good luck now he turns o'clock
operations right translate two nominees
not eaten easy access others to memory
access it may be a bad way to look at
this will be that you're here at shows
example is just one access way I can
have a large critical region with lots
of accesses you you can all see addition
operations right just enforce other for
memory accesses even enforce a lot of
edges right the forgive me get better
performance right but right now you know
we just you look at a signal tation I
know this in addition alien force this
scene at each other right which
automatic Howard's all the memory
accesses reading the critical region
right therefore is going to be more
efficient okay
okay so you know our system actually has
limitations as well right some folks
just pointed out so first of all because
center here is we can actually reuse
schedules right which may not always be
possible for example you know actually
one naughty tourism in your simulation
to get some statistically sound results
right so those were closed or programs
right we not fit within our approach and
also you know by enforcing some this
means order of operations right memory
access or simulation operations we
introduced sometimes introduced delays
right if your program actually is
latency intensive that's not a good work
load for a sway and also we need to keep
track of constraints you have to figure
out the preconditions and our current
and Jionni tracks constraints are
integers if you have floating point
operations the schedule actually depends
on floating point which we cannot handle
it we also require source code or the
air we r vm at the compiler intermediate
representation bit code there's another
limitation and currently we do not
handle not even them coming from get hem
up day or metal up right so if you may
look something you get a memory address
and you do something naughty to music a
simulation based on the return address
of male upright we cannot handle so
actually this probably can be handled
using some existing techniques right for
example there are implementations of
heap implementations that actually are
deterministic way and also we work with
only reads a single process right this
doesn't work if you have multiple
threats and a message to each other
right although we're planning our you
know making this approach work for mpi
programs as well or programs that
communicate by sending and receiving
messages so
right now no so we don't determinates
the other system cause if you have
risked inside the colonel right how
possible okay so you learn lots of
applications we can do on top of this
idea right as a basic level you can
simplify program understanding it has in
debugging array you force the same
schedule pessy schedule at a production
right and also you can use it for a
twinkie to miss replication of
multi-threaded programs as the one
program runs has some non you trim them
instead of logging and sending the non
determinism if the input hits the
schedule cash you just reuse the same
schedule automatically right after its
different music you can report bugs
without reviewing the full input tray
which may continue credit card numbers
and also you know once you have the
schedule right you know what the program
is going to do in the future that we can
do some scheduling trick there as well
right and actually you know not very
interesting application where it
currently exploring is a we can use this
idea to build sound and precise static
analyzer analyzer for multi-threaded
programs right that briefly talk about
this idea to analyze multi-threaded
programs we can use dynamic analysis
right which analyzes the schedules that
are occurred right it's busy and sound
because the next round of the program we
actually use the schedule does not
analyze way I can do static analysis of
all schedules right but that requires a
lot of approximation is right and
sometimes we get increased size results
right like this detection you can get
tons of false positives a whisper grant
you casually solve these your address
these issues to some degree right we can
analyze the program only with respect to
a small set of schedules right that
being in force at runtime therefore
again get precision right we don't need
to assume all possible schedules just a
small set of schedules and also we can
enforce these analyzed schedules right
at one time using Peregrine right or we
can guarantee Stanley's at least for
these schedules right the schedules will
be analyzed and if there are new
schedules you know that we are required
I runtime right forgot a name new input
that can not be covered by these
schedules right we need to you know
learn this new schedule and for this
rare cases we can't reuse some expensive
techniques such as we do you know
simulation of the program right to
guarantee
to check for errors for example and
under the assumption that you know this
most and there's a certain that we can
frequently use schedules as the most of
the improved right ninety percent inputs
can heat the schedule cash ray we can
actually guarantee a precision and
Sonny's for ninety percent of the input
I wish I think he said you know it's a
good contribution and by the way this is
not some ongoing work right so you know
we have this idea we did some
preliminary study and get some results
right it is not published yet okay so
one challenge you hear is you know how
do you actually analyze a program to
work just a small set of schedules right
no way to settle in as is no we don't
have this notion of schedules right and
my approach is you know modified every
setting an asset to say okay that this
is scheduled right take that schedule
into account through and as the program
right but that that's kind of strenuous
right because you have modified a lot of
analysis and also sometimes when we
build a tool we compose a bunch of nasty
together if there's an imprecision in
one of the nicest which does not
consider schedule right and the
including may actually propagate to
other analyses way their issues here you
know this is the nice solution i just
talked about right multivariate analysis
which can is not very practical right so
our solution is actually you know taking
this program right let's take this
program let's take the schedule ray
because specialized the program tour the
schedule right so that i run hot women
and one this specialized the program is
going to generate executions matching
the schedule right so you transform the
program to get a simple word program and
this transformation specialization
process involves specializing the
control flow plus the data flow of the
program right for example look at data
flow when you look at def use chains a
lot by the synchronization schedule at
the schedule in force and have that you
find here use here I and you have other
loading stores on the same memory
address but if they're preclude right
that the data cannot flow because when
you for some students schedules we're
going to ignore those diffuse flows
unless we get this specialized program
which is a lot simpler than the no
original program consider the schedule
as well we can apply stock and assets to
the specialized program
specialized program as an annotated a
program simply program with a location
or do you think that some statements get
dropped or sliced away some statements
get dropped some loop guess I wrote and
some data some values random variables
become concentrated for example I know
if the program are you can schedule
dictates to threads ray and the program
uses a loop to create threads right and
can say okay this lube on must be to
write because the schedule only contains
two threads way I can propagate this
value to all the other places where
these values referred right so you can
do it as know it's a simplified program
not just slicing out statements write
the code okay right make it wrong faster
so we're not sure about the trans fats
apart we're sure about the simplified
again your are making it run faster you
say that now we're examples although the
digital is I think what this this part
is this far as it is it application of
the technique right you can take the
program right you do simplification
remove stuff right yes it made run
faster but we cannot have experimental
data to back it up right we believe we
can do some additional sounds like an
interesting yeah we're gonna definitely
will pursue that direction right but
right now our results is mostly on
precision hard way so Monsieur healthy
throughout throw away a lot of crap and
your specialized the program based on
the schedule ray can do really precise
analysis lee for example you get
automatic sweat City right because the
schedule says to thread we're going to
clone the spread function two times
right I forget automatic sweats and
acuity right how you how you what I
don't you know how you gave the schedule
and do the program so okay let's look at
the controller part right the housing
addition operations right and i look at
the control flow I go from western
addition operator to another right as
street in the program such that these
two new statements wreck responding the
two disputes in whether he wins right
become control equivalent right and the
other paths that you know kick bypass
this annotation operation gets trapped
out of right it's if it go ever go there
you won't reach the second signal in
operation right and know if there's a
loop with three signals asian operations
right and you move with one single at
the operation right and in my schedule I
see this operation appears two times
when know the loop must be run twice
right I like I actually I wrote a loop
ray so that's how we could spice
why's the control flow rate okay okay
bring is really the techniques then we
do for optimization okay loop and so on
and so forth right your goal is is
simply thank you right right right let's
get more precision right yeah yeah
question do that this sorry glassy the
specialized programs still will have
threads right yes okay we still have
threads right but and it does it is the
semantics of the thread usually when you
have a multi-threaded program the
semantics of the multi-threaded program
is that threads game context which
sanity at least a traveler inflation
right the specialized program doesn't
continue to have the same semantics yes
okay right so okay we also needed than
any progress maybe this is what you're
getting a dresser I have seen additional
pressures you might specialize the
program right so z sigma theta
operations might want one to my schedule
ray every time I need some technique to
enforce the order right that's where
there's no why I say that you know where
she need to enforce schedules at run
time using Peregrine right so the lab is
that what you're getting at ok right the
law needs to be cognizant if you okay
the static analysis will focus on those
schedules right no static NASA needs to
be aware of these other edges right sure
sure so okay so this is how we actually
sort of get around the problem and so
this data flow part right we're going to
build this way I should build this a
dissonance Israel which considers when
you float right based on this is a
schedule ray and then you have another
own assets which wants to carry it is
NASA to exactly
it is very our area's messes right and
therefore this it is an asus is made
schedule where a different assets depend
on the alias necessary your your code
you're an ass do not have does not have
we made schedule where okay so you're
saying that there is some basic value
flow or data flow analysis that you will
provide the prevalence of information
there right and you just query that as a
black box all right I'll see the squared
as a black box right right okay
you know we have some initial results
for example look at alias reduction
right so if you do not do this do not
freak the schedule right you get this
many aliases with the schedule
ninety-nine percent actually get score
not right it's that the precision is
pretty the increasing precision is
pretty big right and we haven't no beaut
this beauty reseed Hector based on this
technique yet right but actually no but
run is this an ancestor and looking at
the eighties result we actually detected
you know I think like at least five or
seven no real races in the program's
analyzed by a lot of previous systems
right you see a lot of papers they use
the programs where but they did not
report the recently detected other
previously unknown right so I think that
I'm more excited about this direction
eyes are actually pursuing this
direction yet okay so how much time do I
have or but that's okay i guess i can
drop out right so guys have seen the
summary of results right skip the
evaluation you want the very shape okay
okay so we should wish my each one to
what store ahead okay not just general
the whole g SS jihadi training right
when you're imposing the sink schedule
ready let's say you run your program on
a full commission right and then you
find the schedule right then you try to
run the same program on the same input
58 or machine or any try to enforce the
same synchronize
schedule right I would like to know what
the overheads are so go ahead okay so
let me ask you I mean more fundamental
question is okay programs are non
deterministic for a reason records then
they can respond to you know environment
changes presence of bored course
Valencia running suddenly making a form
of course become available because
another writer process click on the
finish okay so they are non
deterministic for a reason to use all
those computing capability okay and so
if you're restricting it by adding some
determinism reckon I would expect to do
some bombs right so that there is indeed
some progress or Heather and for the
particular test case were told you
mentioned right to get a schedule a full
conversion right you get this schedule
on the for commercial and they will run
it on a commercial I expected schedule
the overhead right will be like lard
right because you know I'm a
machine how lots of comments which is
right now you mean other how it does not
map really well to a full commercial for
the scientific computation I wasn't
right normally what they do is you have
four cards i'm going to just use force
schedules right now eight course i'm
going to use a taste right by the four
cars for threads across a thread right
so this number is actually part of your
preconditions raised part of your
schedule ray so I know eight core you
know for for some scientific batchmate
reverie will automatically find use the
sea fishing schedule writing that says
right okay right number of course is
actually part of you right how do we
input right even if you look at more
dynamic scheduling our continuous
Randall library shortly what they doing
is again I'm running Apache ready saying
I'm a purple so when we running
internet explorer right right and then
you know internet explorer is using to
court where the budget is it six concert
net internet explorer finishes up a
dresser of grows to use their main to
post right answered a lot of dynamic
scheduling algorithms right which are
designed precisely to make use of these
rendition of computation directly thanks
i would like to know what my impression
is that that is always build a weak
point of the entire to domestic
multi-threading story and guess what
that thing under the rug from they want
i wanna get your what is ok innocence so
you know i do an experiment like you
know what did you find so in our
excitement where these are actually
those are mostly scientific programs
right and this program sir that's how
program to a random we run them out for
cross way and these are actually
basically i should also use run apache
to use other courses we do not actually
try the app or the internment news that
way so my my impression that if we do
the exam until you said right you run a
bunch of competing processes together
and your mare performance for some of
the process reading this system way you
may get higher or headway but i think
they're se ways to address this problem
if i do not know whether these ideas
would work right so one idea is you know
if the workload is actually
predetermined like these kind of
computations right you have multiple
processes right the process want to
fernando threads right you catch mold
them together it will have them as a
bigger tits music Marquis execution the
3g tax-efficient framework for their you
know you can capture constraints use
this approach right that's one way right
another way to portunity addresses would
be there you know we can have not just
you know my schedule for many improves
right we can have a few schedules for
these many inputs right and then run
home ray and this workload actually
becomes a factor for us whose was
scheduled to go away to use ray and that
stuff we can get you know efficiency
rate so in some sense not do we want one
to one determined my probably not right
because you know if you change the input
you get really different schedules right
we want managed one maybe baby right but
you can also have many to n schedules as
a small number of schedules shoes at one
time to get the performance right so
those may be may be the way to go right
so
I haven't tried these ideas right ok so
do you guys want to see more results or
so this is it overhead right some of
them like we get speed up right because
they use no barriers in addition which
can be avoided by us when you slipped
right something we get bigger ahead
right so so that's you know the
recording overhead right you know our
current record is like a sultan that
x-ray that's pretty slow because our
recorder is not for optimized right
there are lots of papers talking about
how blue you fish and recording it just
haven't got the time to implement that
yet right so that can be really large if
you look at the papers previous paper
it's like I DNA rise developed by ms out
guys right it's a like ten percent right
record the full actuation stream low
store instructions right ok right the
corruption patchy server a steady HT
bureaucrats court patchy server if you
do h pi PHP right we haven't read web
but i think the ph it won't matter
because it's single-threaded i do a
library card interpret some PHP scripts
and go back right is single threaded
they're gonna do in for scheduled
meeting PHP module' ray okay okay it
works forgot ematic land on these number
of programs that actually get better
performance and I'm sorry no they're
coming
right so maybe there's a better way to
being a work right so right now we
started this work by focusing our nose
reliability right white box by grace its
we remember schedules and what bus right
but right now in the i think that
setting an ass is frame we're really
excited about and also G via one of my
fantastic creature students is working
on that right I think you down the line
we want to do the optimisation story
right I think that can work well as well
but you know maybe the program to work
we're not written in a smart way right
because you use heavy sedation rights
arguable I'm buddy figuring out what is
a better schedule bang right right and
the wonderful thing about working
optimization that you won't never
guarantee anything right very happy
guaranteed semantics it's correct you
just have to make sure you don't change
the semantics or something like right
right hey right it's like the race you
already knew s you're saying I
thankfully there was some raise their
right let me go I was in the program
rises that's actually may be better
directed a good direction for us to go
so by the original sink schedule these
are the heart veena you the
optimizations you're getting a six
schedule + your optimization sing
schedule where's here so sincere it
gives us most optimizations right so
this is mainly my kendo has implemented
does not give you the sphere
you guys made some drinks with the
sleeves right wizard symmetry operations
the pizza after this let's hear the
observation mostly come from the
simulation operation okay so right now
you know we do the simplification we get
the program and the program again
results right I should run run program I
still run the original program right but
you know the thing we haven't tried
right I think there's a quiz suggestion
so everyone to see my program and also
can even or rhesus whether the analysis
part that you his visits because as a
shot suggested by the program has visits
is the programmers father no need to
worry about this is a nigga get like
better performance better promise quick
aggression
do you know what percentage of memory
accesses West synchronization and what
percentage went crazy like you know when
you throw in it okay actually have this
number
okay so these are the races so these are
the program that container to grill was
how racist these are the synthetic
benchmarks they also contain reaches as
well right barney is these are from the
past a crunch mark way we want the right
the number of memory accesses can be
millions right several media see you are
even more i don't recall the exact
numbers in the paper its energy
efficient and some other services they
look at the recent visitors back to the
simulation schedule they're pretty small
number resist these are different and
appreciation Yemassee focusing other
right no races are detected and for
secrecy similar things happen right
forces together in the race isn't
helping
true to you like most programmer your
matter did not help lots of races which
is general for general education
any other
okay it's a simple
so talk about the schedule memorization
memorize schedules and reuse them a
fusion close race you can avoid we can
reuse about Hasse schedules and avoid
potential buggy schedules right I'll
talk about this idea of heavy schedule
basic combines the benefit of the single
schedules and mem scheduler as Madonna
suggested right you have to combine you
can implement this idea using a steady
receipt actor right which actually we're
kind of looking at it and I also talked
about this peregrine system with it
confuse happy schedules by taking a
trace and relax into heavy schedule a is
deterministic make all these programs
dieter music efficient you know or has
it slow and plus it can frequently used
schedules okay that's all</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>