<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Medical Imaging using Microsoft Azure and CodaLab â€“ Webinar | Coder Coacher - Coaching Coders</title><meta content="Medical Imaging using Microsoft Azure and CodaLab â€“ Webinar - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Medical Imaging using Microsoft Azure and CodaLab â€“ Webinar</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kbbj38wA6ZY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">welcome to today's webcast medical
imaging and more I'd like to turn
today's event over to your presenter
Simon Simon you now have the floor all
right thank you very much and good
morning my name is Simon Mercer I'm the
director of health and well being here
at Microsoft Research in redmond just
outside Seattle so it's morning for me
and I'd like to tell you a little bit
about the different work that we've been
doing in-house related to medical
imaging before I get to that let me tell
you a little bit about myself and and
what my role is inside Microsoft
Research I'm part of a group called the
outreach team and the goal of myself and
my colleagues is to demonstrate the
value that Microsoft Research can bring
when it comes to the application of
computer science into different areas of
academic research medical imaging is one
of them but it's not the only area that
we work in we're quite broad microsoft
research itself consists of about 1,200
people the vast majority of them are
computer science researchers and they're
based in labs around the world we
currently have around about 10 labs now
of course as you might imagine the focus
of Microsoft Research is computer
science the types of things that you
might add that would be applicable to
Microsoft products and the researcher
that occurs in microsoft research finds
its way into products quite regularly
but the thing about researchers is that
they're very interested in applying
their theoretical computer science in
different areas of research and so
that's really the genesis of our
interest in matter because medical
imaging is one field in which it's
possible to obtain large quantities of
complex data complex image data etc
which is very useful for us to build
algorithms and to attempt to analyse in
different ways the applications of doing
so applied far beyond the field medical
imaging and relate to computer vision
and the analysis of images in general
nonetheless we do have research is he
who is specifically interested in
medical imaging and i'll be talking a
little bit about their work and the
other work that we've been doing in
support of them over the last 18 months
or so so without further ado I'll move
on to my second slide here and I'll talk
to you a little bit about the context of
what we're doing and and the reasons why
medical imaging we believe that in order
to improve algorithms the larger the
datasets that you can train them on the
better your algorithm will be in fact
this was demonstrated to us a couple of
years ago when we were developing the
Kinect sensor which you'll be familiar
with from xbox and so forth it can
recognize where you're standing and what
gestures you're performing and you can
use that to drive a game or some other
type of application when we were
developing it we created a large set of
body position images literally we took
people we stood them in front of a
camera we made them strike different
poses and then we used that set of
images to train an algorithm that would
recognize body positions more generally
and when we've done that we found
actually we didn't have a very good
algorithm if you just take a few tens of
thousands of images of people and train
an algorithm on that it turns out that's
not really enough data to get a very
good algorithm for body position
recognition and so we tried a different
approach we created an application which
would automatically generate large
amounts of synthetic data about body
position and once we've got truly
millions of images we could train our
algorithm on that synthetic data and
result in the algorithms that underlie
connect today and what that told us is
simple the best data is more data and
the more data that you can train an
algorithm using the better the resulting
algorithm at whatever task it is that
you trained it for so broadly speaking
we use a little tag line here which
you'll see on the slide our goal is to
free the data and accelerate the
research the more data you can get it
the more easily you can get that data
the more data that then becomes
annotated and useful for training
algorithms the better the algorithms
whether applied in medical imaging or
elsewhere so the question that we asked
ourselves was what the best
this would be and that we we broke it
into three phases you'll see these
indicated in the yellow bar across the
top how do you get the data acquisition
how you actually having got the data how
you make it useful by annotating it and
that's the annotation phase and then how
you share the data with your colleagues
and how you start to incentivize
incentivize people to build better
algorithms for medical research and
other purposes and so I'll take those
three different areas and I'll tackle
one by one first one I'm going to talk
about is acquisition now I don't have
terribly much to say about that so I'll
move on to to the rest of the
presentation quite quickly from here the
problem with data acquisition is that it
has to be well we're dealing with when
we talk about medical images quite
naturally we're dealing with patient
data and data needs to be anonymised and
it needs to be received from the
hospital's which act as the collection
points of that data having spoken to
patients who have tumors and and and
other things from which medical images
have been collected is a general rule
are extremely keen to participate in any
type of research that would improve the
experiences of patients in a similar
position to them in short the patient
isn't the issue patients are very happy
to share their data is the general rule
hospitals quite naturally tend to be
more concerned with protecting the the
personally identifiable information of
patients etc and as many of the people
on this call will know the way that
they're the data can be obtained from
hospitals is by consulting through their
an ethical review board and of course
the ethical review board may make the
data available under certain
circumstances perhaps not publicly but
only to a certain set of individuals and
in general it's always useful to have
that data anonymize if not actually a
requirement of the ethical review board
the problem with all of this is this
means that extracting data from
hospitals is a question of dealing with
it on a hospital by hospital basis it
doesn't scale you have to approach the
hospital's you have to approach the
review boards and depending on
the nature of the data and the nature of
the use to which you putting the data
the hospital may apply different levels
of protection on that data this approach
doesn't scale now we still need that
data initially because we need to have
sets of real medical imaging data in
order to determine what we need to do in
order to train our algorithms but
perhaps there's a longer term future and
this is why i said i don't have terribly
much to say on this slide because i
don't have much to tell you right now
about that longer term future but just
as with the kinect the best way for us
to approach that was to generate large
amounts of synthetic data you could
imagine that if we were capable of
generating synthetic medical images of
sufficient fidelity that they could be
used to train algorithms which could
then be applied to real people's data
then we'd solve the data acquisition
problem if we could generate large
quantities of synthetic data than what
we could easily do is if you had a rare
case that you wanted to develop an
algorithm to recognize automatically you
could generate a million of those rare
cases quite easily when of course
acquiring the same data would be hard or
impossible from the general patient
community so we are moving in the
direction of trying to generate
synthetic data the reason why I I'll
tell you about the direction but I can't
tell you about the results yet is we've
only just started moving that direction
in collaboration with the French inria
Research Institute where we have some
joint postdocs located who will be
working on this problem in the coming
months and years so basically our
approach to acquisition is solve it for
a few hospitals in the in the near term
so we can gain data to train our
algorithms but in the longer term we see
the future as being the creation of
automatic large data sets where the
ground truth data is automatically
recognized ie the labeling has been done
when the data was created now that would
be ideal but I do mention labeling so
I'll move on to the next next piece
which is annotation it's all very well
to have a large amount of medical data
available and of course when this comes
directly from patients and has been
anonymized then what you really need to
do is you need to then go in and label
that data so that you know what
showing you because currently state of
the art for for the wrecking automated
image recognition on a computer is not
sufficiently good to automatically
recognize that it's looking say at a CT
scan and a kidney or or whatever it
might be on the screen and so what's
required for the annotation step is you
need to get some rather expensive highly
trained radiologists put them in a room
show them your test data set and ask
them what it what it says and an
experienced radiologist will and go in
and annotate the data now the problem
with that is it's a slow process it's
extremely manual and of course you're
taking radiologists away from real
clinical work and quite possibly they
they will cost you a large amount of
money to do that anyway so the
annotation of large data sets is
problematic and that brings us on to a
tool called gr now as you'll see on the
slide I've got an indication of the web
pages there and the user forums that you
can that you can go to if you'd like to
download a copy of Geoff's play with it
yourself and ask questions on the user
forums of other people in that position
basically gyasi is a semi-automated
image annotation tool that we developed
in order to minimize the workload on
radiologists when they annotate data set
because we need that ground truth data
to train our algorithms we've run some
user workshops for Fujio so you'll see a
picture of one right there that we ran
in Cambridge last year because although
we're developing it as part of microsoft
research we're doing so with the input
of the medical image analysis community
we had we brought in a range of
radiologists we asked them the sort of
features that they that they would see
as useful in this tool and we've been
expanding the tool in accordance with
their requests over the last year or so
it's available freely for download but
please it is only available for research
purposes please don't use it for
clinical or diagnostic purposes it's not
it wasn't built with that in mind so
what I'm going to do now is I'm going to
do a quick demo and i'm going to show
you what geo-scan do we believe we've
built a tool
is quite into intuitive to use and the
radiologists have used it to date have
spoken about reducing their workload by
a very large amount by an order of
magnitude actually as what I was told so
let me just switch over to my monitor
and then I can drive the application and
show you it here ok you should see a
large gray screen with for research use
only not for using diagnostic procedures
written in the middle this is the
opening page of the GOC application and
I will now load a medical image and i'll
show you how to annotate it here's one
that I prepared earlier and after a
second it will load a CT volume you
should see on your screen the interface
which is predominantly in black and grey
and you'll see three different
visualizations of the same CT volume a
large one in the in the Santa here and
two other views on the side hopefully
you should be able to see my mouse
moving indicating those views if you'd
like to switch between one view or the
other you simply click and you can move
that's what between the three different
views and through by scrolling you can
actually scroll through the CTU volume I
know it updates slowly on this on this
call the scrolling is really rather
smooth ordinarily but I can see your
screens in the appears to be rather jump
you there now if I'm interested in this
and I'd liked it well I suppose actually
just walk you quickly through a few of
the features in the interface geoff's is
called Gio's because it uses a geodesic
image segmentation algorithm that to
actually recognize features in medical
images if you'd like to tune that then
you can go to the Settings over here
opening that up you see a range of
different parameters that you can set
for the algorithm there I won't mess
with them right now what I can say is
you can save different combinations of
settings as preset and if I go down to
the other corner here you can see a
range of different presets which you
have the window display levels optimized
for different tissues I'm going to
segment some soft tissue here so I'm
going to select a
the liver settings even though I'm
actually going to segment a kidney for
you so that should that pretty radically
changes the view as you can see that you
can get some further information about
the exact signal as you'll see in a
histogram here and some other features
which are adjustable just above it but
in general this will do for me now what
I'm going to do is I'm going to scroll
through here until I see a kidney come
interview I happen to know that the
circular feature here is a kidney and
I'm going to segment that so here's how
I'm going to do it well first of all I'm
going to choose a segmentation label and
I will actually change the default name
from the segment label here to kidney
okay so now I've indicated that i will
be segmenting a kidney here I'll select
this label which I've already done I can
change its color but I'm going to leave
it dark blue in the hope that that
displays well for you now what I need to
do is I need to indicate which part of
the this this image is the kidney that I
wanted segment and also I'm going to
indicate which parts are not the kidney
that I want to segment and by providing
those two different sets of information
to the algorithm the algorithm can work
out all of the different bits of the
kidney and that's what I'm going to show
you now if you need to know how to drive
this application yourself well you need
you need to know the different controls
that you have you can simply hold down
the f1 button and the display is
replaced by a little crib sheet of the
different key bindings that you can use
I'm just going to use a couple of these
so I'll take that away and I will show
you how to indicate an area and how to
indicate something that is not that area
so by taking this brush I'll simply hold
down the shift on the left mouse key and
I will mark the kidney here I'm just
basically swiping inside the kidney area
now what I'm going to do is I'm going to
swipe outside the kidney area I'm going
to say that's not kidney there now
that's not kidney they're still not
kidney over here ok done that's all I
needed to do now I'm going to hit the f5
button which activates the algorithm and
you'll see that what it's done is it's
fouled all the bits of the kidney and it
hasn't let this area
but it's that segmented here bleed out
into the area surrounding the kidney but
if I scroll up and down through the CT
volume you'll see although it's got it
right it starts to lose the plot of it
as we as we move through the kidney you
see at that point it hasn't quite got it
and got everything and it gets worse and
worse and kind of Peters out as we get
lower down the segments so what I do is
simply repeat the process when I find a
segment that didn't quite make it here I
just swipe in here again and I'll give
it some more indicators of what no
kidney looks like and I'll hit the f5
button again and what it will do is it
will do the segmentation on that slice
and all the other slight is that they
can find but again it starts losing the
plot a bit of further down now what I
can do actually is I don't have to
scroll through and find the bits that it
doesn't find I can simply get it to
suggest where it feels a little weak on
on kidney segmentation so I clicked on
the suggests button at the top there as
you can see it didn't quite get certain
areas here so I'll just keep on whoops
segmenting like this and indicating
areas that aren't kidney I don't have to
keep on doing all of this in every slice
but this will help me work out the
remainder of the kidney nearly there
scroll through to a bit that it really
didn't go down here and I'll indicate
this and then I'll go a little bit
further and I wonder katelyn fat okay
that should be enough and I'll push the
f5 button once more it works it out well
nearly there it looks like it's it's
decided it this isn't kidney so let me
just fix that part thanks a little bit
more we're nearly there okay I'll go
right up to the to the top end of the
kidney here indicate a little bit more
emphatically though that's kidney and
this is not kidney and hit the f5 button
for what I hope will be the last time
yep there we go okay now as you can see
I've segmented the kidney and I did so
in a few strokes quite typically
our applications out there where a
radiologist has to click around the
entire margins on every CT scan slides
to to do the same work now if you will
see okay I've managed to segment all the
pieces there but if I switch to one of
the other views you can see that also it
will show you segmentation in all three
different visualizations here so you can
see that I covered it all of the area
having done the segmentation I can click
on segmentation info over here open up a
panel which has a little report on it
ordinarily well in some versions you
will see a three-dimensional
representation here showing the actual
volume rendering of the segmented area
but if you're interested in simply a
volumetric measurement you can see that
that's that's present present on the
report here and the histogram here shows
signal intensity throughout the
different slices you can add some notes
you can save and print this report for
your records so that's a quick rundown
through through GRS as I say the purpose
of Geoff's really is to automate or to
remove as much of the labor as possible
from the image segmentation process the
reason why we care about this as part of
our workflow here is that the larger
amount of ground truth labeled data that
we can generate the batter job we can
use training medical image analysis
algorithms but nonetheless this tool is
useful more broadly than simply
Microsoft Research and so we've made it
available under the non-commercial
license that I spoke about before and
either you can do a web search for gos
gos or you can look at the the web links
on on my slide deck or simply go to the
medical imaging page of Microsoft
Research and it will find out everything
I'm talking about here is linked from
those pages anyway I'm going to go back
to my slides now so if you'll indulge me
for just one second
here we are okay right hopefully you can
see my slides again and I'm back on the
gr slide and I yes I think I said
everything I need to say about that
moving on okay so let's imagine that
you've you've gone on this journey with
me and you've gone down these different
steps of the medical imaging pipeline we
have somewhat solved the issue of
obtaining data from hospitals although
we have to still approach them on a
case-by-case basis one day we hope to
have synthetic data which will get
around that issue and get around this
use of patient confidentiality now that
we've got a larger volume of medical
imaging data available it's just raw
data it still isn't useful for training
algorithms and we need therefore to
actually have some means of annotating
larger volumes of data than were
available before I've shown you Geoff's
that enables that now this this slide
I'm talking about the third part of the
process and the cloud-based part and
also the largest part of what I've got
to talk about and that relates to a
platform that we're building at the
moment and it's called coder lab coder
lab is intended well we include it here
under the collaboration area the third
part of what I've been talking about in
the medical imaging pipeline but it's
much more than just collaboration I just
had to use one word to describe this
piece but I found it not possible to
encapsulate all the different aspects of
co2 lab in a single word so
collaboration is one piece but there's
more what is code allow coda lab is a
playground coda lab is intended to be a
place where you can actually improve
algorithms easily and interactively and
in collaboration with other people in
your community who would like to see
improved algorithms now I attend a lot
of medical imaging workshops and one of
the major ones that occurs each year is
called Makai mi CCA I now McKay is held
in September each year and in
conjunction with Mekhi that tend to be a
lot of medical imaging competitions a
competition in this context is is quite
simple if I'm a medical imaging
researcher and I want to figure out
whether I've got my algorithm tuned and
optimized in such a way that makes it
perhaps of the best in the field at you
know image segmentation or labeling or
or registration or any one of these
areas that medical imaging people care
about then what I might want to do is I
might want to take a common data set I
might want to put it in a common place
and I might then want to invite all of
the other groups out there all of the
other medical imaging researchers
working on it on problems similar to my
own I might want to invite them to try
their algorithm against the same data
set that I that I put up there so that
we can actually produce a benchmark a
common set of results showing the
relative strength of performance of our
different algorithms on this particular
task in other words a competition now
koda lab supports competitions it also
incidentally supports many more things
and most of them i'm not going to go
into today you're welcome to browse
around the running instance of koda lab
which you'll see is deployed at wwc
odelay org and you're also welcome to
participate in the open source project
that's associated with koda lab well
I'll tell you briefly a little bit about
what those other areas do but I won't be
demoing them this is all about
worksheets and experiments let's imagine
a world in which we are running a lot of
competitions on the codelab platform and
as I'll show you in a minute we are
running a lot of competitions or some
competitions now we've got more in the
pipeline and I'd like to invite all of
you on the call today to explore it and
if you have a use for this please come
to coda lab org and try it for yourself
and try to set up a competition i'll
show you how in a minute but once you
actually have these competitions running
and you have a lot of algorithms that
people are contributing and validating
essentially through the competition and
saying my algorithm performs this well
in this particular challenge then we
essentially unjust growing a pool of
shared data sets and a pool of
competitions we're also growing a pool
of user contributes to algorithms now
there are plenty of other examples in
the community far more broadly than just
medical imaging actually about how
people have run competitions one that
was quite famous
those have a little while ago was
actually run by the streaming video
company Netflix Netflix have a
recommender system so if you if you come
along and and your user of Netflix and
you're interested in say horror movies
then Netflix after seeing a few of your
selections in the horror movie genre
will start suggesting to you of the
horror movies that you might like to
watch and so you know and of course
there are many other things if you're a
a customer on amazon.com you'll see you
know people who like the things that
you're looking at also liked these other
things now of course all this is driven
under the under the surface by
recommender algorithms and there is of
course a tremendous requirement to
improve these recommended algorithms to
provide users of the services like
Amazon and Netflix with better
experience so Netflix went out there and
they set up this thing called Netflix
recommend a challenge and they offered a
very substantial amount of money I
believe is a million dollars and to
anyone who could improve the existing
Netflix recommendation algorithm by ten
percent now it turns out that it's
relatively easy to come up with a
solution that's a few percent better
than than the netflix algorithm by using
currently but of course a few percent
doesn't cut it you need to get over ten
percent or you don't win the prize and
many people tried and fundamentally
everybody failed to win the netflix
recommend a challenge using their
different approaches turns out you can
get about eight percent but after that
people start coming up empty it's just
difficult to improve beyond about eight
percent but nonetheless somebody did win
the record Netflix recommend a challenge
and the way they won it was that the two
front running algorithms in combination
produced more than ten percent of an
improvement in isolation neither did but
in combination they managed to achieve
the goal and what that tells me is that
if you're running a competition and you
have the front-running algorithm in fact
the best approach may not be your
algorithm at all it might be your
algorithm in combination with some of
the other frontrunners and in fact that
is borne out in medical imaging
challenges as it was with the netflix
recommended challenge now that's a very
long-winded way of me telling you what
the other piece aside from recommended
aside from challenges it is in koga lap
it's a process of taking algorithms and
stringing them together and creating
your own workflows or taking a data set
of your own there wasn't actually used
in any of the challenges and subject to
the licensing constraints on the
individual algorithms that you'll find
in in code allow actually taking those
algorithms and producing pipelines so
that you can analyze your data sets with
these algorithms not just the data sets
that they were used for in the
competition and of course with each
algorithm that you're using you'll be
able to tell exactly how good it is
because it's been benchmarked against
its peers in a standard competition
which you'll be able to see and browse
the results of so that's kind of the
end-to-end vision for kodir lab if you
like but we're not there yet we have all
the medical imaging stuff for
competition set up and i'll be showing
you that in a second but we don't yet
have fully working piece that does the
experimentation side you're welcome to
go to the tool and browse and see how
far we've got but it's not in final form
it's not even close to it yet but you'll
see it develop you might well ask
yourself you know isn't this a bit
peculiar mean Microsoft does office in
word and sharepoint and PowerPoint and
all of the other things that we do but
you know we never invite people to come
and see early prototypes and see how
they work well in this particular case
you have to bear in mind that I work for
Microsoft Research I'm not in the
product side and Microsoft Research is
essentially a much more open
organization and we do a lot of our
development in the open in this
particular case as you'll have seen from
the slide this is not a project that is
solely Microsoft's responsibilities
Microsoft in fact doesn't quote unquote
own the project ourselves what we did
was we developed it using an open source
foundation similar to the Apache
foundation called outer curve and we
transferred ownership town to curve and
we made out a curve well we can make out
a curve or article have agreed to
release a coder lab as Apache to license
to open sort in short you can go to
github you can look at the coda lab
project on github and you can see every
line of code that we've written you can
see our approaches and because it's
written in Python you for your and
academic you may well be more familiar
with that
many of the more microsoft standard
languages and that's good for us because
we'd like to you to invite we'd like to
invite you not only to use coda lab but
to contribute to is an open source
project as with any other competition
platform it's not perfectly suited to
any competition or any use you might
have for it hopefully you will be able
to use the standard set of features but
we're actually providing you with the
opportunity to build on the features
that you want and then have those
incorporated into the core code and made
available to everyone else who wants to
use coda lab for their work so over time
this will become a snowball more
features will be added over time it'll
become applicable to more competitions
and it'll be less work for people to run
a competition of their own because
others who've gone before them have
contributed extra features okay so
that's basically it and what I'm going
to do is that are now going to just take
over the screen again and walk you
through what coder lab does so one
second okay you should be seeing my
monitor very nice Pacific Northwest
scene 2 on being today and I'm going to
go over here and I've just got to open
up a web browser I'm going to show you a
few different pages now actually before
I move on to coda lab I forgot to
mention this when I got to it so i'll
mention it now there is of course a user
guide included with g oz if you download
the g oz installer it will install a
user guide on your machine as well
double-clicking on the user guide opens
it in a web page and you can actually be
walked through each of the steps of
running g oz if you're interested in
doing so you'll also find it a number of
videos on the web and how-to guides and
so forth just search for Giants and
you'll get there ok so back to coda lab
here i am at wwc ojala org this is a
public site so you can be welcome to go
there sign up and play around even
establish your own competitions if you
wish to do so now as you can see it's
divided into two pieces we've got
worksheets and competitions the
worksheets refers to all the
experimentation stuff I mentioned
earlier the things that we're not really
fully developed yet but you're well
to to collaborate with us on its
development I won't bother going into
that piece what I'll do instead it is
i'll go into the competition's piece
which you can access either by clicking
on the competition's label that you see
i'm pointing out now or going up to the
menu bar at the top and looking at
competitions there i'll click on this
label and what it does is it takes me to
a list of running competitions as I say
coda lamb is already underway it's
already a project that's bigger that's
in use by a number of groups not just
medical imaging people by the way and
you can browse a set of competitions for
medical imaging and other things here
what I'm going to do is I'm going to
take a look at brats 2012 this is the
multimodal brain tumor segmentation
challenge that's been run sponsored by
the National Cancer Institute for at
least the last three years and they'll
be running it again in 2014 very shortly
and you'll be able to come back here and
see it once we've got it set up which
probably will be by July so I'll click
on the multimodal brain tumor
segmentation challenge from 2012 and
I'll just walk you through the different
pieces of the competition here I'm not
signed in right now so I can't get into
this competition and I'll talk a little
bit more about that in a minute but I
can show you what the public can see ok
so it takes me first to this page where
I'm invited to learn the details of the
competition I will indicate a couple of
features to you here you'll see this
grey bar across the top showing the
different phases of the competition a
competition can have any number of
phases in this particular case there was
an early training phase in which data
from a previous year's competition was
was released to the participants just
really so they could get used to
training algorithms on a set of data the
second phase which began in august on
August the first in 2012 release a new
set of of data which what they did is
they released both of the actual medical
images and the ground truth
segmentations of that data so people
could train their algorithm and actually
check his accuracy versus the ground
truth which they could see then when the
challenge ran which is the third phase
here then a second set of data was
released and that's had were the medical
images themselves anonymized of course
the ground truth data was concealed and
then of course people round their
algorithms against that against those
medical images and attempted to predict
the location of different features and
then after that the there was an
automated evaluation process which
occurred which figured out how close
each one of the participants was to the
ground truth information and rank them
and of course that those were the
results of the challenge but I'm getting
ahead of myself this is just the the
different the different phases of the
challenge and we've you ran a challenge
yourself you could customize and have
any number of phases in any order and
with any duration that you chose to do
including open-ended phases her face
doesn't have to add okay but I'm just
learning the details at the moment so I
want to figure out if I want to
participate in this particular challenge
so by going to learn the details tab I
see three different sections down here
overview evaluation in terms and
conditions again this is customizable if
you run a competition of your own you
can add additional phases and the
different additional pages if you like
but this is just to enable me to figure
out if I want to compete so I can read
this boilerplate here and I can figure
out whether it's what I'm interested in
okay now the next thing I might want to
know is okay this is my area let's see
if I can if I'm interested in the
evaluation criteria now what this does
is this goes into some technical depth
about the different types of
computationally mediated evaluation that
your results will be subjected to and
there are a set of standard measurements
and you'll see someone listed here
sensitivity specificity house door dice
jacquard etc don't worry if those
particular terms don't mean anything to
you they are technical terms of specific
metrics that determine the accuracy of
someone's prediction versus the ground
truth and so this is just really
announcing that those are the different
criteria that will be used to judge your
entry should you choose to participate
now if you are going to choose to
participate you'll need to know the
terms and conditions under which the
data is released and this is this is
listed here and you see different types
of requirements that have been set by
the competition owner saying you know
the data I have here
this is often the case with medical data
has been released under certain
conditions and you must agree to those
conditions before you're allowed to see
the data and that that's essentially
entirely definable by the owner of the
competition okay let's say I've read
these terms and conditions and now I'm
comfortable I want to participate this
is my area I'm interested in the ways in
which this challenge would be evaluated
and I am compliant with the terms and
conditions so go to participate to get
started I need to be logged in okay fine
well let's log in and that what I'll do
actually is I'll go to the main page
here and i'll just show you how you can
sign up obviously here but if you
already have a login as i do i'll sign
in using the the menu bar here now i'll
just quickly enter my username and
password and i will sign in okay take a
second to sign me in okay so this is
what you see when you sign in you take
into a space on Kota lab called my Koda
lab now my Koda lab at the moment only
really deals with competitions and what
it does is because you could be a
participant in certain competitions or
you can be an owner of a competition and
actually set it up configure it and run
it yourself what we've done is we've
created this little space so you can see
the competition's you chose to join and
the competitions that you're running
without having to go through the whole
big public list now I'm not running any
competitions right now I could create
one and i'll show you how in a minute
but i'm in these two competitions oh
look i'm already in the Makai challenge
so I can click on here and I can go to
that make I challenge and I can see a
lot more about that challenge now if I
go to the participate at I've been
accepted for participation so i can
either go go to the data which in this
particular case lives in the virtual
skeleton database in switzerland
clicking on that link would take me to
the bsd and enable me to access that
data incidentally you don't have to go
to an external data source you can store
the data locally on as you either in
your own account and link to link it
dakota lap and that's useful if you have
large amounts of data or it's only been
released to you or you're concerned
about adding extra layers of security
they're all of those are possibilities
also if you have truly huge amounts of
data of course
storage costs on out here and so those
costs would be billable separately from
the main code lab incidents and
typically they be picked up by the
competition organiser okay so i can get
the data in this location in in this
particular case it just links out
somewhere else and once I've analyzed
that data I can submit my results so
I'll go here okay now actually I've been
I've been participating in this
challenge for a little while now so I've
actually submitted several sets of
results rather dull I'm afraid because
I've called them all test submission but
numberless you can cite say see that
I've made three different submissions to
this to this challenge I've made three
different attempts essentially to win
the challenge let me take a look at one
of these okay so i can click on the
little plus sign here now or I should
say just before I get into this if I had
a fifth set that I wanted to submit I
simply click the button here it would
pop up an upload dialog and I could
upload my results of the cloud and have
them automatically evaluated I'm not
going to do that now because the
evaluation script takes a couple of
minutes to run and I'd rather just just
keep showing you rather than watch what
you're an application run for a while so
what I'll do is I'll show you the
results of that run i'll click on a plus
here I didn't click my mistake okay
there I go okay having a clicked on the
plus sign next to that particular line
you'll see I've opened it up and it
shows me a range of different things
about that submission ok so I'm i can
download the submission so i can have it
back so i can see the results that i
uploaded earlier if i wanted to do that
now i uploaded this one actually i did
in january so i could actually retrieve
my results from as you now and take
another look at them if i don't have
them around i can also look at the
standard output in other words i can see
what happened when i ran my results and
it actually records a little real time
log here of the results in how they were
process it's not very interesting really
the point of this is it helps
troubleshoot if anything went wrong on
the cloud while you were running it it
unbundled the the data that you provide
it compares it with the with the ground
truth data it invokes a custom program
for evaluation which I'll talk about
later and then it generates the results
and spits them out in a comma-separated
format in this particular case you know
in other cases it spits it out in
different ways but that just happens to
be what this challenge needed ok so let
me just go back here to to cola ok now
let's say that I'm interested ok so I
know that my my submission ran now I
want to see the results of my submission
well I can take a look at just about
everything that was that happened on the
cloud with my results I have just popped
up a window here where I can look at the
define detail if you like now I'll go in
here and now look at the scores that are
generated on the patient data set and if
I double click on it here it'll start up
Excel because it's a CSV format file but
of course being CSV it's also available
in many other formats and this is the
other details of my competition entry I
won't go into all of these because
obviously there are other complex really
i'm showing you this to say that we're
not concealing anything under the hood
you can take a look at the code that
generated these results you can take a
look at these results themselves which
are the raw data as a result of running
later running that evaluation algorithm
and you can also see the summarized data
which is your competition entry that's
how well you actually did because this
competition actually as a summarization
process and reduces this much larger
data set into your only your competition
results and i'll show you those right
now ok but you can get behind the scenes
and see absolutely everything that you
might be interested in about how your
competition was run ok so i'll show you
what happened to these results i could
submit them to the leaderboard here in
which case a check mark would it would
appear in this column here now as you
can see i already submitted the fourth
set here a check mark appears here so
let's just look at those so i can click
on the comp lit well actually i go to
the results tab here i should say and
what that will do is it shows those
results in context
as you can see these were the real
participants in the in the brats 2012
challenge and as you can see they did
really rather well and all of the
different metrics that we that we scored
here and then down here poor old SJ
Mercer me I was the worst of the bunch
with my predictions but as you can see
that for the different areas of the
tumor the complete tumor the core area
the enhancing region the dice scores are
presented here and ranked for the
individual participants I can click on
different columns and sort in different
orders or i can download as a CSV again
which opens up in Excel if you wanted to
you can download all of this data and
play with it yourself so we're trying
not to be restrictive just because
you're using this platform doesn't mean
you get tied to this platform okay and
that's really how you go about a
competition at least how you go about
participating in a competition but there
are a couple of others that other things
I should mention in terms of how you set
up a competition if you go to my coder
lab as I mentioned earlier you can go to
competitions I'm running and you can
create a competition yourself if you do
so it'll put you into an HTML based
competition editor and walk you through
the different process the different
processes required to define the phases
of your competition to divine devise I'm
sorry too to determine the leaderboard
for each phase of the competition which
are optional where you can have
leaderboards tell how you doing at each
individual phase and define the terms
and conditions etc but if you don't want
to go through the HTML editor we've made
it easy for you there's other ways of
doing it all just minimize coda lab
there for a second and I'll show you
something else here this and let me see
if I can find the other piece of what I
wanted to show you assume too closed it
down I can't find it quickly so I will
waste time on that essentially what I'm
saying here is that you can you can i
see you know either use the HTML editor
to find your competition which is fine
or if you'd rather not go through them
you know more about how to use this
system you can use this format instead
this is yama which tells for yet another
markup language it's not a creation of
Microsoft it's quite common in the
academic community it's essentially a
dialect of XML which enables you to
specify in this particular case a set of
commands which will define your
competition fully now this llamo file as
you can see this actually relates to a
machine learning challenge that that's
being set up for use of Makai the
medical imaging competition or the at
medical imaging meeting that I mentioned
earlier and in this particular cases of
machine learning challenge and what it
does is it defines a single phase and it
defines all of the different columns
that that should go onto the leaderboard
the order that they should take whether
any of them should be grouped together
etc in short this one simple file
enables you to set up an entire
competition but there are certain
exceptions to that or rather simple rule
you still have to define exactly how
your competition is evaluated if you're
using standard medical imaging
terminology you're attempting to do
segmentation which is a very standard
medical imaging activity which you'll
find the vast majority of competitions
run and makai have some segmentation
element associated with them then you
can also go to our site and download an
evaluation script which for which we're
very grateful to to our collaborators in
the technical university of vienna and a
hanbury and his students ease in
particular and they created a large and
complex medical image of al uation
script which means that all of the
standard metrics are already encoded all
you have to do is use their script if
however you have a range of requirements
for evaluation which are unique to your
competition then inevitably as the
competition owner you'll have to write
that script we can help you to do so and
there's ample documentation or
the site once you've written that script
you simply hook it in under the the line
scoring program in the sea animal file
you upload the yeah more and you upload
the scoring program and the data and so
forth and it will automatically make a
competition for you looking just like
the competition we walk through a few
moments ago and of course we do have
user support people here who will help
you do it if you get stuck now going
back now to the website here we are so
that would happen if you wanted to do an
upload or use the HTML editor to create
a competition and that's pretty much it
for for the general part of code alive
I've shown you all the way through
competitions and I've shown you actually
if you go to the site you'll see there's
a range of medical competitions already
in progress and there's pipeline of
others that we're coming online so watch
this space for further ones in the
future the last part I want to talk
about here with relation to coda lab is
how you might contribute features so if
your program are out there if you're
thinking running competition yourself
but what you've seen would almost do but
not quite fit what what what you need to
do and you'd have to add some some
features to make it usable you could do
that if you go down at the bottom here
you'll see github is labeled here github
is an open source repository for those
who don't know it if i click on there it
takes us to our github page i'll just
maximize this so you can see it more
clearly this is our page on the github
site and i can go to our project by
viewing the project on github up here
and now you can see more details about
code lab how you get started we've got
coda lab wiki here so you can look at
your frequently asked questions or
answers to your frequently asked
questions you can also see how you get
started the fact that we support
unix-based competitions actually the
linux-based competitions as well as for
windows and the mac so if you're not a
strong windows user and your you find
your user base prefers Linux that's not
a problem that supports Linux
competitions alongside windows based
ones and there's tons in terms of
information here about a lot of features
that haven't had time to talk about
today relating for example 2 to the way
you might want to paralyze your workflow
and you're on the cloud to get
evaluation done more quickly but there's
a range of different things and you'll
find them in here if you're interested
there's much much more documentation
I've only scratched the surface here ok
now I'm going to go back now to my slide
deck so just one second while I do that
okay so you should see my Koda lab slide
back again so I'll just skip on from
that I spent a long time talking about
how competitions are run so I won't run
through this except to say that we're
implementing a series of shared access
signatures for those of you who are
familiar with out here to secure the
data at the moment because you can link
out to other data sources you can still
use this with secure data you just need
to protect it at the source and but when
you upload data to our system will have
a shared access scheme which will enable
you to restrict data only to those who
should see it in a very secure way and
in the future we'll be introducing a
federated access system to extend that
security model far beyond Cola lab to
secure data and third-party accounts and
beyond so I won't go into this in
details there's more details on the web
if you're interested in the technical
side to it I also won't talk about
exactly how participant participates
because I've shown you that so I'll just
move on to this my final slide this has
been a presentation as part of the
Microsoft Azure for research program
which hopes to show you the benefits of
using the cloud for academic research
thank you very much for your time if
there are any questions please feel free
to I am I am them over or failing that
of course you can also follow up in
email I'll just move on one more slide
to show you this if you will do want
further information on the medical
imaging work go to research microsoft
com / med imaging and with that link
you'll go to you'll be taken to a page
which will show you far more than just
what i've shown you today but will
enable you to find download links for g
oz references to coda lab etc so thank
you very much for your time I'll turn
you back to the moderator now ok Simon I
did have just a few questions if you
just want to look at those in the I am
real quickly ah ok I haven't seen those
como mistaken no I just popped them in
there ok ok so two questions here the
first one is does coda life support
other clouds with regard to application
runs in data storage
no it doesn't it's an as you as your
only solution we do make it possible of
people to contribute to the development
of koda lab by using Python etc but
currently it's all hardwired into as you
are under the hood there will be nothing
in principle to stop someone adapting
the code to use for example amazon but
it to the extent that code lab uses the
features of as you are in particular
you'd have to find the equivalents on
amazon although i'm sure they do exist
the second point is how application runs
underneath coda lab build that is a good
question and at the moment although I do
have a good answer for you it's not a
complete answer as I say code lab is a
work in progress at the moment
essentially the weight code lab works is
there is a default as your account which
is the default location for upload of
everything that goes into kowal app that
account is owned by whoever owns the
coda lab instance now because it's an
open source project there's nothing to
stop you from downloading and installing
your own code alab instance in fact will
help you do it that's not our first
choice to be quite frank because the
whole point of coda lab is community if
you're putting stuff up there to share
it with your colleagues surely it's
better to go to an instance that's
already running in a common location so
that all of your colleagues and their
colleagues are using the same instance
and can collaborate with you but anyway
sometimes you might want to run your own
and so we do make that possible so at
the moment the costs of the runs are
devolved to the owner of the coder lab
instance the owner of the coder lab
instance right now is Microsoft and will
shortly become a professor Percy leang
who is a machine learning researcher at
Stanford University and over time he
will assume responsibility for these
matters and will become one of the faces
of the community that we're building we
have other academics who were also
collaborating with who may also choose
to run their own code alive instances in
the longer run now that's the case at
the moment so everything gets billed
directly to the article
owner or rather I should say the
insolence owner what we will be doing in
the future is we'll be adding a billing
system in there which will enable at the
D hat or at the direction of the
instance owner they will enable the
costs to be devolved to the competition
owner so that will mean essentially if
you have a need to run a competition and
if you want to if you have the resources
to do so you may also have to cover the
billing to run that competition now that
the extent of that billing will entirely
depend on the size of the competition
that you run now what will be happening
with with most competitions is by
default they will just be uploaded into
the default account and costs will be
covered by the Codel a bar owner but the
reality is if you've got truly huge
competitions with truly large data
storage and and software running needs
then the competition the instance owner
may well ask you two to take
responsibility for the billing piece
that you incur okay I hope that's uh
that's covered that all right thank you
Simon so everyone we hope that you have
found today's information helpful if you
enjoyed today's webcast or have feedback
and how we can provide you with a better
event please let us know by completing
our survey you should see the link and a
pop-up box on your screen at this time
like to extend a big thank you to our
presenter Simon Mercer this concludes
today's webcast you may now disconnect
from this call
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>