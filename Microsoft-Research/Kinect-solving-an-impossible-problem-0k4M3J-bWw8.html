<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kinect: solving an impossible problem | Coder Coacher - Coaching Coders</title><meta content="Kinect: solving an impossible problem - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kinect: solving an impossible problem</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0k4M3J-bWw8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
we're high am I on speaker no okay am I
on can you hear me at the back yes
excellent does it need more okay hello
I'm not sure if you're all here yet but
we can do some simple stuff first who
has played with a connect okay I'm glad
to see not necessarily everybody who has
not played with the Kinect quite a few
people is that because you're hardcore
gamers and you can't be bothered with
the kinect who has not heard of the
kinect okay i'm glad to see that number
is small okay so I've got a sort of a
slightly boast II title here where I'm
saying that up until about five years
ago if you'd asked me five years ago and
in fact someone did ask me in exactly
2008 can we build a system which can
follow the movement of the human body I
would said sure we can build it but not
for another five years and I don't know
if you've ever heard but people who work
in research are always saying yeah we'll
be able to do it in five years time and
we know that five years actually means
some time in the future and we don't
know when so building the kinect was
something that looked impossible when we
were asked to do it ah but because of i
guess some great enthusiasm from one of
the people at xbox somebody who
basically didn't understand when we told
him it wasn't possible we were all
forced to do it so i'm going to show you
give you a picture try to give you a
picture why we thought it was impossible
and and then the end how we were able to
solve it so chris bishop earlier told
you a little bit about microsoft
research and the mission oh sorry toad
you little bit about microsoft research
and mission statement and so on but just
to give you picture what we actually do
here we you might think of what we do
is we try to invent new stuff and most
of the new stuff we invent we publish
descriptions of how we do it as academic
papers so it's like we write an essay
saying we've tried the following thing
and this is how it works before I
started working at Microsoft i worked in
oxford and i was very interested in what
you could do studying pieces of video so
in the background here can you see my
mouse no you can't so in the background
of this video there's a piece of a
ancient city and in the foreground are
inserted into that video you can see the
dancing character so our academic
research was on understanding the 3d
motion of what happened in videos when I
came to Microsoft the people here were
interested in a different sort of thing
they were interested in Los in could you
build a computer program which could
recognize what was going on in images so
Jamie chaton who is the first name at
the bottom here on this academic paper
was later one of the people who really
solved the Kinect problem and what Jamie
was interested in is can I teach a
computer to take a picture and then
label every pixel in the picture with
what it is like cow grass etc and he
could do this for 20 different types of
object now obviously that's not the same
as what humans can do humans can
recognize maybe 10,000 different types
of object and they can do it super fast
and super accurately we were delighted
with these results even though you'll
notice in the central pixel central
picture the body has lost its head and
there are bits of sky that probably
aren't really supposed to be bits of sky
but this was a pretty good result in
2006 and Jamie and his colleagues were
even able to do it in real time so they
could have a video where every pixel is
labeled as one of these objects wait for
a second season you Oh while I'm waiting
does anybody not know what a pixel is
does everybody know what a pixel is
getting nods okay and I don't know who
didn't answer either question
okay so Jamie's looking at ways of
recognizing grass and sheep and so on in
real time and that was great although we
had no real practical use for this
technology it wasn't that Microsoft was
planning to enter the agriculture
business with you know Microsoft farm
manager one point oh it was just that it
was a hard problem no one knew how to
solve it at the time and we thought we'd
ever go other sort of hard problems
which again have no real practical use
are centered around again I was trying
to do this thing of putting objects in
his scene but I wanted to do it with a
moving scene so this chaps face is the
real video and as you can see we're
flashing on and on on and off mustaches
on to his face now you might say is
there any practical purpose for that and
maybe you could say in special effects
that would be but really the reason we
were doing it is we wanted to figure out
how to understand moving 3d shapes and
this was just a way of representing or
demonstrating that we understood the 3d
stuff that was going on in that video
more recently I've been interested in
asking if the computer can figure out
what's happening in this set of images
now again you're humans right you're
totally good at vision problems so you
know what's happening in this set of
images it's some dolphins even if you
didn't know what a dolphin was even if
you'd never seen the sea or never seen a
fish if i told you that all six of these
images were for them from the same sort
of object you could probably maybe
figure out what is the set of 3d shapes
that could have given rise to these
images to know if you feel you could or
not but one of the things I'm interested
in the moment is can I build a computer
program which given those images in fact
given many more than those images oops
no jokes
can work out what it must be in 3d that
gave rise to the images we just saw so
this computer program looks at in this
case 32 different dolphin pictures and
then figures out that for those pictures
to be the same sort of thing I must it
must have been generated by some set of
shapes and those set of shapes are
controlled by those sliders that you saw
on the right hand side of the of the
screen so we've built we've recovered
some 3d information from this from these
images something else I was looking at
and this now looks a lot more relevant
to connect is we were trying to figure
out and this is work I was doing with
University of Cambridge and do apologize
Oh
oh dear okay I'll do it on the still
sorry we were trying to figure out if
you could look at a person it through a
camera that's the image on the top left
and figure out in 3d what that person
was doing so this sounds exactly like
what connect does look at the camera
look at the person and generate in 3d so
this is at the bottom or two different
viewpoints of what the computer thinks
that person is doing so this is like the
Kinect problem in a sense it's harder
because we don't have a special Kinect
camera we just have an RGB camera we
make it slightly easier by taking the
color image and turning it into a black
and white image but this looks much
harder than connect we were able to do
this in 2007 so why when they called us
up in 2008 did we say we couldn't solve
it well the technique that we did here
didn't work very well and it was about a
thousand times slower than it needed to
be for Kinect and connect runs on the
Xbox which is a machine that's about
five years older than the ones we were
using then so and also you're not
allowed to use all of the Xbox because
apparently games programmers want to use
the xbox so to do connect we have to do
it maybe a thousand times faster than we
were doing it here and we had no idea
how to do that okay so just in case you
haven't seen what connect does this is a
picture of what the problem we were
asked to solve we would like a camera to
look at a human and then we would like a
3d model that copies what the human is
doing to be entered into the computer so
I don't know does that look hard are you
all thinking that looks pretty easy I
don't know maybe the older people are
saying yes and the younger people are
saying no which is good so it's one of
these in this computer vision so all the
areas I've been talking about are in a
field called computer vision trying to
make computers see and it's one of these
problems it just looks so easy because
humans are so good at it and we try to
explain why it's hard so you know I can
show you this is what a picture looks
like a picture is made up of pixels so
when you capture with your digital
camera we measure the color at every
point in the scene the computer doesn't
really know about color it knows about
color as a combination of red green and
blue so for example
a red pixel is represented by the
numbers 100 meaning all red like one
hundred percent of red Knoblauch no
green and no blue a yellow pixel is a
mixture of red and green so 110 and a
white pixel is 111 so if I look back at
the image that we had here I can say
that the arrowed pixel to the top left
near the top left of the image is looks
a bit like that cyan color at the bottom
of the screen so its code is 011 ok and
etc so who can tell me the code of this
pixel yeah and what about this one
so you're saying it's got no blue it's
got a little bit of green and lots of
red maybe I'd go down a bit on the red
actually because I think it would look
brighter but I'll give it like point
eight point six point two maybe okay so
so that's fine we know how to turn
colors into into numbers and that means
that when we got an image this is what
the computer sees so this is a bit of
that same image a portion of that same
image represented as numbers and when
you look at these numbers maybe you
begin to realize how the computer has no
idea about vision all it sees as big
long lists of numbers so to turn this
back into an interpretation which says
you know a happy family in the park or
even which says human you know human one
human to human three is an extremely
difficult problem of course there are
other reasons why vision is hard it's
sort of obvious to you maybe but it's
not easy to see what's in this scene
what's in this scene a fish that's easy
enough for humans what's not obvious is
that for a computer this picture is
almost as hard there's almost the same
sort of camouflaging going on here
because of all the different colors and
all the different people one in front of
the other so for us the fish image looks
hard and the people image looks easy for
the computer they're both equally
difficult there's so much stuff going on
there are ways you can simplify it so
for example when people present the
weather they capture an image of the
person in front of a blue screen and now
it's very easy to figure out what's
front and back and indeed in on the TV
they use this information to with the
person in front of a new weather map
when we're interpreting images if we
convert this image of him in full color
into an image in black and white it
actually makes it easier for the
computer you might think it's worse
right because maybe clothing would help
to distinguish a person from a statue of
a person but the problem is so
complicated that for us removing all
that information from clothing which
doesn't really tell you about the shape
of the person makes it work
much better okay and then once we do
that we can tell easily from this
black-and-white image if the person's in
a different position so yes there are
going to be problems I'm not going to be
able to tell the difference between my
hand here and my hand here because of
course it won't appear in the black and
white image will solve that later but
this is a way to reduce the information
that the computer has to deal with and
their course that was the technique we
saw in this video I doubt if it will
play this time either who hasn't gone
white okay how's the way okay so the
first problem from connect was if we had
the blue screen background we'd be able
to separate the person from the
background and we'd be able to get this
black-and-white image and I would make
it much easier to recognize the body
shape so the people are connect which
weren't in this lab that invented this
amazing thing which is a 3d camera so in
this 3d camera oops in this 3d camera we
still have colored pixels so I still
have some pixel here and I've colored it
in dark red but these colors no longer
represent actual colors they represent
the distance from the camera to the
person so there's a code here on the
right that says that this dark red range
is about 2.2 meters so the hand is about
2.2 meters away and the background is
about 3.5 meters away so this camera
solves a lot of problems for us we can
immediately separate the person from the
background just by saying anything more
than 3 meters away is background and we
can do that by first of all looking at
the room without a person in it and then
looking at the room with a person in it
so that's easy we can get that black and
white image we can also solve this
problem by where my hand is in front of
me because I have the 3d information so
that's all good let me stop and tell you
for a little bit how that 3d system
works so for a long long time people
have been able to measure stuff in 3d
using lasers so imagine I have a laser
pointer here sitting somewhere in the
world and ignore these XYZ
and I have a camera somewhere else if I
shine a laser on the world eventually
the laser beam hit something and because
it's a non painful laser it simply
causes a red dot to appear in the camera
if I shine if the person moves further
away then the dot moves further to the
right in the camera so i sent loosely
speaking just how far to the right the
dot is tells you how far away the person
is and there were lots of systems which
were built on this principle so they
would scan the laser beam through the
scene there's one that just missed the
person altogether and every time the
beam scanned through the scene they
would get some 3d information so that's
a great way to get 3d information it's
very accurate but it's unbelievably slow
because you have to scan the laser
through the scene it might take you 10
seconds with a high-speed camera to
capture all the 3d information so the
obvious thing is showing lots of laser
beams at the same time into the sea and
look at them all at once there's a bit
of a problem here then the problem is
that this beam and this beam you can't
really tell which one they match to in
the image and if you make a mistake
about which one you match up you end up
with a death measurement that's
completely wrong so we can look at that
by just pretending we have a camera
which only works so I've scanned out my
laser beam just in a one-dimensional
slice so I'm just you know scanning the
beam horizontally and now all those
images would appear on this line in the
camera so here are my three beams out in
the scene hitting the object at these
three points and this is where I view
them in the camera and it might be
obvious to you that I can match up the
left-hand one here with the left hand
one here the middle one here etc and if
I did that I would get the right answer
if I match them up wrongly I could get
any of these other answers right because
we're any ever any pair of beams
intersect that's a possible 3d position
so there are lots of ways to solve that
you don't have this problem if you're
scanning the beam right because the beam
just you know it there's only one image
in every in every captured image
the Kinect guys solve it well they have
a special pattern and this pattern every
little square of this pattern has a
different set of random dots so I can
tell which dot is which by looking at
the neighbors surrounding it and this
tells me what's happening in 3d because
if I look at where that Mouse is here
you'll notice that the dot pattern is
moving left and right under the mouse so
when the thing is far away the dots are
far to the left and one other thing is
near to me the dots are to the right so
this is the basic principle you can
measure just measuring how far to the
right it moves tells you what's happened
in 3d so hooray that means that we get
an image like this well without the blue
bit there's the image where I have grave
where I have 3d data and green in the
background and this is a side view so we
can see that there are three dimensional
points that the camera can see and this
is a top view so we have lots and lots
of information hooray okay well so now
I'm still going to claim it's hard why
am I going to claim it's hard well it's
going to be hard because even black and
white there's a lot of different
appearances for humans right so you can
have fat people thin people people can
wear different clothes so I wouldn't
recommend playing connect with your
handbag partly because you might hit
someone but also because the system has
never been taught to understand handbags
we would like connect to work on people
of all ages so again this huge
variability and what people can look
like you can maybe figure out what that
variability is how many different
positions do you think you could get
your body into
you think a million
that's true Adam position let's ignore
fingers and let's say I want to be
accurate to about this much so five
centimeters sorry you think your
trillion okay we can work it out okay
it's not that hard here's my left
shoulder right and let's say one two
three four let's say 10 positions like
this okay and I let's go from here one
two three four let's say another 10 okay
so that's just a hundred positions just
for my left shoulder other thing is I
can do with my right shoulder I can do
the same set of positions completely
independently right so that's 100 by 100
straight away which is I hope 10,000 and
I haven't talked about the elbows and
let's say we have another 10 for elbows
and haven't talked about the legs at all
where I'm going to do the same sort of
10 by 10 calculation and ignoring hands
but looking at the wrists we'll throw in
another 10 so it turns out you multiply
those up a lot we multiply those up
let's suppose I have 14 just 14 joints
each of which have 10 possible positions
then our 100 possible positions then I'm
going to do a hundred multiplied by
itself 14 times so it's going to be that
that number which is big right 10
trillion trillion or 10 billion billion
billion now I got that wrong whatever
it's big number okay so there's a lot of
complexity now the way I did that
calculation is a bit wrong right because
it allows my hand to go like go through
my body and stuff so if you really sort
of try and work it out properly maybe
it's only 10 with 12 digits after it so
maybe it's only a trillion trillion
maybe it is only a trillion trillion and
the number that we actually have to deal
with but anyway it's a lot lots like
stars
and the other problem is that the only
way we really knew let's say ten years
ago at work 15 years ago how to solve
this problem was basically Chris was
talking today about one-way functions
you may know that video game systems can
animate people right so the video game
system knows how to take a human body
position and generate a computer
graphics picture of the body so the
video knows how to take some
representation so my representation here
is I should know this do you use Greek
letters at school yes you do someone's
nodding okay so what I've done here as I
said the game system is 14 numbers let's
say oh sorry 28 numbers which represent
the possible angles and once you know
those 28 numbers you know everything
okay that tells you where the body is
and the video game knows how to take
those 14 numbers that represent the
position of the body of the pose and to
generate a computer graphics picture we
know how to sorry
so you can think of the way is a bit
like doing that stuff with the laser
scan except it only uses effectively for
laser dots rather than a million or
whatever the connect users yeah but good
thank you for the question because of
course the wii seems to do the same sort
of thing who thinks the wii is different
from connect who thinks it's the same oh
sorry if what a stupid question
different and essentially the same okay
both are right really early but we claim
connect is better because you don't have
to hold anything there's no machinery in
the body it works just for images okay
so that's the function that's easy this
is the function that's hard given the
image what do you do to get back those
28 numbers it's like there's a million
numbers here saying what every pixel is
what do you do to get back to 28 numbers
which tell you where the body is hey we
still don't know so let me tell you what
we did actually before that I'll just do
one little calculation so remember in
2008 I said the Xbox people phoned us up
and said can you solve this problem and
we said haha no we actually said I
actually said something like I could
save you a lot of money by telling you
not to even to try because it's too hard
and but they said well you know you say
that but we've already know nearly
solved it so this is something that the
Xbox people did without any input from
us and this is a system I keep talking
about ten to the twenty eight or ten to
the twelve these huge numbers of
possibilities well they said suppose I
start like this suppose I start every
game like this then a thirtieth of a
second later because the camera works at
30 frames a second right I can only have
moved a little bit right so surely it's
not a trillion trillion possibilities
it's like a hundred possibilities from
frame to frame and then they made this
video so the system is waiting for the
player to start the player goes into
position and now he's locked in works
amazingly well alright fantastic
solution the only problem with this is
you'll notice that this video is how
long as a 9 seconds long or something
their system is never going to be able
to work for a long time right and we can
figure out why you can do a simple sum
to figure out why okay the problem is
something called exponential likelihood
of failure or the problem with temporal
coherence suppose that my system is
fairly good it works ninety-nine point
nine percent of the time so if I knew
the answer at thirtieth of a second ago
I have a point one percent chance of
being wrong this time okay so that
sounds good right point one percent
chance of being wrong doesn't sound bad
that sounds like you would you know you
wouldn't fail that often so the problem
is after two frames I get my point nine
nine nine chance of being right and i
have to multiply it because I could have
failed the last frame i could have
failed this frame all right point two
percent that sounds right 30 frames I do
point nine nine nine and i multiply
together 30 times three percent chance
per second failing maybe that sounds
okay but the real problem is after a
minute that's 1,800 point one percent
chances of failing basically I have to
do this computation where I do X to the
power of why this button on your
calculator who has used this button few
people okay well here's a use for the X
to the power of Y button I want to
multiply point-nine 99 by itself 30
frames x 60 seconds and I'm going to get
this number seventeen percent chance of
success basically certain to have failed
after a minute and there's no way around
it if your system depends on being right
half a thirtieth of a second ago
eventually it's going to fail because
your error is multiply and accumulate so
that's scary and I'm nearly out of time
so i will give you a very quick picture
what are we going to do we're going to
take lots of pictures so the system we
don't know how to do this function
backwards so what we're going to do is
take lots of pictures of the right
answer so we use computer graphics to
take a position and generate an image
and we're going to do about a million of
these
so if i go down here
we're going to do all sorts of shapes
and sizes of people all right we're
going to do all sorts of positions of
people you're going to use motion
capture together get lots and lots of
different positions we're going to put
them into something like this and then
eventually what we're going to have is
this huge collection of different images
of people and associated with each image
as you can see there the people are
essentially wearing a colored suit so
the arm the elbow etc form these
millions of images which of course we
can arrange so that all the fat people
are in the writing and all the thing
people are outside or they could be more
tightly packed thank you that's a that's
a kinder observation okay so every
person has been changed into this
colored image where different parts of
the body are given different colors and
remember we were doing that thing with
cows and sheep and recognizing those in
real time well now we can run that
instead of this pose estimation
algorithm and that will give us an
answer like this one
so coming into the computer is or this
picture this is what the computer thinks
is happening so if it's working it will
always be coloring the right hand with
an orange blob so it looks easy enough
here but even when the hand goes to the
other side of the body or when both
hands are on the same side of the body
it's still correctly coloring the right
hand blue and the left hand orange and
because we have so this information is
now enough for us to to get the kinect
working ok ok I say that's not enough
that bit that we did was called joint
position hypotheses it gives a couple of
guesses as to where the body is in every
frame dozens of other people worked on
this project and they had to do a bunch
of other stuff because those answers
were only good enough to give you a
starting point for thee for the kinect
and of course as you play if you played
with the kinect you may know that it's
not perfect sometimes you're moving
around and suddenly a hand jumps in the
air sometimes you know it loses your
legs so some other and another amazing
thing that happened was that the people
who built video games had to build games
that were still a pretty good experience
and I like them you know bowling or
whatever they're still pretty good
experience even though the hardware or
the software doesn't produce a hundred
percent correct solution in fact it
might even be that the answers we get if
we say that the original xbox solution
was ninety-nine point nine percent ours
might be 95 but because ours is 95
completely independently on every frame
it stays at 95 forever so you never get
any fade so that's why it works the way
it does thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>