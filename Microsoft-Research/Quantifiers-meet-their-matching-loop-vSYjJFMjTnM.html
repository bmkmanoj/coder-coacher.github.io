<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Quantifiers meet their match(ing loop) | Coder Coacher - Coaching Coders</title><meta content="Quantifiers meet their match(ing loop) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Quantifiers meet their match(ing loop)</b></h2><h5 class="post__date">2016-07-07</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vSYjJFMjTnM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
welcome to the seminar we're going to
have to talks here today both end of
internships hawks and I had the pleasure
to introduce first of those coming but L
who's been my intern this hour clémence
comes from MIT where he is a grad
student in Adam Schiff hollis group and
he's worked on on taking a step forward
with with that made at the summer and
he's done not just working on the
project we set out to do but he summoned
immense amount of work on another tool
that he loves me and I think yes I'm as
a description of what we put to work
possibly achieve there comes a point
where when you work with automatic
solvers like smt saw that you had some
limits and the limits can come in with
quantifiers and the question then
becomes I mean do you stop is that all
you can do or can you take step forward
and thanks written and thanks everyone
for coming to attend this internship
this this doc sorry so this is going to
be my end of internship talk about
generally speaking dealing with
quantifiers with new techniques and
tools applied to death um just a word
before i start with a core technical
matter what exactly is Daphne Daphne is
a verification aware programming
language that is a language designed
with verification in white like many
other tools f star in a number which are
developed here daphnia is based on
boogie and on xiii Daphne runs on most
common platform has advanced editor
support and a number of ideas and
particular MX now and just to give you a
feel of what Daphne actually is I'm
going to give a quick demo to begin with
so i'm going to write a small program
and Daphne and prove it with you and
this is running an emacs mode that I
wrote in the context of this internship
so i'm going to write a maximum program
that given a list of integers or
sequence of attention Daphne parlance
and produces the maximum of that list so
I started by declaring the signature and
then i'm going to write the program
exactly as if I was not verifying
anything so I'll right well I'll
initialize my maximum to the first
element in the sequence and then I will
loop over the sequence declaring a
variable bus starting at zero and then
looping over the sequence until we reach
well the end of it I look at a new
element and if the new element at that
position is greater than the maximum
that I've accumulated for now then I've
been update my maximum to that new
element in all cases I just increment my
position variable and that would be more
or less how I would write it if I was
writing it in a programming language
that was not verification aware however
Daphne is already complaining about one
thing here if I put my mouse there it
says well this'll X could be out of
range why does it say this because I
never guaranteed that i would only call
this function with what sequences that
actually had an element at position 0 so
I'm going to require um that the that s
be non-empty and once I tell this to
Daphne Daphne doesn't find anything else
to complain about but notice that our
maximum function doesn't actually export
any guarantee yet so I'm going to add a
few guarantees and we'll see how
definitely reacts to this the first
thing I'll say is well the maximum that
I return is in fact a member of the
sequence that I'm looking at so when I
ask that need to prove this that people
start complaining about the while and
say I can't prove this unless of course
I give it an invariant that oops an
invariant that the maximum is always in
the sequence and with that extra piece
of data definitely manages to to prove
this particular ventures but that's
still not the definition of a maximum I
want the maximum to be bigger than all
the elements in that sequence so I'm
going to add an extra ensures that says
that for all element so for all Y or
actually for all index in the sequence
if the index is in bounds
then the element at this position and is
smaller or equal to the maximum and just
like before Daphne starts complaining
about this it tells me well um this is
the post condition that might not hold
here and the reason why it doesn't hold
is that definitely doesn't have a waves
definitely doesn't actually have a way
to to track this thing across the loop
so I'm going to add the necessary
invariance here so I'll need two of
these this time and i'll just say well
for all positions that i've already seen
in my list my maximum is or it might
intermediate maximum is bigger than this
so for all i if the element is between
well the eye is small in the bus then
the value there is smaller than the
maximum and now a deafening stops
complaining that's your fully verified
maximum implementation and Daphne now
how does this actually work in terms of
proving well what Daphne does is it
starts by converting this file so
translating this vile really to another
verification language called boogie so
actually present this differently all
right so what it does is it produces a
different file that looks like this
that's pretty long and that says well so
boogie is the language to which Daphne
translates and Daphne well boogie
actually translates this down to another
level xiii and produces a xiii source
that looks like this so yeah yeah
there's a bunch of I mean this is Z 3
code and then xiii verifies this and
then we print happy messages in the
editor to say well congratulations you
proved your maximum function and as you
saw Daphne is pretty efficient at
verifying small programs I mean it's
very fast but larger programs actually
done to suffer a lot more and that's due
to a variety of reasons but essentially
verification performance gets gets
chaotic sometimes it's very good
sometimes it's very bad and it's not
really clear what causes it to change
for example you write a program that
looks like this VAR y equals x assert
something it verifies
but then you're right VAR x equals y
plus 0 and and that fails to verify my
work here focuses on on this particular
issue of what we call butterfly effects
and we did in the context of Daphne but
we expect that it can generalize to
other provers so the first question to
start with here is what causes this
instability and there are really two
core causes for this the first one is
translation or encoding if you will
thinks that look very similar at the
daphne level may actually lead to pretty
different things at the z3 level and z3
will not realize the close connection
that existed in the source another
source of chaos and here is the one we
focused on is non decidable domains in a
sense you don't have a clear decision
procedure for solving these problems
that could be non-linear earth medic or
it could be first order logic that's the
one I worked on so z3 has a bunch of
heuristics and if the input that you
give it doesn't really work well with
these heuristics you get horrible
performance and there are two kinds of
issues here matching loops and costly
institutions so how do we make things
better well you can start by educating
users if you explain to your users what
those heuristics and z3 are and how to
actually produce code that will please
z3 then maybe things will be better and
other way is to improve everything else
maybe there are no other problems than
this then that problem itself won't be
that much of a problem anymore and you
could of course for the cases where
things actually start going back improve
the debugging tools so that the
experience the user at least gets a
better experience when solving their
problems but what you'd really like to
do is get rid of that problem at least
to the extent that is possible so you'd
like to choose better triggers which are
what xiii users to guide it through its
search and you'd like to prevent those
matching loops that i've already
mentioned of course the problem here is
that if you let z 3 so if you give it
very little direction c 3 is going to
search in a bunch of direction it's
going to prove a lot of things not very
reliably but a lot of things if you
start guiding it in a much stricter way
then there will be cases that you used
to proven that you won't be able to
prove anymore um anyhow so what did we
implement here we implemented a bit of
all that I mentioned but our core
technical contribution here is really
adding a bunch of trigger related
facilities to Daphne we now generate our
own triggers we eliminate the matching
loops that we can detect and we rewrite
quantifiers in the way that we believe
is going to be better for XIII in
addition to this we added we created
Emacs most for Daphne boogie and a bit
of support for XIII we extended the
existing axiom profiler to give better
visualizations and we added windings and
the IDS that our users well use so let
me move to the technical part of this
talk how does def knee I'm actually
verify your program well Daphne starts
it looks at your program at ports is it
type checks it then it applies the
number of transformation in the AST of
your program to ensure that it ends up
being more z3 friendly and that's really
where i worked in here then it gets
translated to boogie then 2 Z 3 and
finally everything gets verified um so
when you send a problem 2 Z 3 that
contains quantifier z3 prison in the
following way suppose you give it you
have a fact you know that sir cadiz is
human and you have a quantifier that
tells you that for all element if that
element is a human then that element is
mortal and you're trying to prove that
Socrates as a mortal so Z 3 has those
two terms this one is something that it
knows and this one is something that
it's trying to prove but it still has
the term and it has here an indication
an annotation a quantifier that says if
you see something that looks like is
more to love H then use it to
instantiate this fact and learn this new
fact so z3 says oh I have something I
looked like Socrates is mortal thus I
have HS mortal for h equal Socrates thus
I can learn that if Socrates is human
then Socrates is mortal but z3 thanks to
propositional reasoning can now know
that knowing that Socrates is human and
knowing that being so good is being
human implies him being mortal allows it
to deduce that Socrates is mortal um as
you can easily imagine choosing the
wrong triggers that is choosing the
wrong annotations on the quantifiers
that you sent to z3 can cause any sort
of problems ranging from z3 taking a
very strange path to the solution and
thus having a predictable performance or
even not finding the proof at all in
general though z3 is pretty good at
picking triggers
as long as your formulas look as nice as
what I've just shown here but that's not
actually the case on and daphne xiii
produces extremely liberal triggers on
Daphne coat because of a number of
issues but mostly because Daphne
produces extremely large formulas which
are written with what I call parasitic
terms they're useful in the encoding and
useful to ensure that we actually make
sense but they're really not good
candidates for triggering because they
appear in a lot of quantifiers take this
example you start with s of X and
definitely look simple right and then in
Boogie that already doesn't look that
good and when you get to the xiii level
there is no way that xiii would know
that the interesting part was just a
small bit of that thing that got
expanded into a complex term of course
there's a number of ad hoc things that
you can do to fix the situation but
what's really needed it is it is it I
mean kapri hensive approach to that
problem so how do we do we come up with
good triggers well we work at the daphne
level that means that we look at terms
that we can actually report to the user
as being triggered and that we know will
make sense because the user wrote them
we walk the AST we annotate notes that
look like triggers and annotate notes
that could not be triggers and we
collect all these nodes then we try to
find subset of all these notes that
cover all the quantified variables we
reject a number of those triggers that
we found and we eventually annotate the
st the rejection is of course for
performance reasons um let me let me
walk through an example actually suppose
i have for all X P of X and Q implies P
of X plus one I have a bunch of sub
expressions I can exclude all the ones
that mention a binary operation because
XIII won't allow you to use these and
triggers so all of these are out and
then they're just remains to good things
here that I can actually choose that
means that it will annotate this
quantifier with the with the two things
P of X and Q of X um there's one nice
thing here the the terms that I get are
terms that literally appeared and in the
body of that clan in fire and and so
that's one of the big gains actually it
is that when I tell the user here are
the users that are the triggers that I
picked the user can see yeah that makes
sense it was in my formula I don't tell
it hey I picked this box thing that
you've never heard about before but that
I thought was a good trigger
so we don't pick the parasitic terms
like box which the yields of course less
costly institutions and if we don't find
anything we can actually tell the user
there's a problem with this quantifier
we can't find anything you can let it
let xiii do its work but we think that's
going to yield problems and that's not
all actually we can start looking for a
lot more things in particular we can
start looking for matching loops the
ones i've been talking about for a while
now so what's a matching loop well
suppose a quantifier talks about itself
in a way that is you give it a trigger
so you say if you see an f of X generate
this formula and then every time you see
an f of X you learned that f of X is
more than f of f of X well what happens
next you have a new term here that has
an F of something it could be F of Y if
Y is f of X so if you start with F of 0
you learn F of F of 0 at least you have
this extra term and then F of F of F of
0 and so on and z3 gets into a and as
you can imagine two that's not very good
for your performance the trick is that
now that we're we have those triggers a
definite level we can work on
suppressing those loops so we can do is
for every candidate in our trigger set
we look at the body of the quantifier
and we look at the terms and we say this
term looks like it could cause a loop
with that trigger and once we have
annotated all these we choose to exclude
the ones that we think will lead two
loops and we report that information to
the user of course but even then that's
not all because that tends to do a lot
more than you would actually want it to
take the example that already talked
about for example suppose I'm trying to
pick a trigger for this well P of X and
Q of X are two choices here but then if
i pick P then I'll learn in term P of X
plus 1 when I see she ate it and then
I'm getting myself into a loop so what
do i do I just exclude p entirely that
doesn't sound too good now it means that
if I so I only take q but then now if i
have a p of 0 i won't be able to learn
that it holds although the quantifier
tells me very clearly that for all X P
of X holds so I've lost a lot of
generality of proving power here and one
way to regain that that generally be
that experts emiti is to split triggers
it would quantify your sorry so i take
this point if I were and say well
there's really two facts package in one
quantifier here so I can just split it
in two and
give to fax to XIII for all X P of X and
for all X Q of X implies P of X plus one
now we run my usual trigger generation
on this the specs p of x here and this
pics Q of X there and then I'm happy
well I'm not exactly happy because I
still I'm losing something when I had
this full quantifier I had Q of X as a
trigger there if I knew q of 0 I would
gain p of 0 that's not the case anymore
here so the user package those two
quantifiers together because the user
knew that q of 0 would be a good a good
term to eat to learn p of 0 then we just
lost this how do we regain it that's
very easy in fact we can just share
triggers between the split quantifiers
that is we split our qualifier but then
we love for triggers we share them
between all of the quantifiers that we
generated and then we do the loop
detection that as we look at this whole
thing we say candidates are P and Q now
which one's in here cause a loop while
none of them so i take p NQ as the
triggers for the first part of my
original quantifier and then this one i
take only q which is the one that
doesn't yield a loop here and that
reaches an interesting situation where
in fact the triggers that you pick for a
quantifier and not necessarily inside of
its body so let me say a few words of
how well that worked well we did two
types of experiments the first one was
trying to see if it actually improved
predictability the way we measure this
is we run XIII on our fault well we run
Daphne on our full test suite six times
with different seed parameters with the
hope that a stable test is one that
doesn't stop verifying or take a lot
longer when you change the seed and what
we measured then was the standard
deviation of the verification time for
each of those tests and where the two
plots show as the distribution of
standard deviations in the case of xiii
pick triggers and then a case of daphne
victories and as you can hopefully see
on these diagrams we've pushed
significantly pushed the distribution of
standard deviations with that meet
records towards smaller deviations and
of course we can also look at the so it
was not clear to begin with that we
would actually improve the performance
there i mean we're doing more work and
we're being less than erick so we could
hope to gain some stability but maybe
we're going to lose
and actually that's not the case on one
benchmark from the ironclad team
definite generate triggers achieve a
speed-up of thirty five percent over
xiii generates triggers and there's
another type of result that I actually
care a lot about what we do now is
something that we can explain to the
user so we can sell a user well these
are the triggers that we picked and in
fact to support this point I'm going to
actually show you that we do report
triggers to the user so in this
particular example and definitely is
currently running if I point on this
particular oops I point on this
particular quantifier it will tell me
two things it split this into so now it
has two expressions in there Q of X
implies P of X plus 1 and P of X and it
tells me well for that one I fixed Q of
X but I rejected be because it could
loop with P of X plus 1 for the second
one however I chose just the two
triggers pop up dead yeah you want it um
but fortunately also works if you just
put your mouse on it and yeah I mean all
right thank you and another thing is
that even if there's problems start
occurring we want the users to be able
to understand better what's happening so
what we did we came up with better
visualization tools which I'm going to
demo to the idea is that there exists an
action profiler for XIII already written
by me ha which is a great piece of
software the interface is the only thing
that is slightly lacking so what I
worked on is improving that interface so
i took this example from the daphne test
suite what i can do is ask Daphne
through boogie to profile that example
that is for every method to measure how
long it takes which then let me fix the
method that seems to be the culprit and
run it through an analysis um since this
computer is not very fast I've actually
run the analysis previously it would
take a minute but I don't want to waste
a minute of anyone's time so that's the
thing that you get for one of the
methods so what the diagram shows is
each node in here is a quantifier and
each edge is terms learn from that
quantifier causes causing
other quantifiers to instantiate so in
this say that there was one thing that
was apparently pretty costly and then a
number of other rather costly items they
were initiating all other in all
directions and this is actually with
pretty strong filters but if I showed
you the entire graph that's how it would
look like that text selection so one
thing I can do when I have this huge
graph and I'm not too sure what's
happening is to start filtering it so is
there a problem in the sequence with the
method append on lists well I just type
it been here and it highlights the note
that actually talk about it then so you
see that there's a pretty central note
here that connects to the other ones and
a talk about a band so that could be an
interesting direction to look at it
could also be a problem with a heap in
this particular example and in fact yes
this example talks a lot about the heap
and of related problems so if i zoom in
and I just yeah put filters here
actually let me do it for real so if I
if I filter this a bit further and then
I really have the graphical just these
nodes what I can see is well there seems
to be two main culprits here there's
this thing which is a boogie specific
thing that I'm not interesting in
debugging right now so I can just remove
it and then there's a number of other
nodes in particular this one and now
what that one says is you have this heap
suck relation it's transitive and well
it's causing a lot of institutions of
that node and nano tells you if you know
that something is a heap suck then you
know another fact so what I know here is
that there are problems with a heap and
that to diagnose this problem a good
thing would be to look at series of
instances series of assignments to the
heap that caused the success of AD axiom
to be used and that thing is not only
for Daphne in fact because I managed to
sell this to the f star team which for
which apparently it was at least a bit
useful and having an overview of what
actually happens when you run f star in
a program and reducing the shape of
particular shapes that was that were
happening I'm occurring in that graph so
by means of a conclusion one thing I'm
happy about is that Daphne's next
release will come without o triggers
enabled by default entirely or at least
we hope obviating the need for
performance hack that the ironclad team
was using up to now we believe that the
techniques that have developed here are
actually very good areas to look into
and in fact we think that they open a
whole new world of opportunities for
going beyond the problems that we were
seeing with with verifiers improvers and
finally what we realized is that coming
up with good visualizations about these
things can really yield new inside on
surprising often verify your behaviors
and two more personal things people MSR
we're really great so thanks a lot for
having me and Daphne and its users are
pretty impressive I'd like to thank a
few people to finish me how for his work
on the action profiler J for testing me
max mode Alex summers and Nick for the
help with determining what this new
action profiler would be Brian and Chris
for three days into my internship
allowing me to understand the dispersity
fifty percent performance boost that I
got was essentially me replacing all the
preconditions of their functions by
false and rear stone of course for
making all of this possible and for the
wonderful experience so thank you
everyone yeah how do I evaluate this at
scale um you mean on large Perkins I'm I
asked Karen cloud for large programs and
then I run it on those programs and I
see how long it actually takes to verify
it gets thirty five percent faster
overall and then turret that sweet onion
darkest yes um 35 is yeah the average in
the sense we so I've studied the Daphne
test suite more precisely um so there
are a few issues that are not directly
connected to triggers for example we
have things related to encodings those
tend to have varying behavior some get a
bit better some get a bit worse in some
cases splitting your quantifier where
you were you had an explicit loop there
that had to fix me next to it will
actually cause this loop to what loop
more but there is also a number of cases
where well in fact you had a loop and so
you had this instability in the in the
test suite and you get rid of that loop
you don't have the instability anywhere
so you do a lot of the things you do at
the that mean I guess a lot of the
theory that gets 53 is just background
in coatings of things might not have
direct relationships worse how do you do
anything an experiment no we don't do
anything about about those things that
are not don't come from the Daphne
program one experiment that was
interested in the beginning of this
internship was seeing whether reducing
the amount of stuff that we told XIII
when we knew that this stuff was not
going to be useful would actually help
so what I did was this experiment were
essentially so it was cool to boogie
with Baker you would just like poke
through the daphne prelude so there's
set effects that you teach xiii about
general Daphne programs and then tried
to remove as many things while
preventing the well while keeping the
program verified and that doesn't really
change performance so xiii is pretty
good at actually i'm discarding the
stuff that it's not going to use in a
proof you have any chance of having a
group the triggers for these are all
euro yes there's definitely a chance for
this and that's why the triggers in the
in the tests we end up sorry in the
prelude are particularly important we've
done a bit of work on them but I mean
they were written by recent so they're
pretty good other questions maybe
yeah that's great we only look at the
particular quantifier there's an
interesting extension of this work which
would be to say well we can split
quantifiers now so why don't we first
package quantifiers together then share
their triggers and then split them back
you could do this for example for
invariants on a loop you would imagine
that they're pretty closely related um
that's definitely feasible there are
tricky aspects to this with the fact
that all your quantifiers know might not
talk about the same variables so you
need to I mean there are technical
issues to this but it's definitely
something you can do yes um that's also
very interesting problem and we were
hoping to do this at some point the
issue is that it's not as simple as
saying this point of our cause is that
one which caused it that one which does
is this one because of multi triggers
that is if you have a trigger that has
two terms in it then you need to track
essentially the whole history of what
happened on your graph so it's not
enough to say there exist a path from
here to there and then from there to
here you need to say there exist a path
on essentially the the product graph
epatha grep you want to pass on the
graph of old pass on your quantifiers
and that is just huge um everything that
z three runs on actually now so um yeah
it runs so there were a few issues with
the end coatings of big integers but we
fix those um so now we run on mono
without issues well the whole test suite
minus one program that uses a dll that
we haven't boarded yet yep and even
freebsd if anyone is interested all
right so I was wondering
if you know I has anybody studied the
complexity of detecting a matching move
in a set of qualifiers that no um I'm
not aware of work in that direction
which doesn't mean that there does not
exist work in that direction I didn't
actually I could have shown this so
that's the old act in profiler so yeah
the graph is essentially showing you
this but in a slightly different way and
it is known for taking more more time to
get started with and it's it's more
difficult to get started with but theme
because it is less automatic yeah so I'd
say it's a bit of a I think it would be
tricky to compare the two in that sense
because so if you look at the
looks very manual right so you write
your proof and indeed everything happens
exactly as you want it to happen however
after writing a thousand lines of
trivial proof for you say a reflectivity
reflexivity commutativity reflexivity
you get to desire some automation God
has a number of things that are domains
where it's decidable or has like good
ish decision procedures for a number of
these things but then you get to a point
where you need to write your own
automation and then what you're
essentially doing is writing a small
subset of XIII that is specialized to
your particular use case the problem is
that debugging this is generally as hard
if not harder than debugging issues with
these three itself the thing is you end
up writing your own automation but
there's no reason why writing your own
information in 10 minutes would do
better than the automation that sits in
XIII but it won't let you
actually it will let you do anything so
it depends at what level you put the
automation if you do it an LTAC then
we're just doing is you're calling basic
tactics which hopefully don't do in
sound stuff you can also do it using a
no camel plugin the thing is that
tactics in are the individual
steps are reasoning are not verified in
any way what they do it they participate
in constructing a term and then at the
very end this term is verified so you
can have a tactic that takes any goal
and say that goal is solved but then
it's not going to unless it's very smart
but otherwise it's not going to actually
generate the term that does this and so
when you get to the final checking
will say this dummy proof term doesn't
actually have the type that you required
to have so yeah I mean will let you
do a lot of things with your proof term
but then at the end you'll pay the price
of not actually I'm staying on the right
path ok yeah thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>