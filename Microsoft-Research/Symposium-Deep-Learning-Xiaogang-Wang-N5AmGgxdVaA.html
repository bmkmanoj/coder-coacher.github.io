<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning - Xiaogang Wang | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning - Xiaogang Wang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning - Xiaogang Wang</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/N5AmGgxdVaA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so we are very delighted to
introduce sharpen one so shebang is a
professor of electronic engineering in
chinese university of hong kong his
group has worked on deep learning and
computer vision has and has done many
great works in particular his group
achieved near human performance in base
recognition such as over ninety-nine
percent in label faces the wild data set
and also his team has achieved pub
entries in large-scale object detection
challenges in recent years so today
xiaoguang will talk about deeply learned
based representation okay thank you I'm
going to talk about the feature
presentation for face recognition so in
the past two years a deep learning has
to boost the performance of his
recognition substantially so on the
well-known face recognition benchmark
rfw and the fist verification accuracy
has been improved from nineteen nineteen
sixty percent to almost perfect and even
supposing the human performance on this
benchmark so you need to talk I'm going
to briefly talk about how to learn the
fist representation from the
classification and multiple
reconstruction task and given the high
performance network I'm going to present
some empirical study on the properties
of the neural responses and the making
use of such properties will show that we
can make the reduce the size of the
networkers a substance substantially we
are keeping the recognition performance
it also have some other interesting
applications so currently at the most a
comedy way is to learn the visuals and
he changes through this identification
task basically give an input tryn you
image go through the commnet it will
classify as one of the large number of
recent entity class and so the in the
top layer the neurons in the top layer
the other feature presentation we want
to
so the capture to reach interpersonal of
his variations because they need to
classify a large number of theses and
the discriminative also can be well
generalized to new identity outside
training data so also on top of it we
also added a verification signal so it'd
be busy if you you have two images from
the same person will require that they
are learned a feature representation to
be similar so this verification and
identification signal they are trendy I
to the multiple layers to learn the
feature representation we can also learn
the future Fitz representations through
reconstructing multi-view representation
we know that in Fitz recognition the
view where region is a major factor
affecting the performance so we in this
network give an input image in the
arbitrary view we want to reconstruct
all the viewpoints of the same person
and here I'll show you the examples
these are new construction result and
the visio to the conscious and the trini
intensity that they have no overlap on
the other identity so in the network we
are the identity and view representation
they are represented by different sets
of neurons so you can separate identity
features and the viewpoint features also
the viewpoint has a continuous
representation so this is our network
structures x and y they are input and
output face images input different
viewpoints and this is H hid they are
the neurons encoding the identity
information of other input image x it
has removed the viewpoint information
from eggs they are the deterministic
neurons and that is H hv they are the
new random numerous encoding the pupil
and information of the output image the
sample from uniform priors and this HR
these are neurons encoding the features
of the output image why so either
combined posts the identity information
and the blue any information actually
these you can see this network is a
combination of deterministic neurons
also randomly
us and the lisa hv at Lisa V 2 these are
the identity features that they are
useful for this fits recognition and
this viewpoint label can be inferred
from auto put the image as well as from
these random neurons encoding these
viewpoints so when you can use em to
update the probabilistic model on the
network it creates bound to the forward
and the backward of propagations so at
the East AB we infer the values of the
random neurons which includes the
viewpoint information and I'm slab we
use to update the parameters of the
network and because we have a continuous
view representation and you can we can
interpolate and predict the images under
than viewpoint observe in the training
data and units example our chinny data
only have 0 degree 30 degree and the 460
degrees in a we want to reconstruct the
image fits image under 15 degree and the
45 degree the new viewpoints and a
desert reconstruction result and this as
a ground crews and in P will improve the
image are under the 15 degree and the 45
degree we want to reconstruct the front
of you and you can see that even we
observe some new wheel points because we
can interpolate the images they can be
reconstructed well so actually this idea
can be also generalized to other factors
besides besides viewpoints and such as
ages expressions Lighting's et cetera
actually you can also jointly consider
multiple factors here I give you example
given an arbitrary fits image as input
we can reconstruct different combination
of the poses and the inspirations and
the in this example we constructed the
fits image and the different
combinations or Lighting's and
expressions and given threesome are high
performance in your network and some
people think leaves the tip learning
view you simply use a large name
parameters of filter data so we are
interesting studies of properties of the
response of the neurons and actually
these properties are naturally owned up
to large skill training with we don't
either stupid Xperia T added some drag
racing organization to the to the model
here give it a input image and we look
at the neural response in a top hidden
layer and then you can see that some
neuro are responded and some have no
response it's not surprising we have
Lisa sparse representation because we
use rectified linear units as activation
function if you if you added some
illusion and change the viewpoint of the
same process we observed that this is a
magnet here that could be valid can
change it to some extent but the
activation pattern could be a is a
relatively seemed stable and it will
change the identity of the person we
found out the activation pattern a 01
patent you're going to be changed
substantially so Lisa inspire us we just
use as a binary code from this ad with
activation pattern for face recognition
and as a result is a pretty promising
with Duke even you use this binary code
which you can get very high reckon your
face recognition performance on over
ninety-nine percent so this implies that
the active activation pattern maybe even
more important than that than this
magnitude also it has the important it's
important for applications because if
you use Lisa been a pattern for
recognition are going to save a lot of
storage and also the computation time so
if you look at the input that has image
and we observe that about a half of
these neurons are responded and the
other has a 54 have no response so if we
want to you want to compare the Hamming
distance of the activation pattern from
to face images and the little moderated
sparsity response i can give you the
maximum distance between these two
images on the contrary if you have the
three
the representation which is which is a
highly sparse most of the neurons has
zero response and then their distance
will be small you can't waste a lot of a
piece and if you look at a particular
neuron we observe that on the test the
image and about a half of the image you
have responses and the other half have
no response so it means that it can
maximize as a discriminative power mass
measure at the entropy of this new role
on describing this it has the images
said but if we look at a particular
person for example in the air OFW George
Bush has 500 images and you can find
some neurons which always always respond
to George Bush right and you have some
other new neurons which also has zero
response to push so our training data
and the era of W have no overlap on the
identity of the persons and the similar
thing also happened to the attributes
you can you can find some new room the
obvious response to the female male
faces have no respond to female faces so
we found out the listener or they have a
strong selectiveness other identities
and also the attributes and here we show
you some example listen this neuron
always have the response to push analyst
neuron of your hand no response and
we'll show you more examples on more
people more people and it's also
happened to the identity and these
neurons always responds to malfeasance
or it's a no respond to a female VC
there on the country and these are the
reefs related attributes for example
listener always respond to our vital
people had no respond to other
attributes relate to the race so this
means that if you want to classify a
single person from others or recognize a
single attributes you probably can find
a particular neuron which can have
hi recognition accuracy even with a
single euro for recognition and on the
contrary if you compare with high
dimensional PP you'll find the paths of
single feature from our PP for
recognition the dragon Asian reader is
all the only 19 is only sixty or seventy
percent of quite low now we can also
look at the all the new neural responses
here I saw the little neurons according
their average response according to to
the particular person from large to
small and then we can keep the other and
look at their average response for all
the other images and we can see that
it's a kind of a pretty uniform
distribution on the other remaining
images and if you look at their
recognition accuracy and single with a
single neuron and then we find out of
course of these neurons they have a good
recognition capability ambush because
they always respond to bush and the
least this neuron they also how good is
a recognition accuracy because they
always had no response to bush and in
the middle we'll find some unity to have
a lot of uncertainties right so by the
in comparison and for high-dimensional
BP if some feature have a high response
to a particular push a particular person
he also has a higher expand to other
images they are not good for recognition
and here we also computer Eliza's noon
or so for each mural we divided the
images into three groups high middle and
low response and calculate the average e
image in each group and then we can see
that each neuron help clear the semantic
meaning for disabilities one represent
the gender age etc so because of such a
mix of share properties we can actually
simplify the Spotify the network
structure as I mentioned that it because
they have selective
these are attributes if you want to
recognize a particular attributes you
only need a very small and boring
neurons and we can remove a lot of four
edges and this is also happen to we can
explore the correlation between the
neurons and different layers right so if
you want to predict a neuron at a higher
layer you only need to very few number
of neurons from the lower layer and so
you can remove many these kind of
connections and so we propose to
alternatively optimizes learning ways
and also the structures okay you're
treating you to a dance network and the
Spotify the first layer and reach in the
network and then specified as a second
layer and it and so on okay yeah I just
running out of the time I just to give
you the final result and the least why
is that you establish the dense dense or
network and the lease is a submersible
network it only takes 10 than aids of
the amount of parameters that even wake
up even higher recognition performance
I'm going to skip all the remaining
parts so in summary I'm introduce how to
learn surf is a representation and also
talk about that they are some empirical
study are the properties and also make
use of such a properties we can make the
network is smaller okay thank you
so yeah we have some time for questions
so if you have any questions can you
come forward in front the mic
have you tried this on larger data sets
where the pruning might not might hurt
because you're less under fitting the
you a lot of wii u need the property of
the neurons or the horses the pruning is
probably helpful because you're working
in a small data set right we do or don't
have a special which is a regular to
putting up putting layers on the pruning
so removing edges oh ok oh yeah not
about the producer so far is a cheating
cheating data we do we have war 4,500
results and the changing images it's a
Trinity it's a pretty large yeah so do
you have any idea how to so what are the
limitations of the current CNN that
you're using and how what do you think
is going to be the frontier and in the
next you know 23 years what do you think
you're going to work on and to improve
okay yeah I'm quite interesting how to
make the network is smaller so it is you
know that it's a particular office
recognition we have a very good addition
performance but if you want to apply
this to some mobile phone camera through
the front end and then we you want to
make any deal make it smaller and also
we find this kind of trying to learning
the ways and also the structures it's a
cool to be quite a faculty and so that's
a one of them so so in some of the early
deep ide work you guys were using key
points keep comment on the importance of
key points and are they required not
required what is your most recent work
stations are the commands the future so
we use in the face recognition with you
because we use multiple models so
basically we crop multiple regions is
for you to return the cattle feature and
then
to the production to the average and we
will usually need to crop multiple
regions that then we rely on the keep
one's kind of handle is a missile
misalignment but if you we use only use
a single say single model single region
for the face recognition we only have
two very simple geometric normalization
without 3k use coupons hi I'm this is
really good work can I ask about a
little bit about pruning since we also
experimented with ZN r STM and i'm
curious on face recognition tasks how
many percent of the parameters can be
pruned and what is the heritage a more
more than eighty percent and still
getting a higher performance and what is
the heuristic you use for pruning so
this we you start a tree original
Network and you caught the ways and you
know the correlation between different
neurons and then you'd remove some
connections which has a weaker connect
weaker correlation the first layer and
then you'll reach in a network and then
you specify the second layer and so are
so duly iteratively so we are specifying
sponsor fine the first layer the rest of
players are fixed to be perfectly right
we fix it and then we reach in the
netherworld in the second day so in the
first part of the talk you had done
stochastic latent variables representing
pose and and viewpoint or whatever and
in a user nghiem procedure and then you
went on to just have a fully
deterministic feed-forward network as
usual and train it with STD when that
second approach seemed to discover
layton attributes could also discover
latent viewpoints in which case do you
need the hidden variable method what are
the pros and cons are those so you're so
wonderful i we we do have this kind of a
random neurons because we need to
represent this viewpoint you information
you continue
sway so we family we have this a
property model are they such a onyx
glenum yours but I'm sorry what's a
second question well so the second part
of the talk you're discovering Layton
attributes like gender and so on right
say jen is about example let's say race
which you could think of as a continuum
viewpoint is also a continuum does it
discover the viewing angle of the face
organically even though it wasn't
labeled know you did so it's actually
the second part you've scoured the
properties we are based on this we
didn't to use we did we only have the
determination you're honest with you I
don't have is it was not the bass sound
it's another way of Israel feature
reconstruction yeah okay so we have one
more yeah last question oh you have any
thoughts on using this for anomaly
detection like for example if you want
to detect a mole on a face be didn't
have any or you had a very small amount
of mole training data or even so sorry
can you repeat okay oh yeah sorry um
have you do you have any thoughts about
using this for anomaly detection for
example detecting moles on the face uh I
haven't thought about it right no I
guess this kind of example where
everywhere in the in the training data
and I think that for the car the
representation probably is going to be
hard is it because they learn from the
normal normal feces and what he was
saying kind of some normal regions in
right thank you okay thank you les
thanks how far we get okay
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>