<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>VINTA: Combining Model Checking and Abstract Interpretation | Coder Coacher - Coaching Coders</title><meta content="VINTA: Combining Model Checking and Abstract Interpretation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>VINTA: Combining Model Checking and Abstract Interpretation</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/a0TPMvXm9rA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
it gives me a great pleasure to
introduce our Igor Finkel was visiting
from the software engineering Institute
by CMU and um he's here all week until
at least Thursday afternoon maybe even
friday morning so after the talk or
doing the talk asking questions and
after the talk he sits what was it 31 23
or 43 and you can grab the airy and ask
him even more questions and okay go
ahead okay thank you they collect so
i'll talk about vinta which is a joint
work with how's the albergue earthy and
Marsha chechik and then some of the work
i'll talk about is also joint work with
sagar Jackie who works with me as a CI
and Ely who is also interim to his
Mercia okay um I have to show this so
anything I say there's no warranty on it
okay so my work is in automated software
analysis and I'm not going to spend any
time motivating why this is important so
I'm assuming you already motivated
enough so I'll just going to get
directly to a point so when I work on is
this box called automated analysis and
from my perspective the view of the
world is very simple you have a program
and maybe some notion of correctness
maybe inside the program maybe as a
separate property and you have to come
up with one of two answers either
correct maybe proof of correctness or
incorrect and maybe counterexample and
from my perspective there's sort of two
ways to solve this problem too big
approaches and one is called software
model checking it's been a pioneer by a
professor at Clark my mother's and
abstract interpretation was pioneered by
Chris Ault so last year I was here I was
talking about UFO which was sort of a
model checking driven view
of the program verification and today
i'll talk about winter which is more or
less the same story but now from the
abstract interpretation perspective so
the motivation that we had a assertive
on one hand abstract interpretation is
the most Kayla will approach the program
analysis that's the one that scales to
programs with millions of lines of code
but in practice there is a price for
that it's very scalable because it's in
precise and because it's in precise it
has lots of false positives and two
other problems with it it gives you a no
counter example signal refinement so if
it claims that there is a bug there is
no actual execution you can look at and
sell yeah I see what's going on and
there is no refinement if you have a
false positive you have a false positive
that's it so that sort of the motivation
we we wanted to do we want it to go and
reach it to sort of a model checking
view of the world where you have a
structure refinement and try and add it
to an obstruction interpretive cobster
control so what I'm going to do in the
rest of the talk is I'll talk about
numeric abstract interpretation I
anybody here doesn't know what numeric
abstract interpretation is great I guess
I'll go slowly over that part so i'll
just give you my view of what it looks
like and i'll talk about vinta so what
did we do it's different how it changes
this picture I'll talk about how its
implemented and then third of the
biggest claim of fame event is that it
did really well at the recent software
verification competition so instead of
showing you how we did on some benchmark
that we've tried it I'll talk about what
it did in the competition and how how
much responsible it was for the
performance of the tool well first time
I'll talk a little bit about the secret
sauce so all of the things that went on
top of the basic algorithm in order to
make it competitive and then finish with
some of the future some of the current
work is empty I'll try and make it
informal please feel free and ask
questions so interrupt in the middle as
I go
so numeric abstract interpretation so so
so what what is it the basic idea is
that you restrict the set of facts that
you're going to use when analyzing a
program to something called an abstract
domain and you do all your reasoning
inside the side effect so the thing to
note here is that the abstract domain is
a possible infinite set of Fred Achatz
so you have to deal somehow with that
but the predicate come from a fixed
theory so you know a priori all the
shapes of the predicate and you have
some efficient way to do the abstract
operations so here are some examples of
numeric abstract domain so the first one
is sort of the simplest one is assigned
domain where for each variable you going
to keep track of whether it's positive
negative or zero so it's only its fact
that you can express it in one of those
things the next one is a box an interval
domain where the only fact that you
allowed to say about each variable what
is it upper and lower mount then you can
go down and have something like octagons
where you have where you can express for
any two variables whether they equal not
equal how far apart there and then for
the most expressive numeric domains
polyhedra which allows you to use any
linear inequalities so that's the first
part that's the domain so let's see how
it works so this is going to be a small
program and we're going to run an
abstract interpreter on it so we're
going to do an interval a box domain
here so first we'll go into loop and
we'll ask well what do we know at this
point in our abstract domain and we know
that y 1 is between three and four well
then go through this statements and
they'll say well what do we know after
executing those statements and we know
that x 1 is between 1 and 2 x 2 is
between five and six and y1 is still
between three and four well then can go
into another branch of this if statement
and again ask what do we know here we
know that y 2 is between three and four
it just comes from this if condition
apply this operations and we know that x
1 is between 1 and 2 x 2 is between five
and six now we have to do
I joined at this point so we have to say
when we come to this point what do we
know what what is the set of fact that
we know and we can only express them as
a conjunction of upper and lower belt so
what we know is that x1 is between one
and two because that's the same thing
here and x2 is between five and six and
we don't know anything about why one and
we don't know anything about white you
because in one branch of the conditional
what we know that y 1 is bounded but
another branch we know nothing about it
and the opposite is true about y 2 so
when we come to a joint point we just
forget why one that's it and so in this
point we check whether this implies our
assertion it does and we done okay so
pretty straightforward now let's do
another example so what happens this was
the first example is really simple there
are no loops which is propagated things
and we done so now we'll have a loop so
we're going to do the same thing
initially we now that x is 0 as we go
into loop x is 0 and also less than a
thousand eggs of increment now x is 1 we
come back to the loop we have to join so
we knew that equus 0 the second time
become X is 1 we can express it as this
interval constraint X is between 0 and 1
and we can continue and do this again
and again and again and so what's the
problem here but a problem it may take
quite a long time or even forever to
just go and sort of execute the program
like this and so at this point what the
abstract interpretation typically does
is pull the rabbit out of a head it's
called whitening so somehow let's guess
where this is going so here for example
we saw that X was increasing and we
decided to guess that it's going to
increase forever and then we know that
we only enter a loop when X is bounded
by thousand so let's use that as an
other out problem and we go through
another execution of obstacles of
rotation now carrying this constraint so
we now enter a loop access to the less
than a thousand when increment by 1 it's
at most a thousand and now we know that
we've conversed there's no new states
being generated
so we found an inductive invariant we
come to our assertion and it satisfied
then we good so if we want to look at an
abstract interpretation sorta from
operational perspective and its really
gives us this interface we have a notion
of an abstract domain it knows about the
set of variables that we keep track of
as a set of abstract elements which is
how we represent our abstract values
their expressions which we use to
represent program states and statements
and the functions that we have from an
abstract domain is we have an
obstruction function to go from
expressions to elements of abstract
domain we have a conclude ization
function so that we can say what the
result is how to understand an abstract
value we have an order so that we know
what does it mean that we've converged
no more new states so what abstract set
is subset of another abstract set and we
have an abstract post an abstract
transformer there's a function that
takes a can treat statement like X gets
X plus 1 and changes it into a statement
that operates an abstract values it
takes an upper and lower bounds and
tells you how plus 1 transforms an upper
and lower ball and then we have the meat
which is intersection join which is
union and widen which is a rabbit to go
with it so here is an example of how an
abstract domain looks like in the case
of a box abstract domain so our
expressions all statements of the form X
with an upper and lower bound our
abstraction gives us an abstract element
which will be just a tuple representing
the lower and upper bound of the value
our country dies asian takes us back the
operations are very straightforward if
we want to take an intersection of two
intervals then we just take the marks of
their lower bounds and the mean of the
upper bounds if we want to take a union
of two intervals and we take the min of
their mins and Max of their Max's and if
we want to do an abstract transformer in
most cases suggest you apply the
operation to the lower and a fair amount
and that's it now that here we have some
right so when we do a joint if for
example we have an interval 13 and an
interval 712 a join of them is the
interval 12 12 the sum over
approximation we added more things which
were not actually part of the interview
and this is where they sort of
scalability of the abstract
interpretation is because we restrict
ourselves to very simple elements
abstract domain we can manipulate them
very efficiently but we paid the price
we can't express everything we want to
express so let's see how this influences
the results so we're going to run again
abstract interpreter in this program and
it's going to fail some so it first
assumes that is either one or two we can
represent that as is between one and two
we're going to first branch of it if we
know I is one at this point X gets I so
x1 is one at this point the other branch
is 2 X 2 is minus 4 cut that and now we
have to do a joint and as we do join we
now get will lose some of our precision
because we know on one branch of on this
branch of the if statement we had
something about x1 on this branch even
if you had something about x2 when we
join we know nothing about x1 or x2
because we don't know which way we got
to the joint point and so will only
learn that is between one and two
because that's a lie was one here and
two here and now as we go into our
second if we get y is 1 and y is 2 so
both of the things reachable but we
don't know anything about x1 or x2 so
we're going to create a false positive
if we're going to say that this
assertions as far as we know abstractly
we cannot prove the day unreachable but
if you go through the program they
aren't so that's a false positive so
that's the situation that we want to fix
so when um that solution that we're
proposing something which we called
vinta which wraps an abstract
interpretation into an obstruction
refinement sick so the high level is
really a very simple idea you start with
a program and you run an abstract
interpreter well what an abstract
interpreter will do it will compute to
some inductive in your head you check
whether this inductive invariant happens
to be safe if it is you done the
upstroke interpreter proven that your
program is correct and you don't on the
other hand if the invariant is not safe
then you know that the abstract
interpreter looked at part of your
program and found some counter example
so you switch to the refinement face and
you check all of the execution that the
abstract interpreter has looked at and
check whether they have a concrete
counter example if they do then you
terminate and you say the program is
unsafe and you have a counter example
other ways use interpolation to figure
out what the facts have the abstract
interpreter forgotten that a part of the
bounded program that it had looked at
that makes it safe and then you use
these facts to strengthen the state of
the abstract interpreter so you have an
inductive invariant here that's not safe
you come here you check it then you find
out that the reason i'll counter example
and you come back and now you have
something which is safe and error state
is unreachable but no longer inductive
and then you restart an abstract
interpreter from that point to compute
the nest in the next fixed point to add
more reachable States until the sad
becomes inductively and then when it's
reductive you check with it safe you dot
if it's not safe you go back and you
possibly strengthen it again and you
keep iterating back in the first now
there are several novel things we had to
do in order to get this actually work
and so when I'm listening here sir to
what's novel from the abstract
interpretation perspective and let's
novel from the refinement perspective so
from the abstract interpretation
perspective one novel element is that we
scat porn graphs instead of control flow
graphs and what that means that we
compute an abstract value for every loop
head as a positive for every basic block
of the poster every statement it also
means that when we say that the program
makes a step it's a very large step it's
basically some kind of loop free program
fragment as opposed to a single thing
like X gets X plus 1 which makes our
abstract interpretation step a little
bit more complicated but it can also be
a lot more precise because it can be
exact on this intermediate steps now the
second thing that we do is that instead
of just computing what's reachable at
any program location we compute an
unfolding of a control flow graph so if
we come to loop multiple times we keep
multiple copies of it as sort of an
unrolling of a control flow graph that
the abstract interpreter had looked and
then has to side effects one is that you
know everything that abstract
interpreter has explored this unfolding
at the end is sort of the bounded
program that the abstract interpreter is
basing its resultant and that's what
will be used in refinement and second it
means that we always compute this junk
to vineyards so as I showed you before
we can the box domain for example it
will compute an upper and lower bound
for every variable at every location but
because when fold the control flow graph
and because the location that say is
part of a loop will appear multiple
times in the growth we automatically
compute a disjunctive engineering
because the invariant for that location
will be the union of the labels at all
locations corresponding to it yes is
this the number of iteration that
was used for that distant so what I'll
show you an annex like how it looks like
so this is sort of a side effect of
keeping and unfolding because we keep a
whole unfolding you get all that you
could get all of this information from
it'sit's um we don't need to keep as a
separate number say and what the
duration was this label computed it's
simply an annotation of an unfolding
graph and then in this graph you know
each you know giving each loop you know
say how many how far it is from the
initial state but one of the side
effects of this assertive what we do
given any abstract domain and here we
lift it into these junctions we lift it
into a power set domain and so we had to
fiddle and get the widening to work
correctly and so this is so we ended up
third of creating and at different
widening than than any of the existing
ones that's tightly coupled with the
exploration strategy
well what makes it converge
what makes it convert so disjunction you
trade dis jumps for condoms homes
yes so
I on their slides but it's a little bit
trickier but I I don't think we put a
bound on number of the jumped but at the
same time we can prove that there is
some progress following that what's
going to happen is that you have
multiple disjunct but you're going to
widen it whenever you add in want to add
a new element to this side of different
you're going to widen it with that one
of the existing element
and then what you have to show is that
you get this a set of dishing screwy but
at the same time there's always a path
where at least one of the district is
being constantly white and therefore
that the whole chain can never go for
gives me
widening is the convergence but whenever
we do powerset widening you always have
to be careful because you may end up
that the number of diction grows also
each chain for each digit is fine and
then you would still not converge in
some sense you rely on the refinement to
give to make it some Terminator time
well the abstract interpretation is
determinate so and then the refinement
will push back on
but you can hang out
okay so let me wave my hands and say it
that's convert but but I don't have I
actually don't have slides on widening I
haven't didn't think that would be that
interesting you but if you want to ask
me later hey can you explain how it
works and then from the refinement
perspective what we do that's
interesting is we use an smt solver to
check for whether counter-examples is
visible which is fairly novel in case of
abstract interpretation and then we use
this concept of Doug interpolation for
refinement which I'll go more about and
what makes what's interesting in this
particular work is that this
interpolation procedure sort of guided
by abstract interpretation they play
together in order to figure out how to
refine and overall effect is quite
interesting on one hand abstract
interpretation is all about throwing
away constraints in order to get
convergence and then the refinement
parts ends up adding constraints that
were thrown that actually necessary to
prove that certain counter examples i
invisible so let me just illustrate how
this works on an example so I'm going to
take this program and I'm going to take
it through different steps and show how
they work so a few things to know when
we explore the program we use weak
topological order which means we always
go for inner loops and wait until they
converge until we go out we're going to
use an abstract domain of intervals in
here and look around that the side
effect of our abstract analysis will be
labeled unfolding so we start up strict
interpretation the usual way one means
this control node one initial it's
labeled with true everything is
reachable initially we make one step we
figure out that X is 10 we make another
step we figure out the X is less than or
equal than 10 so we did a little bit of
widening here and we went from eight to
ten then we go one more Sergey loop if X
was less than ten we subtract two it
remains less than 10 so we got to
converge right we don't get any more
reachable states we're done with this
loop we now look what's reachable
other than the loop so we'll get the
three edges two locations three and
right now we can prove that when you get
here x is less than equal than 10
therefore this if condition is possible
you go in X is 9 and you hit in there ok
so now we're going to raise the alarm so
this is end of abstract interpretation
phase so we're on abstract
interpretation face as usual but look
what we get as a side effect is this
enrolling right so instead of for
example maintaining that access less
than 10 for location too we have this
full unfolding and we know that our
invariant now at location 2 is the
disjunction of those labels ok does that
answer your question the first verse
again
so that's that's how it's going so now
when we have an alarm you want to check
whether this alarm is curious enough and
basically what we're checking is whether
in this bounded program this location is
ritual and to do that we switch to an
smt this generating verification
condition for this boundless problem and
checking it using smt so we start with
unfolding we forget about abstract
interpretation labels and we start
generating a verification condition for
each edge here we'll just assign what
the action of the edges and then we
build a control flow encoding or for
each node in the control flow graph
relatable and variable and basically
specify that if you happen to be in one
location than in order to get to another
location the edge condition has to be
true than the same for every for each
individual name so this encoding is
really straightforward in a scent that
it's linear in the size of this
unfolding so it's very easy to generate
and then we give it to an smt solver to
check if there is a counter exam is to
unser cider there is a counter example
and then the abstract interpretation
phase gave us a good alarm you can
produce this counter example all the
result is no there is no counter example
and we need to do some kind of
refinement so to do refinement we're
using Craig interpolation and I know it
people here familiar with Craig
interpolation and see somebody smile
Lincoln so I craig interpolation is an
ulterior that says something really
simple it says roughly if you have a
that implies B then they exist an eye in
the middle sides that a implies I and I
implies B and I is in the language which
is common to a and B and here I'm
stating it sort of in a slightly
different way where I'm saying while a
implies not be just because that's a
more convenient way for software mole
chicken application so crack theorem has
been around for a long time and we also
know that it's quite aberrational it's
quite
easy to construct the friggin turbulent
given say Assad proof minus m2 proof
given a resolution group and model
checking it's used to over approximate
the side of reachable state but let's
see how we want to use it here for
refinement so this statement is not
quite good enough for us because it
talks only about two parts we have some
traffic's and some suffix and we can
compute what's reachable by a prefix
before a suffix but in our case we don't
have a simple two parts a and B and we
don't even have a pass we have a
director cyclic graph the drug presents
are unfolding and so the problem that we
want to solve is something that we
called a dog interpolation problem and
roughly speaking it says something like
this it says given a graph a dog where
each edge of a graph is annotated by a
formula so formula spy in here sides it
on any pass a conjunction of the pie
formulas is unsatisfiable what we're
looking for is the set of this orange
labels I such that each label is an
interpolant between every prefix and
every suffix and every label that
together with any edge implies the next
leap so here's an example so for example
I to has to be an interpol and between
PI 1 and PI 8 because of this but also
has to be an interp one between Phi 1
and Phi 2 pi 3 by 6 and pie 7 and the
second condition is that for example I 2
and PI 2 has to imply I three and I 2
and PI a has to imply I sub and so so if
you think about this conditions
carefully and you'll see really what
we're looking for a sort of a whore
style proof of correctness of this
program we're looking for intermediate
States I 12 I n sides that the initial
state is true the final state is false
and any state together with any
statement implies the next
now the question is how do we compute
such a thing and then multiple ways to
do so so one way is to just cast this as
sort of a horn problem where you treat
each individual eyes as an unknown
predicate and you just pause these
restrictions that you want as a horn
satisfiability problem but another way
is to turn it into an interpolation
problem into a linear interpolation
problem that you encode this whole
program just as a normal verification
condition give it to SAT solver get a
result and then mine the result is proof
for the labels this is a your
information that is three days
write the linear interpolation writers
predict so the winner interpolation
method is in 1957
what I mean they are the tools that you
use
grateful the jilted we're using predate
the horn formulation at least in sm t
work so the way we actually solve this
problem is sort of in this very simple
way we translate this whole problem into
a sequential interpolation problem
that's already supported by existing
tools and the idea is clear is quite
simple at first we take this graph and
we build the verification condition and
we realize that the verification
condition has this form where you have
assertions four different locations in
the control flow graph and you can order
those assertions in the topological
order so you have a linear sequence that
each element further in the sequence
means you deeper inside the graph okay
when n can compute a sequence
interpolant for each for the cut between
each and a location and the following
locations so sort of cutting the graph
in different places and then this will
give us almost a result that we want
except if you follow the definition of
interpolation you may have variables
which are out of scope at a given
location if you have two nodes of a
graph which are siblings to one another
then variables that are only available
for one sibling may appear in an
interpol and fold out okay and that's a
problem for us because at the end of the
day you want to get something that's
maybe inductive and so you don't want to
have any free variables in anyhow just
got variables the new expression
otherwise I'll have to be quantified out
and you have to deal respond to fit form
and so we're goes through this cleaning
process to somehow get rid of them so
that's the price we pay for using a
sequential interpolation method so we
get an easy encoding into it but the
output is not quite what we want then we
have to spend some time home from the
spinning things and actually we've spent
quite a while playing with various
versions of this original one used 20
for elimination during cleaning when old
heuristics failed I have a new encoding
that now can do clean completely using
projection and no point for elimination
at all and I'm looking at various other
ways using for example the horn
procedure that
that three has boss has to solve this
whole problem as once and also to just
break it to solve just the cleaning part
of that problem so that's that so let's
see let's go back to a running example
and see where we are so what Doug
interpolation will give us is we have
this graph we know that the result is
unsatisfiable so when we crank the Doug
interpolation handle we're going to get
this I 12 I I three in this case where I
one will be true because everything is
reachable here and I three will be false
because in this particular example error
is unreachable and this is true for
every edge so now we could have taken
this I labels and use them to strengthen
the result of abstract interpretation
like we can go and to have the abstract
label and add those labels to it and say
that's also true and that prevents an
error from heaven okay but there's one
catch here sort of by the time we got to
this point we already forgot anything
that upstroke interpreter has computed
and so we end up redoing a lot of the
work that it has done and we found this
approach to be really inefficient when
you get larger and larger unfoldings
generated by the abstract interpreter so
what we really want to know is we want
to see well the abstract interpret
already found some bound on the
reachable States what you really want to
know is what else we have to add to that
bound in order for the program to be
safe okay so we only want to know how to
sort of help the abstract interpreter as
opposed to redo it show and a solution
is quite simple we simply say well then
what it means it what we want is sort of
a restricted dug in turbulent we want to
take our program take the result of
abstract interpretation and just say
well let the program assume them so at
every program step we can just add an
assertion and say well if an abstract
interpreter said X has this mount just
assume that X always has this bulb at
this particular point that's not going
to change our program because we know
that the abstract interpreter computed
the set of
delvar approximation but it will change
what a solver has to discover because
those facts already there they're ready
available and they can be used and then
the solution to this problem the
solution to the interpolation problem
will be well what other facts do I need
to add in order for this problem to be
unsatisfiable this skeptic takes these
ice
and conditions them to the head of
entities we use because these eyes may
not be described in the same form that
down
do be enough here he is yes so is there
a skeptic conditions command
we do
as you know so it's musician so this is
actually some of the things that we're
looking at right now I have a couple of
slides then to address this question so
yes you're absolutely request is that
this labels may be an arbitrary form
arbitrary empty formulas whereas for an
abstract domain we need something like
say am a conjunction of linear
inequality is a convex hull of some sort
so how do you go from one to another and
the answer in practice how do we go
between one and other we just have a
very simple heuristic to get something
in an abstract domain that over
approximates each label but really
solving this problem for real is quite
difficult and working a little bit on
question on the side is that and when
you can join the ai's to the edges like
doesn't correspond to just run Johnny
applications
I'm wondering why you did not just adds
a I listen conjunction to hear ya next
to t IJ of charts exactly except you
thinking about it in terms of a horn
presentation so you're thinking I sound
interpreted predicates and this is given
to whereas I'm saying this is what given
to me and I produce ice which is the
solutions to my horn problem and it
satisfies this predicate but it
satisfies yes it's not as much oh yeah
but this is where the problem statement
is this is a statement about the result
whereas in horn formulation you stayed
that you want the result it satisfies us
and the solvent gives you tea rose yes
but the point is that the doubt put that
you get now you don't get a dog
interpolant you don't get something
that's good enough on its own but
something that's good enough together
with the obstacle to predation Lee okay
so if we go back to our running example
and we would have run this whole process
here this is what we get we have the
blue label's which is what the abstract
interpreter has computed and we have
this orange label so what them that the
non blue labels which is what we've
computed by by the interpolation and so
what you have to note here is that for
example this label happens to be true
which basically says the abstract
interpret already knows enough about
this particular location because it
knows that X is 10 I don't need to write
anymore and here i want to add that x is
not just less than 10 but it's also ate
and here i want to add that x is not
just less than 10 but it's also 6 and so
now once we've strengthened the results
so we still have sort of a reasonable
abstract interpretation state and in
this case all of the constraints happen
to be inside abstract domain but one
thing is broken and the one thing that's
broken is that this result is now safe
but is no longer inductive so we know
that because we know that this edge is
no longer true this relationship that
the side of reachable states here is a
subset of the reachable States here is
no longer true x is 6 is not a subset of
x is eat and so we can restart abstract
interpretation right from this point so
this is where we need this ability to
take this label convert it back to an
abstract domain and then we can run
abstract interpreter again here it will
find out that while if access was equal
to 6 and we run one step it's less than
6 we converge we come here it's less
than 6 and X is never 9 that's it
okay so just to give you a high-level
overview of what's happening here is we
run an abstract interpretation but at
the same time we keep our unfolding we
keep the bounded program that the
abstract interpreter has given us and we
gather blue label's if an error is
reachable we go to a refinement chase
which basically asks give me a fine that
gives me a whore style proof why you
think this bounded program is safe
that's our orange labels we then mix
orange labels with the blue labels which
now proves that this bounded part is
safe so we have something that's safe
but there's no longer inductive and if
it's not inductive it means that there
are some loops which are not covered
some loops where we don't haven't
explored all the reachable states we
find out the sloops and we restart the
abstract interpretation from less from
this point
that's it
so this is implemented in the tool which
we call UFO it's available here we
source so feel free to look through it
run it try it and contact me if you have
any sort of questions or need help but
this is that the architecture of the
tool we have this big front end which
I'll talk more about that basically goes
from C into an intermediate
representation via llm and then the part
of the to liz's art constructors it
builds this scruff which we call an
abstract reachability graph and you can
control it by giving an expansion
strategy how you want to expand the
graph and what abstract domain you want
to use and how exactly we want to refine
so what sort of there's lots of choices
on how to apply that interpolation it
uses two SMT solvers it uses these three
for almost four everything and do this
math SAT for interpolation okay so there
any questions so far
all of your examples were typesafe very
simple I was expecting to hear that
knows only works on typesafe languages
but you said see how do you deal with
type unsafe
I I pretend to not know about
ok so we deal okay so this is this has
to go about the software ification
competition so all examples I shown you
were small just to fit on the slide
button claiming this works because of
the software ification competition not
because of the smaller company and now
one of the so let me tell you a little
bit about the competition and answer
that that I mean that's a very serious
question and I don't have any any good
answers so the software ification
competition
okay so let me a software ification
competition started in 2012 and so this
year was the second year it's held as
part of it ups and collocated with
targets conference and it herbs its goal
is to provide the snapshot of state of
the art and software verification tools
I had quite a few participants and quite
a few benchmarks so one of the issues
with it with any competition like this
so the decision was made to use see as
the language so that the tools actually
support some realistic language not not
not a toy not an intermediate language
but the problem is that we don't have
formal semantics of see I mean even
before type safety you even just
settling on the formal semantics of the
language is impossible and here then a
decision was made that we'll just use
the semantics which are reasonable for
the benchmarks to which all of the
participants agree and the way it works
is that there's a large collection of
programs everybody around 32 they get
different the benchmarks are marked
whether they should have an arrow don't
have an error everybody runs our tool
decides on the results and if people
happen to disagree there's a discussion
and we decide whether the benchmark is
kept removed or what to do with this
particular case so in that sense there
is a down three sort of very pragmatic
and driven by the benchmarks as opposed
to trying to answer more general
question the way
so you could but that's so the way we
actually do we live inside llvm but let
llvm get to an intermediate
representation at which point we only
work at the level of numeric registers
that llvm provides so love am compiles
the program down to infinitely many
numeric registers and memory betrayed
memory is completely non deterministic
and numeric register such that would we
that's what we analyze so it can give
you a formal semantics of what we verify
with respect to that but tying it back
to see is quite difficult and we not
handle pointer zero but that's it's not
to say that this program don't have
pointers that we don't handle programs
with pointers it is to say that pointers
a lot of the pointers are removed at the
pre-processing level when the program is
compiled down to register by a lot of
them and by our process if you can prove
that a certain location is not LS then
it will be compiled down to register and
then all the points references feel
better
so this program so the benchmarks
consists of a large collection of three
programs ranging from sort of things
that people traditionally used for their
tools to a big set of linux device
drivers so they know what type programs
they don't use you know toy part of a
language they do whatever they want but
most of the properties that we want to
prove are the kinds that don't really
depend on deep point2 reasoning or type
safety or things like that you still
have some kind of keep the name for the
extra communication right
so
are you said sound and since this sound
because I assume that heap is completely
non deterministic so if you write
something to hip and then read something
from hip you get a non-deterministic
phone so that sound it just may be not
precise for anything interesting that
you want to say put something in a heap
I build the linked list and then I want
to navigate through it and the tool will
just tell you you end up in an arbitrary
place okay so you are ready to get
places which might not be late
but the reason why this works is that
the front end takes care of lowering a
lot of the pointer reasoning any sort of
shallow pointing pointer reasoning gets
lowered into registers by the front end
what is so there are multitudes of
similar tickets define the predicates
based on counter examples lazily so a
high-level what is the advantage they're
adding abstract interpretation to this
is giving its more precise amount
convergys custom goes by being in
headings when's when's competition twins
repetition let's Nikolai something you
blast so this duel that were
participating so the ones that I
involved as a tools that somehow it
solves the same problems as our actual
results with the tool is called you
before there's three tools which are
sort of in a different lead sesac and
threaded do concurrency and only
concurrency and we don't so we've never
compared with them and predator the sort
of deep memory things which again we
haven't we haven't competed in this
venture but for all other benchmarks you
for seems to perform a lot better hmm
well it's hard to tease out why give
like if you pick a particular point you
say is this particular thing important I
can say yes if I turn it off it doesn't
perform as well but if you just take
this particular think and remove
everything else you don't know the why
is abstract interpretation important
well because it can discover facts out
of an infinite domain of predicates fuse
predicate obstruction you may get stuck
trying to figure out what does the right
predicate whereas here you start with an
infinite set of restricted predicates
and you use widening to find out what is
a good set but widening can overshoot
and so you use sort of the same
refinement techniques to bring you back
into a safe region
so no questions
okay so this is how the competition was
wrong so the way the way the scoring was
done you get points for solving things
correctly you get negative points for
solving things incorrectly and it was
deemed that finding a counterexample is
easier than proving something correct so
you get more points if you prove
something correct when it is correct and
you get more negative points if you
prove something correct which isn't and
the distinction in this numbers was
partly influenced by the previous year
where a tool set would do bounded model
checking would look only in few
executions would really win everything
because they would look at a few
executions and say the program is safe
and the distribution of benchmarks was
cited if you have an error it's very
shallower and so those tools would
constantly win now this year there's
many more benchmarks and that's no
longer true but also the scoring was
changed so that simply guessing things
would would penalize humor okay so well
that's our the outcome of this so we've
participated in four categories which is
a control flow integers which has all
sorts of the traditional benchmarks used
by software model checkers and then
product lines which comes from dirt bear
some set of examples where there is the
same program but different
configurations of it device drivers
which come from linux device driver
verification project and system C which
is system C programs converted to see
with a scheduler the system see is the
hardware description language that
describes concurrent systems and so in
all of those cases are the two performed
much better than just predicate
obstruction by itself and the abstract
domains were sort of crucial to this so
if you look at the benchmarks we'll see
if you want to find that a bug then it
seems to be really good to use winter
with a box abstract to me and the
intuition here is that the box domain is
not very precise but if it can tell you
that you need to unroll the loop that
loop is easy to know that it's safe for
a small bone and so this domain seems to
be really good at figuring out how much
to unroll the system
so that the bounded model checker will
find the counter example then we have a
winter with the boxes domain which I'll
talk about in a second which is a domain
that allows to have disjunction in
addition in addition to intervals and
that domain very closely mimics the
typical predicate that the software
model checker finds except it has all of
them at once and it seems to be really
good at proving safety so let's see if I
can bring up the results I want some
kids that's so this is a if you want to
go to that link you'll see lots of
details about who did what this is our
you for column I know I want to go down
into numbers but if you're interested
you could go and you could click on all
of the numbers and will give you a
comparison of tools and draw your graphs
you can try and tease out what's the
difference between different techniques
well so yes actually we got a negative
score overall and we didn't quite
realize what this category was so the
idea for the overall category we started
was sort of the addition of all the
other things but in fact the overall
category was all the tools around and
all the benchmarks even the ones that
they know what they don't know anything
about and if the tool gives you a wrong
answer the pasta unknown it's penalized
but you are allowed which we didn't know
to check the benchmarks for example if
the question was about memory you could
just and known whereas we didn't and so
that's what separates this home
so so let me tell you more about sort of
what else so the winter was I think was
the main reason why we did so well in
the competition but there were number of
other things that's really influenced
and those things which we don't
typically publish their like small
things that end up making a big
difference so the secret sauce the
important things were at the front end
I'll tell you more about it combining
quiz abstract interpretation the box is
abstract domain is on and talk about in
a second disability of computing Doug
interpolation so computing a solution to
this whole problem at once as opposed to
doing it like plus at a time or lazily
on in any other way and then at the end
of the day we do run a lot of things in
parallel so no tools answers we don't
have to worry about which particular
setting is the best one so the front end
is something that's in principle is
really really simple but in practice
it's are extremely messy so what we
ended up happening is it's it's really a
huge messy so there is a seal path that
goes through the code and normalizes it
and this is basically where I try to
fight against the software competition
semantics because there is semantics
have nothing to do with say what the
compiler thinks legal see should do for
example in a software competition it was
assumed if a variable is uninitialized
it can have an arbitrary value when the
compiler sees an uninitialized variable
it says it means it's undefined and
therefore it's legal for you to do
anything so if you have a branch on an
undefined variable you could pick the
the easiest path you want to take an
oath to my daughter passed away so
there's a seal pass that sort of tries
to do this at a syntactic level to try
and fix all of those things for example
we add just calls to non-deterministic
functions to initialize every variable
then there's a lot of AMD CC pass which
uses GCC to take the benchmarks and
convert
into a lot of Yemen and there's a lot of
them optimizer based on an old version
of llvm that has a good optimizer but
not too good and that we use in order to
do to simplify member and do all of
those things and the problem here if you
switch to a new version of llvm the
optimizations are too smart and so again
you get into this clash that so for
example in the competition was assumed
that if you get a non-deterministic
integer using a known that in function
and you cast it in too long you get a
non-deterministic long well what I
compiler will tell you now you still get
a non-deterministic hint and the top
bits of this long will be 0 new llvm
knows about this and simplifies faith
based on that older llvm didn't south
station he gets through all of this you
could look at what happens to the
benchmarks and this is quite interesting
that out of 1592 save benchmarks the
front end happens to prove 1320 one of
them so many of them are just simple
things that you could do by constant
propagation and simple simplifications
for the unsafe examples okay there's a
fewer of them that the front end can can
remove so big part of this is just
having a really good front now the
second thing was this box is abstract
domain which is I think unique to it at
two or two and the idea here is to say
that in most cases when we think about
programs where software model checker
did well we want to find an invariant
that's not a convex hull it's not an
upper and lower bounds of every variable
but it's more of a disjunction of such
things and so you'd want an abstract
domain that's not a single box now the
same gun min max but rather a bunch of
such boxes well if you start thinking
about it then okay it's easy to see what
this domain is but the difficulty is how
do you maintain how do you represent
this as a formula so it doesn't block
and the solution that we are using is
using decision diagrams so while back we
have extended their decision diagrams to
the nourishment
so that's the decision diagrams where
each node in addition to having the the
true and false child is labeled by a
linear phonetic formula and then the
diagram knows about it and thus
simplifications based on that and the
boxes domain it basically uses this data
structure where each node represents a
single min max constraint the
interesting thing about this
representation that it's canonical for
this domain so it behaves virtually like
BDDs and can be implemented really
efficiently and lets you compact the
represent those things and then finally
we're on everything in parallel so we
looked at various settings that the
algorithm has using an abstract
interpretation using credited
obstruction using different forms of
refinement and we couldn't find out any
sort of best strategy since we're
running out of time and the competition
machine had eight course we'll figure
out we can run eight different things in
parallel and see what happens and so
this is what we ended up with there's a
whole bunch of different combinations so
for example this one does use the
slaughter of llvm optimizations uses the
boxes abstract domain and use this very
non aggressive widening so it lets you
go deep into the loops but it's run for
a very short time so that's really good
for cases where there is a couple of
iterations of a loop maybe 10 or so that
you can that you have to get through and
the boxes demand can keep track of the
state really precisely and then you
converge but if you don't then that's
probably a bad strategy and so if you
see all of them assertive this list mix
use either strong abstract domain wake
up strength domain and try and decide
whether it's run for a short time or for
longer time
okay so to conclude all us this is where
winter came from this is Ventus family
we started a while back with an
algorithm called whale which was using
interpolation to try and reason about
recursive programs we've sort of
abandoned that work because we didn't
have any good benchmarks to turn this
algorithm in and then we switch to the
competition benchmarks first developed
this utiful algorithm that eventually
became a framework in which we do our
development that introduced this concept
of Doug interpolation and combining
predicate abstraction with interpolation
based verification and Sarah Wynter
pushed it a little bit further by adding
abstract interpretation components and
the difference the sort of the
difference between this two and
conceptual is quite this quite similar
work but the details there's quite a lot
of difference so we had to really work
out how the widening would work how to
interface with the abstract interpreter
and and and the abstract interpreter
really put a lot of stress and our dog
interpolation component we really had to
to tune it a lot more just because
here's abstract interpreter would go
much deeper into any loop than the
predicate obstruction but there any more
questions or
so if not I'll just I'm just want to
talk about some of the one current work
and just maybe get your opinion maybe
offline so one of the problem that was a
that you actually asked this question of
what we call a symbolic obstruction how
do you build an abstract domain on top
of an smt soldier or how do you go from
an smt formula into an abstract domain
representation and this is something
working with with actually ely is the
main student working Elizabeth its work
together without Zach and Marcia so
here's a the statement of a problem so
winter wants an obstruction function
which basically enough as it takes an
smt formula say over Linear's medic make
it simple and gives you a result in an
abstract domain maybe a conjunction of
linear inequalities maybe a conjunction
of min max constraints and if you think
about it for a bit implementing it is
really an optimization problem so you
could look at it in this way so formally
we have a quantifier freelan arithmetic
formula fee we have a bunch of terms t 1
to t k and what we want to know is we
want to find a values for Mina and max
max I such that fee implies a
conjunction of those bones and we want
meaning marks to be the tightest
possible and this would be a value in
abstract domain this would be value in
the abstract domain of box but really
it's more general because T can be
arbitrary term right of course without
loss of generality we can say well since
fees and s empty formula it's enough 42
be variable if you want to make a term
will just add a new variable to fee
there is a knave solution which is
converted into dnf take a disjunct and
then optimize using either simplex offer
your motzkin and then go on to the next
issue but that doesn't it place the very
naive version doesn't scale and the
problem here is that typically what we
want to feed to be is really a bunch of
loop free executions of a program so
taking alien f
quite large so this is a solution that
we've been playing with it seems to be
fairly effective so in a nutshell we
want to do something really simple we
want to successively under approximating
fee by enumerated moment but the problem
is that if he happens to be unbounded if
it's not the a poly top then if we just
enumerate the models we may go forever
into some unbounded region and so what
we try to do is opportunistic Lee check
by basically shooting array into a
direction whether it happens to be
unbounded so this is how it looks like
on an example so say we have this to
this this is our feet this particular
shape and we're going to start under
approximating so we're going to give
this Fitness empty soul over and ask for
a model let me get a point in here then
we can ask for another model and we
optimizing x and y so we'll ask for a
model where x increases and we can
always ask for a model that's more on
the faces of this volatile right by just
taking a term corresponding to any of
the faces and saying find me a solution
on it so the next solution could be here
you asked for a bigger solution okay so
before asking for a bigger solution this
is what we're going to use in order to
decide whether something is unbound so
we have this fact that if you happen to
have two points p1 and p2 where X is
increasing so there's the race route p1
and p2 and they happen to be in the same
hyperplane Sophie and there isn't p3
that on which x increases but that's not
on more hyper planes than p3 that then
then p 2 then this direction is unbound
so here for example if I look into this
direction I have this point I have more
points where where x increases but I
have this point that flies on more hyper
planes right that it applies on a second
hyperplane so this this so right now I
can't conclude whether the Xbox
direction
unbound ask for another point where X is
bigger I'll get a point here well now I
know that the only way for X to be
bounded if there is another point on
this hyperplane that intersect some
other hybrids I can check for that I can
have the equations fall of the hyper
planes I can just check does it exist
the value where X is bigger yes and that
there exists a value where x is bigger
is it intersects one more hyper plane
and if the answer is no then I know I
have this whole garage and once I've got
this I now go and look father values
facts so maybe I get like and ask for
the lower value of x and I'll get here
that also happens to be lower value for
y there isn't one I asked for a higher
value for y maybe I'm lucky and I get
here and now i have my my convex hull so
that's our current solution
but looking for for for opinions of how
to make it better so one sort of
limitations here is that when we get
this point we don't have any control it
seems like if we're using an external
simplex we could always get a point
which maximizes X for example in a given
Paulito but when we use an smt solvers
interface we have now we just ask for a
point and then we ask for another point
in a completely separate Curie as
opposed to trying to say well give me a
point and then try and maximum you know
find another point in the polytope you
already in that maximizes the direction
that's it
it's your done to the top that's okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>