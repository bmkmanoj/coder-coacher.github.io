<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How Different is Different: A Perspective on Music Similarity in Indian Art Music | Coder Coacher - Coaching Coders</title><meta content="How Different is Different: A Perspective on Music Similarity in Indian Art Music - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How Different is Different: A Perspective on Music Similarity in Indian Art Music</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/j9F_e08TyRo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
ok hello everybody it's a pleasure to
have cost of done will be here with us
today so costive is a PhD student in iit
bombay is working with ever so pretty
now on music related technology which we
talk about today but what probably he
will not talk or demonstrate here today
is an excellent vocalist and he has been
taking training from my digestion
ability for how many years do you have
shaken years now so you can imagine okay
cost of you can you know tell more about
good afternoon everyone thanks manage it
for the introduction so today I will
talk about a little bit of my research
it will be a broad overview I can't go
into great detail of everything but I
will try to motivate why I am doing the
approach and I would very much like your
valuable suggestions and please feel
free to stop me at any point so the
title i have given is how different is
different so i'll come into that more
closely and it's a perspective on music
similarity and special on indian art
music so i will focus mainly on
Hindustani or the north indian music and
as of now i am doing my PhD and midway
of my PhD under professor please Robert
iit bombay so why do i start with music
at the first place because the lab I
work on was mainly working on speech and
so apart from being a musician myself I
appreciate music also music the purpose
of musical message is more of towards
cognitive and affective domain rather
than speech like you enjoy the same
music pitch a piece every time you
listen to it so and the main goal is to
redefine the distance measures like if
two entities are there they are similar
the human ears can perceive that they
are similar but there is a difference
but we have been always using the
state-of-the-art distance measure like
Euclidean or dynamic time hoping but can
we know the signal little work more
closely so that we can
re add up the distance measure and the
goal is to estimate the space of
variability like indian music specially
is full of improvisation so there is
maybe one or two canonical forms of the
phrase and then singers add their own
colors so that is improvisation so if we
ask musicians can you oughter say 20
realizations of this phrase they are 20
and they'll be 20 different but they
can't say okay this is the limit beyond
which it will be incorrect so the space
is unlimited but we are trying to find a
limited space between which that is
bowed as the same so that will motivate
us to find a good distance measure and
another important thing is the time
scale of psychoactive sick relevance so
perception study in this Mir is not very
rigorously done in Indian music but the
time scale I mean a tone click and a
note or a phrase these are of different
time durations and the memory processing
in the brain cortex all at differently
done so in engineering we do all signal
processing by windowed analysis but what
the feature window should be used
between which the calculation of the
characteristic should be done so if a
phrase is say 45 seconds human
short-term memory processes it with a
tag oh so they may assign a shape or
something so there is literature on that
but if it's a 10 seconds long phrase it
might not be processed at one go it
might be broken into chunks so we should
always also add up the analysis window
size based on that so that was one of
the motivations so how different is
different is the scale of degree of
difference so in a perception i will
come how it we have speculated something
from speech literature and the broad
perspective of this mir work in my
opinion has these four perspectives one
is the acoustics the signal we walk on a
signal processing engineers the psycho
acoustics is the perception what the
year here's but finally the cognition is
important what we make out of it so
after the year receives the signal
we perceive it not as some discrete
frequency but some note we relate it to
some musical note so that comes under
this branch and finally recognition
happens we map that note to some raga or
some other entity so that depends on the
music illogical knowledge and experience
so the same signal fade to a musician
who is say five-year strained and
50-year strained they will perceive it
differently just because the recognition
is different the significance will be
different and the broad outline of my
talk will be this melodic motifs in
Indian art music I will define what a
motive is and the modeling and the
perception how can we computationally
model the phrase and what are the
perception ohlet's so before starting
this work we have to first standardized
the basis on which we do these melodic
analysis and this was very much
motivated from one of Minaj it stocks
also so how musical is the music scale
he had his works on the music scales and
those so I had my PhD similar on the
same line and just to mention music
appreciation like natural intervals are
preferred by all living objects so I
will just play an example here
so this is an example of a lullaby so
these as all consonant intervals even
infants show their preference to this
without knowing any music so the music
scale the musicality is inherent within
the music on the other hand if we listen
to this a train honking so this is some
sound which is dis Anand and no one
prefers that and that is used to caution
people so music itself has its qualities
but we wanted to know what are the
musicality of the music scale as in the
scales the tuning of the scales is it
just intonation or is it the equity
tempered scale on the basis of which
will analyze the music so this is one of
the key word that's why I kept here
music and then then comes the similarity
I kept a visual example because i think
it's little more intuitive so here are
three pictures and all of us can
directly point out these are similar
because these are picture of birds and
this is because we are having a top-down
view on it but if a machine has to
understand that these are birds and
that's why these are similar so from the
bottom up approach they have to know
what is the background was the
foreground what is the edge so this is
in computer vision they are having their
problems we are trying to do the same
thing in computer audition that if there
are a mixture of signals many
instruments are playing human voice
human ears can focus to only the voice
or only one instrument can a machine do
that so that is the broad scope of our
project so that is the similarity and
just to introduce the project so we are
a project called comp music and in India
we are having IIT Bombay and Madras at a
part of it and in Barcelona we have UPF
the MTG professor xavier is leading and
the main motif of this project is to
organize and make sense of music data
made the audio which we are working on
or metadata or text or any semantic
information so we want to combine all
this available information related to a
audio in a meaningful way
so one of the possibilities what we do
or I do as a musician is a melodic
structure analysis so now the question
comes why do we have to do that if
already the CD has this much information
so this meta data is limited this has
only say the name of the raga or name of
the composition but doesn't talk
anything about the melody itself so if
we want to analyze the melody we have to
go into its features so i will give just
a small example so this is the waveform
of the audio and we have been able to
extract the pitch and now this is kind
of a solved problem to extract pitch
from polyphony so what is interesting is
kind of a pattern detection if I give
this as a query say so this is our audio
query and we know that there are lot of
similar instances in the audio because
this is the refrain of the song but with
variations so can we get the outputs
wherever variation is also present
so see this is another instance where
the percussion instrument is also
playing and there is variation in the
vocal melody itself but we can capture
them as the same so there is a degree of
difference but we want to capture that
as the same so this difference is not
meant to be categorized separately but
these are categorized at the same so
that is the music similarity we are
talking so if we have a kind of block
diagram so from the audio we cannot
directly model this primitive shape or
the motive the query I had so we have to
have a analysis by synthesis kind of
structure so first we extract the
low-level features like the pitch which
is kind of salt now now from this speech
where have we have to model up to these
primitive shapes so we are at this
bottom-up path now so as I mentioned the
melodic motif I will be following this
path and this is an interesting diagram
so one of the TED Talks I found so if
you are having a starting point a and
targeting to get to be but as a
by-product you may might find something
more interesting but we are not sure of
the path so it's a fuzzy thing but
eventually we might discover something
new so I will start with the modeling
part so basically it says represent the
melodic contour with cues from
visualization so as we already have the
pitch contour we can see the visual
similarity now can computer Martha
changes well play this clip
I
so this is just about 30 seconds of the
audio so could you hear some repeating
patterns coming again and again so some
patterns are coming and visually we can
see these are similar looking patterns
and also this overlapping blue contour
that those are marked by the musicians
as the ground truth so those are
recurring patterns so there are
variations see here there are lot more
oscillations and here we are missing
some and even here the peach is missing
but the ER interpolates so the hearing
and cognition is a very complex process
we cannot go into that and also context
dependence is heavily there if something
is already present humans also
anticipate the same thing to come we
cannot model that but purely from the
signal given this one-dimensional
contour can we model this similarity
what is the distance to consider to mark
if this is the query to get this as a
candidate so that is the motivation so
one possible way to go is to do our
dimension reduction because if we start
with all samples of the pitch contour
there will be lot of subtle variations
which might not be relevant to the years
so we tried a piecewise constant
approximation it can be called a note
level transcription so we had some
heuristics like perceptually relevant
the minimum note duration if it's within
the glide so we don't perceive all the
notes in between so we'll get rid of
that and if there are two steady notes
close by will not perceive this as a
separate note so there are some
heuristics to reach from this whole
contour to this string representation so
and also the motivating fact is that
given this contours to any musician if
they are told to write down or annotate
they will go by this because they
remember or they represent they'd like
to represent by a sequence of steady
notes so we thought this is a reliable
representation but can this capture the
whole story can this capture the essence
so we'll have an example here
Oh
so did you find the similarity by
listening to all these four phrases so
also visually we can see this first
three are having almost the similar
shape and also the context so this comes
from a long steady note then comes down
and having this shape so these all are
annotated as the same is called Danny
the pub in some ragga ragga I available
by the algorithm but this is a phrase
from a separate raga a different rather
but it happens such that the steady note
sequence comes out to be the same so if
we oversimplify to this level so then we
are capturing something else as the same
so this might not be a very good
representation or this is not capturing
what the characteristic of the phrases
but this is a good thing to represent or
maybe this is a very reduced dimension
we can do a quick search on that so the
next idea was to do both ways what is
efficient representation for a quick
search through database and what is I
efficient representation to characterize
the phrase so then what we did we went
back to the pit samples but we can't
really take a Euclidean distance point
by point because there is time warping
so we used dynamic time warping to align
the phrases and then took the distance
and just to validate that this is a
valid distance measure so we reported in
2014 that given the positive phrases and
some negative phrases with this dtw
distance we can cluster the positives
towards a very narrow region and we can
separate out the other phrases which are
negative to this so this to some extent
confirms that we can use this duty w as
a good distance measure and also in
western music there has been use of dtw
but that is in scores but we are working
on pitch data but this is
computationally very expensive
the window size on which you apply TDW
window size was the whole phrase we took
the frig man they are marked it was like
four to five seconds we aligned and then
took the digital blue on that your green
curve is the distance between the
positives and positives so if say a is
the positive class so between a and near
the distance is very less yeah all label
data we just wanted to validate that dtw
distance is a valid distance overlap
yeah so that is a long story I am NOT
going into this it's out of the scope it
is non phrase done either / that comes
under those kind of negatives where the
major portion of the phrase are having
the same notes but it is not positive
because if not belongs to the same raga
but as the dtw is also taking distance
between points and lot of the phrase
majority of the phrase having the same
notes so then there is an overlap so
these are called non Princeton is upper
we have called it yes yes earlier
scenario this is still not so that's why
still is the motivation to find a
suitable distance measure for Indian
music some interesting facts we found
that this trade-off between these two
representations so if we go by pit
samples so that is suited for
characteristic characterizing the
melodic shapes like the glides and
everything we are having in the
representation so we can represent the
whole melody but the discrete symbol
sequence is suited for quick navigation
and we recently submitted a paper where
we can have a dimension reduction of say
complexity reduction of 3,000 times and
we are finding an accuracy close to
within a tolerance of five percent with
the dtw versus this transcribed note so
in real time application this is very
much feasible to implement we don't
bother if I percent accuracy is gone but
we can quickly search the whole database
navigate very quickly between phrases
the difference is five percent the
classical dtw that gave some seventy
percent and we can reach 65 but with the
reduction of three thousand times yeah
classical ttw and also this was a work
reported in last FR ism Minaj it was
present there so these representation of
pseudo steady note segments so this cave
like this broken up the whole contour
into two parts one was the steady nodes
and one was the transients so we found
that the pseudo steady node and this
transient this can be like we can take
an analogy of vowel consonant pair in
the speech so we observe that in the
time warping of the two phrases the most
of the time moping is absorbed within
the steady note sections but the glides
preserves its original duration so that
somehow motivates that the glides are
showing the characteristics so even I
can just quickly give an example so say
I have a node sequence party so per se
now facing / this becomes rocks I inert
/ becomes kalyan / becomes youth kalyan
so these characteristic glide these
convince the information which raga it
belongs to but this para are used to
just carry the energy because without
these long steady notes we cannot build
the performance so similarly in vowel
consonant pair say in shouted speech or
straight speech we cannot really stretch
the consonant we can stretch only the
whole so this analogy we found somewhat
interesting but this is more scope to
there is more scope to explore I just
wanted to mention so now I will shift to
the other part because I am running out
of time so in the perception the
motivation is again revisit the distance
measure to obtain the characteristic
motives so I will break it down into sub
parts so we speculate that the
perception of phrases in installing
music is categorical in nature it
not continuous perceptions I will
quickly revisit and this is a theory
from speech but in music there are
spurious works I will just quickly go
through and then experiment followed by
the results so categorical perception
essentially means enhanced with in
category similarity and enhanced between
category differences so this figure is a
famous one so this shows a mixed breed
of hands here this is the real world
scenario when the observer is not
looking at it but when the observer is
looking so he tries to minimize the
intraclass distance and maximize the
inter class distance so this is a very
quick analyze demonstration to show
category perception and I will refer as
CP as now so it was first introduced by
Lieberman as motors theory of speech
perception that human perceives a
phoneme the way he produces it it's like
the silent talker that goes on the brain
when you hear something and a good
experiment is if the physical variable
is the direction and extent of the
second formant transition and if it's
varied linearly along a continuum so the
perception changes very rapidly from ba
door to go so these are the
identifications course so for some
stimuli values these are identify as ba
suddenly drops and it was it is
perceived as door and then go so this is
a very famous theory categorical
perception and in speech there has been
a lot of work but in music there has
been limited works so the tasks
performed here are mainly twofold one is
identification and other discrimination
and the distortions we're in the
dimension of temporarily stretching so
tonal duration manipulation and the
melodic interval so as we do not have
any work on Indian music we try to very
strictly follow this framework but we
had to adapt it to Indian music so how
to draw a parallel to Indian music
though identification task can be posed
as follows so given a phrase is this
suggestive of raga so can they identify
or discrimination given a pair of
phrases are the same or different can
discriminate between them and here it's
kind of a reverse engineered way to find
the space of variability because as we
don't have the answer from the concert
instances or from the musicians so if we
have the boundary that after
incorporating distortions to certain
extent they are not perceived as the
same so that can be estimated as the
boundary of that variation space so that
was the motivation and we kept the
distortion in the same dimension that
temporarily we time warp the phrase
sub-segments as we already have the
steady note transcription and the pitch
shift of a steady note segment that was
just to start with and it's very
important to find a good example because
this parallel raagas there a lot but we
have to be very controlled in the
experiment so you found this pair
interesting so in ragged edge car so
there is a temporal characteristic that
the note ray can't be stretched much
it's only taken within a glide very
short as opposed in bhopal ease the nos
force which stretched very long and as
the pitch the guy intonation is higher
than the just kill it's called cherry
Vega and in this the peaches resembles
the tan pour agrandir or the Justin
krishna so there is striking difference
in the dimensions we want so we try
started with this and the motivation is
to see do musicians pay attention to the
subtle differences and also the time
scale so if only these stimuli
distortion is given can they identify
and if it is embedded within a broad
thing do the holistically perceive so
that's how categorical thing this comes
in the picture so then comes stimulus so
we recorded this piece from musician
so this is a phrase from Rajashekar this
green is the original pitch contour and
we had this steady node transcription as
we had mentioned earlier but we wanted
to stylize this pitch before
incorporating any distortion because
these vocal jitters these are natural
spontaneous but this might not carry the
same relevance all the points so if we
magnify some of these this might blast
out to some unmeaning full information
so we wanted to stylize this not use the
direct pitch contour so we synthesized
this pitch by only having this MIDI kind
of notes and we fitted polynomials in
between glides because this was low in
duration so it sounded like this
so this broadly captures the shape but
this can't be used as a stimuli for
musicians because at first place they
will not agree that this is a musical
phrase valid musical phrase so we had to
do something so what we did is to add
measured noise on this on top of this so
you measured the jitter here and with
some smoothness constraint we did this
and this is how it sounds
and I will play the original just for a
comparison so you have just used very
minimal information but with some
tweaking we have reproduced a very
natural stimuli and we are sure that
this won't be scaled by any distortion
because this is in our control and also
there was a need to add this tan pura in
the background because if we suggest
that this is a rock phrase from some
route first they have to identify the
tonic so there is a subjectivity tonic
perception we don't want that bias and
so that's why we put a tanpura and also
this pause these were all pilot
experiments which we decided on that
this poor should be long enough and
there should be also a metronome because
if nothing is given someone might tap in
some arbitrary way and give the focus on
the bit and not focus on the melody so
in perception experiment in literature
we had these references so finally it
looks sounds like this
so this was the form of stimuli used and
also interesting factor the location of
the on sets also were very much
important the perception if we just
relatively shifted the locations they
perceived something as they focused on
something else and this tambor was also
a constant amber we found found the
weights heuristic alee and this was used
and for the distortion temporally we use
a reverse approach of the dynamic time
walking path so as we already had these
locations of the sub segments so if you
wanted to stretch this very small ray
here we increase the slope of that
segment and then resynthesizer speech
it's like giving the timer pink path and
then come back to the original time
domain signal so this small ray was
stretched to this long and this was
compensated here because this was a very
long nos and it didn't matter whether it
was this short or that one but we
couldn't do here compensate this loss at
the last because that also changed the
perception so i am not going into detail
of every step here but this is how
finally we achieved this temporal
distortion so your slope we tried to
change in a continuum so this is the
dimension of the field this is the
physical variable the duration of this
and we changed into factor of one two
three four and gave this continuum of
stimuli and we wanted to know if the
perception was continuous or categorical
so I will come to the results right away
so I'll play the other one just to show
how it looks so it will be paying that
this one so just focus
Oh
so this ray was long and we synthesized
in the same way and this is how the test
was done it was an online survey so
given this phrase is the suggestive of
the raga we had a three-point scale
strongly suggestive somewhat and not at
all and also we had a comment box where
people if they perceived it differently
we wanted the comments so the results
are this is the route this car no not
boo poly they were told this is a phrase
of rock this car do you agree if agree
strongly suggestive or otherwise not so
results are somewhat interesting so if
that Ray was this is the factor of time
scaling of that rate if that was scaled
very little so all of mostly all of the
musicians told this was suggestive this
one corresponds to that around 2 to 2.5
I don't have all the points plotted here
so they told it was somewhat suggestive
and Beyond around three all of them told
that was not at all suggestive and we
got many comments from musicians this
was sounding like lagu poly so this
somewhat suggests that there might be a
categorization in the perception so idly
it should be a state function but we had
very few examples so that's why it
doesn't look that good and also we used
all the procedures like repetition of
stimuli randomization trial blocks too
we had a lot of responses but we report
only these which are very consistent
response and for the peach distortion
task I will just play and ask you if you
can find the difference so the question
is these contours will be played and
just by listening you have to say
whether they are same or different
any responses do you feel these are same
or different yeah the graph yeah so
graph tells these are different but
surprisingly many musicians said these
are same if they are only given this
difference like one shifted and one
original they can easily tell it and
there is a slight difference but if that
is embedded into a whole set then they
tend to forget the small variation
within so that is suggestive of
categorization they perceive it
holistically and not go into small
details yeah yeah 30 20 cents here it
was a DC shift of twenty cents so this
was how the question was asked given
this pair are these two same or
different and also let us know if you
feel one of them is out of tune so one
original was kept in every set and one
was distorted so this graph is very
interesting I'll little bit be slow to
describe this so the blue one is for
musicians response and the main
attraction is this is a symmetric so for
deviation of say minus 10 minus 5 10 and
also 15 I do not have the point here
they didn't find it was different if the
deviation was still minus 10 say they
didn't find them as different they
perceive that same but on the other side
there was a shaft fall so they're easy
reason because i already mentioned the
goth this dish car was already higher so
when we lower this this comes to a very
consonant gah with respect to the pan
pure so then don't focus on the
roughness because this is very consonant
so that is that might be the reason they
don't feel the difference and we'll
beyond certain level they are certainly
out of tune because they don't make any
sense to musicians but in contrary
non-musicians they don't perceive
consonants or dissonance maybe so there
are no definite trend but there was a
trend
@ @ + 5 there was it like drop in
identical disclination score so there
might be an explanation that this
original gawas around 393 cents and
adding 5 it makes very close to the
equator which has a roughness so that
roughness might have disturbed the
non-musicians also and they might have
all of them almost went for it is not
same but otherwise there is no definite
trend and as it was already higher so
plus 30 here is also not sin so we're
not going to further details but these
are interesting finds and this a
symmetry suggests that there is a
categorization and also this suggests
something about I defining that pseudo
steadiness because the pseudo steady
note it's steady within some tolerance
band so first we started with some
heuristic value that's plus minus this
much will consider this steady but this
somehow recursively tells us that what
should be defined as a steady not
yeah there was there I have to talk to
musicians then so these were all very
consistent in as of otherwise that's why
I just put here but yeah there are cases
where yes yes but the thing is is for
the online service so they put whatever
they felt so I don't have any control of
whether they are really experienced or
they just marked this was online survey
and I have the form no no no no because
then yes it is online survey so it's
very hard to generalize this is just a
starting point but we have to rigorously
do it with lot of attention and control
to generalize or finally conclusively
remark something so summary is that the
this identification score drop that is
suggestive of categorization as of
speech literature and this
discrimination task this asymmetry
somewhat suggestive and speech also we
get similar looking curves so we
speculate that musicians perceive this
melodic phrases holistically and don't
pay attention to these small variations
it's like macroscopic versus microscopic
view of the phrases and this was
recently reported at ncc 90 bombay so i
will just conclude like this we have
something like showing us that this is
interesting but we are still little
fuzzy about it we call it cloud by that
ted talk so but it's insightful there is
a direction so we might want to explore
so as a future work we propose that we
want to develop a category learning
algorithm so if there are any instances
the degree of difference is in but the
categories present indeed might not be
in that might not be em which is very
less so if the computer can learn the
categories by itself with the distance
measure so that reflects here you define
the distance measure and subjective
responses we have to try different
baselines so musician vs non musician is
not really a great base line but we had
to start with this and observe the
effect of music training and teaching
perception so it's like the recognition
part so even if they find this is a dash
car phrase but what significance they
make out of it that basis on the
training and experience of the musician
so what is the effect of that and also
one remark is a do we need to modify the
procedure for music from speech because
we are all borrowing the methods from
speech so these are some open-ended
questions yeah I think that's quite it I
thank microsoft research for providing
this platform this was a part of comp
music my guide these are some of the
references thank you
for your online survey what service with
you using
doing this yourself oh could you please
repeat the fish for your online sir yes
it was a site called servic is more I
made the form myself and the responses
was noted this was sent to the mailing
lists so all the Izmir mailing list so
whoever works on these areas so this was
broadcast to them and I got about 120
responses mixed with musician or
musician many of them were incomplete
after checking the consistency and all I
report 12 musicians and eight
non-musicians yes which were very
reliable and still the question remains
that if they claim themselves to a
musician's do they really know the music
or just like that they ticked that their
musician so yes we have yeah we we would
do that very recent work so we hadn't
been able to continue it further but
will
detecting colors mm-hmm
rock music
so if you just want to put it
renditions of the same in custom song
into one of these are how bad the form
you will have any expense
your first of all I do not know whether
they work on pitch data most of them the
cover detection work on musical scores
so we have recently submitted one is my
paper on that so a score is somewhat
equivalent to that music transcription
so we did a cover detection like task so
given a query by humming something like
that and in a big database can you rank
order all the tracks and we have like
there is a measure called mean
reciprocal ratio it's kind of a map
score and that is about point eight nine
so we are able to find the original
track from which it belongs say the
cover or the refrain or the bandage and
also we can rank order the ragas like
reach our this melodically similar
raagas so now the motivation or the
direction is to make some network kind
of thing the interrelation between these
melodies so say some recommendation
system we don't have a melodically
similar recommendation so if we ask for
rakesh car will find rock dish as a
suggestion but that is not melodically
similar but textually similar but by
these analysis can we find a mechanic
melodically similar like Seibu poly or
shoot Kalyan those kind of raava should
be recommended so those are some
directions we are finding this has some
potential in the database navigation but
on the contrary it's kind of
oversimplification it doesn't really
capture the characteristic glides
because those are carrying the
information of the characteristic and
these are just the sequence to identify
the raga so one is raga identification
and one is rather characterization so
those two are kind of diverging problems
so but we may may fill some sense that
this pseudo steady and the glides if we
can use both information so then might
be will head somewhat close
is coming from Mirax or your medics
hindustani database we haven't used that
but this is computing data set we have
about 350 hours of data in this theater
music did you find any interesting
interesting stories of findings that
yes so there is a another study being
carried out in our lab which is the
style classification so given the North
Indian versus South Indian versus say
Carnatic a Turkish music so based on
only the pitch contour can we
characterize those features so that is
kind of a genre classification so given
the music pace we extract the pitch and
then say suggest whether this belongs to
Hindustani Carnatic or Turkish or maybe
Western we haven't been able to like
laughs not started Western but in these
kind of genres where there are very
abilities within the pitch like the
glides are there the vibra toes or the
oscillations are there so we have these
classification problem yes
systematic study about say similarities
between about switch early morning
ah yeah we haven't done any formal study
on that but morning raava's yeah maybe
the shapes of this characteristic glides
or oscillations might be interesting to
see but as of as a musician I do not
fill there can be any very reliable
feature with which distinguishes morning
versus evening rather it's just a
filling as a musician but I haven't
tried so I won't comment right now
perception experiments in Houston music
yes how is there anything which you
could compare with your results and see
if this yeah so our results of we don't
claim it is scalable so we do not claim
any numbers but this shape like the
discrimination score the shape and the
identification score these shapes these
are coming very similar so from there we
are speculating there might be a
categorization yeah but yeah they have
percentage accuracy and all and they
have lot more listeners to do the
subjective experiment so we haven't
scaled that so we are not reported
because I was thinking I mean western
music engine music emphasizes of
different dimension yes well as when you
were yours niggas and that might lead to
different slightly differences in the
perception yes yes so it was a very hard
step to decide decide on these
parameters so how we bring the parallel
to Indian music so they have used
melodic intervals but we can't use
intervals so we have used some feature
of the pitch so we use the dishes shift
and tonal duration was kind of okay but
they had very stable tones we have the
glides now we could have distorted this
glides also say we have this glide here
and we could stress that but in a
previous study we should we have seen
that the glides preserve their shape
they are not time worked as much so
there was no meaning and even distorting
the glides we have a pilot experiment
there
asian say this is not at all a valid
phrase so do not ask me this is as a
chihuahua so this reconfirms whatever we
found in the previous study but there is
a lot of scope to explore further and
the there are two approaches the MIR
community some of them prefer big data
so analysis on like thousands of hours
and all but for these perception test we
can't really have those many examples
and generalize so we have to start with
a very good example where every musician
first agrees that this is a valid
example to start with and then vary the
parameters and have controlled
experiment and what Tambor to use this
metronome is still unsolved problems we
have come up with these locations where
it's acceptable but if we change that
the person this location the perception
changes but we don't know the reason why
it happens and also so this gives me
personally a perception a redefinition
of rhythm or like singing tempo so the
tempo in Indian music we always go by
the percussion but the Allah or the
unmetered section also have a tempest of
the pulsation so I strongly fill that
could be like having a correlation with
the relative durations of the notes so
that is kind of a tempo and if we sing
we have a sensation of beat at on sets
so if we have that is there any harmonic
relation of the relative durations so
this is something very fuzzy but we'll
work on this these are some future
directions
these were all pilot experiments we had
a group of musicians mainly friends from
ITC SRA so unfortunately disappeared in
the final test it is a great idea so
they all helped me in these pilot
experiments to decide on all these
factors but when the whole survey was
ready so they were all yes there are mu
there is no written down relations like
that and as a musician also I do not
fill in performing music there is in
notation system it is so if you have a
musical score of a composition you have
all the like lines of the order focuses
on long steady notes and add note on set
but there is a very long gap between
performing music and this notation so
this bridge is not very clear so we
cannot directly use those things but
here there is scope of experiment
standardized this
ok</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>