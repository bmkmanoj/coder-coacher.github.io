<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Martingales from pairs of randomized Poisson, Gamma, neg binomial and hyperbolic secant processes | Coder Coacher - Coaching Coders</title><meta content="Martingales from pairs of randomized Poisson, Gamma, neg binomial and hyperbolic secant processes - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Martingales from pairs of randomized Poisson, Gamma, neg binomial and hyperbolic secant processes</b></h2><h5 class="post__date">2016-07-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/aH5m4ikC_lc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">it is pleasure to have logic break
presenting the last talk of the day
logic is a professor at university of
cincinnati now visiting UW as part of
his sabbatical and he's going to be
talking about melting gills the rest of
his life thank you very much for the
invitation and a special to Chris ballsy
for making this visit possible and so we
are pleasure to be here with beautiful
weather and son and I didn't expect any
of this so let me point out first the
invisible things on those slice the
lower part of the slide is difficult to
see so my talk is based on several works
several papers with the attack vessel
was key some of them are in progress
some of them already appeared some of
them are on archive and I apologize for
the two long title so let's just not try
to read it so let me begin with a
picture that comes to mind of a person
who visits a seismic zone and is not
used to living in it so what this is is
a mathematical mechanical rendering of a
simulation of a Markov process used to
2000 points for the rendering and here
you see a 180 or 200 points or so so it
is clear from those pictures that
something is happening around T equal 1
maybe I don't know whether that's clear
or not and the first part of the talk is
to try to convince you that T equal one
is where things happen and then the
second part of the talk is to somehow
try to see how can we see this kind of
things if we were not able to you know
this is a simulation so I know of course
when things happen and you know if you
were to observe a thing like this what
kind of information could we get from
observations perhaps so it is fairly
obvious when you look at the beginning
of the trajectory of this process that
the process is actually following
straight lines and you know a line and
then what do I use then maybe I will be
old-fashioned use the mechanical pointer
so the process follows the line then
jumps up on
the next line and follow the line jumps
up and sort of obvious that that's what
it does from at the beginning it is also
obvious what it does at the end it
follows the line then jumps down follows
the line jumps down follows the line x
down this is easy to see on this it's
not so easy to see on this part because
this is just 200 points so of course we
are missing lots of all those jumps so
let's add more lines this is much less
convincing so this is on authority that
these are the right lines some of the
points are on those lines some of the
wines go I think without any points
let's add more lines from the right
let's let a little bit more lines so I'm
trying to say that since I know how the
process was simulated t equal one is a
special point that's where the lines
change sort of so you know slightly to
be convened more convincing here is all
2,000 points and then fewer lines are
missed but I think some lines like this
line here seems not to touch anything
still so you cannot really see this kind
of picture by looking at that you know
by observing a process every millisecond
or every can't really see that these
equal one is special so let's try to
look at this picture and try to see can
we see things from some simple
statistics of the process can we see
that T equal one is special from say
they meet well of course we cannot this
is the process of has mean 0 about the
covariance well this process I know I
made it up so I know that it has
covariance minimum st so again T equal
one doesn't show up too much there well
there is a point situate there's
something that T equal one is a little
bit special this process is actually
time invertible that is XD has the same
distribution as T times X 1 over T as
the same scaling is the winner process
has the same time inversion thing so the
moments are not helpful I had a friend
in physics that I took to heart his
advice when he was studying physics and
he said you are studying those
distributions like normal and whatever
he said this is stupid he said the only
thing we can measure in this in
statistic in physics is averages
so you should study averages nothing
else okay so let's go to this and say
let's start the conditional averages
let's be you know a little bit at least
through you so this process is a
martingale as well that is expected
value of xt given past sigma field is
excess and it doesn't matter whether T
is bigger than 1 or smaller than one
whether s is bigger than one smaller
than one we cannot see anything out of
this either well this if you want to
study higher conditional moments for
example conditional variance conditional
variance of this process given the past
is a polynomial in excess if you were to
study higher higher conditional moments
of polynomials of XT there will be
polynomials in fact you can produce
polynomial martingales for this process
so nothing special here well let's
continue the game with conditioning
let's look at the two-sided filtrations
where we condition with respect to past
and future so we have f st is the sigma
field generated by past of the process
to the S or future to the T and less
condition here and see what happens so
if we conditioned process xt given past
and future than what we get is
essentially linear interpolation between
two points on the graph x XS + xu and
this is what sometimes people call a
hardness condition and so this process
is a hardness and t equal one doesn't
show up too much or not at all here well
let's look into the conditional variance
the next thing sort of next high moment
one can compute the conditional variance
for this process it comes up as a sort
of strange expression there is this
constant that I will be often
suppressing in in some formulas and then
you have linear function of increments
of the process X u minus XS / u minus s
this other thing looks mysterious but
these are actually increments of the
time inverse of the process you can
rewrite this as increments of this
process so it's a definite time
inversion invert abilities hidden
year so we don't see that t equal one is
anything special but for people who
learn that many but the attack vessel
was give me and a couple more people for
people who play with conditional moments
of processes we sort of developed these
heuristics that if you know the first
two conditional moments of the process
including the two-sided conditional
moments then you actually know the
process so somehow all of those things
that don't show that T equal one is
special somehow equal one should show up
on in the in those here on the
blackboard so basically that's what the
next part of the talk is trying to say
try to show you how T equal one is
hidden in those formulas somehow so it
what happens is a you can this sort of
the cipher that T equal one is special
if you look into so they say bridges of
the process conditionally you know the
condition process on XA and xB fix two
moments of time and then try to look at
conditional moments there so conditional
on XA and xB the mean of the process
stop being zero of course it's a linear
function of T and alpha and beta are of
course random depend on XA and xB
conditional variance is so covariance of
the process conditional on XA and xB is
well it's a linear function of s and T
and it disappears at the end points no I
meant to write x a thank you and the
writer on I will mean to write x1 yes
I even then noticed that yes thank you
so time reversibility so the first kind
of things are lost so timely visibility
is usually lost unless you happen to
choose conditioning times and the values
correctly on the other hand the other
part the two-sided conditionings those
are not sensitive at all to XA and xB
because you know execs we are in the
sigma field so the conditional mean is
still the linear function of excess and
Xu conditional variance is still the
same quadratic polynomial that we had
previously so all of this looks sort of
the same and what I would like to say is
that if we convert this situation to
standard form then the two-sided
conditional variances of bridges based
on X a and X 1 on the blue part will be
similar to the bridges based on X 1 X B
and different then the genetic bridges
based on XA and xB I'll be mostly doing
X 0 X 1 X 0 is 0 so I don't have to
worry about conditioning and the next
thing I should explain is what they mean
by standard form so we typically we
since the process is a hardness we
should have developed a terminology
calling it a quadratic hardness if you
want we can call it a quadratic harness
in standard form if the first two
moments are like in the previous slide
that is the mean is 0 and the covariance
is like for the winner process and the
process is a hardness so expected value
of Z T given past and future is a linear
function of zs + zu if it is a linear
function of Z SGU the coefficients you
compute from the covariance one other
thing that perhaps I want to mention is
that if the process is a hardness and
the cover is s here then the process is
also a martingale so you know you can
pass with you to infinity and sort of
show that the contribution disappears so
they probably harness that happens to
have the covariances in point one is
also a martingale and also reverse
marketing
so number two is the soft assumption
linearity of regression plus you compute
the coefficients from the covariance
number three it looks very scary so let
me say that I view it as a soft
assumption that is the soft assumption
says that the variance of ZT given past
and future is a quadratic function of zs
+ zu and one can prove that under some
technical assumptions this quadratic
function cannot be arbitrary it has to
be of the form an explicit expression
which I don't want to write and then
it's a quadratic expression in
increments of the process of linear
function of z u minus z s / u- esque
quadratic term the linear franco
efficient and the quadratic term for the
time universe of the process and then
this cross term the cross product of the
sort of increments of the powers with
respect to past and future so basically
the right-hand side is the value that
you get for the Wiener process you get 0
0 0 everywhere zeroes the conditional
variance is constant the right hand side
for the Poisson process is you get this
coefficient nothing else the right hand
side for the process that I showed
previously has a tau equal 1 theta equal
1 the rest was 0 and you may say do i do
such processes exist that's a separate
question yes
so okay so basically the what happens is
if i look at the bridge of the process
that i had previously which was sort of
quadratic harness in standard form once
I change to a bridge then it loses some
of the properties but things that it
loses is the covariance the covariance
is wrong so the covenants can be easily
corrected and here is an example how do
we correct for the covariance the
simplest example to think of is a
brownian bridge so a brownian bridge is
a Gaussian process with the covariance
that happens to be of the product form
like for all of the bridges of those
processes s times 1 minus T and other
than that of course it is a happiness
the conditional expectation of xt given
x sx use the linear function of x sx you
it has to have the right coefficients i
forgot to say that this hardness
condition is compatible with more
covariances than minimum st and the
conditional variance of xt given past
and future is I wrote xsx you because of
markov property value is constant so
quadratic so this is sort of a hardness
accepted person is not in the stack
quadratic harness except not in the
standard form because of the coverings
being sort of messed up but then
everybody knows how to correct for this
messing up everybody at least who is as
old as me and had to study from the 68th
edition of billing slave convergence of
probability measures so on page 68 there
is an exercise there that says take a
brownian bridge do this transformation
and you know the transformation is not
that complicated it is really a Mobius
transformation of time multiplied by the
denominator of the smokies
transformation this is exactly what you
need to correct the covariance from this
form s times 1 minus T to the carbon as
being minimum st of course this means
that you convert the brownian bridge
into a winner process and you can go
backwards and you can say ok so now i
can compute this in terms of that in
other words i think i call the one of
them w i think why i call w now and the
brownian bridge can be written
words as 1 minus T times the winner
process applied to the same type of
transformation so it's there fine fine
it's a Mobius transformation x a dinner
function of T so let's look at our
process that we were talking about let's
look at the blue part and let's say
let's look at xt conditional on x 0
which is 0 and x 1 well then this
process can be written transform into
the standard form and if you go
backwards then it can be written as 1
minus T times to a song process it's
exactly the same transformation that we
saw for the brownian bridge so it's 1
minus theta is n where some process at T
times 1 minus T the Poisson process of
course has a parameter lambda well
everything should be conditional on x1
so the parameter lambda of this process
should be oh i forgot to say that this
is centered so that you know you take
mean zero first so you subtract the mean
so NT is a centered poisson process with
parameter lambda but lambda now is a
random variable and that depends on X 1
well not been very complicated way
lambda happens to be 1 plus x1 and
furthermore we actually know what the
distribution of lambda its happens to be
exponential and then if you look at the
black part of the trajectory what
happens if XT if you look at XT being
bigger than one condition on x 1 x
infinity is 0 released you should look
at this this way then X T for T bigger
than one condition on X 1 is another
person process this transformation here
is really just the time inverse of that
transformation so it's T times X 1 over
T applied to that thing and instead of
the Poisson process that we had
previously we have an independent
personal process so n tilde is an
independent Poisson process but with the
same parameter lambda with the same
capital lambda so with the capital
lambda is shared between the two
processes so what this middle it shows
you is that I can take two Poisson
processes with random parameter lambda
and if I choose that
tribution this was a title of the talk
putting together pairs of Poisson
processes into a martingale so what I
did here is I should have showed how one
can put well not convincingly but how
one can put two for some processes
condition with the same random parameter
capital lambda which happens to be
exponential or exponential minus
exponential and I can put together into
a quadratic harness and also into a
martingale so the question of putting
levy processes into Martin gates by this
kind of fashion is of course something
that I'm not even trying to answer the
question of putting together lady
processes into a quadratic harness is
slightly easier to answer because there
are very few quadratic harnesses among
levy processes well okay so let's look
back into the sort of a question better
slightly in more generality so suppose
that we had a quadratic harness ZT which
has me covenants minimum st means zero
it has a hardness condition and also has
this quadratic variance with all of
those one two three four five parameters
floating there and what we want to ask
is when else this situation happens that
we saw previously that is when is it
that we can find a capital T moment of
time T such that the left hand side of
the process this blue bridge 40 is
smaller than capital T conditioned on
the value of Z T in the standard form
becomes a simple enough quadratic
harness what do I mean by simple enough
quadratic harness while it has some
parameter theta some parameter toe and
the increments of the process the if Y
was supposed to be a levy process then
conditional variance of Y T given FSU
would have to be a function of
increments of the process have to be
perhaps not a quadratic function but for
hardness for quadratic harnesses must be
a quadratic function I also left to row
there because we actually can allow this
cross term as well
and the theorem still is the same so
then essentially there are only three
situations that this happens one
situation is sort of boring so all the
parameters here are zero well if all the
parameters here are zero ZT is actually
a wiener process one can show that and
then of course you can choose any
capital T and all of this happens but
that's a boring case the other
possibility is that the upper part is
there but the lower part isn't so there
is no quadratic terms and then and I
think we assume that a 2 times theta is
positive in my example aight aight aight
over 1 well then this is the example
that we saw this is the pair of Poisson
processes that one can glue up so that I
mean I'm not saying that's obvious at
this point but the next slide will make
it more obvious what is what one can do
is one can compute if you know what are
the parameters of the original process
you can actually say say what are the
parameters of this bridge that is you
can say that the conditional bridge in
the standard form this is a complicated
in a sense of it is an ugly computation
so it is good to have good notation but
one can compute those numbers in terms
of the original numbers and in terms of
the conditional variables ET and
therefore we can sort of read out what
is the process so the process here would
be actually corresponding to this case
that we were doing in our example and
the third possibility is that you have
all the parameters really there at a
theta sigma tau and row but they are not
arbitrary row is actually at the upper
range of its availability that this is
two times square root of sigma tau and a
tie and theta are also somehow tied by
an equation with segment Sigma and tow
and then that moment of time that we are
interested in a square root of tau over
Sigma and then the process itself we can
recognize what it is which is the next
slide so the next slide is the theorem
of Vysotsky that says what do we expect
from the process or in each case there
is on
that many parameters the third one that
I allowed for the process start turns
out to always come up as zero and that's
why I sort of could allow it because it
doesn't matter so this is the question
this is this is a question this is the
slide that is supposed to be answering
what kind of processes can you get as
bridges of quadratic harnesses know if
there is this special moment of time
capital T so the only ones that you can
get is the ones that have theta and tow
there and then we can actually show that
such a process has all moments and we
can show that it has martingale
orthogonal polynomials and we can
identify the actual process that has to
be a Markov process which we know so one
of them is possibilities is that why is
the winner process if we happen to have
no towel but linear term then why has to
be a Poisson process if we happen to
have full quadratic form then everything
depends on whether this is the positive
definite form or sort of negative
definite form so if theta square is
bigger than 4,000 this is a negative
binomial process when I say type because
what i mean is affine transformation
that is i'm requesting why to have mean
0 and covariance minimum st so you have
to multiply to assume you have to
subtract the mean of the personal
process you have to scale it by
something related to lambda to get there
and then if this happens to be a
complete square i thought but maybe this
is not a complete square but theta
square equals 4 tau is when whitey is a
gamut I process so you have a gamma
process and the third possibility is
unfortunately lesser-known process
called hyperbolic secant process so
basically what I'm trying to say with
this slide is that if you are interested
in putting together pair of processes
like I did with the Poisson process with
this one example then the only the only
options for such processes are really
and the only interesting options or
Poisson process now
got a binomial process gamma process or
hyperbolic secant process these are the
only processes that are worth trying to
randomize parameters in them and trying
to put them together into a quadratic
reminisce so well I mean one would like
to put a quadratic hardness but that the
trouble is that so you be sort of know
the distribution of the bridge and we
sort of know the distribution of the
right-hand side bridge what we are
missing is the distribution of z1 I mean
I said z1 happens to be 1 plus Z one
happens to be exponential in my
particular construction and somewhat
simpler version of the question is to
say let's be not too ambitious let's not
try to put things into a quadratic
hardness let's just try to put
everything into a martingale so a pair
of two independent Poisson process with
parameter lambda lambda if you capital
lambda has exponential distribution then
we can actually put them together into a
martingale other any other capital
distributions that we could use or we
can take a pair of negative binomial
processes these are levy processes I'm
just writing the distribution of Y T
which is this ugly expression and there
is a parameter pi which is random and
can we put them can we find a pie that
this will make a martingale well
quadratic hardness perhaps but at least
a martingale for the gamma process the
natural randomization to do is actually
the gamma has two parameters and the
scale parameter is what you want to
randomize so you can just as well say we
take two independent gamma processes
with x1 being exponentially distributed
and we ask can we make a martingale out
of those by changing time correctly and
by choosing the distribution of
multiplier w correctly and then
hyperbolic secant process luckily the
slide is hidden so that most people
cannot see it and that's good for you
because because the density is ugly and
has gamma function in it has e to the
Alpha X in it and has parameter alpha
which is
in the interval minus pi PI that's the
parameter we actually want to run demise
well so you sort of saw the answer for
the poor soul process at least a little
bit so let me try to say first sort of
so there's this we have this five or so
theorems that are all identical and one
of them says suppose that the process is
conditionally negative binomial and then
come suppose it is conditionally
hyperbolic secant suppose that they
suppose that that so suppose that we
have a YT for not one of those processes
the Y T and Y T tilde later happens to
be conditionally negative binomial
process well the first thing that sort
of surprised us is that no matter what
the pie is the process is actually
Markov I mean maybe for the audience
here that's obvious but for me for us it
was a surprise then this process is a
markov then if we assume that this pie
has enough moment so 1 over pi square
integrable then we can sort of make out
this is one of those transformations
that we are talking about so in other
words I can transform the process y into
a new process ZT by this affine function
Mobius transformation not that
complicated not that different from
those things that we saw previously
times 1 minus T and subtract the mean
and that will make it into a quadratic
hardness for all the t's that are
available here so all the T's in the
interval 0 1 and you can compute the
parameters which you don't care and the
value of C also depends on the moments
variance and mean of the randomization
thing so basically what this says is
that every random variable pi will work
to produce a harness well that make us a
martingale well I said previously that
harnesses are without even quadratic
harnesses those harnesses are marked in
case harnesses on 0 infinity are
martingales because you can pass with
you with the right hand side
conditioning to infinity and this is on
0 1 don't have to be
martingales so this is actually
typically this is actually typically and
it is YT / z t / t or something like
this is a reverse martingale it is very
rarely a martingale so here is a theorem
that says when is that a martingale the
thing that we constructed that I
described a moment ago so suppose they
take this random variable pi such that
it has the first moment and suppose that
y is the spy conditionally negative
binomial process and that ZT is given by
this kind of transformation except i am
not even assuming the second moment of
pi so I'm saying there are some
coefficients that make this a martingale
so I sub say suppose that ziti of this
form is a martingale well this is
equivalent to PI having a very explicit
density this is equivalent to PI having
a beta density essentially p to some
power x 1 minus p toes and power times
the normalization where a and b depend
on what you used in the normalization
and this works out backwards correctly
so that then this random variable has
the variance and then the all of those
things match together so I don't know
how known is this theorem so what didja
know we prove this for all five
processes and we were fairly happy
because every time we prove this we've
sort of had the proof they were similar
but they were not exactly the same and
then we eventually we ended up thinking
well wait a minute we have a new
property of a Poisson process because we
have a similar thing about the Poisson
process as well and then we thought is
it realistic to expect to have a new
theater and about the Poisson process so
then we should have used bing but we
used google
and we found a paper of necrotic in from
2007 that was essentially saying Martin
gave property of randomized to a song or
something like this or maybe it was
saying polio processes as randomized but
that was definitely Martin this was
exactly this kind of result except for
personal process but then once we found
this we sort of said well why don't we
search more so once we searched more we
found a paper of the econo sandy will be
soccer on conjugate priors for
exponential families we wouldn't ever
look into that paper without google
search because this looks like complete
statistics and appeared in statistics
journal and it's fairly old to which has
exactly the mathematics that that leads
to this I mean has more general
mathematics because all conjugate priors
for all exponential families but surely
it implies this result it doesn't
actually imply poor soul case for some
technical reasons about the supports so
for puesto case one has to go back to a
paper of johnson from 1957 which does
the same thing but only for personal
case so once we know this what we do
next is we say well i'm still continuing
this example of negative binomial
process does not to repeat the puesto
every time so suppose now that I take
why and why I should have used tilde
like previously but i forgot to be PI
conditionally independent negative
binomial processes and let's assume that
pie has mean and the variance and then
we define this process that that's the
previous definition of the process I
used for martingale this is time inverse
of this process with y prime and this is
what I need to do in order to assign the
value for t equal one so this is 1 over
pi standardize this is 1 over pi minus
its mean over the variance I am supposed
to have coverage of ZT suppose the body
a sub city is supposed to be T then by
construction this process is time
invertible because I use the same
formulas the time in verses of the
formulas here and there so actually this
time invertible process
and then I can sort of prove a great
theorem that says well the following
conditions are equivalent ZT is a
quadratic harness on 0 infinity that's
what I want to get really well if it is
a quadratic harness part of the
definition it is a harness so okay one
implies to QED well if it is a harness
there's a limit only to take harness in
with minimum st covariance implies a
martingale so QED and the last fact that
I showed you the econo still be soccer
is it is a martingale then on all T on 0
infinite I should have said then it is a
martingale on 0 1 if it is not given 0 1
than the previous theorem says that pie
has this very specific beta distribution
and the only thing that remains to be
proven is that for implies one which
amazingly works on exactly the same
identities that you get to get from
three to four so it's sort of so the
same kind of results whole four pairs of
Poisson negative binomial gamma
hyperbolic secant processes we actually
work them out the first couple of them
we worked out as exercises because we
knew the answer from a paper that we
wrote in 2006 so the mountain air
conditioned on 01 the term is the law of
randomization and then the correct law
allows us to continue the process to t
larger or equal than one and then the
correct law gives us actually quadratic
harness so this happens for puesto
negative binomial gamma and hyperbolic
secant processes and all of the loss of
randomizations with a small disclaimer
about the poo a song can be deduced from
the econo still be soccer paper so we
don't really have to work as hard as we
did and in particular a pair of lambda K
so this is sort of a summary of the of
those results saying when can you
actually glue together into a martingale
also inter quadratic hardness a pair of
conditionally independent Poisson
processes well if and only if the
randomization has gamma density which is
written here and we knew these answers I
say from the pre paper that we wrote a
long time ago this is not that difficult
to guess that gamma density goes
with person you can sort of do values
formulas a pair of pi conditionally
independent negative binomial processes
Mathematica donne 0 infinity or a
quadratic hardness if and only if Pike
has this beta density this ayah perhaps
I wouldn't be able to guess but the
other class was he was able to guess and
we sort of you know sort of based on
values analogies between those two
formulas and this kind of theorem that
you get a quadratic harness with this
density is actually a master thesis
student student wrote up the complete
proof unfortunately available only to
people who read polish as it's in Polish
so this is sort of student type
assignment then a pair of gamma
processes with multiplier x random
variable makes a martingale on 0
infinity if and only if W has won over W
has a gamma density or W has this
density which is the density of 1 over
the gamma and this result is also easy
because you can get gamma process as a
limit of negative binomial processes and
you can read out the answer you can read
out what randomization you can need to
do so we did those three cases solely to
learn how to recover from martingale
condition the density so that we would
not where we knew the answers solidly
because we had no idea what with
hyperbolic secant process so here is the
answer for hyperbolic secant process
while the hip hyperbolic secant process
has this parameter alpha which is
between minus PI and PI and this is a
martingale that pair of to HiPo in the
conditional independent hyperbolic
secant processes are a martingale and
also a quadratic harness if and only if
the density of the randomization is
given by I don't know how to describe
this I think we even don't know the
normalization constant I think we didn't
confirm that
so this laws that define z1 this law
defines the law of z1 for the
decomposition of a quadratic hardness
into the lady bridges that I was talking
about in the previous theorem so I have
two minutes for conclusions so one thing
that I want to say is that after going
through all of those exercises I I would
be able to recognize the existence of
this special time capital T if you give
me a process that has two sided
regressions that are linear and
conditional second moments and the
product covariance of this form if I if
you would give me all the parameters and
I would be able to tell you whether
there exists a capital T like this or
not essentially by computing values
algebraic things about the parameters
and then if this will happen to be the
case then I would be able to tell you
whether that's a pair of was so negative
binomial gamma or hyperbolic secant
processes so the example they was
showing in simulations was the Poisson
process the Paso and negative binomial
process if you really were able to
observe trajectories you see that they
follow lines and go up and then the time
reversal of the process so it goes you
know follows demise goes down the other
two gamma and hyperbolic second this
even if you saw the trajectories I think
you wouldn't be able to read that there
is anything special about t equal one I
don't know how there is infinite number
of jumps before T equal one and if you
had number of jumps after one in all of
the cases and I guess I squeezed the
talking to 40 minutes so here are the
two authors and here is the person that
was hiding on the lower part of the
slide
so I just want to make sure that they
understand that losophy of this project
because um it seems to me that you know
the first question is why would you want
to construct the process from two
processes if you think well I mean okay
so I'm trying to look at because there
was this joke about the earth break or
something so amazing I am are you saying
that this is supposed to be a model or
some phenomena where there's a
distinguished time I would like it to be
but of course not for earthquakes
because they are spatial and so on and
there is this i forgot how something law
which they're all something low fits
those processes but everybody uses
modified or something low where you put
a power law instead of 1 over t type
things so the intensity of gems for this
process on the interval 0 to this
capital T is of the form 1 over T so I
don't know does that make it a model
good model for earthquakes probably not
because they are spatial as well so I
would like it to be models for something
but our original motivation was that you
can write down this quadratic fire
hardness formula and you say let's
consider process with the following
conditional moments do those processes
exist so we were largely in the business
of saying can we construct a Markov
process that would be a quadratic
harness with the following parameters
it's part of that sort of bigger
strategy of finding processes enough
examples of processes
you might have already answered me a
message appeared in a recent paper of
mine and visually path and which are
setting that paper that there are some
simple examples let me processes and
reproduce so instead of some kind of
theory or characterization of all
harnesses for interesting furnaces
harnesses days I think too many of them
what harnesses that have also second
order moments that exclude for example
lots of lady processes there's only five
of them so there's better hope for that
and for this there is almost a theory
meaning modular technical assumptions
they all have orthogonal Martin a
polynomial are askew Wilson polynomials
except those those are actually outside
of those as he wills and polynomials and
they are not limits of those either so
so in a sense this is we are playing a
game of here is the set of parameters
that you can put in this quadratic form
we know what happens here we know what
happens there well here is the boundary
that we don't know what happens that's
the boundary
and there are still unknown regions that
we don't know what happens sound ages
between this boundary and the other
boundary which you get from a skills
all questions
let's finish me</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>