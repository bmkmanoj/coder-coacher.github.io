<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Reasoning about GADT Pattern Matching in Haskell | Coder Coacher - Coaching Coders</title><meta content="Reasoning about GADT Pattern Matching in Haskell - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Reasoning about GADT Pattern Matching in Haskell</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/xCwtN9wUjtA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
it's actually what I'm going to tell you
about today is how we solved the problem
of bogus overlapping warnings duty used
to issue for the past eight years we've
been working on this with professor
thom's drivers and the meters with
annuities Simon Peyton Jones and
Nicholas purpose built from wish so
let's start with the basics well
functional programming languages like
Haskell or ml the use of the break data
types structured their their data
typical example is a list as you can see
here when we define a list we represent
its list every list may either be an
empty list or the concatenation of a
head and the tail of a list which
represented with constructors Neal and
cons respectively once we've declared
the data type the only way to construct
values of this type is by using the
constructors alone like for example here
L is the list containing integers 1 2
and 3 and this created only using
constructor scones and Neil now once we
have the data what can we do with it
well the the main way we have and
functional languages to inspect yes to
inspect an extract information from a
term created by constructors is by
pattern matching for example foo here
text arguments still lists and depending
on the structure of these two lists
either returns one two and three all
through the example without here we go
foo on these two lists as you can see
the value the arguments both can match
the first Clause so GC returns us to one
while have you call it with these
arguments you can see that although the
first argument can match the first
pattern of the first Clause the second
one is an empty list so it cannot pass
the first so
who try to match the second Clause a
Welker represents I don't care value so
we ignore the first argument the second
argument is an eel so we must and we
return to what I wanted to show here is
that a house called sputtering massing
always performs a top-down and from left
to right in the sense we always try to
check to matts against the first Clause
first analysis from left right if we
fail then we try the second one etc etc
right well what will happen in this case
as you can see here at first argument is
an MP list and the second one is not and
none of the clauses we have for full can
actually be must with these arguments so
we get a runtime error well that's not
what we would like to have from a
statically typed language like Haskell
where we want em we want some guarantees
from our type system and in this case we
want to know that if a term is well
typed for example ah but cold tofu there
if the term is well type then where we
don't expect to have a runtime error
fortunately we can be warned about such
cases by enabling this flag in GHC if we
type again the definition in we get a
warning of this form which simply says
that AA any possible value combination
that is an instance of these two
patterns will not be masked by function
foo and will give us back around time
error one more example here what will
happen in this case as you can see here
the two arguments we give to fool are
two empty lists and this perfectly
matches the third clause but it also
matches the second class like I tell you
before a haskell performance but imagine
always top down so we will not get a 3
in this case but it too and not only
that there is no there is no way we'll
get a 3 in this case because all cases
covered by the third clause are subsumed
by the second clause so this means that
the third clause is actually dead code
fortunately we can also be warned about
that by enable
this flag and tapping again a definition
we get a warning of this form which says
that the third clause can be safely
removed from the match without affecting
the semantics of the program at all now
well ah everything seems Rosie thanks to
JT's exhaustive pneus never Lapid
checker yes it's based on an algorithm
designed in 1994 by Martin get for
compiling pattern matching actually and
was adopted adjusted to work for the
warnings well now we come to the problem
in 2006 generalized algebraic data types
were introduced and juicy and since then
things are not so rosy anymore first of
all what are GE tease author name
indicates generalizing directed types
generalized data normal data types so
for example here I've defined vectors
that are length index lists as you can
see i have named the constructors the
same way as before but the difference we
have here is that the type constructors
vac takes apart from the type of
elements it contains it also takes a
natural number at the level of types
which indicates the length of its vector
so in this in this sense Neal here it
returns a vector of length 0 while cons
returns the vector takes an element of
like a a vector of length n contain
elements of type a and we get a vector
of length successor event that means n
plus 1 in this sense now we have more
precise types and we can represent parts
of the structure of our I'm sorry of our
terms in the types now we can do all
normal stuff with deities like we could
with a DTS but we can do even better
stuff like this here have functions if
that takes two vectors of the same
length which is indicated by the usage
of the same type variable and here and
we also have the same and in the result
which means that we ask from the type
system ax
little to prove this property of this
important property of zip for us that
the lengths of the input vectors will be
the same and also will be the length of
the output vector well the problem is
that if we type this in GHC we get a
warning of this form of this form and
it's kind of expected like we've seen
before because actually these
combinations are missing well actually
it is a huger Seacrest wolf because both
these combinations are ill types if you
recall definition of egg here we ask at
the signature we ask that these two
variables are the same but if you check
the types of the data constructors this
can never be unified for whatever and we
choose right so these are both ill typed
well what most of us doing this case is
if GE T is a warning that something is
missing then put it in ourselves well I
hope fortunately if we type this I've
added here the first vector if she does
missing we get an error a correct error
that 0 cannot begin fight with successor
event it's makes a lot of sense because
these two vectors have different lengths
and this is good because it means that
our type system is expressive enough and
can detect dead code like the last
clause here statically now but the
problem is that what can we do in case
we don't add the clauses to get a
warning if we add them we get the nurse
so most of us what we do we silence the
compiler with a cat soul close like this
where we say that whatever else doesn't
match the first two clauses well that's
what you do and we know that this case
actually covers nothing because all ill
all well typed combinations of values
will be matched by the first two clauses
and unfortunately we don't get a warning
for this so we have two problems first
of all we get false alarms
guarding exhaustless we get warnings
that function is not exhaustive well it
is and also if we add close of this form
we do not get warnings that some of them
are overlapped while we should well the
result is that most programmers do not
trust the emitted warnings of GT anymore
I mean this problem has been up for some
years now and also there is most of them
use this technique with overlapping over
the last development pattern just to
suppress the warning even some of them
just turn the warnings of well none of
this would have happened if we've did my
way ah instead of describing it in
theory i'll just so an example a typical
example of this presentation well while
the general idea is this before
examining our function we just consider
everything missing right if we have no
closes we cannot handle any possible
value combination so we start aah at
first everything is missing which can we
can represent with two wild cards and
then we inspect the first Clause what
happens here the first Clause indicates
it starts with an ill and indicates that
we will force the valuation of the first
argument whatever that is and if it is
an ill will continue and evaluate the
second argument to check again if it's
near here so the first thing we do is we
split this to general wild card into
accounts and Tennille which are the
different data instructors we can have
for the first argument now as you can
see here although we split this in these
two our first cloth starts with an ill
so it cannot possibly much or
contributing covering this case so all
patterns of this for our at this point
uncovered if we get I mean if you
consider that we have only the first
Clause of the mats and someone gives us
this as a first argument we cannot match
well um
less we can contribute we can contribute
and covering in this case because we
start with an eel so we do the same
thing and we expand the second wild card
into accounts and Tennille because we
want to check for quality here the same
reason as before this case cannot be
covered by the first Clause but this is
exactly the first clause so this is
fully covered by a clause now what we
have to hear we started with an initial
set of uncovered cases values that you
cannot cannot be handled by our function
and we took into consideration the first
clause and we got what cases does the
first Clause cover and which are still
missing now what we do is we repeatedly
do this for every clause and we
repeatedly transform this set well at
the end when we have checked all the
clauses we will have information both
about which cases are covered by every
clause and also which cases are not
covered or handled by any of them well
let's see the second one or something
important here you see by construction
by all the uncovered all the other
vectors we generate to base it as
missing I are disjoint so we can check
them separately and then just get the
union of the results get back a final
result for example here we have a
mismatch the second closers with a
constant you have an eel so this remains
uncovered we did the same thing as
before right here we have we both served
with accounts so we match the first
argument and we split the second
argument into an alien accounts this
remains uncovered because we have a
mismatch and this is full of coverage so
we our figure looks like this now ah yes
I don't think I have to step through
this obviously the last gloss covers
everything we took them separately we
must the first one was the second so
both of them are covered
and our situation looks like this well
the inputs of our elgar was just the
clauses the three clauses and the output
is both the cupboard cases here with
green and the orange cases not
intermediate ones just the final ones
let's represent all cases that are still
uncovered although we've checked all the
mats ah yes I'll probably go for that
well now until until this point
everything looks I mean if we should
warnings right now we'll get we would
get the same results as we get right now
GHC amatis consider total if the final
set of uncovered cases is empty if
nothing is missing then everything is
covered right well what we don't force
here is the world tightness and what GG
doesn't do is this exactly this here
also further duns check to consider a
clause useful it has to cover at least
one case so we need a set of work out
well type cases it covers to be
non-empty so now the second phase of the
algorithm performing like this we have
the signature and we have um it's like
every clause that our algorithm
generated both covered or uncovered
green and orange boxes the first one
passes the test with an equal to zero
the second one as well with successor
event for some n now the third one fails
as we said before because it will
pathetically try to unify 0 with
successor of em and knowing so no such
an exists so these two failed to pass
the test and we end up with a figure
like this now this means that this the
first Clause is useful because gather
some things the second is useful as well
now here we can see that we can emit a
warning about the third clause which is
actually redundant that we knew but in
order to see that at gtc gives us
something like this but in order to see
that we'll have to get the empty set
here and also we know that it's all
because the final set of uncovered cases
is also empty well I was quite fast but
I've shown you I yes I was bit brief and
we briefly saw how bout you matching
works in Haskell I've explained a bit
how the basic status checks for pattern
matching works the Palean redundancy
I've explained you how the incremental
approach works which we designed and
it's quite easy actually I didn't show
it here just implied that it's really
easy to check that the pattern vector is
well type in GHC since we have the
existing infrastructure well what I
haven't discussed is that we have
formalized the algorithm and also have a
prototype implementation at GHC we
support guards and literals as well and
we reason about laziness and also we
have formalized that this part of holy
but partially and are your formalization
and also we have tested our
implementation on both on GH see what
everything is structured using a DTS and
ATT CDs and pattern matching right so we
had plenty of test cases because you see
performances with strumming and also
we've rented a suite and wishing perform
as expected on every test case and also
we have I remember correctly six or
seven cases where we get even better
results what we plan for the future well
we would like to optimize implementation
both in terms of space and time because
I would like to be a part of GT 710 also
it would be nice if we could get a test
case study on the harkins libraries
because a lot of them not only just to
check our implementation that works as
expected but also a lot of libraries
many libraries use GED tees and cases
like the one I showed you before with
overlapping pattern at the end
can be detected and now safely removed
from all these matters and so we would
like to improve this libraries also what
we would like to do in the future is to
to represent and handle formally and in
our implementation more of Jesus syntax
extensions like Bank patterns few
patterns patterns inner loops and so
many others before we would like to have
to improve a bit the reasoning for
guards and that could be done by
plugging in probably one of these tools
and maybe more yes I think this is it
well thank you very much yeah I would
like to have a lot of them actually have
backup slides I never expected to finish
socialize yes I've written down the
mouth and I've sketched a lot of
important properties like the disjoint
pneus I told about before also of course
termination and some things about
laziness which I haven't discussed much
here I mean um well I've formalized the
syntax main all syntactic forms and the
semantics I mean it's an ongoing work
but at least the basics are all proved
to be to be working right yes do come
yes a Brazilian we also the optimal is a
pattern matching further you generate
get the information you password yes we
could probably propagate this the
compiler yes I am actually we can do
this but I don't think it's it's so
important because what we can do is
really cheap is to just remove the
overlapping patterns I mean if something
is really redundant we can safely remove
it and save ourselves some code right
but about the exhaustion asst as the
only thing that we really get from
from this is that we remove an
if-then-else at the end right I mean if
the final case covers everything then we
don't have to produce an else cross
which ghz does if something is not
exhaustive I mean if nothing they both
work but yes probably we can do that
when we do far more reasoning I haven't
discussed here we also check which
Clause covers which case which cases and
in which order are the arguments forced
so maybe this is more important
information that we could propagate
probably to the compiler it's a
compiling of sputtering yes it can be
done a lot of Luke maje maje noise work
was about generating an efficient to
otamatone to do maximally efficient
matching and they don't quite
complicated but it got very good code
out of it here your stress is on a kind
of fairly intuitive one equation at a
time propagate the cases that don't
match story which doesn't mean lead to
an efficient algorithm at least a good
error messages so I think the emphasis
are a bit different and it's never been
very clear to me whether Luke's
techniques would make a lot of
difference in in a lazy language we more
or less have to match in the order
specified anyway so we do match a kind
of column at a time just like you know
every decent compiler does but most
really do much better than that I think
that this way we can extract more
information about the mutts example of
some of an optimization you might get as
a result of this ah told you already the
simplest fun we can remove all much that
forgiveness um okay its one sitter
entirely we're done it he's gonna throw
them away fun yes aside from that yes
about the exhaustive pneus I mean if we
know I wouldn't do it actually but wait
here since we know that the second
Clause I mean the third closet we've
done that we can remove it and in this
sense the function with only the two
first clauses its total so in a sense if
we don't match the first Clause we can
match the second right this is not true
actually because we have to force the
arguments first to see if they are real
terms or they diverge right so I don't
think that we can get anything useful
out of it I mean even if we know that
there's no other case it's either the
second one or we fail after that because
of divergence we have to force the
arguments to check that we want diverts
right so I don't think that I'm giving
index type with like five constructors
and only two of them apply for that
particular out of the index then you can
avoid you know once he tested the first
one and muscle video must be it must be
the other one on that test yeah if you
know that something I mean for example
we don't have to check the first Clause
if you mean that at that I'm sorry
Emerson is this forcing businesses you
do oh wait I mean if we're here we know
that we didn't match the first Clause
and we're checking the second we don't
have to force the valuation of this
because we already tried too much with
me so we can avoid one check right
well do because the first match may have
felt on Neil or on the second Neil you
know you don't you know that the second
one must be no no now we're checking the
second clause which means that the
checking before failed is the first but
we don't like it felt here or here the
first was no second one what we bought
him but you see what I mean this was a
strict language then if it was yes all
this problems just appear and Haskell
right because it's lazy cannot be bottom
in this case right yes compress it well
water does it call so we yes but it must
have been constants bottom right to be
here I mean it might either be cons
bottom or consequence we have to check
the second argument anyway here because
what you have to evaluate you know so
tester yes yes the city we can't avoid
it what's all that seems that the type
system is not really taken into account
that as it is before you are extensions
it's not taking to account that for
general ADT's certain combinations are
simply delete them and what we ate it is
it's always legal right it is the fact
that that only those two patterns out of
the possible for patterns yes are
actually sensible seems to be something
that could be probably I mean the type
checker does the reasoning but enjoys
here these are two separate checks the
issuing of warnings and the compliation
itself are different in different phases
of combinations so
the traditional ml lat lunges or Hindi
Miller lab languages but not exhausting
asst was not count that directed and
that has remained the story in GHC and
that's not its factory when you got when
you could use index types and that's
what this work strategist Pierce esta
protects negative information to camp
and generates more efficient pattern
matching it seemed that might actually
fit here right then you get maybe other
sources of negative information which
will be the type here so if you use you
haven't even months on a computer
clothes then you know that's definitely
not sometimes not deemed or it's not
yeah that's not function evaluation will
suspect emotion yeah its most of these
are in marriages or the following up but
yeah if it's on yeah pretty much these
are all in there I think but they and
they're all in a camel as well but its
strict so you to avoid up here and they
don't have charities so we do have we do
when we have this optimization yeah we
have the optimizations based on the
exhaust divot e on the types as well oh
cool I think I'm not mean I'd rather got
into I know gene is indeed going vote
fairly recently yes yes versions for
Jack Rachel I don't think irritating
about it but its enormous it seems me it
seems to be essentially the same as this
algorithm roughly acceptable yeah they
stay close well actually laziness is
quite important here it's a bit strange
that I have this one my backup slide
some of the basic ones well ah laziness
we get an additional case until now we
had useful redundant but with laziness
forget something more consider this
example it's simple ADT right the second
Clause is considered useless by ghz and
by us but it's not because if we call it
this way will fail too much the first
Clause because of the false will try too
much the second
Klaus and we'll evaluate the first one
and we'll cross if we remove it of
course we have different semantics and
we get a three right so this is an error
event with the algorithm I presented you
before I mean I didn't include them the
strictness thing ah how to call this ok
yes now with JD this becomes even worse
I say we have these two data types as
you can see f1 and g1 our index by int
while f-22 our index by two different
types right if we have a function like
this if a ga the only reasonable value
to give here is f1 and g1 all other
possible combinations f 1 G 2 F to G 1
and f 2 G 2 are all little types yet if
we add this as a second clause what does
the algorithm give us start with empty
and the first Clause and we get this as
missing and this is the case cover a
given ok there's no reason checking this
now the thing is here the first claw
seems to cover f 1 z 1 and the second
one covers f 2 g1 and these are them
covered both of them are ill typed this
is also typed so we get that ah the mats
is exhaustive nothing remains uncovered
and also the second Clause here is
redundant because this is ill typed but
if we remove the second Clause because
it's redundant ah then we get these as
missing the first ones ill typed but the
second one is well typed because f 2
let's type f car and wild card may have
any type whatever
that was fast kindness my point is that
what we get here is that we gather the
second Clause redundant and that we're
total but if we remove it we're not
total anymore why does this happen right
this is inconsistent because what we do
here actually the second Clause is that
well okay we ignore the first argument
but we know that it's forced right by
the first Clause and then we force the
second one that's what as you can see
here the second Clause implies the cases
where we have F to G 1 right there's
nothing else left with g1 as a second
pattern so what about the second class
is it useful is it redundant is it what
I mean my choice series be different
well what this does actually it
eliminates this pattern it doesn't I
mean it filters out at the bottom at the
second argument which is not forced by
the first Clause right the first Clause
will force the second argument only if
the first one is an f1 in any other case
we won't force the second argument will
stop matching the first course well so
we have these cases I close my cover
some ah something that isn't right here
I mean well typed everywhere right so we
may cover some well type cases in this
case were useful right may cover no
cases and not force anything so in this
case we're totally redundant look of the
third case which can simply we can
really easy detect with my algorithm
because every time we branch here ah
structure does not help g1 say it's just
give me a split second
yes I didn't solve intermediate steps
that's the problem well z1 here splits
this into F to G 1 and F to G to write
every time we have a branching this
means that this clause forces something
and we can easily detect this because we
do the branching right so in case we
have a branching we should different
warning of the form like this clause
covers no cases but it's for some
evaluation we don't know what to do with
it yet but i think its scientific point
of view it's quite interesting to see
what's going on and it's I mean it's
quite novel because no other language
right now has both gt's and laziness at
the same time this is the only way this
can appear I wanted to save these funds
will never return to ah yes but the
second Clause is useful because if we
call it with f2 bottom it will crush and
it's quite different because if we
remove the second clause and we call it
with f2 bottom we will cross due to non
exhaustive pneus if we keep the second
clause will crust you to the valuation
the month of irritation right it may be
it may be an error something so we get
the warning on the screen but if it's
just a loop when we will look for ever I
mean there are different things right
that's what I believe I mean yes it's a
problem anyway but I don't know from a
methodical point of view it's different
what is the first one crashes been seven
years yes okay semantical they're
different
we model them both witness symbol but
okay echoes is 15 years ago more
semantics of emphasize exceptions that
specifically is trying to say that maybe
we shouldn't care too much about
different flavors of bottom if that's
going to mess up your optimization
strategy well at this point are we have
inconsistent results though I mean you
have to do something about it right we
cannot simply say that it's redundant
because will do the same as happening
right now that the program will say okay
let's remove this it's redundant and
well you get another warning like whoa
you're not exhaustive that's maybe
really is redundant what happens if you
remove it and you read not even such a
woman right was after all all of the
silly that was Tom suggestion um he told
me that because this is something that
appeared just right now it's Noble it's
up to us to make the right design choice
so this is another option yeah I think
it's a good idea to saying that you
shouldn't get into the regardless of how
he force things you are not going to get
to them to any other case in the first
one so it's never going to return to Los
by underscore underscore patterns and
then you can in any other way of colonia
and getting too that's true even with
our albert and intended semantics or if
if we replace the second way with an f
to underscore which is the same as
understand or in this case it will still
work and we'll get it to its really non
exhaustive
well the best thing to do I think it'd
be due to bang the second pattern so it
will be strict but it's difficult to
detect that there are any more persons
there are so a georgian dominantly with
us for the rest of this week is supposed
to modern friday so they are some of the
foreclosure you feel like talking with
dentist to me are just double-click but</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>