<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Our Robots, Ourselves: Robotics and the Myths of Autonomy | Coder Coacher - Coaching Coders</title><meta content="Our Robots, Ourselves: Robotics and the Myths of Autonomy - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Our Robots, Ourselves: Robotics and the Myths of Autonomy</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/M0-tafxh7gc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
good afternoon thank you all so much for
coming my name is Kat Randolph
I work in Dax and I'm not normally the
one who has the privilege to introduce
the authors but it is a special honor
for me to do so today welcome so much
the Microsoft Research visiting speaker
series I have the great honor to
introduce my dear friend David Mindell
who's here today to speak to you about
his new book I've had the pleasure of
knowing David for 30 years when we first
met as undergrads and have followed his
amazing career all these years and the
thing that's always impressed me about
David is his ability to combine a deep
passion and curiosity about science with
a talent for the humanities and the
ability to tell stories when I was in
business school and he was finishing his
PhD at MIT I would go visit him and he
would tell me all about the work he was
doing studying ironclad warships since
the Civil War and tying it to literature
and history and the war itself in
decisive battles and he had me on the
edge of my seat so today he's here to
talk about his new book and this is his
will be his third award-winning book
he's written two award-winning books
already and I'm sure the third is the
charm his first two were called iron
coffin and the second digital Apollo and
he wrote both of them while he's been a
professor at MIT as a dinner professor
of the history of engineering and
manufacturing in his career he's worked
at Woods Hole the oceanography Institute
and Cape Cod and other places where he's
had the ability to do cutting-edge
research and and on various areas that
he'll speak about today with his new
book so welcome David
thank you it's a pleasure to be here
pleasure to see my old friend Kat and to
join you to talk about this topic the
book just came out last Tuesday so it's
been pretty interesting just sort of
seeing the initial reactions as of yet
it's maybe not quite as controversial as
I hope it will be I got one email
telling me how completely wrong I was
although I responded by saying when you
actually read the book you'll see why
all of your objections are not quite
correct and the book is in some ways an
extension not only of my prior scholarly
work but of my last 2530 years working
as an engineer MS cap mentioned my my
previous book was called digital Apollo
and was a story about the development of
the Apollo guidance computer which was
and and how it actually played out on
the six lunar landings for the Apollo
program it was built at MIT the
programming was done at MIT and it's
relevant for this story and in fact I
talked about it in the new book when the
Apollo computer the contract was first
issued the engineers who were working on
I said well this this is a computer it's
gonna fly to the moon all it needs is
two buttons one button labeled go to
moon and one labeled go to home take me
home and by the time the thing actually
flew seven years later you have this
scene which is the it's actually the
cover of the book but it doesn't you
can't see the whole thing on the book
which is Neil Armstrong reaching up to
turn off the automatic targeting system
and fly it in the legend has it fly the
lamb in manually but actually it wasn't
manual at all it was a fairly still semi
automated fly-by-wire attitude hold
automatic rate of descent mode and what
I learned from this book was really
surprising to me actually even as
someone who had worked and was still
working in the robotics world that in
this case it was it was a radical
forward-thinking
decision to put a digital computer in
the lunar lander and it was cutting-edge
technology both on the hardware and the
software of the day but ironically that
high technology and that great advance
was not used to make the trip fully
automatic and very highly automated but
actually to build this system where the
pilots could actually have very finely
tuned and really in some way finely
engineered levels of control of the
system that they could intervene when
they needed to take control over
handover control in other cases at the
time the Soviet spacecraft had less
advanced computers they were all analog
computers analog control loops but were
more automated and that really kind of
led me to the idea that this book the
new book is really about which is that
the highest levels of technology are not
necessarily full autonomy or full
automation autonomy is the buzzword
today of course and that in many cases
what you see in actual practice is that
as robots and autonomous systems find
their way into the field from the
laboratory they actually have human
interventions added at critical moments
and the book is really lessons from 40
years 50 years of experience in the
field with people operating robots in
extreme environments the deep ocean
where as Kat mentioned I've come out of
aviation which I also spend a lot of
time in spaceflight and warfare and the
argument is those fields have been
forced to adopt robotics before
automobiles and other aspects of daily
life and they've learned a lot of
lessons about how robotics and autonomy
ought at work and those are valuable
lessons to think about as we ponder a
kind of coming robotic era so the book
sort of formulates a new idea of
situated autonomy the highest level of
technology is an autonomy that's
situated within a human environment and
responds well and
waise perfectly of course that's
unattainable to human needs and desires
and directions so if you think about
levels of autonomy is something that
sometimes scholars like to talk about
level one being fully manual basically
the way you drive your car today
- cruise control level 10 being fully
automatic driverless the sort of Google
card impossible dream and there's a kind
of sense even just by thinking about
levels in that way that we're going from
level 1 to level 10 and that somehow 10
is the ultimate goal of the technology
and I argue in the book that what we
really want to look at is the perfect 5
the kind of perfect balance of human and
machine collaboration that doesn't mean
you're always at as a even human and
machine you may move yourself up or down
the scale at any given point but what
we're the human again Allah Neil
Armstrong in this view is in control of
what the levels are and that the system
is responding to what the human wants at
any given moment well let me talk a
little bit about the myths of autonomy
because that's always the first question
that I get what are the myths of
autonomy so I'll read a little bit from
the book on that first there's the myth
of linear progress the idea that
technology or raw evolves from direct
human involvement to remote presence and
then to fully autonomous robots Peter
Singer a prominent public advocate for
autonomous systems in his book wired for
war kind of captures this mythology when
he writes the quote this concept of
keeping the human in the loop is already
being eroded by both policymakers and by
the technology itself which are both
rapidly moving toward pushing humans out
of the loop close quote
but I write there's no evidence to
suggest that this is actually a natural
evolution and that the technology itself
as singer puts it does any such thing
and in fact there's good evidence
presented in the book that people are
moving into deeper intimacy with their
machinery second is the myth of
replacement that the idea that machines
take over human jobs one for one but
researchers have found that rarely does
automation simply mechanization tasks
but tends to make the task more complex
often increases the workload
and certainly shifts it around in space
and time finally we have the myth of
full autonomy the utopian idea that
robots today or in the future can
operate entirely on their own
yes automation can certainly take on
parts of tasks previously accomplished
by humans machines do act on their own
in response to their environments for
certain periods of time but the machine
that operates entirely independently of
human direction is a useless machine
I used to say only Iraq is fully
autonomous but then my geologist friends
reminded me that even rocks are formed
and placed by their environments
Automation changes the type of human
involvement required and transforms it
was not eliminated for any apparently
autonomous system we can always find the
wrapper of human control that makes it
useful and returns meaningful data the
questions that interest me then are not
man versus unmanned or human controlled
versus autonomous but the ones at the
heart of the book really are where are
the people which people are they what
are they doing and when are they doing
it and those are really the questions
that interest me and what you find is
that from the New Horizons mission at
Pluto that was in the news this summer
to Mars exploration Rovers which are
detailed at great length in the book two
undersea exploration commercial
airliners remotely controlled warfare
there's always still human involvement
in these tasks but human involvement is
often in different places and at
different times and those differences
matter they're not trivial by any means
they often change the task they have
social and cultural implications as well
but you don't have if you ask those
questions you'll always find where the
people are so the book opens with a
little bit of history of remote presence
in the deep ocean particularly focusing
around my mentor on the deep ocean who
was Robert Ballard who you may know as
the discoverer of the Titanic this is an
image that Ballard published in National
Geographic in 1981 capturing what became
known as the Argo Jason system with
an oceanographic ship which at the time
the most popular way to visit the
seafloor was a three-minute submersible
called
Alvin which still operates today
operated by Woods Hole
but what Ballard was beginning to
develop was a a theme of teller robotics
where you send a remotely towed sled
that scans the seafloor kind of
digitizes it passes it up at the time
what was a very novel technology of a
fiber-optic cable to a kind of immersive
experience on the ship and then
increasingly small mobile robots that
will come off of our go and do closer in
inspection this system sort of took
shape over the course of the 1980s
actually the version of it that was just
our go before the Jason robot came in
was actually the system that discovered
the Titanic by remote video often it's
confused with having been discovered by
alman I'll talk about that in a moment
and I kind of came into this evolution
as it was kind of wrapping up and
becoming operational being refined in
the late 80s and what we found was that
it didn't make the deep ocean
exploration cheaper and safer but it did
fundamentally change the nature of the
work and so what you were doing when
Alvin would dive it would be a three-man
sphere three people would go down to
scientists and one pilot they would
experience the seafloor they would come
back up on the ship at the end of the
day have a meeting like this and explain
to everyone what they saw with Jason you
can barely see it here but Ballard's
original vision is one person in a kind
of immersive virtual reality type
environment it ended up being more like
20 people crammed into a shipping
container full of monitors I'll talk
about that in a minute and that was a
very different experience and much more
like a real time seminar on the seafloor
these two modes were combined in 1986
with a return to the Titanic when Alvin
dived with a little robot Jason jr.
hanging off Jason jr. descended down the
grand staircase of the Titanic that
scene of course was immortalized in the
opening scene of the second most popular
movie
remain Jim Cameron's Titanic movie in
that movie it was sort of a window into
the history and what's interesting about
these two magazine covers from those
years is that the National Geographic
article which Ballard had control over
only publishes an image of remote
vehicle poking in the windows of the
Titanic Time magazine which was the more
public venue only has Jason and no robot
and I go into this a little bit in the
book about the tensions between literal
pulling on the cable in fact tensions
between human presence in the ocean and
remote presence in the ocean that kind
of played out here this view that I
really internalized about how the
robotics was going to evolve during the
1990s is reflected in this family tree
image from Woods Hole you have Alvin the
kind of old dirt just Alvin's been
diving since the early 60s man
submersible moving up the tree to the
remote cabled submersibles and then you
have this whole evolution of autonomous
vehicles and this is sort of the myth of
full autonomy that we're moving from
direct human presence to remote presence
to autonomous presence and instead what
you see actually is a kind of
convergence of them all these are the
newer vehicles up here Nereus actually
has the record for the deepest dive ever
by any human system and is a hybrid
remote autonomous vehicle it can
actually switch modes back and forth the
people are involved in different places
and this is the kind of myth of linear
progress of autonomy that I'm trying to
counter what you find this is a more
current view is okay here's an
autonomous vehicle working in the ocean
on its own but it's still communicating
via acoustic signals sort of basically
like 1990s acoustic modems from your
telephone lines going through the water
you still always want to be in touch as
most much as you can you may we're
actually moving more toward optical
modems where the ship can lay down a
kind of streetlight in a vehicle
communicate it sort of tens of megabits
through the water and that suggests a
kind of system where not only are you
only partially
the vehicle may go out and swim through
the darkness collect some data do some
tasks and then come back around under
the streetlight upload its data maybe
even operate teller robotically for a
while so you see you're kind of always
moving in and out of this kind of
autonomous mode and of course something
that occurred to me about halfway
through which most of my colleagues had
not appreciated we always thought about
okay the vehicle is autonomous you send
it off the ship it goes in and does its
mission and it comes back but of course
every one of those missions is a
collaboration between a manned vehicle
and unmanned vehicle the manned vehicle
being the ship which is such a innate
inherent part of oceanographic research
people tend to forget it's a manned
vehicle it's the oldest kind of manned
vehicle arguably and all these
autonomous missions are kind of multiple
collaborations between manned and
unmanned and that's arguably a kind of
more more deeper holistic systems way to
view the modes of autonomy so the book
goes through a number of these different
examples I mentioned there's a chapter
on space which talks about the Hubble
repair this is Jeff Hoffman and story
Musgrave doing the early Hubble repairs
the later Hubble repairs are very
interesting human robotic dances as well
the Mars exploration Rovers where you
have a team of folks at JPL operating
through a 20-minute time delay over many
millions of miles still managing to feel
present on a remote planet without the
aid of any of the new great Microsoft
technology that's coming out paper
charts and printed landscapes but they
remarkably feel present in those
landscapes I mentioned the undersea
vehicles there's a story in the book
about this vehicle the Remus 9000 that
found the wreckage from the Air France
447 crash and that story kind of links
automation aboard airliners and the way
that people on airliners interact with
highly automated systems very often in
ways that enhance safety sometimes in
ways that really cause accidents and
cause them to crash perfectly good
airliners there's a story in the book
about heads-up displays and and new ways
that pilots are learning to interact
with the autonomy in ways that keep them
more intimately in the loop for safety
purposes and then there's a chapter on
the predator drone that was operated
still operated very frequently in the
Gulf War our sorry in the Iraq and
Afghanistan of a vehicle that like the
Apollo computer was intentionally
originally designed as a fully
autonomous surveillance vehicle or
intelligence gathering vehicle the
original designers for the predator
decided that they didn't need any
interface at all because why would you
need an interface it's an unmanned
vehicle and instead what you end up with
is these only three of the more than a
hundred and fifty people it takes to
operate the vehicle and you can see
there's 1 2 3 4 5 6 7 8 9 10 11 12 13 14
different
LCD and CRT screens six keyboards for
track balls
eight telephone lines 12 chat rooms most
of them added by the users on top of the
vendors engineering and it's a wonderful
case study of all the reasons that full
autonomy kind of gets filtered out of
the story so I can read you a little bit
from the predator chapter it's based on
a dissertation that was written under my
supervision at MIT by an Air Force
colonel doing his PhD ironically despite
its high technology or a predator as a
human factors nightmare it embodies old
tensions about the identity of the
vehicle itself and of the people who
operate it to people fly it from a
shipping container or small building
their control stations look less like
the latest military hardware than a set
of equipment racks cobbled together by
undergraduate engineers the night before
their term project is due how would I
know about that I don't know to fly the
two main predator operators have to
monitor 16 displays interact with four
touch screens type on four separate
keyboards the main control stick and
throttle are perched high on the console
making them fatiguing to operate for
long periods manned aircraft by
actually becomes simpler and more spare
over the years in their cockpits while
the predator control station has
acquired screen upon screen upon screen
it's a 1990s era confusion of PCs tapes
and drop-down menus when predator pilots
issue a command they experience nearly
two seconds of time delay before seeing
it executed thousands of miles away in a
warzone on a vehicle the curio stations
are not designed for comfort making them
fatigue inducing for long missions one
2011 study by the Air Force even
concluded that the poor interfaces of
the predator contribute more to crew
burnout then the combat stress does now
it's easy to dismiss the predator
cockpit as the product of poor
engineering neglected economics and
inadequate government contractors but it
actually represents the fruits of a
remarkable innovative process where end
users and operators took a vehicle
originally designed for a completely
different task and transit formed it
into a global system for conducting
remote warfare and again very many
similarities to both what happens in
NASA what my experience was undersea and
it's a very complicated story because
they are not physically present over the
battlefield but because of the nature of
the cameras and the kind of a
voyeuristic nature of what they're doing
they become incredibly present and
deeply immersed in the situations
they're watching through the social
relationships they have either with
their own troops on the ground or with
the enemy there they experience PTSD at
roughly comparable rates to which that
pilots who are actually in the combat
zone do and yet the Air Force still
can't get its head around are these real
warriors are they not do they deserve
medals do they not are they entitled to
combat pay are they not it really is a
kind of again I think it's the sort of
pointer into the future about the
confusion about professional roles and
traditional tasks that happens when you
get not full autonomy but this kind of
remote presence who are the people where
are they what are they doing when are
they doing it the answers to those
things matter
surely not so different from the book I
wrote about the Civil War where American
sailors fighting from within ironclad
warships wondered why it was so heroic
to go into battle in that way now
actually I think the Department of
Defense is a little bit ahead of a lot
of the industrial world on this I quote
this piece from from DoD report from
2012 all autonomous systems are joint
human machine cognitive systems there
are no fully autonomous systems just as
there are no fully autonomous sailors
soldiers airmen or Marines and if you
extend that sailor soldier and airmen
and Marines out to factory workers
surgeons computer programmers almost any
human profession you realize that human
work is always embedded in different
kinds of networks and this statement is
a statement by the DoD which has burned
up a lot of our taxpayer money and
gotten burned by systems that seem to be
fully autonomous but then when they
actually got them out into the field
doing a job that either had to protect
human life or potentially could take
human life the human response was what's
it doing now and the company that we're
just founding Hugh Maddox which we'll
say a little bit up at the end we're
taking this as one of our kind of
symbols of you never want people to ask
that question about your system and full
autonomy can be very scary for people
they don't like machines when they're
not operating the way they want
interesting videos coming out just in
the last week about people operating the
autopilot the new autopilot features on
the tesla car and doing some surprising
things at 80 miles an hour very
frightening experience so part of the
book is a is critical view at how people
have engineered autonomy but then the
engineering me says there must be a
better way to do it and about four years
ago I started working with a partner
Aurora flight sciences on a Office of
Naval Research funded program called
Akos which is a full-size autonomous
helicopter designed to deliver supplies
or into remote locations and that was
the assignment and
we put a bunch of lied R's and a lot of
computers on a helicopter but we needed
to have the system again if you're
bringing supplies you're by definition
going to some place where people are
where people want water or food or
whatever it is is being delivered and so
we talked to the folks who'd be
receiving those supplies in this case
there's a specialty in the marine call
called landing Support Specialists these
are the guys who kind of vector in all
these helicopters and their response was
a full-size autonomous helicopter
bearing down on me no thank you
very scary they'd all been to Iraq and
Afghanistan they said you have no idea
how unnerving it is to look up and see
unmanned aircraft flying around when you
don't know what their intentions are and
who's operating them and what they're up
to we absolutely want to be able to
control some aspects of it especially if
it's coming right at me because that's
what it's doing is delivering things to
me so we ended up designing a system
this is a complicated picture but it
shows you a little bit about the vehicle
comes in it's actually laser scanning
the full landscape with a lidar fairly
powerful custom lidar and actually it's
capable of identifying landing zones and
there's a brief conversation with the
operator on the ground who has a kind of
iPad Mini type interface and the
operator on the ground says I want you
to land here and bring me my I think the
army phrases bullets but butter and
something and the lidar may say that's
not okay I can't land there it's not a
big enough spot there are trees in the
way and offers a few other potential
landing zones for the thing to come in
and then the the human has a very very
simple set of states come in change the
direction or change the landing zone go
around and let me think about it go home
and abort or go off and hold until
further notice and those states are
extremely well simulated and presented
to the user during training and then the
whole system is engineered around those
states this is just a little bit of a
workflow model the details aren't
important but that basic set of states
for the autonomy is modeled in this case
in
lab stateflow and then as auto coded
both into the interface and in the
mission manager so each one of those
states may contain all kinds of
interesting path planning algorithms and
mapping algorithms all sorts of stuff
but the overall macro states are very
transparent and clear and simple for the
user to operate and when we flew this
system off we flew against one of the
big defense contractors and we we beat
the pants off them and we won the second
phase of this contract and now being put
into larger scale pilot testing and for
production one example and yet when this
this article sorry this project is is
written up in the New York Times sort of
the Wall Street Journal this is the
title Navy drones with a mind of their
own everything that we'd engineered out
of that system the press the kind of
public perception of the robot kind of
reintroduced and there's a lot of work
there to be done about bringing this
kind of perception of autonomy into in
some ways a more mundane kind of
engineering mindset but also into the
world of human control sort of parallel
somewhat follow-on to this project is
now a DARPA project that we're working
on to actually put a robot kind of in
the copilot seat to take over
essentially only half of the pilots jobs
in any number of different kinds of
aircraft and here you have to put a huge
emphasis on collaboration human robotic
teaming and again having a very
transparent and simple set of states for
the autonomy to go through that the
human is well able to comprehend that
system was written up by John Markoff of
the New York Times over the course of
the summer you may have seen it it's
actually based on an optionally piloted
aircraft that's made by Aurora and this
is a great kind of new twist on this
idea it's not an unmanned aircraft it's
optionally piloted
there you can put a pilot in the front
seat who can fly it just like a regular
aircraft it can be flown from a remote
ground station like an unmanned aircraft
my favorite mode it actually can be
flown from the back seat through the
remote ground station
just by a pilot or an operator really
sitting in the back seat so these are
all different examples of ways that the
autonomy of these systems is growing I
think into a richer more complicated but
more useful and I think safer
conversation with the human operators
away from this notion of kind of full
automation which I argue in the book is
kind of a 20th century idea and that the
real 21st century idea is what is this
perfect five balance and I'll give you
to sort of wrap up one example back into
the undersea realm which I come back to
at the end James Kinsey a young
engineering scientist at the deep
submergence lab came to his job with
great plans for the autonomy he hoped to
bestow on his vehicles he began to build
up probabilistic models of how the
hydrothermal vent plumes propagate
through the ocean and to try to instruct
the vehicles to follow minut direct
detection from their sensors back down
to the vents over time however Kinsey
realized that trying to imbue that much
autonomy in the vehicle was likely to be
a problem because of the nature of
exploration the tasks are poorly defined
in the environment is changing anything
programmed into the vehicles ahead of
time constituted assumptions models
about how the world might work that
might not be valid in a new context I
think I focused on the wrong aspects of
autonomy Kinsey said you're requiring to
the vehicle to understand a lot of
context that may not be available to us
one of the problems with the vehicle
that makes its own decisions Kinsey
continues as there's a certain amount of
opaqueness
to what it's doing even if you're
monitoring it you say gee it suddenly
just wandered off to the southwest is
that a problem or is that part of its
decision-making tree you can never know
and in his observations people like to
know where their assets are especially
when they pay a lot of money for them or
if they can threaten human life overall
in the ocean the lines between human
remote and autonomous are blurring
engineers now envision an ocean with
many vehicles working in concert some of
them will contain people some of them
will be room
or autonomous and all are actually
capable of shifting modes and at
different times so I'll just conclude
with a little section about autonomy you
can open it up for questions about this
newer way to think about autonomy
situated autonomy the fully autonomous
robot making its way through the
landscape under computer control remains
an attractive idea for many engineers
including many of my colleagues and
friends at MIT perceiving the
environment classifying it matching it
up to models and prior experience and
making plans to move forward resemble
our daily acts of living uncertainties
in the world and within the machines the
unexpected that will always foil prior
assumptions make the problem not only
harder but more interesting thinking
these problems through aided by the
medium of technology is a noble effort
engineering at its philosophical best
how do we observe the side and act in
the world how do we live with
uncertainty but we should not confuse
technical thought experiments with
what's useful in a human context when
lives and resources are at stake time
and time again over decades from the
deep ocean to outer space
we've reigned in the autonomy it's not a
story about progress that one day will
get it right but it's a story about the
move from laboratory to field the
transition tempers the autonomy whether
the task is to respond to instructions
and return scientific data or to protect
and defend human life in retrospect Neil
Armstrong's last-minute intervention
turning off the automation of his moon
landing or turning it down signaled the
limits of the 20th century vision of
full autonomy and foretold the slow
advent of potent collaboration with
humans and human presence the lone
autonomous drone is as much an
anachronism as is the lone unconnected
computer the challenges of robotics in
the 21st century are those of situating
machines within human and social systems
their challenges of relationships and
I'll just close then talk a little bit
about the startup
that I've been working on with my
co-founder here Gary Cohen Cohen which
is an attempt to rethink how autonomy
works in order to make it safer and more
predictable and more acceptable within
human environments making it transparent
trustworthy because again as we think
about what it's going to take to make
robotics useful and economically
productive in the world it's almost by
definition proximity to human
environments human economic environments
are human environments and we're putting
together a kind of newly composed
product team with a whole set of
traditional robotics professions but
quite a number of other forms of
expertise as well based on the simple
idea that humans will remain essential
to valuable technological systems and so
I will leave it at that
and open it up for questions thank you
see that it makes us to me that you know
California comes between a machine a
human played something to decompile the
assemblers of the teams was the next ask
using this kingdom but the real question
is as far as I read about the Predator
drones one for air force another for the
army yeah and the Air Force wanted to
control it so that shall I put the pilot
and the army
operator so they're gonna give high
level wolves and important execute them
right that's a great question there are
two there's more than two but they're
the oh sorry the quest the the question
were comment was that the Army and the
Air Force operate Predator drones
differently they're actually two
different kinds of it's the same
airframe but the controls are different
and the army situation is a very good
comparison because they're the the
autopilot basically does more of the
work because the army doesn't have the
same kind of cultural baggage around the
role of the pilot and in the book I talk
a lot about the Air Force version which
is an ironic situation because the pilot
still sort of flies although most of the
time they don't
have their hand on the stick and the
pilot is an officer and then there's a
person sitting next to them called a
sensor operator who may have just
graduated high school six months before
who actually is the person who's doing a
lot more of the interesting difficult
cognitive work and adjusting the sensor
and following the camera and whatnot
whereas in the army both of those
operators I believe are enlisted and
they don't have this kind of officer
enlisted person relationship and that
just highlights the fact again autonomy
is and needs to be situated how you
implement it depends on the particular
organizational cultural context that
goes into you know in the airforce they
actually say well we have a an officer
who controls the weapons delivery
because these are big powerful weapons
and in the Air Force the officers are
the ones who make the decisions about
human life okay the Marine Corps one of
their mottos is every Marine is a
rifleman right so in the Marine Corps
every single person you know right down
to the lowliest private are tasked with
fighting and killing basically has a
very different kind of way that it
breaks down and if you're designing a
drone it's some way in that case neither
one of them was really designed this way
the army one was a little bit more
design than the predator the Air Force
one because it would came later but it
needs to be situated within the
professional and cultural service
culture there and there are other kinds
of unmanned aircraft in both services
that fly fully pre-programmed routes
where they don't have the ability to
take over control and it can be a very
complicated story but it's a great point
yeah the question of autonomous versus
man applies to planetary space flight
give any any thoughts about how this
applies to that question ah sure so to
begin with there's a whole story about
the Mars exploration Rovers
which of course even the people who
operate them describe them as autonomous
only in a very limited way
so the the engineer on the ground who
gives it commands can give it autonomous
commands to do some path planning around
some immediate obstacles and they tend
not to do that because it actually takes
much longer than just looking at the
picture and kind of drawing the path for
it even so and NASA and NASA PR even at
JPL routinely describes them as robot
geologists but they don't do any geology
of course they collect data given
instructions by the humans and that data
comes through the telemetry link and
again there's great stories about how
rich and experienced it is for the
geologists at JPL or many other places
remotely connected as well and how much
they feel present in the Martian
landscape interesting debates there
about you know Steve Squyres who headed
that program is famous for saying well
you know what they did was great but it
was excruciatingly ly slow and if people
were up there they could go out and
collect those rocks in a matter of a
weeks but of course when you're doing
geology speed of interaction is not
exactly your highest priority and
actually it's in the book I've spent
some time talking to field geologists
who really value the experience of going
out and hammering rocks and kind of
interacting with their environment about
what exactly is it for an environment
that hasn't changed in hundreds of
millions of years that requires that
kind of real time interaction again
you'd think that slowness what what the
slowness does with with the Mars rovers
it spreads out the kind of collective
cognition and time which for science
should be a good thing right there's a
lot more time to be deliberative more
time as we experienced with Jason for
groups of scientists to communicate
rather than the kind of traditional
opportunistic sort of field science
route I think this is even more true
with the New Horizons mission which was
in the news so beautifully this summer
you know that that spacecrafts out at
Pluto it spent the better part of a
decade getting there certainly reacts to
its environment since
certain ways and actually in some scary
ways for the crew the week or two before
the flyby the flyby was pre-programmed
it did its thing really without too much
connection to humans in real-time for
our time delay but still very much a
human experience of that flyby nobody
would say that the the mission is doing
the exploration or doing anything but
going out and gathering data and
bringing that data back home and just
observing and it's not it's not
something that's in the book and I
haven't studied that particular mission
closely although I know people have
worked on it again it's it's a matter of
human effort displaced in time and the
beauty of studying in space displaced in
space at the furthest possible
imaginable way and so there is autonomy
aboard the spacecraft but the autonomy
is limited in space and time and mostly
it's used to
gather the data digitize the world send
the data back we'll be seeing images
from Pluto regularly now as it takes a
year year and a half to download the
data from the flyby and then the
scientists on the ground are the ones
who have the excitement of exploring in
the data they are in a different place
they're not out at Pluto there's no Neil
Armstrong for Pluto at the moment that
does matter right it is a cultural
change from walking around on the moon
but it's still a kind of exploration and
a kind of remote presence so if it's if
there's human situated autonomy on Pluto
you know I would think there would be on
the highways around CL or mount of you
there's a question from online that
there how would you characterize the
momentum and interest and studies around
systems of collaborating robots swarms
particularly where autonomy is concerned
well again I think one of the
challenging things with swarms is
keeping them under human control and how
do you you know it's perfectly a good
idea to design rules for larger numbers
of craft to collaborate with each other
but how do you enable those missions to
maintain some sense of coherence and
actually be effective without completely
overwhelming whoever the operators are
or operator is and it's still a
relatively big challenge to operate one
remote semi autonomous vehicle much the
less many of them what happens when
certain of them start failing and
whatnot there's no question that small
sets of autonomous rules are valuable in
making that stuff work but the whole
thing still has to someday get its
instructions from somewhere and bring
its results back another question here
yeah there's certain application areas
and robotics that get a lot more press
than others like military self-driving
cars delivery drones that sort of thing
is there a particular area that you
think most common people don't know as
much about but that you think will have
a profound impact that's a good question
I mean I guess if you follow the
robotics world there's a lot of coverage
in different places which ones aren't
making their way into the New York Times
I'm not so sure I do think that you're
seeing I mean I think John Markoff who
has a very good book out in the last
couple months about the history of AI I
think if you follow his reporting over
the last two or three years even just on
the Google car it's gone from a kind of
great enthusiasm and belief in total
autonomy to a more skeptical read of
what's it gonna take to make this system
responsible to respond respond to human
needs in human direction and so actually
interesting thing about the book coming
out now I think that the public
conversation is gradually shifting
toward a more kind of situated view of
robotics even the I mean almost
particularly especially the DoD if you
if you followed the DARPA Grand the
DARPA Robotics Challenge from last June
which was these kind of humanoid robots
doing disaster response work the video
that DARPA put out
so that was mostly of the robots falling
down and it was a kind of semi comical
view of these systems kind of not quite
accomplishing their goals with the
message that autonomy is still really
hard we're still really a long way from
autonomous robots I think that was a
very deliberate messaging on the part of
DARPA to kind of tone down the public
fear of killer robots coming to get you
I'm much more afraid of a badly designed
robot killing you than of an evil
intention robot killing you I think
that's a much more likely effect that's
probably gonna happen pretty soon and
that's a much more of a concern it's a
more mundane concern it's not quite as
existential I doubt Stephen Hawking will
chime in on it but I think it's a much
more realistic concern</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>