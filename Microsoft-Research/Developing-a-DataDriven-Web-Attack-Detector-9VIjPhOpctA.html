<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Developing a Data-Driven Web Attack Detector | Coder Coacher - Coaching Coders</title><meta content="Developing a Data-Driven Web Attack Detector - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Developing a Data-Driven Web Attack Detector</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/9VIjPhOpctA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay good afternoon my name is Allison
soul and I'll talk today about our web
attack detector that we are developing
in partnership with other and unlike pen
shank you will see that I cannot stand
still so I'll move a lot so this is a
partnership as I said with the other
security data science team and they have
been developing just with us for almost
a year now and we have developers on
both sides and it's very important we
have access to data from both the big
users logs the other portal logs ND DSO
request logs so this is a lot of data
that we use to train and to verify the
web attack detector our specific team
the being shared services team also
offers some of the services that we do
as ap ice so we have an API that given a
URL gives you the reputation information
that we have another API that tests your
site for accessibility issues and 180 I
Ted giving a URL we attack that service
for you and try to find vulnerabilities
before others we test your website for
vulnerability I cross-site scripting
sequel injection others and this is a
service that hold on to this name
website because it will come back in
this presentation so the problem that we
are trying to face is basically geez for
being for example we have a website that
he seems requests from customers
customers come plus to make requests
about all the data that we have which is
syndicated content social media graphs
cat pictures and some ads that we serve
to get some money and basically request
is something like people go to our
website and try to solve huge problems
most of the requests are very benign its
people trying to do good things and
search for answers to those problems
what happens in the back end is that we
get this request as an HTTP request that
is having some parameter value that the
value that comes from this request from
the customer indeed we log a lot of data
this is a simple example when we log
even more date about the session about
cookies headers and lots of other
information from that customer request
but for the sake of simplifying and not
showing to you in every slide the entire
Middle bullet here I will just stick
with the final bullet here for the
examples but remember what I'm talking
about here indeed in reality there is a
lot more data for each request in the
back end so what is to verify tetas web
service or website has vulnerabilities
basically you get those parameters that
your service accepts and you inject
attack strings there are websites like
the wasp project where you can go and
learn about attack strings and in this
example I am looking at the query
parameter and inject one attacks drink
that if the site is vulnerable to
cross-site scripting will have some
behavior and of course hackers will do
G's encoding these attacks drink it is
not very easy to read the request that
is a real attack when they do it luckily
in this case being is not really
vulnerable to the cross-site scripting
reflected precise cross-site scripting
and it just kind of returns that
information without any problems but the
real what dads are for more complicated
this is a real attack and later you see
how we found it but basically we go
through this video of requesting being
and we find these things that it will
take a human a little bit of time to is
this an attack or not so we could let
people attack us that's not a problem
especially if we are not vulnerable if
there were not other consequences one is
that from time to time someone deploy
code that has a vulnerability so you
find that vulnerability and you are
hoping that you found it before someone
in the outside the second thing is that
there is some capacity in this system
that is being misused because of this
when you are kind of doing the
anticipation of all the capacities that
you need for the service eat if fifty
percent of the requests will be attacked
you are wasting a lot of your capacity
also you cannot just say how i found it
is that user he's sending me a bad
request maybe his machine is infected
and he is kind of just one of those
botnet participants them i cannot just
say hope that IP is sending me a wave
attack let's block it and finally we are
likely having attacks that we are not
finding they are succeeding we don't
know about so what can we do one of the
simple things is let's try to increase
the cost for the attacker let's do
something as simple as if I suspect this
web request is an attack I delay its
answer for one second for a real
customer probably that's not a problem
you probably have waited for one second
on the internet at some point in time
and that's fine but for an attacker I
just limited his ability to attack
myself from 600 attacks per second to
one attack per second aight 6004 100 per
day so that may definitely increase the
cost how can we do that we do a lot of
line analysis already in our sites we of
course have these logs we do the log
analysis we create attack reports that
include which is attack strings like
what you saw and we'll see how we do
this and also IP addresses and all those
things ideally I should be able to
create a model that we
dude is that near real time so I can
create a web application firewall model
that I put in front of our website
logically doesn't really need to be in
front maybe it's just a model that is
called in parallel and then that can be
that additional cost for the attacker
where his request or her request takes
one more second how can I do this one of
the approaches is using regular
expressions that is the approach that we
are using in partnership with other
indeed ozzard is using partnership with
us because they started first and they
did 99 percent of the work in the
regular expressions so basically watches
that you need to do you as a developer
if you know regular expressions and some
of you may know you can try to look at
those strings and find patterns that
will detect that the request is an
attack and you find one find the author
and keep going and as you can see our
partners are doing a fantastic job on
creating this regular expression the
other approach which is different
approach which is the one that we try to
do when we are also working on
cooperation with other is you have
ground data some data that you know that
has attacked and no attacks and then you
create shitters from this data though at
or attributes or properties or whatever
name you give to this thing and then
from that you do training for a machine
learning model and then your model will
get your request at runtime struck the
same features that you use it for your
experiment classify or regress juice and
give you a probability that this request
is an attack and you need to have a
scoring process which you will then tell
you hey that was an attack you detected
that was not an attack you didn't detect
it or the bad things are the false
positives and false negatives when
something is
an attack and you miss it or false
positives you say is an attack and it is
not each method has its pros and cons so
basically in the case of the regular
expression stacking up is easier so it
was easier to start this process use you
are the first rule it's working you add
the second and so on and so forth and
you go you evolve you have stead
progress because if you try some who it
didn't kind of work what you do you go
back so our partners or azor has they
have just continuous testing process
where they every day they see if there
are no regressions and if something made
things worse you go back but there is a
cost of this which is at the run time
evaluating regular expressions and of
you who has experience with regular
expressions know it is very costly
regular expressions cost a lot of time
so you can have a single regular
expression that costs you 350
milliseconds at runtime and that adds up
if you have a list of regular
expressions and then soon you are taking
a lot of time to evaluate if the he
questions the web attack or not and the
biggest problem maybe it is that your
worst case it is the benign request if
the request is good it means it has to
go to all those tests fail and then you
say oh it was not an attack recognized
by those regular expressions well what
about the machine learning approach the
machine learning approach if you use the
proper method and if you find the right
features as we will talk about the key
is finding the right features if you use
the proper method then you can have a
very good runtime performance there are
ways to whoever is an expert knows we
can prune trees we can do a neural
network with so many layers you can
guarantee a runtime performance
depending on accuracy goes
and you will have the evolution from
your data you can make the system
evolved from your data but the biggest
problem is that starting app is very
costly you have both time that you need
to investing in people and a lot of
effort on tests that will give you those
right features and the second thing is
that progress is not linear with machine
learning one of the biggest problems
that I had in all the machine learning
projects that I work is people saying oh
you are at nine percent when it will be
at 92 you said I don't know and that is
a frustration that a lot of people that
deal with machine learning carry all
witches you fail fail fail fail you know
one day you lose it oh I'm at 95 but
it's fantastic that you can even have
regressions indeed I asked one of the
top experts on the field who I happen to
know Christopher bishop who is one of
the top experts on pattern recognition
machine learning indeed this is the name
of the book that he altered which is the
classic that everybody reads about
machine learning what was the top
challenge for machine learning and on
the long-term he says it is basically
that machine learn arrives at AI but in
the short term is how we can do machine
learning without that much labeled data
how we can use these unsupervised
methods as you probably have heard to
really progress machine learning without
the cost of labeling and why why would
someone say this and not say that the
methods of machine learning you see he
didn't say that the biggest problem is
SVM against trees or trees against new
your networks and all these things that
we see a lot of people wasting a lot of
time in these discussions it is because
labeling is extremely costly suppose
that I have a hundred video requests per
day and it costs me one second to label
each one I have this expert that they
can look at the request that long
request that I showed you and say 'i
just one second this is
attack this is not an attack so I need
this label data to train my system well
with 100 billion requests per day if the
special works just eight hours per day
and it's kind of gifts performance one
second per label it won't take just
9,000 men business days to label this
data and if I find 200 of those experts
it takes just four seven days so after
47 days I label the data for one day
obviously that is not a very scalable
approach so the other thing whoever
labeled data here knows it is that
people make mistakes isn't it so you
have how this books in article statue
have to read about how to have multiple
people labeling the same thing and you
get three people labeling the same thing
and if you disagree from the other one
you have the Minority Report so ok I had
to put that there so the other thing is
that you when you are doing data capture
you will have gaps in your data so i use
the system to watch movies that most of
you also use and they give me some
recommendation of movies and right now
for example a certain time they
recommended that i watched strawberry
shortcakes and also Doctor Who and also
spiral French cities but why why they do
this because for a long time they
captured date about movies watching on
my house without asking who so the data
just say it's awesome but my daughters
were watching so now I have this very
strange kind of paste whoever knows me
knows that I have this strange tastes I
keep watching strawberry shortcake the
other thing that is very important is
there is no such thing as data capture
without a model this is very important a
lot of people that i talked with if and
they say I'm date
even as your k cool I'm really now I
will have this matrix about the
performance of developers okay who and
what are you capturing and they are
capturing tears and what's your model I
don't have that is not to be data-driven
so in what is probably the only story
that we remember five years from now
from this presentation I'll tell you
geez when i was a child i was born in
brazil not on the beaches but on the
country and my grandmother i lived with
her for a year and my grandmother he is
from a kind of indigenous tribe and
basically I never had medicine until I
was probably the ten years old because
you get a code she takes you to a healer
he looks at you he thinks that is just a
spirit on you that's making you sick he
is mocks something from several
different pipes and then you are cured
amazing isn't it that's probably why I
don't get sick as an adult I never had
medicine and 2 10 years old so the
fantastic thing about Jesus is if I'm
doing a machine learning modeling and I
tried use when I was I'd I was enchanted
by this just guy his books a pipe so
probably I need to think I come with a
call this pipe on the left so the day
that I'm capturing is totally dependent
on the model that I have of how the
things work is in it now there was this
other guy a few decades or centuries ago
who was doing something totally similar
you probably have heard about this
doctor from angry that Hungary that was
kind of in the hospital and the doctors
when they made deliveries there was this
very high death rate for both the babies
and sometimes even the person delivering
baby but when midwives were doing the
delivery the hit was low and he started
capturing what
which kind of data who was doing the
delivery and if they were watching their
hands and then when they they found that
if the doctors where were washing hands
the the death rate would go from
eighteen percent to two percent he came
up with this theory of germs okay and
you know the conclusion of this the
doctor said this guy's crazy he's
telling us to wash hands he died at 47
in a hospice so the thing is basically
this even if you have the right data and
if your data is complete you still need
to have a model I'm repeating how many
times geez data-driven means I have a
model that allows me to understand my
data if you don't have a model just
capturing data it's useless so suppose I
have a model for me to have the price of
houses based on square footage and the
number of beds so for simplification of
course here I have two groups and i have
a new house here that i want you as
humans to think which group do you think
this house is closer to well most of you
will say the second group the group that
has houses with bedrooms most humans
consider bathrooms in houses kind of
convenience now one of the machine
learning methods that most people have
heard this I group my data using K means
wherever I calculate the centroid for
that group and then for a new data point
what I do I measured the distance to the
centroid and then i classify in that
group if you do this for jeans
particular new house here it is closer
to which group the first one mathematics
will never fail why because there is one
feature that will you over whom all the
other features the numerical values are
so much bigger
I need to know how to model this feature
so I need to have a human settlements
tells me well typically houses go from
five hundred to five hundred and
thousand square feet and bedrooms in the
house go from zero to five scale and
normalize your data we change these
ranges and when you do this then you see
what the new data point is far closer to
the second group unless you already have
a system for what is called deep
learning there is no way to derive just
from your data because you will have to
have a human to tell you geez or the
system you have to learn this from the
data and that is the goal of this deep
learning systems to learn both the
fitters and how to normalize them
directly from the data but we are not
there yet so I have all these problems I
have incomplete data I have wrong label
data I have wronged features suppose I
didn't have any of these problems which
we have by the way now I have those
features how do i go to that distance
that i just calculated there in the
houses you remember i calculate the
distance using euclidean distance for
those people that are more
mathematically inclined and but that is
something that is not always correct and
the biggest problem is i need to create
features and i need to calculate
distance based on strings strings and
other properties that are just like this
so i ask you what is the distance
between the first and the second strings
there anybody you are the top three
directly turn you know everybody
calculated which distance did you use
Levenstein or so see this is extremely
hard because how the machine learning
methods are based on
distance and numbers and it doesn't
matter if it is regression if it is K
means if you are trying this
maximization or minimization I need to
transform just values that I have which
is mostly strings IP addresses into
distances features that have numbers and
then I will be able to using a model
really classify those things so what you
need to do is to think like a freak
which is the title of the new book from
the guys who wrote the freakonomics book
very good book this one and basically
you have to start testing is the URL
laughs somehow correlated with being an
attack or not is the number of keywords
like script or something is the number
of symbols is this trick distance in the
sense of Levenstein distance something
that really makes sense and what we did
is a lot of experiences and we are still
doing this and we develop code that
calculates numerical values from those
strings for example here is some code so
since we focus on the parameters and the
parameter values for the attack
recognition for example I need to know
that see I have two in the first half I
have two sequences of value is for the
parameters and it gives me the distance
for here i have the parameter value just
changing from which parameter it is the
distance is 24 and finally here I have
this parameter a valid changing and yet
the distance is 0 so this is the kind of
code that you need to develop for you to
be able to transform those attack
requests or those requests into
parameter values attributes that will
give you the features and then you have
the final measurements that you can use
for example you also have to consider
your model
in this case because people we win coat
the strings our code and this is called
a text just one millisecond those three
strings the distance between the n is 0
so it takes an enormous amount of time
for us to do it this code after you do
this code the machine learning really
comes naturally because but who would
think in the beginning that this was the
hardest code for us to develop and
finally both for our attacker in for the
one from the the azure data science team
how do we test it remember I told you to
hold on to that website thing the web
sac application win serves that we have
that attacks our services well if I have
web service and if it is attacking our
own selves I have something that is very
important isn't it I have a tax that I
know they are attacks I know when to
search for them in the logs so i have
several positives and because attacks
are something precious and I can refer
those from the other normals I can then
do this cording I can kind of both for
our in for the wave attack detector
being developed with regular expressions
we can kind of well let's start with a
sample here of 7 million requests and I
know because I I really prepared this
data at three meeting for 159 and 512
are attacks and the others I don't even
need to know perfectly that they are not
attacks I just need a mix that allows
between stack these processes in it
because I can evolve and then what I do
is I run through the recognizer and I
see how many detected s attacks or not
attacks and then if I come if the two
flags are equal and they are one I have
the true positives and then I have these
negatives and so on so forth this allows
me to calculate what
my precision and accuracy and then you
see that for example this is the regular
expression detector it has a very good
accuracy that in most of other fields
would be already perfect but when you
have billions of requests you need to
still continue improving and how do you
continue improving now you need to take
a look at those where let's start with
the ones in which we defer the opinion
from the source ground truth Andy the
cognizer is different but you need to
classify who is the volunteer to go
through 118,000 330 URLs in each one
tell us if you can attack or not well
what we did is we created an application
tab using that same distance
calculations and and all the attributes
and features that we found to to helping
our machine learning system we can group
the data and you see that week in this
case I i simplified for just three
groups you see that the group's they
look like each other the in between the
group those are the three best groups of
this and you can change the number of
groups and then you can label again and
with this you have the feedback loop
that you needing out the machine
learning processes and we also our
intern this summer got this application
and made it into a spark based
application that runs on the other
hdinsight spark clusters and then you
classify directly bobs in the user
storage and just allow us to continue
our machine learning training it's not
as good yet as the web attack the text
or the regular expression but it is
evolving we can do web attack detector
validation and we can identify new
attack strings as I showed you in the
beginning what is the future for this we
will continue our machine learning
training the regex team is continuing to
improve for example we started more with
regular expressions for XSS now we added
sequel
Joe and so on so forth and our ultimate
goal is taking a few months we have a
microsoft something that is in your
container that we can just give you and
you can use it in your solutions but in
the million meantime if you have any
application for juice just contact us in
this alias and you can reuse any part of
our solution test applies to your
problem thank you and I'm</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>