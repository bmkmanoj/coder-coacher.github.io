<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Brains, Minds and Machines - Gabriel Kreiman | Coder Coacher - Coaching Coders</title><meta content="Symposium: Brains, Minds and Machines - Gabriel Kreiman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Brains, Minds and Machines - Gabriel Kreiman</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/iqEvGCrs9PI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay I'd like to introduce Gabrielle
crime on in this just like I I was Tommy
student so Gabby was my student at Cal
Tech was a brilliant student helped us
and discover these like one day he came
to me was a cell that responded
selectively uniquely to three different
images of then President Bill Clinton
that later on turned into these Jennifer
Aniston cell subsequently became a
postdoc with was Tommy at MIT and now
since six or seven years professor at
Harvard ophthalmology and neurology
Korea thank you very much so I'd like to
continue with this theme of trying to
build bridges between brains and minds
and machines and specifically I'd like
to discuss the roles of recurrent and
feedback computations in cortex so in
case I run out of time here are the main
players and people who have contributed
to this work I will highlight the work
of two amazing grad students a handling
tongue and be letter as well as some of
these other people here at the heart of
the main message that I'd like to convey
today I are two main claims the first is
perhaps pretty obvious that over the
course of many millions of years of
evolution our brains have produced
circuits that do interesting things that
we refer to as intelligence and the
second one perhaps more controversial
one is that by studying and elucidating
those neural circuits and biological
codes we can translate those biological
insights into mathematics and
computational algorithms to give rise to
the next generation of intelligent
machines and I'd like to give a couple
of examples on that so this is the
diagram that many of you may be familiar
with that illustrates some of the basic
connectivity in the primate brain it
kristef illustrated some of these ideas
also in the rodent as well and there's a
very complex series of circuit here that
are involved in visual recognition and
as both Tommy and Christopher have
emphasized there has been tremendous
success in describing some of the basic
aspects of computations that have
that we've rise to button recognition
over the initially hundred hundred 50
milliseconds of processing there's
evidence at the behavioral physiological
as well as computational level that we
can capture as many of these
computations essentially in bottom-up
architectures and feed-forward textures
that have been of course also given rise
to the tremendous excitement in deep
learning and deep convolutional networks
now we know very well that in cortex
there are massive recurrent as well as
bad projections throughout cortex and
this is just one of many studies trying
to quantify exactly how many connections
we have in cortex there are recurrent
that is that are basically at the same
level of processing or even feedback
processing from higher visual areas back
on to lower visual areas so so the
question that I'd like to post today
involves trying to take some initial
steps towards understanding why we have
these connections and what they might be
doing and how by understanding the
biology of what these connections to how
we can illuminate the future aspects of
computation in cortex so in order to do
that I'm going to give three examples I
very briefly talked about fundamental
aspects of feedback computation on two
primary visual cortex then move on to
visual search and finally discuss a
little bit more length what happens and
how recurrent and feedback computations
can help in the context of pattern
completion so throughout I'd like to
bring essentially the three levels of
analysis that David Marr antoje
postulated that is trying to understand
all of these problems both at the
behavioral level at the physiological
level as well as the computational level
whether we want to start with primary
visual cortex well as Christoph
emphasized and then Tommy also noted a
lot of the basic science that gave rise
to deep completion networks originated
by some of the initial findings by David
Hubel and Austin Vissel studying the
so-called simple and complex cells that
in primary wish
cortex so I'm going to show very quickly
an experiment that was conducted by Rick
born at Harvard Medical School
essentially a few steps away from the
laboratory that David Hubel use to do
his recordings where he used a cooling
technique to lower the temperature in
area v2 v3 which is the main source of
feedback on TV one and then examined the
properties of Nursing in primary visual
cortex son's feedback in the absence of
this feedback signal so this is just an
illustration you can lower the
temperature of v2 v3 you can therefore
silence those neurons and then you can
record activity of v1 in a wake behaving
monkeys while in the absence of these
feedback signals so the first point I
want to make is that a lot of the basic
properties of computation v1 remain
unaltered in the absence of feedback so
if you look at the direction selectivity
if you look at orientation selectivity
if you look at the tuning with some of
these basic initial response is
unaltered consistent with the notion
that again we can explain some of the
fundamental computations in a purely
feed forward manner however when you
start to look at what happens beyond the
primary receptive field of the neuron
beyond the basic simple computations you
start to see a quite notable an
important differences one of them is
illustrated here and has to do with
so-called areas around a suppression so
if you start increasing the size of the
stimulus eventually the responses of the
neurons become smaller so that's
illustrated in this area summation
curves and the y-axis you have the
firing rate and the x-axis you have the
diameter of the stimulus larger is
better at the beginning and eventually
larger is not longer better and the
responses decrease it turns out that in
the absence of feedback if you don't
have feedback signals this inhibition
that gives rise to this this decrease in
the response is significantly
ameliorated so feedback explaining
fundamental role in this constraining of
the size of receptive field and in the
integration of signals beyond the
classic receptive field of the neurons
these feedback effects are delayed with
respect to the initial onset so it takes
time for signals to go all the way to be
two and then back on
v1 so we can use the latency of these
signals as a signature for the for the
timing involved in in feedback
processing and it turns out that we we
did a series of computational exercises
showing essentially where we can ascribe
these feedback signals and trying to as
I said at the very beginning try to read
biological code and translate that into
mathematical algorithms and
computational ideas so people have
described this area summation curves as
a ratio of two gaussians essentially one
Gaussian curve describes the the
essential in put the other one describes
the normalization operation one of the
fundamental operations in many of these
deep convolutional networks and it is in
that normalization operation that we
think feedback is playing a fundamental
role so by understanding the biology of
these feedback signals we can we can
begin to write an algorithm is
describing how Co feedback may be
instantiating these inhibitory
computations in cortex so I want to move
quickly to my second example now and
change gears to talk about another
fundamental problem where we think these
feedback signals could play a
fundamental role and that has to do with
the problem of visual search many of you
are very familiar with this kind of
Where's Waldo kind of games this is a
pretty difficult task when you try to do
this it takes time and this is one of
the fundamental issues with clutter in
visual recognition whereby it's very
hard to actually recognize objects in
clutter and you need to move your eyes
and actually perform a quite a quite a
lot of computations to reach for that so
inspired by by a lot of physiological
recordings in macaque monkeys we
postulated a computational model
involving feedback to try to solve this
problem of visual search in the interest
of time I'm not going to be able to
discuss the physiology in detail but
everything we're talking about here in
terms of the computation was
significantly inspired by the work of
people like Bob DeSimone at MIT a metro
he's shown many others who studied the
role of feedback signals in Mecca cortex
during feature-based attention or during
you'll search so very very quickly at
the heart of this computational model we
have the traditional deep completion
ille networks in this particular case
the H marks that impose your kind of
instantiation and then what we do at the
top is let's say that we're searching
for Walden we store what particular
features are at the very top of the
hierarchy are representing Waldo and
then when we do is inject feedback
signals illustrated here in the top
right of the slide we inject those very
specific feedback signals essentially
pushing Waldo all over the image pushing
the particular features of Waldo all
over in order to highlight those
locations in the scene that are more
world alike and that will help us
perform a visual search and there's a
paper that's published on this if you're
interested in getting to know more of
the details so here are a couple of
examples where we're looking for
particular objects either in images that
contain a race of multiple objects and
or in natural scenes and what you're
seeing there is the performance so how
many times you need to fix fixate and
how well the model can essentially find
Waldo in this complex image image a so
how will the model can search for
different complex objects by
instantiating these feedback signals we
can do this either in the situation
where we tell the model to stop looking
or the model itself has to realize when
it actually found the object we can do
this in images to contain isolated
object and to a lesser degree as well in
complex images with natural backgrounds
as well and importantly as I emphasized
from the very beginning we really want
to connect the computational models with
what's happening inside the brain with
ultimately behavior so here's a like a
physics experiment trying to ask how
well people can recognize and search for
objects in complex images by measuring
their their eye movements and we show
here that these very simple
computational model instantiating
feedback connections can match human
performance extremely well in this very
simple visual search paradigm I don't
have much time to go into there's a
plethora of other algorithms and that
people have put forward for visual
search laurent ET and krista of concord
and beautiful work with purely bottom-up
saline see models and a lot of other
people have used different strategies
for this target based visual search at
the heart of many of these algorithms
with the idea that you need feedback
signals that are extremely specific to
be able to search for the particular
object that you're that you're looking
for so these are two examples from the
bottom up the basic computations in b1
all the way to the highest echelons of
processing and I'd like to focus lastly
on a third example of how we can try to
connect behavior with physiology with
computational models and that has to do
with the problem of visual pattern
completion so I think pattern completion
is at the very heart of intelligence
here just a few examples where people
can complete patterns in the context of
sequences of numbers of the famous
connect the dots kind of game we use
pattern completion in social scenarios
from a second of of interaction with a
person we can read them the first degree
reasonably reasonably well we do pattern
completion and extrapolation from
partial information all the time I'd
like to focus today on the question of
patent completion in the context of
visual processing there's a number of
different ways in which we can create
images that are incomplete and we're in
order to be able to recognize them we
need to do a pattern completion and I'm
going to argue based on behavioral
evidence physiological evidence as well
as computational evidence that we
actually may need recurrent and all
feedback connections to solve this this
problem so let me start from the
behavioral part we created images such
as the ones shown here for the toy
school bus this is using a technique
that's common in the psychology
literature called bubbles essentially
it's like looking at the world like this
so so you have a few apertures through
which you can look at objects you have a
pretty severely degraded version of the
of the object and it turns out that our
visual
system as you might imagine is extremely
robust to deleting huge chunks of the of
the image so here we are showing
psychophysics performance on the y-axis
as a function of the amount of occlusion
each of those lines corresponds to
different exposure times how long we
present the images for and you can see
that you can go up to eighty or ninety
percent occlusion so you only have ten
to twenty percent of the information the
image and we can still recognize those
images quite well in this particular
case there are 25 images there are five
different categories people are doing a
categorisation task and we can do
extremely well despite a very very heavy
occlusion so I'd like to now very
quickly show you what happens inside the
human brain while people are performing
this type of pattern completion analysis
and Chris have already alluded very
briefly to this notion that in some
particular cases we can interrogate the
human brain invasively by working with
patients that have epilepsy and who have
electrodes implanted inside the brain in
order to monitor or cure them from their
from their seizure events so this gives
us a rather unique opportunity to record
in the activity of single neurons or in
this case field potential signals
invasively from different parts of
visual recordings so here's one example
first without occlusion just what
happens when you present pictures what's
happening inside the human brain when
when you see objects so each line in
this plot corresponds to one
presentation of one particular picture
there are several repetitions there are
25 different pictures in total the color
map over there represents voltage so it
indicates how active this particular
electrode was displayed aficionados the
selector is in the inferior temporal
gyrus an area that we know is
fundamental for object recognition
because lesions in this area render a
significant impairment in object
recognition capabilities if you average
all of these trials and all of these
different pictures within each category
you get a signal that looks like this
this is the intracranial field potential
as a function of time so we get a very
selective and strong signal that happens
very fast consistent with the
feed-forward models consistent also with
the behavioral experiments so we have
very strong selectivity invariants that
I'm not going to show here and a very
rapid response so what happens in the
human brain when we significantly
occlude the objects and we present only
partial information so again here's just
one example of one picture 30-plus
repetitions of that particular picture
showing the potential as a function of
time from another electrode so here I am
going to show you a few single trial
examples of what happens when you only %
about ten percent of the of the image it
turns out that to a first approximation
although there's some variability from
one picture to another the signals
remain largely the same meaning that the
the signals in this highest echelons of
visual cortex remains strongly selective
despite is very strong degrees of
occlusion if you pay more attention to
the details of the way from see turns
out that there are some important
differences most notably this delay in
the signal so those numbers they
represent the maximum voltage and it
turns out that that is significantly
delayed correspond with respect to the
responses to hold objects remember that
I had shown you at the very beginning
that these delays are consistent with
the role of feedback signals so I just
showed you have a couple of examples
just to convince you hear all the trials
with whole objects in the same format as
before here all the trials with occluded
by presentation there's one there's
variability from one trial to another
because the images are actually
different the positions of those bubbles
are actually different but consistently
there is a significant delay of about 50
milliseconds or so involved in the
essential physiological signals
underlying recognition of occluded
objects so this is more data multiple
electrodes I'm going to skip this and go
very quickly through these we
consistently see these delays which we
interpret to imply that we need
additional computations perhaps these
recurrent and all feedback computations
so in the human brain we cannot cool an
area we cannot lower inject electrodes
and lower the temperature of an area
like Rick born did in macaque monkeys
it's illegal to do that our alternative
here is to use a technique called
called masking essentially present a
picture and very briefly after that
picture you present a mask and it turns
out that this has been hypothesized to
essentially interrupt feedback
processing so the behavioral level would
repeat the same behavioral experiments
and we conjecture that a feedback is
important to recognize partially
occluded objects we would be able to
impair performance significantly in
recognition of partially occluded
objects when we perform this experiment
and the backward masking and indeed the
upper plots here correspond to the map
psychophysics data behavioral data in
the absence of masking and if you look
at the lower right version of this
figure on the y axis you have
performance on the x-axis you have the
interval between the presentation of the
picture and the presentation of the mask
and if you present the mask at the right
time essentially to do to be able to
impair feedback we see that performance
is severely degraded in other words if
you inhibit this putative feedback
signals by presenting a rapid mask after
after the stimulus you cannot complete
objects you cannot do pattern completion
you cannot recognize these objects well
when they are heavily occluded whereas
you can still recognize objects pretty
well when they are not when they're not
included at all so just very quickly I
want to point out that there is a
connection between what is happening
inside the brain and what's happening at
the behavioral level so we can go back
and and and take one of those selectors
that showed a very strong selective
signal and asked for each picture how
much of a delay there was in the
physiological signal remember that i
postulated that that delay in the
physiological signal may be correlated
with the need for additional
computations at the same time for each
picture we can measure behavioral
performance and what's the effect of
backward masking to what extent backward
masking impair recognition performance
bear in mind that we do this across
different subjects so we have physiology
data in one group of subjects and we did
this psychophysics experiment in another
set of subjects so despite these
limitations and these differences it
turns out that there's a week
but significant correlation between
these two worlds what's happening inside
the brain and what's happening at the
behavioral level essentially when an
image was more in what particular object
was more impaired at the behavioral
level by masking it was also more
delayed at the physiological level and
that's what these scatter plots are
showing here so let me now come back to
a computation and argue that purely
feed-forward models also struggle with a
very very heavy amounts of occlusion
this is the behavioral data that I
showed you already performance as a
function of the amount of occlusion this
is how well you can recognize the same
set of objects using just the pixels
this is how well you can recognize them
with the H max model bear in mind that
the HVAC smolak has zero free parameters
we're not trying to train these
parameters at all these are for the
aficionados these are different versions
of the so-called Alex net deep
convolutional Network this is the pool 5
level level or the FC seven level these
computational models start to perform
better but they still fall significantly
short of human performance so they still
significantly underperformed humans in
recognition particularly for heavily
occluded objects so the computational
level will argue that we need something
beyond this puny feed-forward
architectures for for recognition so
just to try to visualize that here's a
multi-dimensional scaling 2d rendering
of the representation of one of the set
of pictures that we had in our
experiments from the top level of the
Alex net network so here are all the
different whole objects and you can see
that they're pretty well separated in
this in this space so it's pretty easy
to distinguish all of these different
pictures when they are whole pictures
with this highest level of Alex net in
contract when you look at the
representation when they are occluded it
turns out that the cluster essentially
in the middle and this is what gives
essentially to a very poor performance
in recognition of this heavily occluded
checks so again it turns out that we can
measure for each picture how difficult
it is for the models to recognize them
essentially how distinct is each picture
from the from the category mean and
again there's a weak but significant
correlation between what the model is
saying because in between how difficult
that particular occlusion problem is for
the model and how much delay there is at
the physiological level how can we
rescue performance given that at the
behavioral level and at the
physiological level I argued that we
needs recurrent computations how can we
use this ideas while recurrent
computations to rescue and improve
performance for recognizing heavily
occluded objects and perform button
completion it turns out that there is a
very nice an old literature on hopeful
networks these are networks that are
interconnected in an all too old
fashioned and can perform pattern
completion extremely well so taking
inspiration from these ideas as well as
from the behavior and the physiology
what bit lutter did essentially was take
the upper level of Alex net and other
recurrent computations at that level so
he added all to all connectivity and
retrain the network to learn those
weights in order to try to recognize
heavily occluded objects so I'm going to
go through this very quickly in the
interest of time here's the pictorial
rendering that I showed before for all
of these different categories and this
is what happens in this network over
time because now we have a recurrence II
the network changes its state over time
and you can see that over time there is
a better and better separation of these
heavily occluded objects which suggests
that we may be able to recognize them at
the computational level and indeed when
we go back and plot performance as a
function of the amount of occlusion it
turns out that this adding this
recurrence estep and running these
recurrent computations onto the upper
level significantly improves performance
and also matches human performance not
only in terms of overall performance
this performance improves over time over
these multiple recurrent computations
and also the level of correlating
performance between
behavior and the computational model for
each single individual picture so I'm
going to stop there I just want to
summarize the three main points that are
going to make here are three examples
about ways in which we can try to read
out biological codes and translate those
biological codes into computational cost
the first one had to do with very simple
basic computations in primary visual
cortex the sort of ideas that have
inspired generations of deep
hierarchical architectures and we have
taken initial steps to understand how
feedback can help and act in primary
visual cortex the second one was by
showing how feedback can help in the
context of visual search with cluttered
scenes and the third one is in the
context of pattern completion and how
adding recurrent computations onto a
computational models can help us
understand and perform better in a
heavily occluded object recognition task
taking a step back the main message that
I'd like to convey is a rather
positivistic one arguing that ultimately
by understanding brains by understanding
your science we will be able to design
better algorithms we will be able to
help alleviate the tremendous human
disorders that afflict the human brain
and ultimately perhaps understand better
who we are admittedly I put many many
years there we're not quite there yet it
will take us a very long time to really
translate biology into computational
algorithms but I think this is not only
possible a path to go but actually a
necessary one and finally I'd like to
show the pictures again of the main
people who have done the work Thomas
mikoni here was involved in the visual
search experiments I mentioned brick
born and Joe nasty and Camille Gomez who
did the work on primary visual cortex
and bill loader and handling Tang were
the main people involved in all the work
physiology behavior and computational
models that have to do with a pattern
completion so I'm going to stop there
blood Gabriel um we have time for
questions so please raise a hand so YF
connections only among the top player
neurons are not going down to the lower
layers that's what I would have expected
I assume you're referring to the last
part in the compilation of all indeed
this was our starting point not to as a
proof of principle show that adding any
kind of recurring computation and
training those recurrent connections can
help ultimately as you point out the
recurrent connections and feedback
connections everywhere and we still have
a very long way to go to understand
those but we would left me like to do
that and we'll invite everyone to to
think about what are the computational
roles of feedback connections throughout
which we know are fundamental and
ubiquitous in biology this works yeah
thank you for the nice talk so I was
wondering that you should it's very
interesting that in spite of having
occlusions the activity of neurons
remains the same so the operations can
be similar to extrinsic noise and lot of
computational models have shown that
when you have feedback connections you
can have internally generated noise like
chaotic dynamics and you see that such
internal noise plays a role in
computation or pattern completion for
the model yes yeah it's a good point
it's a good question I'm happy to
discuss for the way we haven't really
thought about occlusion as nice exactly
but but I do like the idea of thinking
about it so i would i would say that our
at the physiological level what we're
probably looking at is the end point the
result of that computation and in fact
that at this very last stage of visual
processing these signals are quite
robust to what you call noise to this
this heavy amount of occlusion at the
competition level that noise or that
that variability that's significantly
impaired performance things are really
clustered at the beginning things I'll
really obscure the beginning and
and what we think is and so the
mathematics of this is lay down in the
hopeful networks is that by adding these
recurrent computations the system learns
to separate these patterns and bring the
representation closer to a more robust
representation that's similar to that
for an occluded objects yes my name is
yoga Schmidt Hoover from the Swiss AI
lab of course there are many engineering
approaches which also use recurrent
networks to better understand images to
selectively direct attention to a
certain parts of the image search that
it can be better explained socially it
can be better recognized and these are
driven by pure engineering principles
and mathematics you have a goal you want
to find your object you have selected a
lift selective attention which means
some sort of recurrent network and these
guys are not at all inspired much by
neuroscience how would you see the
dichotomy that we have that so on the
one side the pure engineering guys who
just solved their problem realizing that
they need recon connections were solving
it better and then the neuroscience guys
who also realized the importance of
leconte connections but there is not
actually a lot of interaction between
these groups absolutely I think it's
fantastic that I think there would be
plenty of ad hoc solutions coming up
from engineering that will work there
are amazing programs much much do I this
is something I don't like but I have to
admit they're fantastic computational
programs that play chess much better
than most of us and we learn nothing
about how humans play chess despite the
fact that the computational algorithms
do extremely well so sure I'm certainly
engineering can find out a lot of
solutions some of those may or may not
overlap biology hopefully we'll learn
from engineers and will inspire what
kind of solutions we might look for
hopefully some of the biology will help
inspire engineers as well and there will
be solutions that have nothing to do
with each other and I think I'm that's
perfectly fine I think ultimately for
some of the very challenging aspects of
intelligence we have a system that works
we have a system that solves all of
those problems that is our brains so I
think that if we can sort of the begin
and fine
how it works we should be able to
translate that into inter computational
algorithms and we should be able to help
and accelerate engineering so that they
don't have to spend decades and
centuries sort of trying out different
ad hoc solutions which you can actually
look at how these coats actually
implemented that said if there are
solutions that have nothing to do with
biology and they work that's fantastic
i'm happy to just to upload those those
approaches as well oh great um so let's
thank KVL again
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>