<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Interactive Design Tools for the Maker Movement | Coder Coacher - Coaching Coders</title><meta content="Interactive Design Tools for the Maker Movement - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Interactive Design Tools for the Maker Movement</b></h2><h5 class="post__date">2016-07-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rxAyXzBoKog" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
um okay hi everyone thanks for coming
this morning for what's really a
two-part series of talks from urine
Herman and David MELAS David will be
speaking right after this at eleven so I
hope many of you can stick around for
that but our first speaker today is Vern
Hartman who I think a lot of you know
but for those of you who don't Buren's
faculty member at UC Berkeley where he
does really great work in human-computer
interaction and ubiquitous computing and
so we're very excited to have him here
today to speak to us about some of his
group's most recent work on interactive
prototyping tools for the maker
community great thanks Thank You salima
for the introduction thanks everyone for
coming half an hour earlier than you
would usually expect for for a talk so
over the course of the next hour I will
show you how you can transform a printed
piece of the nerd 3d plastic into a
working game controller by adding a
super sensor into it namely a camera so
you have this camera to a 3d printed
piece and you end up with with a working
game controller I'll show you new smart
prototyping techniques like this
augmented breadboard that helps you
debug circuits when your breadboard I
think Rob just had his first breadboard
circuit so directly onto you and some
new types of fabrication tools that
we're building such as this machine for
3d surface augmentation so not printing
from scratch but working with existing
objects so this is where we'll
eventually end up but let's take a step
back and and ask why so talk is titled
the interactive tools for the maker
movement so maybe I'll just take a you
know take it from the top and say what
is the maker movement who's been to a
maker faire or an event like that in the
room so maybe about half the room so for
me you know it's exciting about the
maker movement it's this bottom-up
effort to engage people from all ages
and all walks of life
learning how our world of made objects
actually works under under the hood and
so transforming them from kind of
passive consumers in that world of goods
into active participants and so this is
just a snapshot from a recent soldering
workshop in Detroit that that shows you
some of the certainly the age diversity
that that that you have there I think
ground zero for the maker movement are
these events the Maker Faires the first
one was ten years ago in San Mateo and I
just happened to live across the street
at the time so just walked into my first
Maker Faire and it has now turned into
something that I think this year
attracted two hundred thousand people
just to that main event and there are
probably close to a million people who
attend the associated events just the
official ones and then of course there
are many spin-off events so if you
haven't been you should absolutely go
it's kind of mind-blowing the first time
you're there so a lot of this happens
out open in in the community in hacker
spaces open public events but I think in
addition we're also seeing hacker spaces
and make a space as appearing in in high
schools middle schools and on college
campuses so this is a picture of the
hackerspace infringe on Fralick ed at
Maryland and you see actually quite a
number of quite high visibility efforts
going on such as the new innovation and
design center at Yale the invention
studio at Georgia Tech or at Case
Western the seventh story thinkbox that
actually now is already getting too
small so they're getting a new building
next to it okay so there seems to be a
lot of enthusiasm and action around the
maker movement but to me another
question is going to what set at stake
why would we care why is this important
to support rather than just a nice
activity that that's going on anyways
and I think there are a number
of different reasons so let me give you
three the first one has to do with the
nature of our education what we're
training people to do so let you read
this quote from Alan Watts favorite Bay
Area philosopher and this was written in
the 60s and certainly still rings true
today that we've seen kind of this
alignment mostly of what we think of
Education is analytical skills and that
is great certainly the students we we
accept at UC Berkeley are just
fantastically prepared in STEM
disciplines but what is maybe lacking is
an understanding of how all that theory
actually connects to problems they might
face in in the real world and we've gone
so far down that path that actually I've
seen electrical engineering students
enter PhD programs who've never held a
soldering iron before so there's an
educational objective of rent kind of
connecting you know connecting concepts
and theory back to what actually tasks
that matter then there's also an
argument around innovation and eric von
hippel probably makes that argument the
best which is that lead users who really
understand the domain you know
understand the domain better than
companies who come in externally and
therefore are in a very important source
of innovation so this book gives plenty
of examples from the world of medical
devices and sports equipment where it's
really it's the physicians and the
athletes who have the insight and so if
you can give them better tools to
translate their insight into inventions
then you actually increase the bandwidth
of our innovation pipeline last argument
has to do with with the state of
manufacturing in in the u.s. so
there's this rather gloomy article
written five years ago why Amazon can't
make a kindle in the US that argues that
basically we've outsourced now enough
for so long that were not even able to
make things in the US even if we wanted
to and the maker movement here is an
interesting maybe counteracting force so
let me give you an example on the left
you see the type a machine this is a 3d
printer built by a company in the bay
area and they made their first set of
printers at local tech shops by laser
cutting wood and taking hardware out of
the the hardware store and so having
access to maker spaces fablabs gave them
enough tooling to build something that
really didn't look like a finished
product but was actually functional and
they tied into a network of other makers
who bought these first machines and that
gave them enough expertise and capital
to them bootstrap to turn that into
something that looks much more like a
finished robust mass-produced product so
the White House is paying attention to
this and so in 2014 there was the first
White House Maker Faire and i believe
next week is going to be the second
national week of making with events in
washington DC and statewide and i think
it's for a variety of these three
reasons of Education the innovation
pipeline and strengthening you know a
the knowledge around manufacturing in
the US that that the government is is
really paying attention and wants to
confer this okay so hopefully I've
convinced you that it's not just you
know meet activity but there are some
important reasons underneath why we
should support the maker movement as
well that still doesn't answer the
question does the naked make a movement
need us as researchers maybe they're
just fine building their own tools
because they're very enterprising people
so if I didn't believe that research had
an important role to play and probably
wouldn't be standing here so
let me give you just a couple of reasons
first what is really interesting about
the maker movement is that it inverts
the traditional model of engine
education certainly of engineering
education right with a traditional model
usually is welcome takes a math take
some physics maybe some chemistry then
learn about signals and systems maybe
some assembly and then you work your way
up to step and oh before you graduate
you get to do a project that puts all of
that together which basically means that
for three and a half years or so of your
undergraduate career you're wondering
what is all this good for and so this is
really turning it around and saying no
we'll start with interesting projects in
the first place and then that generates
a pool for conceptual knowledge and more
powerful tools kind of just in time when
they're needed for your project a second
reason is that these projects tend to
combine both questions of design so what
is it that you want to build what should
it do as well as fabrication how are you
actually going to realize it there is
also this new digital fabrication
toolset that's emerging that just allows
us to you know as software people to
really bring our skills to into this
entirely new space and that some of the
machines really are not that new they've
been around for decades but it was only
in industrial settings for a prescribed
small number of industrial uses and so
this exploding a number of people have
access to that equipment gives rise to
new challenges and I think just
generally amateurs need different
abstractions and affordances to be
successful than either from novices who
you want to train to become experts in a
particular domain as well as those
experts themselves and so to me all of
these imply need for new appropriate
design tools yes they say what
distinction you're drawing between an
amateur no novice so a I think of a
novice as someone taking CS one
right who is on the path to becoming a
train software engineer but is only at
the beginning of that path and so for me
an amateur is maybe someone who is
actually not on the path to become a
trained expert in that domain but who
wants to be proficient in a toolset
because they'd like to apply it to
problems in a domain they really care
about so maybe like what we think about
is end-user programmers you know in the
programming world that has some overlap
with this notion of amateur here so
people who program but do it because
they want to understand their data or
want to automate business processes not
because they want to be software
engineers all right so one way to
organize this you know my thinking in in
this area has been this research theme
of understanding what the 21st century
workshop will be like for these makers
and I say workshop you know I you know
historical examples to draw on are the
Wright brothers workshop who were the
first ones to get to controllable flight
and it was their background in as
bicycle mechanics and manufacturers that
really gave them the facility to
experiment with with building things and
mechanisms and so it was you know the
19th century workshop with power tools
that enable that to happen and then of
course skip forward and you get to the
famous garage by Hewlett and Packard
right and it was the emergence of vacuum
tubes and transistors and integrated
circuits that gave them the material to
build instrumentation and later
information appliances so what do I
think the core ingredients are of this
21st century workshop well it's powerful
design software combined with digital
fabrication tools and combined with
ubiquitous basically free programmable
electronics design software of course
enables users to create detailed plans
and specifications and code how their
creation should look like and work like
and this is where a lot of my own work
as a computer scientist comes in we
create the software that lets users
create these these models and plans now
the second important trend here is I
don't think there's quite a Moore's Law
of industrial fabrication in that it's
quite a bit slower but we've seen this
trend of certainly the price and the
size of equipment to make things
dropping by several orders of magnitude
now where the analogy a little tumors
law breaks down is that desktop
fabrication is not as powerful as
industrial fabrication right there many
processes that still only exist at
industrial scale but I think the same
force of democratizing access to tools
and having a much wider variety of
people have access to these machines in
their home their lab or maybe the
hardware store in in their in their town
I think that's the the powerful theme
here and then the last ingredient here
is of course ubiquitous programmable
hardware and that you can get
microcontrollers for sense and you can
probably buy now we're on an operating
system and have a radio for a dollar or
two in in your product so we've been
experimenting with how these this 21st
century workshop should look like and
what people would do in it in the Jacobs
Institute for design innovation so this
is a brand new design institute that we
opened at UC Berkeley last August so we
only have two semesters under our belt
so everything you know say about it
subject to change and might sound quite
different next year we're focused on
undergraduate education so under
undergraduate maker centric design
centric team centric open-ended projects
happen happen in this building
we have three and a half floors where
some of the floors are dedicated to
teaching so Berkeley is a big place or
classes come in quanta of 50 students so
a small class is 50 slightly larger is a
hundred if you take intro to CS it's
1500 students they don't fit into the
into this building and then the entire
first floor is kind of an open
makerspace Fab Lab that's never a
reserved for classes and then we have
various digital fabrication equipment
sprinkled throughout the building kind
of separated according to functionality
so you can give people different access
to to those different tools here's just
a shot of what our first floor
makerspace looks likes on any given day
you might find people working on C&amp;amp;C cut
furniture as well as you know mill
circuit boards populate that i'm working
on electronics and all of the classrooms
are also kind of flexible with power
from the ceiling so you can actually do
actual work on on your desk and going to
have everyone huddle around so in the
first year we've had 15 different
departments come and offer courses we
have a program by which you know
Berkeley departments redesign their
courses to be more design and maker
centric so they can then move into
jacobs all we've had 50 courses come
through trained about 600 students per
semester on safety training for our
machines and there were actually three
thousand enrollment so we went from well
within I think two and a half years from
just planning that we should maybe have
a building like this to operating at at
quite large scale so just want to give
you some examples of the types of
projects that students work on in the
Institute maybe that all because I think
maybe some themes then will emerge so on
the purely mechanical side we have
students work with the enable tech
community on building custom DIY
prosthetics low cost and so these
own yet match in terms of performance or
wait what you would get out of medical
prosthetics but the crucial difference
is that they involve the kids who wear
them in the design process and so there
can be much greater sense of ownership
and pride of i made this thing this is
my superhero hand rather than the doctor
gave me this you know page contraption I
have to wear now getting a little bit
more into what a lot of our projects are
there live at the intersection of
there's some mechanical design there's
some electronic design there is software
design and then there's a user interface
design somewhere as well so in
California we have a drought it did rain
a little bit but that didn't really
abate or problem this winter so these
students build a fixture level water
flow meter so running a power cord into
your shower is probably not a great idea
so one of the core questions here was
how do we build something like that
that's totally self-contained so they 3d
printed this impeller that goes inside
the the tube has magnets on its
periphery water rushes through it spins
up induces a current in a coil that's
wrapped on on the outside that current
is enough to fire up a microcontroller
that uses hall-effect sensors to sense
how fast the impeller is spinning and
then uses a lower energy radio to send
that to to a smartphone and this is
actually right now this was first a
class project at Berkeley and then we
had tech transfer across the bay to
Stanford where right now it's deployed
in their dorms he is maybe a little more
whimsical project this is a rocking
chair that generates power to charge
your phone while you're rocking and what
I like about this project is once again
this intersection of different
disciplines that all find expression in
the final outcome so someone learned
welding to make a frame that could
actually support a person someone god
good at ed woodworking doing the complex
angles that we're all driv
by the goal of having something that's
aesthetically interesting then the
students talk to an energy harvesting
expert to think about well what is a
good way to harness the energy of
sitting rocking and so he said ah you
want to have a swinging pendulum that's
hooked up to a generator then they did
the electronics and there's an e-ink
display in in the in the armrest that
that shows you how much you generate one
last example from the medical domain
because I know they're quite a number of
people here working on new medical
devices and here we see so Berkeley
doesn't have a medical school but UC San
Francisco does right across the bay and
there's kind of a never-ending flow of
ideas that physicians and practitioners
have but that mostly don't get
implemented because right now they lack
the tools and local engineers to do them
so if we can lower that barrier I think
we'll see a lot of innovation so there's
a fairly simple device but can have a
profound impact so sensory ataxia is a
condition where you lose feeling in the
nerve endings of your feet due to
diabetes or other age-related illnesses
and if you've taken a class in controls
if you walk without feeling in your feet
you basically walk open loop and so
people start falling they become very
unsteady in their gait and that becomes
a big complication falls in old age so
here the idea is pressure sensors in the
soul of of your shoe just wirelessly
transmit a simple footfall signal three
feet up to your back where you wear cell
phone vibration motors on the sides of
your back where the nerve endings still
work perfectly fine and in early tests
has shown within 10-15 minutes patients
are able to you know reintegrate that
new information the gate becomes
steadier from from having that simple
feedback system so those are the kinds
of projects that are now all within the
realm of you know students completing
within 10 weeks or so and it
this intersection of aesthetics
mechanical electrical and embedded and
interaction design that all come
together so let me shift now from kind
of the larger motivation and all of the
things we do that kind of contribute to
the research agenda but are maybe not
research in and of themselves so as I
mentioned all of this activity to me
kind of raises the importance of
researching new design tools so i just
want to show you a couple of examples of
work my group has done in three
different research areas trying to
envision future design tools for this
general space so we're going to talk
first about prototyping tools for
interactive devices where you know we're
trying to come up with techniques that
let you rapidly explore what a new
interactive device would feel like
without necessarily using the
implementation tools you would for the
final solution now I'll tell you a
little bit about learning and debugging
tools and if there's time at the end
we'll see there's a third area of kind
of hybrid fabrication tools trying to
think what lives in between the you know
hammer or the motor on a stick that is a
drill that you pick up at home depot on
the one hand and a fully automated cnc
robot like a 3d printer on on the other
hand all right let's just take that from
from the top so in the realm of
prototyping tools are guiding research
questions has been how can we make
hardware prototyping as fluid and as
flexible as the prototyping of graphical
user interfaces because certainly in the
latter area we've had you know decades
of great tools starting with with
hypercard and now going into framer and
mock-ups and all the dozens of tools
that let you quickly mock-up user
interfaces well first so we're going to
focus here in this section on on
interactive input devices so things that
take human action and translate that
into controls for a game or for music
playback or for you know flight control
and
first of all I believe that you know the
even though now we all carry shiny flat
pieces of glass in our pocket at the
same time these input devices aren't
going away because fundamentally hand
and brain co-evolved and so there's
always a strong case for keeping some
some tangibility in our task especially
when it comes to virtuosity and and
performance now if you're here at you
know Microsoft hardware you might
prototype your next game controller by
you know 3d printing what the possible
shapes could look like the fundamental
limitation here though is that that's
just a piece of plastic it gives you
some sense of the aesthetics and the
ergonomics but it doesn't work if you
want to create something that actually
works right well then we're talking
about electromechanical co-design
suddenly this design task is a lot more
complex it's not just what's the shape
of it but where can a fit a circuit
board in it and where can a place
components on the circuit board that
kind of pop out at exactly the right
location and so this is really the realm
of detailed CAD design where you can
spend hours days weeks months into
getting the details right and in general
and prototyping read when ideas are
still at a more ambiguous stage we don't
yet want to commit the time and
resources to figuring out all these
detailed design decisions so we've taken
a couple of stabs at addressing this
problem I'll just do a quick rundown of
some of them so a first idea was well
what if we just keep you in really rough
physical prototyping materials tangible
modeling so could you create working
interactive devices through tangible
modeling so we ran a formative study
that suggested that well some things are
easy for people to express through
modeling such as you know the general
overall shape and maybe how
a phone holder might cradle the phone
other things are quite hard to do with
modeling material if you are not an
expert sculptor like expressing where a
joint is where something telescopes or
where you know other interactive
functionality is located and so what
people usually do then is there's a mix
of I'll express some things tangibly and
for others i use annotation so i may
just draw a sketch and describe in words
what i want different pieces to do so we
use this as inspiration to build a
system called maker's marks where the
idea is if i give you tangible modeling
material and then in addition i give you
a suitable set of annotation tags that
let you express functionality then
probably you can build you know
something that combines you know has
shape intent expressed through through
clay and functionality intent expressed
through these annotation stickers and
then if we take something like net
Gadgeteer like a standard set of
electronic components and these kind of
map onto onto those then maybe we can
help you with the detailed design task
of saying let's make something of the
shape that you indicated that has all of
these actually functional components
inside so here's the rough workflow so
you start out by creating one of these
models and then you 3d scan it so that
now gives us both the geometry as well
as texture images of of your creation
and then we take the set of annotation
stickers that we know that's the library
of things you can use and we basically
do computer vision on all the texture
images and try to find whether you used
any of the stickers on on your prototype
so we find those in the 2d images and
because we know how the textures map
onto the 3d models we can project that
back into the space of the 3d scan and
then we basically want to replace that
sticker with suitable geometry that
you to place an actual component in that
spot so then we have a digital model of
that component that we can now orient in
that 3d space of our scan we can check
whether it actually fits and then we can
automatically synthesize geometry to
kind of snap that in in place so
basically what we do is we take your
model we yes if it doesn't fit then
either we tell you we cannot work with
it or we actually modify the model and
we we take your 3d geometry and we push
it out from the center so for example if
the joystick is too big you'll get a
little bit of a bulge in the back of it
to to house it so we take your model we
shell it we add all these cutouts and
fasteners which kind of requires that
for each of our components we have this
additional metadata then you print it
out and then afterwards we basically
have these snap-fit snap that hooks so
you just snap every component in place
and then you work end up with an
interactive object so the programming
itself of it is not handled by this tool
but this is what projects like dotnet
gadget here and arduino and others right
they address lowering the threshold for
for doing that so the key idea here is
that a maker expresses shape intent
through sculpting and functionality
intent through this placement of
stickers or marks and then our tool
handles the detailed geometry
modification all of this does rely on
having this database of of cad
information about each component
available and so one question is is that
actually reasonable to expect or is that
a deal killer well it turns out there is
one group that has a really vested
interest in creating that those models
and those are vendors wholesalers so
mcmaster-carr is the biggest supplier of
hardware for mechanical engineers in the
US and literally everything they sell
has a cad model associated with it
so it just basically means augmenting
that CAD model with a couple of extra
pieces of metadata alright so that was a
first step of printing interactive
devices second approach we were
wondering well with the advances in 3d
printing can we maybe just instead of
taking pre existing pieces and then
wiring them together can we just maybe
print all of the connectivity in the
inside of objects so now a very
simplified example might be maybe you
want to make this interactive bunny that
has a capacitive sensing on the tail and
and zombie eyes that light up can we
just print this in one go and then you
just stick all of your electrical
components just on the surface in the
end and so basically the idea here is
printing 3d circuit boards inside of
objects while we fabricate them and so
we did this project together with
autodesk so we have a design tool that
allows you to specify basically surface
constraints I want to connect this place
on the surface with this other place and
so we then automatically create the the
connectivity on the inside of objects
and you can do this with kind of
arbitrarily complex geometries now when
we did this project actually we didn't
have a printer that could do this so and
most people today still don't right they
still only deposit a single material out
of out of plastic and so I think one of
the themes we found out is it's really
fruitful to combine automatic techniques
up to the love you can with some men
with some instruction for manual steps
that makers do afterwards because
they're already handy they want to be
involved in the creation of the object
so in our case actually instead of wires
what we create our hollow tubes and so
once something is printed you can then
take a syringe and fill all of those
tubes
with conductive epoxy silver
nanoparticle ink crucible any number of
conductive materials that will that'll
cure and so then you've basically
through one automatic step created the
geometry with all the cavities and tubes
and the second step is you then fill it
with conductive material so they're a
bunch of different examples we created
for example this uses Disney swept
frequency capacitive sensing where you
only attach one wire to an object to
sense a whole number of different touch
pads we've also created kind of you can
use the same approach to create neon art
where you constrain the path of the tube
you create to some graphic that you
import and so you can create something
that looks like neon art but doesn't
require the bending of glass with with
blowtorches now since we did that
project actually you know we're looking
a bit in the future into the future
turns out not all we didn't have to look
all that far now you can buy this
printer called box late which in
addition to a nozzle also has a syringe
that will deposit conductive materials
so you can now actually do this without
the the manual post processing step and
that tool is now in Autodesk smash mixer
which is there free mesh munging
software alright so then let me take a
third run at this project by saying okay
so either you know we can snap an
additional components or maybe we can
just print the connectivity inside the
object what if we just change the
paradigm altogether and instead of
putting all these different component
different places we use a single super
sensor to do all of the input sensing at
once so this is what you saw in the
beginning right so what if we print it
out a game controller like that and then
we just take one single powerful sensor
in our case a camera put that into your
3d printed object and as soon as you add
that sensor all of the different input
affordances on
on the object start to work so this is
the Sauron project how this works is
this is a plug-in to cad software so
here we assume that you have some
familiarity with cat we use solidworks
you can really substitute any cat
software and so you model the thing you
want to create and then you add into
your model one more object and that's a
virtual camera and the virtual camera
basically matches the size shape and
optical parameters of a physical camera
we have so you take that virtual camera
somewhere on your object you create a
port where it can fit in and say I want
it to go there and so that cone is the
field of view of the camera and so you
can tell right away everything that's in
the cone of the U of the camera we can
now see and and sense with kind of
off-the-shelf computer vision algorithms
unfortunately you can't see everything
so you have to be a little bit smarter
so we have a range of techniques Oh
camera here is in green field of view in
blue there might be things that just
don't fall into the field of view right
like this button on the side but the key
realization here was that we haven't
printed this thing yet that means we can
change the geometry to make the computer
vision problem easier on us so in this
case we can just take that button and
extrude it until it meets the field of
view of the camera so here's an example
of you know kind of the extreme case of
for that technique so you could actually
only see one of those buttons but we can
extrude all of the others to fall into
the field of view now that may not
always work so here for example a
straight extrusion won't get us into the
field of view of the camera in this case
we just take a little bit of computer
graphics so we do ray tracing we should
race from the camera into the scene and
look for places where if we bounce the
ray off of the internal surface of the
object by its surface normal it'll hit a
component we want to see afterwards
why do we care about those places well
it turns out if you glue a mirror into
that place and then put the camera in
through the mirror through one bounce
you can see the component so this is yet
another instance of of this principle of
if you add a little bit of manual tasks
afterwards but you tell people where
what to do and where to do it so here
take a 25 cent craft mirror glue it in
that place you can extend extend the
usefulness of your techniques so then
you print the object and then comes the
you know the highly technical step of
creating markers for computer vision so
we just paint them on you can also take
a multicolor 3d printer that will do
this for you unfortunately that right
now still involves you know paying 10
times as much for that to color print
and then you add the camera in and
basically the next step then is running
computer vision so we we do this
interactively there's a calibration step
we're basically highlight something in
CAD and say just move this component
through its range of motion and so in
this case here we'll just do blob
tracking and find the minimum and
maximum coordinates for some of the
other components we don't do block
tracking we do optical flow and so
there's basically a computer vision
algorithms with every type of input
device all of the computer vision
algorithms are off the shelf because the
fundamental inside here is instead of
coming up with a better algorithm we
come up with a better environment so
that existing algorithms perform better
so we've built you know game controllers
mice DJ controllers we had other people
build DJ controls to convince themselves
that this is not only something only the
authors can do and we also went through
basically online repositories of models
downloaded the model
and checked which of these models could
you actually sense with this technique
and so many of them work what doesn't
work is if you have very small devices
and devices that have interactivity
around you know thin features because a
single bounce of light won't won't get
you there okay so the key ideas in this
project use vision sensing on the inside
of fabricated objects and there's this
co design of the geometry and the
sensing techniques so we can modify the
shape to create an easier vision problem
this is basically the flip side of the
usual of the kind of how computer vision
usually precedes we say we don't know
anything about the environment we're
going to write smarter algorithms to
extract more information from the
environment here we control everything
about the environment we fabricate it
right and so we can use that knowledge
to to increase the utility of existing
vision algorithms all right let me at
least tell you about one more project
and then maybe open it up to questions
so in the prototyping tools in some
sense we're creating black boxes right
in that were letting you author at a
higher level of abstraction without you
having to understand what the underlying
vision technique is now I think that's
useful for part of the tasks in
supporting makers but in others you
really just want the make us to grapple
with the complexity of what's going on
and understand it so they learn and
become more proficient so here we're
working on better learning and debugging
tools this is work in progress so not
quite complete yet in particular we
became interested in helping people
breadboard circuit so the the solderless
breadboard has been around since the
1970s and was kind of this revolutionary
step that you could create working
circuits without wire wrapping or making
permanent connections so it actually is
a great prototyping tool in itself
but it has a whole bunch of issues so
whose bread boarded circuits in this
room okay so yes and this should look
familiar right there's this complexity
that appears pretty quickly and then
troubleshooting becomes very difficult a
simple thing like a single loose wire if
you can't easily find out where it is
can take you a lot of time there's also
issues like power am I powering my
components correctly have I inserted
them with accra the correct way around
polarity have I connected the right
wires to the right pins are all my
components working etc so just for
reference this is what a solderless
breadboard looks like from the top right
this is what it looks like from the
bottom if you if you kind of peel away
the adhesive that's usually there so you
have vertical connections on the power
buses and then horizontal connections so
everything on one row is connected to
the middle and then everything here is
connected now if you want to debug your
your breadboard circuit today the usual
mode you do that is by coming up with a
hypothesis of what might be wrong then
breaking out your measurement tool like
a multimeter or an oscilloscope and then
doing a point wise measurement to check
if you know according to your paw 'this
is I would expect measurement X do I see
that or not and you can either do that
Justin voltages or you can do it also
instantaneously or you can do it over
time with with an oscilloscope now our
research idea here is point measurements
require a working hypothesis about the
problem we know from studies of how
programmers debug that non-experts are
not particularly good at generating
correct hypotheses initially and so the
idea is let's replace point measurements
with ubiquitous instrumentation where we
just measure everything all the time and
show you those measurements but also
Oh combine the real world measurements
with some model of the circuit to
diagnose what a problem might be so
here's that idea implemented this is the
toast port the better breadboard and we
basically have instantaneous voltage
measurements on every row running at
about four Hertz right now for for the
board and so initially you can just see
immediately what voltage does every row
have but then if you do a little more
work and you create a virtual model like
a schematic of your circuit right then
we can compare what we know about the
circuit with the measurement and say
well this led looks broken because the
voltage drop is unusually large you
should have a voltage drop of less than
2 volts across the diode so either
you've inserted it backwards or it's
broken right and you can show other
information like here's the the current
through your resistor you know other
things that you can then deduce from the
measurements and a model of the circuit
so the way we make this work is we take
a breadboard and then put it on our own
circuit board and we have a multiplexer
scan chain where we basically scan every
row of the breadboard round-robin that
gets connected to a microcontroller
which drives these LED indicators on the
board but also forwards all of that data
to to our software so not sure you can
tell much by this board but what's just
a little detail under the hood is how do
we make all of those connections well we
have a circuit board where you put your
breadboard on here so you peel back the
foam and then you put it on on top of
these pads and we use the access
transfer tape which is adhesive that has
tiny spheres of conductive material
embedded in it which means it only
connects in the z-axis but not x and y
so you just take a single strip off that
tape put it over the board put the
breadboard on top
and then there are some mechanical
issues that I'm glossing over but that's
that's the gist and so then what that
what that lets you do is you know debug
all kinds of problems either through
just simple inspection of the voltages
or through these smart hints that we
layer on top of it so for example here
if you connect this circuit right
there's a wire that connects the
resistor to to ground well there should
really only be one roll it up here the
fact that they are to larosas lit up
tells you that oh you probably didn't
put the wire into the correct row and
similarly we can then also run a higher
level check which says there is no
current through this resistor at all so
you probably didn't connect it to your
circuit and so we're still exploring
what the set of checks is what the set
of automatic feedback is that that we
can give you importantly also right now
we only handle standalone circuits not
circuits that then have Arduino zanette
gadget ears general microcontrollers
connected so that's kind of a whole
other big area of of open questions okay
it is 1050 ah why don't I skip ahead to
some takeaway messages and then open up
to a couple of questions so I think
across this research program a couple of
key themes emerged for me from the users
perspective one in in the prototyping
work right you really want make us to
describe their goals at a higher level
of abstraction then let tools take care
of mapping those goals to the really
detailed design work like generating
bosses and cutouts and manipulating
vertices there is this distinction of
whether you're working whether your tool
is a black box or a glass box so i think
in prototyping doing a black box is
often fine but when the complexity is
inherent in the task and you want people
to learn about it
right then you actually want to show a
lot of information and guidance like in
the debugging work there's this a
high-level story of getting more utility
out of digital fabrication by
intelligently combining automatic and
manual processes and then this is
something I didn't show you receiving
guidance through examples and tutorials
now a key technical couple of key
technical themes here are the projects
students work on in jacobs hall in
makerspaces fab labs integrate
mechanical electrical software questions
of use questions of aesthetics so our
design tools should kind of take this
integrated approach as well where
possible and given high level
specifications co-design sensing and
geometry like things that usually live
in different worlds right to combine
them together combined computer vision
AI digital signal processing techniques
for recognition with geometrical design
I showed you this with a computer vision
we've also done this with sound where
you know you print shapes that that you
know when they're struck vibrate at
specific frequencies and that means it's
very easy to create an audio classifier
based on that for the for the debugging
work it's really ubiquitous sensing
right work with rich real world data and
import that into the design environment
and then something that that we're
really interested in that turns out to
be a quite hard is 3d scanning has also
come down in price but you barely ever
see 3d scanning used productively in
makerspaces today and that is because
what comes out is just this mass of
noisy data and then you tell then you
say here's your 3d scan now please deal
with these million vertices and so
making 3d scanning a productive
ingredient in the in the Fab Lab
toolchain kind of requires abstracting
way from dealing with vertices and
pixels and really is about a high level
of understanding what do you want to do
with this object and then that
algorithms take care of all the geometry
modification future outlook here I think
there's really interesting work right
now being done in material science that
is filtering into the maker movement so
like conductive materials printing multi
multiple materials at the same time
printing a 10 to 100 times the speed and
so I think that will be an area where
we'll see lots of interesting work
emerge I think physical construction and
debugging tools are kind of ideally
suited for augmented reality
applications that includes but is not
limited to head-mounted displays I think
there's a lot of work we that can be
done that we started to do with
integrating projection into handheld
tools and we're using Jacobs Hall as a
living lab to deploy and test all these
tools and I think you could also use a
mic Sinclair shop around the corner also
as a place to deploy tools like this to
make sure to give credit where credit is
due at the end in that all of this work
was actually done by a fantastic set of
students and I just get to talk about it
all right thank you yes which of these
tools you can extend to their skirts
that would be useful for experts as well
so depends on what the what kind of
experts so for example the prototyping
tools also were informed by my work with
professional product designers who do a
lot of prototyping and they're experts
in the design process but they're not
expert trained electrical engineers
either that I've so right do they
transfer to expert software developers
expert electrical engineers I think this
idea of integrating the concerns you're
investigating across
different domains software plus
electronics electronics plus mechanical
that is I think right now also big topic
at places that make professional design
tools like Autodesk like national
instruments and so maybe the particular
techniques don't apply but the larger
approach of thinking across the
different domains that that is relevant
to experts as well so um question about
you know the prototyping tools and you
know I feel like there's like a chicken
and egg problem are you want agree
prototyping tools to help makers make
what they want to make they don't know
what they want to make because they
don't approach admin tools and then what
they wanted to be a great and so you
talk a little bit about like some of the
preliminary studies you had done with
them so weak I like how do you go about
you talk a little bit more about that
like how you go about understanding of
what they want to be able to build and
so you know what rice too great um so
hanging out in those spaces is certainly
a good first step and observing and also
i think there's there's a whole bunch of
kind of remote formative work you can do
by looking at what happens on places
like thingiverse on instructables and
you do get this differentiation that
there are some lead users who usually
have more experience maybe visit their
professional life who then push the
boundary of what can be created and then
you can maybe look through you know do
those projects resonate with the larger
community in terms of that's those are
the kinds of things other people would
want to build as well but you're you're
right if tools don't just makes things
easier but they make new things possible
there is a bit of the the challenge of
what do you want to yeah what you want
to have that's that's possible so in our
class in the class that I teach called
interactive device design we approach
that with a you know quite standard
neat finding design process where we
sent the students out and say you can
propose anything in this class that that
is an interactive device but you have to
demonstrate that you found a user talk
to them and understood what some of
their needs are and so that that grounds
that leads to a wide space of different
ideas of what our students want to build
for others which is not quite the same
as what do I want to build for myself at
home so you got both like these students
that should be a great like falling
functional to get out of the same
process like when you see is the future
when you want to like desktop and over
the form that guess like when these two
except if you still have the opportunity
to work with them and get the phone
right the functionality answer yeah so
um 11 limitation here is that this
process compared to modifying
iteratively modifying software this
process is still kind of slow right and
so I think so you made something and
then it's not quite right how do you how
do you then incorporate the changes into
the next design iteration so yeah that's
a an interesting question so one thing
that's actually happening is maybe the
machines will catch up to the speed at
which we can think about modification so
for example we just started printing on
a carbon 3d printer at Berkeley which
has it's a material science innovation
of controlling the amount of oxygen you
have at the lair where you you do
photopolymerization so anyway started at
a lots of lots of details the outcome is
you can print something this size in 15
minutes and so once you're at that speed
then it becomes feasible to do lots of
physical iterations the question is how
you express the intent
of how things should be changed I think
that's an open question right is can you
maybe print in malleable materials or
can you then annotate on top of the
printed object itself with what you want
to have changed so there's some great
work from Francois Kimbra chair and
Chung Yun Seong from about 10 years ago
basically printing out objects and then
just writing on them and interpreting
that as modifications there's also some
great work by Stephanie Miller out of
Germany who's going to MIT who is also
really trying to shrink down that cycle
time for interactively modifying these
physical products so some maybe some
pointer so that's gonna happen okay
we'll end it there extent consumers yeah
XP right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>