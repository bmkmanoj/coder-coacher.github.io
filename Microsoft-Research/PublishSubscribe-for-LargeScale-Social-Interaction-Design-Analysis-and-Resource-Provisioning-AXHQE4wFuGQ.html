<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Publish/Subscribe for Large-Scale Social Interaction: Design, Analysis and Resource Provisioning | Coder Coacher - Coaching Coders</title><meta content="Publish/Subscribe for Large-Scale Social Interaction: Design, Analysis and Resource Provisioning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Publish/Subscribe for Large-Scale Social Interaction: Design, Analysis and Resource Provisioning</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AXHQE4wFuGQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
thanks for follow you for coming sorry
them Nick it is our pleasure to
have in a city today visiting us from
University of Oslo and avena has done
some interesting work on pop subsystems
and peer-to-peer and other interesting
and the stuff so over to you feeling
thank you hello everyone thank you for
showing it so early in the morning today
I'm going to talk about
publish-subscribe systems for social
interaction mainly in social networks
the design aspects of it the workload
analysis for it and resource
provisioning for it this is a joint work
with my supervisors Roman and Martin and
also a couple of employees from Spotify
gooner and Vito so just a bit of a
background about me I'm a PhD candidate
at university of oslo in the networks
and distributor systems group and my
supervisors are Roman Wittenberg and
Martin Weinstein and during my PhD I
have been working on mainly
publish-subscribe systems various
architectures for publish-subscribe
systems like peer to peer peer assisted
and also looking into subscriber
satisfaction problems and also a
resource provisioning for so during my
PhD I also got an opportunity to do
research internship at spotify some of
the work I present here today was done
during that period of time and before my
I started my PhD thesis I did masters in
Max Planck Institute for informatics in
saarbrücken Germany it was about
identifying interesting time points in a
web archive or a text archive this was
in professor Wycombe screw if you know
and before my Master's I also have
almost three years of work experience as
a software engineer from a company
called electronics for imaging in India
and also got my bachelor's before that
from India as well so I'm not sure if
you are familiar with publish-subscribe
systems in Charlotte spot some it's a
communication paradigm there are
publishers and subscribers and there is
a middleware which access a connecting
overlay or a bunch of brokers which are
matching the subscriptions against
publications and delivering it to the
subscribers so basically there are
subscribers sending subscriptions to the
middleware and there are publishers
publishing relevant publications and
it's the job of the middle where to
deliver them those notifications to the
subscript subscribers there are
typically two types of matching like
topic-based matching very discreet
topics against the publication which
publications are matched and deliver
this also attribute based matching which
is more commonly known as content-based
pops up so there are several industry
standards and applications which are out
there one most popular example is even
RSS feed distribution can be considered
as a pub sub application and there are
standards from omgs real-time data
dissemination service there are also
many topic-based pub sub systems out
there used in the industry there is
tibco rendezvous pops up and google's
internal pops up for synchronizing data
across their data centers called coops
and finally during my thesis i found out
that pub sub also plays an important
role in delivering social interaction
events and this is especially true for a
spotify so i'm not sure if you are
familiar with spotify if not it's an
on-demand music streaming service it has
a large collection of music tracks with
over 20 million tracks it's available
more than in more than 55 countries
across the world and there are more than
25 million active users using it it's a
fast and legal way of listening to music
and
but not the least the little known
feature of Spotify is it also allows
social interaction among its users so
we'll see indeed it what I mean by a
social interaction so if you're familiar
with Spotify client and in the bottom
right corner you can see a real-time
feed of what your friends are listening
to and what your favorite artists are
doing like if they released an album or
if they created their a playlist of
their favorite songs you get notified
instantly but one thing i want to
emphasize here is that this event feed
is fixed a number of events here so
anything if there are more events being
generated at any given point of time the
user will not be able to see those extra
events and they're just discarded so let
me go more in detail into what's what
kind of social interaction and talking
about and what how it maps to pops up so
there is Spotify user and we can follow
other Spotify users are imported users
from facebook when that happens whenever
the friend listens to a music track or
creates a playlist or updates a playlist
and the user gets notified about it and
there are also artists in Spotify you
can follow artists and as I said when
they release an album or a music track
the user's get notified about it there
is also a feature in which the artist
can be verified which means the account
belongs to the real artist so whenever
they listen to music basically the music
activities are also notified and in
Spotify there is also a concept of
playlist where you can just create a
collection of music tracks into a
playlist and some of them are public so
you can search for playlists and you can
also follow them subscribe to them and
of course if there is an update to that
you get notified instantly about it and
finally optionally all the music
activities of Spotify user can be also
posted onto external social networks
like Facebook and Twitter so
having studied pops up for for a while
now it clearly maps to a set of topics
and there is a subscriber in the middle
and for me look it looks like a very
nice fit for a pub sub communication
paradigm so you can also map other
social interactions out there into a pub
sub communication paradigm for example
Twitter where users follow other users
and the follow relationship if a user
follows a sort of use other users we can
say inputs of terms that user subscribes
to these other users and also conversely
you can say that if a user's being
followed by other users then it can the
same user can be a topic so he's being
followed by subscribed by other
subscribers so one unique thing about
the up sub for social interaction is
that a user can be both a topic and the
subscriber so it can also be a publisher
as well as subscriber so I don't think I
need to motivate much that the social
interaction is of large scale these days
to just to give you some perspective in
Spotify there are billions of
notifications being delivered every day
and it amounts to more than two
terabytes of data and being sent into
Spotify data centers and deliver to the
back to the users and there are millions
of active users across 55 more than 55
countries who are subscribing to these
events as I said there are 25 million
active users and at any given point of
time more than twenty percent of users
are subscribing to this pub sub system
and basically Spotify has three data
centers to in Europe and one in North
America the last time you and to give
you some numbers about Twitter I you
probably already know but there are more
than 500 million users on more than 200
million active users and every day they
generate more than 400 million tweets
which amounts to just pull terabytes of
just a tweet
data being sent and received from
Twitter data centers so such a large
scale poses several challenges one of
the most important thing is it demands a
scalable architecture it should be
naturally scalable with the number of
users so in this regard there is a need
for decentralized solutions and having
seen examples of Twitter and qualify
where they redesign their delivery
notification delivery systems due to
increase in scale sport if I especially
wanted to explore if there are natural
ways to scale social interaction
naturally net number of users so in this
regard during my PhD thesis I wrote on a
paper which was published in
middle-earth 2012 this was about a
peer-to-peer publish-subscribe system
for topic-based pub sub systems where we
show that it naturally scales well with
number of users this was a gossip based
overlay to maintain the overlay and we
show that it is scalable with number of
users number of topics and subscription
size which is the number of topics per
user and so on I'll not go into details
of this work in this talk due to a
limited time but just to give you an
overview we in the overlay we wanted to
avoid any rendezvous nodes or special
nodes or special peers which could be
the bottlenecks so and also we wanted to
avoid any relay nodes which are for
example if a node is not subscribed to a
topic it will not be participating in
forwarding the events which is not so
which it is just not subscribing to and
we also show that it's a low latency
delivery and also under churn when the
nodes are joining on leaving the overlay
it performs pretty well in terms of
delivery rate so just to give you
and one is a snapshot of the result we
compared the Miss ratio with Twitter and
Facebook data and we introduced the
churn from skype chat races and we show
that it performs at least 10 times
better in terms of Miss ratio compared
to popular pub sub system topic-based
pops of system scribe which is built on
pastry it also relies on the current
handling of the pastry and it does not
do a good job of preparing the olive in
it when the Norse are leaving and
joining so the next challenge in the
data center sign is important for a
podcast in the context of machinery data
center ok so we addressed it in a more
general peer-to-peer setting but it can
be a single data center in Spotify
probably does not in a data center
doesn't so actually inside the fact they
meant to put on your computer in 45 days
cycles and well in Spotify case we were
actually looking at peer-to-peer network
of the clients of the users because
Spotify is already a peer assisted
streaming service so there is already
appeared to be a network existing for
streaming audio so we wanted to explore
if it's possible to exploit the same
network to deliver pops of events as
well but yeah in the Holocaust was
purely peer-to-peer pub/sub system but
as we'll see later in the talk and the
other ideas we looked at was to actually
combine these two and have a peer
assisted solution for Spotify so the
other challenge in large-scale social
interaction pub sub systems is that a
real lack of real-world workload so in
this regard we got an opportunity to
study the workload characteristics of
Spotify pops up and it was published in
distributed even based systems
conference last year I will not go into
the details of the work but I'm happy to
talk to you later about it the next
challenge we wanted to look at was the
distribution of more clubs so this was
related to the POS system architecture I
was talking about so basically instead
of having all the workload being handled
by the Spotify back and infrastructure
for pizza we wanted to see identify the
part of the workload which is more
beneficial to the users and offload the
less beneficial workload to low capacity
computing or less reliable computing
like peer-to-peer network which was what
you call it decentralized something well
the whole point of that was exactly to
spread the work out yes so how does this
differ from what you were talking about
to begin the first topic so in the in
the beginning there is no
differentiation in the workload all the
work load is distributed to a
peer-to-peer network so but it's less
reliable in the sense that the appear if
you rely on a computing power of the
client users then it's less reliable and
then being delivered by the back-end
infrastructure which is dedicated for
delivering the events so in the
peer-to-peer part we didn't address any
reliable delivery or any persistence for
example but the back-end infrastructure
provides all that so that's why we want
to identify more important work load
I'll come to the part what I mean by
more beneficial workload and the rest
can be distributed to peer-to-peer
component so to identify more more
beneficial workload we worked on various
satisfaction metrics for subscribers so
makes subscribers happy and beyond which
any other anymore delivery of events is
being wasteful so in this work was
recently accepted in infocom it is to
appear later this year so just to give
you an idea here if the there are many
topics being subscribed by a user
usually the kind of social interaction
systems we are dealing with here the end
user is a human user who has a certain
limited capacity of processing the
events at any given unit of time so
let's say we have a subscriber who
subscribes to two of his friends Alice
and Bob on two celebrities gaga on paper
but all of them together produce a lot
of events which is too much to handle
for the subscribe the subscriber says
that I can only handle five events at
any given point of time so this gives us
a threshold on satisfaction for the user
and we set that to be five which is the
processing capacity limit for the user
so having a delivery rate for each user
beyond this threshold is not beneficial
but having the deliberate below this
threshold is a is less beneficial I can
be bad for the user because he may think
that there's something wrong with the
system and may suspect that some failure
or something so in this regard we define
novel satisfaction metrics where we say
that each user can define a delivery
rate that they want to subscribe to and
the goal is to meet these satisfaction
threshold for as many subscribers as
possible and with by considering there
are other aspects like cost and resource
availability
good for the user so there's no kind of
prioritization yeah and in this work we
consider that but you can also imagine
the variations of this problem where if
there is a ranking function provided
between the subscribers and the topics
you can prioritize them based on the
score so yeah I mentioned all these
things that in this work we define a
satisfaction set of satisfaction metrics
and our goal is to select part of the
workload which meets the satisfaction
metric and we also briefly provide an
architecture where you can be used to I
offload the workload to the less
reliable and cheap computing power like
peer-to-peer network so the next
challenge is resource provisioning so
for example to give you an idea in
Spotify it was not very they didn't have
a proper tool to measure the amount of
resources needed to drive the pups of
workload they had and most of the time
they're just all provisioning it so not
the punic paper you're talking about the
central infrastructure yeah okay so in
this regard we solved provided a tool
where but given a pub sub workload we
give the amount of resources needed to
meet the satisfaction of all the
subscribers are given target number of
subscribers with the saints same kind of
satisfaction metrics I talked about
earlier and we also use pricing model
from let's say cloud service providers
like Amazon and then we provide a tool
where you can come up with a resource
allocation which minimizes the monetary
cost so this was recently accepted
in nicd CSI I guess this group is
involved in the track same track so and
the rest of the talk I'll talk about the
subscriber satisfaction problems which
is used for identifying more beneficial
and less beneficial workload and various
solutions for it and then I move on to
the problem of resource allocation cost
effective resource allocation in the
data center and cloud settings and then
I conclude so coming back to the same
example earlier there's a subscriber who
has a specified satisfaction metric and
now we have a limited real estate where
we want to show the notifications for
the subscriber relate relevant to the
subscribe topics of course there you can
imagine various types of ways to fill
this real estate as you mentioned it can
be ranked so so that you can it can be
like a top cake kind of delivery of
events or it can be the most recent very
give the recency priority or it can also
be diversity where you can diversify but
the last one which is the main focus in
this work is actually from the pub sub
service providers perspective how to do
it in a most cost-effective manner
because Spotify for example does not
consider this to be a critical
infrastructure but they also they still
want to have this feature with minimum
as minimum cost as possible so to
achieve this we define satisfaction
metrics and the goal is to select
cost-effective workload to maximize the
satisfaction of the subscribers and also
allocate resources to achieve that so in
this regard we define two binary aside
to satisfaction metrics and the first
one is called binary satisfaction
metrics where we have a subscriber and
for example I'll explain the binary
satisfaction metrics with an example
with the same satisfaction threshold
which was specified in the previous
example the five for example and there
are certain topics and each topic as a
event rate which is the number of events
per unit of time let's say a bob has
four events per unit of time and each
topic also has other subscribers of
course in addition to this subscriber in
the given example so according to the
binary satisfaction metric the goal is
to now meet the delivery rate event
threshold for this user which is five in
this case but selecting bomb does not
meet that criteria so in the body
satisfaction metric in the user is in
this case is not satisfied even though
it meets four out of five the
requirement but now when we include gaga
which contributes a hundred percent to
the required threshold and this is now
on the user is now satisfied and the
second type of satisfaction metric we
defined was fractional satisfaction
metric where instead of saying that a
user is either satisfied or not we give
the relative value to the satisfaction
in this case in a user is eighty percent
satisfied even though it's not hundred
percent but when GOG I selected again
hundred percent satisfaction is met but
one more thing I want to emphasize here
is since Gaga has 1 million other
subscribers selecting Gaga would also
contribute twenty percent sent to
satisfaction of 1 million other
subscribers so their satisfaction
thresholds might be different so why
twenty percent and also just because
subscriber V we let em see gaga stuff
doesn't mean you making that decision
for everybody else yeah so
in the in our model to simplify we
assume that this satisfaction metric is
constant for especially in a Spotify
case each client has a fixed amount of
events that they can receive so so but
but I don't see why this cannot be
changed and we can Mesa kaleem a get a
function and each subscriber can specify
their own satisfaction metric and yeah
in that case the contribution is not the
same but it's it's the power subscribe
or dependent but that doesn't affect a
problem difficulty of the problem or the
solution Gaga means that you selected
for everybody yes isn't that a big
assumption I mean maybe it would be
better for me to you know have Allison
bulb and be burned for somebody else
that Gaga on ball so that now you're
talking about actually are ranked the
same thing justice mentioned that if
there is a priority if we can give
priorities to different events so if
there is a ranking function available we
can do that as well and we can I'll come
to the heuristic where we look into the
benefit and cost of choosing a topic and
we can rub the benefit to include the
priority that you specify are each
subscriber specifies you're saying if
you select once or one source of one
publisher for one user you selected for
all users yes okay it seems like a big
assumption okay yes it would all
interested users yet so each topic also
has a cost the cost can be modeled it
depends on the amount of resources that
it requires to drive that topic our
deliver subscribe publications to the
subscribers of the topic so for to
simplify the model we assign it set it
to be the event rate times the number of
subscribers of the topic and now there
is a capacity
the constraint on the the backend
pub/sub infrastructure like for example
in case of Spotify they say we have
these many servers and this is a
capacity they can handle and now the
goal is to select topics in such a way
that we don't violate the capacity
constraint but meet the satisfaction
metric of as many users as possible so
to formalize this problem it's a
ridiculous name but we do in short it's
called b3m because we we saw that it's
similar to set multi cover under budget
and constraint problem but but in nature
it's a different problem so we are given
a set of topics and their event rates
and the subscribers and we are given a
binary satisfaction metric and we are
also given a capacity constraint and
back-end infrastructure the objective
here is to maximize the number of
satisfied subscribers without violating
the capacity constraint and in the paper
we prove that this is np-hard problem by
a reduction from densest k sub graph
problem if you are aware and as a
corollary will to show that there is no
polynomial time approximation scheme for
this problem so we we stick to the
heuristic based solution I'll explain
the heuristic with an example consider
again there are three topics and two
subscribers and for the purpose of
example and they both have same
satisfaction threshold which is five in
this case so the heuristic is to compute
the contribution of each topic towards
the subscriber so in a very simplistic
model it's just the event rate
contribution of event rate towards the
uncovered events which is the to meet
the satisfaction of the subscriber but
so this is the threshold for a fire
subscriber there is a threshold so for
example in this case the uncovered for
both both the subscribers is five since
we have not selected any topics so then
we select the topics which made the need
needs of the subscribers that's our
shoulders the subscribers partially then
uncover those decreases and eventually
when all the satisfaction threshold is
met the uncovered becomes zero so the
satisfaction threshold minus the cover
when we select the topic the event rate
of the topic is it contributes to the
cover so for example here some of the
event rates of the selected topics sorry
the cover is the sum of the select of
the event rates yes the selected topics
okay so for example if gagah is selected
here the covered part is three and
uncovered part is two for both the
subscribers so now for each topic we sum
up the contributions towards their
subscribers so that's why I say when
when we can have benefit we can modify
the benefit to include the ranking as
well suppose we have a separate let's
say a weight function to give ranking
for each subscriber differently then we
can compute the benefit of the topic by
introducing the rank or the weight and
weight the COS takane street so and then
we compute the benefit to cost ratio and
the algorithm is that we select the
topics with the best benefit to cost
ratio and as we select the topics more
and more we update the benefits of
affected topics which have common
subscribers because having selected a
topic for a subscriber decreases the
benefit for contribution from the
the topics so in this case we have a
time we break the ties with by choosing
the topic with the most absolute benefit
in this case it's it's gaga and when we
select gaggenau the covered part is
three and uncovered part is two for the
given satisfaction threshold of five and
one more thing i didn't mention is they
also there is a capacity server capacity
and as we select more and more topics
the capacity decreases so as we proceed
with the algorithm the benefit of for
example bob is now increased to one
because if you select Bob it completely
meets the satisfaction of subscriber we
won so and then it becomes the most
beneficial topic and this is the topic
which has highest benefit to cost ratio
and then we picked this topic and
finally we also pick be able to make the
satisfaction of both subscribers in the
fractional version the problem setting
is very similar but only difference is
the satisfaction metrics is a metric is
a fractional satisfaction metric but
here instead of focusing on maximizing
the number of satisfied users we the
objective is to maximize the cumulative
fractional satisfaction for all the
users so it's it may be possible that
none of the users are a hundred percent
satisfied but all the users are let's
say ninety percent satisfied so I the
goal here is to maximize the
satisfaction of as many users as
possible without focusing on completely
satisfying any single user but it turns
out such a small modification to the
problem also changes the hardness of the
problem and it's very similar to
budgeted max cover problem and inspired
by the salute
for budget and Maxwell problem we also
propose a greedy algorithm which gives a
constant approximation ratio so coming
back to the same example as earlier here
the algorithm is similar but the way
contribution is computed for each topic
is is different only difference here is
instead of looking into the uncovered
events and how much the selected topic
contributes to the uncovered events we
keep the denominator constant which is
the satisfaction metric are whatever the
satisfaction metric of the subscriber is
and then when we choose a topic we see
how what fraction of it it covers but if
it is meeting more than hundred percent
of already required number of events
then we give a maximum of 12 the
contribution again the algorithm is the
same we sum up the contributions to get
the benefit of the topic and we can
occur a show of benefit the cost I mean
we select the topic with the best
benefit to cost ratio again in this case
we break the ties again by choosing the
topic with the best absolute benefit
which is Bieber for subscriber v2 but
now the interesting thing here is that
the benefit of gar gar towards the
subscriber v2 becomes 0 because
subscribe a video is now completely
satisfied choosing gaga does not
contribute anything to that subscriber
so this we make any important
observation here that the contribution
and the benefit can only decrease so
it's a property called sub modularity
where if we select more and more topics
to an add it to a bigger and bigger set
of topics the benefit keeps decreasing
so if we exploit this pup property of
submodule
ready later I'll show that how it helps
in our well in improving the performance
of the algorithm where we can avoid
updating the benefits of all the
relevant topic so if we if we sort the
topics according to their benefit and
then if we go on updating the topics
until we see that there is no more
decreasing in the benefits then we can
stop updating the benefits of the topic
this pre-termination of updating the
benefits has significant improvement in
the performance so just to complete here
the the next topic that the best benefit
to cost ratio is Bob Bob and when we
select the Bob in this example it turns
out there's no more capacity to choose
third topic Gaga and which leaves
subscriber be one eighty percent
satisfied and subscriber v2 hundred
percent satisfied so let's see how these
heuristics perform in practice we use
the data set from Spotify with
subscriptions and publication rates and
it was collected for 10 days from
Stockholm center and for satisfaction
threshold we give an exponential
variation of the default and constraint
they having like I mentioned in Spotify
client you can only see a fixed set of
events fixed number of events and that
turns out to be 25 and we give an
exponential variation of this to see the
to do the sensitivity analysis and we we
also said the cost of atopic as I
mentioned earlier to be the event rate
of atopic and times the number of
subscribers basically this is to capture
the amount of resources needed to handle
that topic and we also set a capacity
constraint on the back end instead of
setting arbitrary capacity constraints
what we do is to compute the cost of all
the topics in the system and the entire
workflow and then we select we said
city to be ten percent of this topic
sorry ten percent of this cost total
cost basically what we want to see is
given ten percent of resources what is
required to run the one hundred percent
of the workload how many subscribers we
can satisfy well and the goal is to
offload the rest of the workload to peer
a peer-to-peer network for example and
to compare the quality of our results we
also derive an upper bound for a given
set of topics and their costs we see
that without worrying about semantics of
who subscribes to who we can actually
come up with an upper bound and how many
subscribers in theory we can satisfy but
this is a loose upper bound so what you
see here is in the x-axis the capacity
like at each iteration of our heuristic
algorithm we measure the number of
satisfied users and what you see in
x-axis is a cost required to meet the
satisfaction of a number of satisfied
users so the number of satisfied users
is in y axis and this is up to maximum
of ten percent of total workload cost so
the red line is the output of our
heuristic for binary satisfaction in the
left side and for the fractional in the
right side and the blue line is the
derived upper bound so there is there
are four point nine million users in
total and in the binary satisfaction
case we are dealing with maximizing
number of satisfied users so when we
look at ten percent cost then we see
that they're more than seventy percent
users satisfied while we are only using
ten percent cost but in the fractional
case the number of satisfied users does
not make sense but we look at the
average satisfaction of all the users
which is the
traction we computed in the fractional
satisfaction metric I defined earlier
and it turns out with only ten percent
of course we can meet ninety percent
average satisfaction for all the users
so in the next experiments we wanted to
see how it performs in terms of running
times and we see that all the variations
of the algorithms from running under 35
seconds with the here I want to show the
impact of sub modularity optimization I
talked about earlier and with this a
modularity optimization for fractional
version we can see that it runs in under
20 seconds in for all the different
values of satisfaction and it turns out
for a very large satisfaction metric it
actually runs faster because you can
imagine if you said the satisfaction
metric to be infinite then we don't have
to think if we can just select all the
topics because we need all the topics to
satisfy all the subscribers so which
means for large values of satisfaction
metric there is less computation to do
our lessons to update or so I trans
faster compared to lower and
intermediate values of satisfaction
pressure we also wanted to see how the
heuristics perform when we recompute at
periodic intervals with the changed
workload in the let's say in last 1 hour
or so so for this case we divided the
workload into how early windows with 30
minutes overlap with the neighboring
windows and we wanted to measure both
running times as well as ratio to the
upper bound derived upper bound and we
see that it's pretty constant across all
the windows this is for 10 hours of time
and in terms of running time for the
frack
heuristic for the fractional version is
pretty constant around 100 milliseconds
while the solution for the binary
satisfaction metric is very sensitive to
the workload this is again because of
the pre termination of updation of
benefits due to sub modularity that I
talked about so I switch gears and move
on to the final part of my talk which is
resource allocation for pop some to meet
the satisfaction of subscribers all the
subscribers in data center and cloud
settings so in the previous work we
considered the back-end infrastructure
to be a single unit but in practice it's
also hard to set a capacity constraint
on this single unit and it's also not
single unit it's it's comprises of many
servers or in terms of cloud its many
virtual machines and the goal here is to
find a resource allocation which
minimizes the number of virtual machines
required to drive this workload to meet
the satisfaction of the users and also
at the same time minimize the bandwidth
consumption total bandwidth consumption
for driving this workload this bandwidth
consumption I'm talking about is the
inter server bandwidth sometimes in case
of Spotify for example if the pub sub
servers are distributed across data
centers let's say there are subscribers
connected to modify data centers in
Europe data center and North American
data center and there is a topic for
which the subscribers are in both the
places and now we are required to
replicate replicate the events to all
the subscribers and this incur a
bandwidth overhead of replicating
the publications across different data
centers are even within the same data
center across many different servers so
we see that there is a trade-off between
number of servers and and the total
bandwidth consumption if we try to
minimize the number of servers by by
allocating the topics to as fuse servers
as possible it may not necessarily be
bandwidth efficient at the same time if
we try to avoid bandwidth replication it
may not be efficient in terms of number
of servers used so to show that with an
example consider there is a subscriber
and the satisfaction metric is defined
in such a way that either selecting Bob
alone meets the satisfaction of
subscriber or selecting Bieber and Gaga
together meets the satisfaction of the
subscriber so to meet this satisfaction
of the subscriber we basically have two
choices and suppose we also have two
servers with their occupied capacity in
the grey show shown in gray and the
available capacity in showing white and
it's in such a way that Bob does not fit
into any of these existing servers if
you have to look it if you have to
select Bob to meet the satisfaction then
we may have to deploy a third server but
uh oops load is carried by one server
yes why are you assuming that so sorry
all of Bob's workload for this
subscriber just that this justice
subscriber here he only can get five
requests a slot that's very tiny load
right so I guess Bob's load for
everybody might be a lot well sorry once
subscribers can be very small line so
the Bob slowed for every subscriber can
be divided so the sink smallest
granularity we are looking at is the
topic subscriber pair so in this example
I'm saying that
bob and this subscriber Lord cannot be
fit into any of the existing servers
typically we have millions or billions
of subscriber topic pairs right but
they're all very small so the lowly post
by Bob subscription to this particular
subscriber is very very tiny each
individually each individual is very
tiny yes but it doesn't mean that you
can always allocate to existing server
so it depends on what's available it
always it's always possible that there's
not enough capacity like one more yeah
and also there are topics which are
generating way too many events these are
not significant number of topics but in
the workload analysis we saw that there
are very few topics which generate
thousands of events every hour because
this also depends on music activities
and so on many things so in this case if
we select Bieber and Gaga who are
relatively cheaper topics are smaller
load fits into existing servers but
together they have higher bandwidth
costs but selecting bob has a lower
total bandwidth costs but if we have to
select Bob then we may have to allocate
a new server the answer to this question
if we're talking about drops here why
would you if your bucket is already so
close to fill that you have to care
about how big the drop is surely it's
just time to get another bucket what why
would you want to optimize you know oh
yeah the book is 99.99 fool if you're
really that close that one subscriber
topic pair so I'll generate few events /
are in fact is we are not talking about
one topic subscriber repair
right it's it's it's a it's algorithm
which is running and when do you decide
so it's ninety-nine point nine percent
or nineteen ninety percent or when do
you decide that we start allocating a
new your server see my team anymore
sorry
it's just about throughput or latency as
well oh okay we are not considering
latency here I mean these are social
interaction events and at least from the
Spotify perspective and latency is not
critical it's not isn't our critical set
of events we are talking about so we
formulated this problem again for a
given topic subscriber pairs and their
event rates and their and a binary
satisfaction metric the objective was to
compute the minimum cost required to
meet the satisfaction of all the
subscribers and the cost depends on
number of servers and the total
bandwidth consumption and if we are
given a pricing model from let's say
Amazon ec2 pricing model then we strive
to minimize the total cost total
monetary cost and unfortunately this
problem is also np-hard and there we do
the reduction from partitioning problem
and we stick to heuristic solutions here
as well so we solve the problem by
dividing it into two stages in the first
stage we assume there is a single server
with infinite capacity and try to select
as many certain topic necessary topic
subscribers in such a way that the total
cost is minimized and meet the
satisfaction of all the subscribers so
if we have an optimal solution for this
problem this is the absolute minimum
cost that is required to meet the
satisfaction of all the subscribers and
in the second stage we simply distribute
this load and the second stage is more
interesting part in when we look at it
it actually looks like a bin packing
problem where we are given a set of bins
and items and we required to be required
to find a packing for the bins which
demises the number of bits but one
problem with the bin packing solutions
is that it its goal is to minimize the
number of bins but it doesn't consider
the bandwidth over and I talked about by
introducing introduced by the
replication of the publication events
across the servers so I to address this
we propose a customized were a version
of bin packing solution where we
consider the pan beat overhead by
bandwidth over had introduced by the
replication of publications into account
so to give you an example there are two
topics here and three subscribers each
topic subscriber pair is a is a box and
that subscribers belonging to the same
topic our cause in same color and the
server's have a certain occupied
capacity and certain available capacity
and if we just follow the first fit bin
packing which is most common bin packing
solution we allocate the topic
subscriber pairs to the existing servers
and now you can see that both topic
subscribers of both topics are split
between the existing servers which means
you have to replicate the events
belonging to these topics to both of
these servers and this is the bandwidth
overhead I'm talking about this is
especially true in Spotify case where
they replicate publications from all
topics to all servers which is a
significant amount of inter server
bandwidth they are dealing with so they
could actually use this solution to do a
better allocation and avoid the
bandwidth application was employed does
amazon actually charge for the bandwidth
within the datacenter not within the
nets holder so why is there any benefit
with minimizing it or what's that what's
the benefit of so there is no
inter server bandwidth costs but even
uploading the events to the Amazon Cloud
has a bandwidth costs and also i talked
about independent to each server oh
you're assuming you're let it once and
then dispute it internally to the
servers running this yeah you can upload
it once on distribute internally okay so
why does why does why is the first FF BP
not not work for that man so yeah when
we looked at this solution it was not
just for cloud setting it was all so far
i was advisable you're assuming one
where there's an internal cost of
bandwidth as well as the coast of the
VMS yeah okay one more thing is I if it
is across datacenters then there is a
cost each VM is never in a different
data center it's possible that they're
running in the different data centers as
well what would you do that so the users
are distributed across several countries
and the subscribers are connected to
whatever data center which is nearest to
them or in terms of load balancing also
they're distributed across it's a
service where latency wasn't an issue
right yeah so why wouldn't you just cut
out hate them if he's gonna keep prices
down it's not just okay the latency is
an issue for let's say music streaming
but not for publication and also load
balancing is another issue
so the first optimization we introduced
in our solution is a grouping of topics
instead of looking at each topic
subscriber pair separately we can
actually group them according to the
topics and allocate the groups of topics
together by doing this we are achieving
two things one thing is we are trying
trying to avoid splitting the
subscribers of a topic as much as
possible and at the same time it also
speeds up the algorithm by instead of
looking at millions of topic subscriber
pairs we are now looking at early and
individual topics so this avoids
splitting of subscribers to some extent
but it's probably still not enough so we
instead we actually introduced more
optimizations where we order the topics
in the decreasing order of the cost and
consider the most expensive topics first
and also consider the most available
servers first and allocate them to those
available most available servers so
intuitively it's a good match for
expensive topics to most available
servers first and in principle it avoid
splitting of subscribers across
different servers so I'll briefly want
to sorry yeah so basically we show with
Spotify and Twitter traces that we can
have cost benefits and especially when
we use amazon pricing model in terms of
number of servers number of ems and the
total bandwidth cost i'll skip the main
main results and just jumping to
conclusions in this work we lived in two
large-scale social messaging
and system pub sub systems for logical
social messaging and various challenges
it poses and we looked into novel
satisfaction metrics to address the
scale we saw various versions of the
problem where to maximize the number of
satisfied users or maximizing the
satisfaction these are hard problems and
we provide efficient heuristics to so
and finally we also provide a
cost-effective resource allocation for
data center and cloud settings and we
actually show that there are benefits of
using this solution with this I conclude
on thank you for your attention thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>