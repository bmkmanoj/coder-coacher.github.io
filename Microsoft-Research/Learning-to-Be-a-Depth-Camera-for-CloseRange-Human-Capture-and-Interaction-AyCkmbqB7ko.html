<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning to Be a Depth Camera for Close-Range Human Capture and Interaction | Coder Coacher - Coaching Coders</title><meta content="Learning to Be a Depth Camera for Close-Range Human Capture and Interaction - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning to Be a Depth Camera for Close-Range Human Capture and Interaction</b></h2><h5 class="post__date">2014-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AyCkmbqB7ko" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">we present a machine learning technique
for turning any camera into a depth
camera for interactive scenarios in this
example we demonstrate our depth sensing
technique on a modified mobile phone
camera allowing for 3d skeletal tracking
of the hand our technique is designed
specifically for close-range interactive
scenarios where we want to sense hands
or faces of the user
our technique works as follows we use
low-cost
low power LEDs to illuminate the scene
we remove the IR cut filter on the
camera and replace this with an IR
bandpass filter
we then learn a mapping from this IR
intensity image to depth using a hybrid
classification regression forest here we
demonstrate that any web camera such as
the Microsoft LifeCam can easily be
turned into a depth sensor in less than
10 minutes we first remove the infra red
cutoff filter from the lens we then add
a ring of infrared LEDs that is attached
to the camera with a 3d printed case
finally an infrared band pass filter is
attached in order to block most of the
ambient illumination the modified web
camera now only captures the infrared
illumination here visualized in red
which we use for our depth estimation
algorithm learning a mapping from IR
intensity image to depth is performed in
a two layered process we first perform a
coarse discreet depth classification
followed by a fine continuous depth
regression whilst clearly not a
general-purpose depth camera our system
can be used in a variety of
human-computer interaction scenarios our
system produces accurate results in
real-time with up to 220 frames per
second depth estimation state-of-the-art
pose estimation techniques can be
employed forehand part labeling using
the inferred depth data to enable 3d
interactions here we compare the results
of our def estimation technique shown
bottom left with the Xbox one time of
light camera shown top left and a more
naive depth estimation technique based
on the inverse square law shown top
right our system works equally well for
faces here we show the error between our
technique and the time-of-flight
technique from Xbox one
our use of a narrow band pass filter and
the ability of subtracting a background
frame with ambient illumination allow
some level of robustness to ambien I are
given the accuracy of our depth
estimation algorithm we can plug into
existing components that work from death
Maps for example here we can apply
facial part classification an expression
detection for controlling an avatar
here we highlight the quality of the
depth estimation technique by fusing
multiple depth maps into a single model
using the connect fusion system note
that in this case the system has been
specifically trained for the person in
question
in this example we demonstrate how a
learning technique can be applied to
untrained faces as well as untrained
hands
in this final example we demonstrate the
main limitation of our system because we
train for a specific surface albedo in
this case skin surfaces with other
reflectance properties will cause errors
in the depth estimation algorithm
however for interactive scenarios
focusing on faces and hands our method
provides a low-cost and efficient way
for turning any camera into a depth
camera</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>