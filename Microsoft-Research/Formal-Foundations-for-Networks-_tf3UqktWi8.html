<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Formal Foundations for Networks | Coder Coacher - Coaching Coders</title><meta content="Formal Foundations for Networks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Formal Foundations for Networks</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_tf3UqktWi8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
it's my pleasure to introduce any faster
professor at Cornell and will and who's
been working on my programming languages
and in the past few years applied
programming language techniques and all
the tools of the discriminating hacker
including Haskell Python and and of
course at 34 formal foundations of
networks thank you so I'm going to talk
today about some work we've been doing
on really trying to provide the same
kind of rigorous formal foundations for
networks as we have for ordinary
software it's really fun to be here
because you guys been doing this for at
least a decade now with projects like
static driver verifier and slam and
boogie and c3 and all these tools so
we're trying to do the same thing for
networks I should start by acknowledging
this is joint work with a proof
assistant both the tool and the people
who did the real work so argent goo ha
who I think may have interned here
several years ago he's a post I can we
were right now he's on his way to UMass
to start a fan convention there mark
right black PhD student my group and
Rebecca Coombs he's an undergrad so they
of course did all the real work so the
goal of what we're trying to do is to
really provide rigorous formal
foundation for doing precise reasoning
about network behavior and as motivation
you just have to kind of look at the
headlines and see that networks are both
becoming really important for the
operation of big you know cloud systems
and also really fragile so just kind of
picking through the last couple of years
you know github had a major outage last
year in November took down their whole
site for over a day and afterwards they
did a post mortem and they kind of they
released this little snippet saying what
had caused the problem and turns out
that they had a Miss configuration in
one of their routers and this caused the
bridge loop in their network and
eventually caused through the loss of
connectivity for their whole site amazon
had a similar kind of outage in april of
2012 a very similar kind of thing they
were doing some
maintenance and they were changing the
configurations of their ec2 network and
they had a sort of really complicated
series of cascading failures but
basically they did a Miss configuration
sent way too much traffic onto a backup
network and then sort of overwhelmed a
bunch of storage distance and eventually
eventually took down their whole
eastcoast data center for quite a while
godaddy had a similar outage where there
really such very vague so some series of
internal network events corrupted their
router tables and took out their dns
service and give us a lot a lot of their
customers and my favorite one united
airlines had a network connectivity
issue internally a couple years ago and
this sort of took down their whole
computer system and actually led to a
full ground stop at at San Francisco so
networks have both you know really
critical infrastructure both for kind of
web two point oh no cloud computing data
centers but also for companies like
airlines and yet we're still kind of
building them using very rudimentary
sort of 1960s 1970s era software
techniques and this is becoming a
problem so if you're someone I think
from the community we all come from sort
of programming languages formal methods
and so on you might wonder why it's so
hard and I want to kind of take you
through a picture of kind of what the
interaction sort of over the internet
looks like and just how complex the
network actually is so we'll start out
with sort of some hosts and pretend that
you want these hosts to connect to some
servers you know somewhere in some data
center on the other side of memory so
the hosts are may be connected on some
kind of local area network through a
bunch of Ethernet switches and on the
other side you have the servers other to
actually providing the service you're
trying to connect to and they're
connected by a bunch of IP routers and
then maybe they're sitting behind some
kind of load balancer so that incoming
requests from the internet can be spread
amongst these servers and then you have
some kind of gateway router that's
hooking up the internal network servers
are on to the network that the hosts are
on of course there's other kinds of
networks other ISPs so you also have
devices running BGP because you have
outside traffic coming you need things
like firewalls you might have wireless
hosts wireless
Gateway's middleboxes to do things like
recording traffic for lawful intercept
and so on and so you know what we tend
to think of a kind of think of the
internet it's sort of a very simple pipe
that sort of gets packets from here to
there but actually there's just a whole
host of different kinds of devices that
are involved in providing that kind of
functionality and so each of them you
know is usually provided by a different
vendor it's configured using a different
language and yet the behavior of the
whole system is somehow sort of the
composition of all these things and so
if you want to reason about even fairly
simple properties you actually have to
reason about you know a bunch of
different devices a bunch of different
languages and a bunch of different
programs all working together and in
practice the sort of complexity of
dealing with all this makes it
effectively impossible so there's a
recent trend from the last few years
though that sort of has the promise of
simplifying all of this and that's
called software-defined networking so
this kind of started in out of Stanford
a few years ago the basic idea is to
greatly simplify the architecture of
networks and replace all of these
complex devices and languages with very
simple and standard kinds of devices so
it's a it's an area that kind of started
out in data centers but has started to
sort of ripple out into other kinds of
network as well including enterprise
networks and even carrier networks so
the two big ideas in software-defined
networks that make it possible to kind
of start to do the kind of rigorous
software engineering practices and also
formal reasoning our first just to kind
of rip out the very complicated very
idiosyncratic different network devices
and replace them with a standard kind of
device that has just a generic set of
features so that's idea one an idea too
is to actually d couple the parts of
network devices that implement things
like routing protocols and take them off
of the devices that actually provide
connectivity and even put them together
into a maybe centralized kind of machine
that's going to control the whole
network so these the two idea is just
generalizing devices and standardizing
them and then decoupling control
from forwarding so the benefits of doing
this are well first you know if you want
to deploy new kinds of functions in a
network you now have a kind of standard
computer that you can program this
hasn't been possible for and second if
you want to reason about the paver of
network you now have a very precise
specification of what the network
devices should do and what kinds of
programs are going to run and so unlike
the picture I started out with where you
had this sort of huge conglomeration of
different devices and reasonably becomes
practically infeasible here you have a
very clear specification of of what
programs are and so you can start to
write down things like formal
specifications and check that your
network obeys those yeah so this is a
cartoon version no serious deployments
can have a single controller you're
going to have a replicated group of
controllers and and those might control
sort of one administrative domain and
then of course they'll have to talk to
controllers and other domains so you're
still gonna have all the kind of you
know fundamental complex that you have
in the internet but you can you can get
some leverage by you know viewing a
tightly replicated group of controllers
as implementing sort of one program so
you're not stuck with sort of reasoning
about the street protocols all the time
I can explain controlled way nobody
stone before L sure so the sort of
classic architecture for things like
Internet routers and switches goes back
to the first ones that were built sort
of in the 80s places like UCLA and they
basically divided the functionality of
these boxes into two separate components
so the data plane is usually a custom
piece of hardware that actually
implements you know the switching fabric
for a router switch so it basically you
know has a bunch of ports and it just
forwards traffic very efficiently across
those ports and it does it so it has one
data structure that determines its
behavior which is a hardware table that
says sort of you know what to do with
certain packets coming in where they
should go above that you need some other
kind of device that's going to do things
like compute pass through the network so
it's going to run all your classic
routing protocols and that's typically a
general purpose
cpu that sort of coupled to this data
plane and and it you know runs these
disputed protocols talks to other
routers and then computes paths and then
reconfigures the data point so in
traditional network devices these things
are sort of sold together as one
integrated unit and and so you know if
you want to express some kind of control
algorithm you have to figure out how to
sort of factor it into a distribute
algorithm that runs on every individual
device and you know you also have to
figure out how to encode it using vendor
specific you know cisco iOS or guna
prior you know their specific
configuration language so the difference
here is just this thing is like you know
an ordinary server running a seat
program and and it's separate but the
interface that it uses to configure the
data point is completely standard yeah
so I hate to sort my talk is not
actually about suffered of my network
this is just sort of the technology that
enables the work we're doing but it's
very real so Google uses it for their
entered intro datacenter traffic they do
a sort of global traffic engineering and
get great efficiencies by doing this and
the other sort of huge success story is
vmware bought the big startup out of
Stanford and Berkeley nasira last year
and they do virtualization for data
centers and they don't know all their
customers but ebay uses them Rackspace
google
my understanding actually so don't quote
me on this because this is not my area
of expertise but Google was starting to
do a sort of homebrew solution to this
so they were building their own switches
and and then sort of software networking
sort of emerged and vendors were
providing switches like reprogram it in
this way and so they jettisoned the
homebrew solution and switched to I
think I don't know the vendor but
they're a bunch of real vendors that
provide switches that work this way and
they switch to those networks that were
providing the old kinds of boxes are
they now providing this new the boxes
that fit this new architecture also or
this a new breed of companies so the
company is that I I think are most
excited about this or the companies that
are not the dominant ones right now
because it's a very disruptive kind of
thing and it kind of gives them an
opening to a market that is not open to
them right now but even Cisco for
example has a they call it an internal
startup that's looking at this kind of
architecture one but the real catalyst
for this I think is actually data
centers if you want to do something
interesting with a data center network
using traditional network devices make
this very difficult so you actually if
you have one administrative domain of
control you'd really like to sort of run
one program so that was kind of a huge
blind spot that that love this okay so
just as I sort of motivating example of
the kind of properties like the check i
want to show you really i mean this is
like too simple but it still exhibits a
bunch of features that make it
interesting so here's a network it just
consists of one device connected to four
machines and we have a sort of simple
high-level policy that we'd like to get
this network to obey so first it has a
security component so we want the
network to provide connectivity but
block all SSH traffic second we have
some kind of monitoring policy so we'd
like all web traffic to be sent to the
logger which is sitting on the left on
port for and maybe
you know do some kind of analysis for
inclusion injection or something and
then lastly you know all of the traffic
between the clients we'd like to we'd
like to just that drogba forward as long
as it's not SSH so how could you input
this kind of thing in one of these
software-defined networks so basically
you have switches and a controller and
the switches give you one kind of data
structure that you can program and
that's a forwarding table so a
forwarding table consists of a linear
sequence of rules organized by priority
and each rule has a pattern that matches
a set of packets a list of actions that
say what should happen to packets that
come into that device and that match the
pattern and then some counters that keep
track of basic statistics about the
traffic so here's a sort of partial
buggy implementation of the policy I
just showed you the highest priority
rule says any SSH traffic should just be
dropped there's no actions for that for
those packets and then any traffic to
host one should be forward out port one
and then all other packets should be
diverted to the controller which might
decide to do something special with them
so this is one piece of these switches
and they just have this forwarding table
then the other piece is the controller
which basically receives events out of
the network so things like the topology
of the network changing switches
entering and leaving links coming up or
down also packets that might be
explicitly diverted to the controller
the controller receives and then can
choose what to do with them and it can
also receive statistics about how much
traffic has been traversing particular
switches and links and the way that it
manages the network is basically just by
manipulating the forwarding table so I
can send out messages saying please
install this rule please delete this
rule and it can also do things like
query the counters in the rules okay so
it's a very simple kind of interface for
programming network
so the switches at the bottom are also
raising events and talking the
controller that is so in addition I mean
he said the controller receives events
like he knows change in topology right
yep are those events being also
programmed in the switches and sent to
the so a switch that implements one of
the software-defined networking
protocols like open flow the most
popular one they basically run a little
agent that sits on the switch and they
the first thing that I do is sort of
connect to the controller so there's
kind of a handshaking that happens the
switches hey I'm here the controllers
and say I'm here they exchange
information with their features and then
at that point the controller receives a
switch connected event which it can then
you know record remember that that
switch is there it also receives event
to say you know how many links there are
and whether they're up and so it can use
this to do things like compute a picture
of the overall topology of the network
in addition I had an example in the last
slide so which is ken divert packets to
the controller so they can one of the
actions you can do is send a controller
and this is useful if you want to do
something that can't be expressed as
rule in one of these tables then you can
use the controller to do some general
purpose computation and then push down
new rules that may be all managed by the
runtime
in other words the controller but if we
want to push out changes to the round
table to just happens automatically or
is there some kind of thinking that go
on in there there's a little thing that
goes on and that's one of things going
to talk about today so basically the
specification document for open flow
says sort of what switches have to do
when they receive control messages but
there's a lot of reordering they can do
so you have to be quite careful and use
the level synchronization primitives to
sort of get the switch to do the right
thing getting right yeah okay so now let
me step you through sort of three
sources of bugs that make it actually
difficult to program even this kind of
simple machine so one issue is that we
kind of think of the controller as sort
of beaming down you know a configuration
for all the switches in the network so
it's job is sort of to take you know
maybe it computes some complete list of
a forwarding table if it wants to be
installed on some switch and then it can
basically send messages the switch that
do that so here's here's a table
implements our security policy from the
first slide I won't take the time to
pronounce it but entrusting it so we
kind of lute ly captures the security
monitoring and forwarding policy and so
the first thing you do in in one of the
controller's safer open flow is to write
a handler that says when a switch
connects so here's a Python Python
function that says when the switch joins
then I'm going to send it a sequence of
messages these messages basically
contain rules right they have priorities
they have patterns and they have actions
and so these going to get beamed down to
the switch which will then configure its
state to have this table but of course
one thing that can happen is that a
network is a distributed system and so
there's kind of events happening all the
time and well these messages are coming
down from the controller there could be
packets that are arriving at that switch
and the default behavior of one of these
switches is if it if the packet comes
all the way through its table and it
doesn't have a rule that says what to do
at those packets then it's going to
divert them to the controller and
generate another kind of event I will
drop it the default so there's kind of
an implicit rule at the bottom that says
anything good on matches
the controller if you want to drop you
have to say anything that matches the
bottom draw so so the point is that we
have to actually define sort of two
implementations of our overall policy
one the explicit rules that get sent on
to the switch and another that sort of
resides in this handler for diverted
packets that sort of applies the same
thing and you might wonder well this is
silly why do i why do I ever want to
defer it back it's the controller well
one issue is that you might be trying to
implant some function actually can't be
expressed on switches and so you have to
do some processing on the controller
another reason is that you know there
are things like the switches have you
know finite space and their tables and
so even if you sort of can compute a
complete table that influence your
policy you may not be able to fit it and
so you might have to do things like sort
of like paging in you know memory and
basically move rules on and off the
switch as you see traffic so you end up
having to actually implement sort of the
same policy multiple places in your
control program and of course you know
anytime you have sort of replicated
functionality it's easy to make mistakes
and I can she have a bug here my packet
in code it doesn't correctly do the ssh
filtering so this is a general sort of a
problem that you sort of end up writing
the same policy multiple places and even
more worrying problem has to do with
some of the flexibility that switches
have to reorder the control message they
receive so I claim that this first
handler i showed you for switches
connecting would basically take the
table that wrote down and sort of beam
it down to the switch so as a program we
kind of think that what's going to
happen is the switch starts out with an
empty table we send down these messages
and then we get to a table that
implements the full policy but what can
actually happen is I'm sorry this is
what we think you can add what can
actually happen is that the switch
receives all of our messages it buffers
them and then it decides to reorder them
and it does this because actually some
of these patterns in hardware involve
sort of configuring multiple tables and
so it might choose to do the cheap ones
first that only bought one table and the
more complicated ones later and this is
bad of course because while the networks
in this day
if its processing packets we're actually
not implementing our policy correctly so
we're letting SSH traffic through so the
solution is that you have to actually
use explicit barriers to synchronize the
synchronize with a switch and say please
process all the messages that you so far
so what I put the order in which these
rules actually like the semantics of the
blue thing the order matters so you
intended it does so so this is you know
a Python program that executed
sequentially so it sends these messages
down to the switch the switch has to
receive them in order but the switch
further specification is completely
allowed to reorder them as much as it
likes there are good reasons for this
some some messages are cheaper to answer
than others and some message is more
urgent than others and so so I mean it
there's nothing deep here it's just a
little kind of fiddly little issue that
many people have screwed up and it's
caused bugs at Google's deployment lots
of questions you talked about how they
were in reality there's multiple
controllers and it's a protocol momentum
is that also is supposed to
of course I'm not going to talk about
that much so one of the benefits of this
is because the controller's just
ordinary machines they can use existing
you know software and really like
off-the-shelf software to manage their
replicated state so they could run paxos
or they could use some you know
eventually existing key value store and
you sort of get whatever that gives you
so I'm mostly going to focus on the sort
of controller replica group switch
consistency not the controller inter
controller replica consistency the worst
possible picture gear right now is it
train here that when people improve on
this kind of stuff with the data center
they really dig they really all this
freedom and then they are changing the
routing tables all the time I mean
Taylor need this chaotic then in the
past networks should be failing all the
time right but they don't fail it must
be the case that routing tables don't
change that frequently so all these
various conditions are happening
actually manifest so two things I'll say
so one is that sort of a common
complaint in networking is that we're
sort of stuck with lowest common
denominator you know 1970s tcp/ip
functionality so people would like to do
fancier stuff they'd like to do more
dynamic stuff but they haven't been able
to because they don't have an interface
for programming the devices so I think
that's the real source of not this kind
of chaotic dynamics change I'm just very
good very good yeah and I mean like if
you think about renting machines from
Azure or ec2 like if you're a customer
and you have least you know hundreds or
thousands of machines you might like to
configure the network that's connecting
those machines to give you some function
like maybe broadcast service or maybe
some kind of you know bulk transfer with
with you don't care what latency but you
want a good bandwidth and so you know if
you if you imagine sort of all the
customers in a shared data center
wanting to program their own slice of
the network now you do get actually
rapid change
if you wanted that to go completely in
order you have yeah so in this case I
mean I don't actually need berries pH
thing to include my policy the thing
that's broken here is that my ssh
blocking policy has been violated
transiently so all i really need to do
is make sure that i start out by putting
that drop all as a traffic rule first
and then before i proceed to allow other
traffic through i make sure that rules
installed if you didn't know yes the
naughty thing you do is to put barriers
everywhere that would slow down the
throughput of your controller you know
its ability to change the state of the
network so that would be a bad move oh
sorry I'm in general I'll sort of Allied
priorities in some of my diagrams now
you just read them as being in order
yeah there's a field here that exactly
reflects what's there it seems that even
if you have barriers I mean the fact
you're working really would like atomic
weight switch between two complete
tables yes so even worse you'd like to
do that across the entire network Tom
would you switch from n switches in this
configuration and not convinced that you
can implement to get the thing he always
doing so we have a paper that was a
sitcom this year that for doing exactly
this I'll talk about the end yes so let
me show you a third kind of again
nothing deep but kind of just a little
gotcha that can that can and does trip
ups or network programmers and that is
this code I showed you is a lie in
particular the first pattern des port 22
which i asserted and you all believe me
you know matches all sa traffic actually
doesn't it actually matches all packets
and the reason is if you go read the
spec which we ended going to do for a
while the way that packets are actually
matched against these patterns are you
sort of traverse a bunch of sort of
starting from the internet level all the
way up the stack and you only match
fields high up in the stack if all their
dependencies have also been matched
lowered so you know just matching for
destination port 22
doesn't make sense if you're talking
about not a teasing bucket we're not a
eunuch jacket and so what's witches do
is they just ignore this and they treat
that like the all wild card pattern so
actually this code I showed you would
have just dropped all traffic and again
like you know just a stupid mistake but
it's a kind of low level detail that
comes from having to sort of program the
hardware directly that can and has
caused real bugs so what you have to do
is actually write a much more
complicated pattern it's basically this
sort of a dependent type that captures
what what a valid pattern is in this
case you have to say well first the
ethernet frame type is IP and the IP
protocol type is TCP and then now you
can save the TCP protocol 22 ok so in
sort of research controllers some that
my group has built some that some people
have brown have built as in the people
at Yale have built sort of all these
bugs have come up from not having the
correct acton handler to forgetting
barriers to generating bogus patterns
and also the problems with patterns can
lead to bogus optimizations and
compilers and they can lead to
essentially arbitrary behavior where you
know you thought your network was
definitely in a block a stage traffic
and instead it's letting everything
through so in the networking community
there's been sort of a growing cottage
industry in building tools for for
checking configurations and this
predates the software-defined networks
but they've kind of ramped up in recent
years because now there's sort of a
simple interface they can actually check
so there's tools like flow checker
anteater nice header space analysis
verra flow and many others and I think
actually this makes you really happy
they're sort of people not from our
community are getting excited about
writing down formal specifications and
checking them and having automated tools
to do this this is like awesome so
they're great tools but they have a few
less optimal features so one they're
mostly doing basically dynamic runtime
analysis so they're basically wrapping
say a controller with a reference
monitor that inspects all the messages
coming up and down and they just check
for violations of safety properties so
that makes them really slow and second
they all you know build on
some custom ad hoc foundation and often
these are unsound so I won't pick on
anyone in particular but some of these
tools for example don't model things
like barriers and so they might tell you
some property holds but actually the
switches don't have to don't have to
well not necessary have that property so
one of the goals of the work on the
telly about today was to actually sort
of provide a principled foundation that
one could use to build tools like this
and actually prove a theorem that says
you know the assertions of those 20
validates are in fact correct so our
vision was to basically rethink the sort
of controller stack and in particular
use a high level programming language to
describe what we what we want the
network to do and then let a compiler
handle a bunch of the low-level details
involved in doing things like inserting
barriers or generating well-formed
patterns optimizing rules and such and
to be able to do reasoning using adjust
our high-level language and not have to
reason about all these low-level
artifacts and then to make sure that all
of this is correct to build a compiler
and actually actually establish its
correctness using a mechanized proof
assistant so that's what we've done so
we're actually building on sort of a lot
of recent success in the form methods
community so I'm sure you all know
projects like SEO for and concert and F
star done here that are really I think
exciting because there could have you
know taking real software systems and
building them with what you might call
certified techniques so you know there's
great tools now ACL to Isobel
there's text books you need to
undergraduates and so it's kind of
finally becoming possible to build
serious systems and to prove their
correctness so assume most you know this
works but basically what we're gonna do
is sort of write the code that
implements our controller proved it
correct against the specification and
then extract the code 20 camel and then
compile it and we get a certified binary
that we can run and have high confidence
that it's going to be correct
okay so if you're familiar with systems
like concert the architecture of our
system is very similar it's a sort of
classic compiler pipeline consisting of
a bunch of different phases and
intermediate languages and each of the
arrows between these phases is going to
be proof directing so we're going
to develop you know each of the levels
levels of abstraction formalized both
the syntax and its semantics and
we're going to build machine check
proofs that the compiler the optimizer
and the runtime each preserve semantics
as you go down and then we'll be able to
extract Odin one so one thing that is a
little different from this work from say
things like concert is we actually
didn't have a sort of clear formal
definition of our lowest level machine
and so one of the things we had to do
besides sort of build all this other
stuff on top was actually to pick out a
foundational model that we could use to
let all the rest of our theorems sit
upon I'm a question yeah build a new
backing for old camel because presumably
standard vacuum complies on base 86 but
this is the control bit about running
x86 raids I know the control pain is
running exits that's that's the whole
point yeah I guys running on a Linux
machine or so so the controller itself
you know runs on x86 right here and then
it emits messages that get sent down for
switch okay so let me just take you
through sort of very quickly through
this stack and I'll just kind of
highlight some of the interesting pieces
so first I think some of you have seen
this neck or language before it was at
pople 12 also this weekend is di it's
basically a high-level declarative
programming language for describing the
behavior of open flow networks I think
Dave Walker is coming here in a month
and he's going to talk much more about
our an STI paper so i'm not going to
kind of harp on on network as he'll tell
you much more about it but you can kind
of think of it just as kind of a logic
programming language that specifies how
package before a new network so unlike
the little things I showed you it has
sort of a rich predicates language for
classifying packets by where they are
and how they're structured we have sort
of declarative actions for how we want
to transform packets so we can forward
them we can modify their values
and we can query them getting results
back on the controller and then we
combine things like predicates and
policies using natural operators that
aren't implemented in hardware so things
like disjunction conjunction negation
and this makes it very easy to write you
know simple declarative easy to analyze
specifications of what you do so just as
an example for our little toy network
here's how you'd write the total
configuration you write in net court you
basically say anything that's not SSH
forward to host one forward host to
forward to hose three and also forward
all web traffic to port for and that's
it and the compile and run time is going
to take care of turning this into flow
tables and then also generating all the
messages to the switches so this is this
is a different language that we've
designed and here if something doesn't
match it's just dropped so we fit so
okay so I've sort of hinted that the
cymeks of this language is sort of very
natural in high level let me kind of
make this formal so here i have a little
judgment that captures our our
operational semantics for net core this
is sort of a somatic that talks about
the behavior across the entire network
so we have p a program in network the
state of sort of the machine we're
running on is going to be a bag of
packets located at particular places in
the network and so locate it back it is
just sort of a packet parked at a
particular switch in port and what this
rule says is if we start out in a state
with a particular packet and then sort
of the rest of the packets and if
processing that single packet according
to our policy generates a whole bunch of
additional packets and prime then the
whole network takes a step processing LP
and gives us the rest of the pack they
shot it with plus M Prime so it's you
know very simple high-level description
of hop-by-hop processing and the only
kind of asynchrony is just we don't know
what order packets we processed so those
are just this bag of packets that are in
state
yes yep and I think that's unavoidable
right because you're not going to
synchronize one could imagine doing this
but it would be very expensive so you're
not going to sort of synchronize a
packet over here and a packet over here
in force them to be process differently
things are fundamentally asynchronous
and concurrent so the key things notice
our we can reason about hop-by-hop
forwarding behavior we don't have to
deal with the fact there's an underlying
just read system so we have to worry
about controllers and switches and
messages and barriers and things and if
we want to reason about simple you know
reach ability properties things like no
ssh traffic gets through you can do that
using this model and it's very simple
that's the way I imagine that perfectly
just talking about the high-level
operational semantics but I the way I
should imagine the execution that this
program is being executed simultaneously
and all controllers in the network right
this is the intent in this very abstract
view this is the entire network so the
state of the network is a bag of packets
that are in flight and each tick one
packet you know it's processed and more
more things go into the state well they
died at work me all the controllers and
although there's no controllers and
switches here but yes so so our task now
is to build a camp I of it you know
faithful immense this using controllers
and switches okay so the first step in
our compilation is to basically take our
high-level sort of logical language and
turn it into flow tables so elegantly
good flow tables as sort of the RTO of
network programming so they're kind of
an idealized version of what hardware
supports but we don't have to worry
about things like priority yet and also
we don't worry about space constraints
so they're just sort of unbounded
loonier sequences of patterns and
actions the nice thing about flow tables
is if you have a collection of flow
tables one for each switch in the
network you can in doubt with the same
kind of high-level semantics all we've
done is sort of change the way we
represent the function on packets that
we're computing so we still don't have a
kind of distribute system we're just
reasoning about sort of a bag of packets
being processed one at a time
LP you're like processing in one step
yes is that are those packets that are
located at the same node sorry I should
have set this little slower so this is
multi a multi set containing just one
element and then we're picking this one
out we're processing it by sort of
interpreting the flow table and then
this generates United it's long animated
yeah 10 at a time so if it's actually
interesting I don't quite know the
answer to we're doing a sort of classic
you know inter leading model of
concurrency here and you might wonder if
we need true concurrency because ok I
thought those really going but I was
into grad school Sebastian he's much
smarter than I am so I get worried when
you ask the questions ok so so our
compiler is going to take these neck or
programs and generate flow tables and
it's it's maybe a little grandiose to
even call this a compiler because it's
just sort of doing the obvious
flattening of our policies the key
operation that was kind of an
intersection on flow tables so just to
show you a quick example if we take a
simple little atomic policy that just
says forward from post one part 1 this
turns into a little one line flow table
like this we can have another policy for
web traffic out port for turns into
another one line flow table and then we
combine these say taking their Union and
what we produce is this so we basically
have to intersect the two rules to find
their common bits take the union of
their actions and then we can
concatenate the residuals load so this
sorry Union and the other operations are
kind of similar
yeah yeah so packets coming in first try
to match this rule and if not they fall
through to this room they take the first
match correct so I mean there is
something think about here because you
know you don't have things like negation
you can't say not this you have to
encode negation by putting the thing you
don't want above and then letting things
fall through to what you want to have
happen likewise for union you know you
have to be careful and kind of handle
the overlap together and then the
residuals on either side they're not
anything really deeper though it's just
I guess the main thing is first of all
we have to you know make sure that we're
always generating these valid patterns
to avoid the bug where patterns don't
you think and there is a little bit of
thought to how you want some of the
operators when Dave comes I think I'll
tell you about a new operator we just
add to net core which is sequential
composition which let's Express multiple
phases multiple phases of processing and
compiling that is check more challenging
going from flow tables to network yeah
I mean the naive way would be to
literally just sort of you know right
down the atomic program for this and
then take the negation of this pattern
and then union that with this of course
that might be a very large
representation so you might like to do
something smarter but is there that's a
good question i don't know the answer to
a fan so we're a part of the larger
frenetic team is actually building a
tool that will do exactly this and the
reason is we want to expose to other
kinds of controllers some of our nice
compositional policy combination
obstructions and so we can't sort of
insist that everyone work in net court
because they don't so actually going
from exactly probably so going from flow
tables internet core so that we can then
combine them using some of these
operators yeah yep the surance i don't
know but that's a great question so as
you might imagine there's sort of a
blow-up that happens so if you just
naively compiled using this
intersections everywhere then you get an
exponential blow and so you really need
some kind of optimizer that's going to
at least do things like strip out empty
or shadowed rules and it turns out that
these two things actually do well enough
in practice to not generate huge flow
tables so overall this sort of first
phase of the compiler when we predict
correcting we proved was this
theorem which says for all optimizers
policies switches ports packets and
buffer ids but Fred user with a little
detail if your optimizer is semantics
preserving so given a flow table it
produces an equivalent flow table then
evaluating a net core is the same as
evaluating inflow tables so
this is for so this is for all switches
sw1 switch so right so another thing the
compiler does which I didn't mention is
it takes this policy it applies to all
switches and it has to generate flow
tables for each individual switch and I
didn't emphasize this in my example but
net core includes some primitives for
constraining a portion of the policy to
a particular switch or set of switches
so I don't want to step on a lemon
pimpson you don't have but Arjun has an
argument that actually it's not
exponential for as long as the number of
header fields is finite which is true in
practice but let me not I don't want to
assert that because I haven't seen the
group okay so to prove this theorem we
actually do a bunch of things in so
we had to build a sort of library of
algebraic manipulations on flow tables
we also had to write down a new tactic
for proving equalities on bags I'm sort
of all of our theorems end up having to
show that some bag of packets breezed on
one side is equal to some bag of packets
on the other side and and we also had to
have a sort of key invariant that's
maintained all the way through which is
that all patterns are what we call
natural and i'm just going to flash this
up and not explain it which is a
terrible thing to do but this is sort of
the dependent type that captures
well form patterns it just says you know
everything you match all of its
dependencies all the way back down to
the unit level are all reflective why is
this next slide okay great I don't have
a couple more of these so I should ok so
now I want to jump down to do this next
arrow the runtime system but first I
have to tell you about the little model
that we prove this against so you know
we wanted to prove a theorem saying that
our compiler is correct and to do that
we need some kind of mathematical
representation of what the network is
and how it behaves and what openflow
gives us is a 42-page
in formal specification document
consisting of you know English prose
diagrams and flowcharts and a bunch of C
struct definitions so it's hard to prove
a theorem about this kind of thing so
what we did sort of inspired by all the
various featherweight systems out there
was to extract a sort of one page
operational semantics that captures we
think the key features of open flow so
this is really kind of it there's a
bunch of a grammar that gives her a
bunch of syntax and then these
operational semantics rules and what we
included was we made a choice to just
model all the features that are related
to packet forwarding and also to capture
all of the essential asynchrony so
anywhere where something could be
reordered we made sure that our model
didn't somehow linearize things we
alighted a bunch of other things so a
big part of this is related to things
like error messages and we decided not
to model that instead we have we decided
to sort of prove that our controller
never generates these kinds of errors so
it always stays in sort of the safes
upset and we also left out things like
the statistics that I mentioned earlier
so our verified compiler doesn't include
support persistent this part of the
exercise only see you to approve the
hear right that would affect the code
generation of the compilation know so I
mean we actually have mechanized this in
 and are we have built controllers
that target this model we then link it
with a lower level unverified library
that events the full up in full protocol
and there's a small mapping between
featherweight and full that's unverified
that doesn't the obvious embedding
projection so we so you know eventually
yes we should sort of build a full in
not featherweight open flow so that we
can do things like like traffic
statistics and failures and other things
we chose to do this featherweight thing
both because we wanted to publish a
paper not in three years but in six
months and also I do think this model is
actually useful for other people so if
you're building a tool and you want to
kind of reason about forwarding you know
don't make the mistake that's when the
other tools make just sort of taking
some ad hoc definition of what open
photos take this thing it's not that
complicated
can actually prove with your what this
thing in the way that we all do and
you'll get some confidence about a
certain class of properties so you know
I hope we find two and I hope other
people will extend this model but it's
kind of our tasteful attempt to sort of
extract a one-page operational semantics
from yeah so one of our collaborators at
at t labs in Berlin has actually been
working on exactly this problem
basically taking form o specifications
and checking whether switches conformed
to them and because this is in we
have a in order to back we can extract
so we haven't done this yet but we're
planning to use his tool to try to find
you know inputs where they disagree
there are things you can't express in
featherweight just that there's things
that you everything we want expressed
you can or is it that actually the
details are both so we left out for
example counters on on switches so we
just don't are switches in this model
don't have counters and so the message
is an open flow that say please give me
the counters and here are the results of
asking for counters we just don't
include those either so that's just
alighting something that we didn't yeah
okay I guess and so we can't then
express any program that used to do
traffic monitoring yeah okay so that was
the other related question I had which
was empty box you use counters or
anything other than other than traffic
did they actually use
sure I mean so I don't know the innards
of how Google's controller works but
they're they're doing a sort of
continuous online traffic optimization
problem and I don't actually so the
thing I don't know is if they're using
open flow together those statistics but
they're basically taking the traffic
matrix and then you know periodically
resolving some big constraint and then
choosing how to so it is important ok so
just to kind of give you a flavor and I
think I have what five minutes 7 minutes
or ok 10 minutes so I just got to show
you some of the some of the artifacts
from the spec and how we realize them in
our model so here's the definition of of
patterns and for us they just turn into
a sinkhole data type here's the
definition of how packets get matched I
showed you before this turns into a nice
little function and so the point is that
we've we've not cut corners on modeling
how packet matching packet forwarding
and flow table configuration works all
of that is is faithfully modeled in our
featherweight system we also as I've
said you know didn't cut corners with
asynchrony so there's various pieces of
the spec that say things like in the
absence of barrier switches neighborhood
or messages or there's no packet output
ordering guaranteed within a port and so
for us this turns into definitions of
various elements of our model where you
know instead of being queues or lists
their bags and now the operational
semantics you know lets you pull things
out of the bags in any order question
when you approve him here this
natively in the stand back Jack approval
every appear with about bags both so
there are existing libraries and
we've tried to use reuse things never
possible the one thing we did with
respective bags was adding some new
tactics for proving equality so we end
up in many of our theorem as we end up
with sort of a bag and then you know map
of some function over that bag being
equal to some different bag and maybe
function of map you know so we end up
with different expressions we wanted to
basically automatically get those are
qualities when they were actually
equality's without having to unfold
definitions and apply induction of
health season things
yhu soccer as a vehicle for doing all
this for well so first there's sort of a
large and growing community of people
doing buildings offer in this way I
guess we could have used Isabel I've
done some person Isabel before but so
sort of just friendly hype i guess you
know is popular and that's
important actually because you know when
you get stuck and have a question you
can ask your smart french friends and
i'll tell you exactly i do something
second we wanted to actually run the
code and so caucus really nice
extraction features and so so yeah
there's no reason you couldn't do this
in a CL 2 or is it okay um so so that's
our model and now i wanna tell you a
little bit about how we verified the
runtimes so one thing we could have done
that we decided not to do was to you
know prove the correctness of a
particular runtime system for our neck
or language so we didn't want to do this
we actually try to come up with some
more general principles for how you
could prove the correctness of different
kinds of controllers and so in our model
we actually represent the controller
quite abstractly so there's sort of a
type of controller state and there's two
functions that sort of capture the
behavior of the controller an input
function and an output function and the
input function takes a message from a
switch and a sorry switch like a message
from the switch and the current
controller state and outputs the new
controller state and then the output
message takes the current controller
state and produces a message to a switch
and a new state so this isn't quite you
know the most general thing you can
imagine but as long as your controller
kind of factors into these two functions
you can put it into our model so it's a
very fully probably too strong Nick Nick
can say fully with the justification but
maybe I can say that but it's a it's a
quite abstract model of controllers so
now let me show you the kind of the
final proof for our runtime systems and
again as I said there's sort of many
strategies you could use to both
controllers here are three that people
have have done either in toy prototypes
or in real systems so the most naive is
well you could just not install any
rules ever and use your general purpose
controllers to do while processing
that's really dumb and slow by
you could do it another you do is what
we call reactive this was actually the
strategy used in sort of the first open
flow system a system called ething that
was done at Stanford doing very
fine-grained access control in networks
so here the idea is the switches start
out empty and then as they see traffic
packets get diverted to the controller
so it receives the first packet and then
it does it does a computation to figure
out what should happen to that packet
and several future packets and then it
installs a rule that handles that packet
in future packets so this is kind of a
if you want kind of a online partial
evaluation sort of happening dynamically
in the network and then the best of
course are what we call proactive
compilers this is where you actually
take some description of the function
you want the network to implement and
turn it into a set of rules but handle
hopefully all traffic so our goal was to
actually come up with a sort of general
framework for approving all these things
correct and the really thing I'm kind of
happy about happiest about this work
Arjun and Mark came up with a very small
number of simple safety and liveness
conditions that if your controller
satisfies we can prove in that
there's a by simulation between the high
level function you try to implement and
its realization and featherweight open
foot so intuitively what these
conditions say our first at all times
your controller has to have the property
that any rules that have been installed
in the network are an approximation of
the function the controller strong
movement so what I mean by approximation
just in the sense of being a less
defined function so any of the rules
need to be compatible with the
controller function but they can be a
little bit less defined and then the
liveness condition is just wind packets
are the birds the controller the
controller eventually needs to process
all those packets in accordance with the
policy and so just to give you another
little taste of this is actually
all sort of parameterised in a in a
functor and so you basically provide you
know your controller implementation and
some proofs of these properties and then
what you get out is a week by simulation
between the OpenFlow artifact
and the abstract artifact you specified
so this is at all times yet so this is
well the rules are rules you so this is
a good point we don't model packet loss
in our model any of the guarantees we
give you need to in in a real network
degrade them by basically taking
prefixes of what's predicted by our
model okay so if there's no packet loss
that no packets are no H what I meant
was any so the controller has okay so at
any point you have some prefix of the
current controller function and then you
have a default rule which can either
draw or send the stuff to the control
exit the process so there's there's
various approaches you could have to if
you derivative everything to the
controller basically topics or that's
what I intend here so the last rule I
mean the the default catch-all rule wish
to purchase the controller okay so so so
basically so there is so you're not
dropping the packets in in the process
of installing these functions there's
always going to be the default which
will which will send things up
some period of time during the
installation work where controllers may
be a little bit of all and let me say
you know we haven't really dealt with
failure so I said we completely punted
on packets being dropped in our
featherweight model and we've kind of
convinced ourselves not in cocking that
our properties degrade in the obvious
way but I think probably the next thing
to do is to actually put in law see
links and buffers that are finite and
things that overflow impacts that are
dropped and and push on that yes so this
is there the same question as Sebastian
at the beginning let me say this is for
one policy so one net core policy so
that so we don't create loops and that's
that policy has loose if you're talking
about policies that are changing over
time then you need to have some way of
atomically or otherwise consistently
updating a set of switches I'll say a
couple words at the very end let me
defer to them okay so let me jump to our
actual implementation status and a few
small experiments we did so our total
development is about twelve thousand
lines of code and proofs and about
sixteen hundred lines of unverified o
camel coat most of the old camel code is
doing things like serializing and
deserialising messages and also gluing
up with some of the bunkers that we have
in common so the components are just
sort of each of the things I showed you
net core flow tables compilers runtime
systems and machine check groups of
correctness the gold from that's okay
yeah how many lines of ocala code you
extract from that
it's probably I I could check in my
laptop it's probably about one third of
that 12,000 settings about for four or
five thousand but let me check after
we're done and so and so extracto camel
we link it with this unverified glue
code and we've been running it for for a
while now both at arjan's house and in
the lab so so far we've deployed on lots
of software switches and also a couple
of hardware switches so in our systems
lab we have this switch here pronto
switch that runs open flow and Arjun has
this little tp-link Wi-Fi box in his
house that's running verified net court
and we built a bunch of kind of
canonical network applications so things
like host discovery shores math writing
broadcast some traffic monitoring that's
unverified but that can be linked with
the verified code and also access
control and what's kind of nice is
because we have net core you know each
of these little apps can be combined
together using policy Union and you kind
of get both so we actually sort of can
support more than just each of these in
isolation let me tell you a little bit
about about the performance of this
thing so we did too little experiments
these aren't sort of any kind of
comprehensive evaluation so I don't want
to overstate them but we did we have
been running at its real and the first
test was what's the throughput of our
controller so it's pretty obvious that
the ability of the controller to process
messages is going to be important for
the performance of the network
especially if it's ever receiving
packets so there's a little benchmarking
tool called see bench that is sort of
standard in this community that
basically takes a bunch of switches
software switches and just floods the
controller with messages and then just
measures the time needed to generate
responses to those messages and so we
ran this on a desktop machine and we
said somewhere sort of above the Python
plantation and bowl of all the serious
implications so our previous
implementation net core and Haskell
could do about 26 k messages per second
we're at about nine point four and the
reason for this is actually 0 camel has
not great multi core support so unlike
our Haskell implementation which had a
different thread for every switch and
see benched
uses lots of switches to flood the
control of messages our o camel code is
single threaded and we think that's a
big reason for the slow down also some
of the glue code that map's between are
sort of the full open flow spec and our
featherweight spec does a lot of extra
copy and so messages get sort of copied
one extra time going up and down in our
verified implementation so we think you
know this is kind of a first number we
need to do much better so see bench m if
you run in a multi-core machine actually
generates a sort of a bunch of software
switches that that hammer the controller
with messages and then the controller if
it's running on the multi-core machine
can of course do things like spun up a
thread for every switch and process them
in this case we ran it on one machine
one multi group
the proof in multicore I mean bro
encourage yep so i should say you know
i'm not sure how much we're going to
stick using this verified component for
all time yeah it's it's easy you know
each switch has a separate handler and
one for a given no core policy fed
handler is completely static you say
that unverified mentor high school
notation right that thing is it's a
single switch as concurrency at the
switch level as well fight because
that's why you're getting this 36,000
that's insane no it's actually the
controller is spawning off a different
thread to handle all the messages from
every switch so when when the switch
connects to the controller in the
handshake the controller then spawns up
a thread and then actually lose I
thought that there was one controller
for swish but it's not like that what
they do look and be controlling lots of
yes yes so so they would still
occasionally to be much harder if you
would encourage controller yep yeah
would be because right you just
controlling multiple right
the controller is dead ones
so we also did a little experiment we
should a bunch of them below to show you
one to measure how effective the
controller is at basically pushing down
the policy into the network so for this
we used a simple Waxman graph which is a
random graph that is commonly used as a
model of enterprise networks with a
couple of hosts per switch and we ran an
application consisting of broadcast
along expanding tree and point-to-point
forwarding along shortest paths and we
just used a very simple traffic
generator where each of the 12 hosts
periodically sent a broadcast ping and
then of course all the switches would
respond back to that thing it's are all
the hosts would respond to that thing
and we ran this with a bunch of
different controllers so top left is our
o camel verified controller and this is
a time series showing how much traffic
the controller had to handle over the
run the experiment for on a logarithmic
field so as you can see at the very
start there's about 60 kilobytes of
traffic which is just the controller
sending down the configurations to all
the switches and then at periodic
15-second intervals there's some keep
alives that are part of open flow this
is just the switch saying ray still
there and encouraging so there and these
are quite small and this is almost
exactly the same as what you see for our
unverified Pascal implementation just to
kind of illustrate some of the other
kinds of runtimes you can build we also
built a micro flow or reactive runtime
that doesn't install any rules but that
installs very fine-grained rules when it
sees traffic and so here you see quite a
big difference sort of every time that a
host sends a pain there's sort of a huge
spike in traffic because the
controller's scrambling to process all
of those packets that are being sent to
it all of a sudden then it sends down a
rule and then there's nothing for a
while until the next different flow
habits and then over here you see the
most naive controller which installs no
rules and processes everything itself
and so here you see just a high rate of
constant traffic and when the broadcast
comes and the flood of messages come
back there's a spike so again nothing
you know I wouldn't put any this isn't
like any kind of complete evaluation but
just to show you that these things are
running and doing what
question know how much time i had but
we've also built a little verification
tool for net core this is what the
undergrad Rebecca did and the sort of
obvious observation is once you've
designed net core built a verified
compiler then you might as well do
reasoning about network programs in net
court because it's much much simpler so
what Rebecca tip was to basically take
net core programs in a particular
topology encode them in XIII using a
model that was proposed first byte see
and then later on some people at
Stanford turn into a header space a tool
that they can work on for a couple years
and basically you express sort of the
function of the network implements as
one relation and the topology is another
relation you compose them together try
to take their transitive closure and
then you can check reach ability
properties automatically so here's a
little snippet of XIII with all the
interesting bits alighted that kind of
shows how we use it we've also used XIII
to implement translation validation for
net cork so we have a couple of
extensions actually closed lesson sure
who's a intern here before has been
working on how we can do isolation for
net core policies and the isolation
compiler is actual just a net court to
net court translation and so to check
that that translation doesn't somehow
change the behavior of our policy and
also gives us isolation we've used III
to do that check so just to kind of wrap
up I think you know developing formal
methods for networks is a really
exciting area because our critical
infrastructure and only becoming more
important but they're still being
programmed using really rudimentary
techniques so it's a great opportunity
for our community to have some real
impact software-defined networks are
sort of an enabling technology that
makes it possible to build some these
tools and I think exploring ideas like
machine verification and high level
language like net core are a promising
first step in this direction let me
close with a couple of just
advertisements for other stuff we've
been doing and also an advertisement for
summer school that nickel
and I are participating in this summer
so we've done a bunch of other work on
net core and and other systems based
around sort of program languages plus
networks the one that I'll explain in
some detail is our sitcom paper from
this year this is the question that came
up twice sort of how do you move from
one configuration of the network to
another you know this involves somehow
infant somehow updating a bunch of
switches well you know not breaking
important invariance so what our sitcom
paper proposed was a few different what
we called consistency levels where
basically the controller programmer just
says please update me to this new
configuration and the runtime system
does a bunch of instrumentation to craft
a sequence of installations and
installations that have the property
that any packet or set of packets going
through the network will see one
consistent snapshot so we call this per
pack consistency and / flow consistency
and the kind of theorem in this paper
tells you that if you use that kind of
network update than any invariance of
the old policy and the new policy of
these paths properties will be preserved
across the other great so you don't have
to worry about specifying what
invariance you want they're just all
automatically preserved let me not move
some time go through all of this but if
anyone's interested I can give a more
detailed description of any of this work
so let me end with an acknowledgement
this is of course joint work with the
three people here in did all the hard
stuff and also a big group of people at
Princeton both on the networking and PL
side and the advertisement is if you're
interested in exploring sort of the
application of formal methods to
networks come join us this summer I know
that well ethica has the property that I
know Seattle also has which is you know
most of the year is miserable and on the
summer you just don't want to leave
because it's so wonderful so if it goes
very nice in the summer and in June
we're having a summer school with an
all-star cast of lecturers including
Nikolai so a bunch of people who are
building tools for
verification networks and it's open to
researchers and grad students and people
in industry if you're interested talk to
neck wire me thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>