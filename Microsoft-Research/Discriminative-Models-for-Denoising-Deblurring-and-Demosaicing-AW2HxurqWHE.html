<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Discriminative Models for Denoising, Deblurring, and Demosaicing | Coder Coacher - Coaching Coders</title><meta content="Discriminative Models for Denoising, Deblurring, and Demosaicing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Discriminative Models for Denoising, Deblurring, and Demosaicing</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AW2HxurqWHE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so I'm going to talk a little bit about
statistical image processing and a
particular type of model we have used
for many different image processing
class but first off I want to start by
showing you an image this is an image I
took I took it last summer with my nokia
lumia phone so just take a look at it
for a few seconds and then i will
explain to you how this image was taken
so in a very simplified 10-second view
on a digital camera you can imagine a
point in the world that either emits or
reflects light its projected through an
optical system onto a sensor and then
the sensor produces some digital signal
which is somehow processed okay as
simple as that however it's not really
that simple so this is a visualization
of a real optical system that you would
see in a digital camera the in a
smartphone is probably a little bit
simpler it only has six lenses of
different materials different optical
properties so it's a highly designed
system designed to trade off different
factors of optical qualities of weight
of cost of form factor of all the
robustness of being able to stabilize in
terms of motion compensation so it's a
it's a difficult system design same for
the sensor it's it's one of the very
important applications of semiconductors
is imaging sensors they keep getting
smaller they keep getting more involved
there's more processing happening closer
to the signal so typical sensor and a
smartphone would look like this we have
them small micro lens a color filter
that filters certain spectrum of
wavelengths which is projected and these
photons which which hit the surface here
are converted with very high
efficiencies up to ninety percent into
electrons this is sort of the state of
the art in sensor technology and then we
have the imaging imaging pipeline right
so you get a signal which is actually
monochrome but it's filtered with the
color filter array typically a bio
filter and it undergoes a sequence of
transformations each of which is
carefully tuned carefully calibrated to
the optical system and and only if all
these things work together you get an
image like that
so this image probably in the darker
regions here has something on the order
of 50 to 150 photons per second hitting
a pixel okay and you try to get a signal
from there that image was taken in a
tenth of a second so 100 milliseconds so
we are speaking here about counting
single photons for each pixel and only
if all these components work together
the optical system the sensor this is a
in this phone is actually a the lens
system as stabilizers and a small
barrels or suspended it can actually
compensate for optical shake and then
there's a digital processing pipeline
and only if all of these systems work
together highly integrated tuned for
each other then you can take a picture
like that handheld okay so that's sort
of the motivation why I am interested in
statistical image processing how to how
to keep pushing the boundary of images
we can take but I one component I would
like to talk about in this simplistic
view what about the world right as a if
you think about publishing model
generative models we surely care about
models of the world what is the world
about and this is really an interesting
interesting question because we
understand the physics we understand the
world right we understand it so well
that we can actually produce very
realistically look examples of the world
so give them a high-level description of
a scene we can render this is rendered
using a physically accurate renderer
which simulates light transports were
seen we can produce realistic renderings
however these models are not amenable to
computation ok so these models exist we
we understand reality but they are not
amenable to computation some are
computation efficiency needs to enter
our view if you want to build models for
images and then there are more amenable
models such as say the dead leaves model
or small patch based models or the
fields of experts model generative
models of images which honestly are more
amenable computationally but they don't
really reproduce realistic image
statistics ok so and one important slide
I want to iterate here that there is a
trade-off with audiences is as a
continuum between academic image
processing research and sort of the real
world applications of this technique so
an academic research papers we often
make up a model problem which is simply
fight with strong assumptions and then
this is a low barrier of entry for many
people to contribute the research and
for example work on image denoising or
something like that on a very rare and a
very limiting assumptions we as in the
real world if you talk to real image
processing people who actually build
these cameras they will tell you they
are very skeptical too academic research
in general and there's a high barrier of
entry and your model assumptions need to
be really very well validated so they
are very reluctant of making making
modeling assumptions so there's a
spectrum and I will present a few works
along these spectrum so I'm not claiming
i'm totally reward a totally academic
but somehow in this i just want to show
you that there is a straight of and
different model problems could be
isolated so I'm talking about image
restoration so we given and that is a
special task of image processing where
you assume this a true latent image
which was corrupted by some process
usually sarcastic and then you are
observed the stochastic corrupted Lee
image and you're interested in inferring
a likely image that that gave rise to
this observed image and one model which
we have used for a number of tasks is
what we call the regression tree field
model so it's simply a combination of
Gaussian conditional random fields with
nonparametric regression trees so in a
sense a simple bird's-eye view is you
have some you have some pixel you
evaluate some filter statistics for
example what's the mean intensity in a
certain rectangle around this pixel so
you here and here you evaluate it and
depending on that intensity you traverse
a tree down and then the leaf of the
tree you store some model parameters he
do this at every place in the image and
you piece together one coherent model in
this case a Gaussian a single huge
multi-varied Gaussian for the whole
image and then you do inference in that
gosh so it's very efficient a test time
so as a representation we simply use a
sort of homogeneous structure so we just
replicate the same type of factors but
because these factors evaluate the image
content the actual effective interaction
that's instantiated in this factor graph
differs from image to image so something
very naturally that you can express for
example if
there is an edge along a certain
direction the factor can recognizes and
then sort of smooth only along this
direction for example this is the kind
of interaction you can express with this
type of model okay so technically just a
big huge quadratic positive definite
function and you can so you have a
quadratic component here which must be
positive definite you have a linear
component all these depend on filter
respondents on raw pixel intensities and
there are functions of the observed
image X was the difference between a
markov random field and a conditional
random field the parameters are
functions of the observations okay so
you had a single huge quadratic energy
function and you can use conjugate
gradients to efficiently optimize okay
so because a Gaussian conditional random
field is a very limited model class
right you get this expressive
conditioning on the input image but hey
you still only have a multivariate
normal distribution right so because we
have this limited model class we use
something very simple we simply stack
this model on top of each other so the
such a model would make a prediction and
then we take this prediction and the
original inputs and statistics extracted
from these and feed it into the same
model class again and because it's
conditional and nonparametric so it can
condition on all kinds of statistics of
these input observations we can then
make another prediction and so this is
this cascade model it's computationally
very efficient it has an anytime
property so we can show an image every
time a cascade stage is finished and we
because I'm each model in this cascade
has the ability to just reproduce its
input we get nested model classes so we
have sort of wood in in but Nick's
philosophy sort of this increasing
capacity models so we would hope that we
got better and better predictive
performance okay now let me skip that we
do you we had different training
procedures but we ended up using
empirical risk minimization because it's
most efficient and we learn
okay so we can learn with different loss
functions for example a simple
decomposable loss like the mean squared
error or we can learn with non
decomposable loss functions as long as
they are differentiable we can learn to
optimize for specific loss functions so
and it actually matters so if you
optimize a model for a specific loss
function with imperious minimization you
can expect to do better with respect to
that loss function so this one is
optimized for another loss function
otherwise the exact same model you get
better predictions so the loss function
actually matters okay let me skip about
that it's a regularization we have an
efficient way to regularize these model
parameters by bounding eigenvalues from
above and below we tried a lot of
different other regular rises and priors
on this on this positive definite
matrices and we always I mean I never
knew okay how to set these parameters of
an inverse Wishart distribution what's a
meaningful way to set this parameter
swear as bounding the eigenvalues was
very easy and it directly controls the
condition number of the final system
that we need to solve sort or actually
also an op on the test time efficiency
okay for training the trees so jamie has
alluded to the screen greedy training
procedure we actually use a slightly
clever clever thing so we also use a
greedy training procedure in our model
and remember that at every leaf in our
model we store model parameters so say
we have this this type of model we have
model parameters this quadratic and
linear term in this quadratic form and
we compute the gradient of the empirical
risk with respect to that model
parameters and because we optimize the
empirical risk for for our current model
this gradient will be 0 right otherwise
we have not we have not optimizing
empirical risk and now the question is
how can we how can we extend that model
how can we grow that grow the tree and
the way we do it is we just propose a
random split based on the input data so
it could be take a filter response at a
relative position to this pixel and
threshold did and now we need to score
this this is a good possible split this
is a good way to enlarge the model and
the way we do it is we take this model
parameter of the parent we
copy it to the most to the two leaves
and remember that the gradient at the
root here was added at the parent was
zero but now because we have partitioned
the data the induced gradient will no
longer be 0 right so they would sum to 0
because they were just petitioned the
data but they will no longer be 0 and we
can take the induced gradient norm of
these new parameters which we would get
as a scoring criteria the Assumption
being that if we see there's a gradient
with respect to this new model
parameters we could run a few iterations
of our optimization procedure to
decrease the empirical risk ok and the
nice thing about that is actually that
is as efficient as training an onload
regression tree ok so this is slight
technical innovation but it actually
really matter some practice so you get
basically you can get the same
predictive performance if you train this
using this functional gradient method as
you would get with a normal tree trained
using the squared error squared
residuals criterion so if you use the
right function to train your trees you
get better predictive performance of
small arteries ok I have a little bit
time left only but so this is a we have
a number of papers that on this model
and on different applications let me
talk quickly about these applications so
one is image denoising a classic task so
there are many existing methods as a
generative model fields of experts model
with proper bajan inference using MC MC
is very complicated in terms of
computationally very complicated and
then there are a patch based methods
locally sparse coding methods so people
smart people have spent that time trying
to to do these denoising methods here's
a result so we compared against BMC d
which is probably the most practical
real-world denoising method and let me
zoom in here so probably what you can
see this additive white Gaussian noise
so it's not it's not one hundred percent
realistic but you can see maybe I don't
know that we preserve edges better than
this this method but in terms of PS and
are this will me on screen you can see
that it's a visual improvement
also in terms of PSN are we have a
higher fidelity and this is danna
dataset here's a color example again a
zoom zoom in version and again we have a
better performance measure by PS and are
here are the numbers and you can see
interestingly that across these models
stages I told you we have this cascade
model we monotonically improved proved
Pearson R so this is just what we would
hope for we also applied it to jpeg be
blocking probably i skip over this
application but this is an interesting
non iid noise application and okay i
have five minutes left so this is on
image d blurring this is a big problem a
smartphone photography because
essentially the form factor constraints
the size of the optical system and the
size of the sensor that means you either
have very short exposure times no blur
but very noisy images or you have long
exposure times no noise but potentially
blur and if you are if you produce a
smartphone if you want to sell it and
you show noisy images to your customers
they probably think the camera is is bad
but if you show the blurry images they
sink okay of course i shake the camera
must be must be me right so all the
vendors of smartphones they tilted
towards having long exposure times and
potentially blurry images instead of
slightly more noise and sharper images
that's why it's a big problem we make an
assumption here which is a reasonably
accurate for handheld devices like this
and the scenes which are far away which
is that we have stationary blur so we
assume there is a latent image which is
sharp which was convo with a stationary
black kernel of big size usually
something like 60 by 60 pixels at the
seals of blurry observation so here
first some some numbers of existing
models turns out actually that the
Bayesian model is doing really well here
however it takes like four minutes force
I think 128 128 patch four minutes of
inference time so we can achieve the
same performance in two seconds using a
discriminative model here are some
results on a on a tubing benchmark data
set on the blurring
so we go from here to here and
interestingly we took as a starting
point for how to build this model we
took a generative model and then just
replaced components of the generative
model with discriminative without
discriminative regression Terry fields
and this allows us to encapsulate
everything that is relevant to the blur
card or so which is different from image
to image away from everything which is
independent of the Blaugrana so that's
see that's a clever bit we encapsulate
everything that is lower kernel and
therefore image dependent so every image
has a different block owner from
everything that is independent of the
block colonel okay um anyway so there's
a way to generate synthetic colonel
because we need to generate training
data and then we have to benchmark
datasets here you can see the effects is
after the first model States you see the
image the dominant blow has been removed
but there's a lot of ringing artifacts
and noise remaining and then the further
models say just clean this up because
this is much closer to a denoising
problem than a2/ad blowing problem so
the model works very well once it can
latch onto edges this is performance
numbers on one benchmark data set
matching the performance of the Bayesian
model again a monotonic improvement over
the Cascade stages this is a real world
benchmark data set of from the tubing
and lab and this is improvement over the
best existing method at that time so
across all almost all combinations of
images and blow kernels we improve and
yeah finally two more minutes right we
applied this very recently two demos I
king which is a problem every digital
camera has to solve so or almost every
digital camera every camera you can
probably buy for less than a 200 pound
has to solve the demo second problem so
there's a color filter in front of the
sensor and you get basically for each
pixel you only get a measurement in a
certain wave spectrum so either reddish
greenish or bluish measurements but you
want to actually have three measurements
per pixel so you can have a color a big
supply so you somehow need to do you
need signal complete you need to
complete for the red pixel
to complete the blue and green channel
okay most academic papers actually
design it wrongly they design it already
in the color space like srgb which could
only be produced after some
transformations which already need all
three color channels so we were
surprised to find that more than half of
the academic papers on the demo second
problem are completely removed from
reality and work on a completely
artificial application so this is
actually a real de mosaicing message
probably the best existing ones this is
a matlab d mosaicing method and this is
our imaging method and in terms of
removing color tinting and high
frequency areas like this we are much
doing much better and we also handle
noise integrated noise and demos Oh
Akane de-noising intimidating
simultaneously and we get a an O point
five decibel improvement over the
existing state of the art which is
visually as you can see clearly visible
ok and I guess that's it thank you very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>