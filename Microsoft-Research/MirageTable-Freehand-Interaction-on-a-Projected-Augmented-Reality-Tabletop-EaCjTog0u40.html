<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MirageTable: Freehand Interaction on a Projected Augmented Reality Tabletop | Coder Coacher - Coaching Coders</title><meta content="MirageTable: Freehand Interaction on a Projected Augmented Reality Tabletop - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MirageTable: Freehand Interaction on a Projected Augmented Reality Tabletop</b></h2><h5 class="post__date">2012-05-02</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EaCjTog0u40" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">in mirages table a 3d stereoscopic
projector projects virtual content
directly on top of the current screen
the 3d information is captured by the
Kinect camera which also tracks the
users gaze
this enables presentation of correct
perspective views to a single user on
top of the dynamically changing geometry
of the real world to simulate physically
realistic behaviors all real world
objects are represented with proxy
particles in our case spheres which are
dynamically updated and used as
collision geometry in the physics
simulation
this allows the user to use any part of
their body or any object to interact in
a virtual content
real time depth camera information is
used in projective texturing to present
the correct perspective use of 3d
objects the user even when such objects
are projected over multiple real
surfaces
in addition to supporting direct
interactions with virtual content depth
information can be used to instantly
digitize the real world and then
interact with such recordings
for example the user can digitize real
bowling pins and play with them in a
virtual bowling simulation
be fun you know I have real-time
captured meshes of the user the objects
of the pager talk can also be streamed
to a remote location such remote
collaboration enables both participants
to collaborate in and share the same 3d
passive space as if they were sitting
around the same table okay oh this one
is bigger than maybe your blog can you
like when your blocks being okay
we conducted two experiments to evaluate
the image quality of our projective
texturing system when presenting 3d data
over various backgrounds including
surfaces that vary in geometry in color
these images show the backgrounds tested
and the performance of our system
we also evaluated user's depth
perception over such projection surfaces
and found that users were able to fuse
the stereoscopic image and comprehend
the 3d location of the object even on
very geometrically deform backgrounds
in summary mirage table demonstrates how
the depth camera input in facilitate
compelling 3d visualizations and
freehand interactions with real and
virtual objects on the table</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>