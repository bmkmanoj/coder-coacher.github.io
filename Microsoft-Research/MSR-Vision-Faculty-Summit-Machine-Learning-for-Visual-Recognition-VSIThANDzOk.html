<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MSR Vision Faculty Summit - Machine Learning for Visual Recognition | Coder Coacher - Coaching Coders</title><meta content="MSR Vision Faculty Summit - Machine Learning for Visual Recognition - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MSR Vision Faculty Summit - Machine Learning for Visual Recognition</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/VSIThANDzOk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so the next stop will be by IQ
non-randomized decision forests and it's
novel applications okay nice meeting you
I'm taking from Imperial College London
so I'm very glad to be here so thanks a
lot for inviting and also to all for
your coming so taupe tighter today is a
letter quite big admit that machine
learning for visual recognition but in
there I'm going to highlight a
particular technique which is called
lenda my decision for is and I know here
are many experts of it just let me kind
of explain some 300 our own mobile
application job it we're actually this
is material that I talk to my students
at Imperial continue some basic
information but I'm going to go quickly
clip gain with data vector X image your
feed church convert into column vector
and we do some unsupervised learning for
density estimation so many for learning
is also one of them and then if you have
a labor Joe variable then we learn the
mapping function from input to output so
it runs provides us provides running now
so we do some classification some
techniques are very often used in the
field include boosting production margin
classifier also when that target vector
it continues then obviously we do
regression poornima Kofi so sorry about
excellent handwriting and also Gaussian
process is also one of those popular
techniques used ok key a thing in the
area is generalization to unseen data
given a training data to estimating the
density function P or the mapping
function f is relatively easy but then
how we go from left to right when kind
of new test data points are given those
a launch function P or F should be
working well for me there as well so in
the mean where it is a typical saying
though in computer vision the debtors
are in very high dimensional space
so and also due to their large in
chocolate variations practical
assumption is that we never have kind of
complete training data always test data
points are quite different from Thailand
era so how to go from to the left Lloyd
is much more challenging in computer
vision then I think were relatively some
other of traders ok there are many
techniques about how to ensure food
generalization sopra number curve fit
very addition to error tone it also has
a regularization term so avoid
overfitting and also obviously a support
vector machine today the notion of
maximizing margin and that is given by
the objective function and also Gaussian
process that our place is some Gaussian
prior distribution on the weight for
weight vector W so actually quite
interesting there is a kite analogy
among the different methods different
set of the odds were always doing kind
of good generalization particular on the
weight vector W so obviously there are
some other types of message like
boosting they're also which quite a good
at generation transient data but in a
quite different way from the previous so
it combines weak classifiers or linearly
so linear summation of we classify
outputs or the output of strong class
form so by having their weekly far is
relatively naive legionary naive and the
linear summation doesn't go too much
over fitted so obviously there is no
theoretical guarantee for good
generalization but practically has been
pretty well known and working well for
the challenging visual recognition
problems the other coin that I
particularly would like to emphasize in
this talk is random forest so touch my
illustration random forest so if each
week classifier is seen as a decision
stomp then actually a random forest has
also an allergy quite similarity with
boosting so tell you what I'm going to
explain a bit for during the following
slides obviously destroyed compared to
some
techniques in terms of optimality so
when you do visual recognition obviously
recognition accuracy is kind of key
criterion but then actually I want a bit
focus on the other criterion which is
computational efficiency so here we
compare posting a support vector machine
where where it is quite basic so
basically the posting it seemed much
faster than not near as VM but when SVM
adopted in your corner then actually
that computation the discounter
computation can come out of decimation
so actually that computation demanded by
linnaeus vm is also quite efficient
called low so we are posting is more
efficient than boost our linear SVM
depends on how many number we
classifiers to use or watch the
dimensionality of data vector so d ok
then why I mean we are particularly kind
of taking care of the computational
efficiency so there are many such kind
of computational demanding problem one
is object detection so from a given
image we have to scan every possible
scared I mean in a typical approach and
have to scan every pictures to detect
pedestrians you have to class for a
typical image is comprising of millions
of the windows we have to classify so we
have to kind of tell whether the top
each the window contains an object
winters were not in a very fast manner
so to complete this task in original
time ok seated a post in class file
viola and Jones has been very successful
in the field so our own interpretation
of it is very Cheryl network so we see
that each v-class fire now is a decision
stomp so we have many of them and when I
tested upon each given it a pass it on
to every week class for every decision
stomp and then their outputs are
linearly aggregated so that flat
structure very shallow structure often
provides a very smooth decision boundary
which is good for generalization so good
accuracy however the flat structure
to use all the weak classifiers in
computational efficiency it's a
suboptimal so people often use cascade
of it in that cascade each node is from
pusing classifier but it does kind of
course define a search concern but
actually I designing the Cascade
involves quite parameters to set
manually or automatically so this is the
alternative well did you learn them for
is a slide of Jamie shot and I store it
so it has a logical structure similar to
that post in cascais so that all into
the hierarchal structure is quite fast
in both training and interesting also
another advantage is that it can do
multi classes and also were dead
randomization in the featured split and
also randomization in the data
aggregation which is pegging it a quite
kind of Impractical included
generalization smooth decision
boundaries and recognition accuracy
here's a quick comparison between the
very traditional lending forest of
traditional titian three in the left
hand side and in the right hand side i'm
showing the kind of conceptual the
notion of random forest the decision
tree is very kind of notoriously bad as
it keeps splitting a tree or knows it
can always kind of dichotomize all the
training data points so when to stop it
is kind of a big question so many
studies have been done but unfortunately
there is no such kind of priest / rule
so it often ends up with this over 50
the decision boundary but instead random
forest even with a fully grown trees by
having two or three each tree is just
slightly different from others and by
combining them it towards some kind of
smoothing out effect perturbation in
fact it's just going to conceptual
comparison so it does kind of pretty
provide a good generalization in our one
over latest work published in LG TV we
formulated this converging properly from
the posting class for you
inside to the Titian trained right hand
side so we take a posting classifier
lonely learnt in a standard way as input
and then we produce some classifier you
know this tree structure as output but
in this conversion one key thing is that
we preserve the decision boundaries of
boosting class for college pretty kind
of reasonably smooth and good for
generalization accuracy so we converted
from boosting to teach entry by
preserving the tissue or boundaries of
boosting classifier but as a result as
you know hierarchical structure or
intervene many short passes you could
accelerate the variation speed
rats in here just given the titian bomb
decision region to boosting class file
each subregion of it is reached by one
pass up that resulting algorithm so
obviously it has some short passage and
also long passage depending on
difficulty over Sampras to classify okay
now let me show you let me explain some
30 or own application you'll and employs
one is real-time action categorization
so in here actually we use the London 48
a codebook of space and time and we
could do kind of this action
customization almost in your time okay
some major contributions lies in whether
so we did that we learned it code book
of spatial temporal space using random
forests I should briefly explain it and
also we captured some structure
information among many interest point in
addition to that genetic information
also some other contributions include
some extension of west corner detector
into space and time and we could do
continuous action recognition instead of
k-means clustering typical approach for
quotable visual random forest in space
and time also we a capture so it's very
efficient and also robust and also we
capture the search information using the
launch random forest code book and also
it could do some hierarchical matching
to relieve some quantization effects
here to kill overview we detect interest
point and then we extract some fish
tempura boys around each and then we
quantize them using random voice
quotable and then we capture some
switching information by the technique
powered by linden for its code book and
finally perform some again tree
structure classification so or could it
be doing very fast manner okay so here's
about that semantic textin force of in
space and time where each cuboid is
passed down the tree and each spring
node we just simply look at to pick
surgeon space and time randomly and then
we compare them depending on the
comparison we just pass it to the left
or right it's very similar to Jamaica
section forest Jamie what is the
extension to space and time and for the
first time then this is about how we
captured the search information given a
parable q boys we pass them down the
tree and then depending on the leaf
nodes they are arriving we increase the
corresponding histogram bin and also we
have some heuristic Alida find the kind
of regulation rules it's like kind of 1q
boy it is or before or after the other
or how adjacent they are kind of things
so it has this kind of 3d histogram as
you have a mini change in the random
forest so we have many of those
histograms and finally we met chicano
biologically so we perform pyramid in
Mexico no but in a very efficient manner
because we have London for it which is
inherent in hierarchical structure
already such as we could perform this
one in a very efficient manner we did it
to benchmark datasets k th and UT
introduction Deir Ezzor and so there are
a lot of studies in the area and in
terms of accuracy we are quite happy to
have it set of the art accuracy it's not
not much worse called competing but in
terms of speed for katie sarah said
we've got about 20 frames per second and
for UT interaction we got 10 frames per
second a bit further demonstration of
the work
in here we are processing frames about
10 to 20 frames per second or so
recognizing classifying into 10 or 6
section categories that yellow bar
indicates the confidence amount of
confidence on the current recognition
it's quite robust about that camera
viewpoint changes also some scale
variations which will be shown later
right okay now this is second example so
we do phenotype object recognition using
3d shape priors the phenotype here means
whether that a object is slim or fat or
tall or short or molecular or something
so given a curie shira can you tell the
which object I mean which person the
Steelers should belong to the given
calories which is second man the left
hand side so we attempt this one under
deformation so it is articulation of
human body and also we do the same thing
under 3d camera view point changes were
at the same time it's a hard challenge
work based on single should kill Alicia
read a single Curie Sarah so we do use
3d shape lawyers so teaser works have
been published in each TV and I GCV
listen ears here we show how we learn
the 3d shape priors so actually we
decompose problem into two one in shape
in theory supposed variation so we learn
in shape generator from the 3d practical
model human bodies or in the canonical
polls actually used a generative
technique called Gaussian process
Lautenberg motor so from them given that
a PC a coefficient of vortex positions
now if you from actually given that some
latent value it could generate a the
shape and you apply the same technique
to pose variation so that is learned
from this 3d graphical model or
canonical shape but with the post
variations so we use the same technique
to capture positive relations okay from
one to TP rpms so we're in the left hand
side in rice inside we showed some
cross-section of latent spaces of GPR vm
for shape and pose spectively so by
taking one berry in the left and the
other Barry Android you could generate
some arbitrary shape and pose
so we started with the general shape and
then we learned the post variation we
also learned shape variation and then
using the some post transfer technique
proposing the graphics area we could
generate arbitration pose as well so
this motor is serving as our 3d shape
problem so now I'm explaining how we
perform phenotype your clinician using
the launch 3d shape problem it's
basically a by this graphical model we
use random for is here to hypothesize
the latent values from given single
curation route so we have a three
different random forest so one is four
paws and one is for shape and also the
third one is for camera pose so once we
have some estimated very up the latent
variables for each of variation then we
could achieve such as orbital shebin
pose and then we projected into some
certain image plane having children of
it and comparing the shear rate with the
Curie sure we could perform phenotype
recognition here's an example of a 340
shape and post classification so we have
many of them slightly different we also
proposed some dover way to compensate
errors using some just kind of metrics
so you ever collected our own data set
and ever compare some relevant message
but actually most are 2d and one is
using the same 3d shape priors but using
different techniques better than random
forest you compare them with our own
variations within the framework and do
the red bars ladies paws are all one
solution and those blues or Walgreens or
others masters so using the 3d shape
prior could improve that the clinician
accuracy quite significantly in the left
hand side is about human data of jumping
Jay and in the mirror it's for working
right hand side it for shark or some
deformation sequences
so this is some intermediate shape
reconstruction dessert coach after
estimated hypothesizing the rate on
various we could generate this arbitrary
shape from Givens English erodes the
input and shape estimation and pose
estimation and the same at the different
camera view point the same for human of
images so input image and estimate you
the shape and pose and just add a
different camera viewpoint and by the
post transform we could convert them
into some canonical poles in here
actually there's quite varying
phenotypes estimated object this is the
latest the finer I wanted to explain
which ongoing work under submission so
let me go very quickly about it so in
here we do video based of the
recognition rear time showing displaying
that object name with a conference for
you
okay in this formulation we have a old
kind of borders and Kure as a videos so
you perform video to video matching
where this is kind of some conventional
image-based lachlan asian framework I
mean when the video is our variable
actually there is relatively much layer
work on video based object condition
mostly they're about image-based
recognition even even if it is a very
very simple then typically kind of take
videos etc images so they perform
frame-based recognition frame by frame
and then they accumulate the frame
recognition scores letter simple manner
so this could be one you can prove it
from a given image with the tagging
stress points and each interest point is
passed down the random force korbo and
then each image is now histogram vector
so using some classifier the local
analyze each frame and then just sum up
there score values where put our
argument is that actually we could do
better there is a bit more information
like kind of temporal continuity some
setting set properties we couldn't make
usual for better object recognition in
video when video is given what i think i
just i'm guessing that one reason why
the people having attend I mean given
their attention to the video a subject
donation is that in the scenario that we
consider the camera motion is random we
think of the scenario where the user is
moving their camera around an object of
interest so this motion is quite
different from that some debt motion in
the study like action declination or
gesture recognition where the motion is
discriminated kiedis community
information but in here due to the
randomized Random randomness actually we
have to explore some different I mean
properties for video recognition so
we're so just
briefly click on save is such absurd
from given a video we have many images
right so a set of images and then each
image we detect interest point over so
we have set of interest point so by
going down we have a set of a second sir
we'll see if you look at one or image
patch and track them through the time
then we have a trajectory and then we
can collect set of image patches along
the track at work so after that track
tracks we have many of them so it forms
another set of that concept so actually
been studying about how to represent it
set up their concept how to match one to
another for a video-based object
recognition we're just very brief
concepts that we rely on our popular
representation job search so one is your
pick up board touch indeed or let
project a very popular way of
representing set of interest points so
we use it also another technique is
manifold the manifold is particularly
good for representing set of data
temporarily smoothly changing so we use
them in a kind of recursive fashion for
set of data especially distributed and
setup data temporary smoothly changing
so obviously we have some alternative as
well we're in here actually we also beg
many fold but manifold is not single
vector potential described by a set of
basic factors such we needed some new
technique on how to pack too many for it
got your bit of details in the work so
here is our new data set and we compare
some simple frame based recognition
watching accumulation of it on different
object categories objective object
instances and we are performing
significant error also different kinds
of elimination of variations
the training terrorizes the shingle
turntable sequence at the fixed height
and with the camera at the fixed height
a different day and different time so
you could work into your time merely
need your time and also it's quite
robust about 3d 2d rotations or so some
foreground clutters and background
clutters some elimination changes well
we are testing completely different day
works pretty well okay so apart from
that what I presented some ongoing
funded projects are including a
real-time vertically subject detection
so we consider some different object
classes that have different aspect
ratios with us in height and in there
can it do detect all of them in kind of
closely or time that's kind of one of
our questions and also we do continuous
learning 24 hours and seven days
learning rather than just learning
single time and offline fashion
deploying to new environments it's an
Aquanaut work syrup you're interested in
kind of exploiting all the variable
resources in internet as much as
possible or keep improving the
performance touch by the joint world
within us also we do some deformable
objects or clinician and finally we are
very interesting just to interface by 3d
tracking over human hands k-touch mousse
au vin and this is a snapshot of our
group at Imperial College so where ya
any questions and kept for the post
estimation things I was wondering how
scalable it is so you were just showing
a few poses if you want to do something
like really reconstructing the posture
from the 2d silhouettes how applicable
is your method that's true at the moment
actually our algorithm is specific to
certain pose
so we need some motion capture data or
something like and then we have we
collect a lot of 3d graphical model with
a poached variation and then we launched
energy motor / GP rpms but so you can
learn a lot of models so I was wondering
whether this framework it's doable for
really recognition of arbitrary poses
well yes and no I mean yes obviously we
trained at the same algorithm GP are
vehement a lot more poet variations in
each each possible but then the
challenge you would be about hot control
that kind of dimension of latent spaces
and I think just naively applying the
contact need to all kinds of what
variation is not going to work Oh be
more cleverness to be needed I guess ok
so if we don't have any more questions
les thanks taken again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>