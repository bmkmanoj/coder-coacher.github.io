<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Speaker Diarization: Optimal Clustering and Learning Speaker Embeddings | Coder Coacher - Coaching Coders</title><meta content="Speaker Diarization: Optimal Clustering and Learning Speaker Embeddings - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Speaker Diarization: Optimal Clustering and Learning Speaker Embeddings</b></h2><h5 class="post__date">2016-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vcyB8xb1-ys" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by Microsoft
Corporation may be used for internal
review analysis or research only any
editing reproduction publication
reproduction internet or public display
is forbidden and may violate copyright
law
okay so it's a pleasure to introduce
Mikheil ruby a today mikhail comes to us
from Marseilles in France
he's had a long trip prior to his
postdoc position at the University of
Marseille he obtained the PhD at the
University of Avignon while he was there
he developed a super elegant way of
doing Diaries ation that basically
reduces the problem to zero one integer
linear programming and today he's going
to tell us about that and then some
extensions that use embeddings to do
diverse ation thank you thank you thanks
for the invitation and very happy to be
here so today we speak about speak out
that is nation and I will speak about
optimal History Museum together now cami
and after him speak about speaker on the
news so the outline of my presentation
so first I will speak about me so about
my project and my background and after
we speak about speaker deionization I
will just repeat this but what is bigger
dilation and I just described speak
organization I apply on broadcast news
not in meetings so it's some difference
so doing all my conversation I just
present speak of the ization I apply on
broadcast news and laughter I will speak
about speaker cluster India so I will
present the method
ELP clustering so the clustering was
very appreciated by the community
in fact when I sent the paper in the
confirm so logically I can patroclus and
me anime so so nothing propose to come
to the MIT in order to present this
method and Patrick wants to reproduce on
my research and that during the converse
of the conference many people asked me
to send the core
to really the god about Sierra
clustering and after I will speak about
speaker modern India and how to extract
relevant information on speech segments
using deep neural network and I will
present through this method that I
called speak on buildings so what about
me so my name is Michael I'm 33 years
old I come from France France is near
England German Spain so I'm very
appreciate this is not perfect it's not
perfect it's very bad so if you don't
understand please stop me and ask me to
repeat or you can stop me doing the
converge doing the conversation through
ask me every question so I started my
PhD in 2011 in Avenue and I work on
video summarization automatic video
summarization then I move to years old
in computer all sorts of lumo I work on
automatic speech recognition and speaker
dilation and after I move at Marseille
in computer science of Marseille and I
work on extract relevant information
using using deep neural network so I
just forget to say this is I've no low
noise location here and nothing is
located here so I just present to
project true interesting projects I can
be interested Microsoft so the first one
is repair projector so this project
consisting identify the person in TV
show so we can identify the person on
the video but also on geojo and yeah by
example if you want to identify these
guys this guy is John Mackey oh we can
use a face IDE of psychology but sure
you can also use also information by
example this information the name of the
guy is writen is here or the name of the
guys was spoken the last segment and you
can
propagate all the information in the
video so during this project I work on
automatic speech recognition on speaker
ization and unspeakable identification
but I was working in the propagation of
all the information around all the
modalities so the second project is a
bird projector so the goal of this
project was in the machine immediately
meaning word conversation so the energy
was to go beyond the center of the
simple pipeline automatic speech
recognition and machine translation so
one of the girl of this project was to
get X 0 &amp;amp; 2 so the machine must to
detect the arrow and to ask the user to
repeat the sentence by example if the
user say I like you Barrett and the
system doesn't know the world Barrett
the system say you like what the user
say you're at so this is the image the
first sentence and the second sentence
and try to create the sentence I like
you at and translate them Photoshop so I
worked in a lot of fields but one of my
goal was to exploit relevant information
from documents so I work in speech
emerged natural language processing
machine learning and information or Qi
work the numbers that you see here is
the number of fabrication in each of
finsih and now I try to work in
extracting features using neural network
so let's so what about speaker dilation
so the garlic pickle dilation is true
elsewhere to the question we speak and
when so given on audio stream and the
broadcast news we can solve this problem
in three steps the first steps is to
detect the speech and notes which
segment and after we can we take on new
speech segments and we do a segmentation
in order that each segment contains what
with the voice of only one speaker and
after that we don't clustering so we try
to say like my example the speaker and
the speaker as the same speaker so in my
presentation I just focus in the last
steps a speaker a speaker kristinia and
I proposed a new method about optimal
crystalline so in speaker Christine
there is true kind of approach so the
first approach is a yeah she can't
plastering like doctor reported on that
consist are true at each iteration to
increase or decrease the number of
crystal the second kind of method is
positioning clustering like k-means or
machining shift and consists to refine
the partitioning during each iteration
so concerning the bottom-up Agatha was a
gluten a Peugeot is an iterative at
great that major two most similar
cluster but there is some limits about
this kind of approach first
it's a greedy algorithm by greedy I want
to say that at each iteration selects
the best solution but we are not sure
that the best solution is the best
solution at the end of the process and
the second problem is that that never
that bottom up agree never consider the
decision I just want to say that if an
arrow is done this arrow is propagated
around all the processor so ii argue it
is the partitioning
Plus terrain by example to come inside
go Edna and the come inside would try to
minimize an objective function by
example distance and height NASA but
there is some problem the first is that
the number of crystal is fixed and in
the case of speaker dilation it's a
problem because in speaker theorization
we don't know the number of speaker and
we don't know who's speaking in the air
in the audio stream so so we associate
the problem here and the second problem
is that about initialization of the
cluster so if we begin the cell is the
cluster at the beginning we can fall in
a local optimal solution and not a
global optimal solution so we must - so
I like the energy about partitioning
clustering because there is an objective
function but we must be taken as a true
program that the first one is the
prevalence of number of caster and to
Tiger the second problem is the program
modes in the series initialization of
the crystal Center so in order to tackle
the second problem I propose to use the
integral linear programming so integral
in our programming is a mathematical
model that can so given an objective
function in some contents we can obtain
the optimal solution of this program so
I'll do that work so we give an object
if function you want to optimize
minimize or maximize the objective
function is a linear function with some
integer variable sum
Venera variable and we give some
constraints like an inner function I've
thought that we can use like not going
branch and bound algorithm Oh
the third GUI will remove all the food
left on to that during the research of
the best
so one of the goal of the program is to
express the clustering problem as an NP
poor man so we in order to do that we
assume that the center of a cluster is
necessarily a point of a problem so how
to express in the binary variable this
problem so I want to say that this
segment as in the same cluster and this
segment are in the same cursor so first
we enumerate all the points 1 2 3 4 5 to
10 and after we say that segment 4 is
the center of our blue or cluster and
that segment 9 is the center of the red
cluster and we assume that all the
points that beyond this threshold be
known to this cluster so in order to
explain this in binary viable we create
mattress this is this kind of matrix so
the role is to be part of the problem or
you can take the center separately for
example by just considering each Center
than computing the mean average distance
to all the other three sides so I will
explain about the distance the next
slide and yeah I just want to explain
how to express his problem in binary
variable satsang and after I we speak
about distance so we want to feel this
matrix this matrix ax so this is the
segment and this is the cluster there is
as many segments as
as Christa because we can say that the
reason that each segment are a dresser
okay so if I want to say that this
segment be known in the class to the
cluster I just put one here so this
segment frog belong to the crystal from
and the same for nine this segment nine
belong to dress tonight and if I want to
say that this segment be known to this
dresser
I just feel one here and one here for
this segment and after I put zero to the
old matrix okay so so we are way
expressed in terms of binary variable
the clustering so now I will present the
NP clustering model so but I will begin
by gender I will present the constraint
and after I will present the objective
function so in this constraint I just
say that a segment can be known to only
one cluster I just say that if we take
the son of that the son must be again
what because one segment can belong to
one cluster after I just says that if a
segment fiber be known to the cluster
for so the segment for must belong to
the rest of for my example I say that if
I put a one here
I saw it's obligatory to include a 1
here and the last and important concern
is to say that as the distance between
this segment and this segment
must be below threshold assume it's very
important because if the value is very I
so we can say there is only one cluster
if the value is very small we can say
that every segments are the same cluster
so we can to try to to search the best
the best value and after the objective
function try to minimis is the number of
cluster and try to minimize the
dispersal and high-class representations
interspace yeah so w ok so W is a vector
I don't speak about that but you can you
can you can use what you want time axis
become bathing's by example you can use
what you want so it's not important it's
a distance between two segments and X ax
is a binary way up to the table
so tau K is in coaster and Cain in
center
thank month and this is the question so
the segment and the cluster if that's
the one that this has to be smaller yeah
it's not it's like to be the metric
something yeah so in your example went
to be x KN minus X and n is less than
zero because you gave the example of row
six column 4 so k is six nor is the
column and then you said that reduces
that row for column 4 yeah so that would
be 0 right yeah okay so this is a this
is a second
I say if the segment is faster we saw
but I thought matrix and so and I
thought we just to minimize the number
of pencils and some tight-ass of each
Messer
yeah what properties you have to assume
for your distance measure does it have
to be a true distance measure obey the
triangle inequality that kind of thing
or the deep so yeah in fact as a lot of
kids Jenny before I mix up well I'm
asking can you substitute other distance
measures in there today these are part
of the derivation that it has to be a
distance measure or can it be a pseudo
distance measure I don't know so I know
some of you push them
it's my English okay so you can have you
can have functions that behave somewhat
like a distance measure but don't behave
don't obey the triangle inequality
property yeah yeah no no I think I don't
you say if you so there is three
segments ABC and if you calculate the
distance between a and B C it's unfair
to AC is that in such a question or not
no it's not surprise us because I see
not for this inequality when I'm
labeling is what is required for this
relation to work for the system to work
for do you want so I use so Katie I but
I'm so I'll use also distance metric
like cos in my Lucas
and different tours or matrix' you put
it whatever TV secret ball right you put
whatever yeah yeah like you can you so
what this tells me John you want the
third constraint kind of redundant to
the minimization criteria so the third
constraint yeah that's going to
determine sort of how many clusters you
have because if you set the sometimes
you to say that Swisher is very I if you
said D small it's much so there is the
number of you signal one left is one
more crystal no way so now I'm confused
d make that the third one might not be
satisfiable right so I can send that's
friends of truce eight months all right
so if I make them so it's hard when D is
small yeah yeah and as I make these
smaller yeah then this may force more
clusters but isn't that redundant to
what's going on in the minimization
there so where if you put a very yeah if
you put a very high weight on that
second term in the minimization or the
effectively do the same thing as a third
constraint like why do you need that
hard constraint you can I drink fashion
of the program you can remove the who
can do that and in fact you when we use
position partial so I'm for sure a micro
so I just want to say that we shall not
a single show but
logician and we try to detect the
Revlon's
sweeter okay and when we do that we
remove this constraint and we modify the
program in order to speed up the process
the vest is yeah yeah
so it's this constraint only see the
rewards are also aimed at improving
accuracy
yeah this is the same oh so that seemed
to make things fast yeah we can in just
rooms up the same okay so that's per
hard
this is just to speed up just okay so
keep all that so sorry I don't answer
why is there a person with the same I
assume there's a final number of Costas
or we can come in the PI's that they are
how you choose right we constrain that's
why it's fun by this special right so if
you choose different threshold then the
number of clusters you guys were
different right is if I can do better if
you change the value of yeah of course
when sister front you work out different
yeah you know and then therefore if you
remove that constraint entirely the
number of clusters will be different
yeah and therefore the accuracy will be
no picture you're saying the constraint
is not really needed to get best
possible accuracy
it's just needed to make things faster
this is I need to see if we insist on
fun is only to speed up the process on
but but we need to remove on the a
viable okay
we cannot construct without remove
inspired by a but is this program right
and we are saying that is the same
address but but we remove what was the
resolution is more fast
oh but you change you change the sums is
some signal longer or everything yeah
very much so we use are all we undress a
wall broadcast news it's French what
produced the innovation data set is
repair 2013 it's classical we use a
nubian of 120 of kosher die vector of
dimension 200 and we use nationalization
crispy idea screen so the matrix is Jaya
zation arrow rights is in fact a
combination of three arrows means for
Salaam and speech arrow and I use the
Newspeak idolization toolkit so CLP I
use the gel cap toolkit so first we
compile the button web are growing with
cost like new ratio so sorry
I just want to motion that this is the
name of the show in the copy and this is
our world ization air alright so we
compare button up with cost like human
bathroom with a vector so we obtained
again and after we confirm button up
I'll go put on a Peugeot it with IPA
clustering and we obtain a new gang
we've yet to measure the distance
between two houses right so is that
because that you s the Cooper say well
as longer segments so we get together
reliable I back this for this fear it
rational conversation statement who
shows okay so in both decimals
Simon's the reiteration of the segment
around 1 between 1 and 2 seconds yeah
it's really facing your eyes proposing
to 2 seconds worth of speech yes it's
very Alton changes the eye vector is
computed there's a separate eye doctor
for each sector yeah yeah yeah yeah so
thank you I understand what's the
meaning of Xavier and she glamour it's
good enough okay but there are other
popular clustering algorithms there
right yes it's a classical approach in
forward path news with a sign no there
are many other clustering algorithms
yeah yeah for both new spheres of
classical approaches to use of automatic
movement and the Sienna for both
testicles so what's the training
criterion upon solid evaluation criteria
it's easy in fact is this kind of
gyration we just in fact the
segmentation is the same because we
judge change as a speaker clusterings
which I change the middle speaker
clustering so so yes so agitation arrow
right combines the three myth 3 matrix
but in fact we just are comprar there
are 1 1 matrix of restraint right yeah I
just indicates of jurisdiction here
right okay so now question is to achieve
this to a point where are you where you
do need to adjust the data in their
constant advances sorry you you have a
constraint do with the death all right
is a shot hood we have a stretch good
distance is the third constraint that we
talked about
yeah I need to adjust the Delta yeah I
mean optimize or is it one general
purpose our threshold are optimized on
the development office and we are plies
n we take this treasured and we are
playing that on the test coffers is it
true question yes
yeah so yeah I forget to I have a curve
and I forget to prism to crop but yes I
am poor and we are we indicate the
gyration here all right
in function of saturation if you adjust
the number of clusters in the other
ports so for this in fact if I try to
search zero of Japan treshold oh it's
exactly the same time the bedroom on
purpose HJ see I back there yeah I know
for that you get the - yeah I try to
research the best solution now in the
desk office yeah
was to optimize official who's the best
no no oh yeah because you have this free
parameter the first of the parameter
where affect your final is out so in the
other approach you can also adjust for
them who is a maximum distance between
two clusters and since like that you can
also control the number of crossbows you
can generate so that will also affect
the result in your baselines yeah so
more than us you do the similar say well
oh no I still thought I was my for my
results or biblical focus so so it's a
fair comparison and I saw the end of the
same day problem focus he you you need
an additional segmentation right so you
need to generate the segments that you
submit to the clustering how did you
generate those and where they the same
for you for all your different methods
because the segmentation was done by the
newsfeed organization so sauce so is it
some kind of so it's just a speaker
change detector right yeah
so you basically look for speaker
changes and then any you know whatever
comes between two changes is one of the
second movement yes I give that's you
know sweet or plus three and it was the
same for all of yeah yeah okay so you
didn't do this method like in the exceed
ionization system when you where you
generate clusters and then you use those
clusters - resegmented data attractively
right so you you haven't you have some
segmentation at some stage and you are
algorithm and you generate an hmm with
cluster your bottles and you use they
use the term e to segment to resect the
data then you redo the clustering and so
forth so you intuitively really segment
and read cluster you didn't do anything
like that all just you you found the
speaker boundaries once
and then you simply do the clustering
based on that yeah yeah I knew that you
knew things you do that right now so for
broadcast is that that's that's enough I
mean that's sufficient you don't have
yeah we don't result in broadcast music
okay but still that's in getting results
okay so the development conference so I
will speak about speaker on meeting some
so one of the limits does anybody are
you using it now was it a top yeah
Marseille or Avignon Sonia was the
broken you know do you know who's using
it now so there is some guys IBM so so
new muses that Oh Hamza its I know that
Najim use that and Pacific also use it
especially then based on your initial
speaker change yeah what is best
damaging every get so if speaker you
just be able to change yeah what is the
best achievable yeah I'm like a Oracle
to tell you each step zero I don't know
I do there's a the tester one time but I
never reduce there's a test on zones S
Corp yourself obtains the best
clustering with this segmentation on
focus I see
then results of the additional alright
but it's time for some because there is
some programmers of speech overlapping
yeah and this kind of copies that the
system does not take into account so
there is some program so is it true
question second question is HP so how
effects longtime career can - in country
I'm he's very fast it's more fast and
yeah I would like bottom up by example
for bottom up and I mixed up you must
match you must work it relates the hi
vector and next ah so we find P you just
calculate one time or the a vector and
you do the clustering what package so
even lines written kids it's very fast
time we do some testing for show around
150 hours of shows and it takes wrong
ten minutes I'm not sure about the
there's a time but it's wrong 10 minutes
to solve this kind of program it's very
fast because just just because we remove
any crow show we will remove this
constraint we remove this binary
variable and after we we do not solve
this program like that we try to
surprise the program in an su problem
sub problem son I don't explain that but
so we can I can explain later if you
want
it's the scaling with the number of
clusters so if you have if you double
the number of clusters of additional
segments sorry if you don't double the
segments how does the runtime of the
cluster
I love more because it's very very fast
theoretically speaking is a quadratic or
linear non light sensor and media is not
for the Cheetahs yeah okay because the
number of variables is you can remove
lots of binary variable yeah I'm okay
I'm okay to say that as this matrix if
you are increasing number of speakers no
Morris making segments is brother to TIA
but as you use this formula distance you
can remove a lot of binary variable and
just focus on the banner important
binary by number so I say it's not
butter cheek is more than linear so I
just want to speak about speaker
clustering so one of the program about
hi Viktor Tsoi vector pa pa of 10 very
good results in evaluation campaign but
we know that when I speak in January on
speaker verification and just is just a
lot of you just okay but we observe that
on short segments the performance they
cross rapidly so there is a lot of rod
as I try to tackle this kind of problem
to taking who comes in Burgess curry to
normalize a victor about the rate of the
segment and me I propose to because the
I vectorize
extract from the totally viability space
and me I want to extract the features on
the speakers speaker space so joy trims
the speaker's things so in order to do
that I proposed
learn to excite this feature
presentation with a dip neural network
so I take a deep neural network so the
task of the deep neural network is a
speaker identification task so in the
input this is as the first order for
most statistics so we take a signal we
take new p.m. we calculate the bond
wedge statistic and after we are
normalized by the mean and the
covariance about the Nubian so we give
that in the input of the chief neural
network so the output is the speaker
identification by example if the segment
is the speaker ID 3 we will say 0 0 1 0
so X attack star and after we I propose
in fact true to use one of the iDEN
layer like a new representation so by
example if I say this I turn the eyes
are droopy siltation
so I compact the number of neurons and I
think this isin the earth like a new
representation and I conceive that the
spectrum biddings so just to know that
were so this is the speaker meetings so
for the presentation nobody's become
meetings our vector but was a
presentation so I'm just compact the
vector and we see that some patterns are
in common with different this is the
train and test the corpuscle and we see
that I used some a pattern similar
between the training test corpus just
for information so one of my goal is to
replace hi vector by speak on by vinegar
in the high-back table JJ pipeline so
one of the programs that the speak on
buildings is reached without any gosh
cream absorption and there's yeah there
is a problem because the pIJ assume that
also that I must be Gaussian so we
observe that so every color rupees on
two speakers so I take four speakers and
every signals every plants or presenta
segments and he observed that there is a
roger distribution of the data so it's
clear that this course in scoring also
question scores question scoring sorry
focus only on the direction proximity so
the question let's adapt to this kind of
task but I try techniques of these
techniques is was using speaker
verification it's a lightweight unik
normalization in fact I think it
consists to artificial question is the
data I know that who removed the Mena
and to multiply by the whitening of the
matrix so for the experiments so I use
the same background ringing data set
like the previous experiments but I use
a looser data set is it up 2012 I use
the same ubm the vector of dimension one
no its mistakes is true on rod but speak
on buildings of dimension and rather I
write back to ah I like mine to me with
two iterations become the dealings with
with one interracial for the spicata
ization we use the same to cater for the
GN n which we use the cattitude heater
the activation function are ready and we
use the three either layer so so first I
just want to compare so I think that is
the same here I indicate the different
show and this is over overall of
test the data say so in the first
experiments I just compared a victory
idea we speak of a discussion and we
observe that there is a game and after I
just try to normalize the speaker
meeting with the light whitening
normalization and I use this speaker
meetings normalized with PDA so I say
the same result so if I use the speaker
meetings with no normalization and PLGA
we obtained was result so if we use
become meetings with one lightining
iteration we obtain a new game and with
twitter interaction doesn't work it's
different from the previous last night i
used and in this like that i use ing n
matrix so there's no assumption yeah
yeah I thought nominees so for the
confusion perspective so for the LP
clustering so one of the confusion is
that yet because doing explore more
trusting solutions that grid yeah but a
map a droid so when I was in West
Virginia the systems at that develop
with IP as participate to the atop 2012
and the warfare 2012 and 2013 evaluation
campaign and we obtained the best
results in single and for show
and one of my perspective with the E&amp;amp;P
clustering is to make a joint model or
we speak out clustering and speaker
identification by joint mother I say
when by example if you are just doing it
so you you make only notification in
order to know the name of the guy so you
can do that you know jointly at the same
time and maybe we can do that obviously
yet big clustering so for the speaker
meeting so so if you like I extract on
speaker space and I don't present the
works but we we try to to test with
automatic speech recognition by example
when we try the acoustic model so we
retrain psychoses models and we also
added so I vector and so we remove the I
electron will use the speaker envisions
and she works better and the a vector
and we try to use become meetings in the
speaker intensification past and it
works more than speaker in more than a
vector and it works also the word with
specialization task one of my
perspective investigates the use of
different input input vectors so we can
by example I use the input of general a
vector by gemini vector i just say that
i use the posterior probabilities of the
jail given given by the journal and use
this input vector in the journal and
another perspective is true to create a
journal or to automatically learn the
input vector and one of the approach is
to use this combination and know under
for next classification thank you
questions so in the eye okay so you see
how it's a few high parameters this room
I think will I assume we'll kind of
empirically said how many clutch you
know will favor some number of clusters
I guess the question is is there a way
in the framework to incorporate prior
knowledge this way without having to
reach an ally program design deficit so
freaking so for example but let's say
you have some collection of data where
you know that you know the typical
number of speakers is clusters you
should have is between five and fifteen
there's another data set words between
one and five but you don't want to have
each time you don't have to go read
retune although you don't have a free
time you have a kids like that you don't
have to have a deficit and hyper to
novel forever something yeah so this
area of you know if you have a
generative model approach like
clustering you know maybe there may be a
way to put prior kind of in is there
something like that so I'm not sure to
understand your question so you are
something that sent me four one two five
speaker and also data set for ten to
fifteen speakers and you want to adapt
your systems to get the best performance
on one set you have one set of high
performers yeah different different but
you don't you don't have to do that
every time
if you please a number of Christa you
can have that user continues a constant
of the program you can say okay for this
kind of program there is between one to
five cluster and so you can add as this
kind of constraints in the yet but from
the threshold that you learn
for me this threshold is in fact
represents as the distance of an average
of a speaker so so so I say so for me
it's optimal to to what kind of cop is
you you you want yeah yeah I mean of
office of the speaker in fact so do you
observe that your tests you have maybe
you have ten different roles right
did you optimize that for every show
yeah yeah in fact on the show as this
kind of show it's very different because
it's a show of pop stuff and it's
explained what we obtained very bad
results and in fact I tried to optimize
my threshold on all the corpus without
this and the opposite but in fact the
threshold is what but you can use the
same so I take holds the corpus and
applies the same thresholds on all the
compressed so right so so it's not a
register why is that one so much worse
segmentation because there's a lot of
music so much is five minutes a lot of
music and is very it's not usually like
there's a lot of back and forth between
yeah yeah short short turns
yeah this goes back to the question with
this work I like
yeah now you have a lot shorter turns
and you don't have as you know segments
that are long enough to estimate stable
by vectors
culture and you know
I removed is the best law in my computer
so I can show users but we had so it's
very short
a lot of music so in fact 0 are given by
0 segmentation segmentation is very bad
because it's a segmentation you say that
there is a segment but with lot of
speakers and sometimes there is a signal
and also which we have some program
gives a speech and all speech is they
say ok there is a non speech but there
are speaker speak and so on a different
topic this is a very general way of
doing flustering the ILP inside the Hat
and I think a lot of us have so had what
else have people been clustering with
ILP what then so is this the first
application of ILP the clustering yeah I
have has it been used like to cluster
documents previously are used no no I
don't seems that we are using documents
so yeah I tried this kind of approach
and it's never been used and also fins
it's never used in other fields so yes
it's unreal speed organization ok so
that's real innovation and when have you
seen it sense apply to other areas or do
you think of would be applicable other
areas I mean if it seems like anything
that you can currently say use k-means
clustering we could use this I thought
convinced might much better than this
one in many cases
so when I saw I explained the repair and
when I do the propagation of the
identity I use IP in order to provide to
propagate ecology identity and this
based on my NP clustering so we can
induce and we can not play I apply your
moods of tasks like I don't know I can
be gentle invitation but it enable quite
a distance to distance it but it just h
HD is essentially k-means know what
concentration across emerging step no
it's a it's a highlight closely it's a
pretty funky needs because he's bring
because you don't know the number but
you just weren't you don't need terrain
but you look to only well that's was the
end because immunity you know see
tonight for you or knowing when to stop
country what is what is the Cris bonding
whatsoever in your sister right
so the the property the the general
problem in a hierarchical clustering is
knowing when to stop clustering yeah but
when do you know you have the right
number of clusters which of course is
somehow related to the number of two
speakers in case of finalization so in
your in your system it would i appear
what is the corresponding parameter what
what how do you control how aggressively
you you want to cluster things together
the goal or the deputy on your right
that's okay there's the physically
oppress that we have forever yes you do
is talk about before
the third thing just use out
I'd say adult has to rule out to
eliminate eliminate you're just you you
are stepped up already
but you can start but you can innate all
the urban area but and you eliminate -
better so you you you you must to
control a parameter and you can trust
the last person with cells and you have
a separate you had a separate data set
those yeah yes the development set to
change this tester have you have you
tried to read optimize it so how far
from the optimal value where you when
you have to do YouTube those browsers
this find out so far for the true
copious wrote down adopem in fact years
if I met up on the test and that focus
are is that Jesus name really but maybe
in like English podcast or something see
the same parameters of course yeah so
this is this criterion is minimize right
what do you mean wise is a very generic
criterion I think it's very similar to
all the other cluster of approaches
right that's just number of clusters
plus some distance thingy so your method
is not about the criterion but it's
about finding the correct solution or
it's an optimization problem in solving
or is it the tortilla object usually a
good result good question for me it's to
optimize up
I won't optimize this such and
just to say that to try to say that a
segment to like to try to move the
speaker mother to say that okay oh yeah
buzzes because it is the same my
question is the same criterion the first
formula you could also optimize that
with k-means for example right I think
yeah yeah we can do that but there's a
problem of installation of of the came
in son and this is a problem and that I
mean so and I run several times so the
gaminess I'm gonna change from physics
but with yet we have journalists each
time the same reasons we actually did
that yeah and after I tried to different
objective function I try to minimize
communities and fantastic special and to
maximize special I defined objective
functions that try to maximize the
number of speaker and to minimize
dispersal and cyclists but the best
results are obtained gives this kind of
approach also I think that finally same
criterion for a chase we can but so let
me speak with another boy it so if we
think about decision one time this
project
so what you're saying your solution
really is search algorithm that's what
you are solving you have the best way of
solving the same equation is it the same
for you
so can you say a little bit more about
this when you about anything in
particular about the cross show yeah
I've done just treating to show this is
one big meat broadcast or one than the
other
yeah yeah so it's a magician that side
so in Seger show you you trace the
problem like that and I can explain my
previous like that I mean for sure you
take this is to show a so it should be
and in fact you want to detect the rec
room speaker by example if you treat a
show and be separately you can say that
you cannot detect that this speaker and
the speaker the same but you by example
can detect that this speaker and this
because the same like that but how not
the same speaker I guess it just means
the same label okay
the devil speaker 1 yeah so you say that
but so in croushore you steps of four
steps it's a crystal but a globe a
crystal on RZ show so you treat Zeus a
party and after you have four steps
robot clustering the threads all through
all the data and now you can detect the
Rick Rome sweet Rome and say that this
speaker and this week are not the same
we try to do that sorry so when you do
the cross show clustering yeah
with I appeal you reconsider identity is
within the same show so we try the
experiment with crystal yeah and we try
to reorganize
and in fact to not to fix but to
organize works better because I think
that in the first Christine we miss some
so by the way the explanation why you
have this video the rate the radial
distribution of the vector I know I
don't know why nutrition for it you show
the picture so this is a resolution of
sweet on ladies so I've seen a little
before geoff hinton gave it out you know
this is not some he's me some years ago
and said it was like showing word
embeddings or documenting their names
and he made a big deal about all of
innocence it's radio I don't know why
his range of distribution but we
ourselves us
so in fact first Expendables was to know
if it's pecan meetings what was goin or
not and at the end we observe that this
is right your distribution and we don't
know why this is what the dispersion of
speaker meetings yeah yeah so it's we
take for speaker Romney for speaker or
the segment and we use a PCA to to
project any 2d motion just to
incorporate some kind of life
normalization directly
the objective function of the positive
neural network yeah yeah maybe also that
the length is has to do with the length
of the segment and how far you are from
the center in that is related to rhythm
tonight but my name became at an
organization between Cydonia
I know because the impetus didn't for
this length variance right so we didn't
put to your network it's a it's the are
the powerhouse statistics there's a
please the old effective statistics okay
is exactly the same yeah so much because
it basically is Y Z converge to the same
point
you have a point but there's going to be
some physical correlates to the distance
from this origin point zero yeah I must
who on skates
too many nations</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>