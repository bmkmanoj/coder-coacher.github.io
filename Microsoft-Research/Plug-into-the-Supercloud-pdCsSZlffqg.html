<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Plug into the Supercloud | Coder Coacher - Coaching Coders</title><meta content="Plug into the Supercloud - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Plug into the Supercloud</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pdCsSZlffqg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
court
start it's my pleasure to introduce
Hakim Weatherspoon a Hakim is an
associate professor at Cornell where his
research focuses on performance security
and reliability in network systems
before that he did his PhD at UC
Berkeley where he led the ocean stored
project I'm very happy to say that he'll
be spending the next year on his
sabbatical hidden key bridge so he'll be
for six months at the lab here and at
six months at the university of
cambridge today he'll be telling us
about his work on super clouds so
welcome and ho to you great thank you so
this is kind of an introduction to to me
so I'm here for a year like gitesh said
i'll be visiting researcher here and
then also visiting scholar at university
of cambridge so you know please feel
free to contact me for just to talk or
different things to potentially
collaborate on so this is one of the
projects that that I've done part of my
research agenda that's fairly exciting
so this is plugged into the super cloud
in my context that I guess I last thing
about that is that I'm associate
professor so I had to change the slide
used to say assistant so that was pretty
exciting you know after six or seven
years of grueling work it pays off and
so you get tenure so I'm here on
sabbatical so that's pretty exciting so
anyway so this also joint work with
Robert Barron sa who is a colleague at
Cornell and also our students qing jia
wei jia song and Ziming shen so the
super cloud what is it so we'll start
out it's a infrastructure-as-a-service
cloud so this is you know some sense
bare-bones you're given a raw server
abstraction or raw machine and storage
or whatnot you're charged not only per
hour for something like amazon and
whatnot and then a lot of cloud
providers have multiple data centers all
over the world and so here you see the
bottom there's listed a lot of cloud
providers that often have a
infrastructure as a service
abstraction okay and in Google actually
is a little bit late to the game but
they're coming on pretty strong and so
one issue though is that as soon as you
start using a specific cloud then you
can get locked into their features they
may have certain features that give you
performance boost or maybe they start
out cheaper than some other service or
whatever the reason may be you start
using one cloud provider and then it
becomes fairly difficult to move to some
other cloud providers so perhaps your
netflix for example and you're running
on top of amazon and you have 6 to 10
petabytes of storage it's prohibitive to
move that amount of storage from one
provider to another at least not for any
reasonable amount of time and once
you're locked into a specific cloud then
you lose some ability to take advantage
of other clouds who may have a lower
price I'll actually show later on this
talk that they're also maybe some other
advantages such as one one provider is
not does not cover the entire world so
you may actually be able to have better
performance by being able to use
multiple providers and also if you can
have multiple friars you can actually
increase your security and control or
whatnot and increase availability so by
being locked into one provider you
actually lose out on some performance
and perhaps lose out on some cost so we
just talked about that if you have the
ability to use multiple clouds then you
can reduce your cost you can potentially
reduce the latency to the end client you
can potentially have higher availability
for your service you can if you have a
hybrid cloud you can burst from your
local private cloud to the public cloud
you can even eat increased security and
what I mean by that is control I as a
user can now control which provider I'm
using and so you can increase the
security from that perspective so
there's quite a few benefits
of having the ability to use multiple
cloud interchangeably now there's some
difficulty if you want to actually do
that i forgot to say that if anybody has
any questions as we go on you know feel
free to go ahead and raise your hand and
ask and we could have more of a
conversation but so in case there's some
difficulty if you want to actually use
multiple clouds number one there's not
actually uniform image format there's a
you know different types of virtual
machine hypervisor formats there's
different features and whatnot that make
it difficult there's no standard that
would allow you to migrate from cloud to
cloud be so you need some way to massage
that and then how do you actually scale
across clouds anyways there's a cost you
know migrating bytes so for some stores
often you're charged per request and per
byte going in and out of the cloud so
how do you actually balance all that how
to even enable that to begin with and
this shows some examples Amazon uses
cavies excuse me HP Cloud uses kvm and
as ur here would use hyper-v so these
are different formats that we would need
to somehow use a few years back my my
research group with the student Dan
Williams and in collaboration with IBM
honey jams room created a solution that
would enable a multi multi cloud
deployment now what's called Zen blanket
it's so the way that zenworks is
actually nested virtualization kind of
like turtles done in IBM or IBM done 40
years ago nest reverse relations is not
actually knew but the difference here is
that you have some different excuse me
some different hypervisors for different
first layer providers and they're quite
different so the key here is that I
can't touch your control those so
there's I'm going to put a dotted line
here so there's a dotted line here the
provider controls those I can't do
anything about that ok can't modify that
at all and so but what i can do is i can
start up my
instance I can start my virtual machine
or guest instance and normally what you
would do is you would start operating
system you start windows you would start
Linux you start some operating system
within your guest so instead of doing
that was then blanket does is we start a
another hypervisor so this like I said
this is nested virtualization and the
way that this works is that we have what
we call blanket drivers that essentially
enable us to massage I oh so that it
works on top of Zen or kvm or hyper-v or
VMware or whatever the underlying system
may be okay so we have some I oh that is
here in this domain 0 this
administrative domain and so everything
goes through that and so that's how
we're able to actually create kind of
this little shim layer and have it work
on top of different underlying
hypervisors so now when a key takeaways
here is that we as the user control
everything in this guess for you so we
as a user control the the hypervisor and
all the i/o goes through the hypervisor
so we as a user now control the i/o for
storage the i/o for networking and
whatnot is so we can actually create and
control layer to do layer it was called
layer 3 and layer 2 capsulation okay and
so that we can start up second layer
virtual machines instances and now we
can control the second layer virtual
machine insists so within those you
would then start linux or windows
whatnot and since we control all the i/o
we can move all the virtual machines the
vm pages for one instance to some other
physical machine okay so that's how
essentially how we're going to Nabal
migration from one provider to another
is we control everything within this
instance and so we can move
everything that's encapsulated in this
container if you will somewhere else
okay so this is in essence how we're
going to get this super cloud to work
and not only that but we can make on top
of this within this abstraction we can
make everything look uniform so we now
can get this to run on top of Amazon we
can get it to run on top of HP we can
get it to run on top of Google on sir
VMware and everything looks like it's
said like a Zen environment okay so it's
a very uniform homogenous environment
you as a user control everything on top
but you as a user don't actually control
the underlying hypervisor she don't need
to do that the extended for things and
containers ah so this is a former
container but you're talking like docker
type of containers and what you more
like it's more like naked yeah so yeah
so so you know asks does this have to be
extended for containers so the key is
that this is an
infrastructure-as-a-service abstraction
so you're given the ramen so if you have
Linux containers or whatnot you would
just start a linux OS in there and then
you'd have Linux containers so you know
this is a in some sense this is the
lowest level you have raw computing ross
storage rafael and you can build up
everything from there so you can build
up a platform as a service and their
services service and all these buzzwords
that you here with this abstraction okay
any other question before we move on
drinking w ah theoretically yes so
theoretically you could do this and this
is what turtle showed is that's why I
was called turtles is you know what's
holding up the universe a turtle is
holding up a turtle and it was Turtles
all the way down so theoretically yes in
practice no not right now
so with the extended page tables and
whatnot there's only so many levels that
you can do that so there are certain
things and decisions that we have made
as well that limit multiple nestings so
in theory yes you should be able to do
that in practice it's not so easy and we
haven't tried doing three times but you
could imagine you may want you
especially if you have a super cloud
service so now I have some service as
opposed to a library and you know now
somebody may want to do it again for
some reason that now a sudden you may
want to have a third nesting so just to
I'm kind of interested in ah how much of
this is kind of device from for specific
if it is the Enlightenment specific or
and this kind of homely addresses the
difference in hypervisors between the
climate doesn't get with all the
difference but in other aspects between
yeah awesome so let me answer both those
questions it turned out to be mostly you
know the i/o so the difference in how
you whether you have you know full
virtualization and paravirtualization
you know so if you have idealized
drivers or not it turns out that that
was one of the biggest difference to get
this to work now as far as some of the
other aspects you know some of the
storage and whatnot I'll get to that and
networking um you know so to actually
have a service work there's more than
just the instance containers I don't
talk to that that in a second only you'd
have an operating system which the
supports and don't you know how to test
drivers for thats a number of different
network cards or something yeah you a
standard image and it's not clear that
you can't just create a standard image
that works that has device drivers for
the various virtualized Nix that you'd
expect across Europe provider is right
and you just have one operating system
is that where its own this is just
multiple people sorts of DC but i think
that with with linux containers or
whatnot is similar to what you're
talking about so you could just have I
mean in some sense the hypervisor just
the operating system anyways this is a
little bit lower level abstraction so it
makes a little bit less associates in
some sense you know you're just
subtracting that instruction set
architecture as opposed to the ABI the
system calls and whatnot the operating
system but you could get that to work
but now you know going back to the bus
words that's a little bit higher level
so maybe more of a platform as a service
which you could get to work and you
could get that know if I have a silver
type of linux OS and containers running
on amazon and aser then i could migrate
my processes between the two you know
historically via migration is a little
bit easier than process migration but if
it's all in the same container and
abstraction sure you get that to work as
well and there's been SSP papers
recently that show that that actually is
more efficient the more that you assume
this actually is a bit heavy weight but
it's a little bit more transparent as
well what's the what cost it so the the
performance cost so there's a euro
sister talks about that in detail and in
general the performance overhead for the
CPU bound then you know essentially meal
but a lot of the aisle bound if it was
networking or storage for some of the
best brunch iran was about five to ten
percent in fact that was the whole thing
that took us some number of months was
how do you actually know avoid TLB
flushes and avoid some other things that
were making the performance 100x so we
started out got it to work it was 100 x
slower so then we got it down to 10 x
lower ten percent and then five percent
slower so it is it is some overhead but
for some of the gains we we think that
no it would be a benefit for a lot of
different applications did you have a
question
that will more about the performance
other than what the opportunity and that
I will serve in that second question was
a but basically i was a bit confused
about your option to them question about
docker containers if you have duck your
containers way would you need them
blanquita don't know as I guess the
question is you wouldn't necessarily
need that blanket if you had no
containers like doctor and whatnot you
could just stay with an abstraction this
is what I was saying is a little bit
lower level abstraction so now instead
of having to work with linux containers
or work within docker whatnot you're
just given a raw machine image you can
put whatever OS you want on top of that
and then you can migrate that you know
hole somewhere else so this is a little
bit more course in some sense than the
net okay so let's go on a little bit in
terms of performance I won't talk too
much more about the low level
performance but you know if you have
more questions we can get into that I'll
talk a little bit more now about the
applications so what this actually
enables ok so the key here is that this
is a picture to show on the droste
effects so I Robert meron sa is from the
Netherlands and this is some candy some
sugar some from the Netherlands I guess
and this shows the droste effect which
is recursive so you see this none in
this picture is will so this is a image
of some type of recursion okay which is
essentially what we have going on here
so with the super cloud then is now that
we control the second layer we can start
OpenStack so now we have our own cloud
we have our own infrastructure as a
service we don't own any of the
underlying infrastructure but we have
some virtual infrastructure that we
control so we can now have OpenStack
that can control those second layer
instances we can have you know Sdn so
open V switch and we can control the
network and then we'll talk about
storage as well so a key now is that I
can have my
own stack here in Amazon and here in HP
Cloud and here in rackspace and I can
now have OpenStack control all of these
red second layer instances okay and I
can then also have open V switch and my
own sdn network and I can move I can
move an instance from one provider to
another and I can maintain its own the
same internal IP address to have an
issue with external IP addresses but as
far as the internal topology of my super
cloud my own cloud I can maintain all
the the same exact apologies i move
things around physically okay and so
this this actually is quite a bit more
that I've added so I have my own cloud
that I can control now so this is guess
to some of your issues which is there's
quite a bit more than just the virtual
machine instance abstraction there's
also how do you actually managed to
maintain those and there's also the
network okay so yes why did he choose to
use sense of it as your second game
hypervisor and not any other yeah I
don't have a real good answer for that
it was open source we could have done
kvm we are just a little bit more used
to Zen but you could add of a kvm
blanket could have a you know hyper-v
blanket in some sense we happen to
choose Zeb because we were more used to
that at the time you know so it wasn't
I'll have to think about a much better
answer than that in the future but other
than that it was really just that was
the one that we were used to at the time
and so I so we have hyper-v running
which means that we can now control the
topology we have our own virtual switch
within a physical node and we have you
know gateways between that can create
tunnels between different different
clouds and what nine so we can actually
my
great and maintain connections between
different cloud providers okay maintain
the same network topology we also have a
storage abstraction where we have a
distraction of a globally consistent
image store so this for images and we
have an NFS NFS is that's right so
sometimes I can feel with the National
Science Foundation the NFS so network
file system and I scuzzy abstraction to
this this global store and since all the
i/o goes through our second layer domain
0 we can actually then be migrated
blocks proactively or reactively
depending on where images and where it's
migrated and whatnot so this is we've
created this and made it quite a bit
more efficient than some of the more
coarse ways that you may do this so we
have now storage we have networking we
have a management layer on top of our
own cloud and what we don't have is any
underlying infrastructure don't have a
data center you know don't have to own
any of the actual network pipes or any
of the actual disks no for that matter
so we have our own cloud but it's
virtual okay so now what does this by
you I have my own virtual cloud it works
on top of multiple clouds it's a super
cloud as we call it all right so let's
go through some of these examples that
we talked about to begin with can we
actually lower latency to end clients if
so here's a map of the world and a bunch
of data centers from different cloud
providers amazon and rackspace and HP
what not the sole old world I don't have
as Iran this because it doesn't work on
top of hyper-v yet we're working on that
so hopefully we'll get that to work soon
and so the key here is that if you're
here in England and then you move to
know Ireland or whatnot then Rackspace
doesn't have a
80 center in ireland by amazon does and
so if i move to ireland and i can
actually have a lower latency you know
if i can actually move my service from
one provider to to another okay so this
actually shows that this shows on the
x-axis different clients so I have
clients in Washington in the US or UC
San Diego in the US over here is Hong
Kong and China and whatnot this is the
UK right there so I have clients all
over the world this is planet lab and
then I'm going to sexually going to find
the the lowest latency to a data center
within a provider so these bars right
here are the low latency from this
Washington DC node to a data center
within Rackspace ok so the lowest
latency is about 50 milliseconds okay
and and Massachusetts a little bit lower
so they must have a data center close to
Boston or whatnot and in amazon i can
plot the same thing so there's actually
a data center within or close to DC and
virginia and whatnot and so it's a lower
latency from this watch to know to the
closest data center within amazon okay
and then these artists same things all
over the world and then we have here HP
so this is the lowest latency to HP data
center so that then the the key takeaway
from here is that now if i have the
super cloud I can match that lowest
latency to a data center from any one of
these clients so for example i have here
that within I think that's UNC so North
Carolina so super cloud matches the
Amazon latency which is the lowest from
that planet lab node to the closest data
center of any one of these three okay as
HPS so HP doesn't have enough data
centers for yes you're right uh I don't
yet except for in Hong Kong so if you're
in Hong Kong then HP is a right answer
all right I was looking Rackspace sorry
yeah no you're right that'd be maybe the
closest so HP is and the map earlier
does not have that many data centers so
performance would not be the reason that
you would go to HP by any case here in
China then racks them so super cloud
matches Rackspace with the lowest
latency okay uh this one yeah so there
we are we do have a second layer so
there is some overhead so within that
standard deviation but that that mean is
a little bi yeah and I'm not sure
exactly why except step just that the
you know the second layer has some
performance consequence okay so that's
one example another example we call
follow the Sun so follow the Sun you
have some replicated so with the
follower sudden that just means that as
the sudden moves people wake up and they
start using cloud services and so the
load increases wherever the Sun is ok
and so the service now that i'm going to
assume is zookeeper so within zookeeper
it maintains consistency over
replication some replicated service so
the way you do that is essentially
you're going to have a majority of your
maintain decorum and so was do keeper
than you would write in this example to
at least two out of the three for a
right and perhaps you would read from
two out of three as well just to make
sure that there is some intersection
with the most recent update okay and
then you're also going to order the
updates with some master node so this is
just a very very high level of zookeeper
and so the key now is if all of my
clients are in the US then their
performance that they're going to
receive from the zookeeper service is
going to be pretty good there's a quorum
majority of the replicas within the US
so the latency is going to be quite low
but as the day goes on and the people in
the u.s. go to sleep and people in Asia
wake up if the majority stays in the US
the majority of replicas for zookeeper
then the clients in Asia are going to
have a very bad performance you know
it's going to be a very high latency to
to write or read to a quorum okay and so
what you would like to do using a super
cloud is you would like to migrate that
master to where most of the load is ok
so we can follow the Sun we can migrate
to wear that high Lotus and notice also
i migrated from here it was amazon and
here it's Rackspace so i migrated that
master to not only a different part of
the world but a different provider
entirely and i did so transparently
without changing anything about
zookeeper so as far as zookeeper is
concerned nothing changed but as far as
the clients are concerned the
performance is a whole lot better ok and
so we did that and this graph here shows
the example where we didn't migrate the
master the x-axis shows this is a CDF so
the X actually shows the the latency for
I read and black and a right in red for
the u.s. clients and there's blue and
green here for the Asian clients and
this is log scale so it was just a
couple of milliseconds to read and write
for our us clients and it was you know
well over a hundred milliseconds to read
and write for the Asian clients this is
when the quorum was in the US ok if I
now do the migration using a super cloud
like it just showed you then now for our
asian and and us clients know the there
was actually a shift so when we ran this
experiment there's a shift in load based
on the time of day then eighty percent
you know the clients actually received
very good performance just a few
milliseconds and then if you happen to
read or write why the quorum was on the
other side of the planet then about
twenty percent or so received no very
low or very high latency so this sense
shows that we're able to follow the Sun
very transparently we're able to
maintain a high performance and were
able to do so utilizing multiple clouds
so this shows the one of the benefits of
using multiple clouds okay now what
about coughs so when the whole reason
that you'd move to the cloud to begin
with is cost you know you don't want to
maintain your own clouds perhaps you kid
you only buy what you need so the ala
carte you know is advantageous for you
amazon has created what they call the
spot market so the spot market is nice
because if you have underutilized
resources they'll actually price those
instances spot instances fairly cheaply
ok now the consequence though is that
the price can actually go high often if
load increases in that area if they want
to move people out of that area each
available ozone will have their own spot
market they also can terminate your
instance at any time so for that reason
you know prices can jump real high and
you can maintain a maximum price bit or
whatnot and also for the most part your
job should be stateless since you can be
terminated at any time there is a
warning but it's only a couple minute
warning that should be terminated okay
so this is only useful for a you know
certain set of tasks whatnot and so if i
now use a super cloud what i can do is i
can take that warning i can migrate
before being terminated so i can
maintain higher availability and
I can also migrated to the cheapest
market okay so each hour I can evaluate
I can look at all the availability zones
and I can migrate to the cheapest one
and if there is none that are cheap I
can then migrate to a regular instance
that's always there it's always
available so I can maintain a much
higher availability service using this
and I can maintain it at the cheapest
price okay so those soda benefits there
so this then shows a couple examples of
what i was talking about this is a
week-long trace of prices the yellow
here are regular on-demand instances and
they're always the same price in this
example 35 cents an hour and then we
have different availability zones here
and then you can see here that often
they're fairly cheap oh you know a
couple cents per hour but every once
awhile they can actually jump in price
significantly so this is a couple
dollars per hour and that's essentially
they want you off that spot instance in
that availability zone and so with the
black here with the spot with the super
cloud or this smart spot market we can
always maintain the lowest price
possible and if there's no single market
with a low price like over here then we
can jump to a regular instance okay so
in this case we're always maintaining
lowest price and then over this week
this black here shows the total amount
of money we spent over the week and
compared to one availability zone this
what is this this a u.s. East
availability zone 1 e is many factors
cheaper than that and if you are lucky
enough to be on this one a then it's a
couple times cheaper net but the key
here is that super cloud is always the
cheapest and often many factors many
multiple times cheaper than any other
option and you get that all
for free ok we're looking this a little
bit more so if you're actually to
migrate between different providers
there's costs that you have to take into
consideration whether it's actually
advantageous to migrate or not we've
looked at that a little bit more and it
turns out most of the time you would end
up not migrating to some other provider
if so we're starting to look at
different games to where it would
actually make sense to migrate to
different providers or not but at least
within amazon you can migrate to
different availability zones it
maintained a lower price on the
assumption that you have a small number
of very precious VMs if you want to be
able to move to wherever the use
arbitrage to move to whatever its
cheapest to currently run those VMs I
fear so small number of precious long
running some realistic I mean any large
provider take a usenet what's called
Netflix at one point is your example
right let me Netflix is going to have
has in fact and as your optimized
service that runs an insurer plus and
Allison optimized service runs a
talisman right and the way they do their
arbitrage is by choosing are many
instances they spin up in different
places and just by the load as well
right they don't want to pay a five
percent overhead able to move one of
their instances between azurin amazon
right so I I guess yes no so you have to
so there is some calculus and they they
have optimized senses like you said in
both providers but you know how much
state if anything you would actually
need to migrate one thing about Netflix
is you know their state doesn't actually
change that often you know once they
encode a video into 100 different
formats whatnot it pretty much stays
there if you have something that is a
little bit more dynamic if you know is
it worth it to actually migrate your two
to 10 gigabyte vm somewhere else and you
know we actually are able to do the math
fairly easily
you see the cost for that new our you
see the cost actually my great would
that be cheaper at all for you know like
you said just some small number of
instances if I had a much larger
ensemble we're starting to look at this
now I don't have any results here then
the calculus is a little bit different
you know if I had you know hundreds of
machines and I want to maintain the
lowest price and best performance
possible for that ensemble then what
strategy makes the most sense so I guess
the key here is this is a mechanism and
you can now start to play with a
strategy not really said anything about
strategy except the most simplest thing
possible attached should you have a
question okay so so this is we will say
an enabler and you know we would like to
start to look at strategy and games more
in depth but you can save money so we
also talked I won't go too much into
this but you can also burst from private
cloud to public cloud pretty easily
maintain all the same network
connections and whatnot there's also
service other services for this as well
but going a little bit more to what
you're saying if you have the cloud
watch or some of these other services
you can add and remove instances based
on load one of the things about the
super cloud is you actually can maintain
the same number of instances but add or
remove let me say it again you can
maintain the same number of second layer
instances but you can add or remove
first layer instances based on load so
now I don't actually have to change my
service at all but I can actually adjust
my cost and I can do so automatically so
what this shows that is I have three
first layer instances and i have 3 2nd
layer instances and the load is high and
when a load is low
I now migrated so that I have one first
layer instance and i have 3 2nd layer
instances so my service hasn't changed
at all but the underlying number of
physical machines if you will has
changed and so as a result my cost to
maintaining that service has changed but
I didn't have to change the service at
all so this so designing for this we
argue then is a little bit easier than
using something like cloud watch or
whatnot they would actually increase and
decrease the number of servers that you
would have ok so this then shows right
here if I had three first layer instance
all the time and this is some type of
web traffic then as the web traffic
increases I'm able to handle that but
here you know I'm wasting a lot of money
because i didn't need three instances
and here if I had one it's just that
entire time then I wouldn't be able to
handle all the load that the service
would need to handle and down here the
blue line is the second number of second
layer instances and the black is the
number request I'm able to dynamically
scale the number of first layer
instances so that I can handle the
request and I can scale that up and down
ok so this then I'll you know the super
cloud enables that because I'm able to
migrate those second layer instances to
essentially use one underlying physical
machine and then I can spread that out
as necessary you also have actually
scaring off right you can always decide
whether to get a larger vm or get a
medium-sized view more small vm so how
do you make that yes so gay this is
mechanism we're starting to look at you
know one and how would you go to a
larger vm we have start to look at that
you know because it is a little bit
cheaper economical to have a larger vm
with more larger underlying vm with more
second layer instances packed within
those
but I don't have you know this is policy
and strategy and I don't have anything
concrete to say about that this time but
that's a very good question okay so but
this is you know another thing that is
enabled though is start to play with
those strategies so in case the key here
is that with the super cloud we can now
maintain our own cloud it's our own
infrastructure service some of the
things that we've been doing recently is
looking at demonstration cases and
examples to actually work across
different clouds and play with those
examples we're starting now to then do
the next thing which is some of the
strategies where that actually makes
sense so some of the scheduling and
placement and strategies we're working
now to get this on hyper-v this says
that VMware so we actually just recently
got to work on VMware a couple weeks ago
and now we're we're working on getting
it to work on hyper-v and we're all
starting to look at some of the security
implications as well and so the the key
here then is that there are some number
of papers that have led up to where we
are now starting really almost in 2010
there was a storage paper that I wrote
racks which is redundant array of cloud
storage essentially rate over the cloud
the entire agenda here is trying to
prevent vendor lock-in to allow you to
utilise multiple different cloud
providers interchangeably and to make
them more into a commodity really and to
do so today so if there's a standard
that comes about that'd be great but as
of right now everything that I just
shows you works today and there's no
agreed-upon standard okay and then
there's some other work and the code
actually is available so you could
download it and play with it we've had a
class do that and we've also has some
undergrads over the summer do that as
well so kind of guinea pig and you know
test things out for us okay so if you
have any other questions you can feel
email me and follow up I'll be here for
another six months or so yes absolutely
what I would like though so no as a
professor watch what I would like
ideally is a student to do that and then
i kind of right there their coattails so
do i want to actually spend the time
it's a significant amount of time and
effort if anybody's ever done that my
brother's done that i started out with
him i'll tell you a quick story i was a
PhD student i was married and had a son
and we started this company together and
then we had this heart-to-heart
conversation he was saying that you
can't do half of this and half of that
and half acid so he said either you're
in or you're out so I said let me go
talk to my wife so I talked to her and I
said do you want to leave berkeley and
go up to Portland and liat live in my
brothers garage you know until we can
get this thing up and going she just
about knocked me to the ground no way so
I told so I caught called him back and
said that know that I'm out so I would
like to be able to do that but you know
you have to be fairly serious about it
so as right now everything that we've
done you know is open source so there
have been some ravello or I think what
not some similar type of companies but i
think that is still no open game that
you know something like this could be
commercialized and i am interested but I
haven't you know I haven't committed in
that direction what you're doing I think
instance it's technically convincing but
I think it's fairly simple until the
caliper by this until you have so many
uses and you commercializes and the
cloud providers decide whether they they
do something to keep the knocking I once
it becomes kind of a cat and mouse game
without providers make it more difficult
for you to what you're doing then yeah I
mean in some sense they already are
because you know of them have like a
Hadoop service or whatnot so that's what
you're doing then that could actually
already lock you into provider so
there's already today there's a lot of
feature and then you need to somehow
as user not you know take advantage
those or somehow code that into your
your service so isn't know right now
they're not worried about us at all and
I've given a talk at amazon say again
they could do to make your job harder ah
to make it hard I'm not allowed to build
a super cow selected tween pleased
overhead if they change what they're
doing in some way you know what I mean I
suppose so I mean we do have some
trouble so I don't know if they're
explicitly making it harder for us but
implicitly they make it harder so that
we're having a little bit of trouble
with the Google compute engine it uses
kbm but I think that it may actually run
with inside their containers and so you
know we're having trouble there they
didn't do that because of us you know
their infrastructure was already running
that way so there's some things
implicitly they already make it hard if
we were or something like this was very
successful how would they react I don't
know am so I given a talk at amazon they
actually seem very excited about it
there you know high-volume dealer they
think that this would actually drive
more people to utilize the clow so if it
could reduce the barrier yeah the
opposite is there any a standardization
efforts so that I could migrate my vm
from one floor to the other without
using the super there are some variation
effort i gave a talk in July at NIST the
National Institute of Standards and
Technology but you know there you know
what is the motivation for some of these
companies to take up those standards so
they're they're developing them storage
wise you know there's a lot of different
storage standards that exists and what
not and if you look at you know Ezer and
Google and Amazon they actually are
compliant with a lot of those those
standards but still to have a service
that and be able to run from one place
to another still non-trivial that
storage is one part about it just like
we talked about networking so how do you
actually get the entire thing to work
for one cloud to another that's
non-trivial how expensive is it to move
your data between these providers and
have like allocations for storage yeah
so you can calculate at least a one-time
cost of moving you know it's your vm and
the working set of data that is touching
and whatever the cost is too you know
bytes per second or whatnot into into
another provider it's like how for what
types like with size and workloads data
sets this might make sense like the
range versus where it just usually
becomes prohibitive so with the spot
market that we've done we got a little
bit further with that and so for most of
those cases it was not actually
advantageous to to migrate to another
provider so with like a 2 gigabyte vm
and a slight change in price it actually
was cheaper to stay within the same
availability zone or same same provider
then migrate to another one it was too
expensive for most of those cases that's
for a single VM now when you start to
look at ensemble of VMs and how they
communicate and whatnot then it may be
different but for a single VM case it
turned out that it was not advantageous
for a lot of cases to migrate between
different providers very smoothly
solution where we don't get you whrs on
exam so you are net even then and at the
next holiday off two balls and without
net forms what what's the header for why
do you actually need the world of
tradition you and such I didn't actually
understand everything so I'll ask you
say one more time and then I'll have to
figure out why do the same except that
you do not dobriy vecher eyes when the
one in your exam you just had on top of
examining doctor I did so monday or
further exam exam pocket and then under
the machines you do the cut us before so
so
the ghost of the body of tradition and
onions and machines so you say that in
some cases you don't do the nest of
personalization and in some queso if I
understood you correctly then if you're
in your own private cloud you actually
don't need the nested virtualization at
all if you're in um you know if you're
in a public cloud it's hard to have that
control that you need without having
that control of the hypervisor so in
that case that kind of forces you into
having nessa virtualization and let's
say give you some hooks so someone
earlier asked you know what could they
do to thwart things well they could do
something else to enable you know they
could actually give you some hooks into
people talking out about that with
networking so hooks within the network
they could give you a hook so that you
could control more and don't need to do
nested personalization and you know you
can do migration already for example
within Rackspace ok good that you've
been able to do this for BMS then neck
looking and the advantage there you had
was that the API is fixed right with the
vm you're pouring in eight cities its
interface with networking first so it is
harder because there is no leader one
epi for other things or the services
like appliance those mailboxes as even
harder and so this is a secret even said
a couple of this a couple of hours or
companies ago that doing it for the
entire status can be tricky because how
do you expect to offer the same epi
across all the services that cloud
providers at an offer because you know
as in a show on ec2 they don't want to
be stuck into the sort of instruction of
the service business deal probably
opening more services I don't know if I
expect after the same API for all the
services all the providers may may have
you know the issues so for example with
Hadoop you could use Amazon's Hadoop
which may have slightly different API or
you could download your own Hadoop and
run it within your own ensemble set of
it
and then that gives you more control and
then you could you know run Hadoop and
different underlying providers but if
you use if you use some service from the
underlying provider then you know if
provider a gives you that service and
provider be doesn't then you have to
either replicate that service or you
could only utilize that service in cloud
a so you know this these are real issues
and we haven't pretended to solve those
but the more features you start to use
dorm or block then you would be beyond
the mechanism and policy is that I guess
what I'm questioning is you lose the
bathroom because the service providers
will if I use the special hope that uses
this fancy feature on amazon improvement
for me I get vendor lock-in and I'm as a
mood without an agile will do that
because you want our customers to pee
yeah I did so one of the things we've
been doing for that exact question is
you know what type of applications would
work across different cloud providers
that make sense and you know success
looking for trying to create the killer
app where this makes sense but if you do
you know like what Netflix does in your
condition for Azure in your condition
for for Amazon then you know you're
going to get much better performance but
not everybody has those many engineers
this netflix does for example so the key
is you know it is kind of a trade-off we
are looking for and creating different
applications and demonstration cases
okay maybe any last question okay good
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>