<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Small Spaces Feel Large: Practical Illusions in Virtual Reality | Coder Coacher - Coaching Coders</title><meta content="Making Small Spaces Feel Large: Practical Illusions in Virtual Reality - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making Small Spaces Feel Large: Practical Illusions in Virtual Reality</b></h2><h5 class="post__date">2016-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/w_qP4cC4agI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by microsoft
corporation may be used for internal
review analysis or research only any
editing reproduction publication
reblogged public showing internet or
public display is forbidden and may
violate copyright law
thank you so much for coming my name is
Kara benko I'm a researcher here at
Microsoft Research and it's my great
pleasure today to introduce Evan Zuma
he's visiting us from USC from of
creative technologies down there and
he's one of the world's experts on all
sorts of er trickery try to understand
try to basically understand locomotion
expand our spaces in kind of walking
abilities and manipulating abilities NVR
mostly by manipulating what you see and
what you get and the differences between
but I i won't us take much from his talk
i just want to welcome and say you know
thanks for coming down and giving us
this presentation okay thanks pinko for
the introduction so today I'm going to
be talking about how to make a small
space feel really large so this is all
about perceptual illusions and virtual
reality but with a practical spin
because what we're trying to do here is
solve a real engineering challenge for
VR so VR for me is a really kind of
special place to work so ever since i
put on my first hmd I became fascinated
by the experience of being in VR and
creating VR experience for others and
what really ups the ante for me is when
you can use VR as a medium to create
really surreal experiences that
transcend what is possible for the real
world some people say we recreating the
real world in VR is kind of the Holy
Grail but for me it's transcending the
real world going beyond what we normally
can do so as an engineer I think it's
really this is a really challenge being
able to do this is really challenging
because VR has so many be moving parts
that need to work as a researcher it
also is a really interesting empirical
to tool for the controlled study of
human perception behavior you can
actually use it to test things you can't
evaluate in the real world and this talk
really is about the intersection of
these two goals your it's engineering
magic
experiences but experiences that also
enable us to do the empirical study to
understand more about the human
experience so an overview of this talk
I'm actually going to first take a step
back from that and focus more on kinda
just some of the work but we did in just
the fundamental display technology
because we are these experiences are
technology mediated and then from that
I'm going to move into kind of the
challenge the next big challenge that I
see that we're trying to work on and how
we're kind of looking at this from the
perspective of what I call hacking human
/ special different types of illusions
and then finally I'll talk about more
about the practical spin of this which
is how to enhance interaction fidelity
which is kind of my code word or my
technical term for Korea creating magic
so looking back at kind of when i
started in VR so i started in two
thousand four ish 2003 and but I got
really started grad school in 2005 and
these were the displays that I were
using at the time so we're talking
pretty low resolution 640 by 480 / I
bulky heavy very expensive but probably
the most problematic at the time was the
field of view so the v8 kind of the
standard that you saw a lot with 60
degree diagonal field of view and so if
we look at this graph this this is
actually mapping what that type of field
of view is onto your entire on your
retina your what your human visual
system can actually see it's like
looking through a very very small window
and this is for me yvr up to that point
all throughout the time I was studying
in graduate school really wasn't magic
in fact a colleague asked me when I got
started in VR and I told them the year
and he said you decided to get a PhD in
VR when VR was down and awful what is
wrong with you so I guess I just liked a
challenge so so this changed for me in
2010 when I moved to the Institute for
Creative Technologies and we have a
prototype display there called the wide
5 and so this one really and the antlers
they are kind of funky but they're just
for the motion track
system but the real fun thing about this
display was that was when I first
experienced VR magic because it has a
150 degree a wide field of view so the
difference here you can see that it
really is the difference between looking
through a tiny window at something
distance and really for me being there
and so if we look that that wasn't the
only display capable of doing that
although is the widest at the time but
if you look at the cost you can really
see two categories here and it was
really look useful to look at this as
dollars per degree so if you look in the
bottom that is kind of more what we
would target is you know not even
necessarily consumer level but more
affordable HMDs that but their field of
view was really limited and getting up
anything over that 60-degree mark really
ended up it did not scale linearly and
it ended up getting getting extremely
expensive beyond what you know a lot of
research labs can afford let alone the
average person um and so a lot of our
funding at ICT comes from the US Army
and so we had in about two thousand nine
and the acquisitions people who are in
charge of all of the purchasing and
decisions for the army came to us and we
have all the demonstrations of ER and
they said this is all great but it will
never be used by the army and the army
cannot can invest in VR because if we
want to train people we have thousands
of people we need to train and it's just
too expensive there's no way you have to
figure out a way to do this and with a
more cost-effective matter so this kind
of got kicked us started us and got us
thinking and we were really inspired by
this little piece of technology here
which I don't think in has gotten kind
of forgotten and doesn't get a lot of
credit but it was it was kind of a
little before its time so we can
actually get this at like Target or
Walmart or Amazon at the time for less
than twenty dollars and it was a little
plastic device from Hasbro called my 3d
that you could slide your your iphone or
ipod in and you could get a 3d
experience but it really was from a
product perspective not successful
because it was a capability with no
content so but we got really sort of
interested in this and in the
possibility is that now the smartphone
screens were finally getting
big enough and high resolution of where
he could actually start doing
interesting VR experiences with them so
we did this is a kind of a prototype
system that we published it I triple EVR
in 2011 which combined this with a
bluetooth keyboard for interaction and a
few other moving parts and so but so
this kind of got us thinking about this
but then the real kind of insight or was
really when we started doing this with
higher end optics so this is some leap
optics that we pulled off of an old boom
display fact from the 90s but and then
we basically just cut out wood and slap
two iphones in front of it and there
were all these problems with it there's
distortion the eyes are not synchronized
properly but the the real experience is
we took this live demo to the conference
so we started handing it to VR experts
and they were looking into it for the
first time and seeing high-end optics in
front of these smartphone screens and
being like wow I didn't think I the
reaction we got from most people was I
didn't think it was going to look this
good so we left from that and we really
started thinking about okay there's
something here we really have to
continue trying to to make this
accessible so the next year we came out
with what we called fov to go if you
have a bend of the I Triple E VR you
might have seen us hand these out we
brought about 200 of them their car foam
core laser-cut ones with lenses that are
basically a dollar and then you just
basically fold up your own cardboard
display we and we have them for all
different types of phone models so this
at the time this was really really kind
of an exciting thing today I show this
but it's more of a historical kind of
note because now of course Google
cardboard has really gone and
popularized this notion of smartphone BR
over the last couple years and that you
know has really just been an explosion
in terms of that that ecosystem that I
think is really really a special
spectacular in parallel to the
smartphone via our effort we were doing
some really prototyping on the hmd side
and we wanted to really start building
not just viewers butthead mounts and so
we found this habias we hired him his
name's palmer luckey and he
hobbyist teenager working in Los Angeles
who had a quite a baby ARCA hmd
collection that was playing around with
in his parent's garage so he brought him
in the lab and we started we started to
build construct prototypes here which we
referred to as Frank and hmds which are
basically cobbled together from ebay
parts from different displays and LCD
panels you could buy online and
literally held together with tape but
they really started we started see we
can start to build this for about you
know three hundred dollars and so we
decided to open source all of this so
all of these designs the socket hmd is
kind of an interesting historical note i
think the consumer market is now you
know has gone be leaps and bounds but it
was a our 3d printed design for this
display which was very similar to the
oculus rift DK one and all we started to
move beyond the cardboard to 3d printed
phone viewers as well as tablet viewers
which are really interesting because now
you can combine an immersive display
with a touch surface and do a hybrid
interaction where you can actually use
some manipulation of objects on the
screen while you're looking at it so all
of these are available on our website
and anyone with a 3d printer can
download and create them but there's
only a limited amount of people I love
open source I believe in it but there's
a little etouch does so many people and
what really really was the catalyst to
for this explosion was when Palmer sent
one of those prototypes to John Carmack
and then left the lab to do a
Kickstarter and the rest is history you
know with the oculus was eventually
founded and bought for facebook for two
billion dollars and now Palmer is is
being one of these lead spokesman's for
the for the field of VR and one can make
the argument that though this is a this
was really one of the catalysts really
the the real reason was that the display
technology had gotten low-cost enough
and other of course companies were
looking at this at the same time as well
so it really was something that though
this was a particular catalyst this is
something i think was just inevitable
inevitably Bob inevitable
based on the cost of technology going
display technology going down and
becoming the quality going up and you
can really see this I think when you
look at that chart again and you put you
put the rift socket another consumer
level hmds on the dollar per degree mark
we're looking at that 90 degree vertical
was kind of the initial version of the
rift and what we see there is that
that's getting pretty good enough and
the dollars per degree is so much lower
than everything else that really now we
could go back to our the people at the
army and say you can now afford these
and so now we can start to really see
people care about the arc because and of
course now there's so many companies HTC
Sony and all of the other other ones I
don't put microsoft on this list because
hololens is a mixed reality device which
of course is similar but it's in its own
class and this talk is really more about
VR so can we say mission accomplished is
VRA a solved field at this point and so
I'm giving this talk so hopefully you
won't be surprising that my answer is no
and the reason is I think a lot of the
content creators and a lot of the
experiences that we're seeing coming out
at least right now in the last several
years have been have interactions that
look like this seeded use or movement in
a very very small area and a lot of the
interactions are mediated by controllers
game pads or other sort of handheld
devices to move through a virtual world
this to me I've done this you know now
that I've been doing this for well over
a decade when I have these kind of
experiences that are mediated by
controllers and it just feels like a
video game to me this does not feel
magic anymore and I worry that in the
long term that once the novelty effect
wears off the people have been immersed
enough and seen enough VR experiences
it's not going to seem magical anymore
it's just going to seem like another
type of gaming so you still get the
nauseated from induced motion I'll talk
about nausea and you know in a little
bit but yes that's also another problem
with with these kind of just woke
emotion metaphors is that motion
sickness because your motions don't map
with what your body is doing
that is a problem for some people at
least some people so so why is walking a
problem well it should be pretty obvious
that even if you have a tracking space
that can allow some physical body
movement if you want to walk through a
large virtual environment say a virtual
city or a large office space or what
have you at some point you're going to
run out of physical space you're going
to walk and you're going to in the best
case we're going on outside of your
tracking area in the worst case you're
going to physically collide or walk into
a wall and because you're wearing a
headset you won't be able to see it so
this is kind of one of the real
fundamental challenges for any sort of
VR system in you know is this real
problem of physical locomotion to the
environment so we researchers have been
studying this for a while so this this
has been something that people have been
thinking about for quite some time and
so there is one interestingness solution
that came out of the literature about 15
years ago so this is not my work this is
the original redirected walking work
which comes out of UNC Chapel Hill and
and so which really I think has been an
inspiration for a lot a whole class of
research in the field and the basic idea
here is that you just decouple physical
and virtual motions they're related to
one another but if you for example get
some of the work Pat walk through a
zigzag corridor you can actually get
them to walk back and forth in the real
world and if you just roll realize that
there is a that you don't have to have a
one-to-one mapping between physical
motions and virtual emotions there's a
lot you can do with that so let me give
you some examples of how this works so
they're the easiest way to do this or
the original way that Sharif suggested
was through what's called manipulation
of gains so again is just a
multiplication factor applied to your
motion so in the case of rotation I
might walk through a virtual space and
then I in this example rotated I'll show
you that again rotate 90 degrees in the
virtual space about 180 degrees in the
physical space so that you can after
your turn you are now walking along a
different vector you can do this in
other ways another one that's been
identified as
curvature gain and in here it's
different because you're walking
straight and there's a continuous kind
of rotation applied as you walk forward
and you will bend and walk along the
curved path and then finally there's
translation gain which is just a
basically a multiplication on your step
size but only in the forward direction
because you don't want to amplify it
side to side movement so you can travel
greater distances virtually then you are
physically so why is this better than
lokomo using controllers and the reason
is it's because it's linked in control
to buy your own motion and so there's
two different perceptual systems in
place here one is this your vision and
one is your vestibular sensation your
sense of balance your body sense of what
your your movement and turns out that
vision tends to dominate when those two
senses are in conflict as long as
they're kept to us within a certain
threshold so there's been researchers
who have studied this and so there's
these are just some of the kind of
numbers out of the literature and it
turns out if you do it within these
parameters and do it the right way then
not only it isn't imperceptible to the
user but it also hopefully won't make
them sick as long as you just don't do
this too much now i can tell having been
in these environments where you do it
too much it can make people sick so that
is a concern but the key here is that
vision dominates over your sense of
balance so one of the things I wanted to
do was really kind of understand not
just kind of do I notice these illusions
but how does this impact my sense of
spatial orientation cognitively in how
does this impact my my experience of
this virtual world so this is an
experiment that we did where we were
pointing at targets so what happens in
the beginning was you see a virtual
target and you aim and we're using a
tract wand to aim and then we were and
then you point at a real target so you
they bend up the optics of the display
look at a real target in the real world
point at it and then the rest to
remember where these are so point at the
real target pointed virtual target then
you're back in hmd we go through some
sort of virtual experience where we
apply these redirected walking
techniques so for the sake of simplicity
just show you derp it would happen
continuously but at the end of that walk
through your 90 degrees offset from
where you were when you started in terms
of your physical orientation so if my
vigil original virtual target was there
we wanted to know would you point at
that virtual target where you originally
saw it or would you point at it in its
position as if it were redirected
basically where is your memory of that
virtual your orientation of that target
now 90 degree offset and more
interestingly what would happen to your
perception of the real target would you
point it where was you originally saw it
or would your reference frame in the
real world move as well another way of
thinking about this is are you
maintaining to two models of your
spatial orientation do you have your
real or virtual or if I ridicula do I
manipulate also my real and so the way
we look at this we have to figure out
how to how do we measure this
quantitatively so the way we looked at
is looking at angular pointing errors so
this is a way of doing this is a pretty
common metric and vr and so what we
looked at those positions where we
calculated the angular pointing error
and so what we found is actually exactly
what we would expect if they were
correcting for that the redirection and
they were moving those targets reference
frames so for both virtual and real
targets so and the way we do that is to
speak we can see that the angular error
so this is the lower this is the more
accurate those angular error are pretty
consistent with what you get with just
regular pointing so those numbers 35 to
40 ish are pretty typical of just the
angular areas you get when you're asked
to point to something whereas you can
clearly there were 90 to about 90
degrees offset from what their original
positions were so this was a really cool
result for us because this confirmed
kind of an art resolved an argument that
I'd been having with Mark bolas my
colleague and co-director of the lab
where he maintained adamantly that there
were dual models and I said no if I mess
with you in the real world I think I'm
going to be able to get you to your
reference frame in the virtual world
real world's going to shift as well and
this kind of resolved that and he
stopped
planning at me so now i want to start
talking about another class of illusion
so this type of work with redirected
walking really kind of was just the
initial insight that what happens in the
virtual world can really transcend what
happens in the real world and we're not
bound by the same laws of physics so now
let's talk about another type of
illusion that I kind of just came up
with and I really got this inspiration
from the kind of common psychology kind
of stuff you scenes you know psych 101
and here's an example so I'm going to
ask you to look at this picture and then
I'm going to change something I'm going
to ask you to to just call it out if you
see what's changed anyone notice it just
call it out if you saw what I changed
here I'll make it really easy and so the
reason that's difficult is because the
human visual system uses motion to be
able to detect changes and just that
split-second interstimulus image that
black screen disrupts that perception of
motion and then it becomes very very
hard and this has been well studied for
many many years in psychology is called
change blindness and it's very very
consistent across people in a very
powerful illusion so I started to think
what happens if we apply this to VR and
so here's an example of how this works
so in this in this example you're going
to see walking through this virtual room
and watch what happens on the overhead
view on the top right left as they
approach this desk so they were looking
forward at the desk and in this study
environment they were just kind of grew
out looking at pictures but what
happened behind them was that this
doorway moved 90 degrees it stayed in
that same location but the orientation
of the doorway swapped along the corner
you're about to see it again as they
walk to this corner of the desk oh
whoops okay so the key here is that this
manipulation occurs behind their back so
everything
consistent to them in front of them but
when they turn around the door is offset
by 90 degrees and the corresponding
hallway is also offset by 90 degrees
this basically means that within a about
a 15 by 15 foot space I was able to
infinitely repeat this and do a 3600
square feet office building within less
than 200 square feet and this is
basically because this is a consistent
illusion as long as they're going
linearly and entering into these rooms
and kind of not looking back like
walking at the door I'm like staring at
it while walking backwards was people
never really do but they'll never see it
because of the manipulations occur
behind their back so this was a really
interesting illusion I wanted to test it
so I ran several experiments and I was
really trying to get some statistically
significant results of you know how how
many people notice this and what I
really found was that I completely
failed in getting statistically
significant results because no one
noticed so I did this to them throughout
this environment 12 times each multiple
experiments and one out of 77 people
noticed a reported that illusion even
after it was disclosed to them
afterwards they see we tried to tease it
out gradually with questions and it just
it was so effective that um we were we
were not expecting it so this was really
really interesting so we started to look
at kind of how this affects your
perception of space okay you might not
notice it but what do you feel that this
environment looks like so they're going
through this environment which cannot be
represented with a single drawing
because it's a dynamically changing
world but we asked them to sketch map it
and these are kind of very consistently
across the study the types of maps that
people drew which look very similar to
kind of the conceptually this kind of
office space with the you know kind of
in the square environment so what this
and we analyze these through some
subjective ratings and statistics which
I won't get into here but where we
really found overall is that the spatial
inconsistencies just seem to get
resolved you know perceptually or
cognitively when you're going to this
environment as long as your experience
my take
as long as your experience is locally
consistent then kind of globally we we
figure you know we figure out a way to
make this work when you're forced to
draw a map you figure out a way to make
it fit on paper yes yes so these were
drawn after the experience and a medial
afterwards um yes so it's sort of
interesting to me because as long as
they do the path where they go in every
office this will work but if it's sort
of an open world where they can explore
however they want it won't work right so
that's correct so it seems like in order
to decide what you need to do you almost
need to be a little predictive about
where they're going to go so you can
kind of start manipulating the world
ahead of time and manipulate them later
or something yes yeah you are one
hundred percent correct and that is the
latter part of my talk which I will I
will directly address that question yes
so during your study like be the Patsy
pantsu the space before they be try out
they were like the headset before they
go inside the space in these studies
they or we did not blindfold them before
they enter the physical space so they
did see the physical space beforehand
some yes did you did you do a kind of
London to a little study setting on this
in terms of like people adapt to
technology and their skill sets changed
their way they perceive things change
any information on that whether people
over time would actually mature and
understand it differently um nothing
beyond anecdotal um so I'm not really
aware of longitudinal studies in VR cuz
cuz it's very it's difficult you know or
impractical I would say so no I haven't
done it i'm not aware of it but
anecdotally I can say that these
illusions tend to for us around lab who
get to participate in these all the time
and see this they they just seem to to
work like even though I know that that
this illusion is happening that it
doesn't seem to have a negative impact
on the experience it's it's one of those
things that I think I can just accept
because the experience is seems locally
consistent so yes that's a follow up on
Michelle's
do any of the subjects report any kind
of unease in knowing I shouldn't be able
to walk down this hall this far because
I already saw there's a wall in front of
me or do they kind of start walking
slower is again not that specific no not
not that we could tease out in any of
the data although they did report report
a general sense of feeling turned around
and I think that that goes to your
question which was about did they see
the space beforehand they knew I mean if
you see the space beforehand you know
how big the tracking space is you know
you can't walk through an infinitely
large space so I think there is this
general sense that like yeah I got
turned around but when we tried to tease
out of them how did that work how does
that work there the overwhelmingly seems
to be like I have no idea how you did it
I just know that I've been turned around
so yes an observation on that it was the
earlier study somebody else's the zigzag
hall yep I noticed in the first zag you
see a lot of movement there were that
first time they get adjusted there you
can see the frame is figuring kind of
figure something out and then after that
it was pretty clear brain just kind of
yeah yeah and this is a this is a
phenomenon called perceptual calibration
we know that it takes a couple minutes
and and this has been studied in
perceptual psychology that people will
accept very you can actually recalibrate
to all sorts of different things like
different walk speeds different motions
even remapping of kind of the movements
of your head along different axes it
takes usually a couple minutes and then
afterwards a couple minutes to calibrate
back but it's a very rapid process only
you know so okay any more questions
about change blindness before I move on
okay so like I said this illusion was a
was unexpectedly powerful uh so I
started really thinking about other
types of spatial manipulation that we
could leverage in VR and so for this one
I drew my first inspiration from
psychology this one I'm drawing on of my
nerd credibility here from science
fiction and so who here is familiar with
the BBC television show Doctor Who I
love giving talks to technical audiences
because they actually get this reference
so for those who aren't familiar with it
in this kind of timeline or
mythology the doctor travels around in
this thing called the TARDIS which is
the basically the size of a phone booth
here and but the inside of it is much
much larger than could ever exist in the
real world in fact canonically it's
supposed to be infinitely large so this
was the kind of basic illusion that I
wanted to investigate in VR I wanted to
understand I wanted to experience this
magical sense that all the people in the
show got whenever he leads new
companions into the TARDIS and they go
with a sense of awe it's bigger than on
the inside and it becomes this joke but
I wanted to experience that sense of
magic of walking into something that's
bigger on the inside fortunately in VR
we can create this so here's the kind of
experimental environment that I built to
test this so i use a kind of very
similar environment to what you saw
before where you walk to desks and
you're looking we give them a task of
going over to look at monitors to see
pictures because it's just a way at
reg'ment people move through the
environment so you go through one desk
you turn on a picture you walk down exit
the room you walk to the hallway and
then by the time you get to the entrance
of the second room in the hallway the
first room is essentially deleted and
the new room is put in its place and the
of course if we look at these kind of
superimposed on one another this could
never this is a severe violation of
Euclidean geometry and can never exist
in the real world so I wanted to now see
what is how sensitive are we to these
types of illusions so the way that we
figured out to do this is to do what's
called a psychophysical experiment so
what we did was we just ask them to we
did these on whole different levels of
overlap ranging from zero percent which
means perfectly can't exist in the real
world to over seventy-five percent which
basically moves means like most of the
rooms are completely overlapping and
they're almost completely on top of each
other and we just have them give them
this kind of discrimination test they
experience a whole bunch of trials and
we asked them as this impossible or
possible and we do this over many many
many repeated iterations and then from
that we can calculate the probabilities
and generate what's called a
psychrometric function so I won't go too
much into all the detail of this but the
point here
is that this is the probability of being
able to detect that it's an impossible
space and this is the overlap level so
this is increasing amounts of violations
of geometry and what we found in our
data is that about fifty six percent by
convention is is when they start to
become reliable so you can get us quite
a bit amount of space savings by
overlapping geometry and people won't
really be able to detect it if it's less
than fifty six percent and the
interesting thing is this is when people
are explicitly told about the illusion
and instructed to try really hard to
figure it out so I think this is
actually conservative and if you did
this on someone who's completely naive
to the illusion it probably you could
get away with a lot more Corre Dora yes
lock it one to one yeah the corridors
walked one to one yes what happens if
you sort of make a virtually faster
would that make the understanding that
this is a bigger space I haven't tried
it it's a very interesting idea though
so yeah you might be able to because to
some degree people are using their
bodies as a ruler and judging those
steps as a way of judging distance some
of the people I noticed some strategies
in the study that some of the people who
are really really good at the task we're
actually counting steps so just innately
inveterate judging distances that is
true disturb you people that are
probably the best center if you are
people that work the cameras for film
directors and they're amazing and I'm
wondering if you normalize against that
I do take some demographic data I
haven't looked at that um I will say so
most of our subjects are actually not
University students which is a lot
different from a lot of way academic we
are labs do it we recruit off of the
general population on craigslist so I
had a pretty broad kind of selection of
people but not not the sample sizes
we're looking at her and too small to be
able to draw any conclusions about the
population the only thing really I can
tease out his video game experience but
even then it wasn't predictable
performance in this time it's a delay
just unemployed actors I might need to
modify my demographic question
and so beyond just do they notice it
though I really again wanted to go
beyond just that and understand kind of
how does this impact your experience you
know because self-reports have I noticed
this are only so useful so for this I
came up with a metric which I kind of
drawn from the VR literature called
blind walking and so this is a distance
estimation task to get your point so in
this sense what they did was they walked
after they walked to that second room
they were asked to look turn back to the
through the wall to where they saw the
first target so the both both of those
desks were as pictured there kind of
against the same wall so they were asked
to turn and to where that first one was
and closed their eyes and imagine how
far away they were when they when they
were standing in front of that target
the hmd at this point goes completely
black and then you're asked now to walk
until you are physically standing on
that point that you were so that's why
it's called blind walking this is a very
common metric used for distance
estimation studies in VR the difference
and the caveat here was that in the
cases of overlap then the the actual
place that that was would have been on
either forward of the wall or in some
cases in the extreme overlap conditions
literally only a step or two away like
they were almost on the exact same space
so the question here was would they walk
to where it actually was that they were
physically standing or were they correct
for the compression and continue walking
as if those two overlapping rooms had
actually been moved out and we're
actually now correctly side-by-side so
this is what we found in the data and so
what we're seeing here is overlap level
again around here and this is in
percentage of the actual the walk
distance relative to what it actually
should have been if it were accurate to
the real world so if they weren't
correcting from the compression they
were walking to where they actually were
we would expect to see the data
follow that one hundred percent
horizontal dotted line the red dotted
line is what we would expect to see if
they were correcting for that
compression and over walking and this
I'd love to show this data because this
is one of the most clear-cut examples of
an effect that I've ever seen you really
don't need a lot of statistics to be
able to look at that and see exactly
what they were doing so even the cases
of seventy-five percent overlap where
it's really obvious very few people
ninety percent of people were able to
reliably detect that this was an
impossible space even in those cases
they were still walking those
exaggeratedly long distances when kind
of in behavior correcting for this
illusion so I think that was a really
really interesting finding and it kind
of goes to this idea that I like to say
that like we've learned that spatial
perception is malleable and that people
even even if they kind of can perceive
that these things are going on they'll
still try and behave normally as long as
it doesn't mess with their experience no
no or at worst make them sick as long as
you can make the experience still very
rich and pleasant then these illusions
even when obvious could still be useful
but now I'm going to start to get more
of the Rays more of the practical
question stepping out of the basic
research hat and now start talking out
as a VR engineer how is this actually
useful in a real practical system and so
now if you want to dig me on anything
you can dig me on saying hey you know
these these are really only work in
these linear environments where you have
this kind of purpose-built experience
that's kind of validates the technique
but if you want to give free-flowing
expiration of just an arbitrary
environment how would you do that these
aren't generalizable and I think they're
not like there is no generalizable
solution for a redirection that applies
to all spaces at all times at least we
haven't discovered it yet what they are
as tools they're tools for VR delivered
developers and VR designers and content
creators to use for the
variants that they're they're doing and
they're best employed when you can
actually couple the content creation
with the kind of experience and
techniques you want to use so some of
the interesting ways we can use these
tools so this is an example of how we
use it in a mixed reality setting the
change blindness technique is really
interesting because it's a discrete
change it's unlike the motion illusions
this is not a continuous change these
it's a single state switch and so
because of that is predictable so
instead of doing a 90 degree offset this
is one where I did a two-stage building
where there's interior rooms and what
you're going to see here is when you get
to this back room I'm going to pull the
same door switch here and then this door
switch is going to move over here so
there's actually two doors moving here
all behind your back and what this
essentially lets me do is change is
reuse this road infinitely so we trucked
about a thousand pounds of gravel into
the lab which I would not recommend for
cleanliness because we were cleaning
like dust for the next three years but
you end when you enter in a building
here and then when you exit the building
you guys end up exiting here and then
every time you step right back onto that
gravel road you feel the crunch under
your feet you feel that haptic sensation
and so it was a really very very
compelling illusion or so again that's
that sense of magic for me because now
there's there's a sense of realism the
real world is actually kind of playing
along with this illusion here's an
example of another kind of way in which
these impossible space techniques could
be used in a practical setting so this
is a technique I call flexible spaces
and in this sense what we're doing is
we're playing with similar violations of
non-euclidean geometry but we are doing
it in by creating twisty hallways that
kind of curve back into themselves and
so what we're doing here is this is an
environment where each room is pre
modeled and this is this is researcher
art so that's why it looks so so bad but
each one of those hallways is
procedurally generated on the fly in
unity based on the those other polygons
are just generated as needed based on
where you're standing in the space and
where you need to
and so the really cool thing is that you
can just basically do this infinitely
and then so I need a hallway that gets
me to be standing over here I can just
generate a twisty hallway and you do get
a kind of a sense of like again that
general sense of like something being is
fishy's going on here but because we're
not employing any of these motion
illusions there's there's no real risk
of inducing additional simulator
sickness so I think this is a really
cool technique that could be used for
entertainment and 44 experiences in
general that where the individual layout
of the environment doesn't so much
matter so educational experience has
museum exhibits things where you're
trying to experience content but the
exact spatial layout is irrelevant to
the experience and trying to move this
now to really into practice I mentioned
that ICT has a lot of DoD funding so
what we want to do is really again do
the same thing we did with hmds and make
it possible for people our funders and
also just the general public to make use
of these techniques in this toolbox so
this is a example of a redirected to
walking toolkit which we built from
unity we actually have completed it and
we're actually just getting the website
up will be released by the I Triple E be
our conference in march open source for
unity and so what we're really doing
here is trying to build all of these
kind of at least more generalizable
techniques into sort of a toolkit that's
plug-and-play so I can just hand it to a
developer and they don't need to know
about all the math and the perception
they just need to tell it how big is my
tracking space here is where I want to
go in the environment this was an
example where we're actually planning
waypoints so we're telling it this is
where we want you to be able to go so
the environment can plan it and then it
will figure out the math and and make
that work and one of the real reasons
we're doing this now is because we're
finally seeing a consumer level wide
area tracking system with the HTC vive
coming out which can get tracking and
around five by five meters or so four by
four meters something like that and so
it's it's really now you can start to
see okay if we have where we're not
getting up to
like the huge spaces but we're starting
to see consumer level tracking that can
actually allow some movement and I'm
gonna give you an example of how we use
redirected walking using the tool kit
within a valve I've set up so this is an
example of an environment that we did
for the siggraph arv or contest last
year which will actually won first place
of the contest and this is in
collaboration with our partners at the
School of Cinematic Arts so what they
did what you saw there was a turntable
where we're using we're working with
stop-motion animators and so there's a
rig that spins that around and there's
an image taken every second for every
degree and it and so then you're able to
do kind of capture the image at every
angle and what we're doing now is doing
image-based light field rendering within
an hmd so we created this experience or
for the conference but then they said oh
you've been invited as a finalist you
have to bring it to the conference
here's our demo space and we're like the
environment doesn't our environment does
not fit within your demo space and our
environment like the key to this stuff
is really being able to move around it
because you gets all these specular
reflections and subsurface scattering
and all these really fine visual image
elements or that don't come through in
geometric rendering but you really get
from this image brace light-filled
approaches so that that movement that
physical body movement around it is
really really important so what we did
was we we basically went through we use
the redirected walking toolkit and this
is that same zigzag idea that the
redirected walking paper from Chapel
Hill did but this is actually the the
physical kind of de space dimensions you
would get with a vibe so now as long as
we give them verbal instructions so
there's a narration that says turn to
this exhibit where and explains linearly
because there's a progression through
this exhibit as long as we're able to
direct them to go where we want to go in
this environment you can see we put a
couch here as a kind of visual indicator
of the scale that this could actually
work in a living room suicide space and
then so interestingly enough I do have
this demo on my laptop I know that there
are some people with live setups in this
building so if anyone who has a vibe
setup wants to experience this I have
some time this afternoon
I'm more than happy to come by and you
can actually see what it feels like and
so that's an example where we know the
path in advance another way of being
able to deal with this path prediction
problem is in letting the user plan a
plan so this was our one of our kind of
early cheats what is that okay we can't
really let you walk anywhere but we're
not going to tell you where to go in
this kind of free-flowing environment so
we gave them we give them a nap and they
basic said plan your route and then
we'll figure out how to do algorithm
will then figure out how to get you
where you want to go so this is a little
bit more free but not totally free yet
now we're working on the kind of totally
free case so this is forthcoming work
that we that's just been accepted to i
triple e 33 you i will be published
later this year and what we're doing
here is we're building short-term
prediction graphs based on the geometry
of the environment on where you're and
your movements and what we're doing here
is we're basically leveraging a tool
that's already available in all these
game engines for doing game AI and its
navigation message so navigation meshes
are basically how game AI does its path
planning and so we're basically taking
all of that that technique that's built
into all of this and we're using that to
essentially build up these prediction
graphs about where the user is
theoretically going to want to travel in
VR and so this was just the initial
technique and now our next step is we're
building this into the predictive
algorithms that we have implemented to
and then we can measure the the kind of
expected performance or the advantages
of doing that are you able to
dynamically change the level using math
wishes um so we're actually so I can't
speak to that because we haven't we're
just we're dealing with the static case
first we're not dealing with dynamic it
I do know that while our preferred way
to use nav messages are not the unity
built in but using a package on the
asset store that extends it so I'm not
sure about the dynamic case so so and
then another technique that we have in
the toolbox here is a reorientation
technique so what happens if these
techniques fail
so so let me let me start this over
again so what happens is basically if we
know at the very slight second that we
try to predict as best we could but at
some point you're about to hit a wall we
have to do some sort of failsafe or some
sort of way of intervening and maybe
this is one potential trick that may or
may not work in particular experience
but we ask them to take a panoramic
photo so this is an example where we
basically just ask take a town around a
photo that's something that most people
with smartphones now are familiar with
and both this basically does is it gets
an excuse to give them a spinning motion
but that spinning motion occurs on the
spot so we can basically do an emergency
reorientation away from a wall so again
it's disruptive to the experience we
don't want to do this too much but as an
emergency when everything else fails
it's better than having the take off the
hmd or crash into something so you can
see now how these kind of techniques
work we try to apply this continuously
predictively as best we can but as
they're going through the environment if
eventually they end up hitting a wall
that's when those you see that kind of
space spin around them that's when we do
some sort of reorientation ticket
technique as a fail-safe so you can
actually get through a city-sized space
right now with a little bit of
interruption um the reorientation
techniques though do provide a great
metric for effectiveness of simulate for
evaluating these algorithms so what we
did now to kind of move this forward as
we're developing these algorithms more
as we develop the simulation framework
where we can tweak algorithm parameters
and then generate procedural paths to
environments of different types and
distances and systematically measure
using that those reorientation
techniques those periods of failure as a
as a metric of minimum minimization
metric to try and get these algorithms
better i'll give you one quick example
because i'm almost out of time and so
here's an example of popular ways of
doing steering in for any sort of like
continuous system so people in VR they
thought okay the previous convention was
steer to center is best we just in we
just kind of naively try to get you to
be in the center of your physical space
other people have said well maybe it's
best not to go to the center the
should get you to just kind of orbit
around the center so the sentra vs.
steer to orbit was an argument the steer
to Center people went out and so it was
kind of conventional wisdom says sears
centre is always better but when we
started being able to do this simulation
and go up to larger and larger tracking
sizes what we actually found was that
the conventional wisdom was not true
after a certain point that as the
tracking size increase and I'll just
highlight this here there's an
inflection point so this is the relative
effectiveness this is derived metric
based on the probability of getting a
those reorientation triggers those those
fail stuff technically techniques
there's a period of time where the steer
dissenter algorithm outperforms it but
at some point there's a crossover and
there's a substantial increase in steer
to orbit with sufficient space is
actually much better and in fact hits
the theoretical maximum of never having
to do a reorientation sooner with a
smaller tracking area than steer to
Center so this was a kind of an
interesting paper we published at I
count last year that was just one
example of how we can use evaluation to
better design these techniques and in
the future but we're really trying to do
i think the holy grail for the
redirected walking is not just one user
but multiple users because now you don't
have to just deal with the physical
boundaries you have dynamic targets you
want to have people not bump into each
other but if someone wants to handshake
or hand an object to another you might
want to converge spaces so there's a
convergence and divergence of individual
spaces which is a problem we just barely
begin to explore and the question is I
know five by five meters is pretty good
for redirector walking in some cases but
it's not going to work for multiple
people so how big do a space do we need
you know that's the kind of the answer
we have to look at in these simulations
of how big how scalable does these are
these techniques and I think this is
going to be increasingly interesting
once we can go beyond what a vive system
can do in the consumer level and was one
of the reasons I'm really there are many
interesting things about hololens but
the tracking on it the fact that it's
all inside looking out and tracking on
the device is something that I will
would love to see built in to a VR a
pure VR headset rather you know Rollins
being a mixed reality device is somewhat
different and these techniques don't
really translate well to
kind of realm because you can see the
real world um but then you can start to
see if I if the device can just track me
I don't need infrastructure can I just
go out to a parking lot football field I
can just make ad hoc use of big empty
spaces and then you could start to think
about okay I could theoretically see a
multi-user system like this working but
you know the tracking technology just
needs to catch up with our you know our
dreams and our goals so with that I'm
just going to wrap up the lie said VR
for me the real power and the reason I
chose this field is because of this
creation you can really create magical
experiences you can transcend the laws
of physics and you can do things that
you can't even dream about doing in the
real world and that is something that I
think is just going to we've barely just
you know it's just the tip of the
iceberg in terms of what BR can do and
the other thing is is that the role of
researchers I think it's really
interesting that the this isn't from a
blog post earlier this year where
someone a random VR hobbyists was was
thinking about the via vibe and he saw
the vibe and he's like what can I start
to do in a vibe I want to go through a
larger space and she actually started
sketching out things about walking on
circular arcs walking in 90 degrees he
hadn't come up with the idea of marrying
it to rotations or employing illusions
but he's the the hobbyists and the kind
of general public doesn't perform
literature reviews and through brute
force their rediscovering with a little
bit more thinking on this and work on
this they'll come up with redirected
walking so as researchers that's a kind
of the goal is to kind of create
toolkits now and and kind of inform the
general public so that they don't root
for sit and invent the wrong thing all
right with that I'd like to thank shed
knowledge that this is the work of a lot
of my you know students PhD students
interns undergrads engineers and so work
of a lot of different people with that
I'll take any other questions
yes are we doomed to walk in the hour or
at least twenty-five percent faster than
usual um I think I think we don't know
if I'd call it doomed because one of the
things that I do think about in VR is
energy expenditure and fatigue um I
think that it would be great if I want
to go through a large space and I don't
have to walk a mile and I only have to
walk three quarters of a mile unless I'm
trying to get exercise at which point
you might want to slow it down and then
you know get get a higher distance but
it's not always a bad thing we'll get
the problem of inconsistency between
sentences right yes yes although like I
said certain amounts of inconsistency is
tolerable and in fact not just tolerable
but imperceptible and that's not that's
not an attention thing that's actually a
percent when it's a perceptual effect
it's so so low level that it's actually
more it's more of a brain thing then
it's not a level of your attention like
if it's imperceptible you can't it's
really hard you can't even do it even if
you try but of course individual
variation exists yes I love question
observational mother like the gravel
path then we showed hmm that adds a very
strong constraint to your system so that
really won't work with free walking but
because once he exited the first
building and came out to the path if you
had gone back he was stepped immediately
like outside little down right right so
but that but you can use different cues
like audio cues right simulate that he's
walking on a different type of surface
even if he doesn't physically feel it
have you done anything with that um yeah
we've done audio we've played around
with audio sounds like the crunching
sound the other thing I I played around
with um was actually trying to build
shoes which had a layer on the bottom
that that actually gives you like
different sensations on it or could even
we tried to cut it at the angle to kind
of twist your foot a little bit in a
direction and bias you towards walking a
little to the right or left turns out
that works when you close your eyes but
when you're walking your vision
domination you just try to correct for
it anyway so it didn't it didn't work I
was great so we try to look at a bunch
of different different ways of being
able to do that but to your point yeah
the you know do all of these techniques
have different limitations in terms of
generalizability and when they would be
useful and not in different ways of
being able to violate those assumptions
but the point is is that each of those
techniques have different assumptions so
you pick the ones that are best and ho
and in combination you could potentially
get away with quite a lot so so it's
true for all the variables right I mean
like the level of fidelity you were
mentioning this is a UX I mean a a
research-driven research drawn space the
level of fidelity had been a lot higher
it would have in the whole equation of
comfort it would have probably mitigated
against other other things that were
created created disk that makes it yes
yes and in fact i think so i think some
of this is actually empirically needs to
be measured when we get to the systems
that can render it greater than 90 hurts
and have really low latency tracking
because some of the things that were
intolerable or just not really you know
or things that were good before
techniques that were acceptable because
they might have been masked by by
latency and jitter might not and we need
to re-evaluate them under these new new
circumstances Oh most of the
measurements that you do our kind of
verbal scores and some sets like you
know have you noticed they have you know
that you noticed where where was the
door but I noticed in one of the
pictures that you had a kind of kg hat
on wearing the headset we thought about
any more kind of biological sensing or
an electrical something of that what
people might not report being noticeable
but actually is noticeable by the right
yep um I I haven't personally there are
people at ICT who who've done that I
think they tend to be more in the
medical VR sector and so I think that
there's a there's all these the
I think a lot of difficulties with doing
this with large-scale walking because
there's all the physical movement I
haven't personally done anything with
with brain scans but I i have over time
I've become less enamored of using
verbal reports and subjective measures
which is why I started to use things
like those distance estimation studies
and started to look at designing
experimental tasks where if I can't go
for a psycho psycho physical biological
signal I can multi get some sort of
objective behavioral signal and I can
measure use your behavior instead of
relying on just a self-report which has
all those those problems so so far
you've assumed there's sort of an empty
area have you looked at any like having
objects that the user would be to avoid
physical objects and redirecting them
around the subject specific living rooms
or houses could be a lot larger if you
can force them to kind of go through
from room to room as they walk around
yeah the I think we haven't really as a
field yet tackled that we've just
started with our evaluation framework to
start testing non-square spaces because
we started to realize wait these can be
there's no reason why these have to be
squares in fact ours is rectangular so
we're starting to look at different
shape and how shape affects the sides
because shape is actually interesting
because you can get long walks in one
direction but very short walks in the
other the to look at obstacles like that
no we haven't really done that with the
exception of love Coley's work also from
UNC Chapel Hill so about five or six
years ago he had a paper where he tried
to combine passive haptics with
redirected walking and what he did was
he was using the rotation techniques so
he picked cylinders because their
rotation invariant so he could put like
a cylinder and he what we do is redirect
someone and then they would always you
could be the space could be circularly a
rearranged around it but he could always
reach out and touch the circle or the
cylinder in the space but navigating
around obstacles I think yeah that's a
that's not a area for work it is an area
for future work yep okay listen I had a
clarifying question for myself I
couldn't remember
as in the first part of the talk as
people are walking what they think is
straight you do sometimes curve as
they're walking straight or is it mostly
that you do the variation as they turn
themselves likely yeah there are two
distinct techniques rotation games are
done during your rotation curvature
gains are done when you're walking
straight so you're walking straight and
there's just a slight continuous
rotation that get you to bend your path
and both have their own thresholds we
actually but they've always been
measured separately we actually are now
doing a study where we're doing them
simultaneously because we think that
there's a combined effect that hasn't
been empirically measured yet but they
are two distinct ones is there anything
interesting to say about vehicles so if
you have a home be sitting in there in
your lab and you cop into it started it
up drove some place and then got out I
mean this I guess it's got not that
interesting to you I'm wondering if
there's something else to be done in
that space um I've thought about it was
thinking about that as one of your
examples have a city around oh yeah yeah
um no that was just uh yeah that was a
simulator I haven't used done anything
research wise with it because I think
once you guys did the vehicle simulator
once you enter an exit you can be in
completely different places virtually so
be that interesting I mean to me might
just work yeah I think I think we've
been asked actually so by the perceptual
manipulations that we've been asked to
consider are more about when it talks
the vehicle simulations are more about
haptic control surfaces so they want the
army for example wants reconfigurable
easily reconfigurable simulators for
prototyping so they want to be able to
do vr environments that can you know
have these kind of dynamically repurpose
a bowl haptics surfaces so that that's
kind of where the I see more perceptual
manipulation potentially being employed
but well I think you're very nice</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>