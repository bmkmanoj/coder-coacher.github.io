<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Automatic differentiation and machine learning | Coder Coacher - Coaching Coders</title><meta content="Automatic differentiation and machine learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Automatic differentiation and machine learning</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pdSCHtPJ4B0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so my pleasure to welcome my a
human spider our who's from the Hamilton
Institute and after the famous Hamilton
half in in Ireland and yeah it's sort of
his long history of doing I guess I got
to know
berrak and who knows through some
automatic differentiation
implementations that happen in the F
sharp language but of course people do
that in a camel and in Python and C++
and all sorts of other things as well
and then coincidentally Eunice has been
working on a topic which will be very
potentially very important in lots of
machine learning applications which is
just doing a really deep survey on how
this technique can be applied across the
machine learning spectrum and I suppose
in some ways evangelizing the technique
as you know important crucial underlying
technique for across that domain so over
to you unison yeah welcome along okay so
thank you for inviting me here and thank
you for coming to my fault so my name is
Ganesh I'm a postdoc in at the Hamilton
Institute in maintenance universe in
Ireland I'm working with Professor Park
perimeter at human Institute so today
I'm going to talk to you about machine
learning and automatic differentiation
and for this work we are collaborating
with Jeffery Siskin from Purdue
University and Alex a result from MIT so
let's get going
so I'm going to start with an overview
of the problem we are addressing here so
let's say you have some data with some
given inputs and outputs it's just the
basic optimization so you have a model
which I represent here with function f
it's parameterize by a weight vector and
you have some kind of loss function
modeling how of course the earth data
fits how close they are model fits your
data so you just do some basic
optimization you you and you you get the
fitted model out of that so there are
sorry sorry yeah Yoshio CB wait this is
all very familiar so what's common fw so
like fw is a model like yeah I mean I
say model is a function that maps from
the input space up to the outer space so
you have these points like exes like you
can do some maybe like you can think
about this in neural network it has
inputs X and it gives you output Y like
and these are vectors like it's just a
function mapping something to another
thing like it can be any any function
it's just yeah it's just a function and
it is it has this parameter W and you
you just this parameter W to make it
represent your yeah everything's a
vector two vectors W and X yeah you can
say that but you chose to represent W
there as the subscript because yeah
because it I I tend to think about that
way it's just the parameter as just in
your model well and once you adjust that
W through IQs the loss function loss
function yes so it's like an objective
function so you you you it's a measure
of how so you you let's say you take one
of the inputs X ok let's say you you
have lots of inputs and lots of hot
pursuit take one of these inputs let's
say x1 you give it to your function f it
gives you the output Y correspond to the
corresponding to that F X so what you
are trying to do here in opt in
optimization you are trying to adjust
these w's which also go into this
function f you get an optimum set of W
values that gives that that minimizes
this thing that I call was function so
so it measures how closely the designer
yes my constraints W so it's the minim
is the total q yes so why is a Q sub I I
thought he was fixed in this almond
thing oh well it represents it refers as
you have it the thing I represent which
I hear is like you you have a training
set so I is the number of two input and
opt in the training set like the first
entering it yes so you can talk about
them separately you can have you can
talk about the loss of corresponding to
the first input turn first output pair
you can talk about the second cue you
can talk about so you can have
definitive if you if you represent it
this way it gives you the possibility of
tokens each no not here not in the slide
but of course you can have that would so
it's not really relevant it's just like
so you through some kind of procedure
you are trying to optimize this function
f by adjusting W okay so that's what you
do and so you can do this thing with
derivative free methods you can have a
combinatorial optimization you can have
like evolutionary algorithms there is
also derivative paste matters like
gradient descent stochastic gradient
descent like Newton Newton is part
methods so for this type of optimization
you need to supply the derivative of
your model function and your loss
function so to the optimization
procedure so you have to supply this
thing separately that is how it works so
for example you can have methods
depending on the gradient of cute you
couldn't have methods using the Jacobian
or requiring higher order derivatives
like the Hessian matrix ease or vector
products of these any of these things so
and you have to supply these things
separately to your optimization thing so
the short story here which is the
subject of this talk you
he was everything was discrete this will
only work where the X's and Y's and the
Q's or continuous functions that it'll
only work if the X's and Y's and the Q's
are continuous functions and real valued
variables
yes differentiation it has to be
continuous just because you can't define
the derivative if it's not continuous so
if it's not continuous you can use non
derivative based optimization so if you
have continuous Q's and apps you can use
their basic methods and so the thing is
you you have this thing called automatic
differentiation and it can eliminate
this derivation step from of the
optimization procedure and it can
simplify the work flow of this machine
learning workflow so and it using this
you can make the differentiation the
integral part of the optimization
procedure so I'm going to talk about
that and another thing is it can it can
do this it can use exact derivatives and
it can support the larger the larger set
of functions while doing so in today's
talk I'm going to talk about three
things I'm going to talk about how we
can compute derivatives briefly I'm
going to talk about what is automatic
differentiation and we will see how we
can use this in machine learning
applications so let's start with this so
how do we compute derivatives the the
basic thing is you can do manual
differentiation like it's calculus 101
there are rules of differentiation you
just apply that and it's tedious but
it's very common in machine learning
practice so for example this is like
this is a recent paper
it's about computer vision so what
people doing machine learning is when
you have a new model so you perhaps
introduce your model in the first couple
of pages then you spend a lot of pages
analytically driving the gradient of
this thing and in the end you end up
using it with some kind of standard
optimization procedure and it's seeing
a kind of technical like technical thing
like you are showing that you do all
these decorations like it's like a
technical accomplishment so of course
there are situations where we need
analytical derivatives like you can be
up there analytic solutions your problem
you can be after proofs but most of the
time what we really want is to use this
numerical values of the gradient or any
derivatives that we are going to
eventually use in optimization so this
is something to keep in mind on the
previous page pretty simple and I'm
sorry taking derivatives it's not
usually that it depends on the
complexity of your model like so if it's
like it depends it is not a general
question I'm sorry
it depends on what you are taking the
derivative of so you can this is like an
actual paper review I don't want to
disclose the author so you can it's
mechanical like to take in there which
is this completely mechanical like it
has been that's the idea behind it like
if you do it manually it's mechanical if
you do the knowledge approach the
mortality per packet is mechanic it's
always mechanical but the texts are done
so I'm going to talk to you about that
as well so you can use the this thing
called small transition you can use
computer algebra packages like
mathematical maple they work very well
but there is this thing called
expression as well so you get
exponentially more complicated
derivative sort of original expression
so let's say in this example I have the
logistic map you start by X and after
for example if you like look at the
second iteration that thing is not very
complicated that that expression and the
derivative of that is that so this is
not a very big problem but when you are
talking about an expression like that so
this is the derivative out of that that
you get so using symbolic
differentiation the things can get
exponential very quickly depending on
your model
so this is this is called problem of
expressions well so there's another
thing in menu on smoke differentiation
you are but it doesn't stop the
exponential blow-up so I chose this for
black showing you clearly with the
problem but I in the paper I also have I
have three columns I indoors not and I
have the derivative I I have to simplify
derivative you can simplify it it's for
example in Mathematica there is a
simplified first procedure but it still
doesn't solve the problem completely
it's still the highest exponent is going
up exponentially is that yeah I haven't
thought about it but there is something
like that
and this is the logistic map is very
simple it's just you don't have any
transcendental functions anything like
that one once you have this type of like
sines cosines like or maybe I know arc
sine or any complicated function things
get a complete explanation so here even
after simplification it doesn't really
help you after some point
so there's another problem it's more
important and more relevant for machine
learning it's because if you are using
symbolic and many of differentiation you
are limited to closed for mathematical
functions you can apply this so you only
a function defined in a mathematical
sense for taking the derivative of
something test to be a mathematical
function so what I mean by that is you
can take the derivative of something
that looks like this but you can't take
the derivative of something that looks
like that on right like if you have an
algorithm like doing recursion loops
I don't know branching conditional
conditionals you can't take a derivative
of that it's impossible so what we do
with ATS we can take derivatives of
algorithms and so lastly there is this
thing called numerical differentiation
people are very familiar with this you
just use finite differences you use the
limit
definition of the derivative and
you-you-you use a very small step size 8
and you get some numerical approximation
of the value of the derivative using
different approximation formula so here
we have this problem of approximation
errors you you might think that if you
keep decreasing your step size you are
going to get more accurate derivatives
out of this but it's not as simple as
that you have to be very careful when
you are selecting the value of your step
size so because if you let's say you you
start decreasing your step size you
increase the accuracy at some point but
after some point you so you've been
decreasing the truncation error and
after some point if you keep decreasing
your step size this thing called
roundoff error gets no monitor and it
again makes you makes your approximation
less accurate so this isn't really very
helpful in some situations so there are
better approximations you can for
example use this formula people know
that very well it's like it's called the
central approach some sort difference
formula there's this thing called
Richardson extrapolation there is this
thing called differential quadratures
there are methods but they increase
rapidly in context and they never
eliminate this approximation errors so
it's the situation with the numerical
approximation method so what is
automatic differentiation so the idea
here is that you you have an algorithm
automatic differentiation gives you an
Augmented version of the taggert and it
does this by so it takes the values in
your original algorithm and it it it for
each value it keeps a primal part of it
and a derivative component of that value
for all do all the computations going on
in your algorithm so using this you
compute the derivatives along with the
original run of your algorithm so I'm
going to explain how it works this is
this is based on the observation that
all algorithms are eventually
compositions of finite set of operations
and you can define the derivative suit
corresponding to this finite set of
elementary operations you can have an
automated procedure computing the
derivatives along the way you are ending
your origin who are good you get exact
derivatives out of that it's not a next
approximation so I'm going to show you
how that works
so you're going to go for oh yeah I
forgot to mention that so you have this
thing here okay it's a function of two
two inputs so you multiply them you take
the sine so you give this thing to an
automatic differentiation two it gives
you another algorithm it transforms that
so this thing you get out of it you have
derivative components corresponding to
each original value here in your
algorithm so this thing again computes
the same values it for example here
multiple computing multiplication the
sine of c but it it does also compute
the derivative of that thing so i'm
going to explain how that works in the
next slide so for example for a sign
like these equal to sine of c so you get
D is equal to sine of C but also D prime
like the derivative of D is equal to the
derivative of C multiplied by the
derivative of the sine function so this
is the way you do yeah if you are
applying this to mathematical
expressions you the thing you get out of
it it's exactly the same with similar
differentiation like from Mathematica
like the numerical result the way it is
computed is exactly the same but the
advantage here is if you do this while
you are running the algorithm so you are
transforming the algorithm you get
something that computes the original
values and it also computes two
derivatives along the way so it's not
like you are not doing symbolic
differentiation and getting another
function representing the derivative
it's just the transformation of your
original algorithm and if
do it this way you can also have
algorithmic control flow statements in
place so you don't have to get rid of
time you don't have to transform your
algorithm into clothes for mathematical
expression for taking the derivative if
you do it this way you can still have
all the algorithmic control and it still
works for computing the derivative so
it's like a type of symbolic
differentiation that is like doing it in
run time maybe you can say sounds like
that so automatic differentiation is too
much main much there is this thing
called the forward mode it is very
straightforward very simple to implement
there is another thing called the
reverse what it's a bit more difficult
time it's a bit difficult to understand
language it for the first time so let's
start with the forward mode let's say
you have this function there of two
input and so the thing we're doing ad is
we we are interested in dependence
relations between the inputs to your
function and the outputs you get out of
it so for computing that's something
that looks like that you have to do
elementary computations so you will have
some intermediate results you will have
some intermediate values in the
computation this is how we represent
unlike in this computation in graph you
can see that this v2 corresponds to this
multiplication of your two inputs v1
corresponds to the logarithm of your
first input so this one corresponds to
maybe the plus of the addition operation
so this ask you to clarify this one so
my intuition is ok so in in an
algorithmic form of some of these
functions you've effectively got an I'm
potentially unbounded number of terms in
the expression so that you might have a
form in one example that might depending
on the input might involve one term or a
hundred thousand terms logically as a
mathematical formula okay on any
particular input they shape to the
formula can kind of change as the whole
point of the algorithm and the point of
automatic differentiation is it gives
you a way of actually computing
derivatives at it at any particular
import
but you don't actually never compute
that close form of that because that
mathematical expression doesn't it
doesn't have a closed form this is
potentially unbounded number of terms
you
you can't compute a closed form version
of the algorithmic version of these
things so you but you but you can get a
function which computes the derivative
at any particular point yes that's okay
is that the right intuition so it allows
you to apply differentiation to
functions which you can't normally do it
to right yeah functional descriptions
that really makes reference but you
can't normally different yet yes this
convenient functions yes but there's no
way perhaps an ad for doing this thing
but the value you will get at the
discontinuity its it wouldn't have any
meaning because if you are trying to
compute the derivative itself this
continuous point you should write less
than zero than one else minus one yeah
so you can you can run that through a
twenty differentiation you will get some
value maybe but that value doesn't mean
anything because at that point your
function is not differentiable and if
you are trying to do differentiation at
that point
you shouldn't okay the derivative is not
defined third condition of the algorithm
is actually continually
computes a continuous function and you
don't check that condition you don't you
just trust the user for not computing
derivatives that at points usually where
yeah okay I in my implementation I erase
some exceptions like for warning them
you are trying to compute the derivative
at the point where it's not defined you
can have this type of stuff but in many
automatic differentiation tools I think
these conditions are never checked for
performance reasons so in the forward
mode what you do is you you are
propagating derivatives from the
independent variables to dependent
variables so this is why it's called
forward mode and basically use you
selected one of the one of your inputs
as the variable of differentiation and
you argument each intermediate value in
your computation and graph it another
component
which represents the partial derivative
of that intermediate value with respect
to the depend independent variable that
you selected and you you set the
derivative component of your independent
variable to one it's by definition
because you are taking the derivative
with respect to that and you just run
the algorithm forward and you get
derivatives in out of your computation
so you get something like this so here
around on the left side you see the
forward evaluation trace of this of this
example here so you start by some values
for your input your on all these
elementary operations you get let's say
you get your apt here so what ad does is
it gives you this Augmented thing here
on the right so it runs at the same time
and so the values here if you see here
the derivative components they
correspond to the intermediate values
you have in your original algorithm and
let's say you are taking the derivative
here of this thing with respect to x1 so
you start by setting the derivative
component of that to 1 and the
derivative component of all the other
inputs will be 0 because they are
independent variables they're not
dependent on each other so you just do
that and you run this forward
run in the end at each stage you get the
value that it will be the derivative of
that intermediate value with respect to
the variable of differentiation that you
selected and you just run your algorithm
forward and in the end you get the
derivative value and the original value
together so this is the the way it works
basically
uh-huh so there is this other mod called
the reverse mode so two reasons
you need Cali to do this is the Delta to
respect to x1 you need a separate column
fill result derivative with respect to s
2 you know oh yeah yeah if you want okay
if you want this example is just for
computing the derivative of Y with
respect to X bar yeah just just one so
if you have a function of many inputs
and one output if you want to the
gradient of that function you will have
to run this forward mode several types
for each of these input variables so and
this is why we have the reverse mode so
the reverse mode is the opposite of this
so I'm going to come to that so reverse
spot is the actually if I should tell
you if you know the mathematics behind
the back propagation algorithm for
neural networks you already know the
reverse mode they are very related
because back propagation is just a
special case of reverse mostly automatic
differentiation they both trace their
origins to the same papers in nineteen
sixties and seventies but for some
reason these communities the automatic
differentiation community and the
machine learning community today managed
to stay disconnected and if you ask
somebody back propagation is very famous
but if you ask Tom do you know anything
about automatic differentiation they
will probably not know know about
reverse mode automatic differentiation
so in the reverse mode so ok let's use
the same exam the same function that we
used as an example before so this time
we are propagating derivatives from the
dependent variables in the direction of
the independent variables that is from
the up towards thing but so this is the
reason it is called the reverse mode and
it is it is done in two stages in the
first stage you run your original
algorithm forward you compete all these
intermediate values then you select one
of your outputs as the dependent
variable
this way YJ and you again all been told
in intermediate values but this time the
the components the Augmented compound
stick they don't correspond to the
derivative of that with respect to one
of the inputs it's this time it
corresponds to the derivative of your
dependent variable at the output with
respect to that intermediate value that
you are considering and this is called
an adjoint
so you have all these adjoint components
for all the intermediate values and you
will start by setting the adjoint of
your dependent output to one and you run
the algorithm backward so this
propagates all the derivatives
backward towards the inputs and you you
end up with something that looks like
this so the the evaluation trace on the
left is exactly the same with the
forward mode so you run this forward you
get your you populate all the original
values of your intermediate in variables
so you get your output once you are done
with that you start by setting the
adjoint of of the dependent variable to
one and you start propagating this
adjoint values backward so at each stage
for example this represents the
derivative of your dependent variable
with respect to that intermediate
variable like the partial derivative at
that point and if you continue running
this backward all the way to the inputs
you end up with the adjoint of your
inputs and for example in this case the
adjoint of x1 it means the partial
derivative of Y with respect to x1 the
adjoint of x2 is the partial derivative
of Y with respect to X 2 so as you can
see with the reverse or chicken if you
have a function with one output in one
reverse flip you compute all these items
and you complete the partial derivatives
of that output with respect to all your
in just one application so and this is
this is exactly the way back propagation
works for in neural networks so forward
versus reverse if you talk about the
extreme cases like if you have a
function of just one input and many
outputs forward mod is the good thing is
the best thing for that because with the
forward mode if you have just one input
you can run the forward mode and you get
the derivatives of all their outputs
with respect to that one input in the
other extreme if you have a scalar
function of many variables and this is
very common in machine learning it's
seen everywhere in machine learn with
reverse mode you can get all the full
gradient of that function with respect
to all the inputs it in just one
application of the reverse mode in
general if you have a function with an
input
a map to complete the full Jacobian
which is the derivative of all the
artists with respect to all the inputs
it will take n times the time it takes
for you to evaluate the origin a
function with the forward mode and if
you use reverse mode the text M times
the original time it takes for the
Fourier for your original function so it
means your mode is better if you have a
function that many inputs none and not
so many outputs so this is like the big
picture of selecting forward versus
reverse mode so it is already used in
lots of fields like it's it's very
heavily used in computational fluid
dynamics for simulations it's used in
atmospheric sciences nuclear simulations
engineering design optimization but for
some reason it's not very well known
within the machine learning community
and this is the reason why we are trying
to work on from the machine learning
perspective so how can this impact
machine art at this point I have to talk
to you briefly about the sharp which the
sharp is an automatic differentiation
library we implement an F sharp and this
is the address of the website we have
very detailed documentation and we have
the benchmarking tool we have a full API
of all the derivative operations that
you can imagine for scalar functions
vector functions we have several
implementations of 84 different usage
cases we have a forward and reverse mode
working we also have implementations of
symbolic on America's depreciation
mostly for measuring the performance of
this against automatic differentiation
so I would very happy if you go there to
check it if you if you are interested in
automatic differentiation
also because we are trying to do this
for machine learning we have example
machine learning applications and we
show them how you can use ad for this
application
we have gradient descent instance method
stochastic gradient descent we have a
clustering using automatic
differentiation we have k-means
clustering algorithm we have Hamiltonian
monte carlo using automatic
differentiation neural network examples
and we have in North America so these
are all on the website you can just try
them in on your computer so let's look
at gradient descent so you have a scalar
function of an input it's just basic
gradient is on this is all the text for
you to implement gradient descent in a
functional language with AD capabilities
F sharp so the thing you see there this
grad grad effects that is how you put
automatic differentiation in your
algorithm you don't worry about anything
else so this thing takes any function
any scalar function of many puts is a
parameter and you just apply your
function you don't need to worry about
the derivatives you don't need to worry
about the form of your function it can
you can implement it any way you want on
you just trust ad library to take care
of the derivatives for you it's better
than that because you can get some
complexity guarantees with automatic
differentiation and it's one of the
biggest advantages of this what we mean
by this is for example for if you are
computing a gradient with the reverse
mode the time it can take for you to
find the gradient of this function it
can't be more than a small constant
multiple of the term for you to run your
original function there is a theoretical
limit and it's explained by grievant and
walter so you can check that so I have
some benchmark results here with my
implementation so here you see the we
have this thing called the ham pulse
energy function is used in the ad
literature for benchmarking because this
is a scalar function of a vector and you
can try it with different dimensions to
see how your
have your performance case with the
number of input so it's used for that
for benchmarking so here in this table
and in this graph you see the time it
takes for you to have a little function
it is a function of the number of inputs
you have reverse move down forward mode
so I will just tell you the good thing
directly so all these values you see in
the table that they are given relative
to the time it takes for you to eval it
the original function with just one
input so you see in the last row here to
compute the gradient of the function
with reverse most automatic
differentiation you get a factor of
around 2 and it seems to be independent
as you expect from turrets it seems to
be independent from the number of inputs
you have like so it's like a linear
function of the time it takes you to
evaluate the original function so it's a
good property you can have that complex
to guarantee for you but if you look at
something like numerical differentiation
you can see that it's exponential just
balanced it's not exact it's just an
approximation and it has very poor
performance forward mode is of course
better than numerical differentiation
but if you remember forward what is not
a very good choice for this case because
you have a scalar function of minimes so
reverse mode is the way to go they are
three okay you can go to this address
you can you can run this benchmark there
is the benchmarking code there's all the
things you need for experimenting with
this type of thing with the ad police
substantial program transformation
particularly for reversal yeah there are
several ways of with a lightweight
without getting a high-water function
and I'm passing
all you have is that pointer to the
function closure yes very clever so
there are several ways it's not in this
top in a tu you can have overloading
operator or loading this is the way we
do it because it's the simplest way you
can I start to beat up
so you just overload do you have a new
numeric type it's called the dual
numbers for forward for a forward month
I haven't mentioned that so you have a
dual number type you do you do the
operations with the student number type
and it has overloaded operations which
also computes the derivatives for ya for
Reverse we also do it with overloading
so you if you remember in the reverse
but you have to first run it forward in
the first stage so when you are doing
this forward sweep with the overloaded
operations it takes it has a stack of
operations it puts everything on top of
the stack so it keeps a stack of all the
operations and once once you called the
reverse stage it pops these things back
from the stack and it calculates the
adjuncts it just propagates the entries
backward turn with it works so it's the
simplest way you can implement but in in
AD there are many methods other methods
there is a source code transformation
tools so for Fortran for C this is
actually what is used for
high-performance up applications like so
no I don't have source transformation
yet but I'm working on that because F
sharp is very good for for this because
you can have cold quotations like
expression 3 it's very good I'm
experimenting with done but it's not
really for released yet so you can also
do
source code yes yes so but people in for
example the in clear simulations there
there is an ad group in Argonne National
Laboratory in the United States they do
nuclear things they use C as far as I
know and they just have a tool they give
the C source code of their original
simulation and the tool gives them
another source code file with the
transform program so there's also that
is one way you can do that without
operator overloading
okay so we have an example of stacked
stochastic rating some so you have a
function of n variables and M and inputs
and M outputs so this is how you
implement stochastic gradient descent
here the way I do is okay it's not very
important but the way I do it is this
function f that you asked to begin and
here this w vector the parameter
parameters of your model function they
correspond to okay it's actually in the
next slide so so okay this
so let's come to that so I used to
castigating the sound for implementing
k-means clustering okay this is done in
the torture so the way I do this is I
have this model function that I distinct
I call model function and the parameter
W here is just the current catenation of
two vectors of your means like the
coordinate of your means you just put
them into a big factor you supply that
as a as an input to your loss function
evaluation and something like that and
so you just you can just apply this to
stochastic gradient descent algorithm it
works beautifully and people haven't
done this with the 20 differentiation
but we have it on the website there are
papers using stochastic gradient descent
for clustering but they don't do it with
automatic differentiation because they
have to have a closed form of something
to define the gradient of that so the
beautiful thing here is for example this
is all the k-means algorithm I
implemented in F sharp yeah okay we
don't have to talk about this but I when
I was doing this I was completely free
to implement it the way I want like I
just implement dessert complicated
algorithm it is it is a complex
procedure it has stopped procedures it
does it in function calls whatever you
want like you can write a regular
algorithm so automatic different
takes care of everything on it computes
the derivative of the whole k-means
procedure that you are writing you're
effectively writing this out over jewel
numbers instead of numbers
yes the way I - dot yeah you can do that
but you can have generic functions
that's this more useful yes yes but I
I'm also experimenting with another
thing that takes the floating float
fortune look and we can use expression
trees like if you have a quotation of
the tycoon just rip go in there I can
replace all the instances of what we do
so I can I'm trying to make that
completely transparent to the user so
they don't have to worry about the dual
type so but that's the next step but the
easiest way to do it now is to write
generic functions because you can use
the the dual run for optimization that
you can use the optimized function with
other numeric types so this is the way
we do that so ad takes the derivative of
the whole k-means procedure and it is
designed as an algorithm it done it
doesn't have a closed form formula so
these are just some results like
stochastic gradient descent is a very
good thing here if you have a if you
have large-scale later because it's it
doesn't depend on the size of your data
set so it's just something to think
about and I also forgot to tell you so
all these examples I'm showing you here
the code for done and the way they work
on the way we implemented it they are
very well documented if you go there you
can just try not you can you can
experiment the time you can see how they
work so we have a Hamiltonian Monte
Carlo with automatic differentiation so
the thing in Hana Tony in Monte Carlo
it's a it's a very good usage case for
automatic differentiation because you
have gradients of course so what you do
here is you have Hamiltonian mechanics
described by these two functions so it's
like you you have the momentum as a funk
of time and you have the position of it
of the system as a function of time and
so you have some kind of discrete-time
integration procedure this is called
leapfrog school it's very commonly used
in heaven Tony in Monte Carlo so you
have this time integration model which
means the gradients of two functions the
gradient of potential energy function
and the gradient of kinetic energy
function kinetic energy is a function of
momentum and potential energy is a
function of position so this is how we
implement the leap frogging using an
automatic differentiation you do that
and the idea behind hamiltonian monte
carlos if you give the minus logarithm
of a density function as your potential
potential energy and you use the kinetic
energy function like it's typically used
as the classical kinetic energy function
is used commonly you run the hamiltonian
dynamics with these functions and this
gives you something that explores the
that that explores the function the
dance space and it gives you samples
from the distribution that is that is
defined by the by the function you
supply the danced function so this is so
normally the way you will do this in
hamiltonian monte carlo you are required
to sit down and have an expression for
the gradient of the minus logarithm of
your target tells the function this is
needed for running this procedure but in
this case you can just supply anything
you want there is the distribution and
for example here I have multivariate
normal normal distribution this is like
a generic code which runs with and in
dimension like all these things you see
are vectors matrices so it's not it's
not one distribution case that you that
to some particular applications generic
and I just show an example here with for
the bivariate case like it's a bivariate
distribution with 0.8 correlation so the
thing here is a detects the gradient of
any function U passes a parameter and it
is applicable to complex density
functions this is very important because
you can have danced the functions before
which you can you can't even define
closed-form expressions for the gradient
you can you can have algorithmic
descriptions of your target density so
it's so it's a very good thing for
hamiltonian Monte Carlo there is another
thing which is a nesting of automatic
differentiation and this is about taking
derivatives of functions that also take
derivatives so what we mean by that is
using this method you can use you can
have functions that are using
derivatives internally without the
colors knowledge and you just forget
about that and you can the
differentiation is completely internal
to your optimization procedure and you
can nest things many levels deep with
referential transparency so you can
write things like let's say you are
using egg gradient based method for
finding the minimum of some function you
can find that me know you can use that
in another function that is doing
something with that value you can again
find the minimum of this other function
again with the gradient based
minimization procedure so the
theoretical work for this is in place in
this article and others and there are
also working implementations there is a
it is working scheme there is this thing
called the Stalingrad compiler and we
are currently working on that for
discharge as well in F sharp so that's
that's something else so we can talk
about game theory
it's a it's a good application for this
I believe so in game theory you have
this subfield called computational game
theory you can have you can have agents
using gradient based techniques for
adjusting their policy you can have a
expected payoff value and you can take
the gradient of that with respect to
some policy parameter that that
represents the way you have you are
behaving in the game so you can write
things like you are adjusting the policy
parameter using some something that
looks like rating to some degree in
essence here you do take the derivatives
of the expected payoff with respect to
your policy parameter so in this type of
situation so you can have an opponent
you can have a mental model of your
opponent so you can you can use gradient
based method for deciding your behavior
in the game while you are doing that
because the your expected payoff also
depends on the behavior of your opponent
if you are doing a rational method you
also have to consider the ways your
opponent is going to behave in the game
so if you have nesting you can also
model the behavior of the opponent using
a similar gradient based procedure and
you can you can for example write things
like that you can find your optimal
behavior in the gap by considering
different behaviors and for each
behavior you are considering you can
consider the behavior of your agent of
your opponent who is going to observe
your behavior and behavior according to
that so you can have this nested things
so I think this is a good application
for nested automatic differentiation and
there a very important area we can use
this is a hyper parameter optimization
so you can have ad providing you hyper
gradients of gradient descent based
machine learning algorithms so a way to
talk about this is like is the gradient
based optimization of gradient based of
musician so it is already considered
this is a very new paper it's just on
archive writing for for a month so they
have a very good discussion of this and
they also make reference to automatic
differentiation so you can have this
type of hyper hyper gradients in biasing
model selection you can have gradient
based tuning of biasing networks you can
have gradient based tuning of the model
parameters of Hamiltonian Montecarlo so
if you have a D you can have very nice
representations implementations of this
type of stuff so this brings me to the
summary and so in most cases automatic
differentiation is superior to symbolic
and numerical alternatives it is
applicable to algorithms is not just
applied to functions in the mathematical
sense it makes implementations very
succinct and very easy to maintain and
we think that it can have a big impact
in machine learning so yep this
concludes my talk on I already have to
take questions thank we've got some gaps
in the schedule in the rest of the day a
couple of gaps so if anyone would like
to dig into any of this they can I'm
sure he'd be more than glad to like to
hands-on session with the actual dish
shop library he's got Visual Studio and
F sharp interactive and you can sit down
and and just like play with it with and
of course the yes the have you got the
latest copy of the paper another you
will there's a link on the website on
your website there's the paper which is
the overview of ID in machine learning
so let's take a couple of questions do
anyone
learning it kind of seems to me that
people are using this although they've
liked tools so could you tell me think
about piano and standard so I understand
they might not be as general but can you
help me sort of understand what the gap
is in with it yes you is a way of using
automatic differentiation I think it
works by source transformation somehow I
don't exactly know how it works but
reverses it backwards which is certainly
okay you can say people use TNI
they use automatic depreciation as I
understand TM is the more general tool
that it's not just for it it does more
stuff right thing I I'm not very
familiar with the part of the tool that
is sort of tuned there's a use case of
neural networks where they compile down
to GPUs and it seems to me like it it
yeah it is used quite heavily in machine
learning so I'm trying to understand
what's like what I'm trying to
understand your claim that ad has this
potential to ship things more well I
think it's it's it's some attitude like
because I I'm compiling a list of
automatic differentiation libraries that
can be use for machine learning
I have Python libraries of course but
the thing is I think they don't discuss
these things like we do they don't point
out that you can you are not limited to
mathematical expressions like okay if
you are implementing something that
looks like back propagation okay that's
not an expression but the thing is you
are you are free to take derivatives of
your algorithms like I don't know it's
not something I have I have seen in
literature not so much it's like you you
if you talk about implementations from
the implementation perspective people
who use TLS disk or I don't know the
date I don't think they pay much
attention to the differentiation part oh
all of them to give a different answer
which is you've given it's a quantified
thing you've given an existence proof of
the use of image of ordinary
differential differentiation but I think
who knows you're saying for all people
everyone should be using automated
differentiation which of course is also
add another extreme but I think it's
really a matter of degree and
dissemination of the techniques into
beyond the neural network case as well
so I bet anyway you can discuss that
further about how far and where the
limits are I think that's actually it I
mean yes it gets used but the question
is how much more application does it
have and how widespread should the
knowledge knowledge and techniques be I
think it's a matter of degree so next
question similar to our is trying to
find is a general-purpose ad framework
so I can write any algorithm in some
easy way and it figures out all the
derivatives of which something like back
propagation foreigner like this is just
one instance um but I mean I know I mean
it seems to me that that's always going
to be far less efficient at scale for
you know to build a general tool like
that and so in practice wouldn't this
only ever really be used for prototyping
wouldn't people then come up with a
specialized domain-specific solution
like back proper neuro-networks which we
can be computed efficiently on
specialized hardware is over those long
yeah but if you talk about back
procreation its domain-specific but it's
exactly the same the thing you get from
it is exactly the same respect
propagation so it's not you don't have
an advantage it's like something that's
specifically for background it's
probably orders of magnitude faster than
if I implement it back route algorithm
in something like this shot so I I
believe that's not correct
so the thing the way it works is it
gives you exactly the same like
computation that that is happening on
back propagation if you do it with my
library it's going to be the exactly the
same set of operations that are going
like I have it on website I have the
back propagation algorithm at this we
have benchmarks so I don't know the ad
people they really trust that the
performance of that of theory of their
methods so you can have you have the
benchmarks I think it looks good but you
can that to a degree the thing you say
is through you can use this for
what was it you can use this for test in
your case like prototyping and you can
you can done you can use maybe a source
transformation type of method to get the
thing transformed that that you are
going to use your in your final eventual
application sort of you can say so and I
think the question would also why
wouldn't that be the case in those other
more established scientific domains
which already use the ad techniques
appropriately with perhaps GPU
implementations and other things under
the hood so I guess I would idea I might
be driving density functions from a
model would you get that plug into MC MC
sampler and be quite nice to actually
combine that and then the Hamiltonians
using quotation so you tomorrow there is
a very good chance that you can just
plug your function into that that the
code I have on that back page you can
just experiment it that's where we can
we can talk about okay I haven't been
checking the time but if you have one
more question and then any any more
questions
when will you know what is this well if
you are trying to find an analytical
solution to a problem like you can just
compute the analytical derivative you
can maybe say the derivative is equal to
zero you can have an analytical solution
to your problem then you don't need you
want you wouldn't need two great
derivatives at all so you can you can be
after analytical solutions it can happen
sometimes you can be after proving the
complexity properties of your model so
you need mathematical stuff for doing
that but this thing is for competing the
values of derivatives for for
optimization
I think the operational thing there are
highly optimized like GPU
implementations of some of solve many of
these algorithms so for where the more
general framework doesn't yet support
like the compilation down to the
particular target hardware in an
optimized way or something so there are
definitely operational reasons yeah okay
thanks and if anyone would like to maybe
seen this describe us after the talk
Thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>