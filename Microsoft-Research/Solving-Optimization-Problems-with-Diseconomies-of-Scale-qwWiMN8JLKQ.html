<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Solving Optimization Problems with Diseconomies of Scale | Coder Coacher - Coaching Coders</title><meta content="Solving Optimization Problems with Diseconomies of Scale - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Solving Optimization Problems with Diseconomies of Scale</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qwWiMN8JLKQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright so good afternoon everyone we're
very happy to have our very own costume
McCurry chip tell us about solving
optimization problems using the coupling
okay something happened okay yeah so so
so I've alto yeah tell you about solving
optimization problems is diseconomies of
scale while decoupling this joint work
with a maximally genka from yahoo labs
and this paper from fox 2014 so i have
them sort of two versions of this talk
one of them is more rhythmic and another
one is more very probabilistic sort of
and here I highlighted avert decoupling
because this is a more probabilistic
point of view I will talk more about
probability involved in our algorithm
and but let me start with it just define
what problems is the economy of scale
are and why they're important and maybe
many of you heard before about problems
with economy of scale so typically when
you buy resources you pay the price
which is linear as the amount of
resources used in some cases of course
you may get a discount right if you buy
more resources you get some discount you
play with but it turns out that in some
interesting cases the price goes super
linear way so if you buy twice as many
resources you pay more than twice the
amount of money and sort of the typical
and the most important example for it is
the cost of energy used for computing so
if you double the speed of processor
then usually the speed so the energy
used by the processor will more than
double so this dependency of the speed
of a processor or other hardware and the
speed sorry in the amount of electricity
used is typically it's quite complex but
it is usually a modeled as some function
X to the power of Q where Q is between
one and three
and this this Q is really dependent on
the piece of hardware even for different
intel processors this Q is different and
this this model er indeed suggested a
lot in the literature so this is sort of
the best way to model energy use of
processor and one set of simple simple
ways of course there are more like it I
don't know somehow it upon depends on
the electronics use there yeah but let's
throw that the typically if you want a
yoga your battery to last longer you
don't want to compute something to too
fast and this is indeed even I mean this
is used a lot in practice in the pure
radiant systems and in Windows even
though maybe the models use their i will
do a little more precise and so are we
propose some framework to solving
problems with this economy of scale
where the objective is a convex function
of the amount of resources used so we
apply it for for quite a few different
problems of a scheduling
energy-efficient scheduling energy
efficient routing and other problems are
here I will show you the most basic
example which is a I energy efficient
routing so what is this problem we have
a graph gene and you have demand pairs
SI TI di so si is the source guy is the
sink and we want to route SI units of
flow from si tu di GI via a single path
another way of saying if we won't want
to rowdy I units of unsuitable flow flow
from si tu di I think of this flow is
being some information sent and we want
really sent all the information from one
source to the corresponding think why a
single path this is often necessary in
practice this is a classical comunitario
optimization a problem it was
studied a lot what's new about this
problem is the objective function so we
want to minimize the energy use use by
by this routing and for every edge in
let's denote but by X sub e the amount
of flow router divide that age then if
you say that the energy consumed by that
age is X abhi to the power of you and so
the 10 total energy used is sum over all
ages siiii x XE to the power of you so
this is all model questions so far and
see some some just consuming some
constant it is part of the problem here
so some mages can can maybe have
different whatever not resistance but
different when some some some different
parameters depending maybe on the length
of the link so edges in this graph sort
of correspond to to link in the actual
network of course the problem is quite
quite theoretical approximation of what
happens in practice and one example here
if you want to route this purple flow
from this vertex to this vertex and from
this yellow vertex to this yellow vertex
we can find for example air out in like
this and like like that then we will
have for ages V is load one and it means
that for this objective function if all
c is equal to one actually five right I
think whatever just 55 x 1 to the power
of you and two ages have load of to it
it is another 2 times 2 to the Q so the
Ted this is a total energy consumed by
this rounding so what is known about
this problem this problem was introduced
by andres fernandez Aunt Jean and shout
and they gave an approximation
algorithms that linear approximation
ratio depends linearly on the number of
them
the number of source sync pairs and
logarithmic lee on the maximum demand
this de max if all it demands at the
same then the same authors gave a
constant factor approximation and a bump
is gone enough lettuce lucarelli and Sri
Lanka for this special key where all
demands are the same give p to the q
approximation and here p is the Poisson
a variable with parameter 1 so this is a
cute moment of the Poisson random
variable this parameter one of what we
get in this paper we generalized a
result for our be 3d eyes and be in
general introduces framework which I can
be used for many are the different
problems so what okay this a pit of the
power of cumin may look mysterious so I
plotted it in the most interesting
regime for our algorithm the most
interesting regional is when q is
between one and two because maybe 4 q's
greater than to you can do bear better
using or some other techniques and in
this case so this is the plot of qs
moment of the poisson random variable
disease to hear that it is a convex
function and at one it is equal to one
at week it is equal to two so it is
always strictly less than Q so
particularly get Q approximation if Q is
between one and two okay just any
questions about the problem so how does
it does it relate it all to the
combination to estrogen pause to what
edge disjoint paths maybe maybe you can
think of it as some kind of relaxation
of that problem right so you can reuse
the same age but then you pay pay a
penalty yeah okay if you tends to
infinity maybe it becomes the same
problem okay but again I'm not not sure
it needs to be checked and of course if
you is a delight that this approximation
is not particularly good I don't know
whether you can
recover some some reasonable
approximation using the schema probably
not just certainly a suboptimal okay
what is it how do you solve this problem
there is a standard LP relaxation for
routing unsplit double multi-commodity
floor so let this calligraphic PIB the
set of all paths going from si tu ti and
for every path going from si tu che we
introduce a variable lambda P which
tells us how much flow is routed via
this path P so the constraints we have
is that if you sum over all pairs going
from si tu si tu ti the amount of flow
routed via those paths is equal to G I
that's our requirement and all lambda
peers are ends range from 0 to GI of
course if it was an integral problem
problem then all lambda peers would be
i0 oil eyes but we relax the problem and
this relaxation as is has exponentially
many variables but this relaxation is
very standard and there is a way to
write this relaxation in a slightly
different form which has polynomial
mania variable so we will note this
issue and I we denote by capital lambda
the polytope of this variables lambda
Ceti and now we need to write the
objective function and that's the
interesting part of this relaxation and
the most natural way of writing this
realization is as follows if we just
write it as if we want to minimize sum
over all ages e te times the amount of
law routed via this age ii according to
the linear program to the power of p the
good news that this objective function
is convex and therefore this problem is
solvable in linear time so we could
control it and you may think that this
is it we are done we we solve the
problem but unfortunately this rotation
case
really bad integrality gap and to see it
consider the following example suppose
we have just one source inc pair and we
want to route one unit flow from this
vertex to this vertex but this two
vertices are connected is n different
disjoint paths legs it's right then one
possible solution is to assign one over
N to F to every path so these are paths
right we can assign wait 1 over N to old
path and route flow flow as follows now
when we compute the the energy you
according to our objective functional p
function I will get the total and paths
for every age we get the contribution of
1 over N squared so the total cost is 2
over n 2 because every path has two ages
but of course any integral solution
route all flow by a single path so the
optimal solution has cost two and this
is a problem and we need to write a
different LP relaxation for for the
problem but so let's see what what is
the problem is it a problem problem
visas relaxation without variables with
our objective function so it's common to
interpret linear programs
probabilistically so linear programs
give us some distribution of the
solutions in fact they don't quite give
us distribution but they kind of hint us
which should be very distribution right
and so this our solution tell us that we
need to pick one of this path with
probability 1 over N and this is a very
reasonable thing to do indeed all these
paths are good and I are good so they
have all of them optimal solution and so
this distribution of pests is indeed
sort of an optimal solution so PR tells
us the truth it doesn't cheat it just
somehow the objective function computer
here is wrong we and it means that video
I keep
the realization as this but we replace
this objective function with something
different so let's look at a single edge
let's look at this age and what do you
know we know that there is some
distribution of path through which via
Route flow from what source to think and
this age is used this probability 1 over
N what is the energy consumption
expected energy consumption for the
stage and it's clear that the answer is
1 over N right because when it is the
flow is routed via this age the energy
consumption is one and when it's not is
0 and so let's try to generalize a set
of this intuition for for for for a
general graph so what we'll do we'll
keep our relaxation is is so lambdas are
going to be as before the same lambdas
the same constraint but we will replace
the objective function again so we will
compute the energy consumption for every
age individually and then sum up all
these energy consumptions and the energy
consumption for a niche is going to be a
lower bound on the energy consumption
possible for the stage essentially we
will assume that the flow is routed in
the optimal way for that particular age
so that the energy conception
consumption for that age is minimum and
we will use that number instead of what
you had before some of this lambda i's
to the power lambda pistol to the power
of Q so in other words what we are going
to do we set this function f sub QE that
really depends on the age eel as minimum
overall distribution de distribute off
so why why is why is the vector of what
y 1 etcetera why I dia y y so what's the
number yaaay k is a number of demands
some of my eyes to the part of you
and so why I is the random variable that
tells us how much flaw is routed from
the source aside to the sink TI right
so--okay so these are requirements on
this distribution first of all this
distribution should be sort of every why
I and this distribution should be a
Bernoulli random variable or maybe a
scale Bernoulli random variable so it
should only take value 0 and di then the
expected value of y I should be equal to
the amount of law routed from a sight to
see I according to the linear relaxation
to the old p.m. so this should be true
and particularly this equation of course
tells us what's the probability that Y i
equals to G I and what's the probability
that y equals to 0 and here and then are
essentially we know all marginal
distribution and we've only don't know
how what the joint distribution of Y
eyes and we want to find this out what
the optimal distribution and then the
users f fq e as a proxy for the amount
of energy used by that edge you again so
it's not quite clear why we can compute
f QE it is possible to write a linear
program which will again use exponential
amania variables but it turns out that
it's not too hard to solve this LP a
problem almost exactly up to a factor 1
plus epsilon and since this talk is
based more on on the probabilistic part
of our if I will I will skip I won't
tell you how to solve this LP
delectation it's not particularly hard
it's possible so we can in fact compute
this SQ is in polynomial time and this
functions F Q is are convex and
therefore we can solve this optimization
problem ok so right what do we get
we we got the solution lambda peace and
for every age we have a distribution of
Y eyes which is the best for that
particular age unfortunately we don't
have a global of distribution of ages of
paths right so for for one path you may
use also develop for 1h view VV may use
one collection of paths to route the
flow for another age you may use a
completely different collection of paths
and this is unfortunate otherwise you
would get just exact solution for the
problem so we can't rely on those wide
eyes or for rounding purposes and that's
why we use the most basic algorithm you
can imagine tore out the floor also for
every SATA pair you'll take a pass p
this probability lambda P lambda P is
scaled bye-bye dear so lambda P was the
amount of loss so lambda P over di is
the probability that we use path P so
that's how algorithm right so all lambda
piece that go from 40 of opacity going
from siu gie some up to 2 g.i so if you
normalize lambda P by Jerry we get a
probability probability distribution and
this is algorithm me use that's it the
algorithm is simple based on this the
church of them the p what's important
was used on this minimization criteria
right so if you use the different
function the original function that the
solution would be also feasible but it
would be completely different uh
provided right okay so the algorithm is
easy now we need to to analyze and let's
say that X I is the amount of law routed
from si tu ti according to our algorithm
by H E so what we will do will compare
the cost our elder if the expected cost
our algorithm pays to the lp value H by
H so for every let's fix one edge and
let's define random variable so X I is
the amount of flow routed from a site to
GI via our age
II this there again sort of Bernoulli
random variable it's I z0 or GI and just
by the construction all excise are
independent and the cost algorithm pays
for this age is the c e times sum over i
excite to the power of you so this is
either the excited attendant evo just
procedure yeah excise d yeah well let's
fix one edge and look at age by age ok
so the expected cost of the algorithm
for that particular age is expectation
she times the sum of excise to the power
of you and now for this particular age
we had y i's right again all what why is
it different for different ages but now
we fix one particular age and they'll be
cost is equal to the expected number see
a times some of our iyi to the power of
q and we now need somehow to compare
this two quantities and just by the
construction why I has the same
distribution as XY XY so pairwise sort
of X I has the same distribution as why
I again this is a very simple Bernoulli
random variable kid he can value 0 mg I
the difference is that all excise are
independent and why eyes are generally
not independent and so we need to
compare somehow these two quantities and
it turns out that there is a decoupling
equal to do to della penna from nineteen
nineteen and it sells the fallen so
suppose you have a random variables y1
etcetera YN that's jointly distributed
and what's important this random
variables are non-negative and x 1
etcetera xn are independent non-negative
random variable such that X I and X I
has the same distribution as why I again
excise are independent wise y i's are
independent of course if we chose why I
somehow to minimize it the juice moment
of the farm so the q's moment of the
summer for a why ice can be less than
the cuse moment for the sum of
sighs but the apologist says that it can
be too much smaller in other words the
cuse youth norm of X 1 plus etcetera xn
is less than some constant C Q times the
sum of the accused norm of the sum of Y
eyes okay and so this in the quote
immediately tells us that the
approximation reach approximation
algorithm we get has a constant
approximation factor you may be
interested okay what is the constant so
in a subsequent work adela pen ibrahim
of and track metaph showed that she cute
of the part of hue which is really in
the cube what we need the cuse power of
this expression is less than 24 q isn't
between one and two and it is peace a
syracuse moment of force on random
variable with parameter 1 4 q greater
than 2 so these are the bounds again
somehow for us the most interested in
regime is when q is between one and two
particularly because maybe independent
rounding is not the best thing to do if
you slide if this function is grows too
fast so we already get to 22
approximation from this and then we
improved this bound to Peter tube into
extended at the boundary head for Q
greater than 24 all queues so for any Q
greater than one and one inclusion one
if you prove that c to the power of q
equal to the norm of poisson random
variable with parameter 1 to the power
of you and so this is the result and
today i will show you the proof and
before that maybe I remind you some of
some of you what the Poisson
distribution is I was asked to do this
before this is the first definition it
is really easy but maybe not to
intuitive so person variable takes
values from 0 to infinity integral
values from 0 to infinity and the
probability that p equals to k is lambda
to the power of K times e to the power
minus lambda divided by K factorial
what's important here was that for us
for the future that our ports on random
variable takes only integral values and
kind of a more natural definition in a
way follows from the Boston limit
theorem so imagine that we have a large
universe of capital and points and n is
very large and we pick every every point
here this probability lambda over
capital n so the number of points chosen
is a value of this Poisson random
variable so for example maybe in this
case we pick two vertices with some
probability and it means that the value
of the Poisson random variable equals
two in this case you know it's also easy
to see from this definition that the
expectation of P lambda is equal to
lambda ok so what is them how do we
prove the stadium a roughly speaking the
massage all excise and white eyes and
transform them to do Poisson random
variables and so we got this proof when
we submit a differ the paper first and
it was it was correct but it was also a
bit messy and so the idea like that to
simplify the probe maybe we need a
different language we got the skin from
from the wall street journal as you see
here and indeed we look for a different
language and we founded and this
language of convex the highest tech
orders which which I found quite
interesting and so I'll tell you about
this language now so this is some some
kind of G to or fro from from the
problem from that inequality so let's
say that X is less than Y in the convex
the highest decoder if for every convex
function Phi the expected value of e so
expected value of Phi of X is at most
expected value of 5y so this is
definition it looks quite natural even
though it has somewhat surprising
properties first of all it's easier to
share that this is indeed a partial
order right if X is less than Y and Y is
less than Z then X is less than Z in
this convex order it's this is this this
order is really a property of
distribution not particular random
variable so it doesn't depend how
specifically these variables are coupled
and for example is X is distributed the
same way is Z and X is less than Y then
of course g is less than Y as well ok
it's another it's true that X is less
than X it's it's it's also true even
though maybe not that easy to prove that
X is less than Y and Y is less than x
then x is equal to y almost surely but I
we want to use it here and they won't
prove it here ah the distribution is
right good exactly yeah because it can
be defined of person different
probability spaces that's very good then
then what's also true is that very scale
x and y if x is less than Y than alpha x
plus b is less than alpha y plus B and
particularly it says that if X is less
and why then minus X is less than Y in
this convex order which is a bit
counterintuitive but if you look at this
definition sort of it makes sense right
so it really doesn't matter what sort of
where they be change the sign or not and
what particularly it implies that the
expectation of x equals to the
expectation of Y there is a slightly
different notion where you can actually
increase Y and you'll still have X less
than Y but that's not this notion of
stochastic order yeah exactly
and another property okay which is
really not that important but will you
will use it here for simplicity the
three of course can always assume that
phi of 0 is equal to 0 so whenever what
I mean is whenever you want to check
where the X is less then why using this
definition we can always assume that 50
is equal to 0 just because you can
always shift our function by a constant
and both sides of this inequality will
shift by the same constant yeah if X is
less than Y then it's the expectation i
equal this just follows because if X is
less than Y it turns out that minus X is
also less than what wine is one CD is
less than minus y now if you pick the
function just to be identity you'll get
that the expectations like actually
equal and this is a bit counterintuitive
property as is but that's the case and
another definition equivalent definition
of is as follows again vehicle we are
not going to use this definition now but
I think it's very it really illustrates
well what this order means so if X is
less than Y then we can find the
coupling of these two random variables x
and y on the same probability space so
in any way we can find the one some some
random walk martingale and X is going to
be equal to the value of this random
work at some step in time tau 1 and y is
going to be equal to the value of this
random walk at time tau 2 so it's
possible to embed both of these random
variables to the Wiener process you can
also think of this a martingale just
being discrete random walk these two
these two steps if you want and it's
easy to see that this definition if you
have x and y defined like this than x is
less than Y this is really easy follows
from the Johnson inequality in the
opposite direction
it's not so easy I mean is it can be
proved but it's not so easy yeah but
this is maybe more natural even way to
define X less than equal to Y so it
really tells what what happens we first
moved to X and then somehow we
dissipated different direction and we
get Y equivalent to wait to say this is
that you can obtain X from Y by
condition advance and see what exactly
yeah also here so something I just
wanted to say something about the
condition without to etawah your tau 1
must be left out that's it yeah yeah the
tall one in other words expected value
of y given x is equal to x you can
couple again this distribution so that
expected value of y given x is equal to
X so this is a martingale sequence okay
and let's let's prove something
something very simple suppose you have a
Bernoulli random variable this parameter
P and the Poisson random variable again
this parameter P then b is less than P
in this convex order and particularly it
one property of course is already
satisfied the expectations are equal but
to prove it let's look a convex function
Phi and let's assume that 50 is the cool
20 we can always assume that so here is
the picture of a convex function Phi
look at a linear function that goes
through this point 0 0 and 1 1 1 is just
ok identity function ok no it's not 11
its a 50 51 151 it depends on four on
five ok and what is the expect a
expected value of files p it's greater
than expected value of this linear
functionals p why because the Porsche
random variable takes on the integral
values and so for all integral values
Phi of T is greater than L of T right
it's less only for fractional values in
between 0 and 1 so if you have this
inequality and of course for linear
functions we can interchange expectation
with this linear function so it's equal
to L of U of P which is just peel and
this is equal to linear function of this
I Bernoulli random variable and 44
Bernoulli random variables of course
they have just equality 40 for all
values that the Bernoulli random
variable takes right 40 and one so it's
expected value of L of B which is e of
files be so if we proved this and this
is this important for for for the later
proof and another very important lemma
which we simplify our proof is that if
you have three random variables X Y Z
and all of them let's say are
independent and assume that X is less
than Y in this convex order then X plus
Z is less than y plus Z and the prophets
is immediate so again we look at some
convex function Phi and you write that X
back to the value of x plus Z is equal
to the expectation over Z and here the
condition on G so a Phi off here I think
it's this should be an extra bracket
here it's a 5 of g plus x given Z and
now for free fixie of course Phi of Z
plus X is also convex function so we can
say that this is less than expected
value of Phi of Z plus y given G again
should be corrected here what's written
and this is equal to expected value of
Phi of y plus Z given Z
see you give uh ya know is in there yeah
no conditions right yeah and of course
there should be extra whatever brackets
whatever rockets another condition yeah
and there is no condition here right
good okay but anyway this is really
simple and then we can generalize it to
22 more random variables if you have
random variables X 1 etcetera xn that
independent and y 1 y and that they
independent and every exercise less than
Y I then we have that x1 plus etcetera
xn is less than y 1 plus y + + 2
probably just apply the previous lemma
one by one we fix all variables but one
and it plays X by Y so the propagation
is supplied we get this inequality
unfortunately as is it can be applied in
our kids because okay in our case X is I
independent but wise of course not
independent and now let me formulate
what we want to prove in this new
language of convex order so let's go
back to our decoupling equality so is
inequality we probe is as follows
suppose again that why one set of wire
and I jointly distributed non-negative
random variables and x1 it's a rec cen
time dependent quality of y 1 etcetera
YN so then the sum X 1 plus X n is less
in the convex order then the Poisson
random variable with parameter 1 times y
1 plus etcetera why an and this poor
some random variable should be
independent of wise it doesn't really
matter sort of what whether it depends
on x axis or not in fact in the proof if
you couple this poor sound random
variable this axis in certain way ok so
suppose we prove this nicole how do we
get the door open and equal with them
very easily because we write that
expected value of x 1 plus x n to the
power of q is less than just by the so
this function
g to the power of Q is convex so using
that X 1 plus X n is less than P times y
1 plus y n you're right that the
expected value of x 1 plus etcetera xn
to the power of q is less than expected
value of force one random variable x y1
plus that ry n to the power of q of
course p and why sigh independent joy
did you write this inequality in this
week and this is exactly what we want to
show and of course in general this new
quote is a little bit more general and
we can use we can prove inequalities
like this but for different functions
for other functions okay and now you may
ask why why Poisson random variable why
do we get Poisson random variable at 0
here and it's easier to see from the
tight keys so this this constantly this
show is India tight it can be improved
and here is just a very simple example
so let's take and random variables x1 xn
all of them my Bernoulli random
variables with parameter 1 over N and Y
1 etcetera y an i also a Bernoulli
random variable x they they they are not
independent moreover only one of them is
equal to 1 so essentially we pick just
one index I from from 1 to N and let why
I to be equal to one and all other why j
is equal to 0 so what we get is that at
the sum of x 1 plus etcetera xn is
approximately distributed the poisson
random variable and the sum of Y 1 plus
yn is off is equal to 1 so we get that x
1 plus the tarak-sin approximately
equals to P times y 1 plus etcetera YN
and of course we can't approve so we can
write that this is less than equal in
the convex order but we can't improve
this nick roach this is the optimal
involve you want such a little detail in
the lasagna also suggested if you think
of a fixed end
you can replace the person by binomial
and one over it I think you can maybe
yeah probably it did it I don't think
it's going to be a lot of huge kind of
improvement presence yeah and for large
AZ yeah the optimal for a chair okay
also now we need to prove this in a
quote and let's first look at some very
simple cases again 11 case we just seen
so let's look at this case again of what
what we thought we know that some of X 1
plus etcetera xn is less than plus so on
x y 1 plus y n where y eyes are just
like this and we can lower bound the sum
of x 1 plus extent by some of my eyes
again some of Y is equal just 21 and
again so 1 is less than some of X 1 plus
X sense particularly because the
expectation of this some excise is equal
to 1 so the most basic the most basic
case now can you make it a little bit
more interesting just slightly let's
first maybe we don't have to assume that
they're identically distributed but
let's say x1 xn are some Bernoulli
variables Y eyes are the same random
variables but somehow coupled between
each other so they have a joint
distribution and moreover let's assume
that some of Y is is equal is always
equal to one as before and it's it's
natural to think of why eyes is being
just indicated of some event so we are
one of the most is equal to one but at
most one so those events I just joined
and um we also have some constant alpha
1 etcetera alpha n that are non-negative
numbers so the Equality we prove is that
some of alpha i's why ice is less than
some of alpha i's exercise in the convex
order and this sum of alpha
size is less than Poisson random
variable x again some of alpha is why
eyes in the convex solar again if all
alphas are the same that's essentially
the same case as before maybe our we
don't assume here that excise have
social he excites can have different
distributions but that just not actually
important so so you may think that each
x i is equal to one sprint bill to one
over and almost without cranium loss of
generality the detection is very simple
okay so let's assume for a second that
we can generalize the previous argument
to this case and then i will show how
the general case follows from this and
then if i have time i will i will show
you how to prove this inequality as well
so let's go to the general keys and
let's look at this space of different
points so we have our vector y y1 etc YN
and so here of all possible outcomes of
this vector Y so this is a space of
small white y1 is at a white y and let's
write what the sum of Y Isis it is some
of us small small voice in this space x
they indicate a variable of capital y
equal to y and some times the sum of Y
is right so far this is just trivial
right if y Capital y equals 2y then of
course the sum of a capital y is equal
to the sum of a small Y eyes and
essentially we have this important
variable this characteristic vector a
characteristic study in the indicator
city educator variable oops
so they have these variables indicators
of events that y is equal to Y this
these indicator variables satisfy our
previous inequality so only one of these
indicator variables equal to one right
and so let's let let's define a new
variable dis apply this apply is a
Bernoulli random variable and the
probability that it is equal to one is
exactly the same as the probability that
this indicator variable equals to 1 this
are why here it's sort of this
distributed exactly the same but now
let's make all this B's independent in
other words are so the characteristic
sort of this indicator variable pics
only one vertex here right in this
universe and so let's allow to pick many
of them maybe visit same probabilities
elliptic one so we kind of decouple
these events instead of picking one
sometimes if you'll pick maybe two or
three and sometimes now and so now you
have device and we are going to compare
so this is for four quantities in a
moment and show that some of what what
why I is somehow here let's see what we
are going to do so as before you write
that some of Y is equal to the indicator
y equal to y times y I that's for one of
why I and X I is distributed the same
way as why I right so we have this X I
is equal to in distribution of some of a
small wise indicator y equals 2 y's time
the small why I and now we apply the
inequality they had before
so we replace dependent variables by
independent variables V sub y so we get
that in the context order every X is
leather sum over Y be y at x why I and
moreover so let make this device
dependent on I so in general it's also
in total you have many deer newly
variables be subway so for every i from
1 to N and for every small Y in our
space so okay because I call xij
independent and okay here we have index
I for every dy which makes all be DIYs
independent we get that sum over i
excite is less than the context address
of sum over i sum over why DIY why I and
this can be digital like this just we
switch the the summation and for if now
suppose we didn't have different so this
index I here so we have only be why then
we would write that sum over Y in the
space y VI why I device a is less than
Poisson random variable here we use the
other part of our inequality proved some
of a wine in the space summation Oh
again why I times the correct statistic
vector of y equals 2y right so he
replaces / this indicator variable of y
equals to y and we get what what we want
the only small caveat is that a here we
assume that they have different
variables d Y sub I and they independent
and here we replaced all of them by the
same
but ok so this is the only problem it's
easier to show that this inequality hold
for any variable beer this is just using
against nicole gym and this finishes the
proof yeah this is again this is hmm so
the last is body the silicon this what
can you go to the last riffa yeah so
right oh yeah so vm v iyer we are
independent cohesively yet the eyes an
independent corpuscles beer and then
actually i think it when it's not
important that they independent but they
are independent what we first of all
week and anomalies why is right we may
assume that Y eyes some of my eyes is
equal to 1 because if it's throw for for
those we can always risk you and now we
rewrite some of a few of semi why I bi
is it most some of over aye yie of fee
of bi and this is equal to now
expectation of again why I expected
value of V of B because b is a has the
same distribution as beer and now we
yeah we just regroup yeah I and
we yeah what sitting here is probably
not quite correct wait what's the role
no no okay you have to push the shaman
side up yeah yoga but Murphy you you
just you but pushing how did you get it
by outside but the equality is
already used isn't some of why I but
that's okay it but that's a key because
the thumb of Wyatt we assumed to be
equal to one so so the sum is equal to
one and we can write it in you know add
the Sun inside yeah if you don't assume
that it's normalized you should be a
little bit i mean just divide whatever
appropriate properly yeah okay so this
this this sort of a show prove this
lemma but what was important sort of in
this proof is really that yeah if you
looked at this we applied the previous
inequality to the elementary events here
or two to the indicators of this event
that why e equals the particular point
and everything kind of worked very well
ok now i can show you the proof of the
special case again it's very simple so
what we do is we prove we need to prove
to two inequalities the first one and
the second one the first one is
particularly simple so you assume that
phi is the convex function is 50 equal
to 0 then why is super additive so five
a plus b greater than Phi of a plus 5 SB
particularly a Phi of alpha 1 x1 plus
Delta alpha NX n is greater than Phi of
alpha 1 x 1 plus etcetera five ave n xn
and and on the other hand for this wise
we have sort of exact
quality because only one of them equals
to 1 because right and this this
finishes the proof in the in the
opposite direction V first I use the
fact that we just proved prove that
every X so every X is the Bernoulli
random variable so we can replace it by
a Poisson random variable that's what
we've seen as the first example of this
convex order so if we replace excise
this Poisson random variables having the
same expectation and now what we see is
that this Poisson random variable which
must be independent of why's it kind of
be have a dependent on this piece so if
you say that p is the sum of P 1 etc PPN
and then we just condition on p equals
to 2 some key so essentially we are we
can write here key and now if you have
this variables P I conditioned on their
total sum equal to K and somehow now the
left hand side and right cancer look
similar so on both sides we have
dependent random variables once we dip
conditions of the somme so the sum is
here is key of course here only one of
these variables equal to K on all others
a 0 and here's a SAM how smooth the sum
is also equal to 2 K but it is possible
that there are several nonzero entries
and we use just again against an
inequality so let's go maybe line by
line via yeah I don't know we just
rewrite our expression like like like
this first now this ti over k ik
efficient we think of the this P is over
k2 as being some some some coefficients
that sum up to 1 we use against
inequality here so we write some / PR
over K times Z of alpha K again
conditioned on p equals to k and now
what what's important is that this value
expected value of P I over K given that
p equals to K is easier to compute I
mean it is a known value so it is just
the expected value of pi and yeah and we
simplify the expression we get what what
we need yeah and that's a pretty pretty
much it okay so the conclusion that we
we gave this framework that can be used
again for energy minimization problems
it can also be used for various LP
minimization problem so if you want to
minimize out p norm and maybe minimizing
some other convex and maximizing concave
functions yeah and then we found the
exact constant in the lower panel
equality and generalize it to to kind of
convex and concave functions and they
would say an interesting question if
there are any other applications of this
Nickelodeon so that's it any questions
why is it died only for between wallet
too what's know the din equality is tied
for any Q the inequality but of course
you can you can use a different
algorithm you don't have to to round
everything independently if you do that
then this is tight but maybe you can you
can use potentially different to the
fish now you can try to yeah to use some
dependent rather than even the algorithm
you it's possible that you can improve
the algorithm for Q equal be between one
and two you don't know but the new coat
is tied for a for a particular but for
your own with civilization is tight Oh
for
question probably I need to double check
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>