<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microsoft Translator: Speech Translation Made Easy | Coder Coacher - Coaching Coders</title><meta content="Microsoft Translator: Speech Translation Made Easy - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microsoft Translator: Speech Translation Made Easy</b></h2><h5 class="post__date">2016-04-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4swsd1JHxhM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hi my name is Chris Lindh I'm the group
program manager for Microsoft translator
and I'm here with Kelly autumn also a
program manager on the translator team
we are here to talk about new
functionality for the Microsoft
translator service which offers you
speech translation close to real-time
this is the same service that is being
used by start translator used by
millions of people having translated
millions of conversations between two
people who do not speak the same
language well first go through a little
bit of basics then Kelly will walk us
through the code of an iOS application
using the speech translation service and
then we'll have a demo and a short
conversation of what what the service
does the Microsoft translator service
has been around for a while offering
text translation between 50 languages we
are now adding speech translation
functionality is offered as a streaming
service you feed it a stream of audio
and you receive the recognition and the
translation and translated audio if you
want it back to to process in your
application as you like it it's
competitively priced and it currently
supports 8 languages speech input for 8
languages and text output for 50
languages this is an optimized service
for human to human conversation so
that's different from any services where
you talk with a with a machine the
service is specifically designed to
clean up the artifacts of human spoken
language and make it translatable it's
provided as a web socket API and you
feed it a stream of PCM encoded audio
and you receive back the text of any
partial recognition the translation of
the partial recognition and then you
receive the final recognition when the
speaker makes a little pause and the
translation of that final recognition if
you want to you can also receive the
audio to play to the audience as you
like our demo will not include
translated audio but you get it as part
of the as part of the stream that you
receive back here's an example of the
WebSocket call with parameters you can
see you said the languages you said the
voice that you want to hear and you say
whether you want to receive partials or
not for a bi-directional conversation
you just open two of these so the
translation service has been around for
a while offering as I said text
translation between 50 languages there
are also related methods to feed
Corrections into a translation memory
and use these Corrections to Train
customized translation systems for your
organization that translate your
organisation's terms and terminology and
commonly use phrases better than the
generic translation service would do
that also offers array methods of all of
the functionality so you can save on the
time timing for round trips
Kelly will now walk us through and a
sample application it's also posted on
github I'm gonna step through the
typical flow of a speech API application
and then I'm going to walk through some
code from an iOS app that we did as a
demo app the iOS app will be available
on github so you don't have to pay a lot
of attention or copy any of the code
it'll all be available for you on github
as a sample app the first thing you do
when you setup an app as you set up the
audio for the app you can have the audio
coming in from a microphone or you can
have it coming in from a file or from a
video then you need to get an OAuth
token to access the service and then you
send that token via a WebSocket to the
Microsoft translator service and and get
connected as soon as you connect you set
up a header and then you begin sending
audio as soon as you start sending audio
you also start receiving back over the
WebSocket text and data and data is is
the audio and then once you get the
audio back you can display the text to
the user and play the audio
for the user and then disconnect when
you're done so this is an application
that we created and this application is
an iOS app running on an iPad and the
scenario is you you walk into a tourist
information center and you want to ask a
question but you don't speak the
language so you pick the language that
you speak on the iPad and then you speak
into it and the other person who's going
to answer your question has an iPad they
see the translation in their language
and they answer you and then you see it
on yours so you pick the language you
speak into it and there's the
translation that comes back after a few
seconds the person can read it in their
language and then they can answer your
question so let's look at the code the
first thing you need to do is you need
to get an OAuth token and there's four
parameters that you need to send in the
client ID the client secret grant type
and scope the secret and the ID you get
at the time that you set up the account
with Microsoft translator then you need
to encode those strings and prepare them
to be part of a URL you create a the
parameters for the URL insert the
parameters and then you set up an NS
mutable URL request with the endpoint
and you set it as a a post and you put
the URL with the end point into the HTTP
body then you create an nsurl session
task with a completion block and then do
a to-do trycatch and extract out of the
data from when you deserialize the JSON
you extract out the access token now you
have to put the word bearer with a space
in front of the access token and once
you have that then you're ready to
connect and we call the connect
WebSocket method the tasks resume is
what kicks off the tasks to begin with
so now we're in the connect WebSocket
WebSocket method and we want to send the
parameters to the service we're
interested in voice we have a two
language and a from language we also are
going to get partials and text-to-speech
means that we get the audio back
the partials are very interesting
because you can see that the process of
voice recognition and translation as
it's happening it builds up the entire
sentence that the system is working on
at the time now we're going to create a
WebSocket instance and this comes from
the Starscream iOS that we got from
github to help us with the WebSocket
connections we have the endpoint we
stick the parameters in there and then
we add a few things into the header the
token itself so we can get access
there's also a thing called the
correlation ID and the correlation idea
is used when you have multiple
conversations going you can identify the
conversation from the correlation ID we
have some delegate methods that we need
and in case the socket is connected we
want to disconnect it before we connect
again so we're going to connect now we
are in one of the delegate methods
called WebSocket did connect this is
where you want to start sending data to
the service so we're going to create an
a/v audio PCM buffer and then we're
going to do a do try catch now this is
to open the file we're at this point
what we're doing is we're taking data
out of an audio file but we could just
as easy take this from the microphone or
take it from the video so once we have
the file we're going to format the file
so that it's ready to be used
we're going to ANU it do another do
try-catch to put the audio data into the
buffer and then we need to set up a
pointer and get the length and then we
put all of that data into an NS data
audio data which is what we will send to
the service now before we send to the
service we have to configure the header
so we're doing a sample rate of 16 K and
32 K now I'll show you the method in a
second that sets up the header and then
this socket right data is where we we
send the header to the service we're
going to take the data that we have and
we're going to put it into three catch
unk's and then once we we chunk up the
audio we're going to
right it to the service now at this
point we're going to start getting data
back from this service now there's one
thing that we need to do to let the
system know that we're done talking that
the audio is done talking so there's a
concept of an utterance so we need to
know when the utterance stops so to do
that we're going to send about two
seconds of silence and we're gonna send
that to let the service know okay you
can go ahead and start processing
because I'm done talking and then we're
going to write it to this service so
this is what the header looks like this
is a way file header it's really
important to configure the header
yourself to make sure that you get it
just the way the service wants it we
have the sample rate in there we have
the bitrate in there we have the bit
depth we have the number of channels
variety of information but once the
header is right then the service can can
move forward now that we're sending data
we also want to process the data that's
coming back at the same time we're
sending it because it is a WebSocket so
we're interested in three pieces of data
we're interested in the message type the
recognition and the translation there's
a lot of other data that comes back to
the service but right now we're just
interested in these three pieces of data
so what we want to do is deserialize the
JSON that comes back in the message and
then we want to extract out the message
type to find out if it's a final or a
partial once we know that it's a final
we want to grab the translated string
and we want to get the voice recognized
string and once we have those two we're
going to put the display the recognized
text to the person who asked the
question we're going to post the
translation to a web service so that the
other iPad can pick it up and then we're
going to disconnect the socket now if we
were processing the data we're not in
this app right now but if we were
processing the audio data you might it
might look something like this so when
you get a chunk of audio data back from
the service from the WebSocket did
receive data method what you do is you
check the the first
bit of the chunk to see if that is the
last bit it's called the fin bit and the
fin bit will let you know that you got
all of the data that you need to get
back and then you just put all the data
together and play the audio and as I
said before all of this data will be
available these sample apps will be
available on github along with some
sample apps for c-sharp and Python Kelly
thank you for walking us through this I
have a couple questions of the of the
functionality area a lot of
functionality of that program you said
that you need to get an access token in
order to use the translation service how
long is that token developed the token
is good for ten minutes and one of the
parameters it comes back tells you how
many seconds it is and you can either
monitor that and when you need to get it
to renew it make a renew call or you can
just every time you need a new request
just get a new token okay that makes
sense
what in the architecture why did you
choose to use WebSocket instead of HTTP
- well HTTP - is is primarily used for
text bi-directional text transfer and we
needed to do text and data and the
WebSocket is really the best for text
and data transfers bi-directional what
happens if you forget to close the
WebSocket connection and you just start
anew well we're not doing this service
for free so there is some charging going
on and if you leave a WebSocket open we
don't know if you are mentally bit open
or or if you just decided to forget to
close it so we're gonna continue
charging you by the second and so it's
very important to make sure that when
the session is done you disconnect the
socket okay
saves me money yeah the as you wrote
application you did you choose to use
the partials or not why would I use the
partial results if they are not realized
yeah you know the partials are really
cool because you get to see the system
as
it's kind of for lack of a better term
thinking about how to recognize this
text and translate it and so that's
really interesting to see but run of the
cool things about that is is you can
send that to the person so they that
they know that the system is processing
what they're talking about and they can
see it so you can you know in an iOS
world you can put a little spinning
spinning donut up there to let them know
that if the system is working on
something but sending back the partials
is a cool way to do that so Chris what's
up next for the translator api's okay so
we are adding new languages as we as we
go we have been adding new languages
every couple of months we are going to
continue that that pace so going from
the current set of eight to two more to
twelve sixteen and so on and we also
improve the quality continuously this is
automatic speech recognition automatic
translation neither of them work on
percent reliably all the time giving you
exactly what what you said so there is
there is continuous work to do to
improve the the quality of the service
then we are also going to enrich the
text translation methods for translation
and and transliteration to give you four
more options and and capabilities in the
text translation space and how long does
it take you add a new a new language so
the most labor involved in adding a new
language is collecting training material
that's the audio and transcript in the
appropriate domains that you want to
cover and that takes some time takes
takes money and and effort that's why we
can do that only every couple of months
adding a new language so Skype
translators been using this for a long
time how many conversations do you think
have happened
with Skype translator and in in the
languages that we support we have
translated many millions of
conversations since we launched in in
fact in December and the the
conversations are between people who
would normally not be able to talk to
each other because they don't share a
common they don't share a common
language so we feel we have really
advanced the state of of international
communication breaking down language
barriers great so Microsoft has been
working on translation for a long time
Adventist since mid early two-thousands
well in fact the natural language
processing group that the translator
team grew out of has been one of the
first two teams that were established
when Microsoft Research was founded in
1991 Wow I haven't been with it for that
long yet but but the foundation has been
laid in 91 great that's a long time okay
we're going to do a demonstration of the
iOS app Chris is going to speak in
German and I'm going to speak in English
and imagine this is a a tourist
information center and Chris walks in
and wants to ask a question I'm choosing
my language here hello Conan Zamir Dean
Baquet so nice and bounced up see once
again now the system is translating and
once it gets translated and sent back to
his iPad it also gets sent to my iPad
and I can see it and he's asking me
where the nearest train station is so
I'm gonna answer him yes I can tell you
where the train station is go out of the
building turn right and go down 200
meters now it's being translated and
it's going to show up on my screen in my
voice recognition and in Chris's screen
it shows up in German
vielen dank that's really smart
you're welcome you're welcome have a
good day and that's how quick it is
after of just a couple of seconds the
the recognition comes back and the full
screen comes back and Chris knows where
to go and I've done my job as a tourist
information center thanks Kelly for
walking us through it that was very
informative if you have more question
about the service visit us on the web
Microsoft comm slash translator or
browse to samples that we have on github
and if you're a build come and see us in
our booth and we have some other
demonstrations we can show you thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>