<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Kitsune: Efficient, General-purpose Dynamic Software Updating for C | Coder Coacher - Coaching Coders</title><meta content="Kitsune: Efficient, General-purpose Dynamic Software Updating for C - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Kitsune: Efficient, General-purpose Dynamic Software Updating for C</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CkvoYZGypNA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright so let's get started thanks for
coming it's my pleasure to introduce my
kicks who was my advisor at the
University of Maryland and he's visiting
here for this week and then a bit of
next week as well for the faculties of
it so I'm sure he can corner him at some
point and chaplain more about DSU and
other things too so he's going to tell
us about kitsune which I as I understand
is a the latest in a long string of
dynamic software updating systems and
this one seems like it's really easy to
use and actually works on large C
programs so okay thanks very glad to be
here so this is a this is joint work
with colleagues at the University of
Maryland so jeff foster is a professor
there everybody else is a student and
Chris Hayden is underlined because this
work is part of his his thesis he just
graduated so software updates are
critical programs change we add new
features we fix bugs some bugs are
really important like security bugs and
so we want to make up and apply those
patches as quickly as we can on the
other hand software upgrades are
disruptive because now you have to stop
what you're doing and upgrade your
software and restart it again and that
would make the service unavailable which
is perhaps not what you want I'm not
sure where many people like these sorts
of messages so dynamic software updating
is an approach that attempts to solve
these problems by updating the programs
while they run and of course the
advantages enter that you avoid
interruptions and you get to preserve
critical program state that you had
gathered up while you were running so
this is going to be great for non-stop
services that provide financial
transaction processing or air traffic
control or something like that but in
general it's going to be useful for
programs with long-lived connections so
for example login sessions for ssh or
media streaming or any sort of
long-running program that gathers up in
memory state that you'd rather not lose
so an operating system a caching server
like memcache d and in-memory database
something like that so how does it work
so a dynamic software updating process
is running along at the original version
v 0 and some patch becomes available
we've gathered up some state at that
point that we'd like to preserve and we
have the new code for the new version of
the program and what we're going to do
is we're going to dynamically update
that running program and we're going to
transform that state as necessary to be
compatible with the new program and then
we'll carry on running with the updated
process and the goal here is to preserve
all of those existing connections in
that critical state that you had
gathered up while taking advantage of
the new program features and the bug
fixes so dynamic software updating has
been around for a while this is not a
new idea by any means I've been working
on it for quite a while but it's been in
the field long before that this is a
this describes the demers system that
was a telephone switch system an
operating system that ran bell telephone
switches in the 70s and 80s and it
describes their dynamic updating process
and in the last 20 years or so there's
been a flurry of research on many
different systems kind of a since the
mid-2000s a dozen or so systems have
come out for a variety of programming
languages and frameworks that provide
some form of dynamic software updating
so for example languages that you might
have heard of have dynamic software
updating features dotnet and Java both
of their VMs give you a way to change
methods on the fly the code of the
method bodies without shutting the
system down Erlang and small talk
provide more pervasive support for
dynamic changes there are tools that aim
to support applications they're not
within the vm but they are ways of
compiling or modifying a running
application to do updating and most
recently the company k splice provides a
dynamic updating service for the linux
kernel for very small sort of code only
changes targeted at security patches and
this company was bought by oracle in
2011 so there's increasing interest in
this so what are the research questions
with software updating i think the first
question that people
immediately think of when I talked to
them about this topic as well how's it
work how do you actually take a program
that's running and change it on the fly
and there are lots of ways to do that
you could compile the program specially
in advance to be prepared to be updated
you could modify it on the fly by
rewriting the binary inserting code into
the running program you could build a vm
specially to do it you could use process
migration and checkpoint restart and
other techniques to do it there are lots
of ways to do it and there are lots of
trade-offs amongst those different
techniques another important question is
why do you think your program is going
to be correct after you update it you
have the old version you have the new
version you have sessions that started
at the old version now you've changed
the code the program does something
different why does that session make
sense when it continues between the two
versions so figuring out a way to say
what you mean having a way to verify
that indeed what you mean is what you
get and to test that your update works
properly is important and then finally
all of these things are trade-offs it's
a big design space where you're trying
to balance performance flexibility the
pause time that it takes when you do
your update the applicability to many
programs so it's a big research area and
we have worked on all of these questions
over the last 10 years in my research
group we built implementations for c and
java as Nick mentioned this is the
second C implementation that we built
that I'm going to talk about today we've
implemented dynamic updates for 15
programs dozens of updates per program
four years worth of their release
history we've developed formal models
verification tools testing tools for
updates and we've empirically validated
a bunch of assumptions that various
groups are making about those updates so
today I'm going to tell you about the
synthesis of all of that experience all
of this this ten years of becoming an
expert as they say your 10,000 hours on
a particular topic that boils down to a
better way to do thi namak updating
basically the system I'm going to tell
you about today is very easily arguably
better than any system that is preceded
it and i'll give you details in a minute
okay so what's the main idea of this new
system well first
all current DSU systems aim to provide
their service transparently the idea is
that the programmer just writes the
program as they would have normally
written it and then magically someone's
going to come along some clever
researchers and could tell them how you
can modify your program on the fly and
things will be just fine and the goal
here is to reduce the lines of code you
have to change and hopefully reduce
effort and basically I've come to
believe that that that's a silly idea
that that's not going to work and
there's a couple of reasons for that if
we think about see first of all
programmers are really aiming for low
level control when they're writing a
program and see if you really didn't
care about your data representations or
the time it takes you to perform a
certain operation or the way that you
manage resources memory things like that
then you wouldn't be programming and see
you'd be programming in some
higher-level language where you could
defer all of that stuff to a runtime or
something else and yet many updating
systems that aim to be transparent for C
take that control away they compile
those data representation the structures
the things like that in your program
differently they use different memory
management strategies they forbid
certain programming idioms like casts
between buffers and structures and
things like that in order to implement
transparently this dynamic updating
approach and all of this thing all of
these things cause programs to break so
you'd have to change your program or
they reduce performance and you don't
want to do either of those two things
and see the other thing is that even if
you did do those things what we have
found is that through an empirical study
where we use the systematic testing
strategy it's very difficult to know
when during a program's execution to
perform an update so that the program
behaves properly and the approach is
that people have considered before one
of them is called activeness safety
which says you're allowed to update your
program as long as any code that you
have changed is not actively running
works most of the time but doesn't work
all the time and if it doesn't work all
of the time and your program crashes
then you've sort of defeated the point
of doing dynamic updating in the first
place if you're willing for your program
to crash you might as well be willing to
shut it down and restart it so it works
properly a prior system that I worked on
called jin-sang
I had to find situations where that
might happen by using a whole program
static analysis which didn't scale was
conservative and so complained about
programs that there was no problem for
and would be basically impossible for
non-experts to use so we felt like all
of these things were lousy and they were
all stemming from this idea that you
could just magically do dynamic updates
so we thought well what if we instead
decided to consider updating a program
feature where we get the programmer more
involved we say you're going to have to
write more code to support dynamic
updated as a feature for your program
but you're not going to have to give up
those other things you're going to be
able to represent your data however you
want you're going to be able to more
easily reason about what's going to
happen because we're not going to use
any automatic safety checks or anything
like that anymore you'll be able to read
the code of your program to see when the
updates and so on are going to take
place and by doing it this way we're
going to get further we're going to get
better flexibility will be able to
update more programs we're going to get
better performance because the way you
wrote your program before is the way
it's actually going to be compiled and
implemented so you have the performance
you want and you get to maintain that
low-level control so the principle is
that you pay for what you use the name
of this system is kitsune that's the
japanese word for fox and fox and
japanese folklore is a shape-shifter
foxes are also very clever so it seemed
like a nice word to use okay so what are
the results we applied kitsune to modify
five open source programs memcache d
Redis and icecast memcache d and Redis
memcache d is a caching server it often
sits between a client server and
back-end database to speed up queries
Redis is an in-memory database that's
used by things like Craigslist and the
Guardian and ice cast is a streaming
media server tour is an anonymous router
and vsftpd is a secure ftp demon in all
these cases we looked at at least five
updates to those programs through their
release history in the case of tour and
vsftpd we actually looked at two full
years and four full years respectively
of their release history and we could
perform all of those updates we could
create patches from each one of those
versions we could get the program
running and then dynamically update it
on the fly while it was going no
performance overhead effectively and in
all of
these things it's basically in the noise
the time it took to perform an update
that your program was paused was 40
milliseconds which is also roughly in
the noise and the amount of work that
the programmer had to perform which was
largely one time was a less than 200
lines of code for each program for the
part where you transform the state if
you remember when I did the little
update and little circle went across and
you might need to modify your state to
work with a new code we developed a new
tool called XF gen for a transformer
generator that takes two programs
written in a little dsl that you use to
define transformations between state and
in these cases between 27 and 200 lines
for the entire release history that we
considered so while I think you should
not be too swayed by lines of code
sometimes one line of code can be very
hard to come by so that's not a direct
court doesn't directly correlate with
effort I think the fact that it's
reasonably small for larger programs is
encouraging and all of the other
benefits that we get are encouraging as
well let's see so tor tor was the
biggest one that's 75,000 lines icecast
is well there's going to be a chart
later on so i might get this wrong
vsftpd is on the order of 20,000 lines I
think guys cast is maybe twenty or
thirty thousand lines and memcache d and
Redis are smaller more like five or six
thousand lines all of these things
though i should say are in production
use memcache d is widely used tours why
we use the SDF TBD is the only ftp
server that linux people use these days
on your group that's something that's
good or were you working with open
source do we modify these probes okay so
here's how it works consumed it takes
your original program and instead of
compiling it to an 8 out and executable
that you would just run from scratch
instead what it does is it compiles your
program to a shared object file and
instead loads it up with a little driver
program that's about a hundred lines of
code so the driver program starts up and
it loads your program into memory and
starts to run it and it will be running
for a while and eventually it will be
signaled that a new version of the
program is available at that point it's
gathered up a whole bunch of state in
memory because it's been processing
connections
storing its database and so on and so at
that point it will call back into the
driver remembering sort of where it was
when it got the signal and it will load
the new version of the program it then
starts the the new version of the
program and migrates and transforms the
existing state to run with the new code
so this is your database and that
representation has changed so it's going
to run this transformation it will then
free up the old resources and we'll
continue on with the new version making
its way back to the equivalent program
point where it was when it received the
update and then carry on with new
processing so in terms of the build
process things are mostly as they were
before instead of compiling with your
regular compiler flags when you add two
additional flags here you have to
compile to position independent code
because now you're loading your program
is a shared object file you also have to
run it through our little source to
source translator which basically just
inserts a few boilerplate calls into
your program but otherwise does not
affect the way your program works it
doesn't change fundamentally the way
your data structures are compiled for
example once you've compiled all that
stuff you link it with our runtime
system that's going to receive the
signals and provides a boilerplate and
stuff for these transformations that
you'll ultimately right and then you
link it together into a shared object
file so in oftentimes what I when I was
a junior researcher I didn't think these
things matter but now that I am a little
bit more senior I think differently that
our the old systems for dynamic software
updating would require these very
pervasive pervasive changes to your
build process you would have to change
the way you did make files or or
whatever to use different compilers and
so on and I think it's really important
that all we have to do is change a
couple of flags and change the way the
program is linked but otherwise leave
the programs host build process alone
yep
does this require single-threaded
program no okay I'll spend some time
talking about that later okay so what
does the program have to do this is a
program feature they have to identify
they have to do three things first they
have to identify where dynamic updates
are allowed to take place inside of the
program they have to update they have to
identify so called update points I'll
show you what those look like they have
to ensure execution reaches the right
event loop when the new version restarts
they have to work their way back to that
equivalent program point and they have
to identify the state to be transformed
and of course they have to identify how
to do it so to illustrate these
obligations we're going to use a simple
example this is a single threaded server
that's implementing an in-memory
database so we have some data here and
we have a mapping that's a from instance
basically i'm going to index into this
data mapping the clients will prevent
present get and put requests or
something like that so in the main code
the server will start up it will
initialize the mapping it will create a
listen socket to accept connections and
then it will repeatedly accept
connections each time it gets a
connection it will go into the client
loop and then it will receive one at a
time client requests and then return
back to the main program and this isn't
a particularly realistic server but you
get the idea of the shape of the
programs we're going to update its going
to be similar to this okay so now i'm
going to show you the parts that you
have to add to use kitsune so first
thing you have to do is you have to
identify program points at which updates
are permitted to take place so this the
first one is going to be within the
while loop of receiving client
connections and why is that well because
it's going to be running around this
loop repeatedly and we want to make sure
that we have an opportunity between
client connections to dynamically update
the program if a new update is available
another place that we're going to insert
an update point is within the loop of
receiving client and actual requests and
again this is going to allow us between
each request to look and have an
opportunity if an update is available to
go ahead and apply it in general the way
you would pick these points is you would
find these long running loops in your
program these event processing loops and
you would stick an update point in the
middle of them
the next thing that you do is you decide
what data needs to be migrated by
default all global variables are assumed
to be in play for migration so you don't
have to do anything in particular that
is by putting no annotation doing
nothing we'll assume that the data is
going to be migrated from the old
version to the new version and then
you're going to insert a call in the
beginning of your main program so that
when this program is restarted as a
result of an update right I load it in
the new version and called into it this
do auto migrate call is going to begin
the process of moving that data across
once the auto migration has happened the
data transformation has has occurred the
program is going to continue on and now
it's the programmers job to get the
program back to the place where it was
before so you're going to insert calls
like this that say if I was starting my
program from scratch i'm going to do one
thing if i'm not updating i'll go ahead
and allocate the mapping but if i am
updating i've started it because of an
update i'm going to skip over this
because i don't want to reallocate the
mapping that he just spent all this time
gathering and migrating across it may be
that you want to also map across local
variables in which case you need to
indicate to our compiler that you care
to register the local variables for this
function which you do with this little
annotation and then you're allowed to
use this function my great local that
says well if I'm not updating then don't
then go ahead and execute the body of
this code but if I am go ahead and
migrate across the initialize this lfd
with whatever the value was in the old
system okay so finally we now need to
work our way back to where the update
points were and we remember we had two
choices of where an update could happen
the update could have happened in the
old version at this point or it could
have happened at this point when we
restart the new version we want to go
back to the equivalent point in the new
program and so we're going to insert
this call if I am updating and I updated
from the client point then I'm going to
go ahead and locate I'm going to migrate
the client file descriptor as well
because that's now a live file
descriptor and then I'm going to go
ahead and call in to the client loop so
i can go back to where I was before
taking requests inside of the client if
I was not updating from the client loop
I'm going to go around this right to the
regular while loop and
I'm going to hit this kitsuna update
point which is the point where i would
have updated before okay so this little
bit of code is going to serve to migrate
one extra local variable if you had
previously updated from the client point
and otherwise it's going to skip over
that and go to to the original point
there okay so that's it that's what the
programmer has to right now there's a
lot of red on this slide because there's
not a lot of black on it but basically
this red code is one time fixed code
that you write sort of per server and it
largely stays unchanged and it's not
really dependent on the size of the
whole program that is you mostly added
this stuff in the main in main function
and in functions that are sort of
shallow on the stack and you don't make
any changes to any other code inside of
your program so as we'll see later on
for the 75,000 line tour or the 5,000
line memcache d it's essentially the
same number of lines of code that are
changed okay so you ask a question about
multithread here's the way that it works
in that case instead of just having one
thread of control that you're in the
main loop you go back and then you
migrate your way back again you have to
orchestrate the restarting of all of
your threads and the way that that works
is that each thread that's running in
your program is going to have to
synchronize at its own update point once
all threads have reached these kitsuna
update points the main thread will do
this jump back to the beginning of main
again and restart the orchestration
process once it gets to its equivalent
update point it's sort of unleashes a
ton barriers the other threads who are
then allowed to proceed forward and
inside of each of their loops and so on
there's the similar sort of logic that
gets them back to where they were before
in order to do this we have to put a we
sort of use an LD preload to hijack the
threads library so we can keep track of
well what functions where these threads
calling so that we can restart for
example the new version of those
functions if the functions have changed
and we also have to do things like
hijack blocking system calls like except
if it's waiting on a connection or
pthread cond weight or something like
that so that we can interrupt those
things so the threads can more rapidly
get to their update points okay and once
all threads reach their update points
the update is considered finished and we
free up all the resources and carry on
okay so the last thing is we have to
write the code that's going to that's
going to migrate and transform the state
how do we do that well let's look at an
example first here's our example program
where we have our data mapping and let's
suppose in the new version of the
program we change the definition of the
data type so that it's now a string
rather than an int well the existing
data is a mapping from instance but now
it needs to be a mapping from insta
strings and so we're going to have to
change that existing state so that it
corresponds to the new types before the
new code is going to be able to use it
properly or it's going to core dump or
do something untoward by treating what
should be care stars that sorry treating
what are in but are expected to be care
stars so how would we do that well
conceptually what's going to happen is
when i call that data auto migrate
function i'm going to need to run
through all of the elements of type data
in my program in this particular program
they all live inside of this mapping but
in general when i change the type i have
to find every occurrence within my
entire program and the stack and heap
and the static data segment and so on
and i need to change them for example to
do this al-malik a pointer to the the
actual data to be some size and i will
store there the string representation of
whatever integer was there before so
conceptually this is saying writing a
bunch of code like this this is the find
all instances of data and then this is
the interesting part that you are
telling the system here's like well how
I want you to transform those things so
in order to make it to the programmer
doesn't have to write the find all
elements of data of this type part we
wrote a tool called XF gen where you
write the interesting part and we will
generate for you code that will go and
find all of the stuff that needs to be
changed so this is what this is an
example of the code that you would write
you would say I'm transforming the old
representation of data to the new
representation and this is how I want to
do it and I'm going to show you some
examples in a minute so do that
discovery automatically is
kind of a stealth version of the
requirement that you be a little bit
well behaved but you don't do bet alien
casts and escape things yes what let's
let me tell you how I do it and let's
come back to that okay so here's how XF
gen works inside of this this process so
here's the build process that I saw
before and here's the new bit that I
haven't shown you yet so when I have a
new version of my program i'm going to
write one of these XF files that defines
the data transformations for this
dynamic update and I'm going to run it
through my tool XF gin which is going to
generate a C file that does all of that
find all the elements and perform your
user defined transformation on it and
then that's going to get linked in with
the new version of the program so that
when it calls my great local and do auto
migrate it will invoke the right code to
perform that XF jen is attempts to be
helpful and identifies all types that
have al use that have changed between
the two versions of the program these
are stored in these TS files that kitsy
produces and if you fail to write an X F
definition for some code that's changed
it'll flag you and say hey a new field
was added to this truck but you haven't
told me what to do with it please write
a specification to do that it also uses
this stuff to type check the code that
you write and make sure that you haven't
introduced silly typed type errors
inside the program okay so what do these
specs look like so the first one is an
initialization specification so this
says say I have a new global variable or
a new local variable and I need to
initialize it as if not the program was
starting from scratch but because it's
been running for a while how do I do
that well I'm name it here and I put an
action in here what's the action that's
just see like code it's basically see
code with a few meta variables in it
that will substitute various things and
I'll show you what those look like in a
minute this is the one that we quickly
saw an example of this is the Target to
target transformation so in this case
target can be either a tight so a type
definition changed and then I uniformly
tell you here's how you change all
things of that type it could also be
that something was renamed for example
you might say hey this type but was data
in the old
program is now named to data to and I'm
just telling you that that renaming has
taken place or it might be that a global
variable has changed and I would say oh
here's what the old global variable here
it was here's the new one and here's how
you initialize the old given the new the
new given the old okay and the next fgn
is going to generate C code from these
specs so let's look look at an example
let's suppose that in your old program
you had a counter of the number of
operations that you had before performed
and let's say that the operations for
our sample server will get or put
operations to stick them in our memory
database and instead of just counting
the operations all together I now want
to in the new version count them
individually so I'll count the number of
sets and the number of gets okay so that
means that I'm in the middle of running
my program the programmer is going to
have to decide how to initialize these
two things given the old value the old
value does not actually provide enough
information to accurately make that
decision because who knows how many gets
and sets have been performed to this
point but you have to initialize them in
some way so the programmer is going to
have to define what that is and they
might write some code like this they're
going to say well these are two new
variables so I'll initialize them and
i'll refer to this meta variable out for
storing the value of those things and
i'll compute the floor or maybe the
ceiling of those two things i'll just
assume maybe half forgets and half were
sets from that we're going to generate
this code which is going to be called to
initialize get count so the do auto my
great thing we'll call this and this
function and this will look up in a
symbol table a pointer to where the old
counter was stored the pointer to this
and it will then initialize the the new
one and then sorry and then it will look
up the pointer to the new one and then
it will initialize the new one based on
the old one and it will do the same
thing down here so the nice thing is you
write this and then we write this icky
stuff for you
so what are these little meta variables
that appear in the sea program well out
in an or as you would expect out is what
the is a variable that represents the
target the new version and in represents
the old version you're dealing with two
different names for types if you have
the data aero data transformation that i
mentioned before well one data is the
old data representation one is the new
so you can distinguish between those
when you need to buy wrapping with this
new sim Oh actually I guess new type old
type same thing goes if you were
initializing a variable where you want
to refer to the new one versus the old
one but they happen to have the same
name and then finally you might want to
recursively look up the type of some
other transformation function for
example if you are transforming an array
where that array had things in it that
themselves were changed you could
recursively look up what the
transformation function is for the
elements of the array and then
iteratively apply it to each thing in
the array and in fact that's an example
i'm going to show you now let's suppose
for example we had in our old array we
want to turn it into a linked list
instead so instead of the key being the
index to the array and the value being
whatever the contents are at that
location in the array I now put the key
and value explicitly in linked list
elements and then you to transform this
to this we're not going to generate code
to automatically do that for you you are
going to have to write code that will
iterate through the array and create
these new linked list elements but what
you'll be able to do is you'll be able
to refer to the old configuration size
to know how big this was you'll be able
to refer to the new type for the for the
list versus the old type and so on to
fill in these values by the way in all
of those programs that i showed you
updates for that was 35 updates to five
programs we have never had to write
something this complicated so this is
another interesting thing about research
there's the worst case there's what
about this what about this what about
this can you handle this and this and
this and then there's what actually
happens in practice and if you think
about it people don't make gigantic
pervasive crazy changes to their program
very often they make small reliable
incremental changes and so we see over
and over again that is very rare that
someone massively restructures their
program that would necessitate writing a
complicate
transformation like this did make a
massive chain then they might consider
shutting down get that risk for that
that's right exactly I mean eventually
for example the hardware is going to
have to be swapped out maybe we could
coordinate our system with VM migration
or something like that so you could even
getting around the hardware swapping
problem but yes that the the goal is not
necessarily to run indefinitely but to
create much greater spaces between
shutdown and restart okay so here's the
last example we we update data this time
from int to long and let's say we have
our link listed that I showed you a
moment ago and we add a new field to it
and then we happen to rename the next
pointer for some odd reason in this case
we can write this transformation what
this says is that well I'm changing data
to data but interestingly because the
representation of those things has
changed I'm going to have to assign the
into the out and I'll cast it too long
so of course the cast is going to extend
it from 32 to 64 bits in this case I've
added a new field so it shows here that
the target does not have to be just a
variable or complete type but you can
actually indicate a field that says hey
keep every other field the same and just
initialize the new field this way and
then finally this is illustrating a
renaming do nothing but take note of the
fact that this P next is a is a renaming
of the old thing and this is to keep the
tool happy when the tool notices
syntactically that there's some sort of
change and says hey you need to tell me
what to do with this P next field you
say you don't have to do anything with
it you just have to assign you have to
realize that it's been a sign from the
list next field okay so now let's talk
about how the generation that's the
specification the programmer writes
let's talk about the generation code
that our system produces we bait we
generate this code based on data types
so we look at the types thus trucks and
so on the global variables of your
program and we generate a traversal
that's sort of like a garbage collection
the traversal that starts at the roots
and follows pointers based on the type
information that it has now the problem
is C does not provide you enough type
information to do the right thing in all
cases for example if you see a pointer
to a type T you don't know whether
that's a pointer to 1 T 2
an arbitrary number of T's like it's an
array etc etc you don't know if it's a
zero terminated string and so on there's
type information that's missing so we
require the programmer to add
annotations to the type definitions if
the programmer wants us to generate this
traversal code automatically so we
borrow annotations from a project called
deputy that came out of Berkeley for
proving type soundness of C programs and
we find that we basically need the same
sorts of annotations so here are some
examples of those annotations if you
have a pointer to an array you have to
tell the annotation what's the size of
the array could be a constant it could
be another global variable it could be a
field inside of the struct opaque tells
kitsune that it does this is a pointer
that does not need to be traversed it's
just going to be the data that was there
before has not been changed at all by
the update and you're just going to copy
the pointer from the old version to the
new version and no traversal is needed
and then KS jen is a way of specifying
generics if you have a container an
array for example you might want to
indicate what the elements of the array
are so that XF Jen can automatically do
this recursive call for you to transform
each of the elements of the array so as
an example the annotations look like
this this is the c plus C++ style
template annotation where you indicate
that this is the quantified variable and
then this is the instantiation and we
basically have annotations that
correspond to both of those things okay
so given such a definition if you had a
list that you said has data elements in
it and you then define a data to data
transformation it would automatically
traverse the list for you and transform
each of the data objects okay so now
let's go to your question about a
stealth requirement that the programmer
has to change their program so yes and
no yes it's a stealth requirement in
that if you want XF gen to do the work
for you you're going to have to make
sure that you don't do things that will
you're going to have to make sure that
XF jen is going to do the right thing
you have to understand enough about how
it works so that you don't think that
it's just going to magically get
everything right in the worst case what
that will cause you to do is to write
some of traversal code yourself they
you might have wished that it could
write for you in our experience that
almost never happens although our
experience at the moment does not
involve really really big programs we're
in the process actually of getting
consuming to work with snort which is
about 250,000 lines it's an intrusion
detection packet inspection system and
snort does some wacky things that is
caught that are causing us to have to do
some stuff ourselves but I'll talk a
little bit about that okay so there's
the benchmarking programs let me just
show you a quick demo okay so I'm going
to do a dynamic update to icecast which
is a streaming media server okay so I
just started icecast this is running on
a machine at Maryland I'm remotely
connected to it and that started the
stic script starts the kitsune driver
which then loaded in the esso file that
implements icecast and that's what I
Scott says when it starts up the next
thing I'm going to do is start a stream
actually let me do this first so this is
the ice caste status page so you can see
that ice cast is running version 2.3
point 0 RC 2 and there's the connection
that I'm making to that guy and it
doesn't have any streams yet there's no
live feeds that you can connect to now
i'm going to start this stream so that
when i reload this page we can see
there's now a streaming subscription
that you can get you can connect to that
stream and start listening to music so i
have that on this tab
there it is okay and now finally I'm
going to see here so now I'm going to do
the update so this is the this is a
little script that says sends a signal
to the running program the program is
this the pit of this driver and it's
going to say i want you to update it to
this new SL file which is version RC 3
instead of RC 2 which is the one there
before so i do the dynamic update the
music is still playing and when i reload
the admin page you can see that the
version has changed to RC 3
but as exciting in the program efficient
oh yeah I knew you guys would appreciate
it it's free so it's one of those you
can just download and it's a complete
free open common license and so on okay
so I've already told you about these
programs there they all are what do they
look like so here's the number of
versions that we did that we considered
for each one these are both
multi-threaded programs whereas these
are single threaded programs these are
the releases and then that's the rough
size of the program so they're even
actually smaller than I thought other
than tour this is a description of some
of the changes in the programs so vsftpd
aims to be very secure its what's the
very secure ftp demon and as an example
of the source of changes that you would
want to apply right away security
patches hey there's a problem with TLS
there is a way that we could have denial
of service attacks there's a bunch of
SSL improvements that eliminate timing
channels or whatever it is I might want
to apply these updates right away rather
than just waiting until tomorrow or the
next day or the next day to shut my
system down and restart it tor is an
anonymous routing server again very
concerned about security it's got
encryption and so on in it and so these
are a bunch of changes for the releases
that we considered that if you use our
system you'll be able to get these
things on the fly the old code does get
unloaded at the end of the update
process katina does that okay so now
let's look at the changes that are
required here's the programs again and
this is a summary of all the changes
that we have to make this first column
says how many update points we had to
write so these are the places where you
write kitsuna update inside of the
program and as I mentioned they tend to
go in these long-running loops most of
them there's a handful of these changes
memcache d there's basically one update
point per thread type that it uses
icecast has to update points per thread
type there are six different threads and
actually a new thread is added in the
very last release this plus here
indicates the number of changes that
were made in versions other than the
first version where is the thing that's
to the left of the plus indicates the
changes we made to the very first
version just to get updating to work in
the first place so you can see that most
changes that you end up making our to
the very first version of the program
and then occasionally you make changes
to subsequent versions for example in
this case because icecast added a new
thread okay so those are the number of
update points these are the number of
lines of code we had to add for control
migration so that's the if this is
updating then do this if this do that
and so on so that's on the order of you
know a couple of dozen lines of code in
the worst case for data migrations these
are things like the annotation note
locals various things like that where
you make small changes to your program
to indicate the data that's being
migrated and then this II underscore our
annotations that we had to make two
struts and so on to provide type
information to XF gen so that it could
generate the traversal code so that's
what that looks like there and then the
rest of this is just other changes other
code changes that we had to make in the
program right so as it just as an
example the 66 lines of code that we had
to make to memcache d the reason for
that is there were state that was stored
inside of a library that was not
accessible from the program itself it
was only accessible from the library and
yet that state needed to be transformed
so we had to change the program a little
bit to keep track of the state that it
then registered with the library so that
it could then come along in the
subsequent version and dynamically
updated so you guys didn't read new cash
to you guys soon
it must have been a bit painful to
figure out that there was this extra bit
of space one of the ways of us yeah that
was painful so usually the way that this
is a good point so the the way that we
figure out whether we got this right is
we use testing and we usually test
updating a version of the program to
itself so you you create a version you
do a dynamic update to it that just
loads the same esso file as before and
you have sort of the null XF gen update
and that tends to work out these
problems that you're pointing out so in
that case we do the v 0 2 v0 update we
call it from em cash d the new version
of the program what was being stored
away were function pointers inside of
this live event library and so the
moment that we did that and then
unloaded the old s 0 the program crashes
immediately because it tries to call a
function that doesn't actually exist
anymore or in the case that it was
pointing to data and the heap or
something like that again eventually
it's going to crash because that's data
that stale that you didn't have access
to so that does a very good job of
working out most of the kinks of just
getting the V 0 2 v0 update and then
when the new version of your program
comes out of course you test it locally
before you would do it in the live
system and you do the same thing ok so
then this part is describing the XF gen
changes so these are the number of the
total number of the specifications we
had to write so this was the the v2 v
specifications these are ones where
global variable X got is changed in the
new program so we have to write some
transformation for it and this one is
some type definition t change to some
new definition in the new program so in
some sense these are just
characterizations of how much the
program's data represent changes changed
over time and it's not surprising I
suppose well maybe it is a little
surprising so icecast had the most right
it changed quite a lot over the small
streak of releases that we considered
and because it changed a lot we ended up
having to write consequently more total
code to to update that so these are the
total number of specifications we wrote
and then this is the size of the total
code the action code for each of those
specifications we had to write but
nevertheless write a couple hundred
lines in the worst case for a streak of
years
worth it releases eyes is not so bad
capsule the function pointer thing is is
interesting to me so it seems that
because you're in see where you don't
have closures you can't read please
state transformers 4 function pointers
in C itself yet so if you were actually
in some so it seems to be a case in
which see actually helps you because if
you were in ml that's a where you
actually had closures yes you wouldn't
be able to just unload code and get rid
of the old stuff because you couldn't
break the closer to transform estate
yeah that's a good point yep so you're
the leader of easy road testing
and I'm having a hard time getting an
intuition for there's still the it seems
the worrying that open you had to do
something in d0 to be prepared for some
future transition that you might not
have done if you thought about
randomized semantics preserving
transformation testing her so yeah I
guess the key is to think about what
what are the things that could possibly
limit you about what you could do in the
future so one limitation is that the
control migration code that you stuck in
will somehow be insufficient but that's
actually not a limitation because the
control migration code is in the new
version of the program that you're going
to load in so whatever you need to do
once the new version becomes available
you can do inside the new version and
you can test it so that's not so much of
a problem one thing that's in the old
code that you can't change are the
location and placement of update points
if you didn't put enough update points
in so that it took forever to reach an
update point that would be a problem and
probably you would like to do you could
do an analysis for example to make sure
that these things are reached you know
often enough you could do it by testing
I think that's something that but that's
something that that's you could do v 0 2
v0 you should do v 0 2 v0 in terms of
data the thing that could happen is you
could fail to recall that you need to
notate which local variables remember I
had to write this note locals thing if
you forgot to do that there might be
some local variable that you can't carry
over because you failed to remember that
you remember it but that's also an easy
fix you can very easily do a control
flow graph analysis that figures out
well what are all of the stack frames
that can lead up to any update point in
the program and just annotate all of
those functions with note locals and
then I'm not limited and then the same
thing goes with global variables by
default all the global variables are
available so it's the only drawback to
doing all of that stuff is you might do
more work and hurt performance just a
tiny bit by remembering stuff you didn't
need to but it's usually in the noise so
we just do
okay so here's the performance overhead
slide basically we for each of these
programs we came up with workloads we
ran them under the build build the
system the way that the designers wanted
you to build it just run the make file
put in all the optimizations and
everything else and run it on this
workload and then we did exactly the
same thing with Kitson a and we see that
the performance overhead is in the noise
it's at worse around two percent slower
but sometimes it's faster and actually I
really enjoy citing todd mikov it says
paper which says if your performance
difference is less than eight percent it
doesn't count on modern architectures it
could be linked order that calls it
causes a difference that's that much so
you know this this means nothing it's
basically in the noise and why is that
well this makes sense all of the
performance overhead that we introduced
the registration of these variables this
is it updating or is it not updating all
of that stuff is on paths that that do
not intersect with paths of the regular
programs execution right that just goes
along unfettered the way that it was
before other than every once in a while
reaching one of these update points and
doing checking a flag is an update
available is it an update and available
every iteration of this loop it's in the
noise for a program that's doing I oh
now jin-sang that's a prior system that
we developed for see that attempts to be
transparent and it does crazy
compilation and adds extra sort of slop
space to structs to allow you to modify
them in place it sticks in levels of
indirection it does this analysis all
these other things it's performance
overhead is more substantial for example
in memcache d it's up to twenty percent
another system upstair that also uses a
special compiler introduces sixteen
percent overhead for vsftpd so i like to
quote what all far earlington told me
about when they built a tool for cfi
that if you have more than fifteen
percent overhead no one will ever use it
so our goal was zero percent overhead
and we just viewed you know this is
unacceptable and of course that does
that leaves out all the other problems
of certain programming idioms are not
supported and and and so on this is the
time to actually perform the update so
when I said that do update I sent a
signal I hit the update point and then
it takes a while to carry the state over
into my great control flow back and
during all that time your program is
pause
not doing anything so how long does that
take so usually it takes on the order of
40 milliseconds or less here's the one
exception the reason that ice cast is
slow is that it has a bunch of sleep
ones all over the place in the program
and so surprise surprise it takes about
an extra second to to get past that if
you drop the sleep ones then it drops
down to 180 milliseconds and then if you
also make a small change to the way you
do blocking i/o and ice cast on the
order of six lines of code you can knock
it down to about 130 milliseconds I'm
going to skip that this is a function of
update time with respect to state size
so the x axis is the number of key value
pairs in both Redis and memcache d and
then this is the time it takes to
perform the update right so if i'm going
to traverse all of these things the more
data i have the longer it's going to
take now it turns out from em cash d it
does make any difference how much data
you have because the data representation
does not change and it just copies one
pointer which is to the whole big array
from the old version to the new version
so that doesn't hurt you or as it turns
out for Redis it has a linked list
structure where each element in its
linked list points to a statically
allocated address and the problem is we
have to run through the whole list and
redirect all the pointers to the old
address bases address to the new address
spaces address which takes all kinds of
time upwards of 150 milliseconds so the
way we solve that problem is we fix the
design if you don't do that and point to
a static allocated at a static address
but you use an enum instead which is
what a sane person would have done it's
really unclear why they did it this way
then you're back to it costs you know
extra time ok so I said at the very
beginning there's been lots of stuff
that's led up to this work our own
system jin-sang already mentioned but
there are a bunch of other systems 2k
splice is the the one for the Linux
kernel that I talked about I've already
talked about upstair dynamo season is a
system for updating the Linux kernel to
opus is for a binary rewriting strategy
for updating running see programs polis
is the same thing so many of these
systems have been proposed in the last
10 years all of them have the problems
that I've already said they
they all impose too much performance
overhead or they limit what you can do
in the attempt to make things
transparent and it's it's simply just
not necessary I guess Simpson operating
system that would be alone I mean
nothing in principle that's an easy
thing to say but it's definitely not
supported right now that I mean the
tools rely on you know using shared
objects and using the GCC compiler to do
share objects and so on and it just be a
whole bunch of different mechanisms in
the US okay so we don't have support for
custom allocators yet this is a big
problem with big programs the reason is
that when XF gen generates a bunch of
code and it finds something in the heat
that's old it freeze it and then it
calls malik to make the new version but
if you didn't use malloc to make the old
version than calling freon it's going to
crash your program and calling malik on
the new version when you should have
called some custom allocator it's going
to cause your program to crash later so
you need a way of doing custom
allocation we're working on that another
problem is this pause at update time you
had to run through all of your state and
as we saw up you know the more state you
have the more time that might take we
have an idea for doing this lazily by
using page mapping tricks basically we
can make the new not copy the stuff over
right away but page protect the global
variables that would have new stuff in
them and then incrementally bring stuff
over as as we page phone so that's in
the works and then we're also working on
getting this to go for java java
everything will be much easier but the
same strategy will apply why because
jobs has type safe so and it doesn't
have this this same custom allocation
problem and so on a lot of the problems
that we have to deal with now or that
the programmer has to think about they
would not have to think about in that
setting
officials are you turning safe Java code
into more safe knowledge of your only
serving things
I know are you thinking about cut you
like if you have C code that's linked
with your Java code or something like
that well so it's not implemented yet so
you might be identifying something
that's going to be harder than I think
but if it's just pure Java code you
should never have to do anything unsafe
I've actually already implemented a Java
system that's a part of a vm that
implements you know safe java
transformations you have a new version
you have a new version of the class it
has extra fields and so on and all of
that is fine this would be sort of a
version that you would not have to
change the vm and it would have the
similar sort of benefits that kitsune it
provides we have to violate access from
the fires and stuff right to go to reach
red state or that is true that is true
so we would what we would end up doing
is yeah that's a good point so you could
compile your program to sort of hide
those for the sake of being able to
support this or you can use reflection
which is I which allows you yes you can
get around access modifiers that way ok
so there you go consume a DSU dynamic
software updating as a program feature
it makes the semantics apparent to the
programmer so you have to write some
code to get it to work but it's not that
much code and it's exactly the code
that's important for understanding the
semantics of your dynamic update so that
you can read the code you can see what
it does and it does not impinge on your
ability to use the program idioms at
least in our experience so far that you
would like to use when programming and
see this is the most substantial
demonstration of effectiveness of any
DSU system today 35 updates of five
applications two of which are multi
threaded with better performance and
better flexibility of any prior system
so we're actually considering a start-up
venture for this this stuff where we if
we can get snort to work that we're
going to start releasing our own version
of snort that people can use so that
they can have a daddy s you enabled
snort and then hopefully if we manage to
generate a user community you know we'll
see where things go from there and
that's it
we met jennette that's where you and
foster fake update ah so you're worried
that some bad guy could come in update
your program so I would say that it's a
similar problem that the offline
patching people already have to deal
with when you get a windows update how
do you know it was for Microsoft how do
you not make sure that some other person
can inject some patch into your system
so whatever techniques that people use
their I would argue you could use the
same techniques to make sure that bad
code is not end up getting injected in
your running program so you had the one
example where you kind had to there
wasn't enough information in the
pre-existing state to properly populate
the new state you had to make a guess
yes and it was a particularly simple
example of that sort of guess you had to
make I gather in the 35 updates you seem
almost nothing like that so not in those
updates no actually that's not true so
there is one vsftpd update that's like
this and here's the example at some
point vsftpd decided to implement load
balancing since you can only have n
connections from a particular IP address
and the problem is when you perform the
dynamic update you have to initialize a
couple of hash tables that implement the
load balancing so they have a map from
IP address to pit of the child process
and they also have a map of IP address
to the number of connections from that
address or maybe it's a map from the
paid to the number of connections or
something like that so that you don't
have too many more than end connections
and the problem is when the child
process dies it informs the parent
process hey I'm dead and the parent then
goes and looks up in the hash table to
CEO what would pidd was that and what
address did it has so I can knock the
countdown now the problem is when I
perform the dynamic update and I'm in
the parent I already have a pile of
child processes implementing connections
but I don't know what their IP addresses
are so I can't populate the table the
right way and if I just left the vsftpd
code the way it was when the child dies
and the signal gets sent the parent goes
to look up the entry in the table which
it sure will be there and it isn't and
then cordones
so we actually had to change the source
program in that case to stick a test if
this doesn't equal null then go ahead
and make this change otherwise don't so
in that case we could not implement the
transformation the way that we wanted we
didn't have the information so we had to
change the program to accommodate that
lack of information so that it wouldn't
crash based on how we did actually
initialize the state but that's the only
time in I don't know probably 60 total
updates I've ever used I've ever
implemented that ran into that problem
so this is the context of explaining the
context of server stuff attention Java
and.net things that are somewhat similar
and imagined at least for dotnet you're
talking about it and continue so you
could do edit and continue with this
although it seemed it seems like the
method that's already used Fred and
continue in the VMS which is just to
replace a method as long as that method
is not running is more appropriate
because you just want a quick and dirty
response and you don't care if your
program crashes because of the crashes
you just restart it which is what you
would have had it done to do anyway
having to write state transformation
code and all of this stuff you may be
less interested in doing that on the
other hand if you really are testing
something and you you care about the
current state of the program and you you
had a scaffold that got it so that you
have a bunch of state and you want to
test a fix in that setting maybe you
would be inclined to use our stuff to do
it so I wasn't thinking about it and
continued I was more thinking of Java
server programs you know application
servers JSP things like that or I was
thinking you could even imagine phone
applications like Android for example
where you know you're moving from you're
in the middle of playing angry birds and
you get a new version of angry birds and
you know hey why not perform the update
and not have to stop playing this
particular screen and go back to the
main menu or whatever I mean that's a
bit of a frivolous application but once
you can support it in language why not
these five the five application that you
talked about so they were already
designed to be lets say running BTW all
the time there was a lot of care yeah
but then they has they have to have some
kind of full tournament mechanism or
something to be registries even of bugs
or something
some perhaps copies or something and so
I mean the work that you so how do you
basically compare it's very very vague
question but the type of techniques that
you use with the work and full automatic
how you merge both because like if you
were to apply this type of techniques
for it's a real phone system you mention
develop but Bell Labs I mean there are a
lot of things that were in place I mean
it was a great a better business they
have never go down there's a lot of
stuff already and yet so far that's our
problem but then you would have to get a
merge type of techniques that you
probably that you talk about with this
kind of existing features that are part
of the system to deal with scampi's
fault or anything so where are you I
mean I don't even know if it's a very no
no it's do not well Chris question but
no it's a very important thing about
that's so I have thought about this I
thought that so there's any there's an
easy answer in a more nuanced answer the
easy answer is so a lot of people will
try to debunk what we're doing by saying
hey why don't you just built doesn't the
fault tolerant stuff just get you this
so for example if you hot standby like
they did in the old ESS iess phone
switches load the new version on the
standby and then fall over to the new
version and then now the old version is
a standby and then upgrade that one and
the reason they didn't do it that way is
that you needed to then wait for there
to be no active connections right you
had to you had to have no state and
that's what we want to avoid we want to
keep the calls if there's that phone is
serving calls you want to preserve those
calls so that's why the Deemer system
allows you to do that you could change
it inside of that and then you'd still
have on the side the fault tolerance
part so one answer is you have this you
certainly want to have fault tolerance
for catastrophic failures you know if
you have a if you're using memcache d
you're using as a front end for a
back-end database where you really care
about the data and so yes you're going
to use fault tolerance mechanisms to
make sure that you never lose your data
and availability and so on what we're
doing is in some sense with memcache d
is we're saving you performance problems
right you could just whack your memcache
d and restart it but then you'd lose
your 10 megabyte cash that made that
your users performance much much better
which you'd rather not do if you can get
away with it or you rather not if you're
icecast
kill particular users connections I mean
icecast does not have any way of for
fault tolerance reasons failing over if
it crashes while people are listening to
music if your ssh server crashes while
you're logged in you lose you know your
connection goes away so we're not it's
it's orthogonal in that sense but on the
other hand if you had a fault tolerance
mechanism you could imagine trying to
use it and the main problem then would
be how would you migrate the active
state the calls in the example of the
bell labs switch so that it did it
worked in the new code that might
represent those calls in some different
way you'd have to have some way to
package up the state and bring it over
and then initialize your new system in
some way to deal with that state and in
some sense I mean that's what kitsuna is
doing right it's got the old version
it's just loading it into the same
address space but all the state is
sitting over here and then it's bringing
across would actually not be very hard
to start up a new process actually send
it across on a socket and then restart
the new process and initialize it using
the I transformation stuff that we did
before in fact we have an earlier system
called eka den but that is just like its
unit but works that way so that's
basically all I have I've thought about
it not so well form question which is so
let's say I have system running I I find
that it has some security vulnerability
and i went up to it and it may be that
mice the version 0 of my system that was
running is has been compromised in some
way maybe the attacker has already come
by and he sprayed my eat my ham is full
of shell code and you know you're going
to win the update dixon you can copy all
that excel code all over to the news to
the new version when what you might
really like to do is just teen up and
and start fresh with the new patch that
you have in place so you can do that so
the exit gene gives you you can write
your own transformation for example if
you wanted to do nothing let's say you
were doing you're doing a patch where
you're just changing a little bit of
code and none of the state changes you
could make all those XF files just be
opaque pointers and all of it would just
go straight across
or what you could do is you can say you
know I don't want I don't want to do any
of that I want it to just be initialized
the way that it was before and you can
write that in the control migration code
right so remember when I say is updating
whatever i'll either initialize this or
i won't well if i want to reuse it fine
i won't put that ifs test there and i'll
just go ahead and initialize it when i
restart and we have we do do that on on
many occasions actually where we don't
care about this particular state and
there's no point in going through the
pain of migrating it over there's a
separate question which is you might not
want to you might want to keep the old
statement you might want to fix it so a
good example is suppose you have a
memory leak and you fix the memory leak
but now you'd like to fix the heap to
write like the heaps got all this extra
stuff in it that you'd like to throw
away so you can do that again by writing
XF gencode that will find the the leaked
objects and throw them away and then the
challenge is well how do you how do you
know what the heap looks like to know
the stuff that's leaked but the
mechanism is there for you to use we
actually so this work is published it is
going to be at oopsla this year we have
another paper that's appearing at hoops
load that i did with Catherine McKinley
that attempts to automatically infer
fixes for memory leaks that it can look
at the heaps of the old in the new
program and figure out what the
relationship between objects that are
leaked and objects of the same type that
are not leaked and generate
transformation code that runs through
and nulls out all of the leaked objects
but you could use X if we had the
similar sort of synthesis system for
kitsuna you could use it with XF gentoo
to fix your league or fix your heap
spraying or whatever sort of corruption
you had
this tank Mike again</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>