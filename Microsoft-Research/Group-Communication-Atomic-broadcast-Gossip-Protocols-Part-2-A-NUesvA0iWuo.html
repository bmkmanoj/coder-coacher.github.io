<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Group Communication, Atomic broadcast, Gossip Protocols Part 2 (A) | Coder Coacher - Coaching Coders</title><meta content="Group Communication, Atomic broadcast, Gossip Protocols Part 2 (A) - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Group Communication, Atomic broadcast, Gossip Protocols Part 2 (A)</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NUesvA0iWuo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so yesterday Chandu started with the
intent intent in in the introduction
yeah said this thing there's no such
thing as a stupid question only stupid
answers I wasn't familiar with the only
stupid answers part I think that might
might have been shonda's innovation and
certainly I make this very obvious
yesterday I got a lot of very good
questions and I gave some very stupid
answers and so I thought let me revisit
some of the stuff that that went on
yesterday yeah so what was going on and
I'm going to post this as a puzzle to
you guys is that I made some assumption
in some of the answers and then I
dropped the assumption and some of the
other answers I made that assumption
explicitly though I wrote it down it
wasn't a slider I said it and then
sometimes I forgot about it so there is
a mystery assumption X I'm going to have
you at some point guess what that
assumption was so under the assumption
your replication protocols that I
presented are in fact correct although
the the passive replication protocol
actually does more work than it needs to
do but it works this form you know I
think without the assumption and I
dropped it sometimes the best of
replication protocol is still correct
with the active replication protocol the
effect is not so the question is well
what is that assumption and again you
know like whoa so now I'm asking a
question you guys have an opportunity to
give stupid answers I want to go back
into that before i get into gossip first
of all gossip is a bad thing to do but
also Paxos doesn't actually use that
assumption and it's it's kind of
interesting to see what happens when you
drop the assumption it also drops texts
also doesn't use a cured failure
detection so something that Texas does
in order to give you these these
consistency properties you know it
doesn't with way weaker assumptions then
then I was using yesterday so under you
know just to see what that assumption
eggs does so let me know before we go
and try and answer the older you know
somebody wants to answer it already go
ahead so in first very quickly so
virtual sing any fur to sing this group
communication it's just a little
different from the group communication
that the Peter just talked about we've
got processes executing in air box and
it's a POC has a view like the view in
which it starts and processes processes
can only communicate with other
processes in that view and then work and
it simulates our an execution that's
indistinguishable from one in which no
failures happen and and then at some
point the epic ends with a you know new
view of the of the next epic and and it
is as if you know at that point some
subset of processes may fail it has to
be strict subset at least one of the
processes has to survive because if all
processes fail at the end of the air
pocket you're left with nothing so
that's the the virtual sing any recap
and then we also talked about something
called reliable broadcast which is that
if the sender is correct and some
correct process delivers em then all
correct processes must deliver em and
the implementation that we talked about
is quite simple when a process simply
broadcast a message in every receiver
when receives the broadcast echoes that
message to everybody else and then
delivers the message now yesterday I
accept the other way around which is
actually wrong I said delivers the
message and then it it echo and then
it's a sense the echoes this food you
know cool you know the way you would
implement it is the right way first you
echo it and then you deliver it and
that's actually important because then
guarantees that this echoed messages are
costly before the delivery the local
deliver your message so if you deliver a
message the the other the messages will
be delivered to the other processes
causally before that local delivery okay
so something you get then is actually
something a little stronger than
reliable broadcast something that's
called uniform liable broadcast which
says that if a sender is correct or any
process it doesn't matter what its
correct or not delivers the message then
all correct processes must deliver em
and why is that well you know does it
just set you know the broadcast
primitive re you know echoes rebroadcast
messages before they are delivered and
so if occur if a faulty process delivers
did well you know the the other ones are
causally before it and so the the
correct process must deliver em as well
let them become important in a second so
then we talked about these two different
ways of doing replication one is passive
replication in which there's a single
copy of a replicated it's a single copy
of a deterministic state machine it's
actually doesn't even have to be
deterministic for passive replication
there's a single copy of a state machine
and there's a leader and the leader
orders operations advise the operations
to its to the company of the state
machine that it has and then whenever it
has updated the state it broadcasts the
updated state to the other processes so
you got n copies of the state but
there's only one state machine like only
one process that executes the state
machine that's passive replication now I
had in my protocol the following line
before you send a result of the client
you have to wait until there until you
have a received and acknowledgement from
all processes in the view and I got
various questions about that very very
good questions and I gave various very
stupid answers to that to that question
because of this assumption X that I
dropped in my mind but in fact it it
holds so this protocol actually works
without this line in it we don't need
this line you don't have to wait the
after you do a reliable broadcast you
can immediately send a result of the
client and why does it work well if the
client receives the output then that's
causally after the sending of the result
while the sending of the result is
causally after the delivery of this
event and and in particularly its costly
after the reliable broadcast the
reliable broadcast will send everything
to the to the other processes and
particularly the correct processes
constantly before sending this this
event so even if the leader is faulty if
the client receives the output then all
constantly prior messages according to
the properties of virtual singin e 0 cos
Lee prior messages have to be delivered
as well well particularly the state
update that would send to the correct
processes have to be delivered as well
and so we don't actually need this
particular line and so I gave the wrong
answer to that and why did I give the
wrong answer will so I was arguing when
I got the answer somebody asks like why
are you waiting for acknowledgments I
was saying well well here here's here's
the deal
say that so you know the some some some
Israeli the leader replica here sends a
response to the client and then fails
then it's not guaranteed that the other
other processes have a copy of the state
and now the client has seen a response
the the the update is not persisted at
all the replicas and in fact you know
maiden may not have been persisted
anywhere but it's not true I mean
because it's causally prior it has to
they have to be delivered to all those
those replicas so there's an assumption
i'm making there and i don't know maybe
some people can already figure it out
that then i can silently dropped when i
give you that answer now an active rep
is this already said i think so in them
what's happening here oh I'm pushing the
wrong button how do we go forward active
replication okay active replicas here i
showed you active replication protocol
yesterday after the talk rama gave me an
excellent question so there's something
I don't understand about this protocol
it's an active replication you actually
have n copies of the replica of the
state machine so it's called a
replicated state machine will approach
you actually replicate the entire state
machine notice the state the entire
state machine and so you still have a
leader typically and the leader you said
operations to the leader the leader
orders the operations and send them to
the to the various replicas of the state
machine along with the sequence number
to ensure every replica applies to the
operations in the same order and
therefore end up in the same state now
around us said what i don't understand
if if you send a result here to decline
and this is just one of the replicas
when the you know receives a operation
from the leader it applies it in then
since
sensor response to the client what if
that leader but if that particular
replica is faulty and the other
processes don't receive that message
after all I had the Defiant reliable
broadcasts to mean if some correct
process delivers the message then all
correct processes have to deliver the
message well if the process is not
correct there's no obligation all that
just told you that in fact the
properties are stronger so with these
stronger properties even if a faulty
process delivers the message all correct
processes have to deliver the message so
again if the client received the result
that must have been causally prior to
this particular event which must have
been costly prior to my saying that the
wrong way around the the delivery of the
output to the client is causally after
the sending of the of the result which
is causally after this delivery this is
called causally after the reliable
broadcast and so every correct replica
will infect receive the update I hope I
got my answer right this time so this
protocol is in fact correct under the
mystery assumption that i'm making that
i made explicitly so any guesses what
that assumption was that i sometimes
dropped and sometimes used yes in the
back there
I certainly used the property that
messages are causally ordered but it's
not the one I was making it through out
already there was it isn't another one
it's a little bit of a you know not a
good question to ask because after all I
stated that I was making that assumption
the assumption that I was making is that
the clients are in the view too it's not
just the servers that are in the view
but the clients are interview the
clients are not in the view then that
all those properties of you know of
causal you know causally prior messages
have to be delivered no longer apply and
the reason I was dropping a de sumption
because in practice clients aren't you
know like in these group communication
protocols clients are typically not part
of the view in systems like Isis and
trances and what have you all these
these fur to be seamless computer
systems they didn't put a client's in
the View for this simple matter that it
wouldn't scale you know you've had a
service that had a few replicas since
you put them in a group but there could
be you know thousands and thousands of
clients and to agree on who exactly is
in the in the group you know sir didn't
really you know didn't make any sense
and it was expensive to maintain because
of this consensus property if the sulfa
consensus every time a client joins
leaves and so they didn't put clients in
the in the in the group so yes here's
that assumption that I made I said the
processing fee we can only send message
to and fro and deliver messages from
members of V and oil has to include the
clients and so protocol like active
replication in fact doesn't work at
least not in this form if clients are
not in the view because if the client
receives a message it's no you know it's
it's outside of the view so this must be
some kind of utter you know out of Bend
type of
and operation well the whole causal
relation is no longer tracked virtual
signi only tracks messages that are sent
within the view this is outside of the
view and now Rama is absolutely right
without that assumption the client may
receive an output from a faulty server
that faulty server may crash
subsequently the other processes may
never there's no obligation at this
point the other processes ever received
a message because maybe the leader also
crashes and and the protocol would be
broken you would actually have to do
something more complicated and that's
you know what packs is in fact is going
to do for for one thing is there's no
assumption in Texas that the that
there's any kind of causal delivery in
fact let alone for four clients so I
just wanted to rectify that and I think
it also makes it an interesting
introduction to the Texas verticals and
replicated state machine protocol's that
you'll see but you know it's it's a it's
a very subtle thing and the the thing
with virtual singin e you can sort of
pretend things are not subtle right it's
just there are no failures and so you
can make keep your protocols very simple
and they work because you can pretend
that all processes are correct as soon
as you drop some of that stuff things
get a lot harder and then you'll sleep
exes you'll see CDC various consequences
of having dropped those those those nice
properties any questions about that and
otherwise we'll go actually I'd run one
more thing I wanted to mention but no
questions ok so I just wanted to quickly
talk about the various properties of
broadcast that have now come up I mean
yes they give a simple hierarchy there
talking with Lorenzo I mean it's I you
know we
talked about it is it's not really a
hierarchy it's really a collection of
properties so there's a variety of
ordering properties that we talked about
50 ordering calls of ordering total
ordering the texting we talked about
atomic ordering which is causal plus the
property that all messages have to be
delivered in the same order at the
various processes that you could
actually separate you could make
something that's totally ordered but not
causal or five every 500 ordered so the
ISIS atomic broadcast gives you both
causal and total order but you could
have told order by itself cause the
order implies 50 order but mostly these
these properties are fairly orthogonal
let me look at reliability which you can
think of his life as properties or
though in the world of virtual sing and
either basically they're they're
actually safe safety properties because
Stephanie ho have to hold by the end of
a view but that's a detail I won't go
into you've got these these properties
so I gave a give you a combination of
the persistence and the relay property
persistence probably says that if a
process is correct and sensitive
broadcast then all correct processes
have to deliver the message the relay
property says if some correct process
delivers a message then all the correct
processes have to deliver the message so
those are those you can combine into one
property like the one I gave you
yesterday which said if the sender is
correct or some correct process delivers
the message and all correct processes
have to deliver the message and then
there's something called uniform
reliable broadcast which says that if
some process delivers the message it
doesn't matter what its correct or not
then all correct processes have to
deliver the message so that's a stronger
property then then the relay property
okay so that's the various kinds of
broadcast
properties that that people talk about
and of course each one of them has a
different implementation and we saw a
bunch of them the if you drop some of
these these properties like or these
assumptions like eckerd fill detection
the protocol's get harder and pax is in
some sense is an implementation of an
atomic not actually totally ordered not
on the time we want to totally ordered
broadcast protocol in some sense that in
fact gives you uniform reliable delivery
okay now we're going to start gossiping
and so I'm going to argue that some some
forms of gossip are good so I am
probably not going to cover all the
slides you got in your slide set I will
give you an introduction say a little
bit about the history give you some
intuition about how these gossip
protocol's work and then I will only
present in the next hour one case study
I think it's probably a lot of time for
but we'll see how goes so introduction
is so gossip is is essentially form of
data dissemination like broadcast but it
looks a little bit more at a particular
implementation of broadcast so you want
an efficiency you want robustness you
want speed you want to scale all those
kinds of nice performance properties now
tree distribution beer talked about this
this morning is very efficient it's also
very fragile if a node in the tree fails
you have to reconfigure the system it's
now can be kind of tricky and there's
certainly a hiccup in involved during
which messages can get lost so the trees
are are efficient but fragile are
flooding is another way of doing it you
know in fact you could do that probably
on pastry as well you know you just send
it to all your neighbors
no like whenever you receive a message
rather than sending it on the tree you
just pass it on to your neighbor list
and every neighbor passes on to their
neighbor list and eventually the message
will get to everybody and if the graph
is well connected enough it's it's it's
highly robust it's also very inefficient
because a lot of processes will receive
a copy of the message more than once and
then we got gossip which tries to find
it a different point in the design space
so wants to be efficient like trees
wants to be robust like flooding but
it's not going to be as fast as these
other protocols and if you put that in a
nice here's a nice graphic where you
know you see the trees and trees and
flooding our fast trees and gossip /
efficient and gossip and flooding or
robust and there's a certain you know a
cap like property to this like with cap
that was talked about yesterday got
these three properties that you want but
you can only get two at a time pick any
two but that's what you can get and
simplest it's similar here you know I
getting actually a dissemination system
that's all three you know efficient
rebet robust and fast is hard to get so
two out of three fine three out of three
it's it's complicated their their new
trade-offs involved okay so a little bit
about the history I usually don't give
much about history when I talk about
things because you know most afraid of
Miss some people and of course i need
some people here but I could you know I
just love the title of the first gossip
paper that I found that I had to put a
slide in there was actually at MIT paper
1972 that was cold ladies and telephones
and and in fact it looked at the
dissemination of gossip in a telephone
network
for some of its sexist title but there
it is 1972 it's not even dead long ago
the bmore computer science ii stuff came
in 1987 when L demers now a colleague of
mine at Cornell but then the researchers
Xerox PARC worked on the Clearinghouse
the clear has directly service which was
in fact an alternative to the domain
name service at the time it was the same
time that the Internet domain name
service was being developed and sir
spark proposed his other thing wearing
house dns one that we could have had a
gossip based domain name system if if
they hadn't been more successful and
then there's various things that came
afterwards including bunch of projects
that I've worked on either took types of
gossip that are called rumor mongering
and anti entropy and they they have
served different objectives so rumor
mongering is more like the broadcast
primitive but with sort of probabilistic
properties so basically when you have a
message you want to disseminate in the
system you give it to some of your
friends and some of your friends will
and possibly some of their friends and
so on and eventually that message will
spread throughout a population that way
and you do that for some time and some
time you stopped because you can gossip
forever a message and so there's a
probability that not everybody gets it
the longer you gossip the more likely it
is that everybody gets it and so there's
a trade-off you can affect analyze this
thing and it's very much like the same
kind of analysis that you use for
checking virus spreading or something
like that so epidemiology and then this
anti entropy which is not not a
broadcast primitive it's more like a
state machine replication like thing
you're replicating some data and you
have an update and you want to point it
update 22
every copy well you keep on gossiping
this update and and the updates actually
have version numbers on them and so
since you know you only need to apply so
for example a key value store something
like that you may timestamp the update
and so newer updates are obsoleted by
older ones and so when you start
gossiping a new update the old update
just disappears out of the system
because you're only gossiping the latest
one and that's good for state
reconciliation and in fact I think
pastry uses some version of this so
properties the nice properties of gossip
bar that the gossip spreads you know is
certain in certain you know
exponentially fast like a virus or like
like a like gossip and propagates in a
time that's proportional to the log of
the number of processes it's very
tolerant of various kinds of failures
with a message loss or crashes and
that's a tolerant of Byzantine failures
by the way we're talking about crashes
and and it's easy to be to model the
behavior mathematically okay so here is
a gossip protocol this is in fact the
only you see this is an anti entropy
protocol probably most of what I'll be
talking about is anti entropy so
basically you got two threads running in
each process 11 threat that periodically
picks a random process is knows about
random peer in the system and then since
its state to that process and there's
another thread at running a bit process
and then every other process that sits
there waiting for these gossip messages
to arrive and when it gets one of these
messages that contains you know some
state from another process it merges its
own state
with that from the other process and
updates its own on state that way so
receive state takes its own state runs
it through this virgin and outcomes it's
updated state so for example in the case
of a key value store the merch function
would take the latest version of a
particular key value pair so how does
the work is there is a system with what
aight aight processes yes eight and in
this case it's a fully connected network
so everybody's everybody's here doesn't
necessarily have to be the case but you
know so one process has some information
and new update we sometimes say it's it
infected and so it's it's thread at some
point picks a peer at random and since
it's at state and now this spear is
infected as well so after Round one two
processes are infected now we've got two
processes that are infected and they're
gossiping so around later they each pick
a random pier on this case they're lucky
they pick different gears and so after
round two we got four processes they're
infected all that can always go right
you know so at some point they're going
to pick the same here so sometimes you
know at some point there will be some
overlap but nonetheless after around
three there's only one beer left if we
had been luckier all all peers could
have been infected and you know that's
as much as much as i simulated this
thing I mean it could of course go very
badly to whether you could have these
abilities these two pairs could have
been gossiping to one another by sheer
chance for for many rounds to come and
only in after around 100 it could still
be only two and in the best case it will
take four rounds is it what is it three
rounds right to to infect all the
members so if you look at the the
function here it's I drew out of just
with my hand here but so if if time
going
left or right like Lorenzo likes to have
his is his time going left or right and
here's the y-axis is the the percentage
of processes that are infected well you
know you get initially a sort of
exponential growth then at some point
you know half of the members are
infected that point there's going to be
you know a lot of collisions where
you're trying to infect members that are
already in fact it's so things are
starting to slow down but eventually all
processes are infected another question
is well how long does it take on
expectation actually that's a question
that I'm going to be talking about in a
second so the stress I said the gossip
message has a as the state from the this
from the center of the gossip and uses a
merge function in order for this to
converge in some way or another we need
to have certain properties of that merge
function like you know picking the
latest update is a good one it's sort of
you know always makes progress but if it
picks one at random from the you know
the two updates you know it's it's this
this particular gossip protocol won't do
anything that's that's useful so when
you design the merge function typically
want to have something no something like
one state is better than the other state
this is when you've merged it you get
that the new state is better than the
state you had and also better than the
state you received and or at least know
as good as okay so this particular
scheme is that is called anti entropy
it's a so-called simple epidemic because
we don't have any because of this this
fully connected graph so how fast does
that spread all that's a nice big old go
to the library you know i forgiven this
publishes it's all from guy named bailey
who looks at epidemics and so you know
when you first started looking to gossip
protocols that's the book we got out of
the library and and there's a bunch of
math in there i'm going to give you some
idea of
how then math works so that we can get
some intuition about how gossip spreads
so again simple an epidemic fully
connected graph anybody can converse a
bit with anybody else and we pick and
they all pick their their their peers
uniformly at random and so let's let's
look at a case where we have a
population of you know some size N and K
members are already infected what's
going to happen in a round of gossip so
everybody is going to gossip what's
going to happen so here's that
population of size n is the set of K
members that is infected and you know in
this case to those members constituted
to the same probability so what is in
fact the probability that some member
here what is it the probability it's
some member that's not infected is
infected if they are already infected
well it's a fairly simple binomial types
of thing so you know the probability
that that some process infected is 1
minus the probability that nobody
infects any of these members which is
you know this simple formula here and so
then we can you know look at the
expectation of how many members are
going to get infected in this uninfected
population here and that's n minus K
type at times the probability okay
that's clear more or less so we're going
to sort of you know now look at the the
gossip running in two phases first going
to look at how long does it take to get
from one infected member to half of the
members being infected and then how long
is going to take from half of the
members being infected to all members
being infected so the halfway point by
the way so if what's the probability or
the probability that some member gets
infected or that nobody gets infected
what is it that some member gets
infected if half of the members are
infected
is about point four so the halfway point
the half of the members are infected the
number of members that had infected here
is goes by about about a factor of point
for okay so in the first half as I said
it goes pretty exponentially because the
probability that the two members pick
the same other member is relatively
small still and so you know at the very
beginning the rate of growth is to when
there's only one member infected because
it cannot take itself and then halfway
we just saw it's the factors point force
that goes from the factors one to 1.4
and so and everything everywhere in
between that halfway somewhere the
growth is somewhere between one point
four and two so it's bounded between one
point four and four that's somewhere
between that is the rate of growth right
it's it's not less than 1.4 because
that's the halfway point it's not more
than two busy the process is only gossip
with one other member so can grow by it
most effective too so you know it's
exponential somewhere and the first half
is definitely exponential now what we do
in the second half is sort of turn it
around look at the rate instead of
looking at how fast is gossip or the
number of infected members going I'm
going to look at how how fast are
uninfected members declining so
initially that's very slow right it's
like we have n minus 1 uninfected
members and and then it's n minus 2 and
then it's you know either n minus two
and minus 3a minus 4 so it's pretty slow
initially but halfway the uninfected
population declines x factor point four
and then at the very end when there's
only one uninfected member left the
probability that that uninfected member
gets infected is 0 point 6 3 play the
same game we know that
you know everywhere in between you know
it cannot be that's it can be but it's
it's it's it's at least this as good as
point six three and the worst is about
point four so again it's bounded in
above and below and so we still have
exponential growth there and so the in
fact the number of rounds that are
expected to infect the entire population
grows logarithmically in the size of the
population and if you just you know do a
little bit of simulation you can see
that the base of the locket it's about
1.5 58 so it's that's the the the
average growth of across the entire
epidemic okay so it's still the case
it's logarithmic if some of the members
are not gossiping if some of the
messages get lost of course the base of
the log is no longer valid then it gets
a little worse but it's still
logarithmic okay so here's some
experiments there are some simple
distributions here's the number of
rounds that it takes to infect the
population of either 64 to and fifty six
or ten thousand twenty four participants
and you can see that you know it takes
about what is it about eight rounds to
two thick in fact 64 participants and
then what is it twelve rounds or
something to do 256 and fifth 14 rounds
to do 1024 so that's just you know this
i actually just did a simple simulation
of gossip to produce this graph and a
bunch of experiments and a lot of the
data points if you then look at you know
for many experiments what the expected
number of rounds is you know here's the
number of participants on the x axis and
you can see on a log scale that it's
approximately
the straight line in fact should be a
straight line okay so so far i only
looked at a very simple form of gossip
which is one in which the processes have
some state and then they get fit state
to some other process you can also and
then particularly that's that's an
epidemic that starts very quickly x and
then the we saw that the probability
that if the entire population is
infected except for one the probability
that last minute remember gets infected
zone leo point 63 it's excellent it's
not that great well we can turn it
around we can you know rather than
sending state we can pull it we can you
know and it's our turn to god it's my
turn to gossip i pick somebody at random
and i asked that process for its state
and and pull it to me and then i
inverted with my state so that has the
sort of the opposite effect like when
there's only one member that's
uninfected and it pulls from you know a
random outer member it's guaranteed to
be infected as well because all other
members are infected so it ends very
quickly but in the beginning if there's
only one memory infected the probability
that number doesn't get choses this
again point 63 it has exactly deserted
the opposite properties and so what
people doing practice is typically
actually combine the two so whenever you
gossip you exchange your states so when
it process be gossipy process q p sends
its state of q fue since its state to
pee and they both invoke the merge
function and so they both end up
hopefully with the same state if the
merge function is commutative so that
way you start quickly you end quickly
and the price you pay is that you send
two messages in are in and around rather
than just one
so it reduces the number around but it
increases the overhead song but still
this is typically the the choice that
that people make because it's a good
trade-off okay let me have a quick look
at time how we're doing here so still 15
minutes is the right okay so maybe there
will be time to go slightly into a
simple case study which is that a
failure detection right so failure
detection is a very important primitives
in distributed systems so far I've
assumed the failure detection is
accurate I'm going to drop that here you
know you cannot do eckerd failure
detection but we can use gossip to
implement a fail detector that gives you
probabilistic guarantees about the
accuracy of failure detection you can
actually set that accuracy pretty much
arbitrarily high if you if you like so
so a nekkid fail detector is impossible
to build but you know in some cases we
can allow for some mistakes I'm sure
that the the pastry system uses some
kind of failure detector and you know
it's it must be have some probabilistic
properties as well so various various
good reasons to have an affair detector
but the existing field detectors in
order to be reliable to exist until
detectors are usually based on pinging
you ping a process and then you wait but
mrs. can get lost process it can be slow
in order to make it accurate you may
have to ping for a long time and in fact
in industry something like three minutes
is not not unreasonable you know wait if
you haven't heard from another process
for three minutes then you decide it's
faulty because if you're faster than
that then the you know simple case of
overload could lead to mistaken
suspicions and if you make it much more
aggressive you know set it to like half
a second you're going to make a lot of
mistakes so we're going to build one out
of gossip that has fairly you know nice
property
I'm going to actually you know like have
a constant probability of making
mistakes it's going to scale in the
number of members order n log n the
bandwidth is growing order n whatz in
the internet is fine if you have n times
as many members you can use n times as
much bandwidth it's resilient against
the message loss and resilient against
crashes so how does this work well
what's the environment we have crashed
failures we're going to allow partitions
actually I'll probably won't go into
that message delay is unbounded guat
rift is negligible and the protocol is
like this so each member is going to
maintain some state right we've got
state and the state of these member
maintains is a list of all the processes
in the system so that has the ever sees
of this process at IP address tcp IP
address and a counter what's I'm going
to call the heartbeat and periodically
each member increments its own heartbeat
and sense that list to a randomly chosen
number from that list it looks at it
lists picks a random number and since
the list of the member so far so good
good so when a process receives one of
these lists simply merges those lists
and so and how is how does the merge
function work well it looks at these
heart beats for each member it maintains
the the you know the so if you have to
list with the same address in it you're
going to maintain the one with the
highest heartbeat and also you're going
to keep track every time you see a
heartbeat increase of the time at which
that happened so we're going to add some
local state it's not gossip which is the
time at which you see heartbeats
increase and then the idea is simply if
you don't see somebody's heart beat
increase for some time that's an
indication of something not being good
let's look a little bit of how this
performs so clearly the message the
gossip missus itself grows linearly with
the number of members because it is an
entry for every member and the number of
members grows linearly with the number
of members and so we have a problem if
if we if they all gossip at a constant
rate the bandwidth requirements on the
network would grow quadratically and so
we actually slow down the rate of gossip
with the number of members and we do we
you know we have some bandwidth that
we're willing to spend it takes about
eight bytes to to track of the heartbeat
and the and the address and and so the
time between gossips gross with the with
the number of members and then the other
thing we need to determine is how long
do we wait before we say well somebody's
heartbeat hasn't hasn't increased for a
long period of time should we report
failure so for that we need to analyze
the how fast gossip really works I gave
you a simple one before I'm not sure I
don't think I really have time to go
into details here so maybe I'm going to
skip that in the interest of time give a
question
it's a very good question and I was
sweeping that under the rug so in the
protocol actually allows these
heartbeats to wrap around so that we
only allocate I think two bytes for
heartbeat and six bytes for TCP IP
address or UDP IP address so that's
eight bytes total of course you know
after 65,000 increments this thing will
go back to zero and so we really
maintained for each process is a little
window and you know see because so to
see if somethin the heartbeat increases
sometimes it actually decreases so it's
from going you know like around at the
point where it goes from a very high
number to a very low number and so we we
do a sort of a circular comparison using
a window to see if heartbeat increases
okay so I'm going to skip over the how
we obtain these things and just give you
some some numbers so we're using 250
bytes per second from member so very low
bandwidth and I picked that bandwidth so
low so that you know the numbers are a
little easier to understand but you
might in practice probably use more like
you know 10 guilt kilobytes per second
and there I have in the top of the graph
33 probabilities of making mistakes
probability of making a mistake of 10 to
the minus ninth into minus 6 and 10 to
the minus 3rd and so here i have the
detection time how long do you need to
wait before you report a failure and the
number of members is on the the x-axis
you can see that the failure detection
has to grow as a function of the number
of members and so with you know hundred
members if you want to have you no one
in thousand probability of making a
failure it takes about a little over a
minute or something before you can
report someone is faulty and if you want
it to be more accurate of course you
have to wait longer or even longer
depending on how many how accurate you
want this thing to be now that sounds
well that's similar to what we had with
pinging like three minutes or something
like that but again you know that's on a
very low bandwidth requirement if you if
you're willing to gossip ten times as
fast just those numbers get ten times
better see here's the equality of
detection the probability of making a
mistake as a function of the number of
members by the way if I forget exactly
what this graph shows so maybe I'm going
to skip over that whole get back to you
on the spot if that so this is a more
and more important graphics this is so
the analysis looks at also takes into
account the probability of some members
not gossiping because they're in fact
faulty and then there's a lot of members
that are not gossiping things have to
slow down a little bit here you can see
the effect of that so the red line so
the x axis is the number failed members
in the and the y axis is the detection
time that's the the ratio q is the ratio
of the number of members that are in
fact not gossiping their faulty and you
can see that in order to deal with you
know twenty percent of members fail Phil
failing you actually have to wait longer
in order to before you can report a
failure in order to get this constant
probability of making mistakes but it's
it's it's it's fairly minor similarly
with mess its loss if you have message
loss you know you gradually will have to
wait longer before you can detect the
failure and so this is the probability
of Nessus lost four for three different
numbers of members again the ghost
fairly slowly as a function of none of
the number of process that are faulty or
are not gossiping or message get get
lost so that's where I'm going to stop
for the for the break the so this is a
very simple failure detector you can the
paper that I wrote on the subject also
shows that if you actually use a two
level hierarchy things scales a whole
lot better but you know for just to give
you an intuition of how these gossip
produce might be used and how effective
they are I think this is a good example
in the next hour give you a much more
interesting example of building a what
is essentially key value store with
gossip but if there's any questions
about this part I'll take it now too yes
actually it not another the skew is not
so important the drift is important did
I say skewer drift i meant drift so
because you need to measure time in this
particular protocol so it's the old all
the calculations are based on time that
has passed but it doesn't require
synchronize clocks sorry about that
there another question or yes oh yes and
there yes yeah
oh I'm right I mean you could still
accidentally suspect a member if
something happens so this is the how
long you wait when you so if you wait
for like what is it 100 seconds here and
you don't see somebody's you know for
example Peters in the list and Peter's
heartbeat hasn't increased for a hundred
seconds that's pretty serious so but
Peter might not be faulty it may just be
that gossip had a bad scenario and that
the the heartbeats that Peter is
gossiping don't make it further than say
Lauren sir lawrence and peter or
gossiping with one another but with
nobody else and so I made some point
decide that Peter is faulty after after
100 seconds it would be a mistake and
here we see so here we don't have I
forget there was a like some fix that's
probably 10 to the minus 6 probability
of making mistakes at wates point so
even if there are no faulty members you
still have to wait and you still may
accidentally flex somebody is folding
okay well let's take a break and I'll
see you in about half an hour I believe</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>