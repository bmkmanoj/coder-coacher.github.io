<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Automated Debugging as a Constraint Solving Problem | Coder Coacher - Coaching Coders</title><meta content="Automated Debugging as a Constraint Solving Problem - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Automated Debugging as a Constraint Solving Problem</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Dcu3Mj0EDoE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay all right it's my great pleasure to
welcome Thomas wheeze and this is one of
a polymer which was sitting over there a
lot of you have probably already know
Thomas he has been a visitor at MSR many
times after he graduated from andres
patel skis group he joined New York
University a few years ago he works on
decision procedures automated theorem
proving problems and program analysis
and as one a mirror is as PhD student
working together for about two years and
today you're going to get to talks for
the price of one Thomas will go first
and that will be followed by a
presentation from from zara me okay okay
thanks a lot for the introduction and
the invitation yesterday i'm going to
talk about application of formal methods
to software engineering problem namely
automated debugging and so you will get
to talks related to that but in a
slightly different context so i think
this is a quite nice application domain
for formal methods so if you look about
what what's the time that developers
actually spend on debugging then they
have been some studies on this and
roughly fifty percent of the total time
it's actually just sort of wasted on
fixing bugs in problem understanding
bugs so i think that this is a problem
where automated tools can have a high
practical impact and so just for the
overview so i'm going to there will be
two parts of this talk and i'll start
with the first part which will be about
a technique I call fault abstraction so
that's the technique for slicing error
traces for imperative programs using
certain static techniques and then in
the second part a swan email we'll talk
about finding type error sources in
functional programs or actually any
programming language supports automated
type inference
so just to get you started here's a
little example program you don't really
have to understand what's going on here
so this is a faulty implementation of a
shell sort procedure and so this is a
this program just takes the sequence of
integers as input and it's supposed to
return this argit sequences output and
well if you run this program say with
the input sequence 14 11 then where it
will return is 0 11 so it's a sorted
sequence but it's not a permutation of
the input and so what's going on here
well it turns out there is a call to the
actual sodding routine here that takes
the array that is supposed to be sorted
and it's supposed to take the length of
the array but while the programmer
actually provided well the number of
command-line arguments if you're
familiar with C programs that actually
includes the name of the program so
essentially the lengths he is off by one
and that's why there will be some array
out of bounds X that sort of pulling in
some some bad value now ideally what we
want to do is sort of do some kind of
root cause analysis where well ideally
we just want to point the programmer to
this line in the prone say okay here's
what you have to do to fix the program
now when you look at what people have
done in this context then actually most
of the work has been on the sort of
dynamic range of of techniques so people
have used testing to essentially compare
failing and successful runs of the
program trying to narrow down the points
where where things go wrong and
essentially then just provide some kind
of ranking of suspicious statements in
the program we're sort of the the most
likely source of the errors ranked first
and then you just get this list and well
the problem with this is that well for
this to actually work well you really
need good test suits and well if you
don't have good test feuds than the the
quality of these techniques really
grates quickly and the alternatives of
course to not do testing based the
techniques but actually use static
analysis of the air
basis and so here essentially we're just
going to look at a single failing
execution of the program and then just
trying to see what can we learn from
that single execution trying to help the
programmer figure figuring out what's
going on and so the advantage of this is
that we won't actually need any test
suits to get some some good results of
this there is another reason why static
techniques are interesting of course
sort of just providing these kind of
rankings of suspicious statements it's
sort of unclear whether this really
helps the programmer figuring out what's
going on I mean just having sort of a
single statement out of context then the
programmer still has to somehow see walk
why is that related to the bag so what's
really going on going on here and so in
practice you see that when programmers
fix bugs often they don't really
understand the true cause of the bug and
actually introducing more bucks in the
process when they try to fix the program
so perhaps what we can really do is
trying to provide some kind of
explanation of what's going on in the in
the failing trace so that the programmer
has some better idea of how to how to
actually fix the back so it's not just
about providing this fault localization
but more about providing an explanation
of the bug so that's what fault
abstraction is going to give you so it's
a technique that essentially takes an
error trace as input so the error trays
is the actual failing program execution
so a sequence of statements in your
program then an input state and an
expected output state okay and but you
can generalize this to say you're having
a precondition and and say a post
condition you weren't aware satisfy so
this is so the same the technique works
generalizes to sort of symbolic
representations of of inputs inputs and
outputs and so then what the technique
produces is what I call an abstract
slice and that's essentially a sub trace
of the input trace so essentially a
subsequence of the original statements
that are relevant to understanding the
the bug and in a
we get assertions explaining what's
going on in between these relevant
statements sort of giving information
about the state of the program that is
useful for understanding what's going on
so if you go back to our shellsort
program so this is sort of what this
technique produces it produces the
sequence of statements in the program
and these assertions that hold in
between and so why is this useful well
there's a bunch of information you can
actually extract from this so for
instance if you go here so this is the
actual on the main loop of the sorting
routine so there's this outer do-while
loop here and if we look at these
assertions we can see for instance so
here we have this it says that H must be
one and if we look at the loop condition
so we can now extract that essentially
the the arrows sort of happens in the
last iteration of the outer loop so this
is already provided by the assertions
here and similarly as we have this outer
for loop here inside of the do-while
loop and so we have the loop bound is
small in size and here we have is two
and size is three so we know that this
is the last iteration of the outer for
loop and so forth and then we can see so
here we have the expected output and so
this is the the the final output we
actually get and so we can see sort of
now how actually this this array cell he
received that value zero name it was
because of these two updates here so
here we set a of Gir j2v and well v is 0
and j is 0 so this is where this value
is written and so you can see so we is
this the value that we assign and it's
it's red from the i'th entry in the
array and so here we can see that is two
and a of two is zero and that's sort of
how we pulled in this this wrong value
so this is sort of the point where the
actual
read happens and then we can see well
this is because we have that is too and
our array so while you're sorting an
array of size 2 so we actually be
reading out outside of the bounds of the
array so this is where the out of bounds
reach happens and well the reason for
this is that size is 3 and it's supposed
to be just too so we know when we assign
size and this is the true cause of the
error so you can see we get a lot of
information out of this this absolute
slice here and in particular we can sort
of use this information for instance to
steer a debugger right so we we don't
necessarily present this to the user but
we can for instance extract information
but we had to set breakpoints inside the
program where which variables to watch
so just by looking at this these
formulas we can use that information to
help the program a debug the program yes
before relying on an interpreting
formulas formulas are sewn on direction
so the error could have been that well
the size was just fine you didn't make
the Arabian short yep so how are you
determine which with in general of
course you cannot just by looking at a
single single trait so the point here is
really just to help the programmer
understand what's what's really
happening in that trace and sort of
trying to eliminate all the information
that is relevant for understanding how
say a specific output was generated
alright so it's really not it's less
about local localizing faults in the
program at RADA explaining behavior in
the faulty trace it was very hard to
understand which conditions around
yeah so I mean in principle you can also
look at sorry if I have time I'll talk
about an application we actually we do
something like that we really look at
the more like a program fragments trying
on to explain certain behavior in that
fragment and also so I'm going to ignore
certain issues for instance how to deal
with wrong branching conditions and all
of this can be handled in sort using
slightly different encodings and so on
execution is already given to you that's
right so it can just be a failing test
case or say a trace generated by a
static analysis okay so let me explain
you the basic idea behind this approach
and so i'm using this very simple model
where i'm explaining this in terms of
finite automata okay so say look at this
automaton here and you can see this is a
word that is accepted by this automaton
so we read a then b c d and a and three
times B and a is so this is the
accepting state and well one thing we
can do is we can sort of slice away
these sub words here that correspond to
are traversing these loops in the
automaton right so then we get this
simpler word here and that's of course
still a word that is accepted by the
automaton so you can think of this
simpler word as being a an explanation
why this longer word is accepting right
so we can say ok the the longer one is
accepted essentially because it has 3
a's in it and that's essentially the the
idea we're going to use for the fault
abstraction so how does this relate to
programs well now what we're doing is
essentially we think of programs as
automata right so we have the error
traces essentially as finite words of
program statements so what the program
is essentially an automaton accepts
error traces and the formal organization
then is this very simple idea of taking
the trace
eliminating loops in the era trace but
of course you might ask okay what does
it actually mean to eliminate loops in
an era trays right when it's a a program
is not Ramadan what I have in mind is
really not the control flow automaton
but rather the transition system that is
the semantics of the program so this is
typically in so an infinite states in
infinite graph where we have from our
tralee long choices and in particular if
we look at if you think of error traces
in this in this graph and typically
there will not be any loops right so we
will not visit exactly the same state
twice in a single trace that's very
would be very uncommon in an actual
program that you really visit the same
state twice so there's always some some
states change okay so so here is
essentially where abstraction comes in
so now what we're going to do is we use
this very simple idea of essentially
predicate abstraction where we
petitioned the state space into finally
many partitions and from that build a
finite abstraction of the program right
so just to remind you predict
abstraction means we're given a finite
set of predicates over the program
states so some assertions say of this
form X smaller equal to 0 x greater 0
and so on and then we partition the
states into equivalence classes
depending on which of these predicates
they satisfy so if you have two states
satisfying the same conjunction of
predicates then they fall into the same
box here and then well we get in since
you transition between these boxes
whenever there's a concrete transition
between actual states inside of these
boxes
okay so normally well this is used for
computing say invariants of programs and
doing a program verification but how
does this help us in our setting well
suppose we now have such an such an
error trace here in our program so we
somehow visit the some some error state
and what we're going to do is well we do
find an appropriate abstraction of this
tray so certain states inside of the
strays bill essentially end up in the
same box and then we do this extension
existential abstraction and we get these
sub transitions on these boxes and then
you can see that well at certain points
will introduce loops by doing this
abstraction right essentially it could
think of this as taking a transition
inside of the trace that does not really
make progress towards the error right
and that sort of tells you okay so as
long as we are staying within that box
we don't really make any progress and
only when we so step outside of the box
that's where something interesting is
happening so that's why we now do the
slicing where we remove all the loops in
the trace and so what we end up with is
essentially just the sequence of
statements where we move from one box to
the other and then the boxes themselves
they will correspond to these assertions
that explain what's going on in the in
the air okay so of course the question
is now how do we actually come up with
this abstraction right we cannot just
introduce some arbitrary predicates that
partition the state space it has someone
has to do something has to do something
with the actual error so what you want
is somehow to be two states to end up
being equivalent to end up in the same
box if they sort of from these two
states you can reach the error state for
the same reason right and so next what
I'm going to do is sort of formalize
this notion of of equivalence okay so
this is where what I call error
invariants come in so let's look at this
simple example here so we have a very
simple trace this is the end
say this is the output state and while
you can see when we execute this thing
then X should be minus one I think was
zero actually so we not we are not
satisfying this this property here so
here is the actual execution so you can
see here so x is 0 and this violates the
the expected output now what is an error
invariant so an errand variant is a
format an assertion for a specific point
in this error trace it has to satisfy
two properties so the first one is when
you execute the trace up to this
position here then every state that you
can reach at this point has to satisfy
the air invariants essentially it's an
over proxim a shin of the reachable
States at this point and the second is
well if you continue execution from this
point with any state that satisfies the
air invariant you still have to hit the
error so you still have to violate the
property at the end so you can think of
the air and ground as being an
explanation of why the by the trace
files from the perspective of that
position in the era trace so here's some
other air invariants in the program and
so there's some some interesting thing
here so if you look at these two
positions they actually satisfy the same
error invariant now so essentially it
means that well what you sort of do in
between doesn't really matter for
reaching the error in the end right so
well this case it's sort of obvious
right because you're assigning a
variable Y that is sort of irrelevant
for for the value of x and this is sort
of what the slicing criterion gives us
so the the arrow invariance is what
defines this abstraction of the of the
trace so once we have the air invariant
so if we go back we go to this finite
abstraction so now we have these boxes
corresponding to the actual Aaron
variance and then we have transitions
between these boxes and we can see here
is a loop that we can now slice away and
that's the output of the
of the analysis now of course Aaron
variants are not unique so you can say
so for instance if I people go back here
you would see that just by taking the
actual reachable States here as our
errand as formulas that would also be
potentially Aaron variants and that
would of course not give us any
abstraction at all and so we essentially
would end up with the same trace that we
started with and so here's another set
of Aaron variants where there are so
slightly more abstract when I will just
say that X plus a is a smaller equal to
zero and now we can see that this Aaron
Riley actually holds throughout all
these three positions so now we will do
the abstraction I end up with a slightly
more compact explanation where say okay
the only relevant statement is this
assignment to X and before I do that
assignment this this formula will hold
throughout the entire trace okay so this
leaves us with the questions whether
first of all we can actually
automatically compute error and variance
from a given our trace and the second
thing is can we actually obtain useful
error and variants that really give us
useful explanations of what's going on
in the trace and this is where sort of
constraint solving comes in so now we're
going to take the error traces convert
them into logical formulas and then do
reasoning about these formulas to
extract Aaron variance from them okay so
here's how this works so this is
probably something your bulbs all scenes
we we start off with a trace we do some
kind of logical encoding using static
single assignment so you can see now
whenever we have an assignment to one of
the variables are we going to introduce
fresh logical variables for these for
the resulting value and well this
formula now essentially encodes exactly
the
the actual executions of that trace that
in the end satisfy the expected outcome
so well this essentially means that
since this is an error trace that
violates this property this formula here
will be unsatisfiable so there's no
execution actually satisfying x2 greater
than zero at the end so now what does it
mean to actually check that a given
assertion is an error invariant and well
we can do that by looking at these trace
formulas so we just look at this
conjunction and say we now have a error
invariant for for a position P inside of
the trays well what we do is we split
the trays into these two parts a and B
and then I is an Aryan variant for P
well if it's implied by a so it over
approximates the region will say that at
that point and the conjunction of I and
B is still a salon satisfiable right so
this means we still hit the arrow when
we execute the suffix of the trace well
you might already have guessed this sort
of connects the question of computing
Aaron variants to crack interpolation so
now if you look at this condition we had
so we have that I is an errand variant
for position p if well it's implied by a
and it's still inconsistent in
conjunction with B so this is exactly
the condition that a crack interpolant
for this conjunction a and be satisfied
satisfied so essentially this means that
we can use in say an interpolating smt
solver given a and B to automatically
generate these air invariants I so
essentially we just take the take the
trays encoded as a formula and use an
smt solver to compute Interpol ends
along the way as candidates so for
seeding this the slicing and then we
just use it to compute the the XX slice
so if you go back to our example say
this is our trace and these are the
interpolant we get back from our SNP
solver and now all we do is essentially
propagate these
these are invariants along the trace
trying to see whether they hold it and
in the other points along the trace and
this is how we defined as this
abstraction of the trace so in this case
well we get our form an X plus a small
equal to 0 and this is the one that
holds all the way here so essentially we
compute some kind of smallest coverage
of the trays with the given interpolant
from the SMT solver and that what's
that's what defines the actual
abstraction the actual app sex lies we
give back to the to the user okay so um
we're actually implementing this in a
tool and we did some preliminary studies
where we looked at some real world
examples so this is taken from the UNIX
tool SED where we had some seeded bugs
inside of there and so this is one
example where say we have so the whole
thing is roughly like 12,000 lines of
code the entire program and the error
trace is around one thousand lines of
code and it's really spread out over
most of the actual source code so
actually understanding what's going on
there just by looking at the traces is
rather difficult problem so this was
some examples that have been used in
some previous work so it's essentially
for comparison of these for mobilization
techniques but the actual bug was
missing in the initialization of a
global variable and so this was pulled
in into some at some point and then
there was some some invalid pointer
access some somewhere in the program
leading to a segmentation fault and this
is sort of the the abstract slice we get
back we using our techniques and it's
really quite nice so you can see this is
essentially the initialization of this
global variable last rack X so it's set
to null essentially and then you can see
how that value propagates through the
program to the point where some pointer
is the referenced leading to the
segmentation fault
okay so yes before I finish let me just
talk about another application of these
techniques in a slightly different
setting so this is a taken from an open
source java program and so that this
program is not wrong per se but there's
something funny happening so if you look
at this conditional here saying that he
is now can actually can you see whether
this value is ever now in this program
so is this is test ever ever succeed
when that point is reached anywhere
crashed yeah I exactly so you can see up
there in the first conditional there's
this call to get ID on a right so then
of course if he was now then that would
already be a nullpointerexception at
this at this point here so whenever you
get to that conditional then he will be
non now so there's something strange
going on here and we call these this
kind of situation inconsistent codes so
essentially the programmer has some some
assumptions about the program States and
well these certain these assumptions and
she can never be true so as for instance
the conditional branch can never be
taken because the branch condition will
always be false and so we previously
worked on a two layer can detect these
kind of situations and the questions can
we also explain them to the programmer
right and this is again something where
that we can do with with error
invariants perhaps just so why these
these kind of consistencies interesting
well often they are actually related to
true backs in the program so here
essentially what is what the problem is
that these two conditionals here that
these two if conditions they should
really be swapped in the program so this
is the test that should happen first and
then the other one should actually
happen
okay so what we did is we applied era in
variant based techniques to this to this
problem so essentially whenever we get
such a program we compute an abstract
slice of this entire program and this
gives us essentially some relevant
statements and some assertions over
these statements and we've made some
human studies where we used these
absolute slices to let programmers
understand so try to see whether
programmers understand these
inconsistencies and what it turns out
that using these air and variants it's
much easier for them to actually
understand what's going on in the
program it's not surprising if you see
that you really sort of end up with the
relevant statements that explain the ed
inconsistency together with these
assertions telling you what's what's
going on running wolf or CN or John yeah
it's true it's two different tools so
there's one it is sort of running on
Java and we are working on another one
for 4c programs so this I mean this tool
is really just for now looking at these
these inconsistent code in Java programs
and then explaining them using air
invariance the running time Michael the
cell example if you show with about a
thousand how long does does it take to
find the explanation so the I mean the
actual interpolation is in a matter of a
few seconds still I'm even for these
sizes of of traces its sooo pretty fast
yeah exactly that's all yeah so it's you
could do some kind of binary search on
the tray so it's a I mean sort of
bluegrass making the size of the trace
okay so let me stop here and then swan
aamir can take over so just to summarize
what I talked about is this new
technique called fall abstraction that
is essentially a static technique for
doing fault localization or more
accurately actually fault explanation
and what's the the key difference to the
existing work what essentially allows
you to avoid so it doesn't really
require any kind of comparison
comparison between failing and
successful executions of your programs
you don't actually rely on testing to
get good results out of these these
techniques and well we did some case
studies and we were actually able to
compute concise explanations of errors
in in real programs and well the key
concept you should remember is this idea
of Aaron variants it is sort of closely
tied to two interpolation and that's
sort of how all this ties back to
following methods and verification
techniques that we can apply in this so
software engineer in context okay so but
if you have more questions I'm happy to
take them now and yeah well not gorgeous
but looking at just one place you can
miss out on for stock vector control
flow and you're supposed to go some
other way yeah so are you going to be so
I go to move on other statements or I
wrote it for spurious so what we
actually do is we use a slightly
different encoding of the trays into a
formula so essentially whenever you take
a branch you make the conjunction of the
the brand or this of the statements in
the branch you make that conditional on
the branching condition since you get
some kind of implication encoding of the
trace essentially whenever you whenever
your arrow sort of depends on all the
information inside of that branch you
sort of have to also explain why you
were taking that branch and if it
doesn't depend and sort of it doesn't
matter in the end so essentially in this
case you will also get relevant
statements that explain why a certain
branch condition was true at a specific
point
so I'll be happy to take more questions
after the talk and then otherwise one
way I can take over for the second part
okay so thanks for invitation again I'm
wanna meet for dinner which and I'm
student and why you Thomas is my advisor
and today I'll show you what our minimum
temperature TSA's why are they important
how to find them so this is also
generally tim king who was anybody
student also at a time so i apologize if
my voice breaks it seems that that was
not prepared for this amount of rain in
Washington so in this work actually
focused on a slightly different problem
so if you're interested in localizing
type errors in programs written
languages that support type inference so
to introduce it to this problem or
remind you if you're already familiar
with it let's consider the following a
camel program so if you're not familiar
with a camel I'll just walk you through
it so on the first line so actually
still written by student who is
completely new to camel so on the first
line the student is defining a
polymorphic this data type so basically
says the lists can be constructed with a
no constructor basically sets an empty
list or with a cons that takes the first
parameter the head of the list and then
the reminder of the list as you can see
here we are representing a type
symbolically which means we have a list
of integers list of strings or list of
list of integers but every element in
the list has to have the same time so
more interesting Leon the next line the
student is defining X to be a list
having a single element number three
which means that this X has a type of
list of integers and then on the last
line the student is trying to print this
X we have a function print string that
is defined in Steiner library and it has
the following text signature so except
strings and it turns a unit turn it is
similar to avoid in for example Java and
C so if you focus on this program you
can see that the student didn't provide
any type annotations so for example an
egg's you but you will usually see in C
in Java it would say eggs has to be a
list of integers and then they find a
value so no camel you don't have to do
that so the way that the camel deals
with this is that it in first types of
program expressions just based on how
they are used in the program so it is
usually called type inference so the way
the compiler actually will be this
program is pretty much the same as I
just explained you so when it comes to
the X expression on the last line it
sees that X has a type of list of
integers but a print string accepts
strings so
no camel this is not allowed so this is
it so this product has a type error and
the crema compiler here stops
immediately reports X as the error
source basically and says to the
programmer you should fix six however
maybe print string is the actual source
of the error in other words maybe the
student should have rights a matter
function that just takes list and then
prints every element or maybe student
define X inappropriate in the previous
slide maybe you should have written some
string but if you focus on these error
sources it's unlikely that X is wrong
because she explicitly write a list
having a single integer number three and
also it's kind of likely that X is the
actual source of the error because it
was just defined on a previous line and
it's the only variable in the program so
it seems them that print string is
actually a resource any it really is so
the students later round her own
function that takes list and then prints
every element so the main problem is the
following so the way that this common
type inference algorithms one can find
in ml a camel how skilled is that they
take the input program and then your top
down fashion the inferred types of
program expressions based on how they
use and the moment they see a conflict
in a way a program expression has been
used they immediately stop you pour the
location of the conflict is the error
source other error source is like the
finishing of aches and print string here
are completely disregarded they're never
considered now let's consider it another
example so again this is this was not my
program is this is a really weird
program is again written by a student
who was really new to the language and
again if you focus on the definition of
loop function we can again see there are
no type annotations so we know that
Princeton takes strings returns the unit
which means that else branch now values
to a unit value now you know camel both
branches of a DML statement have to
evaluate tomato same type which means
that this accumulator funk variable HTC
also has to have you any type and then
the whole loop function at the very end
returns the unit but in the last line
the student is calling this loop
function is passing a list of pairs of
flows instead of a unit so the compiler
sees this and generates the following
Terrell airport so it blends this
location to be the source of the error
and says you should fix this you should
pass a unit here however maybe again is
print string to the source of the error
in other words maybe they should be used
a function that takes
strings and returns a list of pairs of
floats so believe it on that this was
actually error source but the reason why
this example is particularly interesting
is about the location that the compiler
suggested suppose we actually pass a
unit here so what happens well the cool
to the loop function is well typed but
since loop returns a unit this is passed
to list reverse that accepts list so
even fixing the location that a compiler
suggests that doesn't make the error go
away we still have a type error so what
is the problem the problem is that these
type error reports can often get really
tricky and cryptic and David is
basically don't help the programmer fix
the error so this increases the back in
time and it's really difficult for
novice programmers to learn a language
so how can we do better well we can
consider all the resources rank them but
and compile it rang them assigned
criterion they find useful and then show
the top-ranked error source to the
programmer so is this a new problem well
it's not actually it's a quite an old
problem and in fact it's quite a
recurring problem every couple of years
you can see a couple of papers on the
subject so basically the solutions range
from showing the slice of type inference
that is involved in the error the
showing the program slice that's
involved adair to special designing type
systems that trace the error however
among other things the drawbacks of the
research is this proposed solutions is
that what would they actually do is they
would propose the dis criterion and then
they will design and implement the
system are centered around this
criterion and then evaluate on
benchmarks and say we believe this would
work good in practice but if you want to
change this criterion you have to change
the whole system also these solutions
would usually focus on a specific type
system and they will also require large
compiler modifications so in this work
we were not actually interested in
providing yet another criterion for
ranking error sources that we believe
might be useful in practice we actually
asked us have something more general so
can you enable compiler is localized
type errors but inside she evaded first
we can abstract from a specific ranking
criterion and this means is that we want
to enable compilers easily plug in and
plug out criterions
so they can compare them disseminate him
Jones to the ones I think of the request
in practice basically change them at any
point that one also came in design is so
that we can support different type
system sorry different type systems
because we would like this approach to
be applicable to ml or caramel and
haskell as well and also can we design
it in such a way that the implementation
overhead is kept low because we have to
have in mind that if we propose this to
compile developers they probably reject
any solution the changes the whole
compiler infrastructure so this work we
actually propose a general framework for
type paralyzation that meets these
requirements is based on constraint
solving now before showing you the
actual framework I think that we
actually first need to define this
notion of an error source more precisely
so again we had a really simple kind of
program and we can see this natural type
because boolean occasion is applied to
value it has string that so in our
framework when we say that X is an error
source so what we actually mean is that
is there is a fix to this program
location that makes the error go way it
makes the program well type for example
instead of weeks we could have write
some boolean constant and that will make
the programmable type so another
framework we're going to represent a
generic fix for a program location but I
by replacing the program expression with
a whole so this whole is merely a
placeholder it doesn't constrain the
type in relation itself cannot be a
source of a type so now when we replace
X with a whole this program is well
typed which means that X is a potential
error source so we're going to define an
error source to be a set of program
expressions that once corrected I'll
replace by holes the yield of l-type
program now it's all it earlier you can
have multiple error sources for example
not X is also nursers we can just fried
eggs instead of ethics and this will be
a well type program but if you compare a
developer you might try sure the phrase
this is a well dang program well dive
according to which type system the talk
of the programming language ok so to
give you some markers doesn't the time
ty system does not understand okay ?
sure so yeah I wanted to strap on that
by the way we actually formalize this is
this is a programming construct each
time it is used it gets a fresh start
variable so basically each will it will
if you always unify with any type of
give it you know right so no camel it's
actually raising these lovely an
exception in our camels Oh basically if
you go to camel then you write X program
expression that raises an exception you
look at a type it is going to be a type
variable so this is how we formalize it
but as you as we will see shortly will
actually not going to implement this in
the language we're going to do something
relatively simpler let us better hear
the same effect okay so like I said we
can have multiple data sources so but if
you are compiled developer you white 1i
just show xterra fanatics as an error
source but in general there should be a
way for compilers to prefer some error
sources over the others or in other
words they should be waived for
compilers to rank error sources by sun
criterion it defined useful and in our
framework this criterion his comfort is
cooperated by compilers of providing a
function from program expression to
weights now the smaller the wait the
bigger chances are that the program
expression contributes to the error
which means that this top-ranked error
source is Error sorcerer has minimum
cumulative weight and we call this a
minimum error source now note that we
didn't put any constraints on the
weights you can be positive negative but
for simplicity which is going to assume
you have positive ways which means that
minimum error sources are also minimal
so we don't have to consider our
resources that are minimal this for days
of exposition now to make this concept
of ringing criteria more precise from
more concrete let's consider an example
suppose it we are compiled developers
and we want to prefer those their
resources that require fewer Corrections
so what would be our criterion well it
could be a function that for to each
program expression assigns the weight
that is equal to the size of the program
expression in AST form so if we go back
to our example so in order x itself is
an error source you know it gets wait
one because that is its size in st form
not is also an air source because we
could have used some other function that
just takes strings for example it also
has weight one because that is its size
in HD form natick sui know it's an error
source now has weighed three high is
also narrow source because we could have
define X to be a boolean constant
for example that would be a belt I
program he also has weight one and the
most extreme case the whole program is
an error source I could just write one
and he has weight 5 so why are error
sources are these three program
expressions separately because their
error sources and they have a minimum
cumulative weight one and indeed they
correspond to these error sources that
require fewer Corrections so know that
its criteria I just show you just an
example of a possible use for criterion
the actual criterion is responsibility
of the compiler okay so the probability
actually trying to solve in this work is
the one of computing minimum type error
sources so given an input program and a
compiler provided ranking criterion we
want to find an error source this is
minimum subject to this criterion so how
can we do this so first node resection
optimization problem so we want to take
the input program when a plugin holes in
all possible ways then consider those
holes the basic represent error sources
and then find that errors of the has
minimum cumulative eight so we're not
going to write an algorithm to do this
in fact we're going to reduce this to a
well-known problem for which you already
have available tools in fact we're going
to reduce it to weighted maximum
satisfiability module tears so this is
our framework so compilat provides an
input program and the ranking criterion
to this typing constraint generation
procedure so what this procedure does is
that it takes the input program and
using the typing growth of the
programming language for each program
expression it generates typing
assertions that basically denote the
typing information they of the
expression and that the set of these
assertions is a part of something called
typing constraint also this typing
constraint contains encoded program
locations and two-inch this program
location we propagate the weight given
to it by the ranking deuterium now this
typing constraint is then passed to the
weighted max SNC solar which in turn
produces minimum error sources now
before showing you the actual details
how this actually works I just see what
this reduction to very much less empty
gives us so since we'll be using way
DeMarcus inches over to compute minimum
error sources we can support a different
type system by relying on rich
SNT solvers support also we are using
the weighted magazine tissot emergence
of black box so we are not imposing
substantial compatibility requirements
for modifications and also note the
ranking criteria now is just past and
different parameter is not fixed once
and for all so each time the framework
is called you can pass a different
criterion okay so let's define a way to
max S&amp;amp;T problem sure yeah it seems to me
that you are doing a lot of changes to
the compiler will have to modify the
compiler so you can implement the
left-hand arrow ok so the compilers in a
sense they already produce this typing
assertions I think what I do they
produce a typing assertion and this
unification to solve it so ollantay we
have to do is just put it on the side
and encoding into an smt formula it
actually did it is it really rather the
simple so they're really produce we just
use need to inquire yes empty and put it
on the side how is the ranking criteria
your specified so it's a function from
program expressions to wait expressions
are being put through exactly so
basically each time is called you can
pass a function that accepts the program
expression it just returns away so we
have be abstract from a concrete
experience just some function for
program is precious to me what is the
actual function is responsibility of the
compiler ok any other questions ok so
let's define a way to math isn't a
problem so its input we have a set of
hard clauses that mouse hole we had a
set of soft clauses where each clause is
assigned the weight and each clause
belongs to some force some fixed
personality like on your relatives for
now as output we have a subset of soft
clauses that are the same time
satisfiable I have maximum cumulative
eight and this is going to be computed
for us by the solar so you might not
wonder ok the solution are a set of soft
clauses that have maximum cumulative way
but we want to compute minimum type
error source
so how do we do that to see that we need
to actually look in Arkham encoding so
remember that i mentioned that what
you're actually trying to do is we try
to plugging holes in all possible ways
and then find that set of holes that
represents a minimum error source so we
actually want sober to do this for us so
somehow we need to encode the structure
of the input program as well as the
typing information so the way we're
going to do that is basically we're
going to simulate the applicant x3 of
the program where the context of the
node are going to be typing assertions
that encode the typing information of
the program expression as well as the
point of three children so now for the
whole expression that the whole program
we have a root node which we denote with
a propositional variable T line and
basically in this proposition that it
implies the content of the node the
reason why we use implication is going
to be going to spend in this manner so
this typing assertion says that a type
of the variable the type of the let
expression denoted by the type variable
Follette is equal to the type of the
natick function application result now
we do the same for the children now for
x equals high again we have
propositional variable standing from the
node and the contents are that the type
of the X is string and we do the same
for function application and let me say
that the function the type of the
function being applied is type of nut
and the type of the parameter being
passed is type of X and note that not
function is defined in the standard
library so some honey to encode also
this so we have another clause basically
says type of the null function is
basically its function from bullion's to
bullion's and these are positional
variable stands for the location in the
standard library so this is going to be
set as a hard clause so what are soft
clauses the propositional variables
since each propositional variable
basically represents a program location
the weight assign to the program
location by the criterion is propagated
to these soft clauses so for simplicity
let's assume we have a super dump
continues to say assigns wait one to
each program expression so when give
this the soul that the first thing the
solver is going to do is going to set o
propositional variables to
so what is but it means that these upper
heart clause is going to reduce the
following set of constraints and they
are unsatisfiable and this corresponds
to the fac an input program as it is
right now is not well typed the series
know that that is a function from
bullion's to billions and they're in
this function application we are using
this not function but a type of the
parameter being passed is string so this
is not satisfied okay sure but then the
long arrow is yeah that's implication
right and then so good the relative
finding power between education and
conjunction so basically this and they
basically this have a harem ah okay
maybe I should have made this more clear
okay so for example this part should be
together that mine yeah line breaks yeah
yes is it yeah we just corresponds to
this doctor of the disc responders are
actually some expression and so the type
of its veins are higher than personal
and februari you said txt Falls for
example yeah so I'll come to that
actually okay so right so this is
unsatisfiable again corresponds to the
fact that the whole program is that what
type and actually these typing these
typing assertions we have here is
something that actually compilers in
their type checking problem consider
basically like I said in the top down
fashion they generate this assertion and
they solve it using unification and if
they fail they just report this location
as the source of Europe but here we have
an optimization problem so what the
solver is going to do is going to set
some represent variables to false and
let's say sets TI to false not as we set
the I to false because the implication
this typing assertion can basically be
disregarded and as a consequence this is
now satisfied and this corresponds to
the fact that this program expression is
replaced by hole so the effect of
setting some preposition variables to
false is that the corresponding program
expression is replaced by whole and now
since TI has these
propositional variables in green are set
to true and basically now we have a
maximum cumulative a solution so
basically minimum error sources are
actually complements to weighted max smt
solutions okay so we have implemented
this framework can be targeting a camel
actually the camel part of it and which
at its core hands a hill in many type
system and constrain generation was done
using an easier camel tool this is a
tool build in the previous research in
the subject and this typing assertions
were basically encoded in a GF in decade
data types so the variant Mac isn't if
so where we had to build on our own
basically it was a simple ramp wrapper
around CBC for SNC solver and sat for J
max said services the reason for that is
that we had there is yikes this is
Oliver that supports waiting Marcus
empty but generally perform well but
actually it seems that in Microsoft
Research is now putting some effort into
providing this facility for Z dream
which is very nice and so we also make
evaluation on these benchmarks from the
previous research on the subject we had
350 programs in fact these benchmarks
are all camel programs written by
students and they will develop the do
dub actually those two examples at the
very beginning we're actually from that
bench ranks so know that our framework
the our contribution is a framework that
abstracts from a secret Tyrion basically
formalizes this problem of fair
localization is an optimization problem
but we also wanted to see how good at it
actually is at pinpointing the actual
error sources against compared to the
side of the camel compiler and we saw a
15 increase in accuracy for a random
sample and the actual criterion we used
was the one where to each program
expression we assign weight equal to the
size of the expression in SD form so
more interesting the virtual for
execution times so how much time does it
take to compute a single minimum error
source so the x-axis basically we to the
management we broke it into the groups
based on the size of the code so this
item basically says that we are here
considering those programs from 0 to 50
lines of code me here 47 of them you can
see the medians are pretty good but
maximum can be pretty high so what is
the reason for this
ok so our wedding market sent this over
can be definitely proved this is a naive
implementation however the problem is so
is more fundamental and that is that the
size of the typing constraint measured
in a number of typing assertions is
actually actually getting exponential
and the reason this is as follows so we
have here a rattle a simple program
basically we are defining a ID function
and then just applying it to integer and
bullion this is a well type program so
here I'm not going to use our encoding
be propositional variables just for
simplicity so what happens is that these
are typing assertions are so did it to
this function medical sense the type of
ID is function from some input type to
some output type or the input type and
output type of the same so in this ID 1
what are the typing typing assertions
generated for that expression are the
following so the most interesting pile
is this so what happened is that we took
this typing assertions copy them and
instantiate it in with fresh type
variables and we did the same for the
for this part why do we have to do that
if you haven't done that if you just use
alpha ID in both cases then we would
restrict alpha I inference first time to
integer in the second time to boolean so
basically each time a polymorphic
function is used the set of typing
assertions has to be copied and
extension refresh type variables this is
how you support polymorphism in
constraint-based type inference the in
fact the matter of fact i'm not using
our encoding yet just the coding that
compilers use generally shows that this
is not a problem that is tied to our
approach in fact type checking believe
it or not is exponential time complete
so you can design a small camel program
of six lines of code and basically take
forever to type check by the way that
the compilers deal with is is that when
they compute is set of typing assertions
associate to the polymorphic function
they actually compute a principal type
for this polymorphic function which is
basically a type summary and then the
instantiate this principle type each
time to use however we can't exactly use
the same trick in our problem because
type checking is a decision problem and
we have an optimism
asian problem so if you compute a type
summary and then just use it each time
we have a polymorphic function then when
the solver sets a hole in the definition
of polymorphic function this shoe size
will be propagated to the typing summary
and this is what we're currently doing
and the paper we actually propose two
solutions lazy quantify debate
Association and layers unification bay
de stancy ation unfortunately due to
time constraints I won't be showing this
in more detail and also we're breaking
or something else third approach however
even if you saw that is possible that
you just have some so much typing
assertions if you have the huge program
like 100 thousands of lines of code but
we actually observe is the following so
suppose I have a program that is like 10
pounds of lines of code is perfectly
well type and now you write an
additional function completely new
irrelevant to the previous code and it
has a type error now a framer has to
pull in all typing assertions and and
some of them the great majority are
completely relevant to this problem so
basically we designed in the paper and
actually experimented with to further
optimizations constraint slicing a
pre-emptive carry cunning so what
constrain slicing does is that it runs
the standard okay I'll type checker
which reports a location of the error
which we know that is not correct
probably by basically but it allows us
to take that location they computed a
slice of the constraint that is relevant
to the error and then just consider that
slice and prick pre-emptive cutting is
something else in a based on the fact
that programmers are now used to the
fact that when they have a type error
they're always looking for the solution
in the upper part so this is what we did
we have a type error and this part below
we completely disregard and just
consider the upper part and in fact we
can actually see four to five times
increase in execution times so as in
conclusion to the contributions so we
believe that this is a clean formulation
of type error localization basically we
reduce this problem to optimization
problem and we can abstract from making
criteria which actually opens new
research directions so basically we are
separating the search for the minimum
error source for the actual definition
of a minimum in Japan is really useful
also we find we propose a solution
this algorithm by reducing it to the
weighted max SNT problem and but if I
that we can use the solvers we can
actually support various type systems
and it can actually does require
substantial kampala modifications so
these are also top is you can also find
in the paper and I ready to take any
questions sure are there situations
where you can out you need to make our
footballs in part yes yes would you does
it make the simple all the time closing
right if if you're wrecking criterion is
such that putting two different holes is
in that is the action minimum air source
maybe we computed so the guarantee we
provide you that we're going to find
that error so that has minimum
cumulative eight so that is a formal
guarantee that we provide you so will
not do any approximations you will
actually compute the actual minimum
every source whatever it is you do the
experimentation you have users for you
so these benchmarks that I mentioned so
we took random sample and about it
basically the way that this benchmark is
organized is that the students were
starting to write program and then you
can just look the versions of the
program and then that's how you see you
know why they actually fixed and this is
how actually observe and what was the
actual source of the error but it was
kind of difficult because students
really knew sometimes tend to just you
know give up and write the program from
scratch but yeah we were able to take a
random sample and run it sure based on
same vision to help and does this happen
that minimum energy source is not
actually the real source so you're
supposed to do more changes right so
sure so consider the following program
of camel not to it is not well tagged
right so why does the actual source of
Europe is it too is it not you just
don't have enough information to program
text so basically all you can do you
just heuristic alee try to guess and
that's what previous frites which we do
they will just propose different
heuristics so another framework these
heuristics are actually this ranking
Criterion's so we in our work we weren't
focusing on yet providing an adequate
you're actually providing a framework
you can just experiment with these
different Rotarians change the
choose the ones who take you never work
best and actually can easily prototype
this so sure functions i can give you is
it in the IDP function any function for
programming practice two weights hello
phytic acid acid base playing good sorry
it has to be translated two weeks for
the encoding yes exactly that's true so
I can't give any complicated thing okay
native well in a paper we actually
propose a this AST we just gave an
example but the ocean also so also show
some other criterion so let me just go
back doing this kind of optimization for
this way you have that's it graphic
weights essentially whom that might be
one thing that's interesting to see ya
see the size is your first material that
you just add up more criteria can narrow
it down yeah so so one day my machine
that in technique exactly field on
radial basis function so can i use them
yeah so complicated exponential okay let
me actually answer that actually so so
see here the lobby say that when you set
up a position variables to false the
fact you have is that the corresponding
program is passion is replaced by a
whole which means that program expansion
should be fixed so what it means if
setting this variable to false it means
you should fix the implementation of not
in the standard library but it is never
the case right this isn't this is not
that you want to show so the way you can
completely disregard such error sources
is making them hard assertions so you
presented so this way you can you can
completely disregard error sources that
come from the standard libraries so also
in the paper we show how to actually
give actual constraints themselves as a
part of a criterium in basic you can
support even richer an easier way you
can support richer experience about a
question of machine learning so what we
actually observe this is a is that in
our programming the type errors we get
actually follow up pattern so when I
program and have type errors i can
actually see a pattern which maybe means
that i'm a bad programmer but
nevertheless if we could apply machine
learning techniques that basically learn
each time i fix my errors and update
this criterion then i would be able to
actually cast
my type error reports but a problem
actually want to do this the problem is
these benchmarks and I be representative
and we are currently trying to get in
contact with people from like Jane
Street and Wall Street basically they
develop the whole infrastructure in your
camel and actually really interested so
we hope that we going to get some good
benchmark so we can experiment with this
see my yeah yeah sure so that definitely
definitely it's actually where we find
this is really important for you know
adopt in the language so people from
James 3d actually told us that you know
once i get experienced you get better at
resolving errors but still front i'm
tanking it's really annoying but this is
the most problem is for students they
can get really frustrated actually you
can see from the benchmarks it tries
once to three times and then just gives
up doesn't solve the task and we feel
that at least for for this slowest
programs they can actually really help
and had a question about our
localization I understand that people
build cloud infrastructure and services
sometimes when a failure happens they
can spend on the order of gays but yeah
so you gotta expert for marriages and so
make sure we very interesting is whether
we can you generalize this to baby cast
different error localization problems as
this one and then bake that you will
have a really nice framework think about
this problem we sometimes can get
actually really really useful questions
okay sniper speakers</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>