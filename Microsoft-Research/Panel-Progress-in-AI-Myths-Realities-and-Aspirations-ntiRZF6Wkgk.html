<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Panel: Progress in AI: Myths, Realities, and Aspirations | Coder Coacher - Coaching Coders</title><meta content="Panel: Progress in AI: Myths, Realities, and Aspirations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Panel: Progress in AI: Myths, Realities, and Aspirations</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ntiRZF6Wkgk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
next have a panel to tell us about
what's happening in the world of
artificial integers the progress discuss
the myths and realities to do that who
better than my dear friend and colleague
as a moderator le coeur wits Eric come
on out
Eric's of course doctor doctor which you
know and he's also the head of her
Redmond research lab and I call him mr.
AI because he's been with the field as
long as in EFS was the president of my
American Association of artificial
intelligence now back again Eric
well thank you very much and let me just
might my guest our panelists today come
on out welcome to the panel on progress
in AI myths realities and aspirations
our guests today include Christopher
Bishop distinguished scientist Microsoft
Research on your on your right and next
to him Oren Etzioni
chief executive officer of the Allen
Institute for AI we call that AI to push
short around here in the northwest faith
Bailey associate professor at Stanford
University Michael Wittmann professor of
computer science at Brown University and
Josh Tenenbaum to my left professor at
MIT beyond our panelists of course we
have many experts in AI in and related
areas scientists with us in the room
here today and I've asked the panelists
and I'll ask this audience to think as
well today as we reflect together
several framing questions where are we
today with hype versus reality on the
path to developing richer notions of
machine intelligence along the lines of
what the founders of a I dreamed about
in the 1950s where will we be in 15
years what are the biggest standing
challenges what are your best guesses on
the technical and programmatic paths to
addressing these challenges
I'll start by Framing discussion just a
bit with some comments on progress in AI
so I view AI as the pursuit of the
scientific understanding of the
principles and mechanisms underlying
thought an intelligent behavior and
their embodiment
and machines and the filth has its roots
as many of you know in the early work of
Turing and church on computability and
the later work by Turing and by Norman
on the notion of a universal computing
machine which lit up imagination about
what we might do with these machines
including building Minds one day the
phrase artificial intelligence was first
used in early 1956 in a very prescient
proposal type I refer that folks to read
all the time for a workshop on machine
intelligence that took place that summer
at Dartmouth and in a beautiful document
the co-authors called for research on
machine methods of forming abstractions
from sensory and other data carrying out
activities which may be best described
the self-improvement manipulating words
according to rules of reasoning and
rules of conjecture and developing a
theory of the complexity for various
aspects of intelligence now things moved
quite fast at the outset and there's a
great deal of optimism about where the
field was going in 1965 herb Simon I
mentioned to many of us said that
machines will be capable within twenty
years of doing any work a man can do
two years later Marvin Minsky predicted
within a generation the problem of
creating artificial intelligence will
substantially be solved that would have
been the 90s now on the one hand we've
made great progress over the decades
there's been a palpable upswing lately
we saw some examples in the first
session of today and this work has been
largely fueled by the explosive increase
in the availability of data and
computational power and of course some
some good ideas we've made progress
especially I'm building out narrow OLAP
but I refer to as deep but narrow wedges
of competencies such as work on the
Mosel classification prediction ranking
work in vision and speech recognition
and natural language processing and
these advances have quickly found their
way into our products and the products
of our competitors and indeed are
defining a shared competitive
scape now for success in industry on the
other hand it's been a slow slog on the
dream of building machines that show the
kind of deep more general intelligence
exhibited by people
I'm sure the founding fathers of of AI
would likely be rather taken aback if
they saw where we were
in 2015 about our understanding of the
magic which is still called magic behind
human level abilities to reason learn
understand with the common capabilities
and the common sense that even small
children have one might even say that
that is six proposal if properly
reformatted it could be resubmitted to
the NSF or DARPA today and we'll
probably get some funding by some
excited program managers even though the
progress on building out deeper
intelligence has been slow researchers
do have fabulous intuitions they working
on the things that excite them the most
on the path to answering some of the
bigger deeper questions on the
challenges and frontiers and how we
might get to the next level and this is
why I've invited these particular folks
up today to help us as guides in a
sextants in where to go next and so I
each just share five minutes of
reflections and then we'll open it up so
Chris go ahead okay thanks alright so I
guess maybe a good place is my
microphone working by the way ok great
so I think a good place to start is just
just to acknowledge the fact that this
has been a tremendously exciting few
years and we're living in a very very
exciting time and obviously one of the
reasons behind that has been the
spectacular successes in a number of
problems as Eric has already hinted at
in in the use of neural networks and
so-called deep learning and I'm actually
a big fan of neural networks I I started
at my career in physics and I switched
into computer science in what you might
call the second wave of excitement and
in your networks around the sort of late
1980s
and I thought there's a really great way
to approach artificial intelligence by
learning from data and today we're in
the third wave of excitement around
neural networks and as eric has
mentioned there are only three factors
behind this behind the fact that we can
have much better performance now and a
whole range of tasks than we would have
had a decade ago so one of the factors
is the availability of huge amounts of
data compared to what we had in the in
the 1990s the second is a huge increase
in in compute power compared to what we
had back then and then also some I think
relatively minor but important technical
advances so really the whole idea of
deep learning deep networks has been
around a long time I wrote a textbook on
your networks which was published twenty
years ago and there it talks about
multi-layer convolutional neural
networks for invariant object
recognition but today we have systems as
some of some of the other panelists have
developed which have really human level
performance on many of these tasks now
the fact that we've been able to take
some of these twenty-year old ideas and
accelerate them through more data more
compute and a few tweaks to some of the
the algorithms means that maybe some of
those other ideas that have been around
for a long time could be right for big
advances so I do feel the next few years
is tremendously exciting for the field
of machine learning and I guess I'm sort
of implicitly assuming that the machine
learning is going to be the thrust of
our approach to artificial intelligence
maybe there are other ways we should
approach this but I think machine
learning will be at the heart of it and
I'm sure neural networks and deep neural
networks will be components in any
larger a more capable system that we
build so are we kind of nearly done are
we nearly at AI well I think not and and
deep neural networks and similar
technologies for all their advantages
they have a lot of limitations so one of
them of course is that in standard
approaches they're trained using labeled
data although data is plentiful the
labels typically are not often the
labels are obtained by humans perhaps
hundreds of thousands of hours of human
effort to get those labels whereas the
human brain seems to learn mostly from
unlabeled data you know kids crawl
around the world and they just sort of
take all this stuff in and occasionally
mum and dad says oh that's a cat that's
a dog you don't have to see 27,000
examples of a cat before you begin to
sort
get the idea of what a cat is so there's
something something that we're missing
in those in those techniques and I and I
guess I'm fast running out of time but I
have a few thoughts on what the next
steps might these a little bit later we
can we can talk about some of those so
in terms of where we've got to where
we're going to get to I actually think
we've made a very big advance in the
last five years towards artificial
intelligence in a general sense and by a
big advance I I would guess we're sort
of we were 2 percent of the way there
compared to where we were ok so 50 more
of those big advances and I think we'll
have something pretty exciting great but
you came in under time so orange
excellent thank you I'll take up his his
exit Eric runs a tight ship we're not
allowed to use slides I have some notes
and I say that several folks on the
panel said well no slides I'll just do
some some dancing on the stage I always
plan together yeah so I very much agree
with what Chris said about a we're in
the midst of what's called AI spring and
that's where I can't show you the slides
and that was my spring dance and and
secondly that this AI spring and this
big data paradigm not just neural or
more broadly machine learning algorithms
has some very clear limitations and I
just want to take that theme two steps
further so again as he said we need
label data often we don't have it that's
a wonderful computer science problem
whether it's Mechanical Turk or distant
supervision there's a variety of
techniques for getting more
semi-supervised learning getting more
learn data I would say that that's not
enough to me a lot of what AI is going
back to herb Simon is the study of
problems that are very hard to formalize
or maybe even impossible to formalize
directly so I feel like once we've cast
it as a technical machine learning
problem once we've identified the
objective function and all we need to do
is solve the optimization can still be a
very hard computer science problem and
actually that's a great thing for us is
collaborating with you know folks like
Jeff Dean and Google and
others read who come from different
backgrounds and help us scale our
methods it's a wonderful success but but
many of the most fundamental problems of
the eye we don't know how to formulate
the objective function in the first
place so the problem that we're working
on at the island Institute is really
taking the I grant challenge problems
and figuring out how to map those to
technical computer science problems case
in point the problem that's near and
dear to my heart is machine reading very
simply take a textbook say in biology
read the chapter in the book and answer
the questions in the back of the book
okay very very hard to turn that into
any kind of reasonable optimization or
machine learning problem I mean you it's
it requires a lot more decomposition a
lot more formalization to do that it
doesn't just reduce to a simple vector
and actually I do think that you know at
AI we've had these kind of hype cycles
over over expectations while I love deep
learning methods I do worry when you
start to see terms like I saw recently
thought vectors where you where again
we're verging into the hype cycle
because thought is not something that's
expressible as a vector okay it's just a
little bit more complicated than that
it's a classic a few more dimensions
there but I like where you're going the
the other point that that I wanted to
make and again actually just to stay
with the greats
I thought Allen Newell put it incredibly
well when he said you can't play 20
questions with nature and win you can't
reduce AI intelligence to a series of
binary or even probabilistic
distinctions it's just more complex
requires reasoning requires
formalization require mapping from say
how we think about things how we think
in language or in images to more more
formal structures anyway that's that's
what we think about I wanted to use my
remaining one minute or so to also talk
about the whole fear thing right there's
a lot of concern about AI more broadly
in the popular community
with you know with movies and and so on
but also even within the AI community
right they've been various thoughts and
useful discussions about how do we think
about the threat of AI and so on and I
guess my specific thought on that is
that I really want to emphasize the
benefit of AI the potential benefits so
when we think a thousand or a million
years ahead it's very easy to speculate
but if I think five 10 20 years ahead
what I end up with is with a quote from
somebody that I really admire who said
it's the absence of AI technologies
that's already killing people through
errors okay and that's quote from my
friend Eric which I really think
captures the fact that if we think about
AI in a rational way as opposed to
emotional way we need to weigh the costs
and benefits in the wrist let's not
forget about the benefits and when did
those come from better academic search
engines or whether those comes from cars
that will reduce you know intelligent
cars that will reduce the number of
accidents on the road or you know help
in accessibility there's so many AI
systems that can really make a
difference and help us and then people
ask well what about the distant future
and my last line I want to quote from
John markoff's upcoming book he has this
great line and he says don't mistake a
clear view for a short distance we have
a clear view of where we're gonna go I
see in this room intelligent beings it's
not a short distance by any means thank
you Eric the on the subject of thought
vectors in this terminology back in the
1990s you probably remember there was a
very nice paper published that's
actually by a young Laocoon i think and
co-authors and it was very it was
essentially how to remove redundant
parameters in a neural network and it
was a very sensible paper at a nice
eigenvector analysis actually beautiful
they decided to call the paper optimal
brain damage well first of all it's very
great honor and humbling to be with
these great researchers and scientists
who have actually inspired my own work
and mentored me when I was a student so
so Erica when he invited us he gave us
the task of discussing two things
related to AI where have we been and
where are we going
so I want to make one analogy and Josh
already and I just agreed the backstage
we're gonna disagree even though we
actually like each other's work
so um everybody knows I'm a mom or most
of you in the audience knows I'm a mom
I'm a mom of a three-year-old so if you
had have recently had small kids or
still remember having small the
experience of having smart small kids
the first thing you probably remember is
this term terrible too but actually what
we don't talk about is there's a short
stage before terrible - they were just
in total euphoria and it's somewhere
between the depending on your kid one to
two or one and a half-year-old these
babies are just so happy and they're
just like little angels running around
they're not terrible yet but my own kid
also went through that and passed that
hypothesis and I promise I'll get to AI
of why this is I think that around that
time the babies have made a huge
developmental progress in their lives
and they're aware of that and and what I
call that progress is actually the
perceptual achievement the perceptual
progress they've go through so much
actually hardship being born and dealing
with the world and for a year or two
they kind of have figured out some of
the important basic tasks especially
relating to matching patterns of objects
getting some of the words even the
language is still in formation but
they're starting to understand language
so they can match a lot of the
linguistic vocal patterns they think
they're perceptual visual perception
pattern recognition this is doing really
well they're they're haptic pattern
recognition skill is also doing really
well and they start to actually put that
together with motor skills so there is
this euphoria stage that we don't talk
about and I think we're in a euphoria
stage in our AI research and I think we
deserve that but I do wanna point out
this is where I'm getting that I think
for the past 15 years 16 years after a
lot of long history I mean starting from
symbolic system expert system
statistical machine learning we've got
certain part of perception I mean I'm
not saying we've solved object
recognition or speech recognition a
hundred percent especially when it comes
to product we still have a way to go
but I think today where we have been is
that we've hit a great progress for
perception but I do want to emphasis
that all first of all terrible to is
coming but no just kidding I do Elvises
that there's a lot more to perception
itself but really beyond perception is
the word cognition a lot of intelligence
is about cognition if you read the
original Dartmouth proposal by John
McCarthy you read the really my favorite
AI books to Russell and Peter enormous
book about introduction to AI you see
that in embedded in the definition of AI
if you unpack the word cognition it
involves acquisition of knowledge
representation of knowledge abstraction
reasoning planning decision making and
this touches on a lot of the issues Oren
and I think you guys will mention you
know it's not as AI is not just about
pattern recognition especially with a
clear objective function which class of
cat or you know where is the next eye
movement even there there's a lot of
neurons AI is really about reasoning and
formation of knowledge and in mind last
twenty second to just be a little
technical I think where we go
I want to emphasize on the word that
Chris already used is learning I think
the past at least 20 30 years machinery
has given us amazing algorithms focusing
on pattern matching and pattern
recognition I think the next stage I
hope to get to is we we learn to learn
we're learning situations we're learning
and developing strategies learning to
acquire knowledge learning to reason and
that's where I want to see AI going okay
thanks very much Michael
great so so I guess we're at the end of
the wonderful ones terrible twos that's
sort of disturbing but I want to you
know thank thank Eric for inviting me
it's really great to be a part of this
and maybe maybe you know just surrounded
by so many mentors and and and and
thought leaders though I never I never
thought of myself as a sextant symbol
before so it's sort of I'm gonna how
many but cherish that I think for a
while I was worried about that we're not
getting to correctly after late seniors
say I feel like that's worse but okay
great so yeah I really like this idea of
objective functions that's come up both
in the discussion and also in our in our
kind of set up in the green room
beforehand and it does kind of point out
I think to to kind of things that a I
might mean so if you if you think about
the questions that Eric asked there's
there's a sort of aspect of AI as it is
and as it's having impact on the world
right now and then there's AI as it was
as a vision fifty years ago and as it
you know for many people still is a
vision now and and what are the
difference between those things and and
what are the advantages and
disadvantages and they can they coexist
and the pathways yeah and how do we how
do we get from here to there and so I
want to say that the objective functions
in some ways is kind of a kind of a
branch point for that that one of the
reasons that I think the the field has
been very successful and has actually
been able to accomplish an awful lot is
because you know we now have as our
practice we define a problem we develop
an algorithm to solve the problem we
maybe throw in a lot of data we do some
evaluation
and and if it doesn't work we you know
we turn the crank and try to try to do
better we try to engineer a better
system so those objective functions are
incredibly powerful incredibly useful in
driving a kind of progress but at the
same time defining those the the way
that that set up has to happen is
there's an objective function and then
there's the system that's going to
attack that objective function and the
objective function has to pre exist the
the the optimization of that objective
function right doesn't doesn't sort of
make sense to do it any other way
but when you think about human cognition
when you think about intelligence
it'sit's not so clear-cut it's not so
obvious what that objective function
would be and and one of the ways that
I've been thinking about this is I
remember back back to having kids he
also had kids at a certain point and and
one of the things that I thought was
pretty amazing was that the process of
trying to learn to be funny so turns out
to be a very hard objective function
especially for young kids and there was
this period that my son went through
when he had gotten the syntax of jokes
pretty much but the semantics was simply
not there and there was no way to tell
him no you're not that's not that's not
funny for this reason because if he knew
that it would have been funny in the
first place and so I actually find that
to be a really powerful and interesting
idea that so much of what we think of as
intelligent behavior and human behavior
is actually layered on top of layered on
top of layered on top of layered to the
point where you can't set up the
objective function in advance and then
expect the system to kind of get there I
know we we tried for a while it's like
well will not feed you unless you're
funny and so you know it's very clear
objective function they're very
motivated to get to work but the fact
the matter is this is this is a terrible
idea right so you lose a lot of kids
this way so he's no easing we would only
caught you're AI systems that way
is that what you movie reinforcement
learning yes this is this is what we do
in reinforcement learning we put put our
machine learning algorithms in a box and
then we we deprive them of things until
like cry for marking this is turning out
way more dark than I intended but the
the fact the matter is that sort of that
notion of layering to me is actually
really important and I think it's
something that we need to we need to
rejoin as a field and really get back to
some of these ideas of of systems that
don't you know we have the objective
function we shoot at the objective
function we meet that and then we're
done we put that system on the shelf it
solves problems for us and we're really
happy but systems that are actually
gaining capability over time and that
the new objective new objectives can
actually be defined in terms of past
competence and so that's something and I
think it's really important machine
learning not just of here's a static
data set let's give it to it but maybe
us as people interacting with these
systems you know getting them to it to a
new level of confidence and then
challenge him to go even further and I
don't think we have a good model of that
at the moment but I think that's a
that's a direction that I'd really like
to go fabulous
Josh you said it wasn't clean up but
it's called something else so so thanks
yeah it's a great honor and pleasure to
be here and sort of echoing what a lot
of the speakers said I mean obviously
this is a golden age or a you know the
latest golden age for AI and we want to
be thoughtful about what we're gonna do
with it and where we're going next um
you know I'm I'm partly an AI researcher
and partly a cognitive scientist I try
to reverse-engineer how the human mind
works in the same kinds of terms we
would use to engineer more human-like AI
and III think that that's gonna be
important to driving where we go next I
I look at all the success and I have to
as a cognitive scientist I have to kind
of have to admit see the gaps I think
that the current excitement around say
for example you know data driven
learning the ski there's a clear scaling
route there for certain kinds of tasks
with well-defined objective functions
but the sense of general intelligence
that's more flexible than just any
particular task a certain kind of common
sense I don't think that scaling route
is is going to get there not because it
has inherent limitations it's just not
even trying
I think so I want but but I think I'm
inherently an optimist and I think we
actually do have good insights if we
look to cognitive science and if I can
just do anything with my five minutes is
to point to the area of cognitive
science which i think is most has the
most valuable guiding vision for AI when
I was in grad school actually I don't
remember where he said this but Bill
Gates actually said this very well he
gave a talk in the mid 90s and he and he
was talking about the early days of MSR
and one of the goals was to try to
understand certain basic capacities of
intelligence seeing and speaking and he
said if we can only get computers to be
as smart as a five-year-old then that
would be a huge accomplishment and of
great value and you know this this idea
that we should try to build AI by
looking at the intelligence of young
children and seeing that the cognitive
development half over the first months
and years of life as a scaling root AI I
think is a very valuable one right so
Bill Gates said it the early founders of
AI Turing Minsky McCarthy they all
suggest of that at key points of their
career we need a lot of the the deep
learning people also talk in that way
Feifei was talking that way I think you
know I I not only respect FAA's research
accomplishments but her vision is I you
know I think it's it comes closer to
what I'm talking about then a lot out
there but the thing is that it's not
just enough to be really smart and to be
an observant parent and to look at what
your children were doing and try to
think oh well here's my kind of
intuitive theory of what they're doing
there's an actual science of cognitive
development and just as there's been
great progress over the last say two
decades in the AI research there's been
just as much transformative progress in
the study of cognition in infants and
young children and so that's in the
first few months of life in the first
few years and I think when when Bill
Gates said let's let's aim for a
five-year-old he was already being too
ambitious because even a one-year-old is
more intelligent and has more common
sense than any of our AI systems even a
six-month-old and there's a lot of
research about this and we should study
it and learn what are the ways which
even a three-month-old has a certain
kind of common sense and then how does
that change what are the learning
mechanisms the real learning mechanisms
which grow that knowledge over the first
few
months from three to six months from six
months to twelve months from twelve to
eighteen and and two years and Three's
each of those stages are different
they're they're fairly well understood
in a lot of empirical ways there's a lot
of data it's not there's not a lot of
theory by the sort of formal standards
that computer scientists would recognize
and it's one of the things that these
fields can offer to each other we with
our computational toolkit can go and
look at the empirical literature on how
kids thinking develops and actually
contribute quite a lot and similarly
that that that empirical study and the
theories that the conceptual frameworks
that developmental psychologists have
built are hugely valuable just I'll just
give two key insights that I've learned
from my developmental colleagues one has
to do with what we start with and the
other is how we actually learn so from
the very earliest ages and some form
even like three or four month olds about
as early as you can study with the
current empirical methods a human
thought is structured around a basic
understanding of physical objects now
things like this object here this object
here intentional agents people like you
know agents with minds I don't have to
be people they could be dogs computers
they could be balls if they roll in the
right way we can see them as Minds
things that have beliefs and desires and
the interactions between objects and
agents and this is a key insight infants
don't the brain does not start off
filtering the filtering perceptual
experience just in terms of features and
more and more features it's set up from
the beginning to think in terms of
objects real things that are there and
agents how many people have heard of an
object permanence okay so most hands go
up you probably heard about this from
pop culture from your intro psych class
how many people have heard of Jean
Piaget so he was the founder of
developmental psychology and he
introduced this idea but you know if
that's where your developmental
psychology ends for example how many
people have heard of Liz wielkie not as
many hands all right she's one of the
great modern developmental psychologist
who studied infants concepts of objects
this would be kind of like if your
understanding of a I was you know in
terms of touring or Minsky right great
but a lot has happened since then
so Piaget introduces idea that that
there's a kind of perceptual achievement
to use faith-based term the infants by
one year of age
to see the world not in terms of just
pixel data but objects right but
actually as spell key and others have
shown even three month olds already in
some form have a proto object concept so
objects when you can't see this object
so over here doesn't wink out of
existence
you know if I drop it enough you could
hear that sound I'll take something more
massive right right sorry so the you
know the ability to put together sights
and sounds and represent a world of
things that even when you can't see them
but it infants are set up from the
beginning to do that okay and also to
think about I'm worried now about how
Eric is feeling if I if I you know how
do I give out a the common sense of
social discourse people seem to know
that's done but but you know again even
a even a like a one and a half year old
has a lot of common sense the ability to
you know to recognize if somebody's
reaching for something that it's the
thing they want they're not just acting
if I drop something you you know to help
me pick it up and to distinguish the
difference between setting something
down so I'm done with it
and dropping something and and you know
that your your wonderful one year old
wow they're part of how they're so
bright is they will see that they the
ability to help you that those wonderful
ones do if we could build robots that
have that intuitive sense of other
people's goals and how to be helpful
that would be huge the other thing again
is about the learning mechanisms that
grow this knowledge it's not just about
kind of statistics on a grand scale but
in the same way that these these are you
know again to echo themes of some of the
other speakers here that the early
knowledge isn't just patterns but kind
of these intuitive theories
understanding of abstract concepts the
way the knowledge is built is much more
like the way a scientist builds theories
that there's not just filtering patterns
of data but in finding patterns but
building abstractions trying out
different hypotheses in a
curiosity-driven way the way our basic
science research is done going out kids
plays is has come to be seen as a kind
of sort of informal experimentation so
understanding these two kinds of things
right
these early the early conceptual systems
these kind of intuitive theories of the
physical and psychological worlds around
us and these theory building learning
mechanisms I think that is a place where
is we hugely valuable to cognitive
science if we can have formal
understandings of those things and
hugely valuable to building AI I think
they're there various kinds of exciting
technical developments there I'll point
to one which I think you'll hear a
little bit more about tomorrow which is
the idea of probabilistic programming so
this is this is an idea of again a idea
that has has some some roots over the
last say 10 to 15 years the Microsoft
internet system is one notable example
but it's one of these great places where
the early kind of symbolic and more
recent statistical paradigms are coming
together and it's a set of tools that
actually is allowing us in our models of
children to to to kind of capture in the
way that you can deal with uncertainty
and even even guide computer vision in a
much more object-based way to capture
this kind of early add to tech knowledge
and even something about how it learns
Thanks well I'm sorry on the stage and
while I do that please queue up for
questions or raise hands I guess for
mics to involve you in the discussion as
well
one comment that comes to mind or a
reflection I'll share with the panel and
maybe week you can each comment back or
share your thoughts is some of the the
the magic that you me personally into a
I was reading some other besides just be
fascinated by how my own mind worked in
the minds of people was reading some of
her Simon's early work like the sciences
of the artificial where you had a real
sense for the notion of the prospect of
building machinery to deal with
ill-defined problems in an open world
and we've made great progress both in
the logical world and in the public a
decision theoretical world in closing
those worlds in specific ways and
exactly you guys you I think is that
Chris and Feifei and Orrin pointed out
with objective function Michael with
objective functions that type things up
we've been very excited about decision
theoretic optimization as we were about
logic but we also have the frame problem
in logic and believe it or not in
decision analysis and decision theory we
have the framing problem where do these
distinctions come from what is the
objective function what am i doing right
now and I'm just want to get you get you
to comment on whether or not or what do
we do now that we're posting site
about decision theoretic optimization
where we assume we have probability
distributions we assume we can we assume
we actually encode a utility function we
build planners and single-shot decision
makers that are doing great work with
going from perception to reflection and
action
and even better reasoning about these
things is it time to basically put that
aside and say okay that was great
progress but it didn't get it's it's
fragile brittle we don't know how to
frame we don't know how to go up the
frame problem we need to bring AI into
the open world Chris and yet first of
all just a big thanks to Josh for the
plug for info doc net that was great
I'll give you $100 backstage
yeah promising program is very exciting
Brad wanted to make some comments
that'll pick up a share some things that
Josh and faith day and others have
mentioned around this sort of open world
issue how do we move away from this
well-defined task we've got our labels
and objective function we trained it and
then it's frozen and it does that one
task very well and that's it and that's
a long way for what we think of as
artificial intelligence and every time
we solve the task that way it's
immediately defined to be not artificial
intelligence how do you how do you get
to something that's much more like the
child kind of making sense of the world
and just said not just statistics
although I kind of think of Statistics
in a very general sense so it did sort
of if it's making sense of the data that
the child is observed observing how can
it do that and of course I don't know
all the answers but I think one of the
directions that we could and are
pursuing I think has a lot of promise is
to recognize that the these sort of two
modes of cognition if you like the sort
of the bottom-up fast mode which is like
the trained Network I turn around a
split second I can I can recognize it's
Eric I can recognize a predator that's
some fixed pre-trained
so same same neurons yeah that's kind of
fixed fast bottom-up thing that's sort
of pre trained that's trained in some
other place or some other time
but then there's something that's more
bottom down it's about an internal model
of the world so we just take object
recognition for example you've got kind
of two ways of doing this one way is to
is to use
discriminative method to try to learn
decision boundaries between apples and
oranges another way is sort of
unsupervised without labels if you just
given a huge amount of data if I give
you billions and billions of natural
images of the world and I just said
compress that data which is equivalent
to modeling the probability distribution
of that data then you could discover the
presence of regularities you could
discover objects and you discover apples
and oranges you wouldn't know they were
called apples and oranges but now if you
know mum and dad tells you that one of
these is an apple you know about the
whole concept of apples and that's sort
of much more like the the you know the
child making sense of the world in this
statistical sense so there's a lot more
to AI than this but I think but let me
get to the thing that I think is really
exciting it's just a little personal
thing that I think is great which is how
do we combine these methods because if
you look at these two approaches if you
look at neural networks discriminative
methods that they're very fast and
they're very accurate but they need a
huge amount of label data if you look at
these generative methods or this
analysis by synthesis then you can get
away with little or even no label data
but the problem is it's computationally
very expensive you sort of have to test
out all the hypotheses you say you look
at this thing say is it an apple now not
very good is it an orange note is it a
bottle yeah maybe it's a bottle okay
it's a red bottle they're not quite as
it is a blue bottle yeah okay now it's
looking so you've got this
computationally very costly process in
principle of exploring all the
explanations of the world to find one
that fits okay so that's kind of a
generative the generative method so so
one of the needs needs labels but is you
know it's very fast the other is slow it
doesn't need labels kind of kind of
train each other then they mutually
train each other and it's and and I just
give you a couple of little evidence
points that I just can't resist because
I think this is maybe not completely
crazy so if you go back to the skeletal
tracking system that in connect you know
the the the the 3d body sensor that
system was trained using motion capture
data so real data but the variability in
clothing infrared reflectance camera
noise was so huge that we actually use
synthetic data so we start with the
motion capture data and then synthesized
all sorts of variants so a Jerris if
model was built by hand and used to
create label data to train the
discriminative system here I'm talking
about learn
generative models we have a system we're
working on now called kyra which is a
hand tracking the real-time hand
tracking system where those
discriminative methods are pretty good
but they're not accurate enough to get
super precise details of where all the
fingers are so what we do is to use the
gen the discriminative model the it's
actually decision forest but it's like
deep neural networks to give us a very
good guess as to where the fingers are
and then we tune the generative model so
there's another example of the two
working in synergy so I think that's a
any one of many possible interesting
directions
I know there was a recent award winning
paper or is the best paper or automation
CBPR by quite - working with push Nicoli
at Microsoft written really well really
my 10 just Kulkarni graduate mighty who
were describe the work though yeah it
really aligns with what this was saying
yes it's a sort of joint MIT MSR project
also with the Casamance Inga mi MIT and
yeah it's how it totally aligns with
that I mean it that's exactly what we do
so so Ted just introduced a new
probabilistic programming language in
which you actually take you know
graphics rendering and put it in there
as part of the model-based approach and
then you use various bottom-up
data-driven techniques it could be sort
of very simple example archive hashing
methods it could be deep neural networks
to do exactly what you're saying
basically to kind of learn a bottom-up
route to doing fast inference in a
generative model you know I mean we both
know Jeff Hinton's earlier work on the
Hummels machine so to me the most
interesting version of deep learning was
actually Hinton's sort of mid nineties
version I guess that's when I was just
paying most attention to what everyone
said but you know how many people know
the Helmholtz machine so go back and
read it it's this was there was a
science paper called the weak sleep
algorithm for unsupervised learning in
the in the mid 90s and many many people
who've been around for as long as some
of our older folks you know know that
that those ideas are back now in a big
way and it's sort of it's part of the
background behind what Chris was talking
about and what we did in this cvpr paper
I I think that's totally right on but I
would just add I think from the
cognitive development perspective a lot
of what you what you call in like what
you did in connect specifying the
generative model by hand that's also
actually the way it works in the brain
in that it is I think there's a tendency
to overweight how much learning goes on
in infants evolution did much of that
for us the idea that there's what what
we've sort put into our system or what
in some forms there and how you train
connect a kind of a graphics engine we
believe and there's I think good reason
to see this from cognition and
neuroscience that there's something like
a graphics engine in your head and that
evolution is put certain you know if we
don't really know exactly what form this
is but has certain put certain
understanding of the three-dimensional
physical world and how you know that
leads to images it's not just graphics
but physics I think a lot of that the
phrase I'd like to use these days to
describe the infant core knowledge
system is the game engine in your head a
lot of the pieces that are in modern
game engines which include graphics
engine physics engine is and even simple
complaining engines I think are part of
what evolution has given us and so we
need to understand I think to build more
human-like AI how to integrate
statistical learning with all those
components of that system yeah I'd like
to just a committed them a word that
we're gonna lose some of our audience or
it's really nap by just reflecting just
just literally my shirt just reflecting
on the panel without getting into too
many mechanistic details I think what's
really interesting you never know when
you put a panel like this together there
was a note of agreement which I would
state as simply there's something
missing right there's a lot of exciting
results but there's something missing in
a I think everybody reflected that and
then there was also a note of
disagreement which is always the more
exciting thing with the panel and not a
disagreement that's aggressive but we're
reflecting very different methodologies
about how to get at that ingredient so
let me repeat that in more explicit
terms and again I I apologize if doing
that I slightly disturbed where people
said my main thing is just to get the
point across so I feel like a lot of
what Chris was talking about is okay
we've got supervised learning it's got
limitations let's figure out how to
extend learning algorithms whether it's
with better ways to get label data or
with unsupervised techniques it kind of
sketches out a research program of
unsupervised learning and the thing that
I've learned over the years when I was
young I was always right and and now I
learned that this methodologies in each
one has benefits
and and pitfalls so the obvious benefit
is that is this really interesting
algorithmic work to be done it's really
important to extend the state of the art
the potential pitfall is that at the end
of that we'll have a whole class of
algorithms and not be that much further
along towards towards ontology it's the
next piece of scent it's the minutes
right so you're out lighting a house for
the next 2% that's that's great if you
go to what Josh's articulated I think
incredibly well he said look there's
something incredibly tantalizing and all
of us have had kids all of us who are
interested in AI get into a thing of it
is I'm incredibly tantalizing about
human cognition he's saying we've got
more data on that and we can also start
to build system using you know
probabilistic mumble foo which is the
mechanism does your program people and
give it two years and or whatever but
but but the point is you know there'll
be another DARPA initiative but but but
but the point is that it's very very
tantalizing and very very exciting gets
it the D problems that's the benefit and
also a new source of data the potential
pitfall is around are we actually able
to build systems with stronger
capabilities right so it's it's you know
that that's a key question right where's
if you look at some of these other
systems they have these well-defined
objective functions and you can see so
that's what I see some of the trade-off
and in general cognitive science again
to just you know pain things with a very
broad brush has repeatedly given us
deeper insights very starting with the
work in dual on simon and proceeding
into the human mind and at the same time
has not been the shortest path that AI
is produced to generating more effective
technology potential i just go through
two more and I'm done
and then I want to make sure that I have
an equal opportunity offender but I
think you could stop down that's fine I
actually tried trying to be balanced I
does it and and you'll see that you know
it's not like I've got the answer that's
not where I'm going
I felt like Michael was saying look
we're excited about this kind of ill
form stuff but let's not forget let's
not forget then when we're formalized
things that's when we're really able to
make progress as computer scientists
right I heard that I'm gonna say so
again the obvious methodologies look
let's take that 2% formalize it solve
the problem algorithmically or
empirically is good computer scientists
and move on and that's very very
satisfying leads to great theses and
papers and the worry is we'll keep going
but we won't get there and then
faithfully aside from the conversation
about her her child which I could really
relate to as somebody as a five year old
was pointing out there's a lot more to
AI than perception when she and others
make great progress let's think about
all these problems you know reasoning
and planning and what-have-you in
representation and of course when you
think about those that's great the risk
is we get hideously lost right because
those are very ill for from last thing
our methodology we've identified these
grand challenge problems as I mentioned
we're trying to connect the dots the
good news is we do have metrics and and
we will be very clear if we make
progress the bad news is again we might
not have a clue on how to do that we're
a much more data-driven and challenge
driven than that we have a particular
algorithmic philosophy which again
convener we could get hideously lucky so
let's open up to the audience with some
questions from the audience and comments
and we see some folks coming in we have
a runner here yeah
good hi Eric is this huh yes okay I just
want to build on what what Josh and Oren
were saying if we continue doing nothing
but picking a problem and formalizing it
in solving it will never actually
achieve what we want to achieve you have
to actually start taking a different
perspective think about what you're
doing is building an organism an
organism does multiple things that
solves multiple problems that formulates
its own learning goals now there's a
line of research in AI and cognitive
science called cognitive architecture
that does this there's some beautiful
examples where works been going on for
decades if you look up at dar or so
or you'll find that they've done an
amazing range of modeling phenomena but
also building systems that actually are
practical and used as performance
systems and if you think in terms of for
instance what humans are a human level
AI really is a software social organism
that's got human level capabilities and
all of the reasoning and learning it's
capable of doing and that's a way of
formulating the goal that's completely
different from here's the technology
here's the problem it's actually a
specification of what it is we're trying
to get to and if you think about
building simple versions of that start
with the equivalent of shacks if you're
thinking of an architectural metaphor
and build up two skyscrapers then that's
a path that will actually get us where
we're going and there's still plenty of
room for people doing the traditional
pick a problem and solve it and gather
all of our evaluation data and all that
stuff all that's producing a stream of
ideas but if there's not an equivalent
set of people who are putting those
together in building organisms you can't
tell if these are going to go anywhere I
think that's what I would suggest that's
question any comments on Ken's you know
we just think yeah well I think the idea
very much idea of a system that can make
its own goals and make its own sub goals
this I mean it's another way to put I
think what Michael was saying right
which is that there's somehow we have
this kind of intelligence that can but
it doesn't just have a single task as
directive engine but can make our own
objective functions and can decide oh
well I'm going to work on this thing
like I understand AI and then formulate
sub goals and sub sub goals as part of
plans to do that integrating that kind
of approach with our sort of expected
utility optimization toolkit that's
driven so much of the excitement in
recent AI
sort of from a machine learning point of
view I think is really important
question from peers yeah so first thanks
to all of you for a very interesting
panel there's so many things I'd love to
react to from a technical perspective
but since the title was myths and
realities of AI there's one I think huge
myth that sort of being perpetuated by
some of the language that's being used
in the in
panel in the lead up to the panel which
is when we use terms like AI winter and
Golden Age and AI spring it gives this
impression that AI as a field has had
some huge breakthroughs and then
nothing's happened for a long time and
then another huge breakthrough and
nothing's happened and there's this I
think there's this sense right now that
there's been this huge breakthrough but
I think the reality is instead that
there's been this steady incremental
progress over many many years and that a
lot of this I think you're Chris gave
this sense a little bit that you know
with neural networks for instance you
know there's this notion that this
so-called you know deep learning is this
huge breakthrough but really there's
it's because of the people who've stuck
to it over many many years and made
these small breakthroughs in small
progress and this is happening I think
all through AI that for a while
everybody was doing symbolic and then no
it's got to be probabilistic and for a
while SVM's where the breakthrough and
then and I think it's you know the this
is it's a it's a harmful myth in the
sense that it causes people to jump on a
bandwagon and everybody go to in one
direction we're really you know the wave
for progress is that for everybody to
stick to they you know the their their
area and there's many different really
promising areas in AI and I think you
know we should have this vision of a
steady incremental I mean we're you know
at the point today where we're we're you
know jeanette wing who I'm thinking of
we think of all of his a you know miss
formal methods it gave a 45-minute talk
on AI which is great that's great to see
you do that Jeannette but but I want but
you know I think we also you know it's
really exciting and it's tempting for
all of us to say yes this is a golden
age and everybody should jump on it but
I think we all do need to also recognize
that the whole field of computer science
needs to keep moving in the you know the
steady incremental progress and we
probably will get to a point that's
where the hype is gone and where there's
not the the news coverage again and you
know it'll be tempting to say that
that's an AI winter but really you know
we should keep keep pushing and so
that's a big mystery fabulous comment ok
smells very much over here Erica did a
great panel and very thought-provoking
I just have a very simple question any
of the panelists mentioned that there
are all these terms with no definitions
from a mathematical point of view do we
have the right mathematics and
formalisms to formalize the concepts
that AI is struggling with what does it
what will it take to turn AI into a
science well first of all I'm not sure
it's people like people to say it's not
a science but go ahead you know the the
speaker the questioner is quite
pejorative calling it not a science and
in a response I would say that the
question really bespeaks a tremendous
ignorant of the field and the philosophy
of science most scientific terms
starting with the cell are very
difficult to define Vidkun science
philosophy of language has shown that
most terms are actually difficult to
define even the notion of definition is
questionable also most science doesn't
have mathematical underpinning in the
sense physics may be an exception look
at biology look at geology so I don't
really think the question merits
discussion the way it was supposed and
and and people know that I asked the the
panelists to be as pointed as they'd
like so it seems that the panelists
still agree that you know we've had some
great successes recently and it's good
to celebrate them but also that you know
there's these other things that we
really need to focus on to get to AI and
we saw various I think great ideas about
how to get there
but the thing the question that was on
my mind through all of this is that that
part of the dissection some ways is not
that different from the discussion that
happened at Dartmouth and so the
question I think that I would like to
ask the panelists is what have we
learned from the failures of the last 50
years about where to get in these things
because surely it's by learning from
those favorite favors that we're gonna
succeed sometime in the future when when
we didn't in the past comment a thought
on this and I guess and you know the the
the good old-fashioned days of AI
predate my involvement but but I guess
you know the 50,000 foot view is that
there was a a move away from as it were
handcrafted rules to sort of lurching to
the other end of the spectrum which is
sort of learning from data and neural
networks are kind of the this black Bop
model that that learned from data and
have very little prior knowledge built
into them with the except probably of
convolution which should have captures
local translation invariance and I think
an interesting question Joshua hinted at
this earlier is around what sort of
prior knowledge should we build in and
what prior knowledge is the brain build
in I mean the genome doesn't have enough
bits in three billion base pairs to
specify all the synapses in the brain
most of that has to be learned but there
are a lot of bits in the genome and you
could specify things like I mean why
would the brain not encode the fact that
it's going to be born into a 3d world
it's going to see lots of 2d projections
of that world why wouldn't you bake that
into the structure of the visual cortex
it seems to me you would and so you know
again one of the things you know that
what many of us are quite interested in
is how do we back away a little bit from
that extreme end of just blackbox neural
goop that kind of learns anything and
how do we bake in some high-level prior
knowledge I think that's a republic
programming comes in as a very efficient
and elegant way of encoding some of that
high-level prior knowledge but still
having all the details learn from data
so I think there probably may be is a
very interesting time to go back and
revisit some of that very early
nutrition because you know very smart
people thought long and hard about this
and they didn't have fast computers they
didn't have neural nets they didn't have
you know tons of data but there were
smart people they thought about this
long and hard and maybe there are ideas
that we can take and then transplant
them into the modern context I think
what we've looked for one extreme to the
other extreme and now we're sort of
backing away a little bit and finding
more of a middle ground is very
interesting time and yes but more
generally I think learning to be wary of
extremes right learning to look at the
different eras of our field and try to
say well when some really smart people
said something and then it didn't turn
out to work then there's some lessons to
be learned from that but part of it is
to understand well what was the really
right thing that they were
- can we extract that out from the
things that maybe they just either other
things they didn't know how to do or
they didn't have the technology or the
data to make these things happen you
know again pay and pager of course your
reer work is you know I think I think of
say for example Markov logic as an
example of understanding okay there was
something really right about logic what
was right about logic wasn't deductive
inference that's too weak and brittle
but abstraction right and if we can
combine the distraction of predicate
logic and then combine that with the
power of statistical learning and
inference we could do some pretty cool
things and and I you know I think that's
a field learning that and also kind of I
think having since learning as the theme
of the day or the decade the more
sophisticated appreciation for what
learning is really about and
understanding that learning isn't just
something you can just follow your
intuitions on but there's a science of
learning and that may be may be the way
that um you know I think a lot of people
in machine learning or AI will will and
again - maybe foreshadow some of the
thing that you might be talking about
soon evolution is kind of the real
learning algorithm in a sense right or
there are there's learning over many
different timescales if you think of
learning in the very broadest sense of
adapting to the statistical structure of
your environment there's aspects of the
three-dimensional world and the fact
that we perceive it through light and
sound that is millions of years old okay
and or even more and then there's things
which happen on other timescales of
years months days seconds and so on and
understanding that no one of those is
the right time scale to focus on but
understanding how a brain or an
artificial brain or an intelligent
system adapting to the structure of its
environment over all those timescales is
something that we're gonna have to take
seriously just to make a comment first
of all I think evolution has already
encoded one prior structure for coping
with the 3d world with this we have to
ice not one knife so just a little
comment I think I think this whole
discussion about what's next and we said
technically we talked a lot about
programming language the other thing I
think we should consider is actually go
back to the early a I concept but in
modernized ways think about knowledge
knowledge formation and knowledge
acquisition and common sense knowledge
and and here you know speaking from a
vision point of view people like Larry's
Nick and MSR is actually meeting a lot
of those research and also in the AI -
you guys are doing knowledge and and I
think this is one topic that we should
pay a lot more attention to to extract
us out of simply statistical pattern
matching for one task but start to
formulate that kind of back-end
structure of reasoning give us a path to
abstract information and form
relationships and be able to reason in
an ad hoc way more ad hoc and
situational awareness way rather than
just go for that and task well thank you
very much we're having to break now to a
break for all of you and sorry we can
take last question I want to thank the
panelists like to say that I had a
fabulous it has to be the most exciting
green room I've ever been in we make
some research done I think and they
could all share some insight with you at
the break and the planning time to meet
each of these wonderful people and have
some some insightful conversations
thanks everybody each year Microsoft
Research helps hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>