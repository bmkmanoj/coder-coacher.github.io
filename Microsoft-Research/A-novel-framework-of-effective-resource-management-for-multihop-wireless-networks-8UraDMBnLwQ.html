<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A novel framework of effective resource management for multi-hop wireless networks | Coder Coacher - Coaching Coders</title><meta content="A novel framework of effective resource management for multi-hop wireless networks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A novel framework of effective resource management for multi-hop wireless networks</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8UraDMBnLwQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright well I'm pleased to introduce
Chen Lu she's visiting us from the
University of Alberta she's in town this
week to attend the Grace Hopper
conference down in portland and but
while she's here were taking advantage
the opportunity to have her have her
tell us about her research particularly
relating to resource management in
wireless networking so Chen thank you
for the introduction it's my pleasure to
present my research at Microsoft and
today I'm going to talk about the
framework I developed to achieve
effective resource management for
multi-hop wireless networks by effective
resource management I mean three
criterias first how fared resource
allocation is second how efficiently the
allocated resources is being utilized
and three how low the control overhead
is and this is a joint work with my
supervisors dr. Janelle harms and dr.
Mike MacGregor in this talk i will first
to motivate this research and summarize
our contributions after that i will
present this proposed to framework into
four parts first the first mechanism
aims to find optimal fair share of
resources for wireless networks via
globalized localization please ignore
the name now and I will explain that
later and the second mechanism the
second mechanism aims to improve
resource utilization efficiency via
adaptive multivariable control for the
third and the fourth mechanism handles
the challenges in multi-hop scenarios
specifically in terms of the coexistence
of inter path and Inter path
interference as well as the correlated
congestion congestion and collisions at
the at the end I will conclude my talk
by pointing out our future directions
the motivations for this research is
very straightforward on one hand users
always want more resources better
service also the variety of applications
we always have more and more new apps so
it is challenging to satisfy user
demands in terms of quantity quality and
diversity and on the other hand where
this resources is limited and competed
among multiple users on top of that
where this transmissions are lossy
subject to dynamic interference
scenarios and dynamic network conditions
especially when traffic is forwarded in
the multihop manner the it further
degrades the network performance so
there is a big gap between the user
demands and the actual network delivery
capability an effective resource
management in mechanism helps to reduce
this gap it also makes the network more
tractable so other advanced mechanism
can be built on top of it
right now is the generic model and I can
and I aim to apply it to specific
networks for systems that's the the goal
i will talk about in the future work
yeah sure ok so now the scenario is ad
hoc multihop where it's not talking
about applications so you mean with kind
of applications running in the system
awesome user demands yeah this one is
also generalized right now ok so one
example is take us when you have what
that's the ultimate goal for my work
that if you have like multimedia and you
have also the interactive traffic you
also have the data transmission like 40
web browsing with different things so
you have different requirements right so
that's can be one scenario to consider
did I answer your question I think that
there's some servers serving some cotton
and the users have a platform that can
consume this contact but this network is
kind of bottle like to deliver this con
new years
this that's the case okay so this is the
motivation so our research achieve well
that the major contributions can be
summarized into four aspects first we
offer a novel method to achieve fair
allocation despite the diversity of user
requirements and the wireless at in the
impact of where does interference and
dynamic network conditions and the
second contribution is our way of
efficiently utilized resources despite
the coexistence of conflicts in terms of
collisions and the waste in terms of
unnecessary idling okay the okay well
anyways the third contribution is our
method effectively control network
behaviors despite the complicated
interference scenarios and these
interference scenario can be summarized
in a single hop like it hidden exposed
terminals and we will talk about that
later and also the specific scenario
interference scenario for multi-hop
networks and the last contribution is
our method minimizes to control overhead
in terms of the amount of messages
that's being passing around for control
and the computational complexity okay
okay now i was there talking about the
framework and the first mechanism is the
globalized the local optimization it
aims to find optimal fair share of
resources for wireless networks and the
reason is called globalized the local
optimization is because we achieve
competitive performance and as global
optimization by only using local
information without message passing
and so before diving into the technique
okay so this is your work focused on
Wi-Fi networks at hot Wi-Fi networks
that is what that is the application
scenario we use now for the
demonstration but again this is a
generic model and I aim to apply it for
different networks for example mash or
different system that's the ultimate
goal single radio right now yeah okay um
okay so before diving into the technical
details I want to elaborate a bit about
the design philosophy and here i want to
discuss two issues first how is fairness
influenced by wireless constraints in
terms of the dynamic interference
scenarios and network conditions as we
know convention the conventional
fairness criterias developed for wired
networks where we do not need to worry
about the interference and the network
condition is relatively stable but when
we use them in wireless networks the
consequence is the gap between the
amount of resources being allocated and
the amount that's the amount of
resources that's being actually used for
a successful transmission so why two
reasons first transmissions are lost in
words Network second scheduling
algorithm may make false detection and
the wrong decisions for example csma so
what can we do about this gap from the
utilisation point of view we should
minimize this gap as small as possible
but the problem is the effort you put
into minimization also consumes
resources so there is a trade-off
between the price you pay and the gang
you get from this gap minimization and
if you see this trade-off from another
perspective okay
just another background was forgetting
the specifics you're thinking of this as
a mighty commodity fill problem ah as a
each node has demands to send multiple
other saints and you just need to out
them in some sort of a fair fashion is
that formulation okay so is that shrek
foundation okay so it's okay so user
here you can abstract it as a flow
that's between a source and destination
pair and it may start from the same
source node or different source node
currently ama at the mac layer so
routing is definitely an issue and I
will talk about that later on but it's
not currently right now the path is
fixed yeah yeah thatthat's this for the
current stage okay so okay I was talking
about okay so from the efficient
utilization point of view we should
minimize this gap but also we have this
overhead problem that's what I just
talked about so if you think of this gap
from the fair allocation point of view
actually it characterizes the impact of
wireless into the current interference
situation so instead of pushing to make
the gap as more as possible and incur
high overhead you can adjust the fair
share to reflect this trade-off okay so
this is the first issue and the second
issue is what fairness criteria should
we support as user requirements as
diverse and system might be different so
it's impossible to generalize a single
fairness criterias to cover all
possibilities so we decided to support
different types of various criteria how
I will talk about that in a moment
another related issue is who has the
authority to define fairness criteria
okay before answering that question
let's see what fairness is it's actually
defines a bunch of rules that prioritize
a certain groups of user and
discriminate a certain groups of user to
a certain level so it's subject at this
subjective and judgmental so it's a
question whether protocol designers
should define these criterias my opinion
is should be the people who have more
knowledge about the applications that's
running in the system and user profiles
they are the right candidates to define
this various criteria and the protocol
designers should support whatever
decision is made from the above so based
on this principle we separate the
fairness definition from its fulfillment
again what do I mean by that
specifically we leave the task for
fairness criteria definition to for
example network operators no managers
but our mechanism simplifies their way
to derive fair share by allowing them to
assume static well the stable Network
condition and the static interference
scenarios and the idealized the fair
share they derive is plugged into our
mechanism so we explicitly consider the
impact of the interference scenarios
that the actual interference scenarios
the impact to it and to readjust this
fair share okay so these are intuitions
for the this first mechanism so based on
these intuitions we formulate this
globalized local optimization and we
call it G local just for short ok and I
will explain this formulation in terms
of its components the first component is
consumption utility and it characterizes
the user behavior or how aggressive a
user consumes resources ok and we choose
the log function not for the purpose of
proportional fairness but to just for
the sake of convexity because we aim to
ok I just after finishing this sentence
just to aim to because we aim to support
different types of fairness go ahead you
can start by single deck sir sir
apparently if you can start by
describing with the excess
ok so here X high-level wise is the
banner it's the resource or the
bandwidth that you can Zuma for the I
transmission and here is descending rate
well it can be sending rate or the good
foot and you will see it in the example
I will show later on ok for each user
yeah for ages if this the first the
two-part the mechanics will talk about
this for single hub and the second the
third and the fourth make has been for
multi-hop so for a single hop scenario
this as one user so it's like him a
conversation between a source and
destination pair ok so that's I so the
exes are given the Exeter that demands
the user is putting on the network no X
is the the actual and there's the actual
yea networks granted x yeah yeah it's
grunting you're you're changing that ok
I'm sorry yeah i'm talking about that
right now ok so the second components
called consumption costs it has two rows
first it drives the user consumption
behavior to converge to a certain level
so you want to shoot always for the
maximum amount and the second row is
more interesting that's that's this x f
it is d well I call it configurable
fairness interfere you enter interface
so it is where the idealized the fair
share that's derived by whoever is in
charge of this this this role that we
talked with war plug it in and if you
ignore this scalars ignore it is w which
I will talk about right away if you see
the formulation after ignoring these
parts the the control policy will
guarantee that the ex I will always
converge to X F because it just a simple
formula but remember we are in wireless
networks this idealized a fair share is
impossible to achieve because of this
the reasons I talked about that the law
Cena's and depending on how the
scheduling algorithm
work so there's always a gap right so we
have to explicitly consider the impact
of collisions okay go ahead true ready
if take out you I and WI about you're
left with is max minus of 1 minus KC is
I know you your left has no ignore k + y
minus K and this wxi so you will it's
just when you have the derivative so x
will x i will equal to X F right 2x my
x-ray no x cycles to accept so if you
just the one you will have the
derivative equals to zero so you get a
derivative of you I and the CI which is
this one so that will be X 1 over X I
and this derivative is X 1 over X F when
they are equal x i equals to X F right
yeah thanks so I said this X F is not
realistic and wireless environment to
achieve because of collisions and the
necessary idling which is the amount of
bandwidth that should be utilized and is
which is not utilized okay so this is
the formulation and we demonstrate
whether this G local optimization find
the optimal fair share in a simple
network s aloha and why Aloha because
simplicity for the for this stage we for
the control is simple okay go ahead
Pierce one so you're assuming okay
please specify the desired fair share
for each pipe so it should be except for
Phi or is it the same except for every
depending on the application scenario
right ya know depending on the you will
see in this example that i'm going to
talk right away that's a very
disassembled based on the interference
scenario the fair share for each link
the idealized is this way so it's not
the same for for each one well I mean
also depending what well in this simple
demonstration I assume the proportional
fairness is the criteria that's being
used to derive this idealized a fair
share okay and I will talk about that
very soon depends on the device and if
you can't get the pair share the
individual demands right now we're doing
this saturated the traffic right well
and and for more realistic realistic
scenarios that will be a disco well
considered later on okay I'll sorry I
have to go back okay I was here so why
Allah has because it's it's simple to
demonstrate our purpose for this
mechanism but the control effectiveness
is not the concern for the car for the
first mechanism that's the focus for the
second mechanism and they will talk
about that very soon so here I only have
one control variable that's the
transmission probability and this X is
DM the p i multiply the the total
capacity and the control policy here i
will skip the mathematical derivation is
just a base on the lagrangian
transformation and and gradient search
so you get this and the details i
already ignored but this is the control
policy we've arrived and i will if you
are interested in the detail i refer you
to the paper published in lcn this year
it has all the mathematical details so
we evaluate this the first mechanisms in
two I will talk the next slice into
setups the first one is a toy example I
just have three links
link1 link3 interfere with each will
interfere with link to and they do not
interfere with each other that's just
for the easy illustration and after that
I will talk about a larger random
deployed networks but this is a
simulation results ok so we compare our
method with the global optimization
algorithm that's developed by dr. Munsch
um from a Princeton University as if
you're interested I will show you that
paper after the talk and this idealized
optimization is like the we do not
consider the color d it's so we'll so
you assume the collisions and the
unnecessary idling do not happen because
of you have some purpose scheduling so
that's the idealized fair share how it
is derived okay so for this toy example
the second row shows our performance and
it's very quite close to the global
optimization performance but you see a
big gap between the idealized fair share
and our performance that's why because
of a loja is very naive in terms of
controlling the the well in terms of the
way to avoid collisions and handling
these conflicts unless too yeah so we do
the same experiment okay go ahead I'm
sorry no can you explain a water bath I
mean the Google optimization is doing
something that requires through the
knowledge yeah it's the ways if maximize
the total utility for all the users and
it it has the well so it decomposed this
global optimization problem into local
but each user have to collect all the
current consumption information from the
competitors that means whoever is
interfering with you and how they
consume and readjust and you compute
some kind of shadow price and then we
readjusted the way or in terms of and in
this example is the transmission
probability to maximize this poodle
utility so that's the high-level
description
formulation that you presented the GL is
making up for the lack of local
knowledge so we only use the local
knowledge because you know your local
collisions and you know the you can
infer the unnecessary idling but also
the global aspect is you have this idea
of lies fair share as initial goal to
reach but you readjust it based on how
this the current interference narrow is
to reject that once you figure accepts
then yoga knowledge then you don't need
any further global knowledge is that
what you're yeah awkward yeah that's the
goal yeah for the first mechanism yeah
that's why we don't need the message
exchange or for figuring out the actual
fair share okay so we did the same
experiment in a larger random Network
just we have a random nah we have 10 20
30 random single destination pairs and
so here we vary the level of the
interference in terms of the number of
links sorry here should not be path so
it shows our our mechanism which is the
black bar achieves similar sometimes
slightly better a packet loss rate
end-to-end delay throughput and fairness
well GP sorry gb is the global
optimization performance the white bar
is our performance ok so as similar
fairness performance and we also vary
the traffic load and they show similar
results so so far so this is the first
mechanism it aims to find optimal fair
share by only using local information
without message passing and the second
mechanism is called adaptive
multivariable control ok go ahead it
seems like you're you're still improving
moving on because the way you know for
the globe optimization the impact of
interference is not explicitly modeled
and it's just the based on whatever the
best efforts you figure out the fair
share but you are not making efforts to
minimize this order to to to handle
these collisions so it here is the way
they formulate and also the also the gap
you see it's the problem for both our
method and the global optimization is
because of the control effective hasn't
been taken into account yet so that's
the second mechanism adaptive
multivariable control aims to minimize
this gap
yeah this is what I'm going to talk
about okay here we explicitly consider
different interfering scenarios so in
time interfering signals can come from
the earlier transmissions it can also
come from the simultaneous transmissions
it is also possible the interference
signal is coming from the transmissions
and later on or in the future and in
space when two transmissions they're not
aware of each other's existence and they
interfere with each other collision
happens this is the typical hidden
terminal problems and in the opposite on
the opposite one two transmissions they
are aware of each other's existence but
and they actually do not interfere but
they do not transmit its waste of
opportunity so it's the exposed
terminals and our method differentiate
these different scenarios and we select
effective factors related to these
scenarios and the tunein toward the
direction we want this is the high-level
idea so these are dia ok so the first
factor it's called idleness probability
the reason I do not tune the physical
career sensing range there are two
reasons first it's the way we handle the
exposed terminals so the way I do it is
I set the career sensing range small to
be same as the transmission range the
reason is that within the transmission
range whatever information you received
you you are able to to decode it you
will know where is from where it is
going so it's easy to know whether
exposed terminals will happen or not ok
so this is our method to handle exposed
terminals to limit it within the
transmission range and then to reference
it now to deduce it so in terms of
hidden terminals we use this idleness
probability which is the probability
that you do not transmit even the
physical career sentencing range tells
you the current medium
idol because we have a very limited
career sizing range so the result might
be fault detection right so we use that
to react to adapt to the current hidden
terminal problems so this is the first
factor that's designed that's selected
for handling the earlier transmission
costs interference and hidden terminally
expose criminals the second and the
third before talking about the second
and third variable I want to review a
little bit about the house csma handle
collisions so it divides the collision
handling into two phases one is
collision avoidance when you start a
transmission you randomly select a slot
to try to avoid the simultaneous
transmission cause the collisions once
collision happens you entered the
resolution phase by double the
contention window to avoid repeated
collisions and and your attempt this
retry will stop and to a certain limit
is reached and they dissociate a single
contention window with both phases the
problem is that it's possible that a
transmission doesn't have many
competitors around so you can use a
small contention window to to control
the delay to not incur very long delay
but the problem is if collision happens
this small contention window cannot
increase fast enough to to avoid
repeated collisions but if use just if
you consider the the collision
resolution you want to have a bigger
contention window but at the same time
if you have less competitors you may
cause extra delay so what because
collision avoidance and resolutions are
two different phases why don't we just
have two different variables so that's
why i introduce a void when avoidance
with a window to handle the simultaneous
transmission calls to collisions and the
resolution windows for the collisions
calls to buy future transmission
so these three parameters are used to
model this amount of bandwidth that's
used for transmission which is X I and
the this model shows it considers the
impact of each parameter as well as
their interaction and same in the same
way we model the the collision the
amount of bandwidth the user you can
zoom for collisions in terms of
multivariable function of these three
selected factors and the derivation is
based on the eye turret is at least
squares fitting okay here police it's
just very brief and the police ignore
the details it's just you substitute
this model you combine this model with
the G local optimization framework I
talked previously and you use the
Lagrangian transformation grade into a
search I got three control policies for
this idleness probability avoidance
window and resolution window okay now we
do the same experiments by comparing our
mechanism with the csma that's the
reference line for performance wealth
compare it with the single variable
control we used it previously to show
the effect the gain of having
multivariable control so it has the
control effectiveness we also you
compare our method with SPS a
simultaneous perturbation stochastic
analysis and why do I choose it's
because this method it estimates the
gradient for each factor by simultaneous
perturb this for each factor it does not
require the model it's just it's just
estimation based approach so you save
the modeling cost but let's see whether
it's but it has other issues and I will
will show in the results soon again the
first is the toy example for easy
illustration
the second row is our performance and
you see the gap is smaller than before
compared with these two single variable
control okay and this SP is the
performance of having that estimation
based approach that s PSA and it's very
it's the in terms of convergence is very
slow so it's not even convert within
this for this example that's why you see
this performance also this csma/ca ET is
d so you're you see SMA you consider
about exposed terminals by setting the
physical career sensing range small so
the nodes are more aggressive to in
terms of transmission so the trainer the
link were the transmissions that have
less level of interference will be more
aggressive and the one suffers more
interference is starved okay and when
you consider about hidden terminals you
are more conservative and the gap is
bigger because okay semi experiment for
a larger random Network has the same
setup and our performance is this the
the first one on the left it achieves
better packet loss rate throughput and
to end delay and fairness index one app
well with the different offered loads
and different interference level like
sugar here is our aggregate across the
whole network yeah
very good throughput because like
depending on the number well like we'll
have ten one we varied interference the
level we have ten pairs 20 pairs 30
pairs so that means 60 notes at most
placements is random and then what we
showed is some kind of average
measures okay so so far I've talked
about the fair allocation and efficient
utilization for single hop networks and
now from the third McCann is among its
exploited explicitly handle the
challenges for multi-hop networks and
also just a note here its work in
progress and I have some preliminary
results but because it's not complete so
I didn't show it here but i will
verbalize that whatever i get a little
bit so the third mechanism is called a
hyper ACSM ATM is scheduling its design
for the coexistence of inter path and
intra path interference so the way I see
this problem can be illustrated by an
analogy it might not be appropriate
about lighting it serves to go for now I
see the coexistence of Internet inter
path interference similar to like a
group or a country that's under the
attack of both interval rice and the
external invasion so when you have this
situation if you try to fight both you
have more enemies right and if you form
an alliance inside your country or
whatever organization you consolidate
your strength to fight the external
invasion or external attacks is more
effectively so based on this intuition
our method to handle in short path
interference is to coordinate the
transmissions within the same path to
minimize the collisions by scheduling
and I will talk about that in more
detail later on it can please ignore the
the graph for a figure for now and I
will come to that soon so for the
competition from different path is our
method is to let them compete and our
method will guide this competition to
converge to the fair share so this is
the high-level idea to do it in terms of
scheduling our methods is very very
simple is pure local we determine the
schedule for each node within a half to
transmit just based on hop count so for
the first node is one second to three so
every two knows that's our two hops away
within a path you repeat the schedule so
that the underlying assumption is that
there is no interference coming from the
notes that are two hops away but it's
not true you will argue I'm sure you
will think of scenarios like if they are
close although you have hop counts but
that's not this tense or it does not
show the actual the interference level
that this guy and this guy is receiving
but we can do something about it you can
adjust the transmit power to make sure
the virtual distance among these two
these two guys are far enough so they do
not interfere with each other so that so
then we can keep this local inference
mechanism to do this / path scheduling
so it's very simple and the for to guide
the competition between different path
is to converge to the fair share that's
actually the goal what we just talked
about this multivariable control and the
J local optimization does so we use that
for this purpose and I don't show the
results here because not complete yet
and from the data I collect it minimized
the collision quite significantly the
fourth mechanism is called hop base
congestion control it handles the
correlation between congestion
inclusions what do I mean by correlated
congestion and collision in wireless
networks one collisions happen it
waistband with right your effective
bandwidth for delivering is already
shrinked but and also you will put
efforts to resolve this collision so
more bandwidth will be used for this
resolution so there consequently the
effective bandwidth for delivery is even
smaller and this will contribute to the
growth of the the Q or the backlog so
make the congestion even
and in from the other perspective one
congestion happens so every note tries
to push the backlog the data out as much
as possible so the frequency of
interference in the period of
interference is longer and more and it's
more frequent so which contributes to
more collisions so that's what i mean by
correlate the congestion illusion the
point here is that congestion anymore in
wireless network is not only because of
traffic overload it's also because of
interference and you have to consider
the both aspects but existing methods
for example i categorize them into the
tcp like and back pressure like approach
and they do not consider this
differentiation for example the tcp like
and just control it blames everything to
offer low so at the source node based on
certain kind of whatever end-to-end
metric you used to indicate this
congestion when it happens you will just
you adjust that the source at the
offered load at a source node to react
to it because the congestion might be
caused by the interference so your
adjusted this Alfred load might be too
conservative pick so it causes the
resource under utilization but for the
back pressure like can just control the
basic idea is whoever has the larger Q
you will transmit you have more
opportunities transmitted to the
foregoing maximize the aggregate network
throughput for wired networks yeah it
can do that but for wireless network
because this backlog might be caused by
collisions so if you let them to have
more a priority to transmit you will
further aggravate this interference in
their room and the result will be even
worse so neither mechanism works for
wireless networks our method takes into
account of both the traffic overload and
these interference the impact of
occlusions on congestion so
we introduced the offered load at the
source for the source node to the model
so our congestion considered the traffic
load as well as the parameters related
to interference this is at the source
node and the model derivation the same
as before just we have one more variable
okay but for the nun source node for the
intermedia knows you don't have the
offered load but you have the amount of
traffic that's being received so that's
this X I receive here represents and why
I differentiate that I will talk at in
the next slides again here is the
derivation by using this new model into
the G local optimization framework the
same method Lagrangian transformation
gradient gradient search we got the
these new control policies but these are
intermediate control policies and I will
show the ultimate control policy next
slice and I will tell you why ok for
source knows you have the you have the
authority to adjust the offered load
because that's where it started we have
the kind of the offered load control
policy but at the intermediate node you
receive traffic and our assumption is
that we try to push as much received
traffic as much to out instead of cut it
so so intermediate nodes do not have all
threaded authority to change this amount
of traffic being received but it has the
ability to compute the amount of traffic
that's that it cannot handle based on
the estimation of the the current
interference scenario locally and you
can pass that information back to your
previous hop to let them adjust for you
right ok so that's why in the ultimate
control policy this part does in the red
frame is the amount of traffic that your
next hop wants you to change and that
message is and that information is
passed to the previous hop in order to
to adjust the traffic load and all these
parameters related to interference so
this is for the source and Mission
Control and the fourth intermediate
congestion control we do not have any we
cannot do anything about receive traffic
but we passed what we want to the
previous hop but we can do something for
the next hop by adjusting the parameters
related to interference again now I
cannot show the result because doing a
work in progress sorry about that so in
conclusion our methods it offers a new
method to support different types of
fairness criteria it readjusts the fair
share for wireless networks by
explicitly considered the interference
scenarios and we provide an effective
way to control Network behaviors by
differentiating different types of
interference scenarios and by
considering both the coexistence of
waste and conflicts in terms of
unnecessary idling and collisions we
also handle the challenges in multi-hop
networks explicitly including intra and
inter path interference as well as
correlated congestion and collisions at
last well here we minimize the control
overhead by reducing the amount of
control messages to be passed for single
hop scenarios we have 0 message passing
but for the multi-hop a scenario we need
the like two successive hops you need to
pass the information for the congestion
control i just mentioned the amount of
traffic you cannot handle you need to
pass to your upstream node so that's the
only messenger passing we need here ok
so in the future my goal is to apply
this method or customize this framework
for to support qos or quality of service
or quality of experience
so that's the first step for the future
work and the second one is to
incorporate routing routing it's about
it distribute the traffic load and it if
the routing layer has very
discriminating they were very a naive
way to distribute loader you have
already and fair traffic distribution
and even the mac layer is effectively
you still get influenced by you're a
player so here there's some cross-layer
organization to do and ultimately I want
to make this work framework work for
mobile traffic's so that's the future
work thank you very much questions
please okay so the viewer thought about
frying tell when something's ideas an
adjustment that would be nice but I
think now it's the end of my PhD I don't
think I have well before my thesis have
time to do that but if I continue to
work on this one after my thesis that's
definitely a direction to go yeah
prisons correctly you're assuming all
the links are they the same day rate
well for this in for this example or the
current experiment assumes that but
because like later I want to support
different types of traffic that's not
that that should not be the assumption
so you change your algorithms to
incorporate different one thing is okay
there are two ways I can go one is the
way to derive this idealized fair share
when you have different traffic's what
this idealized fair share should be one
possible way is you use the demand as
the initial fair share you impose but
let our so our method will consider
about the demands the fairness as well
as the other constraints related to the
specific system features well in
wireless network is the I talked about
the collisions and necessary idling so
consider this aspect to readjust it to a
proprietary
and the second way is you can do
something about the utility function
because that's how user behaves for
example for quality of experience one of
the my friend he was working in this
area and the heat uh he the information
he gave me it's like for example for web
pay for for the web page was a call
sorry judges for quality experience
sometimes the user behavior is
exponential so by incorporating
different utility functions then I need
to readjust to how I impose the cost for
these all these constraints we have in
terms of transmission features so yeah
these are the challenges and also the
possible ways I can go to apply it for
more realistic scenarios complexity
renders compared to simple
so can you say
about how obvious you're
mutational expensive
that's a very good question that's a
very good question because currently our
way still naive you periodically adjust
this multivariable model so overhead in
terms of this periodical update its high
but the thing is depending on the
application scenario depending on the
how fast your network condition changed
it's not necessary you apply it
periodically it can be done at the
beginning for a certain phase and then
when the network condition changes you
apply it again so I updates does it
require whatever some kind of Oracle to
know everything
I stressed de based on periodically no
you just need to your local information
about this Xin collision the the
transmission collision and then estimate
the impact of each parameters in terms
of the the the performance so it's a
pure local you do not consider other
performance other your neighbors Oh your
dad it seems like when you get a new
floating you're already in control even
the dimensions table your orthotics
abide to converse to the right range
yeah well I think that depends on how
freak I mean this new ad added traffic
how long it will exist if like this very
short very short traffic yeah what you
said might be true with one is it's
relatively long it's 2 converges so
that's a very good question actually
currently this framework does not
consider the dynamic truck like when you
add new traffic and you have traffic to
go how it will work so that's definitely
i'm going to add in the future work
older now miss ya right now and the
early has a lot of data to send
this current but if you look at real
artist man I bring yo sup the fairy law
is my web brownie shall the traffic
framework can can you adapt its prequel
that's the challenge I'm going to tackle
yeah that's that's definitely currently
at the assumption is not that realistic
in terms of long live the traffic but I
mean so it can handle certain types of
network traffic before why browsing the
type of application I need to add
different mechanisms that's definitely
what I'm going to tackle next step if I
want to provide quality of service or
quality of experience yeah yeah yeah
that's that's the goal let's go yeah
sure so when your tribulation is already
through some complexity there and then
to account for this
dynamics and this first in some traffic
I assume that's going to get more
complicated well do you have any
insights as to handle okay so your
complexity the the the the argument here
is my model right that you think of the
way I'd Arab the model is already
complex so when I have more dynamic
scenarios or are other constraints to
consider it might get more complicated
and the thing is it's not that all the
factors you select it's I mean it has
significant impact all the time right
from what I observe is for a different
scenario certain factors who stand out
so this observation will help me to
reduce the number of factors I need to
use at a certain 11 certain scenarios
happens so it's not necessary to include
all the factors all the time so that
helps to reduce complexity thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>