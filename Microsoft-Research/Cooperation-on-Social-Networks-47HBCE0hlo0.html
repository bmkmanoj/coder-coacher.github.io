<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cooperation on Social Networks | Coder Coacher - Coaching Coders</title><meta content="Cooperation on Social Networks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cooperation on Social Networks</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/47HBCE0hlo0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
very happy to have Najib ali here today
he's visiting Microsoft for the nerd
Center for the whole year from UCSD he's
a economic theorist who works on a very
wide range of interesting topics
especially in sort of game theory around
social economics and he's going to be
talking about a topic that i think is of
interest a very large number of people
here about cooperation in social network
right thanks so much a ford introduction
that thanks even more so for letting me
hang out here for a year my mother
equant visitors I feel embarrassed of a
bit of an introduction given that so
many of you know me um but I'm thrilled
to absolutely be here I tell you what
I've been doing in up to so as Glenn
mentioned I'm sort of very interested in
thinking about social structures and a
lot it's pretty easy for me to place my
research on sort of some sort of pivotal
moments in my life the pivotal moment
being when I reached came to the US for
college from Bangladesh arriving in the
US with a couple of suitcases a fake
guitar fake gibson guitar called it but
the name gibson not Gibson um and trying
to figure out how to make my way to a
place called a school called brand a
that i thought was called brian day in a
town that i thought would be called
walsim and so everyone said no it's
Brandeis not brand day and it's Waltham
and so that was the first thing I saw I
noticed the second thing I notice they
actually gave me pretty good directions
on how to get to Porter Square and take
the commuter rail and a third thing I
noticed as they didn't try to steal my
suitcases that last part surprised me
because coming from Bangladesh I didn't
quite think I'd be able to rule and in a
random place and be completely
comfortable on trusting strangers and
that led me to be interested in thinking
about social structures and the thus I
shifted from wanting to study math and
physics
wanting to study the social sciences I
started saying economics funded
incredibly boring and that I wanted to
do Poli Sci or sociology until an econ
prof took me aside and said look one of
the joys of being an economist is you
can take whatever confusion we have
about markets and extend it to
confusions about everything else I'm
using the word confusions you may have
used the word clarity um and so
essentially a lot of the work I do is
trying to understand issues of social
structures issues of power questions of
self control that's largely because I
have a lot of self control problems and
so that's essentially what i do and
thinking about economics of privacy as
well in terms of issues of social
signaling so does the work I'm going to
talk about today is joint with David
Miller and we're incredibly excited
about this work because we think it
speaks to a lots of different issues
across a lot of different literature's
both in and outside of economics David
by the way was a visiting researcher at
Microsoft as well who some of you
remember he was here in the year twenty
twelve to twenty thirteen this is a
picture of him very recently in Michigan
um where he's pretty happy and David and
I two of us being theorists you know we
we did have a lab that both he and I
used to do all of this research and so I
want to show you our lab its office
number 12 142 on the 12th floor here
which is incidentally the office I used
when I visited in the year twenty eleven
to twenty twelve I left on a Friday and
David occupied this office on a Monday
continuing the very same research and
then this year when I came lo and behold
I'm in the same office once more so this
is our lab this is where we've acted
never sat in the lab at the same time
together um but all of the ideas all of
it was what I'm talking about really
happened in here okay so here's a
motivating question for the entire
research agenda that we have is trying
to understand why people cooperate in
the absence of legal enforcement so this
is something you want to connect two
times in history prior to the advent of
modern legal institutions as well as in
developing and transitional economy
is where court enforcement is either
absent or incredibly costly so just to
take an example from a book by avinash
Dixit he talks about the Indian legal
system and a paper that finds that there
25 million cases pending before the
courts in India and even if no new cases
are filed it would take three hundred
and twenty-four years to clear that
backlog so clearly this is a setting in
which people who are cooperating are not
hoping to rely upon the court to do so
so now you might think about how is that
the people are going to cooperate
economists have modeled ideas of
repeated interaction where if someone
cheats me today I refuse to work with
them in the future now they might end up
still being able to cheat other people
but you can imagine what simple social
norm where if anyone cheats me I'm not
going to work with that person so that's
something i'm going to call bilateral
enforcement so now when I defect on one
individual that individual punish me I'm
not worried about how it's going to
affect my relationships with other
individuals when I know it's without
areas without legal enforcement but I
would actually argue it's applicable all
sort of areas with legal enforcement in
the sense that what is legal enforcement
mean I can suppose that a judge says you
are condemn what it really means is that
the judge said something and then
someone will go and take that person to
jail why will they do that well they're
afraid that if they don't do that
somebody else is going to do some you
know etc etc etc so the legal system
itself is in fact a form it's not
there's no extra completely ignore you
so that mean so I mean from the
perspective of our modeling it's almost
some thoughts economists and social
scientists broadly have found it useful
to distinguish legal from non legal
enforcement but in some sense
philosophically the distinction is very
hard to pin down because in both cases
all that an institution is is it's a
coordination of expectations of what's
going to happen and so in some sense
everything is community and force
I agree with that comment it's it's a
way in which we value laws is as
difficult to pin down as it is to think
about why we value money okay so that's
one scheme of enforcement where people
don't cheat those a person doesn't she
doesn't work with those who has cheated
upon that person a more powerful scheme
which naturally comes to mind is that of
a reputation scheme where if I shirk on
Glenn Glenn might tell other people
about it and everyone else then is going
to refuse to work with me and that's a
scheme of multilateral enforcement where
each relationship is influenced by
others so these notions of multilateral
enforcement have been incredibly
important in economics so a sort of a
case study of this where that's been
relatively influential in the field is
that of demography traders that operated
in the 11th century in northern Africa
this was a coalition of Jewish traders
who have had faced a challenge of long
distance trade they had goods that
needed to be sold in faraway markets
what they would do is they would hire
agents in those faraway markets to do
this to handle all of your long term
long long distance transactions now of
course it's feasible for these agents to
say look the good spoiled while I had
them or something else happened to the
goods and just sell the goods and keep
the money to himself so what the mongrel
be traders did was they developed an
information sharing network among
themselves so in the event that their
agents did this they would talk to each
other about it and with no longer work
without that agent unless that age and
any agent with chetan unless that agent
sort of paid some sort of penitence so
this is a famous historical instance of
multilateral enforcement that in some
sense began a lot of the literature in
which our work lives sociology is have
been thinking about this probably prior
for economists so this is James picture
of James Cole Coleman who as you can see
looks very concerned about society and
so he was thinking about the diamond
market in New York City so one thing I
learned from his work is that apparently
the diamond market one thing that's very
difficult is of course verifying the
quality of diamond so what these a
diamond soldiers would do is they would
sort of trade diamonds with their
friends ask her friends to look at the
quality of it now of course what their
friends could do is they could look at
these diamonds which are very valuable
replace some of them would fake stones
perhaps take one stone so on and so
forth and so there was a question of how
could the community get around this
issue and so the way in which he
suggests they do so is that it's a it's
a they live in the same community they
come from the same ethnicity or religion
or background they go to the same
synagogue and if any member defects by
substituting other stones are through
stealing stones in his temporary
possession you would be punished through
non-economic means losing family
religious and community ties the
strength of these ties makes possible
transactions in which trustworthiness is
taken for granted and trade can occur
with ease these issues recently we
discovered go beyond just the social
sciences and recently theoretical
biologists have been thinking about
social norms in this way so Martin no
lack whose runs to the Harvard program
on evolutionary dynamics this is a
review article that he had recently
where he asked a question how can
natural selection promote unselfish
behavior various mechanisms have been
proposed and a rich analysis his
analysis of indirect reciprocity has
recently emerged I help you and somebody
else helps me ok so these are the
questions that people have been asking
and now I'm thinking about what you're
trying to enforce it's useful to
distinguish two different problems and
i'll tell you about which problem we're
going to focus on so the two different
problems are what economists would call
moral hazard and adverse selection the
second in some sense is a little bit
more intuitive which is there good types
of people in
world and bad types of people in the
world and what we want to do as a
community is give the boot to the
bathtubs and surround ourselves with
good people who will always do too good
and the right thing and that's that's a
really nice way of viewing the world but
sometimes you might be suspicious
whether good types of people always do
good things and bad types of people
always do bad things and so the moral
hazard perspective is that every person
has the capacity to be good or evil
depends upon incentives and that's the
view that we're going to take not
because we think a heterogeneity is
uninteresting we think it's very
important but in some sense this
provides an easier theoretical place to
begin okay so we're going to be
interested in resort of model a lot of
disposals we use the term ostracism in
fact it's the title of one of our papers
where we're thinking about the community
practicing for excluding someone from a
society or group when they deviate of
course ostracism also has a historical
precedent from the Athenian democracy
where some wonder someone would be voted
to be kicked out of the city there
wouldn't be any formal charge whoever
got the most votes to be booted would be
booted um and then could we enter after
about 11 years but I'm not going to say
much about that okay so common ways in
which everyone economists sociologists I
all just have modeled these kinds of
reputation systems is the following
either people have assumed that everyone
in society observes everything just
heroic very heroic or the assumption has
been that and this is the model that
both Martin no lack likes and
evolutionary dynamics as well as
economists like is that we all have on
our foreheads a label like either G or I
guilty or innocent that magically
transforms after each interaction so I
meet Glen I had an eye on my head he
says ok I can work on a jeep and then I
cheat glad that I somehow on my forehead
turns into a G so that later when I meet
Brendan Brendan sees the g and says oh
man I'm not going to work with me G ok
version of the model in which we see
every excited juice from your
interaction anything I just see this
label instead which is much use the work
that's right so this is this is a simple
model and so far as this can sometimes
be sufficient to do a lot of things you
would want to do here but our starting
point in this inquiry is sort of
recognizing that what has this modern
work so if you via direct and you cheat
me I'd print guilty on your head this is
exactly not modeled it's one of the
things that's on you it is printed upon
my head I centralizing to meet some but
God judge said you cheated and God
decided you can sir it's not there's no
game series exile Mark of Cain it's not
that I want to ostracize you even though
you a good guy you never get guilty on
your head if you are right that's right
so there are no mistakes or problems in
the process now you could imagine what
this is trying to proxy for is the fact
that if I cheat on you you're going to
tell other people about it so it's as if
the guilty good the guilt is going to be
going on to my head this is trying to be
a proxy for communication and this is
indeed what we're going to try to study
in this series of papers is that is the
fact that what happens in this
interaction was privately observed by
you and me not by other people in this
room and so they're two questions that
you would want to ask one is um if you
were to tell truthfully to other people
what it is that I'm doing how would we
want to structure the social network and
my relationships my network of
relationships so that in the event that
I cheat on you bad news about me spreads
quickly to my other partners and they're
able to punish me so how could we do
that to maximize cooperation that's the
first question that we asked in one
paper assuming that victims communicate
truthfully which is an assumption that a
bunch of a literature makes what is the
optimal network but the more recently
we've been interested in more
fundamental question which is when I
cheat you do you actually have an
incentive to communicate truthfully
about what I've done okay yes
and likely that that we actually
beverage our settings in which we
construction the network ourselves
something social interactions it seems
like that's me our digital pod take us
fixed so that more sort of getting it
the question of in what sorts of network
structures would I expect to see a lot
of cooperation so so so one subject two
reasons you'd be interested in this
question one reason is to be able to
compare different network structures
that we see like as in a comparative
statics or in a positive sense a miller
is to sort of understand why we see the
network structures that we do so for
example when Chris you dreams like
thinking of risk sharing in northern
Nigeria now if you're thinking about
like you know us trying to worry about
you know my crops might fail or Greg's
crops might fail you might say to
diversify risk we should link to
different people we shouldn't all be
linked to the same people or within the
same village because we want to be you
know linked to people who have whose
risks are uncorrelated with our own in
some sense okay best negatively
correlated um well what he finds off
what you often find and risk sharing
villages is that people do indeed link
to the same thing that it's almost like
a click and this seems very hard to
square with sort of incentives to
diversify and that's something that
we're going to be able to explain here
so just to give you a sense it's this is
this is the fact that individuals have
an incentive to communicate truthfully
something that smart people take for
granted so avinash Dixit says I reliant
a natural tendency of victims to
complain to their neighbors and there's
to pass under gossip along the network
my Jackson recently says if someone
behaves badly other people hear about it
gossip serves a strong purpose and as we
were combing through the literature was
really only one citation that we could
find where someone said you know what
this actually thought may not be
something you want to take for granted
so the Samuel bowls and herb contestant
and said something stronger do an active
area of research explanations of how
private information could be converted
to accurate public information in a
population of a moral self-regarding
individuals ie Homo economicus have not
been presented okay so this is in some
sense
what it is that our research is going to
be trying the second part of one of our
research is going to try to do look at
what it seems like one really
interesting issue in here is when the
information is ambiguous that the two
sides get and they might in some sense
have different interpretations of what
occurred between the two of them so it's
not simply an issue of telling the truth
that's but an issue of being fair to the
people you interact with so exactly
sunder three issues and understanding
this question one is what happens when
information is ambiguous another is what
happens when information isn't fair
fiable where you know I say Glenn
cheated on me and Glenn says Najib
cheated on him so it's a he says she
says problem we're going to kill both of
those issues by assuming that
information when presented takes the
form of evidence that can't be distorted
and nevertheless i'm going to show that
in the most natural constructions that
the literature has worked with you're
not going to have the incentive to
communicate truthfully so i'm going to
try to stack the deck against me to try
to say that there's something rather
suspicious with the way in which we've
been thinking about this ok so let me
give the first sort of thing that we got
in our first paper which is if you were
if you thought people were going to
communicate truthfully or you were going
to live willing to live with what
economists think of as contagion
equilibria then the best network you
want to have are indeed clicks you want
to divide society into these different
islands and have these ions be
completely connected the reason you want
to do this is in the event a player one
thinks about shirking on player to you
want information to travel to player
once other neighbors as quickly as
possible so it's better to have your
neighbors be linked to each other than
your neighbors to be linked to your
neighbors neighbors that's that's that's
the central intuition I'll go through
the math exactly so so if I thought
about the best network among all
networks with the maximal degree of D
the best will be the click of degree D
now so this was on our first paper in
our second paper um what we did was we
sort of something ready to trade off we
are perhaps like you value diversity in
some way or you know you can get some
benefit from someone who's connected to
your neighbor but not from other people
that would be you to want to have things
that are like more spread out so that
you can get like the value of trading
with someone who's in some sense far
away and then that gets traded off
against the possibility so we mount you
as a green for example by five foot mix
and network 500 people I mean I'm
volunteered to give as a dumbo number
and makes a network lunch no but he's
already done that but I don't think I'm
that so I've got the thing that he
doesn't have Christian is that like
there's no reason in his framework why
you shouldn't just be tightly knit in
the sense that like you know there's no
extra benefit that you would get by sort
of being indirectly connected to someone
who's really far away as you would in
like a recent example right in grapes
example you there's a huge value to like
having someone who's eventually
connected to China as they can bring
spices over from China right so that
gives you a natural incentive not to
have a click because you know basically
comparative advantage means that it's
good to be connected to someone else
it'd be nice to have some model where
you have your motive but then there's
also this motive to get connected to
people far away and so there becomes
like some trade-off between those things
so uh so you could have like a theory of
optimal societies or something like
absolutely absolutely so um so it's it's
it's put this in de it was in the NSF
proposal in terms of thinking from the
perspective of risk sharing yeah it
hasn't materialized into a paper um
because of lack of tractability so
you'll see the challenge the fundamental
challenge that we have here is you know
most repeated game settings it's
incredibly hard to say anything concrete
for a fixed discount factor and one of
the constraints that
may perhaps I imposed on my co-author he
comes from repeated games I did not as
to say look where people's preferences
are people's preferences we shouldn't be
proving results saying what would happen
if people had a certain set of
preferences we should be holding fixed a
discount factor and 46 discount factor
try to figure out what would be the
optimal equilibrium and optimal network
structure so that sort of been a
constraint that we've had that we have
and part of the reason the difficulty we
have improving this result okay in
particular because for a fixed discount
factor and not actually for most
networks I'll I'll tell it all I'll show
you you're not able to even we know of
no methods I could find the best
equilibrium for any fur fur for network
so we have to have a very indirect
argument here to be able to prove that
this is we have an equilibrium on this
network that's better it's question yes
which is why would I not thought this
was going to be awesome was there a
countervailing intuition might have had
that might have want to think that this
would not be dancing rigor um so good
this is actually this so this paper this
project this long-term project divides
into two sorts of pieces that are
somewhat interesting because lesson
number one is one where the intuition is
so incredibly clear and yet it's amazing
at least for us how difficult to math is
the second paper I'm going to tell you
it's one in which it the result move by
most audiences strike them as being
incredibly unintuitive the math it's
actually very easy to prove um so yes I
do I don't have a great countervailing
intuition except it would be great it
would be great to be able to capture why
do math is hard to prove in some sense
that would be the intuition yeah okay so
here's the thing that's counterintuitive
which is if you are suppose you were to
do what the literature is done and say
assume communication is truthful then
permanent ostracism or if I deviate on
anyone I'm permanently ostracize that's
actually the best equilibrium but this
is a this is an assumption we don't like
so let's suppose instead that someone
tells the truth only if it's in their
interest to do so what we prove in that
context is that permanent ostracism
can't do anything better than what
bilateral grim trigger could have done
meaning community and
course materials going to be completely
redundant so that tells you the strength
of these communication incentive
constraints that getting people getting
Christian making Christian willing to
tell the truth that najib deviated is
going to be such a binding constraint
that he's not going to be willing to do
so unless the level of cooperation we
have in society is very low but here to
me what my incentive what the game is
you're playing here in which I okay so
three players and Bob and Carol they're
going to interact repeatedly in
continuous time they have a common
discount rate far and each link is going
to meet and exponentially distributed
arrival times governed by parameter
lambda and then when they meet until
they meet or until a link meets
everyone's just twiddling their thumbs
when a link meets they play prisoner's
dilemma okay and the constraint is that
every one observes activity only on her
only so this is a game where people are
interacting asynchronously and at any
given time at most one link is
recognized and anum barber to only want
to observe when they meet and what
happens when they meet okay so what
happens when people meet their going to
talk then they're going to select stakes
then they're going to play a prisoner's
dilemma with those steaks ok what did so
I want to go a little bit more into this
extensive for me i'll talk about the
talking in a moment so christian just
hold on to your question for a few
seconds um what players are going to do
is they're going to decide what size of
project to work at you can have a lot of
different games by which this is decided
but here's a sort of a simple game I say
no I want to work on a project of size
point 5 someone says they want to work
on a project of size point 8 the minimum
of our two numbers is pick so it's a
project of size point 5 what does it
mean to have a project of size point 5
it's going to come in straight into our
prisoners dilemma where if we both work
we get the steaks that
head in that the stakes that were
selected point five exactly if I shirk
while my partner works i get this extra
temptation bonus I get point five plus
point five squared this is what my
partner does sucker gets and if we both
shirk we each get payoffs of zero why
are we doing this game so there are
multiple reasons one is that stakes are
going to be a sort of nice way of
measuring the level of cooperation and
it's a different way than what repeated
game theorists usually do usually we
measure the level of cooperation by the
minimum possible discount factor to
sustain a particular level of fixed
payoffs where players are working and
sometimes we're looking we're looking at
the mathematical journal problem we're
fixing the discount rate looking for the
maximum level of cooperation as we
discovered this is actually more
tractable as an approach in the
conventional approach and in sometimes
it's more realistic as well I mean we
typically believe that in most
relationships people can adjust the
level of cooperation that they want to
have okay you know there's actually
something in Stigler that goes sort of
back to this Bree asks how big of a link
elusive cartel can you form for a given
type of environment and the like the
bigger and more ambitious the cartel is
the easier it is for it to fall apart
and so you sort of like measure things
not by like can you get cooperation or
not for a given discount his way of
thinking about it was like how much of
an elevation of price above cost Pacific
so it's going to get right to get the
reference so so we went writing this
paper originally we claimed credit for
this variable States environment and
then multiple people we don't think
really what a variable stakes
environment have been telling us we
should actually credit to them for
writing a variable stakes environment so
now we have a massive list of things up
other papers that have similar kinds of
environments um so the great Stigler it
would be a better person neutral party
that's right okay so now you know way
best way of showing how tractable des
scissors to just think about different
equilibria so now let's go back to
bilateral grim trigger
where you're going to work with a
partner if and only if their partner has
never cheated you so someone's thinking
about it should I work or cheat today if
I cheat this is my one-time gain from
cheating or I could work in which case I
get five today and every time we meet in
the future I'm going to get fine so at
some point t in the future which I'm
going to discount appropriately I might
meet the person which happened to the
probability of lambda dt in that time
period and then at that time I'm going
to get five okay so is it trivia that
once I've decided not to cheat that then
I should never cheat because maybe I
want to not warning shot deviations yeah
so in this one in this study would
bilateral grim trigger so one chut
deviation principles going to fail and
things I'm going to show in a couple of
slides here it is true which a deviation
and so so this so this is the and once
this player has cheated so dude here's a
simple way of doing it in this variable
stakes environment once this players
cheated that partner who he's cheated on
is always going to set stakes of zero in
every future interaction once he SAT
stakes of zero and every future
interaction there's no game in some
sense to be played everything cific you
a policy your choosing so this is
actually the best you could do with any
bilateral enforcement scheme is you work
with someone if and only if that person
has never cheated you in the past you
don't care about what this person's done
to other people I'm just doing this as a
lower bound for what community
enforcement should be able to choose
yeah that's rice it's not like it is
this is this is this is sub game perfect
at this look is proof that among all sub
game perfect equilibria which only
depend on history between you and that
person that that such one is the grim
trigger it's like a classical roots omj
means they okay you don't play once you
exactly a young clock radio bilateral
thank you the one thing that one reason
why the famous a result doesn't apply in
our context I should mention is because
because of the variable steak so you
could imagine wanting to vary the steaks
on the basis of your history higher
stakes and so on and so forth but we
proved that that's a complication that's
not going to that's not go to create a
complication here so best you could do
with this and I said I'm doing this
studying this as a lower bound for what
you could do with a network of a little
vent when people look at these evolution
I game series as sometimes have
different situations right there people
South Africa tit for tat and as I sort
of cheap but it sort of good from time
to time you so that's not the case
that's right that's right well then I
can work well in different environments
but this is a complete information
environment essentially so this is this
is a complete information environment
and in some sense typically when we're
so if we had a kind of fix takes game if
I fixed fee and then I'm varying the
discount factor if players are patient
enough and you can always enforce mutual
effort by saying look I'm only gonna
punish you for three periods and then
we're going to come back and not punish
you anymore so that's why you could even
do that you could even have an optimal
iquilibrium take that form with fix
takes once you have variable stakes it's
going to be optimal at least for two
with two players it's going to be
optimal to make a punishment as harsh as
possible and permanent punishments are
going to be harsher than these temporary
punishments and that's why can enforce
more
what gonna happen if you had a perfect
monitoring so everyone observed
everything and now you wanted to think
about ostracism you'd say you're going
to work with someone if and only if that
person has never cheated anyone so
you've got the same gain from shirking
today same game from working today but
the difference now is wonder when an is
thinking about shirking on Bob she says
look I'm going to lose my relationships
with both Bob and Carol Institute okay
and now you can once again figure out
what's the best yeah colubra me could
have in this form for this particular
parameterization by the way this is just
an example you could get you to get
twice as well as you would with just
bilateral grim trigger okay now this is
of course here or we don't expect people
to be able to perfectly observe anything
everything and so the question is who's
going to conceal this information so
let's take the first blush shot this
which is supposed that Anna's shirt
clearly and does not want to tell Carol
that Anne has shirked if anyone does
you'd hope that Bob would do so but an
wouldn't want to self incriminate
herself so for now we're going to assume
that Bob communicates truthfully we're
going to return to that but we're now
going to no longer assume that an
communicates truthfully about what she's
done in the past so he's got the same
social norm but now monitoring is no
longer perfect and asks herself should I
work with Bob or not fire cheatham Bob
I'm going to get this immediately if I
see under echo Librium path these are my
payoffs as before and if I cheat on Bob
there's a chance I might be able to
cheat on Carol in the future the only
way for me to do this as if I can meet
Carol before Bob meets Carol so at some
future time T I might meet Carol and be
able to cheat on her I can only do this
successfully if it's the case that Bob
and Carol haven't met yet and if it's a
case that I haven't met Carol yet and
already shirked on her because I could
only fool her once I can't fool her
twice
so this is now once again using the same
process by which people communicate is
the process by which their trading
that's right so there's no there's no
have you explored model it's very easy
to generalize it and allow for
information just information trade yeah
that's right yeah sorry you lose also
pose yeah exactly okay so this is
bilateral the house of the highest
stakes that you can have are now going
to be somewhere between what you had
with just bilateral enforcement and
perfect monitoring now we're achieving
this in a nash equilibrium where the
assumption is that Bob and Carol ball
communicates truthfully to Carol if you
wanted to get rid of that assumption you
could always achieve this in what's
called a contagion equilibrium where
once and shirk son bob bob says to hell
with it i'm going to shirk on everybody
whoever gets shirt done by bob also says
to hell with it i'm going to shirk on
everybody so that now answers I don't
want to shirk on Bob because now it's
going to lead society into this downward
trajectory where we're all shirking on
each other so that's a simple way of
being able to implement it using a
sequential equilibrium which is what
game theorists love doing but people in
my own department or not game theorists
find such equilibria counter intuitive
and don't like them which is why for the
most part I'm going to talk about
auspices I died an idea that a lot of
people find appealing is that when
someone shirks on me i punish the guilty
we directly target our punishments
towards the guilty and we try to
preserve relationships between innocent
people oh these are within constant
factors right am I missing something
here because the previous one was
to assume this is basically a wine so
are as big or small that's right so when
so when r is small in some sense you
shouldn't be that interested in
community enforcement if people are very
patient you can get you can do very well
we just bilateral and all right yeah
there are small is since I'm this number
is big right sure that's sort of machine
where the sticks where the payoffs of a
passerby that's right
on the other hand if you were to believe
that there are some sort of maximum
stakes out there that any relationship
can have maximum payoffs if you had to
impose that sort of upper bound then
would bilateral enforcement you'd be
able to reach that upper bound if our
was sufficiently small so let me so the
intuition for the clicks is relatively
simple as you've seen so if you had a
circle of 3m individuals where m is any
number greater than 1 and if I'm shirk
some bobbed and Bob's going to show kaun
carol carol is going to shirk on David
and and it's very likely in this big
circle to meet professor x before he
learns from white that this has happened
and so then the best steaks you could
have in a circle are definitely going to
be less than what you could have into
triangle that you're going to want to
divide the society from the circle into
M different triangles so that's sort of
the intuition for it um let me tell you
now where we sort of had some technical
difficulties with this so more generally
a player's incentive to work is going to
hinge it how quickly her other partners
learn about it if she sharks so this is
a term that we didn't find in the
literature which we call the viscosity
of a network and what's the viscosity of
a network capturing which is if player I
shirts on player J at time zero what's
player I going to ask her herself she's
going to say let me think about a
neighbor player k and say think about
the probability that player k doesn't
know by some future time s plus t then
I'm guilty so so this is player I has
shirked on player J and she's thinking
about what's the chance I'll be able to
successfully shirk on my other neighbor
player k 0 SS I'll just some future time
so she's shirt uh-oh I'm 0 OS is you
know yes is 0 yeah perfect that should
be a time s okay so she's going to ask
yourself what's the probability that
this other third party doesn't know I'm
guilty by a certain time if the player
doesn't know I'm guilty at that time
then I'm going to discount whatever
payoffs I get at that time accordingly
and I'm going to get this so one way in
which I think about this game is suppose
suppose my wife is expecting at the time
at which I was thinking about that she
was expecting suppose she's expecting I
know whoever I tell that my wife is
expecting they're going to go around
telling everyone else my one Najib's
expecting a baby did you hear the Jeep's
expecting a baby now I want to get the
joy of being the first person to tell my
friends and so now I'm going to have to
think about what is my expected payoff
in the game and that's actually what's
what viscosities copy now if my friends
if it were a tree that would be awesome
because then anyone I say doesn't know
anyone else and I get all the payoffs
from being able to share this good news
on the other hand when everyone's very
connected information is going to travel
quickly and that's when a networks going
to have low viscosity and it would suck
in that game it's great in this game
okay so what are my general incentives
and now I've replaced a fee plus V
squared with any temptation pay off so
player says player i sighs should I sure
can player J if I do so I get dis
temptation bonus today if I work I get
the steaks from working with player J
and all my discounted expected utility
from stakes of working with all my other
neighbors now when I sure can player j
information about this is going to
spread to all my other neighbors and
only if it's the case that they
information hasn't spread to them then I
can shirk on them and get this payoff of
being able to shoot the temptation to
shirk otherwise they're going to know
I'm guilty they're going to set stakes
of 0 and I'm going to get 0 pay off so
that's a general incentive to work this
is one case where we always had in mind
of replacing this generic X with some
variable that meant something because
when we came up with the exit was
something we didn't know how to analyze
we never ended up replacing it because
we still don't really know how to
analyzer particularly well but we were
able to sidestep it so there's no
closed-form we looked there's no post
form that we could find for what
viscosity would be except for two cases
where we could compute it trees and a
complete graph and we knew that if
there's a cycle from one player to that
player so in other words if there's a
way that information could spread from
one of my neighbors to another of my
neighbors then the viscosity between
these two neighbors of mine has to be
less than the viscosity I would have in
a tree or trees the worst case scenario
we have an algorithm to compute
viscosity but it's nothing that we could
use in our incentive constraints so this
Glen and Greg was exactly the challenge
we face and say how could we prove this
is the best aqua Librium when we can't
even compute something that's featuring
in every incentive constraint let me
skip these on where we compute so we
looked at clicks and so the first thing
we were able to do is to say if we had a
network in which the maximum degree is D
and for every pair of links we're able
to prove that the viscosity has to be
higher than the viscosity that you have
in the cliq even though we're not able
to solve for what this isn't closed form
we were able to use a coupling argument
that coupled the information process on
a click with how information would
travel on any other network and show
point wise and some sense for all of
these paths information will travel
weekly faster on the click so that was
sort of the first sort of step and a
result the second result was trying to
say figure out what dis implied for
equilibrium incentives so I want to go
back here for a second this is a
incentive constraint but we're now
living in a world coming back to
Christians question where the one-shot
deviation principal doesn't hold so it's
not clear that when player I is going to
cheat that she's going to then choose to
sequentially cheat on everyone else in
particular what I might want to do is I
might want to cheat on Christian but
then when I meet Greg not
because I want to slow down the rate at
which everyone knows I'm a cheater and
this was this is a fundamental challenge
for a fixed discount factor we know and
every repeated games theorists we've
spoken to those of no way of figuring
out what is the frontier of
disequilibrium set one of the things
that sort of came out relatively crazily
is realizing that whatever the
equilibria might be you're always will
face an incentive constraint of this
form namely it can never be in anyone's
interests to cheat forever on whoever
she meets now this may not be a tight
incentive constraint but as it turns out
a disincentive constraint is enough for
us to be able to rank equilibria on the
cliq with any equilibrium on any network
in this class of networks and so that's
how we were able to prove that if you
were to just look at equilibrium which
everyone works no one is going to be
able to do better then the payoff that
they would get on the cliq indeco
librium i described if working has
strategic compliments or you don't want
to sort of trade schemes or sometimes I
shirk like Glenn work and then sometimes
I work and let him jerk then any other
equilibrium on any of these networks
can't do better in terms of average
utility than what we have and one of the
things that contrasts us from standard
repeated games is our comparisons are
for all parameters you see strategic it
mean my idea is like no no I don't what
I mean is that my marginal incentive to
work in the stage game is increasing
when you're working well which one
you're shirking ok so now I'm going to
come back to the question of
truth-telling and his shirt on Bob does
Bob want to tell Carol that Ann has
shirked on Bob this is the result that's
counterintuitive but the math is too
easy for us to have been convinced that
we did something correct for a long time
so you hope that Bob wood and now here's
the constraint if Bob tells the truth
they're going to ostracize and give her
the boot and then you've got Bob and
Carol left with each other you have to
be willing to work with each other
because this is an ostracism equilibrium
where you're innocent they're going to
want to work with each other but they're
not going to want to work with an for
them to be willing to work with each
other in the future once they've
ostracized an it can't be that their
stakes in that history or anything
better than bigger than the bilateral
stakes so they have to reduce their
relationship say look we're not going to
work on that high term project because
that stick and carrot through an is no
longer available we're going to work on
a lower scale project and so now let's
think about Bob's incentives you can
either reveal that Anne had shirt work
at the bilateral stakes forever with
Carol or he can conceal this from an and
shortcut to equilibrium pass sticks so
just to describe the communication
protocol here how it works is when an
goes along meeting different people she
has to write down truthfully in her
diary everything that happened she
cannot lie in her diary then when she
meets someone she decides which pages of
her diary to show in which pages of her
diary to not show kushiel's she's the
only one who knows how many pages in her
diary jurors and this is a magical diary
I know we don't expect diaries of
truth-telling here um but the reason
we're sort of looking at a disclosure
game rather than a cheap talk game is
because we want to stack the deck
against us we want to show the permanent
ostracism has very difficult incentive
constraints and even if you were to
allow information to be verifiable in
this way you're still going to find it's
going to be hard to support these
equilibria you have an incentive to
report that someone is a cheater even
though he's honest that's exactly right
that's right so so so one way of putting
this is you could imagine winding down a
whole series of reasons why you could
think this could fail one is the he says
she says we're cheap talk one is that
you might want to sully people's
reputations
and you have other incentives to do so
in a competitive sort of setting we're
trying to show that even if you were to
take all of those other problems away a
problem was still going to remain yeah
plumbing that's not completely obvious
because it could be the guy yells
incentive interacts negatively with your
incentive they sort of cancel each other
out and to create a countervailing
antenna that actually makes cooperation
easier that's right but I think in all
of these cases it's just compounding the
problem I've been looking i mean here
i'm going to give you one history right
at different histories at different
histories so yeah else cases one in what
she you know someone wants us all need a
reputation of someone who hasn't been
cooperating here i'm showing that you
don't want to reveal when someone hasn't
been cooperating yeah no it's okay so
let me let's think through this what
does exactly what his incentive
constraint is that Bob faces so he's
been cheated on by Carol and he says I
can either act as if life is good and
cheat on Carol in which case I get this
or I can tell the truth to Carol in
which case we're going to change our
relationship so that we're now
cooperating at bilateral stakes I get
those bilateral steaks today and every
time I meet in the future now of course
the definition of the bilateral stakes
are those that equated the one-time gain
from shirking with my lifetime gain from
working at them and now the combination
of this inequality and this equality
tells you that your equilibrium paths
takes can't exceed your bilateral stakes
now I didn't anticipate having time to
get into the formalism of this I'll tell
about intuition this is a setting in
which forgiveness is going to help so
remember we're coming back to the
question about permanent versus
temporary punishments if you didn't have
this communication incentive constraint
there's no reason to have temporary
punishments you won't have permanent
punishments cuz you want to have a harsh
as possible stick
but having that harshest possible stick
impedes incentive to communicate
truthfully the way in which it impedes
incentive to communicate truthfully is
it's destroyed too much social
collateral when an is being ostracized
she's no longer available as a
carrot-and-stick in Bob and Carols
relationship and taking her out of from
being a carrot-and-stick is is hurting
that relationship and thereby hurting
Bob's willingness to tell the truth not
a way of phrasing the intuition suppose
our result weren't true suppose it's the
case of permanent ostracism could do
better the reason Bob and Carol could do
better than bilateral grim triggers each
of them knows that if either party
defects unto other they're going to be
punished by an but Bob privately knows
now in this off path history that an has
shirked on him he probably knows that
disincentive is no longer available for
him but carol doesn't know that this
incentive is no longer available for him
and he doesn't have an incentive to let
Carol know the situation is analogous to
imagine that you were a boss and you
hired two workers to supervise each
other as in pure monitoring and one of
the workers sees that the some person
was supposed to monitor him is
constantly playing on the xbox it's not
monitoring kick now you would hope that
this worker tells the boss but this
worker says wait a minute I'm no longer
being monitored I should instead played
xbox too and that's exactly the
fundamental problem that comes up out
here is that when Bob knows that he no
longer has the punishment to bear from
an he doesn't want to let Carol know
that is a bit weird here is that the
game doesn't change ball when you take
your violin so if I'm a whistleblower I
might hope that I get some sort of
truant or bonus for my boss all apps
that we interact more in the future
since there's nobody else left in our
social group it seems like in this game
everything else is held thanks oh yeah
okay so let me tell you about the tunes
so this paper we presented it a whole
bunch of places and every place we
presented it to people present the
things that could break the result and
then it grew to be a 60 page paper and
then our referees have told us take
these 40 pages of extensions and put
them into the supplementary appendix so
we thought about both of those so let's
first talk about what happens if this
frequency of interaction can be rescaled
so Bob and Carol meet more often then
you'd want to think about what does
bilateral enforcement mean in that case
when you just have two players that
gives you a new benchmark and then
permanent ostracism can't you do better
than that new benchmark okay the other
one is somewhat interesting of what
happens if when Bob tells Carol Carol
says look that was an awesome thing that
you just did i'm going to make you this
transfer and then after that we're going
to continue playing this but i'm going
to make you this transfer as a way of
rewarding you for sharing that
information and those equilibria what
you're going to have is no player can do
and so we apply to us for general games
no player can do better than the best
payoff they could have had in any
bilateral equilibrium in a permanent
ostracism so generalizes the bound by
but not by too much changes that I'm not
comparing across different ostracism so
I get a bound foster so than now to
think about a thing with forgiveness
it's going to be clear that forgiveness
this little bit of an ostracism that's
right I mean another version of what
Greg said which I think actually
probably is an important factor in these
types of situations is honor it imagine
that there's some chance that you find
out without me telling what happened in
my relationship with you or the Greg
does if upon learning that I didn't
report your cheating on me other people
now think that they can get away with
cheating on me that is a reason why I
might want to report any time you cheat
on me
I I see the I see the intuition um even
in larger societies though this so so i
should i should mention something to
find that you can't do better than
bilateral stakes isn't something that's
coming out of us having three players
this is true across all networks
regardless of the population size you
can never do better yeah exactly so then
you'd want to look at histories where
everyone has shirked on me except for
Greg and now I'm trying to say think
about this incentive constraint do I
want to tell Greg that he and I are the
only cooperative members left is he
thinking backward and die from that I'm
gonna be troubled by this so you know
I'm troubled by this because he now has
an equilibrium as a modeler I'm allowed
to pick my history and check the
incentive constraints add those history
regardless of how crazy that history
seems I'm uncomfortable with this but
it's I tell we test for our co Librium
oh maybe one problem is that our
intuition that ostracism is the right
thing arises from somewhat larger
societies and that in histories when we
get down to just two people or three
people or four people we would actually
have different types of equilibria but
we don't have good intuitions for what
those would be as we're used to living
on societies that are large fair enough
so we I think the paper we have
equilibria to bridge contagion and
ostracism where after a certain number
of people Sher Khan me yeah I say to
hell with it i'm going to shirk on
everyone but until that point I'm still
I trust anyone who thinks seems innocent
to me yeah okay so reason forgiveness
helpful I think you guys save permanent
ostracism destroying social collateral
if you had temporary ostracism now I've
got some future social collateral and
being re-entered into the fold now
that's going to reduce ann's incentives
to work but it's going to improve Bob's
incentives to communicate the truth and
we show that you can balance these two
so that you can actually do better right
so let me conclude so um the way in
which we sort of viewed this project is
sort of a lot of the prior literature
when thinking about community
enforcement assumes information
diffusion almost as in a mechanical
process
the first thing we did was we made that
same assumption and thought about if you
assume it what would be the best kind of
network to have the second project then
wanted to think about this assumption
more critically and realize that
information flows and monitor your
strategic choices someone is monitoring
monitored wender someone else chooses to
monitor them someone spreads rumors and
gossip when they make that choice to do
so and as soon as your model
communication you find that equilibria
that people in the literature across the
social sciences and theoretical biology
that people have been studying don't
give victims incentives to tell the
whole truth and instead temporary
ostracism having some forgiveness is
going to help with communication whether
I forgive you I ostracize you over them
good it ends a little bit of how I view
the world as an agent with I think the
moral Haswell have a selection kind of
way I think I've just learned that you
are now and forever a bad person then
really it seems like we should ostracize
you but if I learned that you know
possibly in the future you could play
the game in a nice way again then maybe
I want to think a little bit harder
about communicate that's right that's
right so if you were to think about this
as trying to trying to discipline both
moral hazard and adverse selection
issues you might want to use ostracism
at the initial stages to screen out and
kick out all of those folks and then
once you know that everyone in it left
in the room are the good type of people
then you don't you no longer want to use
ostracism or in you just described
before that you had some things where
you might do some things when it's a
large community and other things do you
have a sense of whether ostracism in a
large community part it can achieve
close to the offer
so we have so when you wanted to mix
ostracism at contagion the contagion in
that smaller community is going to give
us incentive constraints on
communication up to that stage okay so
you're never going to be able to do
better with ostracism then you can with
contagion and in fact you'll do strictly
worse all right so that I understand
what I mean if you started putting in
incomplete information in some sense you
could sort of see why Cajun wouldn't be
a very good thing to do early on and I
wonder whether you could get a theory
that would actually pick out ostracism
as being optimal on certain parts of the
game tree but not so yeah I'm sure if we
were to take that model or trying to
make contagion and opted ostracism and
includes introduce some incomplete
information about types different types
um we would be able to work noisy
observations or something yeah might be
thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>