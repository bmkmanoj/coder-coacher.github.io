<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Online News Sharing and Annotation in the Age of Participatory Media | Coder Coacher - Coaching Coders</title><meta content="Online News Sharing and Annotation in the Age of Participatory Media - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Online News Sharing and Annotation in the Age of Participatory Media</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7R8Kand8hmE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
the
we have Elena visiting us from delicious
an intern right now at JPL at NASA but
we actually met when I was in Cambridge
and she was also in cameras she was
working at the Berkman Center for
Internet Society and also collaborating
with some people in the center for civic
media and she was a master student PhD
student at the science department at
Harvard so she's going to talk to us
about filter bubble and how to deal with
biases on our news consumption thank you
um thank you hun dress hi everyone thank
you for being here it's a pleasure to be
able to present to you some of the work
I did in graduate school so to tell you
a little bit more about my background I
just finished my masters in computer
science at Harvard with a focus in
human-computer interaction part of the
work i did there had to do with
interfaces for behavior change I've done
some work in collaboration with the MIT
Media Lab which I'm going to present on
today things I won't talk about but you
should ask me our work that I did at the
Berkman Center where I worked on media
cloud a project that is aggregating over
15,000 news and blog sources to make
them available to researchers and the
public and I'm currently working on
interactive data visualizations at the
judge propulsion lab where I'm helping
engineers communicate data better for
space missions they're planning so today
I'll be talking about the filter bubble
and how we can overcome it and how we
can think about that from the
perspective of the user interfaces we
are using um the three projects that
i'll be presenting our cover three
themes one is content sharing and i'll
focus on memes shared around a couple of
social events and how they reflect
filter bubbles the second part is about
content reading and how we can design
user interfaces that encourages to read
more
diverse content and the third is about
the way we search and how to build
better search interfaces so I mentioned
the filter bubble I'll run with some
some examples from from the wild this is
an image that was training about a month
and a half ago when protests were taking
place in Turkey so what you're seeing is
on the left screen there's a picture of
penguins this was a documentary that was
being presented on CNN turkey at the
same time the world and CNN world was
looking at the protest and the violence
in the street you can see it's pretty
big contrast this is a man-made filter
that was imposed on people no big
surprise penguins really became a symbol
of these protests so when when I was
tracking this story I thought let's try
to see how what what happens when I
search for this event online for this
purpose i will use image search because
it really illustrates the information i
was finding so a lot of the protests
were around istanbul and nearby so I
thought you know I would search for
Istanbul and see what kind of results
come up and this was a week after the
protists happened so they were trending
in the media get a lot of pictures of
tourism and pretty monuments nothing
about the actual news I thought I would
try to be a bit more specific I'll
search for Istanbul and events maybe dad
tells me something there are a lot of
concerts still nothing about the
violence that was taking place in the
streets I thought I would be more
specific so I look for Istanbul news
this starts starting to show the events
that we're taking place and on the
streets there's still some fashion shows
some some fishing but there's a majority
of pictures that depict the events and
finally if you knew what to search for
which were the estimable protests
you get a lot of images of violence and
protests and what was happening in the
streets but it's a pretty big contrast
between the surge that I started with
which was Istanbul and the Istanbul
processed search that I should have done
because that was exactly what the search
engine expected me to look for and the
type of results really are very
different so unless I knew what exactly
to search for I would be really deprived
of a lot of information and this is a
bias of how this current technology is
design and what is expecting from us but
it reflects how we can be stuck in a
filter bubble unless we know what
information to search for so throughout
my talk I'll be referring at the filter
bubble problem and how that reflects in
the perspective of the social network of
the information we search for and the
information we read so the first project
that I'll talk about is a study the
study of how people shared memes around
a couple of social events and this is
work that I did incredible collaboration
with the Center for civic media at the
media lab so I tracked how memes are
getting shared around political event
political crisis that was taking place
in Romania round the marriage equality
the equal red equal sign and the memes
that got generated around the Boston
Marathon I'll be talking about the first
two in this presentation so this is
where my interest for this started about
a year ago a political crisis was taking
place in Romania to cut the the story
short it's the pret Romania has a
president at Prime Minister they're part
of different political parties the Prime
Minister was trying to take down the
president and organize the referendum
where people had to vote whether to take
down the prison and or not so there was
a lot of the discussion that focused
around let's support the President or
let's support the Prime Minister
and you can already see kind of a theme
in these pictures the Prime Minister on
the left is depicted in a James Bond
suit with a plastic gun what's written
in the corner is my name is paste copy
paste this was a theme around the event
because two weeks before this they
discovered that the Prime Minister had
plagiarized his PhD thesis that that
happens in that part of the world and
the president is like a die-hard eyes in
a die-hard posture so everything started
when I was watching my facebook feed
where I'm connected to a lot of romanian
friends who are there or abroad and a
lot of these pictures would show up in
my feed so if you look at them carefully
you'll notice that all of them are
around they're supporting the president
so it's either the president with the
German prime German counselor
associations with a German er-positive
their associations with the West they're
making fun of the Prime Minister copy
from Russia base to Romania associations
with Russia are negative their
associations with the East a lot of
making fun of the paste copy paste the
issue the church is also appearing
believe without questioning more making
fun of the Prime Minister with Dumb and
Dumber so while I was watching these
images some point I realized that all of
them were about let's support the
president and lets make fun of the Prime
Minister there was nothing about let's
take down the president in my facebook
feed and I searched through the history
and nothing came up so I thought oh how
there must be pictures around that
people must be talking about that so I
thought I would try a different
community and i went to the romanian
branch of reddit ah and here's what i
actually found their most of the
pictures that i found there were
around let's take down the president um
and actually very few were making fun of
the Prime Minister except for the copy
paste issue which was just to make fun
of and actually just as a side note to
the type of means a lot of them are
really based on macros that are used on
for means in the US which are slightly
different than the previous ones um now
what this showed me that it was that I
really had to go through a lot of effort
to get to the other side of the story if
I wouldn't like if I wasn't part of the
reddit community I wouldn't see these
because they wouldn't appear in my
facebook feed so i thought i would i
would see if that reflects in other
events where memes are shared so i tried
to do the same thing when the radical
sign memes showed up so first the human
rights campaign i started an initiative
a few months back when they encourage
everyone to change their facebook
picture to an equal sign to support
marriage equality so i thought that's
great I'll track you what what like
messages and images people share in the
hope that there would be a discussion
thread taking place well I started
tracking but the results were
overwhelming there were thousands of
images that get generated in this
process and I I gathered around a
thousands of a thousand of them but
apparently there are many more out there
and millions of people change their
facebook profile so I'm just gonna pull
up that sees
this set of images just to illustrate
that the type of things people came up
with so they're actually a lot of them
has been labeled I labeled them with
another annotator to identify the type
of themes that were occurring through
this discussion so there are a lot of
artistic manifestations there's a lot of
food and bacon there are a lot of cats
of course there are a lot of places and
that mark the support for equality and
then there are other themes that that
appear in this in this initiative but
what I started with I wanted to see what
the threads of discussion were most of
these images reflect one point of view
which is support for marriage equality
and that's an overwhelming set of the
images but not all of them art that way
so these are examples of images that are
against equality there are all sorts of
variations including religion not equal
sign babies but it wasn't easy to get to
these because they weren't being shared
in my social network so I'll describe
how I got to that so again I started
with the social filter bubble I was in
which was Facebook and Twitter where
this distribution started um and then I
wasn't sure where else to check for
these images of course I could go to
read it again but a lot of these images
were trending so I looked on the on the
search engines on Google and Bing and a
lot of the images showed up there there
what was interesting about that was that
when I followed where those pictures
were directing me I found other social
communities like reddit
or know your meme the human rights
campaign had a collection of their
favourite memes Catholic memes had means
that were generated and what is
interesting to observe for example is
that the not equal sign then the the
images that were not supporting equality
a lot of them I could find on the
Catholic memes website they were of
course spread out in other sources too
but there was they were more predominant
on this in this community again this is
an example that shows us that well in
order to find a threads of discussion
that are different than our own really
requires a lot of effort and these four
communities during away social
communities and unless you're part of
them or you make an active effort to
check them out you won't be able to see
the content that's being shared they're
also the search engines are themselves a
temporal filter too because the equal
sign means are still somewhat trending
but if I were to look up the Romanian
means again right now there's no way to
find them although a year ago they were
trending too so really the the goal of
this study I mean part of it was to
understand how these memes got shared
and see how like we could see the
different filter bubbles that are
created even around image-sharing and we
don't want to see penguins right if
there are other events taking place we
want to be able to have access to a
broad set of information in order to be
just society in from the perspective of
societal point of view so lucky us
nowadays we have a lot of technology
that's aggregating information and we
could find information that comes from
various sources and should come from
diverse points of view
it's all I agree in one place and I'll
discuss the challenges that come with
having access to this diversity that
should take us out of a filter bubble
but there are still issues with it so
the second project that I'm I'll be
talking about has to do with how we read
content and how even if we have access
to diversity it's still challenging to
consume opinions that disagree with
ourselves so in particular in this study
i'll be looking at annotations of
opinions so say you have a comment it on
a forum on a news aggregator it could
come with all sorts of annotations to it
i'll be looking at the author of this
comment and how we can enhance this
annotation in order to engage people
with content so i'll give you a bit of
background on why content consumption
can be difficult there's a lot of
studies and social sciences that tell us
that we we like to read things that
agree with our own opinions we tend to
discard arguments that are threatening
to us there are studies that found there
a lot of users that are diversity
adverse they are more satisfied with
reading things that agree with them and
there are a lot of studies around
annotations like you can perceive
information as more informative if it's
recommended by a friend some of the
studies that inspired my work were from
political sciences like k hands paper
that shows that when you present people
with two different points of view when
they read the point of view that comes
from someone that they like let's say we
like this young man here
and he has similar type of world views
as we do if we don't agree with the
content they're presenting but we agree
with the author it's more likely that
will perceive this content more
positively so to make with this more
specific if we think about the turkey
example and we think of two sides of the
story supporting the Protestants and
supporting the state and the police as
being opposing points of view and let's
see we agree with this young man and his
views but we disagree with a person on
the right and their profile reflects
their views what this theory tells us is
even if we support the protest ins if we
read an article that talks about the
state and in support of the state and
the police and it comes from this young
man that we really relate to and like
we're more likely to pay attention to
this and this is the type of mechanisms
that I'll leverage in my experiments so
a couple of examples of profiles that
are used online Twitter makes if when
you look at a Twitter feed of people you
don't follow it makes more obvious how
this person relates to people you know
Google News is making profiles of their
authors more prominent and their Google+
profile associated with them this is
somewhat more unusual example New York
Times earlier this year I had an article
on when the Pope got elected and the
comments of the article show reactions
of the people who commented and whether
they were a Catholic or a non-catholic
and that's because they asked everyone
to fill in a form where they submitted
their comments that reflected more than
just the comment but also some
their opinions so these type of
annotations and profiles are becoming
more and more prominent everywhere and
everything online has is starting to
have an author attached to it any piece
of information um so based on these
findings what the current scenario is
that if you go to an information
aggregator and you see a bunch of
articles some of which you agree with
and some of which you don't agree with
you'll choose to read the articles that
support your opinions because that's our
natural tendency to do so and what I'm
proposing is to attach some annotations
to these articles like the profile of an
author that has the same views as you or
is similar in certain dimensions with
you so that when you go to this
aggregator you will choose based on
who's presenting the information which
in this case are these three profiles
that we agree with and choose to that
could be a filtering mechanism through
which you choose to read content so as a
result the choice won't necessarily be
based on the content of the article and
you'll be able to be exposed to a point
of view that you wouldn't initially
through this triggering mechanism so
this is an example of different types of
profiles you can categorize people's
views in many ways it can be political
views you can measure similarity based
on where people come from whether they
have the same background as you this is
an example of theory that's used in
social sciences cultural theory that I
use for my experiments but that can be
generalized to other other dimensions of
similarity and this is an example of how
this is
based on how individualistic a person is
or how community how egalitarians and
these are just some examples that are
being used to illustrate how profiles of
different people can reflect different
types of views and if this doesn't
convince you this is an example of a
picture of the same person in different
poses that can reflect very different
views so in order to test our hypothesis
of how people would interact with
content when you attach profile
information about an author you need to
have some profiles we can of course grab
information from facebook or google+ but
we don't have a lot of control about
what that information reflects so i
created the content that would go into
profiles it's inspired by people's likes
and activities we tend to like a lot of
causes for example on Facebook so the
profiles that i'll be using reflect
charity donations so i asked people on
on Mechanical Turk to fill in a form
where they would give me their cultural
views and the charities they would
donate to these are all made up but
actually if you look up on Facebook a
lot of these things are organizations
and pages that that exists and they
illustrate very strong opinions but
we'll use this throughout our study so
we constructed these profiles from
mechanical chokers we validated the
profiles so we asked other mechanical
triggers to look at these charity
profiles and try to interpret people's
views in these cultural measures and
they could do that with almost eighty
percent accuracy you could also use
inference algorithms get a similar
accuracy and I did that because we can
learn
from profiles information is so
structured we can infer a lot about
people okay so what we're basically
doing next is picking comments or
new-snippets and attaching a profile
information to these to these opinion
pieces so if we have a user and they
have certain views will want to see if
when we present them with opinions that
they don't necessarily agree with they
will engage with them because they come
from someone who's similar to them thank
you so this is a study that Iran and
actually right before my internship and
I'm still analyzing the data where I
picked new-snippets coming from various
social topics like gay marriage climate
change gun control and i use the
profiles that i created initially and
attached an author to each of these
snippets so these authors half of them
have a profile that would agree with the
reader and half of them have a profile
that would disagree with the reader
mostly because they represent very
opposing organization support so what
we're looking at is we're asking people
to pick two articles that are most that
they are more would like to read more
about and we're measuring click-through
rates and although we haven't I haven't
analyzed this results yet what I ask
people to leave me comments on why they
chose how they make their choices and
there's an overwhelming number of people
that say well I think because I agree
with the organizations that are
mentioned in that post so I mean this is
an example where we make this
information very prominent but this this
is to inform us on how
people will make choices on what to read
based on annotations that we add to the
answer and this is information that's
becoming more and more prominent online
so it's a takeaway from this project is
that social annotations will affect how
we choose content and what we content we
choose to read and we should really
understand how these social annotations
affect readers especially as we design
more and more systems that contain a lot
of information yes a little bit news
items that you're saying to people yeah
do any of these don't match they will
you will expect oh so in this case we're
using the the content itself of the new
sim but I've picked it so that it's
someone in its as neutral as possible so
most of them are factual somebody did
something as opposed to climate change
is not real so most of them try to be
factual as opposed to expressing
opinions so basically next I will
combine snippets of texts that have a
strong opinion for me it takes more
cognitive load for me to read the
sentence
when it's about them to glance at the
bolded text there so you may get a cup
representing it more like a search
result we have the title you know in the
ya-ya hours it's actually I would like
to make it more as a like search engine
result yeah oh by the way if you ask
questions i will give you a token so so
so you should counter the token do we
share you can get 12 and and I have more
of them um ok so again I really believe
that we should understand how all the
information we attach to content effects
users because it really affects what we
choose to read on how we perceive that
content so we've talked about content
sharing and how people read content the
third project that i'll be presenting is
thinking about how to design better
search interfaces that encourage better
search behavior so this is a work I've
done at the fuji xerox the FX pal Palo
Alto Research Lab last year and I
presented at Chi earlier this year so to
to go back to the turkey example if we
were to look for current events in
Turkey especially a month ago that event
that event was trending so a lot of
people do queries around that so if you
were to type a really short query like
turkey events a lot of results would
come up and you would find like even in
the first results you could find out
what the church events were about but if
you're looking for some information that
is less common let's say the
woman in reds name this is also an image
that was trending that is a piece of
information that's not as common and not
trending as much and it requires a more
complex search so if you were to search
again with like woman in red that would
not be enough to give you the correct
results so for for this type of
information you need to type in a more
complex square let's say like turkey
woman in red name and you would find the
result so in this type of situations
when you search for more complex more
uncommon information longer queries
actually found to be more effective but
people are really bad at doing that we
really have bitch ooh it is so this
project will actually address the
challenge of how to get people to type
longer queries and it's really about
thinking of some user interface
intervention that gets people to engage
with this behavior so what we designed
was in the end was the dynamic search
box where it has a colored halo around
it and as you type in more words it
changes colors from red to blue and this
was inspired by it was meant to nudge
people to type longer you can think it
as a parallel to the password indicators
of how strong your password is so we
wanted to test how this interface
compares to for example just telling
people hey if you type longer queries
the search engine will give you better
results so and then explicit
intervention and we ran several
experiments to understand this how
people interact in a hub
will behaved when using this dynamic
search box but I'll talk about the first
one so we ran a mechanical turk
experiment where people were using our
own platform where we had a search
engine and search puzzles that people
had to solve and they had to do various
queries to find a result and what we
found through the experiment was that
people actually actually typed longer
queries because of this nudge so it was
pretty exciting to see that such a
simple intervention got people to engage
more and change their behavior and
really this is a very simple
manipulation that shows how we can
change people's behavior at least in how
long of a query daytime um but was also
really interesting was that when we
compared users behavior when they
interacted with this dynamic search box
with telling them explicitly hate type
longer queries it's better we found an
interaction effect so people will type
longer queries with our dynamic search
box they'll type longer slightly longer
queries when you tell them explicitly
longer queries so they listen it was
almost a significant dependent in the
second case too but there was a
significant interaction between the two
so when we presented people with both
stimuli they actually typed fewer words
than when they were presented with each
stimuli separated and that was a bit
surprising to us because especially in
this case you would think both stimuli
are effective when you combine them
they'll still be effective what we
hypothesize is that people had a mental
model going in of what it meant to type
longer queries because we told them that
before the task and somehow interacting
with this dynamic search box actually
threw them off and that's something to
research more but I thought this was a
really interesting
finding and in particular it should
really make us reflect on how to design
stimuli in the user interface because
combining a lot of stimuli can really
lead to damaging effects on the user
behavior and lead to them behaving not
exactly as we expected so what what this
research shows is really we can is that
we can manipulate the user interface
really with minor changes and change the
the user behavior dramatically and we
should really reflect about how to do
that well especially as the world is
full of content that's coming from so
many directions so many annotations
social network use and so on so to recap
the three projects that that I mentioned
I think it's important to think about
all these aspects of content consumption
and content sharing so what we choose to
read it's not necessarily trivial even
and we're and when we're exposed to
diversity what we choose to search for
will determine the type of content we
get exposed to and the content sharing
reflects like the different type of
bubbles that we're in and and to do that
I think it's very important to study
user behavior and understand how they
interact with different types of
interfaces and to try to design
interfaces accordingly I really care
about exposing people to diversity and
helping them understand the information
that they're getting can't relation to
the University information out there but
that's not an easy task and I think all
these three aspects of
content consumption really can tie into
the filter bubble problem and the type
of the filters that are creating through
technologies and through the social
filters we've created around ourselves
so this is a highlight of the project I
wanted to talk to you about there are a
lot of other things I would like to tell
you about like the mean typology around
the events that i looked at tools of for
news reporting that i've been thinking
of and work that i did at Berkman needs
influence analysis that i actually did
with a fun over there so please ask me
questions I have tokens for you and
could you give a brief summary of the
tools of news reporting what is it Oh
soar in terms of tools for news
reporting this is very related to work
that I've started doing at the MIT Media
Lab where nathan is also from with ethan
Zuckerman and there we're discussing a
lot about how we can improve news at
different levels so one thing i
personally care about deeply is how do
you provide tools that help people
understand news better so nowadays if
we're going to a new site and we read an
article about an event that happened a
week ago if we haven't been tracing
what's been happening in the last week
it's so hard to get the content like a
summary of that content and the
realistic understanding of what's being
presented in a news article so I think
tools that do a better job at
summarizing and helping people
understand content is very important
especially as as news reporting
sometimes is very factual unless you
read opinion pieces that come with their
own biases so yeah one thing I've been
thinking about is around helping people
understand the history of an event and
secondly I've been looking into how we
can think about news report
from countries that we know nothing
about so if something is happening in
Kenya right now unless it's being
presented in one of the news outlets in
the u.s. it's hard for us to get to that
content a lot of events are starting to
a lot of places are starting to use
social media more and there are people
for example on Twitter who are active in
foreign countries but if you don't know
anything about that ecosystem how do you
look how do you identify those people so
part of the work that i started doing
with nathan a while back was looking
into identifying people on twitter who
are likely to talk about what's
happening in a particular country like
Kenya so for example we looked at a blog
called Global Voices where a lot of
people a blog internationally about
what's happening in their particular
countries and they use a lot of social
media references so let's see people in
Ghana would make references to people
who are posting on Twitter and Ghana and
what they say so we build up a core of
people who are likely to talk about
what's happening in ghana by using for
example this blog that was already
curating some content for us and that
generates lists of people who will talk
about what's happening on us so when you
need to know about what's happening
there you could use this type of
mechanism just know where to start
looking and that helps you with social
media what was more user interface away
to the first one yes and in the second
one so it was a reporter's tool to be
actually capture information and be part
of the conversation amongst those people
it's almost similar to the self the self
selection that you were talking about in
the beginning when you were saying that
most of your like your newsfeed had a
certain alliance yeah certain bias but
and it's essentially automating that and
allowing you to dip into that to be able
to understand what's going in that
conversation is that right yes yes
that's a great do I get one of those I
thought that's why you probably asked
usually most of the work never stops I'm
a pink paper will get to you sign of
oppression by a second yes yes you want
to increase the engagement with diverse
content yeah however you choose like to
read all to view the Aptos from
different authors where these authors
basically you like their profile to me
that is kind of buyers to the authors
now try to diverse the comment yes that
so choosing to read based on authors is
biased but I'm thinking of it in terms
of providing you with different cultures
of looking at the information so in the
New York Times example with comments
around the Pope election you could if
all these all those can't know those
comments were annotated you could filter
on people's opinion whether they agreed
with the new election of the Pope or not
but you could also filter through who
was writing about it so the people for
Catholic or the people who are not
Catholic and that I I agree with you
that that's also it's a filter but that
there are people with different
backgrounds that have a variety of
opinions and that's just a way to expose
you to a different a different set of
information so that's how I thought of
it
so wondering about different strategies
you guys used for enhancement of the
content search in relation to the
specific cities of the search engines i
I don't know there yeah maybe you can
talk about it but I was just wondering
about like some specific things that I I
don't even know for example does like do
having different proposition matter in
you know your search because that can
make your search long what doesn't
really make it very purposeful or even
the order of the words or I don't know
like if you use specific words in
comparison to like some general words so
did you take into consideration these
things so we can we did not take into
consideration those things at all um and
we basically build our fake search
engine for for this experiment in terms
of a I mean up thinking about how to
apply these findings to an actual search
engine I don't think just taking this
intervention and putting it into the
search box will get people to type
better queries it might take them to get
them to type longer queries for a while
I think the way to go about it is to try
to educate people about what it means to
type a better query so if you have let's
say the intelligence of a search engine
that can tell that you're not looking
for you're looking for something more
specific and you should type a longer a
query maybe then you could use some
intervention like this or you could use
a message that makes the user understand
why they should type longer queries and
I think that applies to like specifics
like using certain like prepositions and
things like that I think people just
don't know always how how search engines
work I think it would be great if we
could inform them a bit better about
that and that's it's tricky how to do
that because you don't want to impose
that on everyone but I would go around
like teaching people what what their
actions mean what you guys are doing is
pretty
using some sort of game gamification
techniques and make it colorful and
visual yeah you actually other than
having the knowledge and practically you
get more involved and you know see how
it works or I mean I'm still even
confused are you certain all the time
and I still don't know how to approach
to get my different perspectives or I
don't know if like specific things that
happen I have to search around over many
times not a writer's own and actually
another project we did I did with the
same group and that's being presented at
CAIR this summer is to show people
previews of so if you're in a search
session where let's say you're looking
for research paper and you don't exactly
know the name and you have to do a
couple of queries and each query you get
different results we would show people a
preview of how novel the results they
were getting in their current queries is
so let's say you get results on let's
see maybe I have this somewhere show you
an example
well so you get research results on 10
pages and most people look only on the
first page and at the top results so we
basically build a widget where it would
show you how novel the results on each
page are so with each page was returning
results that you hadn't seen before and
by seen is like seeing on the screen or
covered over and this type of
intervention got people to actually
engage with results from other pain like
beyond the first page more and explored
the results more because they would see
this another layer of information that
said look how many new results you're
getting through this query so this is
another type of intervention that we
thought of in terms of information
retrieval interfaces um I think there's
a question as you have covered our baby
time to get you to break out of your
filter model but I was thinking is there
a way to actually find the filter bubble
all together at the more basic step so
for example whenever you had a friends
on Facebook whether it's possible to
find the anti anti pair of that friend I
was thinking of your known as to speed
exactly so whenever you do something
every reaction causes a reaction every
action causes the reaction so basically
you would have a balanced feed and for
each thing that you do you also do
something else that adds to your other
profile so maybe the other view so that
she said yourself your other shops that
you should contradict with yeah exactly
so you can always get a balanced view of
everything
get more of it more I mean I think it's
not easy especially as we don't
necessarily want to attend to a content
that's different I think you can think
of user interfaces that do that I think
other approaches are like some for
example some of the projects that are
taking place at the Center for civic
media make biases more obvious in the
news so they show like what is the world
coverage in new york times in the past
10 years and then you notice how little
are many articles there are and by
making this information more prominent
you can encourage people to actually
engage with foreign news more so i think
i think sometimes there's a lot of
content out there that is a bit of a
different take a lot of content that
when we don't we can't evaluate that
content very well because we are don't
have then a little cope hours to do so
and tools that show us the biases and
the news can also help us engage more
with our other self but if we don't even
know that other that the other self
exists and we should engage with it then
it's a hard task the average Joe that's
not having you know what the soldiers
bubble is again the end above actually
yeah it's but he's condemned to either
user of that talk about even if it
doesn't know about it yeah
presentations about I salute videos i'm
topping and i may be cooler it's like
about our incentives for companies like
Facebook are against fighting the
controlling you can't use the sink on to
the other like advice you'll start
visiting place with less and that's
against the right the type of things
that closer to what you are and you can
start from the assumption that you're
always tracked online so that means that
Google Facebook actually know about what
you're searching for what you're looking
for what your preference are what your
queries are all these kind of things
that add up to your profile and then it
adds can actually be targeted
specifically for you and that's the
incentive over there I mean I think as
are doing a great job at understanding
yeah yeah well not always but sunday are
making a lot of effort in understanding
the answers um my not successfully no no
this will make it you yes so I um you
put forth the idea that um to get that
the lack of opposing opinions is
essentially a problem and the enemy
understand more now I would I I'm not
necessarily disagree with that but I
could make the argument that that the
whole that there's so much information
out there that you're essentially
unsorted the information like that first
thing you're putting downward pressure
on um on consumer satisfaction right so
if you're at a new site you know what
you want to read and if you're saying
basically you're flipping that saying
okay here's the stories that you agree
with here's a bunch of stuff you don't
care about but I mean it's a new kind of
just saying that it would be honest to
seem to be like it was you're like
baking in a dissatisfied for the sake of
whatever because of like let's say I
let's say I support marriage equality
and then I'm probably not that
interested really necessarily having you
put in my
a bunch of opinions of the things that I
fully sorted through my mind he made an
opinion on something sense and I wonder
like I wonder if it's what its value is
when when the whole purpose of a news
website is to filter that day's news and
sorted in a way that gives you the
opportunity to know what's important
that day or what's happened that day and
then taking shoes whatever it is to
choose for you so I actually think that
use websites especially the news
organizations that are putting a lot of
effort in that are doing that they're
doing a good job at that I mean they are
summarizing content for you and I mean a
lot of them want to show you a real
reflection of the news that are out
there but one issues that is coming up
is that in today's world there's much
more information that's gink being
created through other sources like
social media that represents news where
there's no authority that can do the
fact-checking and the verification of
the information that's being shared to
aggregated for you in a it as an
authority so when you think of that then
it's harder to to make judgments over
that content and I think there we should
need to think about different mechanisms
to to put that content together because
there's a lot of it and it's not
summarized and you just interact with
some more or less random selection of it
and I think these type of tools can be
very useful in that space for example
New York Times will curate comments for
you they choose which comments go with
their articles but for arms and a lot of
other websites can't afford to do that
and I think they're you need other
mechanisms to to aggregate that content
and to inform people where where it's
coming from is your research about the
idea of having having the bubble or your
social media bubble essentially upended
so that you see more stuff of whatever
people are are are
doing or saying you're in your late your
newsfeed or that make sense I mean I'm
not sure I understood what you my
question is like are you like you think
this is something that you would want to
do where you would surface opposing
views into your newsfeed so that you
would be you would break that that that
social media bubble in this example yes
I am talking about surfacing these
opposing views this doesn't necessarily
have to be done as a like in the future
as a hidden manipulation where I'm
trying to manipulate you to show this
information I think people should be
aware that they are getting diversity
but given that it's hard to engage with
diversity this is a mechanism I'm
proposing to manipulate that information
but I think at any time the user should
be it should realize what we know what's
being manipulated on him or her but yes
that's that's the context of the current
study oh i think there's a question
that's been fending it yeah i was
curious about unintended consequences of
exposing beautiful so get her back to
the Nemesis feed idea we know that if
you expose to a person who really
believes in something the opposite
viewpoint it only increases their belief
in the original thing yeah it has the
negative and so I'm wondering you know
if we just feed content into a feed are
we in fact making the problem worse for
a certain group of people who really
want to be helping job a tough challenge
so it leads me to wonder if there's a
layer kind of deeper where it's not just
the content that are coming out of these
dreams but the reasons why the contents
being generated it's not the output is
going to be input gansta i mean i agree
with you and you know i'm not trying to
change people's opinions i think they
should just be exposed to more diversity
they should be aware of what points of
view are out there and they can make an
educated in the ideal case is just to
make an educated decision based on
viewpoints yes what's going to the end
goal of having people
some working points then to make better
judgments based on seeing the diversity
yes he was even our own atomic bomb cuz
I don't like it right so I think we have
the choices I'm not sure to your polling
that really wants the really what's the
issue here is it really maybe I think we
need to understand what the audience
really wants to gain and I like very
good at exposing the patterning is
really important for me to know that it
is being filtered to some extent so if I
want the other choice I can change the
filter yes but I mean people do have
that choice I think making it easier
would be great and for example in there
are more debate platforms that are being
built where for example people are
discussing the voting of a certain
preposition and then you can see the
pros and the cons of voting to agree or
disagree with a certain like voting
option you have and there you can think
about what's the effect of seeing these
pros and cons side by side and how if a
user interface makes a difference and
how you perceive this point of view
where you want to see maybe both
perspectives to make a judgment
well I was just thinking about sometimes
people don't want to hear the apoco it
might be interesting to look at some
different scenarios we're hearing a
diverse opinion is really positive so I
was just thinking like a scenario might
be local local events right all my
friends might be saying they're going to
this thing and then hearing some opinion
from something different might just let
me go and experience something didn't I
brush but what all my friends are doing
but it isn't trying to pass judgment or
make me feel like you're training I
don't think people might be more
open-minded about it because doing
either is sort of positive and you're
you're exposing you to diverse things
but it doesn't feel like it's
necessarily this versus that so I was
just thinking it might be interesting to
look at other scenarios and I don't
think maybe more local situations might
be more interesting than the hyper-v
Apple things because I people do get
really biased on things like a generator
on version of religion and these kinds
of things that kind of getting them to
change could be a lot harder than
something that might belong that that's
actually the feeling at all so I got
designing these studies that it's really
hard to get people to I mean if we don't
want to change people's minds but I'm we
have very strong opinions on these
issues like religion and I think
somewhere where where it's lighter to
make a decision might be a good context
to study these things like elections
that the election giving us and
sometimes have a strong opinion like I
didn't know because there's so many
candidates or like that's you know like
certain initiatives get a lot of press
like 20 marijuana one but some of them
read it I'm like I'm trying to figure
out like what it means
you know like I think like there's still
like you like I'm always searching the
air and it trying to figure out like you
know trying to hear who's for and
against it and you know what I think
about it but I think they'd be useful to
have a tool that kind of gave me
and sometimes it's not even just
negative and positive like there are
different categories and different forms
of looking at things and different
perspective that people don't even like
people are not even aware of those type
of you know possible yeah use I mean
it's like things that are happening
abroad if you don't know they're
happening you can't even search for them
because there's just not something
that's accessible to you you just have
the image to CNN
yes let's thank the speaker</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>