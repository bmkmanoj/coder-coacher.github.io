<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Research in Focus – Teaching Machines to See | Coder Coacher - Coaching Coders</title><meta content="Research in Focus – Teaching Machines to See - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Research in Focus – Teaching Machines to See</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/YWfUU9pl-d4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
it is time for a segment we call
research in focus and right now I am
joined from Paris there in pole position
there in France dr. faithfully of the
Stanford vision lab in dr. Sebastian
nawaz in a Microsoft Research Cambridge
two of the young leaders in the field of
computer vision dr. Lee and no Allison
thank you and welcome hi Chris hi Chris
well how appropriate that our first
research and focus segment should deal
with computer vision I'd like to start
with you feifei and ask you to explain
what you mean by giving computers visual
intelligence well think about humans we
go around the world and experience the
visual world a very vivid and lively
ways with we look at objects we
experience the scenery we understand
what's going on and we navigate and do
things in it this is what we want
computers to do we want the computers to
have at least the same level of visual
intelligence as humans so far you're
trying to build a computer they can
mimic human vision uh yes at least maybe
even better Wow what Sebastian what do
you see is the biggest challenge in
endow in computers with visual
intelligence well um think about it like
this if you look at an image you took at
your holy day and the image shows
certain objects then it's immediately
clear for you how to parse the image
what objects are in the image how the
scene is composed where the light is
coming from other people in the image
all these kind of natural questions and
it doesn't take you any effort at all
but if you think about how to make a
computer recognize all these objects and
recognize the scene it's quite hard to
find the right presentation to go from
pixels from single pixel measurements to
these high-level semantic qualities that
you want to infer and really it's about
inferring these representations from a
lot of a lot of training data a lot of
data a lot of images so how then
Sebastian do we get the machines to that
point I mean how long will it take for a
computer to recognize
that my Chevy Nova was the same category
of thing is my boss's BMW yeah well one
thing that has changed in the in the
last few years is that we now have very
large data sets available so that's a
big asset so we can just give the
computer access to a large database of
images and we can try to find the
consistent appearances for example if
you want to recognize a car then we can
ask no matter what brand the car is no
matter what color the car is no matter
where the light is coming from what
stays the same for example maybe the
wheels look always the same and we can
learn with machine learning models we
can learn to pick up on these
statistical coherence ease and we can
build models that can pick up on these
features and then produce as an output
that days with so and so much certainty
there is a car found in the image so a
fey fey I understand that your lab
studies human vision in an effort to
tackle just this kind of challenge right
uh yes we want to study both human
vision and computer vision because they
look at the same visual world and visual
system is what we know in the universe
the best working visual system so we
want to study study it so that we can
build machines to do the same thing so
farrah how do you train a computer to
approximate human visual intelligence
well that's a very good question so um
let's take the problem of recognizing a
dog so what did human do my son is one
year old so you know you show him
pictures of dogs or if you have a live
dog to show him you show him a few times
and the baby learns what the dog looks
like how it moves maybe its bark and
mostly how it what's his shape and color
and texture the same thing goes to
computer you hopefully show pictures of
dogs or models of dogs and the computers
register some of the important
characteristics of the dog's the shape
the color the texture and after a while
hopefully the computer can learn to
abstract and build a good model so that
the next time it sees a dog just like my
one-year-old son it'll say oh look
there's a dog and obviously these things
have to have labels and I feel like 14
million labeled objects I'm assuming
humans have to give these the labels how
does that happen well yet like Sebastian
just said um in the one good thing that
has happened in recent years is thanks
to a large amount of data and a large
amount of crowd engineering efforts we
are able to have these data with labels
and you know part of the work in my own
lab was putting together a gigantic data
set with these labels and we utilize a
lot of Internet technology a lot of
crowdsourcing technology and with this
the computers can have have information
to be trained on so if FA once you've
trained computers to recognize millions
of types of objects it would seem to
open up real possibilities for visual
searches on the internet absolutely a
visual recognition is at the heart and
core of so many important applications
searches being one of them a big data
photo album organization is another one
surveillance assistive technology for
visually impaired autonomous driving you
name it so once we have technology up to
the scale and up to the accuracy we can
do meaning things Sebastian shifting
back to you what are some of the
practical applications of computer
vision that you're working on well
computer vision is becoming more
practical in a sense because everybody
of us is carrying around devices that
can catch a visual information like us
or smartphones and I've worked on
enhancing for example the images that
you capture with your smartphone now at
first sight enhancing the image would
look like quite a different task to
computer vision and it is because the
representation that you extract from
computer vision problems is a high level
representation but on the other hand if
you understand the the complexity of the
signal of natural images
and you do a good job at that and you
can also do really good practical
applications in terms of enhancing the
image you capture for example you can
remove noise from an image or you can
deploy an image many images i take was
my smart phone off blurred especially at
night so i try to address these
practical issues as well but recently
i've also worked on gesture recognition
so in particular using the Kinect sensor
that Microsoft has released um gesture
recognition is now in many many living
rooms and so gesture recognition
research is also one of my research
domains well good news you guys are
provoking thought we are getting some
questions from our online viewers
watching right now let's take a few
we've got one right here earlier
professor Andrew Blake talked about
computer vision and the idea of the
driverless car came up you mentioned in
a minute ago feifei what do you think of
that possibility is it feasible and when
would you be willing to be a passenger
in such a vehicle oh I think very close
I autonomous vehicle using vision
technology is something that's upcoming
uh there is you know like Professor
Andrew Blake mentioned Mercedes is
rolling out of high end cars that have
that technology I personally would want
to sit in that car right now so this is
something we're making tremendous
program progress got another interesting
question here from a viewer who says her
mother is legally blind and they're
wondering if could you work on computer
vision eventually lead to a device that
could restore vision to someone like her
and what would you need to do to get to
that point um that's a good question so
what is restoring mean so to help a
visually impaired patients there are
several fronts we need to work on one is
the clinical aspect which is more
outside of the domain of my own
knowledge but to build a machine that
can act like some kind of narrator of
the visual environment and scenery to
help the visually blinds I think that's
one of our goal we're building
components that are somewhat already are
working for example read
text which is a technology called OCR
are recognizing faces these are core
technologies for helping visually blinds
that are actually relatively mature but
we are also working on technologies such
as reconstructing the 3d scenery
recognizing generic objects
understanding the movement of objects
and other people and items in the scene
so I'm I think one of the exciting goals
of computer vision is to help blind
people all right Sebastian I got one for
you from our online audience and this is
something I've seen come up a couple of
times this person says call me paranoid
but I get a little freaked out when I
think about all these vision and enabled
device is tracking my every movement so
the question is how do you see the
privacy issue playing out well yeah if
you if you build devices that understand
the user better that can indeed enable a
lot of useful interactions with the
device so it in a sense understanding
the human is clearly a benefit in a lot
of applications and I think the benefit
far out weights potential paranoid risks
but we take privacy very seriously so
whenever we collect data from from such
a new device and of course is a legal
process involved that that ensures that
this data is only used according to the
legal laws in place in that country so
yeah I think the benefits far outweigh
the risks in understanding users by
visual systems now the viewer question
for you hear from somebody who's hoping
you can help their confusion confused
about the way that the Bayesian
inference helps with categorizing visual
objects they're open you can explain
this as simply as possible right so
Beijing inference is a fundamental
principle of how to do probabilistic
reasoning in complex models and if you
set up a model and you do proper
probabilistic inference in that model
using Bayes rule so using the calculus
of probability the calculus of
uncertainty
then baseball will tell you exactly what
you need to infer and it will lead to
exactly the conclusions that are encoded
within your model so in that sense
Bayesian inference and the basis based
rule is a enabling inference and
probabilistic models and if you have a
model for categorizing images say then
just applying the base rule allows you
to classify images got a question that
just came in here on the surface says
what are the computer vision techniques
that made it into mainstream consumer
technology that made you go wow well I
just say one word connect right my I
think my daughter would agree with you
on that one I can lose her for hours on
that watching her her own avatar
explored Disneyland and things like that
so I'm with you on that one I've got
another one here from a student says I'm
a high school senior I want to
eventually go to grad school and to work
on artificial intelligence wants to know
what kind of courses should they take as
an undergrad well mathematics for one so
mathematics enables all kinds of
statistics probability machine learning
and it's really at the core of what we
use in machine learning every day so
mathematics and computer science I think
that only the key ingredients you need
if you want to do research in artificial
intelligence machine learning statistics
probability great stuff well you know
what good timing because our timing is
up and thanks to both of you a fair face
Sebastian really illuminating look into
how machine learning is teaching
computers to see the world the same way
we do sort of thank you guys both very
much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>