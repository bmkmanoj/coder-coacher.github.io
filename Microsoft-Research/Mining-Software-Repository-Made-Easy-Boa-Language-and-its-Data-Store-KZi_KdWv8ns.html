<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Mining Software Repository Made Easy - Boa Language and its Data Store | Coder Coacher - Coaching Coders</title><meta content="Mining Software Repository Made Easy - Boa Language and its Data Store - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Mining Software Repository Made Easy - Boa Language and its Data Store</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KZi_KdWv8ns" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
thank you for coming and to all our
viewers online it is my pleasure to
welcome to this rajan from Iowa State
University today she has been there
since 2005 and prior to that he was at
the university of virginia where he
worked with kevin sullivan and God his
ph.d his primary area of research has
been on aspect oriented software
development and he's actually going to
talk to us today about a new project
he's been working on called boy which is
about mining large-scale software
repositories well thank you nancy and
thanks for coming both here and an
online so this this talk is about ball
which grew out of my personal our pain
trying to do empirical evaluation of
programming languages in some sense this
is a joint work with rubber tire horn
one and ten new one all of them are at
Iowa State University so hopefully I
don't have to convince many of you that
mining software repositories arm is an
important aspect of software development
analytics and we want to be able to
learn from the past due perhaps part
anti-patterns what is actually practiced
and then help those observations to
inform the future so for example to find
better designs keep doing what works do
some empirical and validation so there
are so in order to mind software
repositories you for the first thing
often is to find a target the
repositories to mine there are several
examples on repositories that academics
have access to and then some
organization specific repositories that
that industry folks have access to this
is a rich set of data that is available
out there on and it's it's valuable
innocent it allows us to to make
observations that previously would not
be imagined so give you an this idea of
the scale of these things the there are
three large large depository google code
github and source for and these three
together
I have over a million projects over
building lines of code and tens of
millions of revisions of things come
when you compare this to a large
software company this is really not such
big data but for for academics this is a
huge amount of data that is available at
our disposal to be able to test research
hypotheses so what would be examples of
such hypotheses I picked some simple
ones so for example you could ask what
is the most used programming language a
very very simple hypothesis how many
methods in my cold unnamed tasks in this
water what is the number of unit tests
in the in the in the system you could
ask things like how many words are in
log messages do people actually bother
to communicate their intent when when
when committing committing code you
could ask questions like how many issues
issue reports have on have duplicates
and this is essentially a very common
questioning in software development so
we'll i'm going to pick one of these
questions and just and explain to you
what it takes to answer this question
today so here's this task and this task
is is computing what is the average
churn rate for java projects on source
sourceforge our turn rate is essentially
the average number of files that are
changed perl revision ok so today if we
wanted to go and do this task will first
go to source for nut and we'll say okay
let me mine the project metadata this is
essentially a JSON file and then for
each project that you are that you find
you're going to run this this loop ok
and this what this loop does it's
essentially says okay you know is this
project java project sure if if that is
the case then does it have a repository
is that the case if so then right from
code that access is a repository
to mine revisions and then using the
revisions calculate calculate project
rate and keep current rate and keep
doing this until you are done to finally
give you the average on average earn
rate of the project now for somebody
whose primary task is not mining
software software repositories this is a
lot of work so a solution I present on
the understand the slide there it's too
much code don't bother reading this it
just on the if I we just want to
illustrate it up to show how complex it
it could become so this is this code is
written by a mining software repository
export who is one of my one of my
collaborator so it's really optimized as
down to the bare bare minimum so over 70
lines of code that you have to write and
you have to write this code after you
know about these two libraries yes
libraries and svn libraries and how to
access them and use them proper
effectively this code runs sequentially
and it takes over 24 hours on to run and
process sourceforge data so if you start
running it just build it will take over
24 hours and if you are if you take the
time to download the project data load
and locally and and run this code on
that download data it will take almost
three hours to run and finish the scope
now it is conceivable that one can write
a parallel version of this which will
run faster but that would be additional
additional complexity on top of what we
have what we have already for answering
a relatively relatively simple question
here is an alternative in ba is simple
this program essentially answers this
answer the same question I'm going to
explain different parts of the program
to you as during the part of doing my
presentation but just to make some basic
high-level observations this whole
program is about six lines of code now
it doesn't require a
users to understand external libraries
it's automatically paralyzed and it
gives us the same result in about a
minute and that's what boy is all about
it's about giving softwares and program
language practitioners capabilities
write queries of this sort and be able
to run them run them and in a timely
manner in some sense okay so this is a
topic of my talk more language and are
indeed an intensive infrastructure it is
available with limited release right now
I'd bought the siesta taio state edu on
so do to tell you a little bit about how
i came to UM tube or from 2005 and
2002-2012 the focus of my work was
recompiling modular reasoning a
separation across a cross-cutting
concern as um I worked on a language
called Ptolemy with Professor Gary
Elevens I'm from University of Central
Florida that that had this on that the
whose primary goal was to do this and as
part of a language evaluation we wanted
to empirically validate Ptolemies design
what to say okay we wanted to use real
code and a significant set at that to
show benefits and the questions that we
wanted to ask us which which projects
use event based separation of concern
and how do they evolve over time so this
was students work I had a couple of my
students a look at in mind software
repositories such a source for and so on
it took them about three months with not
very much on significant result coming
out of that I didn't think much of that
problem at the moment but when recently
again when I started working on this
this this idea called modulation guided
ilysm in this program language finally
that we are working and I'm not going to
get into details of what this does but
we also wanted to do the same thing here
we empirically validate what is what
does the design and design looks look
like what would you use a real code and
significance that show our benefits and
we want as for that
we want you to find out which which
projects use concurrent program language
feature in the same stories at three
months of three four months of time
that's to spend not so much progress to
show for it because it's just it's just
very hard to do these things at things
manually so a lot of work not too much
time the result and so then we don't
think thought about or can we can we
have can we fix this problem can we fix
the thumb of doing this these sort of
queries so that we can get these results
in a reasonable time and not have to
write thousands of lines of code or
spend thousands of hours doing this this
work and thus that's where book thus a
where ball came to be so Boris three
design goals first one is that it should
be easy to use um it is for folks and I
will come to and explain to that a
second is that should be scalable and
efficient and the third is that you
enable reproducible research results and
I will explain to you to each of these
goals so easy to use this should be a
simple language no need to know the
details of repository mining a data
paralyzation and essentially what i want
to do is honest i want to be able to
empower social scientists and humanities
export to be able to do open source
research that's essentially my my goal
with with this project there's also a
little story behind this I mean this is
um this this requirement came out of a
collaboration that I'm recently involved
in with with an English faculty at Iowa
State University and this this person is
interested in in understanding where the
terms may mean the same thing in
different domain so for example if I
would use the word efficiency in in one
contact does it mean the same in this in
this other context so this person is
trying to do the study for open source a
research and he came to me and said you
know this is just too hard this sort of
work as a person who doesn't know very
much about programming and details of
that is just not possible for me to
to go and answer answer these sort of
questions and boy is hoping that we will
to do fill the sort of gap and I will
come back and show to you show you some
details on that another goal is to be
scalable and efficient we want to be
study millions of projects and we want
to have results in menace and not days
and essentially what we want to do is we
want to have a more ambitious
data-intensive scientific discovery in
this in this ends particular area
finally we want to have reproducible
research results and this this goal
essentially came out this paper is
published in a conference call our
mining software repositories by a by
Gregory robles on this paper essentially
studied there's also in this area on
about 171 papers on that and essentially
says that only about a couple of them a
ver application replication friendly and
it's for variety of reasons and
sometimes the data source is not
available its proprietary data source so
I mean there's really nothing that that
others can can do to make this so what
we wanted to fix this problem as well so
that every researchers can produce it
provide something of that a third party
can verify verify on and we'll show how
to how we achieve that and if you have
any questions please do not hesitate in
in interrupting me so both capable ities
are essentially are on three dimensions
first dimension that most program
program analysis folks are familiar with
is containment so we we look at the
program as an abstract syntax tree
programs contain classes classes
contains methods methods continue
statements and so on and so forth our
enemy into our program analysis we think
about this this containment relation
that's one dimension the second
dimension that is important is a
software artifact evolution in the sense
you know how do how does code change
over time there is a method being added
they are statements being added and so
on the third dimension that is of
interest to you is to us is is scale we
want to be able to do this on very very
large large source code and the code
base I'm going to now delve into a
details of of this language so let's
look at the ball architecture we are an
important component of that is this data
store that we have data stores actually
replicate sourceforge on it is there is
some caching translation goes on and
essentially lookup creates a local local
cache here it's essentially keeps it up
to date in some sense that's that's the
responsibility of that other aspect of
that was designing the language the
language that we that we are designing
and I'm going to come to detail the
details of that essentially a a variant
of a language that came out of alcohol
sawzall we did more work work on that
arm now on top of that we have added
domain specific types and functions and
I'm going to get into details of those
also as part of we'd built a compiler
for boar which becomes Google's compiler
is is a google sign language is
available with the compiler isn't its
development in a usable form so we did
did some work on that essentially a boar
program around like this so once you
write a query parameters compiled it
query plan is created the square plan is
deployed on the cluster which makes you
the local cache which finally produces
query query result so it's a standard
MapReduce the environment and I will to
see a demo of that also are today so
regarding domain specific types this is
one of the core contributions of ba what
kind of types of we need to provide to
make job of of a mining software
repository export easier or ominous so
what provides certain domain specific
type in this program we we are seeing
several domestic types a project is
is a type project has properties like
programming languages code repositories
repository kind code repositories have
properties like revisions and the
revisions have properties like files and
all these all that so the once these
facilities are available in the language
level the personable is not doing any
work to me do mine these sort of
information yes you you can and that's
um add the implementation level on the
swear we start from so the role that
these types play is to abstract the
details of how to mine software
repository so that we can people can can
just worry about a program in terms of
these yeah you explain the program later
will confuse the program
if you're going to compute the average
churn rate i'm expected to get a number
out and here the domain operators exists
so i would guess from that mr. mother
gives you do you I will come to that but
but yes you will get a number out and
and so for now think of the the first
line in the program as what you will get
out of it rates yes yes and I'll come
back and and talk about that also so
here's a here here's some details of the
of this domain specific type if it
provides the name of the project home
page URL programming languages licenses
and all that information that you would
typically expect a from a project now
there are other types like code
repositories revisions files and so on
and they provide usual usual details
about about these artifacts more
information about this is available from
the from the website of course we also
have done a specific type for source
code analysis um and these include
declarations namespaces types and Sarah
think like variables things like
modifiers things like methods so all
these types are essentially are to make
the life of a mind software repository
and export easier we also have said a
statement level access and the
expression level access so you really
have the entire a track syntax tree
available at at your disposal once again
I'm not getting your details of these
because this is this information is all
available online and really when you're
programming you can look up which one
which are which type you need ok so the
boat boss type are not specific to any
particular language it's a generic
enough to support any object oriented
language currently we are suppose we
have support for java source code
we are planning to have support for c++
and also our forces sharp if the refined
the library that is useful what we do
essentially for mapping is to we pass
the source file generate a st and then
we store it in the distributed database
on the database that we are using here
is the HBase on HP's database to do the
do the job here so Java code like that
would probably represented like this an
internal ast and again the details of
that are are not so important but just
just taking a look at the in containment
relation and this is essentially what I
meant when I talked about the
containment dimension you can browse
through the statement and say you know
what is the name was the variable what
are the expression that it contains and
so on this is the program language
portion this hood this will come
naturally in some sense this is standard
HD containment we also provide has a
domain specific functions these are
first-class functions on that we have we
make available in the language so how's
file type is a function which takes two
arguments revisions and NS string and
returns a boolean and as as the body of
that function it tests whether there
exists a project there exists a file
that matches certain format and so it
returns true otherwise it returns it
returns false ok there are other
versions of these functions are click
project or code repository so here's
another example um this is a it's one of
the common things that people do in
mining software repositories to say with
it when somebody comes to the code they
were there fixing a bug so this function
try that tries to test for that yeah by
looking at the log of the of the commit
message because oftentimes people write
things like fixing this bug or fixing
some other ball and so on and so forth
so it looks at the log string and said
okay you know if it matches if it's
matching certain pattern
then we will consider that to the bug
fix or or not the details of this
particular implementation is is not so
important what's important is that a
user is allowed to write these these
heuristics on themselves so in general
user defined functions take that and
take this form return type is optional
and essentially the idea is to allow for
some other complex algorithms to be to
be encoded next hour of quantifiers and
this is this was essentially earlier
your question I understand so
quantifiers are essentially the same as
in mathematics and this essentially it
allows us to easily express loop over
data and bouncer on it inferred from the
from the conditionals so I'll go through
some of quantifiers in details so this
is this is one especially for each
quantifier say it's for each value of I
if certain condition whole then run body
of with I bound to the to the value ok
on the exists quantifier essentially is
the same as mathematical exists one
would when you imagine if if there
exists a value of I where condition
holds then run body once when I is bound
to on I'm to magic one matching value
and if all essentially says that if for
all values if the condition holes then
run body once with I not bound so this
is the reason why we have these is
because we have found that these kinds
of quantifiers make the task of
expressive queries here where is easier
of sabor under as a detail of a muted
computation and underlying architecture
is a map is used as a MapReduce
framework so I'm going to for those who
are not familiar with this I'm going to
give you a quick summary so MapReduce
essentially this idea that you have you
are processing a bunch of data and in
the map step you are you process you
have identical copies of a program that
each process is a certain portion of the
data and then in this shuffle step of
you you take the output and you you you
take it to reducer which then based on
its output gives you one or more values
okay so essentially the idea this idea
is same as their mothers multiple data
but the single program is running on
each each dataset okay so that's
essentially basic idea is not an
invention not the contribution of boa
per se it's a butt bow it makes use of
that that paradigm so out an output and
aggregation ingression are part of a
boss design so output is defined in
terms of predefined data aggregators
like from that mean a maximum minimum
acerra values are sent to output
aggregate variables so here's an example
of an output um is declared here this
says rate is an output and this rate is
going to compute a by computing a mean
indexed by the string sent to it and
this mean will be essentially an integer
here is um here sending data to the tude
aggregator and this this we are using a
C++ syntax of doing a dream of cs if
you're familiar with ascending later the
output C out or CN you will probably
immediately see what's going on here so
we are sending two rights and we are not
just where we are sending rates and
index
and this value so society essentially
saying find thing at this index and then
come and increment the mean with this
additional data value
so let's see it in endemic see if there
is a
so when you go to the wall that page
there is a user login on the left this
we don't have open access to this
infrastructure infrastructure available
yet but when once you login you get to
this page this is how you use ball out
of a tablet or a smartphone or your web
browser and abs and we teach people how
to program in you in boy using examples
so we have a wide variety of examples
that we make available on available to
users so if you if my query matches one
of these examples I'll typically start
with start with that so imagine for a
second that I was interested in in
saying in asking this question how many
projects use the Java programming
language so I will start with this
example which says how many projects use
the scheme programming language and this
when I pick that it populates the
program and here this program is saying
on that the output of this program is
count it's going to be some of some of
integer of values that are sent into
your integral values that are sent to it
and imported the program is is a project
and for each into your I such that the a
programming language used in the project
matches scheme i'm going to send a value
1 to the counts so that you know we
basically counting distributed over
overall arm so i want to change this
program to say that counting projects
using java
okay now this little program that counts
the number total amount of projects in
sourceforge that use use the java
programming language next thing we have
to do is we have to pick which data set
we I want this program to run and this
is sort of where the reproducibility
requirement comes in when you report a
result you could report results by by
mentioning which data set you ran your
program on so there is a better
understanding to the third person that
oh you know this is the data set on
which this this result holds so we have
only one data set at the moment which
was done in 2012 and July we are going
to we're planning on doing one more one
more snapshot but i'm currently just
going to run it on on the live data so
once i have my program i can then i can
then run it this is essentially just
clicking the button that's about all the
work that a user has to do so it's going
to compile compile the program and let
me return to the presentation here for
our for for a second so it's
so we will wait about a minute for the
result but so let us understand why are
we waiting for these results this
problem that we just wrote is analyzing
about 600,000 our projects it is
analyzing about 370,000 our repositories
and about about 4 million revisions okay
and these are contained in this money
out of money there's many files okay so
let's take a look at what worse the
program is doing so see here on the the
compilation has finished its just on the
end the execution has also finished and
this allows you after the execution has
finished it allows you to see the job
instead of only about 450 thousand 136
projects I use Java as a programming
language okay you can also download the
java office if you so wish if let's
suppose your program made an error you
can you can edit the source code and you
can you can send the new query that is
based on based on your your earlier
program and this sort of has to do with
that all of this has to do with the ease
of use requirement and that I pointed
out earlier we want this to be available
to a class of users that just cannot be
bothered with installing a bunch of
libraries and a bunch of other software
system to make the make their make their
queries work you which they should be
able to just point to a web page and and
be done with it in some in some sense so
this is the end this is a reformer that
that ball achieves a very well on the
setting
so I already check the results of all
I'm we check the promise a bow on a
bunch of task the important details of
these are these of these tasks are not
are not important until different
categories of things more details about
that is in our XP paper this year what
we saw is is that compared to java
programs both programs achieved results
in much faster time and this is a as you
can see this is a time in logarithmic
scale on an average both promise finish
much faster there were three categories
of these programs the one category was
of these programs where it was accessing
only one repository version the second
category was variable for accessing all
revisions on the project and the third
category was where it was it was only
doing a metadata that was um that it was
this the sky here okay so Java programs
has used to cici's variants but the
board programs are nearly take the same
amount of time and most of that is most
of that essentially is is Hadoop's
startup stop or start overhead here
the our programs are sequential what
they're looking looking at local and you
can add you can for example paralyze
them if you would like speed up adheres
do girls you know to do the main the
main speed up here is is is because of
parallelism and also because of the data
storage strategies those two things play
play at all because querying querying
from distributors tour was requiring
from a centralized data set that's where
the comes from any other questions on
this to look at it in some more detail
of one of the important things to notice
is predictability of result both
programmes nearly we can say you know it
takes about a minute it will take you
about a minute to run it whereas for
java program is sort of varies based on
what what you're trying what you're
trying to do next thing we did was we
examined whether these things are the
these things kel so for that are we
again looked at three different I'll
protect categories 6,000 projects 60,000
projects in 620,000 projects 6,000
projects that's six two thousand
projects were picked out of this set
using random sampling and so again shows
the ball program programs in blue and
java programs in in in red is as as you
can observe for java programs for
different data set the performance as
expected decreases for boys the slope is
much smaller and this again like i
pointed out previously due to two
reasons first is increased parallelism
and second is better data storage
strategies
I utilized here at this point it would
be important to look at that all of
these things could be done at the ad and
these all these queries could be run
using Java enough in both the same time
but the cost of writing those queries
will be much greater compared to what
what we are providing it so some some
exactly some concrete examples for
numbers and we see the improvement for
larger size you see from 30 seconds to
33 seconds of 41 seconds not not very
much in increase in the amount of time
takes a process whereas for java I you
see 2011 9692 and 600 6,000 seconds so
and at this point it sort of becomes it
becomes very difficult to wait that much
to compute answer to some questions like
this next thing we did was we said okay
you know can we if we throw more thing a
more infrastructure at it it's going to
work for soup for that we we scale to
more course on so this this shows
different charts are for these maps you
are essentially to present the amount of
resources that were available to it 32
maps essentially means 32 cores where
available available to it this shows
that as we throw more more machine at it
the performance actually decreases a
performance increases at the time taking
decreases so if we continue to add more
we will see some of our similar trends
if we have more infrastructure available
to
so one of the things that one of the
goals for bar is to be able to replicate
earlier results be able to stand so if
you recall we had we brought up this
paper earlier which says two out of 154
experimental papers for application
friendly and most of them were due to
the lack of published data I mean it's
in it's it's understandable because
there are cases in which you cannot make
data available publicly so probably the
chills were difficult to reproduce and
our claim is that ball makes it make
this easier and to validate this claim I
would like to reproduce something very
very small for you today to show what to
give you the taste of what it is like so
what what we have done is we have we are
written about 18 19 questions using bar
and we make this available from our
examples examples webpage and these
questions are independent in many
different different categories and one
thing we did was we we wanted to show
what it would be like to publish a
result using bar okay and and this is an
example so imagine that this is
essentially what the contribution of my
research paper a very very small
research paper would be what I would do
is I would say okay this is the research
question that I'm answering here's a
program to answer to answer that
research question and I'm using this
data set for my format for my results ok
so I can take a look at that data set
and this is essentially it's essentially
it please don't try to read this just
shows you the counter counter projects
what I'm going to try to do however is
to try to reproduce this result so
trying to reproduce the result
essentially involves copying this
program here
going to the sense of structure
pasting it they're picking the right
data set and and running it so for this
trivial thing is it will run it will
give you the right answer but the
essence of this is that if with a simple
example query and a tag you in this
infrastructure will allow people to
essentially see what you saw in the
first place what you have without having
to build build the whole thing
so we also did a control experiment
where we use the published artifacts
from the war website and data set used
and here here are the result of this
this control study so in this study we
had folks involved from postdoc stage to
run a grad student who try to try to use
bar to reproduce some results some of
them were experts some of them were not
and their and their task was essentially
to pick one task out of out of the 18
that we provide and try to see if they
can reproduce that result okay and most
of them were able to really do this in
in less than 10 minutes we were able to
to show show the same lyst same result
of that that was published earlier so
there are a bunch of work on the in this
but number-wise direct support for
mining software positives and so i'm
going to give you some examples with
that sauce solid is where boys comes
from similar syntax to ball abstract
ideal of MapReduce pig latin is another
example in this in this category the
declarative syntax similar to SQL dryer
link what is another example of this
kind of language compiler drive
framework there was some work on on on
sorcerer which was essentially in SQL
database about 18,000 18k projects which
allowed you to do mining software
repositories boy is more scalable
compared to the shorter and more
fine-grained because it provides you
fully abstract syntax tree there are
some commercial products also available
on there was used to be a google core
search that allowed you to do a grab our
repositories but that allowed you to
only
our answer very limited questions
whereas we provide much more much more
information than that although from
black duck it gives you a REST API which
gives you project metadata metrics etc
for some projects but this is not we
found it's not as scalable as as bore
boys and then there are things like
Google course search github or cetera
compared to those both provides more
than just textual textual map there's
their ongoing work in several directions
um I'm going to identify the directions
and tell you a little bit about that
first we want to support more kinds of
repositories here we have support for
svm want to do get bizarre etc and then
we want to support more data sets expand
to Google Code github launch pad this is
more of a logistics question than it and
then a research question but if for four
they did that to be really contain
millions of our projects it will be
important to have some sort of
arrangement with these these folks to to
have their data set in the repository we
want to enable a mining of other
artifacts issues emails bug reports on
the project related other project
related communication of the key etc and
then we want to also be able to have
designed some language abstractions and
solve them we have started to look at
already last but not the least
infrastructure improvements are
extremely important i mean as we are
putting throwing more data at it we are
really hitting the scale issues of and
but we have some some progress on making
some progress on that also so with that
I will conclude for today what I've
showed you today is a domain-specific
language an infrastructure software
repository mining which essentially has
three goals have two wants to be easy to
use efficient scalable
and allows you to produce research
results so if you have any further
questions I will be happy to take them
at this point yeah do you support
intermediate results in caching
immediate results if so if let's suppose
we have two queries and you want to you
you are talking no currently we do not
currently we do not support intermediate
results um and that's that Scott what I
wanted to do n sum K goes first at the
moment we we don't let the website that
I showed you does not have support for
it but that may not be the case in a
month because I mean there are somebody
altri already working on it yeah so I
mean this is a but that's a good
question thank you thank you Tom nes so
I decide to decide an external these
error other then say it is healthy they
didn't shower that one could call out to
other child methods to whatever build a
comma-separated this is an output or
about a data flow analysis on the AST
something back there the it was
primarily due to the audience that will
clear that we are targeting it's the
goal of boys is to bring this sort of
capabilities to people who would who may
not necessarily be export programmers
and often giving them an assignment in
in java compared to giving them this
simple feature we think that is likely
that we will succeed more here than in
in java so how are we support something
like that i would assume that those
that is correct it would arm it would
not be it would not be very difficult
and to support something like that for
for expert users it has an API like
Thing Thing available it would not be
difficult at all it is is it was simply
a matter of selecting the right product
for the audience that we were we wanted
to target yes Rob in the examples that
you show the scripts are kind of running
over kind of cleaned up well schematized
data sets so what do you think about the
other eighty percent of the job which is
starting with the messy raw data and
getting it to a clean data set is that
kind of in scope for your project it is
okay so and so I'm the if you if you
recall from data infrastructure one of
the one of the important things is to is
to replicate the data from this
repository over to and there are many
problems that needs to be reconciled for
that so for example same things don't
mean same across repositories and it is
it is certainly within the scope so we
have we have started off with addressing
addressing issues relative source for
the moment currently there a work in
progress for trying to see what how
ontologies for source code matches with
ontology is for for google code and so
yes that is within scope it is
essentially an ontology mouth mapping a
problem whatever approach you take kind
of want to make it so
because as more and more miners go after
this data they're going to want to
schema ties it in different ways to
answer different questions all right so
if too many decisions get made to do the
tool then Albert adoption right so you
want to have it pretty open it correctly
um yes and at that point that sort of
you also want to bring up this another
philosophy that we have which is to not
provide interpretation of data but
rather provide the data itself and let
people make their own interpretation in
some sense yeah okay all right that's
good thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>