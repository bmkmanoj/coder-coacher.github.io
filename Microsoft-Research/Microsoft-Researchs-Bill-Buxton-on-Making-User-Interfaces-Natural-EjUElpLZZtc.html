<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microsoft Research's Bill Buxton on Making User Interfaces Natural | Coder Coacher - Coaching Coders</title><meta content="Microsoft Research's Bill Buxton on Making User Interfaces Natural - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microsoft Research's Bill Buxton on Making User Interfaces Natural</b></h2><h5 class="post__date">2010-03-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/EjUElpLZZtc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'm bill Buxton and from Microsoft
Research and I just want to talk a
little bit about natural user interface
and the main thing I want to talk about
is what's the natural and natural user
interface what's it all about so it
seemed natal all this gesturing it's
kind of cool but the first message here
is it's not about the technology it's
about the human doing the gesturing and
if it's going to be natural we have to
understand that it's got really a lot to
do with very very fine detailed skills
so let's bring it back to something to
really understand writing or we think we
understand so pretend I'm writing I'm
just not pretend I've just finished
writing my notes for a thing for craig
mundie and and i'm finished so here the
arts on this a half by eleven sheet all
nicely lined out terrible handwriting
but we think we understand what i wrote
but this isn't what i wrote so of a
friend EVR and he did this study I'm
this is a replication of what he did
carbon paper on the bottom of the
writing service for the sheet of paper
here and so that is actually what the
carbon paper said I wrote and what
you'll notice when you compare the two
this is way smaller it's narrower and
it's rotated now what this clearly shows
is that while I was writing I was
manipulating a paper rotating it and
sign it left and right as well as up and
down so that the zone of comfort for
writing is much much smaller on their
surfaces writing even though I've got
this larger desk covered that it was
perfectly available to me and this is
works all the time what this says is
that God's in the detail understanding
that writing is a bimanual action that
requires this coordinated skill of the
two hands using different functions
touch and stylus if you will gives us a
hold of an insight on how we write with
a pen and on any endeavor that we set
out from writing things much more
complicated where we want to support
natural user interface we have to
understand the activity the intent and
the human capacity at this level whether
the capacity is at the motor sensory
level at the cognitive level or at the
social level now I want to talk about
this in a few other devices how this
reflects and can reflect into how we
interact with using devices so let's
weekend
a camera is a mobile device while it is
of course it's a digital computer it
happens to light in and pixels out and
notice when I navigate over this
document I can zoom in and out I can pan
left and right and come down and examine
any part of the document everybody knows
that but the other part is I'm looking
out and got my eyes closed or I can
still go to the top left top right
bottom right bottom left part of the
document without looking that's kind of
interesting so let's compact contrast
that with how we navigate on digital
documents so my colleague Michelle pose
going to come in and give me a couple
other devices here now here we have two
devices this is your standard PDA or
phone where I have in this case a
landscape you know we're up in the
Columbia River and I can pan around and
I can zoom and so on using touch this is
seems to be like a pretty cool fancy
modern way to do things but i want you
to notice I can't go back to a certain
part of that photograph without looking
I can't zoom and pan at the same time
which I could do in the camera so in
this case you notice I move around on
the display and navigate the photograph
in the same way in this virtual
landscape as I did with my digital
camera but the fact that can zoom and
pan simultaneously using one hand
actually is very very different than in
in the traditional way where we do it
with two hands where I use the the pan I
have to hold the phone with one hand and
do the pan and zoom with the other hand
I have motor memory I don't have motor
memory I can zoom and pan simultaneously
now that's fine and dandy if I'm doing a
virtual photograph like a panorama but
now what if Michelle brings me a
document so now instead of a virtual
scene I can come into this web page and
now all of a sudden I can start to read
by going left and right up and down and
navigate that way and so all of a sudden
what's kind of interesting is I can get
around the document in and out and so on
with one hand but now I can pin that
should come in and touch and do
something my other hand is free
going to demonstrate that now with with
yet another device so what's interesting
here is that I've got the menu over top
of the map so you notice like the
crosshairs in a gun I move it around so
now i can come down to a spot and i can
just push the flag and you notice i laid
the flag down and i can do other things
here too now watch this I can hit my
annotation button here and now I can do
something because I want to tell you how
to get over to to my office i'm going to
hit the record button i'm going to say
something like okay this is the building
where you're at right now and if you
come out here under 148 and just drive
down here and then turn left you can
sort of park right in there and this is
where you want to go and the main thing
is just don't come into here around
building 122 that's not where you want
to be now watch I'm like building where
you're on right now and you come out
here and just drive down here
this is where do you want to go the main
thing is just okay now the main thing
here is what I want to the key point
here is is that what am i capable of
doing I'm capable of zooming panning
marking and speaking all at the same
time this device is capable of capturing
all of that and now all that says that
natural UI is that I can now send that
to your phone to instruct you how to
come and so it's a whole new type of
layering up these multi modalities it's
not about any one of these speech
gesture maps and so on be natural it's
how they're used together in context for
an intent now here's the here's the most
important part sure that helps us
communicate between my laptop or my
phone and your laptop or your phone but
now thing with this way at the same time
I'm going to CC your car so that the
message that i sent here goes through
your car navigation system and the
natural language understanding parses
what i said in the context of the map
which are recognized and registers with
the maps in its database and then it
segments my speech and then the map the
route i drew drives the map instead of
the algorithms that your navigation
system would have given otherwise and it
puts my voice to direct you how to get
there and furthermore if I left
something out it'll substitute the robot
voice in the thing to flush out the
instructions the point here is that all
of a sudden you now see it's not about
the speech it's not about gesture it's
not even about the phone and it's not
even about human human communication
it's about also this to other devices
the society of appliances the phone to
the car and then the car been able to
deliver in the most natural way for the
purpose while you're driving how to get
where you're going and combining it is
intermediary in the human human
communication and this society of
appliances and how these things work
together in a natural seamless way that
reduces complexity for the users
the engineers taking on the complexity
of how to build these things that's what
we're about and getting these things
right opens up a whole other dimension
of how we have technology integrated
into our lives it involves all these hot
topics like sensor networks ambient
intelligence and yes actually getting on
with their lives without technology
intruding but rather being transparent
and enhancing our lifestyle and our
quality of life
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>