<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Small Spaces Feel Large: Practical Illusions in Virtual Reality | Coder Coacher - Coaching Coders</title><meta content="Making Small Spaces Feel Large: Practical Illusions in Virtual Reality - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making Small Spaces Feel Large: Practical Illusions in Virtual Reality</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bn_0Q1EpUEg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
thank you so much for coming my name is
karai Banco I'm a researcher here at
Microsoft Research and it's my great
pleasure today to introduce Evan Zuma
he's visiting us from USC from it's true
of Creative Technologies down there and
he's one of the world's experts on all
sorts of er trickery trying to
understand try to basically understand
locomotion expand our spaces in kind of
walking abilities and manipulating
abilities in VR mostly by manipulating
what you see and what you get and the
differences between but I won't take
much from his talk I just want to
welcome and say you know thanks for
coming down and giving us this
presentation okay thanks pinko for the
introduction so today I'm going to be
talking about how to make a small space
feel really large so this is all about
perceptual illusions and virtual reality
but with a practical spin because what
we're trying to do here is solve a real
engineering challenge for VR so VR for
me is a really kind of special place to
work so ever since I put on my first HMD
I became fascinated by the experience of
being in VR and creating VR experience
for others and what really ups the ante
for me is when you can use VR as a
medium to create really surreal
experiences that transcend what is
possible for the real world so some
people say we recreating the real world
in VR is kind of the Holy Grail but for
me it's transcending the real world
going beyond what we normally can do so
as an engineer I think it's really this
is a really challenge being able to do
this is really challenging because VR
has so many moving parts that need to
work as a researcher it also is a really
interesting empirical tool for the
controlled study of human perception
behavior you can actually use it to test
things you can't evaluate in the real
world and this talk really is about the
intersection of these two goals you're
in it's engineering magic
experiences but experiences that also
enable us to do the empirical study to
understand more about the human
experience so an overview of this talk
I'm actually gonna first take a step
back from that and focus more on kind of
just some of the work but we did in just
the fundamental display technology
because we are these experiences are
technology mediated and then from that
I'm going to move into kind of the the
challenge the next big challenge that I
see that we're trying to work on and how
we're kind of looking at this from the
perspective of what I call hacking human
perspective illusions and then finally
I'll talk about more about the practical
spin of this which is how to enhance
interaction fidelity which is kind of my
code word or my technical term for Korea
creating magic so looking back at kind
of when I started in VR so I started in
2004 --is-- 2003 and but I got really
started grad school in 2005 and these
were the displays that I were using at
the time so we're talking pretty low
resolution 640 by 480 per I bulky heavy
very expensive but probably the most
problematic at the time was the field of
view so the v8 kind of the standard that
you saw a lot was 60 degree diagonal
field of view and so if we look at this
graph this this is actually mapping what
that type of field of view is onto your
entire on your retina and your what your
human visual system can actually see
it's like looking through a very very
small window and this is for me why VR
up to that point all throughout the time
I was studying in graduate school really
wasn't magic in fact a colleague asked
me when I got started in VR and I told
them the year and he said you decided to
get a PhD in VR when VR was down and
awful what is wrong with you
so I guess I just liked a challenge so
so this changed for me in 2010 when I
moved to the Institute for Creative
Technologies and we have a prototype
display there called the wide five and
so this one really and the antlers they
are kind of funky but they're just for
the motion tracking
system but the real fun thing about this
display was that was when I first
experienced VR magic because it has a
150 degree wide field of view so the
difference here you can see that it
really is the difference between looking
through a tiny window at something
distance and really for me being there
and so if you look that that wasn't the
only display capable of doing that
although is the widest at the time but
if you look at the cost you really see
two categories here and it was really
look useful to look at this as dollars
per degree so if you look in the bottom
that is kind of more what we would
target is you know not even necessarily
consumer level but more affordable HMDs
that but their field of view was really
limited and getting up anything over
that 60 degree mark really ended up it
did not scale linearly and it ended up
getting getting extremely expensive
beyond what you know a lot of research
labs can afford let alone the average
person um
and so a lot of our funding at ICT comes
from the US Army and so we had in about
2009 and the acquisitions people who are
in charge of all of the purchasing and
decisions for the army came to us and we
gave them all the demonstrations of VR
and they said this is all great but it
will never be used by the army and the
army cannot can invest in VR because if
we want to train people we have
thousands of people we need to train and
it's just too expensive there's no way
you what you have to figure out a way to
do this and with a more cost-effective
manner so this kind of got kicked us
started us and got us thinking and we
were really inspired by this little
piece of technology here which I don't
think in has gotten kind of forgotten
and doesn't get a lot of credit but it
was it was kind of a little before its
time so we can you actually get this at
like Target or Walmart or Amazon at the
time for less than $20 and it was a
little plastic device from Hasbro called
my 3d that you could slide your your
iPhone or iPod in and you could get a 3d
experience but it really was from a
product perspective not successful
because it was a capability with no
content so what we got really sort of
interested in this and in the
possibility is that now the smartphone
screens are finally going
big enough in high resolution of where
you could actually start doing
interesting VR experiences with them so
we did this is a kind of a prototype
system that we published it I Triple E
VR in 2011 which combined this with a
Bluetooth keyboard for interaction and a
few other moving parts and so but so
this kind of got us thinking about this
but then the real kind of insight or was
really when we started doing this with
higher-end optics so this is some leap
optics that we pulled off of an old boom
display back from the 90s but and then
we basically just cut out wood and slap
two iPhones in front of it and there
were all these problems with it there's
distortion the eyes are not synchronized
properly but the the real experience is
we took this live demo to the conference
so we start handing it to VR experts and
they were looking into it for the first
time and seeing high-end optics in front
of these smartphone screens and being
like wow I didn't think I the reaction
we got from most people was I didn't
think it was going to look this good so
we left from that and we really started
thinking about okay there's something
here we really have to continue trying
to to make this accessible so the next
year we came out with what we called fov
to go if you've been to the I Triple E
VR you might have seen us hand these out
we brought about 200 of them they're
calm core laser-cut ones with lenses
that are basically a dollar and then you
just basically fold up your own
cardboard display we and we have them
for all different types of phone models
so this at the time this was really
really kind of an exciting thing today I
show this but it's more of a historical
kind of note because now of course
Google cardboard has really gone and
popularized this notion of smartphone VR
over the last couple years and that you
know has really just been an explosion
in terms of that that ecosystem that I
think is really really a special
spectacular in parallel to the
smartphone VR effort we were doing some
really prototyping on the hmd side and
we wanted to really start building not
just viewers but head mounts and so we
found this hobbyist we hired him his
name's Palmer Luckey and he
a hobbyist teenager working in Los
Angeles who had a credible
a baby ARCA hmd collection that was
playing around with and his parents
garage so he brought him in the lab and
we you started we started to build
construct prototypes here which we
referred to as Franken HMDs which were
basically cobbled together from ebay
parts from different displays and LCD
panels you could buy online and real
iterally held together with tape but
they really started we started to see we
can start to build this for about you
know three hundred dollars and so we
decided to open source all of this so
all of these designs the socket hmd is
kind of an interesting historical note I
think the consumer market is now you
know has gone be leaps and bound beyond
this but it was a our 3d printed design
for this display which was very similar
to the oculus rift dk1 and all we
started to move beyond the cardboard to
3d printed phone viewers as well as
tablet viewers which are really
interesting because now you can combine
an immersive display with a touch
surface and do a hybrid interaction
where you can actually use some
manipulation of objects on the screen
while you're looking at it so all of
these are available on our website and
anyone with a 3d printer can download
and create them but there's only a
limited amount of people I love open
source and I believe in it but there's a
little eat uh ch's so many people and
what really really was the catalyst to
for this explosion was when Palmer
sent one of those prototypes to John
Carmack and then left the lab to do a
Kickstarter and the rest is history you
know with the oculus was eventually
founded and bought for Facebook for two
billion dollars and now Palmer is is
being one of these lead spokesman's for
the for the field of VR and one can make
the argument that though this is a this
was really one of the catalysts really
the the real reason was that the display
technology had gotten low-cost enough
and other of course companies were
looking at this at the same time as well
so it really was something that though
this was a particular catalyst this is
something that I think was just
inevitable inevitably inevitable
based on the cost of Technology going
display technology going down and
becoming the quality going up and you
can really see this I think when you
look at that chart again and you put you
put the rift socket under consumer-level
HMDs on the dollar per degree mark we're
looking at that 90 degree vertical was
kind of the initial version of the rift
and what we see there is that that's
getting pretty good enough and the
dollars per degree is so much lower than
everything else that really now we could
go back to our the people at the army
and say you can now afford these and so
now we can start to really see people
care about VR cuz and of course now
there's so many companies HTC Sony and
all of the other other ones I don't put
Microsoft on this list because hololens
is a mixed reality device which of
course is similar but it's in its own
class and this talk is really more about
VR so can we say mission accomplished is
VR a solved field at this point and so
I'm giving this talk so hopefully you
won't be surprising that my answer is no
and the reason is I think a lot of the
content creators and a lot of the
experiences that we're seeing coming out
at least right now in the last several
years have been have interactions that
look like this
seeded use or movement in a very very
small area and a lot of the interactions
are mediated by controllers game pads or
other sort of handheld devices to move
through a virtual world this to me I've
done this you know now that I've been
doing this for well over a decade when I
have these kind of experiences that are
mediated by controllers and it just
feels like a video game to me this does
not feel magic anymore and I worry that
in the long term that once the novelty
effect wears off that people have been
immersed enough and seen enough VR
experiences it's not going to seem
magical anymore it's just going to seem
like another type of gaming so I'll talk
about nausea and you know in a little
bit but yes that's also another problem
with with these kind of just locomotion
metaphors is that motion sickness
because your motions don't map with what
your your body is doing
that is a problem for some people at
least some people so so why is walking a
problem well it should be pretty obvious
that even if you have a tracking space
that can allow some physical body
movement if you want to walk through a
large virtual environment say a virtual
city or a large office space or what
have you
at some point you're gonna run out of
physical space you're gonna walk and
you're gonna in the best case we're
going on outside of your tracking area
in the worst case you're going to
physically collide or walk into a wall
and because you're wearing a headset you
won't be able to see it so this is kind
of one of the real fundamental
challenges for any sort of VR system in
you know is this real problem of
physical locomotion through the
environment so we researchers have been
studying this for a while so this this
has been something that people have been
thinking about for quite some time and
so there is one interesting mist
solution that came out of the literature
about 15 years ago so this is not my
work this is the original redirected
walking work which comes out of UNC
Chapel Hill and and so which really I
think has been an inspiration for a lot
a whole class of research in the field
and the basic idea here is that you just
decouple physical and virtual motions
they're related to one another but if
you for example get some of the work Pat
walk through a zigzag corridor you can
actually get them to walk back and forth
in the real world and if you just roll
realize that there is a that you don't
have to have a one-to-one mapping
between physical motions and virtual
emotions there's a lot you can do with
that so let me give you some examples of
how this works
so there the easiest way to do this or
the original way that Sherif suggested
was through what's called manipulation
of gains so a gain is just a
multiplication factor applied to your
motion so in the case of rotation I
might walk through a virtual space and
then I in this example rotated I'll show
you that again rotate 90 degrees in the
virtual space about 180 degrees in the
physical space so that you can after
your turn you are now walking along a
different vector you can do this in
other ways another one that's been
identified as
curvature gained and in here it's
different because you're walking
straight and there's a continuous kind
of rotation applied as you walk forward
and you will bend and walk along a
curved path and then finally there's
translation gain which is just a
basically a multiplication on your step
size but only in the forward direction
because you don't want to amplified
side-to-side movement so you can travel
greater distances virtually than you are
physically so why is this better than
locomote using controllers and the
reason is it's because it's linked and
controlled to buy your own motion and so
there's two different perceptual systems
in place here one is this is your vision
and one is your vestibular sensation
your sense of balance your body sense of
what your your movement and turns out
that vision tends to dominate when those
two senses are in conflict as long as
they're kept to us within a certain
threshold so there's been researchers
who have studied this and so there's
these are just some of the kind of
numbers out of the literature and it
turns out if you do it within these
parameters and do it the right way then
not only it isn't imperceptible to the
user but it also hopefully won't make
them sick as long as you just don't do
this too much now I can tell having been
in these environments where you do it
too much it can make people sick so that
is a concern but the key here is that
vision dominates over your sense of
balance so one of the things I wanted to
do was really kind of understand not
just kind of do I notice these illusions
but how does this impact my sense of
spatial orientation cognitively in how
does this impact my my experience of
this virtual world so this is an
experiment that we did where we were
pointing at targets so what happens in
the beginning was you see a virtual
target and you aim and we're using a
track wand to aim and then we were and
then you point at a real target so you
they Bend up the optics of the display
look at a real target in the real world
point at it and then the rest to
remember where these are so point at the
real target pointed a virtual target
then you're back in HMD we go through
some sort of virtual experience where we
apply these redirected walking
techniques so for the sake of simplicity
I'll just show you it would happen
continuously but at the end of that
walkthrough you're 90 degrees offset
from where you were when you started in
terms of your physical orientation so if
my visual original virtual target was
there we wanted to know would you point
at that virtual target where you
originally saw it or would you point at
it in its position as if it were
redirected basically where is your
memory of that virtual your orientation
of that target now 90-degree offset and
more interestingly what would happen to
your perception of the real target would
you point it where was you originally
saw it or would your reference frame in
the real world move as well another way
of thinking about this is are you
maintaining to two models of your
spatial orientation do you have your
real or virtual or if I read it the
virtual do I manipulate also my real and
so the way we look at this we have to
figure out how to how do we measure this
quantitatively so the way we looked at
is looking at angular pointing errors so
this is a way of doing this is a pretty
common metric and VR and so what we
looked at those positions where we
calculated the angular pointing error
and so what we found is actually exactly
what we would expect if they were
correcting for that the redirection and
they were moving those targets reference
frames so for both virtual and real
targets so and the way we do that is
just be we can see that the angular
error so this is the lower this is the
more accurate those angular error are
pretty consistent with what you get with
just regular pointing so those numbers
35 to 40 ish are pretty typical of just
the angular areas you get when you're
asked to point to something where as you
can clearly there were 92 about 90
degrees offset from what their original
positions were so this was a really cool
result for us because this confirmed
kind of an or resolved an argument that
I had been having with Mark bolus my
colleague and co-director of the lab
where he maintained adamantly that there
were dual models and I said no if I mess
with you in the real world I think I'm
going to be able to get you to your
reference frame in the virtual world
real world kind of shift as well and
this kind of resolved that and he
stopped
planning at me so now I want to start
talking about another class of illusions
so this type of work with redirected
walking really kind of was just the
initial insight that what happens in the
virtual world can really transcend what
happens in the real world and we're not
bound by the same laws of physics so now
let's talk about another type of
illusion that I kind of just came up
with and I really got this inspiration
from the kind of common psychology kind
of stuff you scenes you know psych 101
and here's an example so I'm gonna ask
you to look at this picture and then I'm
gonna change something I'm gonna ask you
to to just call it out if you see what's
changed anyone notice it just call it
out if you saw what I changed here I'll
make it really easy and so the reason
that's difficult is because the human
visual system uses motion to be able to
detect changes and just that
split-second inter stimulus image that
black screen disrupts that perception of
motion and then it becomes very very
hard and this has been well studied for
many many years in psychology it's
called change blindness and it's very
very consistent across people in a very
powerful illusion so I started to think
what happens if we apply this to VR and
so here's an example of how this works
so in this in this example you're gonna
see walking through this virtual room
and watch what happens on the overhead
view on the top right left as they
approach this desk so they were looking
forward at the desk and in this study
environment they were just kind of
looking at pictures but what happened
behind them was that this doorway moved
90 degrees it's were stayed in that same
location but the orientation of the
doorways swapped along the corner you're
about to see it again as they walk to
this corner of the desk oh whoops okay
so the key here is that this
manipulation occurs behind their back
so everything appears consistent to them
in front of them but when they turn
around the door as US offset by 90
degrees and the corresponding hallway is
also offset by 90 degrees this basically
means that within a about a 15 by 15
foot space I was able to infinitely
repeat this and do a 3,600 square feet
office building within less than 200
square feet and this is basically
because this is a consistent illusion as
long as they're going linearly and
entering into these rooms and kind of
not looking back like walking at the
door I'm like staring at it while
walking backwards because people never
really do but they'll never see it
because of the manipulations occur
behind their back so this was a really
interesting illusion I wanted to test it
so I ran several experiments and I was
really trying to get some statistically
significant results of you know how how
many people notice this and what I
really found was that I completely
failed in getting statistically
significant results because no one
noticed so I did this to them throughout
this environment 12 times each multiple
experiments and one out of 77 people
noticed a report of that illusion even
after it was disclosed to them
afterwards they see we tried to tease it
out gradually with questions and it just
it was so effective that we were we were
not expecting it so this was really
really interesting so we started to look
at kind of how this affects your
perception of space okay you might not
notice it but what do you feel that this
environment looks like so you there
going through this environment which
cannot be represented with a single
drawing because it's a dynamically
changing world but we asked them to
sketch map it and these are kind of very
consistently across the study the types
of maps that people drew which look very
similar to kind of the conceptually this
kind of office space with the you know
kind of in the square environment so
what this and we analyzed these through
some subjective ratings and statistics
which I won't get into here but where we
really found overall is that these
spatial inconsistencies just seem to get
resolved
you know perceptually or cognitively
when you're going through this
environment as long as your experience
my takeaway was as long as your
is locally consistent then kind of
globally we we figure you know we figure
out a way to make this work when you're
forced to draw a map you figure out a
way to make it fit on paper yes yes so
these were drawn after the experience
ends immediately afterwards yes so it's
this is sort of interesting to me
because as long as they do the path
where they go in every office this will
work but if it's sort of an open world
where they can explore however they want
it won't work right so that's correct
so it seems like in order to decide what
you need to do you almost need to be a
little predictive about where they're
gonna go so you can kind of start minute
but in the world ahead of time and
manipulate them later or something
yes yeah you are 100% correct and that
is the latter part of my talk which I
will I will directly address that
question yes through the space before
they try out they were like the headset
before they go inside the space in these
studies they or we did not blindfold
them before they enter the physical
space so they did see the physical space
beforehand some yes did you did you do a
kind of London to law studies studying
on this in terms of like people adapt to
technology and their skillsets changed
their way that perceived things changed
any information on that with whether
people over time would actually mature
and understand it differently um nothing
beyond anecdotal so I'm not really aware
of longitudinal studies in VR cuz cuz
it's so it's very it's difficult you
know or impractical I would say so no I
haven't done it I'm not aware of it but
anecdotally I can say that these
illusions tend to work for us around lab
who get to participate in these all the
time and see this they they just seem to
to work like even though I know that
that this illusion is happening that it
doesn't seem to have a negative impact
on the experience it's it's one of those
things that I think I can just accept
because the experience is seems locally
consistent
do any of the subjects report any kind
of unease and knowing I shouldn't be
able to walk down this hall this far
because I already saw there's a wall in
front of me or do they kind of start
walking slower is again not that
specific no not not that we could tease
out in any of the data although they did
report report a general sense of feeling
turned around and I think that that goes
to your question which was about did
they see the space beforehand they knew
I mean if you see the space beforehand
you know how big the tracking space is
you know you can't walk through an
infinitely large space so I think there
is this general sense that like yeah I
got turned around but when we tried to
tease out of them how did that work how
did that work there the overwhelmingly
seems to be like I have no idea how you
did it I just know that I've been turned
around so yes observation on that it was
the earlier study somebody else is the
zigzag Hall yep I noticed in the first
is I you see a lot of movement there
were that first time they get adjusted
there you can see their frame was
figuring and trying to figure something
out
and then after that it was pretty clear
the frame is kind of yeah yeah and this
is a this is a phenomenon called
perceptual calibration we know that it
takes a couple minutes and and this has
been studied in perceptual psychology
that people will accept very you can
actually recalibrate to all sorts of
different things like different walk
speeds different motions even remapping
of kind of the movements of your head
along different axes it takes usually a
couple minutes and then afterwards a
couple minutes to calibrate back but
it's a very rapid process only you know
so okay any more questions about change
behind this before I move on okay so
like I said this illusion was was
unexpectedly powerful so I started
really thinking about other types of
spatial manipulation that we could
leverage in VR and so for this one I
drew my first inspiration from
psychology this one I'm drawing on of
Minard credibility here from science
fiction and so who here is familiar with
the BBC television show Doctor Who I
love giving talks to technical audiences
because they actually get this reference
so for those who aren't familiar with it
in this kind of timeline
or mythology the doctor travels around
in this thing called the TARDIS which is
the basically the size of a phone booth
here and but the inside of it is much
much larger than could ever exist in the
real world in fact canonically it's
supposed to be infinitely large so this
was the kind of basic illusion that I
wanted to investigate in VR I wanted to
understand I wanted to experience this
magical sense that all the people in the
show got whenever he leads new
companions into the TARDIS and they go
with a sense of awe it's bigger than on
the inside and it becomes this joke but
I wanted to experience that sense of
magic of walking into something that's
bigger on the inside
fortunately in VR we can create this so
here's the kind of experimental
environment that I built to test this so
I used a kind of very similar
environment to what you saw before where
you walk two desks and you're looking we
give them a task of going over to look
at monitors to see pictures because it's
just a way of making people move through
the environment so you go through one
desk you turn on a picture you walk down
exit the room you walk to the hallway
and then by the time you get to the
entrance of the second room in the
hallway the first room is essentially
deleted and the new room is put in its
place and the of course if we look at
these kind of superimposed on one
another this could never this is a
severe violation of Euclidean geometry
and can never exist in the real world so
I wanted to now see what is how
sensitive are we to these types of
illusions so the way that we figured out
to do this is to do what's called a
psycho physical experiment so what we
did was we just asked them to we did
these on whole different levels of
overlap ranging from 0% which means
perfectly can't exist in the real world
to over 75 percent which basically moves
means like most of the rooms are
completely overlapping and they're
almost completely on top of each other
and we just have them give them this
kind of discrimination test they
experience a whole bunch of trials and
we ask them is this impossible or
possible and we do this over many many
many repeated iterations and then from
that we can calculate the probabilities
and generate what's called a
psychometric function so I won't go too
much into all the detail of this but the
the point here is that this is the
probability of being able to detect that
it's an impossible space and this is the
overlap level so this is increasing
amounts of violations of geometry and
what we found in our data is that about
56% by convention is is when they start
to become reliable so you can get us
quite a bit amount of space savings by
overlapping geometry and people won't
really be able to detect it if it's less
than or 56% and the interesting thing is
this is when people are explicitly told
about the illusion and instructed to try
really hard to figure it out so I think
this is actually a conservative and if
you did this on someone who's completely
naive to the illusion it would probably
you could get away with a lot more
one-to-one
yeah the corridors walked one-to-one yes
what happens if you sort of make of
virtually faster with that make space I
haven't tried it it's a very interesting
idea though so yeah you might be able to
because to some degree people are using
their bodies as a ruler and judging
those steps as a way of judging distance
some of the people I noticed some
strategies in this study that some of
the people who are really really good at
the task were actually counting stuffs I
do take some demographic data I haven't
looked at that I will say so most of our
subjects are actually not university
students which is a lot different from a
lot of way academic VR labs do it we
recruit off of the general population on
Craigslist so I had a pretty broad kind
of selection of people but not not the
sample sizes we're looking at her and
too small to be able to draw any
conclusions about the population the
only thing really I can tease out is
video game experience but even then it
wasn't predictable performance in this
time I might need to modify my
demographic
so beyond just do they notice that
though I really again wanted to go
beyond just that and understand kind of
how does this impact your experience you
know because self reports have I noticed
this are only so useful so for this I
came up with a metric which I kind of
drawn from the VR literature called
blind walking and so this is a distance
estimation test to get at your point so
in this sense what they did was they
walked after they walked to that second
room they were asked to look turn back
to the through the wall to where they
saw the first target so the both both of
those desks were as pictured there kind
of against the same wall so they were
asked to turn and to where that first
one was and close their eyes and imagine
how far away they were when they when
they were standing in front of that
target the hmd at this point goes
completely black and then you're asked
now to walk until you are physically
standing on the bat point that you were
so that's why it's called blind walking
this is a very common metric used for
distance estimation studies in VR the
difference and the caveat here was that
in the cases of overlap then the the
actual place that that was would have
been on either forward of the wall and
are in some cases in the extreme overlap
conditions literally only a step or two
away like they were almost on the exact
same space so the question here was
would they walk to where it actually was
that they were physically standing or
were they correct for the compression
and continue walking as if those two
overlapping rooms had actually been
moved out and we're actually now
correctly side-by-side so this is what
we found in the data and so what we're
seeing here is overlap level again
around here and this is in percentage of
the actual the walk distance relative to
what it actually should have been if it
were accurate to the real world
so if they weren't correcting from the
compression and they were walking to
where they actually were we would expect
to see the day
follow that 100% horizontal dotted line
the red dotted line is what we would
expect to see if they were correcting
for that compression and over walking
and this I'd love to show this data
because this is one of the most
clear-cut examples of an effect that
I've ever seen you really don't need a
lot of Statistics to be able to look at
that and see exactly what they were
doing so even the cases of 75% overlap
where it's really obvious very few
people 90 percent of people were able to
reliably detect that this was an
impossible space even in those cases
they were still walking those
exaggeratedly long distances when kind
of in behavior correcting for this
illusion so I think that was a really
really interesting finding and it kind
of goes to this idea that I like to say
that like we've learned that spatial
perception is malleable and that people
even even if they kind of can perceive
that these things are goons are going on
they'll still try and behave normally as
long as it doesn't mess with their
experience no no or at worst make them
sick as long as you can make the
experience still very rich and pleasant
then these illusions
even when obvious could still be useful
but now I'm gonna start to get more of
the Rays more of the practical question
stepping out of the basic research hat
and now start talking out as a VR
engineer how is this actually useful in
a real practical system and so now if
you want to dig me on anything you mean
you can dig me on saying hey you know
these these are really only work in
these linear environments where you have
this kind of purpose-built experience
that's kind of validates the technique
but if you want to give free-flowing
exploration of just an arbitrary
environment how would you do that
these aren't generalizable and I think
they're not like there is no
generalizable solution for a redirection
that applies to all spaces at all times
at least we haven't discovered it yet
what they are is tools they're tools for
VR delivered developers and VR designers
and content creators to use for the
variants that they're they're doing and
they're best employed when you can
actually couple the content creation
with the kind of experience and
techniques you want to use so some of
the interesting thing ways we can use
these tools so this is an example of how
we use it in a mixed reality setting the
change blindness technique is really
interesting because it's a discrete
change it's unlike the motion illusions
this is not a continuous change these
it's a single state switch and so
because of that is predictable so
instead of doing a 90 degree offset this
is one where I did a two stage building
where there's interior rooms and what
you're gonna see here is when you get to
this back room I'm gonna pull the same
door switch here and then this door
switch is going to move over here so
there's actually two doors moving here
all behind your back
and what this essentially lets me do is
change is reuse this road infinitely so
we trucked about a thousand pounds of
gravel into the lab which I would not
recommend for cleanliness because we
were cleaning like dust for the next
three years
but you and when you enter in a building
here and then when you exit the building
you guys ended up exiting here and then
every time you step right back onto that
gravel road you feel the crunch under
your feet you feel that haptic sensation
and so it was a really very very
compelling illusion or so again that's
that sense of magic for me because now
there's there's a sense of realism the
real world is actually kind of playing
along with this illusion here's an
example of another kind of way in which
these impossible space techniques could
be used in a practical setting so this
is a technique I call flexible spaces
and in this sense what we're doing is
we're playing with similar violations of
non Euclidean geometry but we are doing
it in by creating twisty hallways that
kind of curve back in unto themselves
and so what we're doing here is this is
an environment where each room is pre
modeled and this is this is researcher
art so that's why it looks so so bad but
each one of those hallways is
procedurally generated on the fly in
unity based on the those other polygons
are just generated as needed based on
where you're standing in the space and
where you need to
and so the really cool thing is that you
can just basically do this infinitely
and then so I need a hallway that gets
me to be standing over here I can just
generate a twisty hallway and you do get
a kind of a sense of like again that
general sense of like something being is
fishy's going on here but because we're
not employing any of these motion
illusions there's there's no real risk
of inducing additional simulator
sickness so I think this is a really
cool technique that could be used for
entertainment and for for experiences in
general that where the individual layout
of the environment doesn't so much
matter so educational experiences museum
exhibits things where you're trying to
experience content but the exact spatial
layout is irrelevant to the experience
and trying to move this now and to
really into practice I mentioned that
ICT has a lot of DoD funding so what we
want to do is really again do the same
thing we did with HMDs and make it
possible for people our funders and also
just the general public to make use of
these techniques in this toolbox so this
is a example of a redirected walking
toolkit which we built from Unity we
actually have completed it and we're
actually just getting the website up
will be released by the I Triple E VR
conference in March open source for
unity and so what we're really doing
here is trying to build all of these
kind of at least more generalizable
techniques into sort of a toolkit that's
plug and play so I can just hand it to a
developer and they don't need to know
about all the math and the perception
they just need to tell it how big is my
tracking space here's where I want to go
in the environment this was an example
where we're actually planning waypoints
so we're telling it this is where we
want you to be able to go so the
environment can plan it and then it will
figure out the math and and make that
work and one of the real reasons we're
doing this now is because we're finally
seeing a consumer level wide area
tracking system with the HTC vive coming
out which can get tracking and around
five by five meters or so 4 by 4 meters
something like that
and so it's it's really now you can
start to see ok if we have where we're
not getting up
like the huge spaces but we're starting
to see consumer level tracking that can
actually allow some movement and I'm
gonna give you an example of how we use
redirected walking using the toolkit
within a valley of I've setup so this is
an example of an environment that we did
for the SIGGRAPH a RV or contest last
year which actually won first place of
the contest and this is in collaboration
with our our partners at the School of
Cinematic Arts so what they did what you
saw there was a turntable where we're
using we're working with stop-motion
animators and so there's a rig that
spins that around and there's an image
taken every second for every degree and
it and so then you're able to do kind of
capture the image at every angle and
what we're doing now is doing image
based light field rendering within an
hmd so we created this experience for
for the conference but then they said oh
you've been invited as a finalist you
have to bring it to the conference
here's our demo space and we're like the
environment doesn't our environment does
not fit within your demo space and our
environment like the key to this stuff
is really being able to move around it
because you gets all these specular
reflections and subsurface scattering
and all of these really fine visual
image elements or that don't come
through in geometric rendering but you
really get from these image brace light
field approaches so that that movement
that physical body movement around it is
really really important so what we did
was we we basically went through we used
the redirected walking toolkit and this
is that same zigzag idea that the
redirected walking paper from Chapel
Hill did but this is actually the the
the physical kind of disk space
dimensions you would get with a vibe so
now as long as we give them verbal
instructions so there's a narration that
says turn to this exhibit where and
explains linearly cuz there's a
progression through this exhibit as long
as we're able to direct them to go where
we want to go in this environment you
can see we put a couch here as a kind of
visual indicator of the scale that this
could actually work in a living room
suicide space and then so interestingly
enough I do have this demo on my laptop
I know that there are some people with
vive setups in this building so if
anyone who has a vibe set up wants to
experience this I have some time this
after
I'm more than happy to come by and you
can actually see what it feels like and
so that's an example where we know the
path in advance another way of being
able to deal with this path prediction
problem is in letting the user plan a
plan so this was arc one of our kind of
early cheats was that okay we can't
really let you walk anywhere but we're
not going to tell you where to go in
this kind of free-flowing environment so
we gave them we give them an app and
they basic said plan your route and then
we'll figure out how to do algorithm
we'll then figure out how to get you
where you want to go so this is a little
bit more free but not totally free yet
now we're working on the kind of totally
free case so this is forthcoming work
that we that's just been accepted to I
Triple E 3 D 3 UI will be published
later this year and what we're doing
here is we're building short term
prediction graphs based on the geometry
of the environment on where you're and
your movements and what we're doing here
is we're basically the lab leveraging a
tool that's already available in all
these game engines for doing game AI and
it's navigation message so navigation
messages are basically how game AI does
its path planning and so we're basically
taking all of that that technique that's
built into all of this and we're using
that to essentially build up these
prediction graphs about where the user
is theoretically going to want to travel
in VR and so this was just the initial
technique and now our next step is we're
building this into the predictive
algorithms that we have implemented and
then we can measure the the kind of
expected performance or advantages of
doing that so we're actually so I can't
speak to that because we haven't we're
just we're dealing with the static case
first we're not even dealing with
dynamic yet I do know that while our
preferred way to use nav messages are
not the unity built in but using a
package on the asset store that extends
it so I'm not sure about the dynamic
case so so and then another technique
that we have in the toolbox here is a
reorientation technique so what happens
if these techniques fail
so so let me let me start this over
again so what happens is basically if we
know at the very sly second that we
tried to predict as best we could but at
some point you're about to hit a wall we
have to do some sort of failsafe or some
sort of way of intervening and maybe
this is one potential trick that may or
may not work in a particular experience
but we asked them to take a panoramic
photo so this is an example where we
basically just ask take a town around a
photo that's something that most people
with smartphones now are familiar with
and but this basically does is it gives
us an excuse to give them a spinning
motion but that spinning motion occurs
on the spot so we can basically do an
emergency reorientation away from a wall
so again it's disruptive to the
experience we don't want to do this too
much but as an emergency when everything
else fails it's better than having the
take off the HMV or crash into something
so you can see now how these kind of
techniques work we try to apply this
continuously predictably as best we can
but as they're going through the
environment if eventually they end up
hitting a wall yet that's when those you
see that kind of space spin around them
that's when we do some sort of
reorientation tkip technique as a
fail-safe
so you can actually get through a city
sized space right now with a little bit
of interruption um
the reorientation techniques though do
provide a great metric for effectiveness
of simulate for evaluating these
algorithms so what we did now to kind of
move this forward as we're developing
these algorithms more as we develop the
simulation framework where we can tweak
algorithm parameters and then generate
procedural paths through environments of
different types and distances and
systematically measure using that those
reorientation techniques those periods
of failure as a as a metric of minimum
minimization metric to try and get these
algorithms better I'll give you one
quick example because I'm almost out of
time and so here's an example of popular
ways of doing steering in for any sort
of like continuous system so people in
VR they thought okay the previous
Convention was steer to center is best
we just you know we just kind of naively
try to get you to be in the center of
your physical space other people have
said well maybe it's best not to go to
the center the
should get you to just kind of orbit
around the center so the steerer Center
versus tier two orbit was an argument
the steer to center people went out and
so it was kind of conventional wisdom
says Sears Center is always better but
when we started being able to do this
simulation and go up to larger and
larger tracking sizes what we actually
found was that the conventional wisdom
was not true after a certain point that
as the tracking size increase and I'll
just highlight this here there's an
inflection point so this is the relative
effectiveness this is a derived metric
based on the probability of getting aid
those reorientation triggers those those
failsafe take maybe techniques there's a
period of time where the steer to center
algorithm outperforms it but at some
point there's a crossover and there's a
substantial increase in steer to orbit
with sufficient space is actually much
better and in fact hits the theoretical
maximum of never having to do a
reorientation sooner with a smaller
tracking area than steer to center so
this was a kind of an interesting paper
we published at iCal last year that was
just one example of how we can use
evaluation to better design these
techniques and in the future but we're
really trying to do I think the Holy
Grail for the redirected walking is not
just one user but multiple users because
now you don't have to just deal with the
physical boundaries you have dynamic
targets you want to have people not bump
into each other but if someone wants to
handshake or hand an object to one
another you might want to converge
spaces so there's a convergence and
divergence of individual spaces which is
a problem we've just big barely begin to
explore and the question is I know five
by five meters is pretty good for
redirector walking in some cases but
it's not going to work for multiple
people so how big do a space do we need
you know that's the kind of the answer
we have to look at in these simulations
of how big how scalable does these are
these techniques and I think this is
going to be increasingly interesting
once we can go beyond what a vive system
can do in the consumer level and was one
of the reasons I'm really there are many
interesting things about hololens but
the tracking on it the fact that it's
all inside looking out and tracking on
the device is something that I would
love to see built in to a VR a pure VR
headset rather you know rawlins being a
mixed reality device is somewhat
different and these techniques don't
really translate well to the
kind of realm because you can see the
real world um but then you can start to
see if I if the device can just track me
I don't need infrastructure can I just
go out to a parking lot football field I
can just make ad hoc use of big empty
spaces and then you could start to think
about okay I could theoretically see a
multi-user system like this working but
you know the tracking technology just
needs to catch up with our you know our
dreams and our goals so with that I'm
just going to wrap up the like I said VR
for me the real power and the reason I
chose this field is because of this
creation you can clearly create magical
experiences you can transcend the laws
of physics and you can do things that
you can't even dream about doing in the
real world and that is something that I
think is just going to we've barely just
you know it's just the tip of the
iceberg in terms of what VR can do and
the other thing is is that the role of
researchers I think it's really
interesting that the this is up from a
blog post earlier this year where
someone a random VR hobbies' was was
thinking about the via vive and he saw
the vive and he's like what can I start
to do in a vibe I want to go through a
larger space and she actually started
sketching out things about walking on
circular arcs walking in 90 degrees he
hadn't come up with the idea of marrying
it to rotations or employing illusions
but he's the the the hobbyists and the
kind of general public doesn't perform
literature reviews and through brute
force they're rediscovering with a
little bit more thinking on this and
work on this they'll come up with
redirected walking so as researchers
that's kind of the goal is to kind of
create toolkits now and and kind of
inform the general public so that they
don't root for sit and invent the wrong
thing alright with that I'd like to
thank Chad knowledge that this is the
work of a lot of my you know students
PhD students interns undergrads
engineers and so work of a lot of
different people with that I'll take any
other questions
yes are we doomed to walk you out or at
least 25% faster than I think I think we
don't know if I'd call it doomed because
one of the things that I do think about
in VR is energy expenditure and fatigue
I think that it would be great if I want
to go through a large space and I don't
have to walk a mile and I only have to
walk three-quarters of a mile unless I'm
trying to get exercise at which point
you might want to slow it down and then
you know get a higher distance but it's
not always a bad thing yes yes although
like I said certain amounts of
inconsistency is tolerable and in fact
not just tolerable but imperceptible and
that's not something attention thing
that's actually a percent when it's a
perceptual effect it's so so low level
that it's actually more it's more of a
brain thing then it's not a level of
your attention like if it's
imperceptible you can't it's really hard
you can't even do it even if you try but
of course the individual variation
exists yes
that adds a very strong constraint to
your system so that really won't work
with free walking right because once he
exited the first building and came out
to the path if you had gone back he was
stepped immediately like outside of the
bounds right right so but that but you
can use different cues like audio cues
right simulate that he's walking on a
different type of surface even if he
doesn't physically feel it have you done
anything with that yeah we've done audio
we've played around with audio sounds
like the crunching sound the other thing
I played around with was actually trying
to build shoes which had a layer on the
bottom that that actually gives you like
different sensations on it or could even
we tried to cut it at the angle to kind
of twist your foot a little bit in a
direction and bias you towards walking a
little to the right or left turn
thought that works when you close your
eyes but when you're walking your vision
domination you just try to correct for
it anyway so it didn't it didn't work
how it's great so we tried to look at a
bunch of different different ways of
being able to do that but to your point
yeah the you know do all of these
techniques have different limitations in
terms of generalizability and when they
would be useful and not and different
ways of being able to violate those
assumptions but the point is is that
each of those techniques have different
assumptions so you pick the ones that
are best and ho and in combination you
could potentially get away with quite a
lot so it's true for all the variables
UX I mean a research driven research
drawn space it's a level of fidelity had
been a lot higher it would have in the
whole equation of comfort
it would have mitigated against other
other things that were created created
just yes yes and in fact I think so I
think some of this is actually
empirically she needs to be measured
when we get to these systems that can
render it greater than 90 Hertz and have
really low latency tracking because some
of the things that were intolerable or
just not really you know or things that
were good before techniques that were
acceptable because they might have been
masked by by latency and jitter might
not and we need to re-evaluate them
under these new new circumstances where
was the Thor but I noticed in one of the
pictures that you had a G hat on wearing
the headset we thought about any more
kind of biological sensing or electrical
something of that what people might not
report being noticeable but actually is
those brain yep um I I haven't
personally there are people at ICT who
who have done that I think they tend to
be more in the medical VR sector and so
I think that there's a there's all these
the
I think a lot of difficulties with doing
this with large scale walking because
there's all the physical movement I
haven't personally done anything with
with brain scans but I I have over time
I've become less enamored of using
verbal reports and subjective measures
which is why I started to use things
like those distance estimation studies
and started to look at designing
experimental tasks where if I can't go
for a psycho psycho physical biological
signal I can now forget some sort of
objective behavioral signal and I can
measure use your behavior instead of
relying on just a self-report which has
all those problems there's sort of an
empty area any like having objects that
the user would need to avoid physical
objects and redirecting them around the
subject specific living rooms or house
this could be a lot larger if you can
force them to kind of go through from
room to room as they walk around yeah
the I think we haven't really as a field
yet tackled that we've just started with
our evaluation framework to start
testing non-square spaces because we
started to realize wait these can be
there's no reason why these have to be
squares in fact ours is rectangular so
we're starting to look at different
shape and how shape affects the size
because shape is actually interesting
because you can get long walks in one
direction but very short walks in the
other the to look at obstacles like that
no we haven't really done that with the
exception of love Coley's work also from
UNC Chapel Hill so about five or six
years ago he had a paper where he tried
to combine passive haptics
with redirected walking and what he did
was he was using the rotation techniques
so he picked cylinders because their
rotation invariant so he could put like
a cylinder and he what we do is redirect
someone and then they would always you
could be the space could be circularly
or rearranged around it but he could
always reach out and touch the circle or
the cylinder in the space but navigating
around obstacles I think yeah that's a
that's not a area for work it is an area
for future work I couldn't remember
as in the first part of the talk as
people are walking what they think is
straight you do sometimes curve as
they're walking straight or is it mostly
that you do the variation as they turn
themselves like yeah there are two
distinct techniques rotation games are
done during your rotation right
curvature gains are done when you're
walking straight so you're walking
straight and there's just a slight
continuous rotation that gets you to
bend your path and both have their own
thresholds we actually but they've
always been measured separately we
actually are now doing a study where
we're doing them simultaneously because
we think that there's a combined effect
that hasn't been empirically measured
yet but they are two distinct ones is
there anything interesting to say about
vehicles so if you have a home be
sitting in there in your lab and you can
opt into it started it up and drove
someplace and they got out I mean that's
I guess it's kind of not that
interesting to you I thought about it
was thinking about that as one of your
examples having a city around oh yeah
yeah no that was just uh yeah that was a
simulator I haven't used done anything
research wise with it because I think
once you guys did the the vehicle
simulator once you enter an exit you can
be in completely different places
virtually just yeah I think I think
we've been asked actually so by the
perceptual manipulations that we've been
asked to consider are more about when it
stalks the vehicle simulations are more
about haptic control surfaces so they
want the Army for example wants
reconfigurable easily reconfigurable
simulators for prototyping so they want
to be able to do VR environments that
can you know have these kind of
dynamically repurpose Abal haptic
surfaces so that that's kind of where
the the I see more perceptual
manipulation potentially being employed</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>