<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>HRTF Personalization using Anthropometric Features | Coder Coacher - Coaching Coders</title><meta content="HRTF Personalization using Anthropometric Features - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>HRTF Personalization using Anthropometric Features</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cMDVJWExcxY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so good afternoon everyone
those who are in the room and those who
are watching this talk remotely today we
have belinskiy he's a PhD candidate in
India in France in this spatial temporal
activity recognition systems research
group but today he's going to talk about
his work during the last three months
here as intern in Microsoft Research
without further ado gather you have the
floor
thank you even for the introduction good
afternoon and thank you all of you for
coming for this presentation for those
who are here and for those who are
watching this presentation online today
I will talk about my intern internship
project head related transfer functions
and their personalization using
anthropometric features this work is
done together with my supervisor event a
chef and errands and Mark Thomas so at
the beginning I would like to thank for
the wonderful summer it's been really a
great pleasure being here and I think
even as my supervisor for bringing me
here and for collaboration thank you
thank young parents also for his Co
supervising me also mark Tomas I would
like to thank people from the
interactive entertainment business
division especially Alex kipman for
founding my internship project and
Jeremy Sampson for helping with the data
collection I would like to thank John
Platt and Misha Belenko from
machine-learning tip for their
consultation about the machine learning
I would like to thank and repass to
shark for his consultation about the TOC
library and Chris Burgess for letting me
use his booster decision trees also I
would like to thank Yasha dropo from the
CSL seed team for the consultations so
here's the overview of my talk I will
talk about HR TF what is what is an HRT
why do we need them I would talk about
the data collection we did and the unsub
America feature extraction which I work
on I would talk about Universal HR TS if
they exist I would talk then about HRT F
recommendation if you are learning from
user studies and then I will talk about
two approaches we proposed one based on
sparse representation and another based
on neural networks finally I would
compare all of these techniques of all
of the proposed techniques and I will
conclude and talk about future
directions so when I start what is an
HRT F so H OTF is a head related
transfer function that represents the
acoustical transfer function between a
sound source and the answers on the
block ear canal and the HRT F describes
the complex frequency response as a as a
function of a sound source position it
means the azimuth and elevation and here
in this particular work how focus on
modeling and our focus on modeling
magnitudes as a solution for the faces
or the exists so here is the sample of a
nature TF in the horizontal plane and we
can see that on the horizontal axis we
have here azimuth of sound source and on
the vertical axis we have frequencies
and this plot shows the magnitudes of
the Fourier transform of the input
responses and we can see on this plot
and magnitudes of the HRT f on a
logarithmic scale and we can see that at
low frequencies below 1000 Hertz HRT s
are independent of the direction of the
sound source but they are dependent at
higher frequencies above 2000 3000 Hertz
and the differences can be in order of
around 30 decibels so why do we care why
do we want HRT F basically we would like
to have 3d audio over headphones and
imposing HRT s onto a non special audio
signal and playing back the results over
headphones evokes the perception of a
vr-12 3d auditory space so in other
words having someone's picture TF allow
us to control the perception or the
perception of sound source localization
over headphones so there are many
potential applications
it can be used in games so we would like
to know where is the opponent and how to
move in a game and maybe in even
streaming or music performances also in
virtual reality or liking the movie
Minority Report we would like to not
only see what other people see but also
to hear the same what other people here
so why we don't have it we don't have it
because HR tiers are highly individual
and music someone's ass HRT F using HRT
s or other than the users own can
significantly impaired the results and
if we choose incorrect HRT F the
perception of a some sort of
localization might be also incorrect and
also because measurement of HRT F is an
expensive process
it requires specialized equipment and
anechoic chamber so what do they depend
on so h OT f are highly dependent on
human anthropometric features so they
are dependent on ear features like the
pinna height in a wave and they are
dependent on height features like head
deaf head height etc and also torso
features and shoulder so what can we do
as there are indications that h OT f are
correlated with human anthropometric
features will try to select and
synthesize a 30s for a given person from
a database so in order to do that in
order to start working we firstly had to
collect the data so let's start with the
audio data so here in Microsoft Research
there's anechoic chamber when we ask
participants to to enter and to sit on
this chair and the part of the chairs in
the middle of this arc the head of the
participant is stabilized so it should
be in the person's head should be in the
middle of this arc and we plug
microphones in participants ear on this
arc you can see 16 loud evenly
distributed loudspeakers and the arc is
moving towards 25 different directions
and so basically we place specific
measurement signals
from which we can calculate the HRT s so
as you can see on this image we have 16
animals 25 different elevations in total
it gives us 400 direction so what we
what we don't have we don't have some
directions so we basically extrapolate
them using spherical harmonics and at
the end we have 32 elevations and 16
decimal does give us 512 in different
directions for all the 512 direction we
have hods so once we have the audio data
I would like to extract entrepot metric
features and in order to do that we
firstly do their head counts so we have
different room where we ask participants
to sit on this chair and to put a
swimming cup so we can pick up his Scot
geometry so participants sitting on this
rotating chair and there are two
capturing units the party for
participants sitting in an angle more or
less approximately 90 degrees from this
capturing unit each of these capturing
unions has two cameras so at the end
four from each capturing Union we get a
cloud off point as a representation of
human head and not an example we have a
participant we rotate the chair we take
pictures from different angles from so
at the end we can align images and
create a 3d scan 3d head model of a
person and so there is first thing
there's lots of pre-processing steps
like images alignment feeling of the
hole smoking on the smoking of the mesh
and I would like to thank Jeremy for his
help in doing this and at the end we get
a 3d 3d head model of a person so once
we have this model I would like to
extract some features from it so we have
the model which we which is represented
by the cloud of point by the 3d
triangles and from this we can extract
some contours and
the head so does the features are
extracted from the head so I implemented
several algorithms which in automatic
way extracting features I'm not going to
go and say step-by-step how we do each
of them and we'll just take too much
time I would just say that we extract
some features from head by cat we've had
at length we extract features from the
neck from features related to Pina we
also extract from these head scans
features from the ear and so there are
features rated to tow pin height pin a
wave and other features apart we also
take measurements by hand from
participants so we have features like
interpupillary distance using this for
example kilometer we have we use
measuring tape and we with other
measuring devices to capture information
from shoulder from torso from head and
neck and you can see that some of them
are both extracted from the head scans
and some of them are asserted by hand
not is correct and there are two reasons
for that basically because in the 3d
models sometimes the neck is just not
visible so we cannot extract what is the
way for what is the death of the neck
and also basically sometimes boundary
between head and neck is not not clear
not visible the second reason is that we
need some features to scale the image
pixels the distances in model model
dimension to the real-world dimension
and as cameras are not fixed and chair
are not fixed and chairs actually
participant Omniture is rotating that's
why we need to scale the image big self
to the real-world dimensions so here are
some examples of the screenshots of the
software I did over the summer so it's a
extract some anthropometric features as
I described before for one and another
participant
here are some more samples what we also
do is participant to feel a short
questioner and there are 12 different
questions about gender age race height
weight and some part the question is how
they're necessary some participants
basically might not willing to provide
all the information all the details like
a chore wife so that's why we have
another less personal questions that are
correlated with the orgy on one so in
total we collected 115 people people's
href and 436 out of this 100 people we
have full measurements so we have the
head features from head scans we have
ear features from 3d head scans we have
measurements extracted by hand and we
have questionnaires so in total we have
93 anthropometric features per person so
up to this point I created data set I I
created algorithms for Entrepreneurship
features extraction I there are scripts
for data extraction and validation for
measurements questionnaires there are
many converters like participants are
coming from different regions so some
would like to put data in fees meters
some some converters for weight for shoe
size etc so finally you can come to the
topic of HRT of recommendation so my
first question is is there any universal
href which can one size fit all so I
took the head and torso simulator from
the Bureau and car company and this is a
mannequin with remove a removable and
artificial mouth and Pina and they
provide this mannequin with average
human head size which is supposed to be
correct for kids and other words for
females and males and I wanted to see
how far is the the this nature DF from
dead from this hot model to the people's
HR tears so I'm using the log spectral
distortion is the most commonly
use distance in the literature and I
will compare the locks pressure
distortion distance between a person
take on HRT F and HRT from the hot model
and I would just like to mention that
perceptual meaning of logs picture
destruction is not clear so here are the
result we have results for the straight
direction
so basically when someone's coming in
front of a person and we have for all
the direction around the person's of all
the href or the 512 the HRT s and we
also created the perfect and worst
classifier so basically in perfect
classifier I don't don't look into the
anthropometric features I basically
always choose the closest HRT F in the
logs picture distortion distant so that
that doesn't exist it just shows that
what this is the range of results we can
receive and we see that hot models give
our gives us results very close to the
worst classifier which we can create so
basically the conclusion is the hots
model is not suitable and we cannot
create one universal href for everyone
so if we cannot create one universal
href let's try to select one of them
from our database and that's our goal in
this part I would like to identify the
best href for a given person from our
database there are however two problems
one is that to select the best href we
need a a charity of distance and as I
said perceptual meaning of ASD is not
clear so the idea was let's do the user
studies and learn from there how do they
run a church yes so we can find
correlation between peoples and
thermoelectric features and their
personal nature ts working so we design
user studies here's one of our
participants and we provide them laptop
with headphones the headphones have the
head tracker and we designed the
iterative comparison experiment we ask
people to compare
each time to HRT s/he can switch as many
times the participant can switch as many
times as he want between an MA B and
then he has to provide his preference he
can strongly prefer a slight preference
to a strong preference towards another
one and this is a slider so he can
obviously put it wherever he want and in
this experiment we have in the training
phase we show participant 12 different
pairs of stimulus showing the range of
HRT F and the testing there are 156
pairs to compare I just would like to
note that we use my a speech for for
this listening experiment with better
based on what like it's supposed to be
in the given direction or just better
and so they are supposed to make the
decision while the sound is coming from
the from the screen so this they are
evaluating mainly the straight direction
what properties to look for because the
priorities that people set up by the
individual so we just ask them to give
their general impression whether this
sounds better to them doing this spatial
yeah so beans or whatever they can be
judging any clear orthogonal axes from
and then true and also my little
inconsistent later because people just
use different so we discuss many options
and for each option that we saw there
was arguments supporting it and
arguments against it so eventually you
just have to go for one but yes there's
always
whatever choice it is is there an
assumption that if you use the wrong HRT
I'll just sound bad regardless of
directionality
yes odious there's two main perceptual
dimensions are the localization and the
tempura they're not necessarily
independent one can influence the other
but you can hearing a sound source from
the right direction doesn't mean that
it's a good set of entity that's because
the number of might be a pair but you
too dark or too bright or so so yeah we
wanted to give people the freedom to put
their priorities
yeah so this is up to the people to
decide what they prefer in this was
there how do they judge so so how do we
choose the stimulus for the experiment
we take basically all the available HRT
F and we'd go after them and for the
training we clustered them to free
groups and for the testing to twelve
different groups and for each cluster we
select representative person and
obviously the people selected for
training and testing are different so I
tend for training we select free HRT F
and for testing 12
HRT F and then we ask each participant
to compare for matarese of selected HRT
F so and each pair of HRT F the
participant has to compare twice so if
we have for example twelve selected HRT
F we will have 12 by 12 plus 12 of the
diagonal so that gives us 156
comparisons so how to select these
representative 830's which gives us the
range of different HRT F for this we use
the log Specter distortion I said that
perceptual meaning of log version of
distortion is not clear but definitely
contains some true information if the
distance is big it also the Hitler tier
should sound different and if the
distance is small they should also sound
similar and here we want to select
representative HR TS which somehow cover
the full range of HR TF that's why we
believe that using LSD for this
selection of representation HR TF is
correct and we can represent we can
rewrite this distance in this form and
now we can apply some some clustering
algorithm means and that's what we
actually do so we had 23 people which
participated in our experiment and for
every participant and every pair of
Samoas we calculate the difference
between responses because every
participant has to rest reply twice to
the HRT F
do the same thing of h.o.t F and if the
alert if the party fans reply strongly
firstly to the hay and straw beetle eBay
that gives to the beam and that gives us
the difference between his responses for
so basically we put to them on the scale
the the values they range from minus 2
to 2 so we can see how what is the
consistent consistency between
participants with responses 0 means that
the reply exactly the same for the same
pair of stimulus for means that they
reply in totally up totally opposite
directions so we can see that there is
some inconsistency between participants
responses it might be that they were
tired it might be that the brain has to
see the difference when there was
actually no difference because in this
experiment they were looking for the
differences and it also might be that
people participated with different level
of engagement and actually once
participants fall asleep fell asleep and
we asked him what was the reason
actually it was not because of the
comfort of butcher and it was not
because of the experiment but because he
was on a party up to 4 a.m. so they
opposed all participants they
participated with different level of
engagement and that's why there is some
inconsistent see in the database some
participants spent like 1 hour 20
minutes to do this experiment and other
participants only 20 minutes so we also
plotted the same results in a different
form so we here we see the
representative 830's that 12 selected HR
TS and this shows how many times 1h30 F
is preferred over other HR TS so the
range obviously is from 0 to 24 and we
can see here that some HR tiers are very
preferable by this person and some are
not so this can give us the conclusion
that this representation provide better
data for further analysis
and we can create ranking from this and
that's how that was a that was the idea
let's learn iterative ranking from a
person from user studies and I already
mentioned several times ranking and some
of you probably thought about search
engines like Bing and Google and indeed
there is a similarity and that's how we
treat this problem as a learning to rank
task so how does it work we have 24
people each person is described by
ninety-three anthropometric features for
each each person I indirectly rank
twelve representative HR TS and each HR
TF is represented represented by 29 mal
frequency capture coefficient and for
ranking we used the boosted decision
trees so what I did is to create the
ranking ranking formula how to how to
create a ranking from our experiment and
basically them say short that the idea
is like let's try to give the high rank
values for the less often and low values
more often so basically only choosing
the putting the high values to only the
best HR TF only and only to a few of
them and we also to evaluate our results
we follow the metrics from learning to
rank domain and to use the normalized
discount cumulative gain metric mmm we
can see that 0 to 1 here is treated like
a classification problem and here are
the results however I believe that for
this audience would be more appropriate
log spectral Distortion so we also used
the log spectral distortion here to to
see the result we can see that results
are better than the hot model which was
13-point 77 and we can also compare it
to the perfect and worst classifier and
that's the result however I believe that
to evaluate this technique much better
will be to do another user studies
and that's what I will show later this
just shows that it's already better to
hang than the hot model also the second
excuse us the information which features
are more important for the for this task
and which which was our totally
uncorrelated so there are features
related to the head waved and the de
pinna then the head
and now I will talk about synthesis we
try to generate the H RTF for a person
and we have two approaches which we
proposed one is based on the sparse
representation and other on neural
networks so in a sparse representation
and the goal was the synthesis of a
dirty F using anthropometric features
and the idea was we model a person and
chop-o-matic features as a sparse linear
combination of anthropometric features
from other people and we assume that the
person's 830's
are in the same relation as on Superman
cheek features so we have a full range
of people in our database and we would
like to generate synthesize a charity F
for this gear so we'd like to combine
fewer people and say that how
anthropometric features are linear
combination of anthropometric features
from these people and ideally we would
like to obviously have only one person
the closest person and maybe two maybe
three people and not use any other
people so we'd like to create the sparse
representation and that's the idea and
it's learned sparse vector alpha from
anthropometric features and apply it to
H or TF and not that's basically our
idea so that's the problem definition
it's a minimization problem and here we
minimize the sum of the square error of
the overall anthropometric features and
we also add aerobic regularizer to this
and we solve this minimization problem
using the lasso technique and I just
would like to note that we learned a
sparse representation on people so
selecting people and not features as
usually it's done and once we learn
these parameters from entrepreneurial
data we applied it on nature tiers
and we again computed the results in the
lock specter of distortion distance and
you can see that now the results are
much better compared to other techniques
and the res are actually very close to
the perfect classifier which which we
created and again you can see the
distance for the straight direction for
the left and right here here separately
and for all together for all the
directions together and basically in all
cases that the results are very close to
the perfect classifier so that was the
first technique and we also have this
Technic based on neural networks so the
idea is the same let's synthesize a
chart EF using unchoke metric features
and here we basically try to map and
semantic features directly from href
attribute netic features to a chart EF
using neural networks here I was using
the radial basis neural network so they
contained input vector hidden vector and
sorry hidden input layer hidden layer
and output layer and in the hidden layer
there are radial basis functions and
after this mapping we get search results
which are actually and even better than
sparse representation so there are also
very close to the perfect classifier and
let's compare them so we already have
several techniques and let's see which
one is the best so that's all our two
things we we we created so there is this
perfect classifier which is as a
reference there is a sparse
representation there is there are neural
networks there is learning to rank we
also try to reach regression which I
haven't mentioned before which is like a
sparse representation but without
constrain of the sparsity and we have
hot model and the worst classifier and
using log spatial distortion we see that
sparse representation is mostly
preferred especially in the frequencies
which are the most important from 50 to
80 kilo Hertz
and neural networks are also performing
very good there are very close to each
other and stickings and we also believe
that the the performance of the sparse
representation can be further improved
with future selections but also we
evaluate the results user using the user
studies so we run a small user studies
with seven participants and we ask
participants to compare their own href
with selected and synthesized so
basically results are very similar to
the procedure is similar to before and
for Destruction we also present other
people's ideas and here are the results
so you can see five different techniques
learning to rank sparse representation
richer aggression neural networks and
hat and on the left - - means that the
person strongly prefer his own personal
href and towards the right means the
person preferred the synthesized href so
basically we would like to have
obviously everything from zero to the
right and here we see that the technics
which gives the worst results are the
heart that gives the worst results and
and the second one is reached regression
which also quite quite natural so let's
remove these two techniques for a second
and let's analyze the other two Heath so
we have learning to rank sparse
representation and neural networks and
so from this plot we can see that neural
networks actually works the best and
also and so one person said once firstly
that he prefer his own href but actually
when he compares second time the same
pair he said that he strongly prefer the
generated one so actually I would see
neural networks rather on the all
positive side
for the learning to rank that's the the
blue color the person said that firstly
he one person said I prefer slightly
prefer my own and then I slightly
preferred the generated one and the
second participant said I don't see a
difference and then said I slightly
prefer own sparse representation
actually two people said two people will
judge that they prefer the their own one
was consistent so he twice said that he
prefer his own href another person said
you slightly prefer his own and later
said he slightly prefer the generated
one so there's a game inconsistency in
the result and we should probably run a
little bit more user studies to try to
understand but from this what we can see
here is basically neural networks were
the best you know other things are
actually quite close to each other and
also work relatively good exactly the
same ATS is more precise well the neural
net was create a better idea than their
own because the maximum is kind of
shifted on the right it is one thing to
keep in mind the zero means same subject
has little preference of professing me
they don't need to sound identical they
can both sound bad above sound good
or some bad yeah but the reference is
always their own yeah but no preference
doesn't mean that they don't hear a
difference it just says that they sound
both equally pleasant one maybe it is
better in terms of extravasation and the
other one has a more natural tundra that
is also included in the zero but making
assumption that and that his own is
relatively good this was sure that they
both sounds relatively good explanation
yet for why we can create an HTS that
sound better than people's own assuming
that their own the best ones and that
this is what their auditory system is
first of all that and the other thing is
also you can't measure HTS such that
they are they are directly useful for
for organization so you will always have
to do some sort of compensation or
equalization of microphones and laws
because all these things and it's had we
haven't managed to have an automatic way
that spits out the perfect equalizer or
so there's some sort of manual tuning
involved and you can never say that it's
this is the truth what you're doing so
it can it can happen that there's some
some flaw in our equalization and the
synthesis algorithm happens to correct
for that it's also based on initial
impressions it doesn't take into account
base the fatigue so in the same way that
a lot of people might turn up to
contrast on the TV because it looks nice
expects away they're up for a while they
realize that sometimes things with a
boom in your face was sound more
impressive that's actually what was
happening lots of people decided firstly
that they prefer some H RTF and then
after some time they said huh maybe for
short while it's very nice I would like
to have it but the second decision they
made against another one present the
same pair of edges yes and sometimes
they say suggest that either they are
kind of equally good for users are
unreliable maybe because their
priorities shift this is these are
things we can't say we can't really say
what is going on so this is this is all
subject there are certainly indications
that subjects work especially those so
fatigue and it's it takes such a long
time that it's even I caught myself and
I noticed that my priorities shift
sometimes I put more weight on the
externalization at some time so it's
nice yeah that's the hinge is it true so
there's still lots of stuffs which
should be investigated and the
conclusion so we created a new data set
with 830's and at romantic measurements
or design over the summer we created
algorithms for anthropometric feature
extraction we created four different
techniques for iterative personalization
recommendation we have relied evaluated
our techniques using both log spectral
distortion and user studies and results
are encouraging and based on the results
the best technique is the sparse
representation when we are using the log
spectral distance and neural networks
based on user studies as a future work
definitely we should collect more data
more extensive user studies to assess
the proposed techniques and we should
collect more data to cover a wider range
of people like more females more kids
more elderly people for the techniques
for the sparse representation based
approach will be really nice to add
future selection so we can find useful
features and easier to measure features
that give good results and remove you
all useless features for the learning to
rank maybe it's good idea also to learn
ranking from of HRT s from LSD distance
and also definitely we can try in the
direction of magic factorization for the
recommendation of HRT s thank you for
your attention
is there a
it seems like you're generating these
things we have a fast Mars even in some
features and this could have a turkey a
threatens to go the synthesis but it
seems like these things work are only
really evaluated by people in prepares
your classifier no my understanding of
your classifier so there's nothing that
says that I'm gonna give you the
features to the left here the features
in the right here is like that so these
two is you agree
your kids can be sort of anthropomorphic
the inconsistent
that's it can you ever like for example
to mess up on prisons give them their
really love you see what that does that
matter
actually what we are doing is the
synthesis of both ears at the same time
yes so though they're equally bad or
equally good yes oh yeah all your tears
all entrepreneurial features going to
and they say yeah that's the href which
you should use so and it generates both
for left and right here
yeah how many new policies one agency
how many numbers is one a truth yet so
we have 512 directions and for each
direction we have 512 values 96 he puts
in you managed to synthesize 500 by 500
quarter of a million points that's that
must explain I mean at the end line
subspaces are small
so there are basically work
teachers everyone
no actually no we know you can generate
in one direction and apply the weights
too
I mean like for example when we are
using that which taking like for example
disperser presentation we learn ways and
then we don't care which direction it is
we basically apply the same ways for the
H 30s and the same word in neural
networks basically the idea is like we
put all the direction the same in the
same spirit yes all the all the other
directions not all along because a dance
to a kettle white wing we need all the
direction so just back up you know I
know I can imagine two classrooms one
where you say these are the
anthropomorphic features and this is the
direction elevation give me the key
Barry is about fewer parameters to learn
the first base
yes basically we can also obviously
create 512 separate classifiers for
generating eventually use them as
features then you'd still the same
network sharing all the weight room but
they're not exactly the same that's why
we like learn for ever separate</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>