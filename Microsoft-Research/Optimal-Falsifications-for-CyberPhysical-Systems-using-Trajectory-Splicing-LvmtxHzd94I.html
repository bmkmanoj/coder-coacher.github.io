<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Optimal Falsifications for Cyber-Physical Systems using Trajectory Splicing | Coder Coacher - Coaching Coders</title><meta content="Optimal Falsifications for Cyber-Physical Systems using Trajectory Splicing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Optimal Falsifications for Cyber-Physical Systems using Trajectory Splicing</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/LvmtxHzd94I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so good morning thank you for
coming here and it's a pleasure to me to
introduce our speaker and let's start
with enacted this summer we ran with me
and manuel fangio should we run SAS and
we had the same person it's a valid
speaker and you know the session chair
who introduced him nikhil outbox was
kind of a angry with me and with manual
because they say okay inviting producing
a better speaker it's a big honor but
anybody speaker with such a long name
it's like to introduce and now I
understand why nicol nicola was a little
bit nervous because i have to promise
ate his name so it's shriram
Sankaranarayanan yes what i have to say
that i read it but to be honest nicola
he learned by artist name so i spend all
the evening's probably the night doing
it ok no stopping with jobs you I think
everyone knows kurama did great
contributor in the field of verification
static analysis and think everyone know
but us knows about templates then were
introduced by by Shri Rama and all this
work we made on a numerical domains when
he was in speedy with the SWAT man and
was really cold vital to any signal any
sigma and then we moved the two to the
industry and you see where he worked on
a real software static analyzer use that
many see for my understanding and and
then echo DA's Korea to university of
older which now which now you know is
trying to prove that human bodies
correct so you're trying to verify you
my body or something like this I hope
let me see okay thank you so yeah thank
you Francesco for the kind invitation
and thanks for having me here I've had a
wonderful time yesterday and hopefully
you know promises to be a great day but
today my talk is about this title called
optimal falsification for cyber physical
systems some of the slides in the talk
where is was a talk given to a broader
audience so so some of these lights are
going to be
I wish I ask you to forgive me for that
so what are cyber physical systems so we
all have an idea of what cyber physical
systems are these are systems which
interact with the environment so these
are software systems that have a
physical component to them so if you
think of an artificial insulin delivery
system it controls the human body which
can you can think of as a physical or a
biological system through a software
that controls how the infusion pump
infuses incident software is becoming a
huge deal in automotive systems where a
lot of functions that were taken over
that we're done by mechanical parts are
now being software-controlled it's
called drive-by-wire software is coming
in a big way to the power grid like
active active micro grid power systems
and these are very important so it's
very important for us to get the
software correct right but it's very
difficult as well to get the software
correct so I I thought I would go up to
the National Highway Transportation
Safety Association and they have a bunch
of recalls and just get a couple of the
recalls as you know small sampling of
software related recalls and you can
find this if you do bang on automotive
software related recalls and one of them
says okay due to a software problem the
door may unexpectedly open while the
person is driving the car which seems
like a very strange thing what is
software I have to do with the door of a
car but it's the it's a security system
in a car where software controls whether
a door opens or closes and now the door
can open while the person is driving
right yes sure so okay it's fine no
problem if you are wearing a seatbelt
but now look at this one it's perfect
another reason to wear your seatbelt but
look at this one so this one says so for
the electric motor to rotate in the
direction opposite to that selected by
the transmission due to a software
problem now now I'm not you know it's
the reason is not because they don't
know how to build software it's just
that when you build it there there are
so many bugs and and you may ask me okay
we've been doing software verification
for the last 20 years what's different
about these bugs
two things are different these are
functional correctness properties these
are not buffer overflows these are not
null pointer errors which we know how to
take care of and hopefully you know
there will be no more talks on these
subjects of null pointer as buffer
overflows thanks to all the good work
you guys do but there are still going to
be these bugs left so our job is not
done and these are properties of the
closed loop system these are not
properties of just the software alone
these are properties of the software and
the physical environment the physical
artifacts that it controls without
talking about the physical artifacts you
cannot just verify this inside the
software that's the main point I wanted
to make with this setting that's that's
absolutely a you knew that car from sir
racing go-karts it's actually completely
falsified can be completely false it
about exactly a modern automotive is
automobile is is it's becoming more and
more electronic and I'm playing like in
a car and then you got in the car and it
was actually very similar yes yeah and
because it was physical and most cars
you press the brake you're just sending
a signal to a computer that's going to
then control the braking system there's
no direct connection between your brake
pedal and unless you are you really have
a very old model of a car there is no
direct connection between the brake
pedal and the drums there's no
mechanical connection anymore it won't
roll roll if it has no power uh-huh so
Tesla's get braked if you if you don't
if the batteries drain mm-hmm it's
impossible to roll the car right
probably yeah I mean these are and there
are systems like like the Boeing you
know the latest Boeing aircraft can
actually override the pilot the
autopilot can override the manual pilot
used to be the other way around so now
they place more trust in their computer
systems then in the on the human so so
things are things are very interesting
and where is verification in all this so
what is stopping us from just solving
this problem with all the tools that we
have so that is going to be most of what
my talk is about so I am going to come
up with some somewhat a different view
of what we can do as a first step
towards getting verification on the
track you know some someone has to start
and something has to be done so as a
first step we are going to try and
approach the full force of this
verification problem through model-based
design and I will show you what we have
done so far it's going to be very simple
it's mostly testing pretending to be
falsification so i will talk about that
and i will give you a couple of case
studies on which we have had some
initial successes so we haven't solved
anything but we have hopefully made a
step towards you know doing thinking
about these problems and solving them
okay so the first challenge when you
think of these systems is modeling so
what do you need to model you need to
model the computation and you need to
model how this computation interacts
with the physical subsystem but this is
nothing new we know about hybrid
automata a lot of people pioneered this
in the 90s and we've spent 15 to 20
years looking at hybrid Automator maybe
more than that 25 years looking at this
hybrid automated model which has the
states inside each mode there's an
ordinary differential equation that says
how things evolve inside the mode and
there are these guards that go from one
mode to another right and we know hybrid
automator we know what's decidable what
is undecidable how to model check how to
do static analysis and to know n but all
of this is no good when you come up
against this beast which is called a
simulink state flow diagram and if you
go into the industry this is what people
do their development in it is equivalent
to a hybrid automate and you could prove
the theorem but it is going to be an
hybrid automate and that you cannot
write down it is going to have more
modes with a number of atoms in gas at
standard temperature and pressure right
because these are not easy to translate
to hybrid automaton and a lot of work
needs to be done so what stops us there
well they could have continuous input
signals they have discrete switching of
course otherwise they do not become
hybrid they have continuous dynamics so
each of these these blocks with a
picture just expands into a huge block
when you double click on it right they
are non linear linear systems are much
easier to deal with
and to take the cake the semantics are
unclear but that's not the huge problem
you could say that the semantics are
unclear in some corner cases it's quite
clear in many of the cases but there is
inadequate documentation it keeps
changing from version to version and
there is very little front-end support
this is not the world of c or c sharp
where we have nice front-end tools to
parse these things to load them up and
intermediate representations to simplify
them we have to tackle these diagrams in
the full force of the diagrams right
they are really hard to deal with as
static analysis inside a static analysis
infrastructure and so there is none
there is no static analysis
infrastructure this is within the
expressiveness of its little the
expressiveness of hybrid automated but
it's outside the expressiveness of most
verification tools so when they start to
combine funk arbitrary functions that
are defined by tables and and so on most
verification tools are not able to do
them and they compose these functions to
make huge functions so they can very
easily defeat our verification tools
yeah decidability barrier is very low
two variables in a hybrid automaton is
already undecidable right two modes I
mean we know all those I you know from
the 90s we know what you need to get
undecidability and nothing really very
little right these are like well into
the undecidable frontier so so nothing
you know definite can be said about
verification or falsification but we
still track right it still doesn't stop
us from trying okay so the goal for this
talk is I'm going to try and verify
these complex systems but I am going to
use simulations as the only way of
obtaining information about the system
so given up front let's restrict
ourselves I mean this is a harsh
restriction unnecessary but let's still
restrict ourselves with this let us say
simulations is the only thing that we
can do then can we still do something
that's better than randomly testing the
system that's that is going to be my
premise for the stock so it's going to
be you know hopefully nothing deep
but let's see how much we can get and
where do we you know break when we start
to simile and this is something like
black box falsification you are treating
the system as a black box that may be
bad but it's convenient to do so because
we can start to get tools that work on
real models right up front so so it's a
very practical thing to do so we will
presume that any system they give us is
flawed and we are our hope is to search
for this violation systematically if we
find one it's going to be golden we can
go to the developer and show them their
violation but if we do not find one then
we are done or effort we've run for many
days and that's what most model checkers
do anyway after running for many many
many days you still may not exhaustively
have exhausted your state space so you
press ctrl C and stop the engine like in
many practical model checking examples
that's how you end I mean if you took
look like explicit state model checking
with spin you never finish on big
examples you find a violation or it just
keeps running and you just gained
confidence by its run five days and
found nothing okay so the big question
then is where should be church and how
should be searched so ideally I would
like to use an smt solver and use BMC we
also the talk yesterday where they did
corral and they did some nice unwinding
and gave it to an SMP solver and SMT
solvers have inspired a lot of our
thinking process but we are nowhere
close to doing this because we would
immediately get it a nonlinear theories
and immediately get into trouble okay so
there are two ideas that i will present
one is we are going to reinterpret
temporal logic and i am going to call
this the robustness interpretation of
temporal logic so what temporal logics
the logics we study is they take a trace
and they give us true or false is this a
property violation or is this not a
property violation but what we are going
to do is reinterpret it with real values
and we are going to do it in a
systematic way where properties can be
proved the boolean interpretation can be
compared with the real valued
interpretation and so on so we are going
to systematically do that and once you
change a boolean value to a real value
what we will now see is it's very
natural to use optimization as a search
procedure and some very interesting
properties of cyber physical systems can
be exploited once we do that so I will
show you how those two things can be
done
and i will show you some some better
ideas on how to do the search that are
also inspired by thinking about how SMT
solvers do this search so i will give
you some flavor of what how we are
proceeding with that okay so let me
start with the robustness interpretation
so this was work it was originally
started by giorgos and then i joined
with george olson on doing this
robustness interpretation so i think
it's a very cool piece of work i really
like the way the issues have been
brought out here so the way the standard
picture works is okay i already told you
we have a simulator it goes into that it
produces a trace that goes into a
property monitor now think of your
property as an LTL property or a metric
temporal logic property or a real-time
temporal logic property of your choice
and the property is monitored and you
get a true or a false and we are after
false that is why we are doing
falsification okay now let me take an
example to motivate this so in this
example this is a very simple example it
but it's also a complex example in
another way this is a small example but
it can produce very complex behaviors
and it's called a van der Pol oscillator
I just brought it up so that the green
or the blue box are the initial states
and our goal is to find a trace that
reaches the red box okay and I have
shown you around 10,000 or some such
number i have shown you that many
simulations and you can see that the
property is clearly violated so this is
not meant to be a tough problem it's
meant to illustrate what we are seeing
okay so hopefully if this is clear the
details of the system are not too
important to us it this could be any
system okay now let me do this plot to
motivate what we're after so this plot
just says the the bottom the X and Y
axis are going to be our initial
conditions between minus 0 point 5 and 0
point 5 minus point 5 and 0 point five
for each initial condition point i plot
plus 20 the plus 20 is just to make
matlab show it as a big in a y-axis z
axis plus 20 fits true and it's shown up
there in pink and minus 20 if it's false
and it's shown down there and you can
see the thing down there okay now if you
look at this is our search space and I
visualized it for you okay the search
space looks quite flat so if you are an
aunt
at the top right so in you randomly
choose a point the hype with very high
probability are going to land in the
Pink Zone in the top right but if you
are there you don't know whether to go
left or whether to go right which is the
direction should you search towards
falsification okay and such a question
may not make much sense in program
verification but it makes a lot of sense
in cyber physical systems because it you
always think about suppose I have tried
input 0 point 5 and point for then
should I try point 6 and point 5 you
always think about the neighborhood of
your input space that's how you think
right so in a program you know the
programming world point the nearby
inputs could produce something widely
different but in a cyber-physical system
you expect it to produce something
similar and that's called a continuous
sensitivity to initial conditions for
something all over and shake it so
simulated annealing right that's right
and that's that's that that's right but
but if you do simulated annealing on
this it's just going to do random search
on the pink zone right because the the
way the search space looks is it is a
cliff and you don't know where the
dropout points are right so this is the
first thing we are going to do we are
going to change this we are going to
change how we view this and we are going
to say thus a trace violator property is
a boolean interpretation we get to how
close does a trace get to violating the
property so what's distance between the
trace and the property and can we define
this distance systematically and if we
do that if we manage that without
bringing in an arbitrary definition of
closeness we have to make it systemic or
else you know we would get something
that looks quite random and and mode
give us the answer we want right so to
motivate that idea let me take up two
traces okay the bottom left corner the
circle there is the initial condition
and there's two traces phase 1 and phase
2 and the red box is what we need to hit
to violate the property of our interest
okay now you can look at it and you can
say ow trace one is so far away from
being a violation but phase two is so
close to being a violation okay but the
boolean interpretation is hiding this
because it just gives you true for both
traces it doesn't give you any more
information other than how close to
being false but can we make it AB
definition that
he gives us how close at races to be
false and we can do this for the kinds
of systems you are interested in because
the state space is real value and what
we define here is the notion of a
robustness of a trace which we say is
the radius of the cylinder around the
trace okay so that any other trace in
the same cylinder that you can think of
has the same valuation as the trace that
you are interested in so in this case
the blue trace has a valuation of true
for the property that I do not hit the
orange region and therefore I put the
cylinder around the blue trace and you
can see how the cylinder is quite
natural it's you know it's formed by
making sure that its boundaries just
touch the unsafe region and then any
other trace like the like the orange
trace that i have shown inside that lies
inside the cylinder has the same
valuation as the property okay and the
radius of the cylinder is the number
that we will call robustness if the
property is true we will make it a
positive number if the property is false
we'll make it a negative number okay so
so this is basically the formal
definition of robustness and the nice
thing that we can now show is the
following so we can define robustness as
a function that take traces two real
numbers okay and the idea is we connect
it up with the boolean valued semantics
like this so if the trace satisfies the
formula the robustness is made strictly
positive and we ensure that it's
strictly positive and if it's strictly
negative then the trace does not satisfy
if it's zero then there is a it's
actually a corner case where the trace
either could or could not and and that's
one of the problems with this definition
but it's still so rare to get exactly
zero that we do not worry about it okay
so we make instead of boolean semantics
we now go to real valued semantics but
how is this real valued semantics define
and the cool thing is you just take the
way you define a boolean semantics and
you change a few parts of your
definition and out comes the real valued
semantics so how does that work so
instead of saying whether a point
satisfies an atomic proposition P you
look at the signed distance between the
point the state and the proposition case
distance between a state and a set is
well defined and you
and signed distance means that if the
state is outside the set it is a
positive number if the state is inside
the set it is a negative number so
instead of being you know saying does a
state X satisfy an atomic proposition P
you say what is the distance from X to
pee okay boy then the frontier of the
Frankie out there so it's not it's the
it's called a horse trough distance you
connect through form isn't it you can
have the closest to the forest or do you
ever write so this would be the closest
yeah so we use the closest distance from
the point to the frontier of the set as
the point set distance okay and we make
it signed to give us the negative
robustness means violation positive
means satisfaction so we make sure that
the sign convention respects that and
now or becomes max and becomes min
negation becomes sub you know taking the
minus of the robustness and and things
like boolean operators like box if you
remember from temporal logic they can be
expanded out into into or and the net
wat holds in the next state the same
thing now becomes you know or becomes
max and becomes min and so you
immediately get the recursive definition
that you are really interested in and
everything works out nicely so you just
change or two max and two min and and
you change the boolean operators
accordingly and negation becomes a minus
so and then you get the robustness as
long as the actor at the atomic
proposition level you look at scientist
ences it's a very interesting just a
very simple modification of how you
think of temporal logic and suddenly you
get this number that makes a lot of
sense which one the project is over
Sandy since you have been so faces does
it also destroy my property for sign
distance yes it has to have it has to be
a metric yeah so we make sure it's a
this is X Y so sweet able to zero this
correct because because we use the sign
you know if it's inside the set we we
kind of give it a negative sign but our
distance has to be a metric we have a
paper in which we show that even if it's
a quasi metric where we drop one of the
requirements of being a metric it still
works but yes you're you're right it has
to have those topological properties
or else it this this does not work yeah
you get some nonsense otherwise all
right so what we then do is the
following okay so what is the
computational complexity of computing
the robustness well it is linear it is
almost the same computational complexity
as evaluating the formula on the trace
except for a small change which is
instead of doing whether a point lies
inside a set you have to do the distance
computation in the general case it is a
convex optimization problem okay
depending on how distances are defined
l2 distances or l-1 distances or l
infinity distances but there are some
special cases where the atomic
propositions are just boxes or hyper
rectangles things remain in a certain
range is an example of a hyper
rectangular predicate then we can make
this distance computation rather fast
and so this would be you know would have
been a bottleneck but we can make it
rather fast and make sure that you know
we respect our logic formulas to make
the distance computation fast okay and
we have a tool or I should say giorgos
as a tool called tally row which
computes temporal logic robustness for
matlab traces and we have extended that
to hybrid system traces as well so that
was the first part of getting a distance
and let us see what has that achieved
for us so go back to the van der Pol
example we had this 01 surface which
wasn't helping us a lot especially when
we were trying to do simulated annealing
instead let's do robustness and
immediately you get the surface on the
right which now has some interesting
features so it's very hard to see from
this projector but what you can see is
that on the right hand side on the on
the right hand top corner things are
elevated oh sorry your left hand side
sorry your left hand side top corner you
can see things are elevated you can see
that there is a peak in the center
because the system as an equilibrium in
the center it just remains where it is
and so robustness is pretty high there
because it goes nowhere near the unsafe
said but you can see how the violations
the two red arrows that I have shown
correspond with the violations here but
there is a gradient that informs how you
get there and so you can do simulated
annealing on on this surface and your
you you will get a lot better
performance empirically then on this
surface very cool just behave like a
random
on the surface so that was the main idea
behind using robustness for
falsification so again it is nothing
deep but it is building on what is the
minimum that we can do and what is
better than that minimum right so again
so again you start with your property
monitor out it goes and in comes
robustness computation so you have these
robustness computation tool palio and
what you do is you hook it up with an
optimization of your choice there is no
silver bullet here but we we tried many
different optimizations always and each
one of them works well on an example
it's the same problem that coral has
yesterday which is you know or slam has
which tool which optimization do you run
you just run all of them if you can
right and that is what we do there's a
bunch of these tools we can run you know
starting with simulated annealing we
have a method called the cross entropy
method which a stochastic optimization
method you can even run genetic
algorithms ant colony optimization we
just threw it you know whatever solvers
we had there are no guarantees on
performance which if you know my
research is not how I like to operate
but you know this is the world of we
started from ground zero and we said we
are going to solve a hard problem so
let's let's do it from ground zero let's
get the low-hanging fruit out of the way
which is I guess put an optimization
solver and let it find a falsification
again we actually got very good results
from this very promising we managed to
falsify examples which you cannot even
get started it any other method because
we are very simple we are just testing
and we just have this optimization loop
and robustness is the main thing the
secret thing that gives us the power to
test it because it gives us a gradient
it gives us a direction go this way and
test this way that gives you better
answers okay so just to illustrate one
case study where B we got some good
results so this is an automatic
transmission model that was proposed by
two researchers then at Ford Motor
Company now can versus said Toyota and
he proposed this as a tech report of a
challenge problem that people in the
hybrid systems community should try and
solve and he gave a so this system is is
it models a powertrain which roughly
speaking is innards it takes the current
throttle position like where your
accelerator pet
LS pressed you can think of it that way
the initial speed and the road great
like whether you're going up or down and
it adjusts the torque that the engine
provides to the wheels and the shift
schedule which gear should I shift
should I be in the first gear or the
second year which gear should i go to
make sure that I am NOT stalling or
falling back right it has six continuous
state variables 24 discrete modes it is
not a very complicated system and it's
by by no means the most complicated
system we have looked at and its
dynamics are affine but it's still
complex enough to defeat most of the
tools out there okay and they were given
some properties like you know starting
from zero speed if the vehicle ships
from the second gear to the first gear
and then back to the second gear is that
even possible or they they asked us if
the vehicle shifts into the first gear
it will not shift back into the second
gear for at least 2.5 seconds it should
remain in the gear that it just shifted
into and it shouldn't just keep like
shifting back and forth and they wanted
to know if these properties by false for
example to it wasn't known you know it
wasn't very well known whether it was
true or false and what we found out was
it was actually false we found a
falsification we actually falsified all
the three properties out there okay
using esta narrow and here is an example
of what the robustness looks like we
managed to plot it for this example it's
just fixing the values of some of the
variables and plotting for the rest and
you find that that's the overall figure
on on to my right and to your left there
you see that yellow region at the bottom
in that little yellow region if you blow
it up you will see another little region
here where the robustness goes negative
and you will find a violation elsewhere
there is no violation so so drawing this
figure is very takes a lot of time
because you see each of these little
dots is a simulation but astillero just
samples a small part of the space and
gets there okay it's around 700
simulations but this figure itself took
around 10,000 or more simulations so you
know even though this figure is
misleading you could say just watch this
figure there's a violation there s
Toledo has to find it without drawing
this plot this is just for your
illustration and the nice thing is
because this is a testing method we can
provide them the test inputs that show
you know okay do this and and this gives
you the false 4k
so it was very easy for us to convince
the people who had formulated this model
that there was a violation because we
just had to send them over our signals
so that was nice ok so the tool is
actually available it's called estando i
will give you a link and it supports
simula ng state flow models it's that's
very nice because it lets a lot of
people adopt this tool because we
actually support something that they use
we have tried it on many challenging
examples some automotive examples
closed-loop models of medical devices i
will tell you a little bit about them
and we one of the projects i used it for
was on searching for failure modes of
insulin infusion pumps where we looked
at how to find failure modes of this
model and and how to do parameter
synthesis of patient parameters and
controller parameters using this kind of
search so we are also trying to get into
some synthesis using astillero but what
i will do instead of talking about these
examples is I look at something that was
actually inspired by the way SMT solvers
work and that inspired how to think
about falsification a little bit more
and what we now we now call this
multiple shooting methods we initially
called a trajectory splicing and this
was inspired a little bit by thinking
about how would an smt solver approach
the problem of falsification and
multiple shooting is a name that the
control theorists said was the standard
name for it rather than in a trajectory
splicing so that's why we call it
multiple shooting so what is multiple
shooting and what is single shooting
okay and single shooting is a term that
says we fix all the initial conditions
and all the signals and then simulate
the system to find a violation and
that's how a style yo does its search it
needs everything all the inputs and then
it runs a simulator then it obtains a
trace and then it finds a violation and
you might be wondering is there any
other way to do it right the other way
to do it is like this and this is partly
I said inspired by ass empty solvers
which is you find small segments of
traces okay little segments of traces
that can be disconnected and you try to
join them up okay and we call these
segmented trajectories and we call the
process of joining them trajectory
splicing okay and and then my
when you do things this way you can get
much faster on some of the benchmarks
and and let me explain what what this is
doing so what this is saying is if you
can think of choosing the initial
conditions and all the signals as saying
let's solve a satisfiability problem by
upfront fixing the entire model and then
seeing if the model satisfies the
formula but I simply solvers don't do it
that way they come up with partial
assignments that fix parts of the model
and see if they can learn conflict
classes backtrack and and then you know
come up with you know so they don't
search the entire space up front they
search for partial assignments and see
if that you know backtrack so this was
you know a very naive way of saying
let's also search for partial
assignments let us look for parts of a
trajectory and see if we can join them
up to make a full trajectory okay how
does this even work so the way this
works is like this so what we have is
suppose you have these split
trajectories where the gaps there are
gaps between the segments okay what we
will let the solver do is search in the
space of these split trajectories but
use these gaps as a cost function and
i'm just showing the you the version for
safety you can also extend it to other
temporal logic properties but i will not
complicate the presentation here right
so you can minimize if you can minimize
these gaps and eventually get them down
to zero as part of your optimization
then in the end you would have a
complete trajectory where the state at
the end of a segment will match with the
state at the beginning of the next
segment and you will be able to join
everything up okay so there are some
nice advantages is setting up the
problem this way in multiple small
segments that you know you can join
together and get a violation so what our
tool does is it starts with some such
segments that it finds through random
simulation so we'll randomly simulate
the system for part of the time and then
just take a random jump randomly
simulate the system take a random gym
until you find violation and then it
will join together and find a trajectory
with gaps in it but you can't give it to
the user because this is nonsense right
now but if you can narrow the gaps
recursively using optimization then you
can give it to the user so that was the
whole idea and our hope was that we
don't even have to narrow the gaps down
to zero if we can get it below double
precision then what is the user care if
the user can't see it
simulations if it's below the precision
of a floating point number then we are
done right so we use that as a as an you
know heuristic to say let's narrow it
down to 10 to the minus 10 and then give
it to the user the user and the
simulator will usually be able to
reproduce it ok so that was the idea how
does this work it's very standard
actually so what we then do is we set up
the optimization problem like this so we
say the cost to minimize is the distance
between the end of one trajectory which
is X I is the starting point of a
trajectory TI is how much time I spend
and f is the the system simulation
function ok so I say that the gap
between the endpoint of one trajectory
and the beginning of the next trajectory
the sum of all these distances becomes
my objective ok and what we can sorry
usual reese's usual distance so we do l2
or or or l-1 distance but in this case
we do l2 yes usual distance not signed
any more and we are just looking at
safety I am NOT giving you the full
picture here and what we now do is we
you can compute the gradient so we can
actually compute the derivative of these
things with respect to X I with respect
X I plus 1 it sounds very surprising but
it's actually possible to do so and in
our paper we'd arrived at it's it's
based on some very standard ideas in
ordinary differential equations ok so we
do the derivatives we can also calculate
the second derivatives and and what you
get is something called ordinary
differential equations sensitivity
analysis that can give us the
derivatives that can give us the second
derivatives and now we can use
techniques that are well known in
optimization like Newton's method or
gradient descent to try and narrow these
gaps so we use random simulations set up
an initial state for the solver and just
let the solver go and narrow the gaps
down to zero and it's pretty good at
doing that and there are some functions
we don't have to implement all of this
these are all so standard in
optimization that we just take a
function like f min corn in matlab and
just give our tool to f minh con but we
also have to give it the derivatives
which we calculate we also have to give
it the second derivatives if you want to
use Newton's method which we also
calculate and once we finish those
calculation we can give it a fin con and
what it does is it you
is our calculations and finds a
violation okay at least tries to find a
violation if it fails to do so we just
again randomly simulate try another
initial scene try to see if it finds a
violation and so on okay so let me just
illustrate why one would want to do this
kind of a technique on on a different
case study and this case study is a
small example of an artificial pancreas
controller it's not the latest one it's
an early example and I will tell you
what stops us from doing the latest one
just just in a few minutes so here the
idea is we are looking at a control
system that's controlling an insulin
infusion pump that's pumping interested
into a patient who is who is type 1
diabetic so it requires external
incident and the patient has a variable
glucose sensor which is sensing the
level of glucose in their blood and the
controller looks at the level of glucose
and decides how much insulin the patient
needs to get so it is a closed loop
controller and it's called the
artificial pancreas okay and in this
what we have is we have mathematical
models of insulin glucose dynamics in
the human body so the human body has a
very nice way of regulating glucose
through insulin and this dynamics is
well understood people have spent around
30 years modeling the dynamics using
differential equations so that part is
well understood so we just take one of
those models and people are also thought
about control algorithms for controlling
the flow of insulin so we also use one
of those control algorithms and the
input to such a model would be the
caloric intake of the patient what is
the patient eating and and the output
would be the blood glucose level G of T
that the patient has currently ok and
for some more specifics for the insulin
glucose dynamics we just use for our
examples a very simple model it's called
the Bergman minimal model it has some
deficiencies but it's pretty good for
trying to experiment with these systems
and see how well our solver does on them
okay and we looked at a couple of
control algorithms that were published
in 1985 by Furler 1991 by Fisher so we
went to their papers fished out their
control algorithms and just implemented
it in our in our closed loop and what we
did in this case was we took 21
different instances of parameters so if
you go back to this slide the insulin
glucose dynamics is governed by some
parameters some numbers magic number
that come from various patients so what
people have done is looked at patient
studies where they have looked at the
insulin glucose levels in a patient over
time and they have adjusted these
parameters so that the model fits what
the patient actually shows as real data
and there is some 21 different instances
that are available with the bergman
minimal model you can get these
instances for 21 different patients or
virtual patients so what we did was try
to see it as the controller work on each
of these patients right and what are we
testing what are our properties here
properties are to safety properties one
safety property says hypoglycemia
shouldn't happen which means that the
blood glucose level should not dip below
3m mole per liter or it is like 50 mg /
dl and that's the limit below which if
it goes it becomes very dangerous so you
should not let the blood glucose level
go below that and hyperglycemia which is
blood glucose level should not go above
22 and more per liter or roughly around
360 mg per year okay and we had some
very interesting results here and let me
take the time to explain these results a
little bit so the on the left we tried
21 different patients and we found six
examples of violations okay five of them
were hyperglycemia violations if you go
back the level of glucose greater than
equal to 22 and one of them was
hypoglycemia violation which say so the
controller is pretty robust against
parameter variations it's not too bad
because I would have expected to see
violations in all 21 cases right now
let's look at these violations a little
bit detail so you can see the times we
took in seconds which is roughly like
one second in one case we took eight
seconds so that's not too bad but I have
another metric here which we call the
degree of difficulty which is we tried
10,000 random simulations and we saw of
the 10,000 how many gave us a violation
that gives us an example a metric of how
difficult is the property to violate by
our straw man that if random simulation
is a straw man we have to beat then how
does random simulation perform on this
so so you can see out in two three of
these examples 10,000 simulations
yielded nothing right and in two of
these examples it yield at around 293
out
ten thousand and eighty-four out of ten
thousand so probability wise just by
chance finding these violations is
pretty hard okay now the interesting
thing is we actually do find violations
even when random simulation completely
fails to find one or it's pretty rare to
find one through random simulation right
and some other interesting things are
okay so random simulations in these
examples takes around two hours to
finish so 10,000 simulation takes around
two hours to run because simulations are
in cheap they are also expensive and and
this to ours is on parallel for core
machine so it's not you know even so
it's it's all paralyzed and even then it
takes a long time to finish and we have
a lot more benchmark results like this
in our CDC paper we have one more
example called the nav example where we
show very similar results across many
instances of the benchmark where random
simulation takes a lot of time whereas
we can find a violation fairly fast okay
which is very interesting so so we get
and we also get around 5 200 XP dubs
when we do the same thing using single
shooting if we don't do this multiple
shooting and just do single shooting we
get some very impressive speed ups and
we also tried esta lido with simulated
annealing and we also get significant
speed ups on este lío when we do this
multiple shooting method we get some
very good speed ups on estero so this is
a very promising idea but we still
haven't managed to make it work on
simulink and stateflow primarily because
silicon stateflow makes it very hard for
us to do these segmented simulations you
can't do a short simulation for a short
amount of time reset your simulation
then do another short simulation that
becomes pretty hard for us to automate
in simmering state flow it insists on
recompiling the model so it is a
technical issue that that we just have
you know so every time we do it the
model compiles against of that that
makes it very hard for us to to make
this worthwhile otherwise the simulation
itself just swamps up all the cost of
doing work for us so that becomes harder
and computing these gradients and
Hessians and simulink state flow still
require some support which we haven't
which we are they aren't providing yet
but they're there is some hope that they
will provide it soon enough so what's
the future work going to be so the
future work is
we really want to expand on artificial
pancreas verification and we really want
to make sure that this verification can
help people who are developing the heart
critical pancreas which is an ongoing
effort in many academic labs some
industries have also started looking
into the development of artificial
pancreas it is a huge industry there's a
lot of money that has been invested
billions of dollars have been invested
in type 1 diabetic research so this
would be a huge deal if we can get these
things to market faster using
verification right and the state of the
art model here is a you know models like
Huaraz model or Dollar man's model not
Bergman's model because there are some
significant limitations to the
physiology or that it can capture so
what we have already is we can model the
insulin glucose dynamics which much
better fidelity so incorporating those
models is one thing and the
incorporating the control algorithms is
another thing so the control algorithms
are now much more complicated they are
what are called model predictive control
algorithms which involve a solver and
optimization solver inside the
controller that's running so it every
time step the controller itself runs a
linear programming or a quadratic
programming instance so capturing such
controllers is going to be even harder
but so what we have done so far well we
have taken the top part that part is
easy to do we have modeled it we have
taken the models from the paper and
incorporated it the bottom part is a
really hard problem verifying model
priety of controllers is is really hard
it's going to be the next big challenge
if we want to be relevant to the
industry because this is what the
industry really wants to use MPC
controllers because processes are fast
and they can solve optimization problems
in real time so people want to use this
and we don't know how to get there yet
but the hope is that we will using some
of these techniques we make it there
right so to end this whole long story
CPS are quite challenging and
complicated and everyone says that you
know models of cars aeroplanes human
physiology they can be arbitrary complex
and these are these models are in human
artifacts really they are combination of
human artifacts and laws of physics and
loss of biology so it's very difficult
to say that they can be as intuitive and
they can you know in program
verification we say programs have simple
variants at least for the kinds of
properties we are interested in those
kinds of things one cannot reasonably
expect here but one can expect other
things one can expect to work in
continuous state spaces continue have
continuous sensitivity to initial
conditions have properties like local
linearize ability which means if i make
small changes to the input the output
changes will be linear in the changes I
make to the input which is a very nice
property programs generally don't have
it because we have if statements that
destroy local linearize ability control
algorithms are often designed to
stabilize the system so most of the runs
will be stable a few of the runs will be
unstable so or so that actually helps us
in verification as well because over
time as we simulate longer the system
behavior will get to the stable behavior
and and so it's very easy to do
verification for systems that are stable
okay systems that are unstable you have
to face a lot of other problems but
stable systems are are nice and easy
well behaved very faculties through
simulations so the hope is that we can
exploit these properties and more
properties which i haven't mentioned
here to make these verification problems
easy and make them even though you know
they are not decidable the the decidable
cases might require us to exploit these
these kinds of conditions so that's all
I had to say and we have a stiletto
online so it's available online for you
to use and I wanted to thank you all for
listening to me yep traction thank you
this abstraction layer to simplify the
program he knows this is coming the
first part was already abstraction of
that object well that's an abstraction
of of the of the trace yes that's right
yeah and it's a very different kind of
abstraction it's not the kind of
abstraction we are used to doing right I
mean normally abstraction takes a system
and gives a simpler system all we are
doing is here we use abstraction of
traces to give us a number that says how
close are we to violating the property
so that is still an abstraction but I
haven't done abstraction of the system
so so that would be a nice idea right
using solvers on the abstraction to tell
us how to start falsifying would be a
nice idea right now I don't know any of
any you know I don't have any front ends
to take simulink state flow and do some
abstractions so that would be a good
place to start for us and and and
already you know there are many ideas on
if you had abstractions and how could
you use them in falsification but we
don't have any yet but but yes if you
want to think about abstractions in this
work yes the use of the cylinder around
the trace is an example of an
abstraction but it's a different purpose
of doing abstraction then why we do it
in normal verification all this way kind
of marriage is very highly only on the
local system that time I was thinking
about the interaction with the
environment right so for example this
function about that the more you
accelerate more the more likely you are
to get to some later some failures day
but I was wondering if you can input
into the measure function this function
maybe the probability of going taking
some inputs rather than others so for
example in the case of the of the of the
motor it might be the case that more
people the more faster they're going
they're less likely they are to
accelerate more hi so so if you can't
just make the distance function even yes
so we have some some ideas of adjusting
the distance function so the way I
talked about the distance function I
won't bring that slide up its way in the
beginning of my talk it seems like you
use this Euclidean metric but that
that's not usually done so we really
want you know distance functions to
relate to the what this distance
actually means in the scale of the
system so so I take your question to
mean that suppose you know you have some
inputs and you know that where you you
know you may be able to make a big
change and make very little change to
the dynamics of your system so so you
might have
but given the environment i know that
it's much likely that that the trace
will actually go far from the earth and
actually getting closer so that that
actually brings in yes you're right that
brings in the dynamics into measuring so
one of the reasons this was so easy to
work and I guess I should have put a
slide on this but let me let me try and
fish out this like so okay right here so
one of the reasons this was so easy was
the robustness computation knew nothing
of the system that produced the trace
right and problem is yes that also means
that things like what you are saying you
know like incorporating some system
knowledge into how you search is not
possible right but if you can do that
then you can of course too much better
right you can people already know a lot
about you know how to control systems
that are nonholonomic and and and people
know that okay you cannot you know even
though two states look very close in the
distance sense it doesn't mean that you
can get from state a to b but those
kinds of things we can't incorporate in
this framework because that requires
breaking the box and looking into the
simulator and looking into the model we
haven't done that yet but what you are
saying is a very good idea that's what
we are hoping to try
all right thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>