<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Transactional Memory: Language Integration | Coder Coacher - Coaching Coders</title><meta content="Transactional Memory: Language Integration - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Transactional Memory: Language Integration</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KD0PhAXuKhQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay so um in this last session before
the break I'm going to try to okay it
helps if I have the slides so in this
last session before the break I'm going
to try to link together the two topics I
was talking about first of all the
transactional memory API in terms of
starch read and write operations and
then the higher level programming
abstractions such as atomic blocks and
retry and all else that we'd like to
build over that um I'm not sure I'll
quite fit this in the time so might keep
a few of the last slides from this
session over until the the next lecture
in my set so this is again taking some
of the work we did in the bartok STM
system so the code is loosely based on C
sharp but it would apply to lots of
other imperative languages and what I'm
going to talk about is how we would
build a language implementation for
atomic blocks with this kind of syntax
over the region right API so this is
very similar to be the pseudocode I
started out with we've got a queue with
some in this case some left and right
sentinel nodes and a linked list of
elements instead of an array but a
similar push and pop left abstraction
and the code within the atomic block
implemented in much the same way as it
would be implemented in sequential case
so to put an item onto the left-hand end
of the queue we allocate a new queue
node we then update a lot of pointers to
link that together making the left
sentinel point of new node that we've
allocated and making the previous
left-hand node of the list a point to
our new one so lots of pointers
whistling but the guarantee of atomicity
and isolation means that we don't have
to worry about how can go into atomic
blocks interact we just have to make
sure that this atomic block moves from
one consistent state of the queue to
another
and we like to allow the program to
implement something like that with
atomic blocks rather than using the the
low-level read and write API that the
STM system provides so the basic idea is
that will have the compiler expand the
high-level syntax into a series of reads
and writes so each of the rights to a
field turning into a call to a a write
function on the STM runtime system each
of the weeds turning into a read
function and of course although this is
in in a high-level language the
transformation here is something that
would happen during compilation by a
trusted part of the system maybe the the
JIT compiler on ahead of time byte codes
native compiler so of course the this
syntax for direct taking the address of
individual fields and making direct
accesses in the style that you you
wouldn't see is something that would be
possible in that level within the
runtime system even there's not
something that would be actually
expressible directing the in the source
language like this the approach we've
taken in the bartok STM system is to put
most of the work at this end so when
we're going from the bytecode language
internode and you just have a little bit
of support in the source code to
bytecode compiler for allowing the
programmer to express atomic blocks and
to express retry and all else and so on
and the basic motivation for splitting
the work like this is that in fact is
there's very little information loss
between the source code endure the
bytecode the bytecode still has to be a
type-safe it's not able to express
although the pointer arithmetic and
things that we use in the STM runtime
system whereas if we do this work in the
bytecode to native compiler that can be
integrated much more closely with the
runtime system and as I'll say later
late this morning on the next session
we've also got integration with other
parts of the runtime system such as the
garbage collector and that really pushes
us towards working at this this later
stage during compilation so I finally a
doing the work at this late stage also
enables a lot of optimizations I'll come
back to
some some examples of those in a in a
moment in terms of a high-level language
the extensions that we do are to
transform an atomic block into a special
kind of try catch block so when the
source compiler sees an atomic it
becomes a try-catch with a specialty
named exception and that's just a way of
expressing in the bytecode language that
this is the block structure of a of an
atomic section it's difficult to add
additional constructs the bytecode
language so there's avoids us needing to
have to modify it then the byte codes
native compiler recognizes this special
try catch and that triggers the
compilation of the code within into
calls on to the STM runtime system so
within one of these try catch blocks
we're going to do some fresh wholesome
expansion of the start and end in to
effectively boilerplate operations on
the STM so we start by repeatedly
executing this until the commit succeeds
so the start of the function will set a
flag that's going to say whether we're
done with the transaction or not will
then try executing it and if we get to
the end we'll we'll try to commit the
way that we designed the bartok sgm
system is the difficult flicked as
detected either inside the commit
function or if it's detected say when we
compete for a write lock within one of
the the data accesses then the runtime
system will raise a transaction invalid
exception we catch that at the end of
this this loop we just set the flag back
to false to say we're not yet done with
this atomic blog go around the loop
again and and try once more so the
actual starting commits a
straightforward and the difficulty then
is in expanding the data accesses inside
the transaction the UM first attempt to
this is just to turn each of the reads
and writes to a field into a call on the
the TX feed or the or the TX write
function so we can do this by a fairly
mechanical expansion of each of the byte
codes there's different ones faxing
different types fields
accessing arrays of computing various
kinds of access so within the bytecode
to native compiler we recognize each of
these kinds of data access byte codes
within an atomic blog and expand that
onto a call on to the appropriate STM
runtime system function now there's a
few problems with this basic approach
here um one of them is that we'll be
expanding a lot more memory accesses
than we really need to because um we can
see here that we we might be reading or
writing to the same field all times and
we don't really want to be going through
this call on to the STM runtime system
and doing all of the logging work every
single time we access the same piece of
data okay we might also want to handle
thread private data separately because
we know there's not going to be a
conflict between one faith and another
third if they're both at affect just
dealing with red private data so again
we can end up accidentally over
instrumenting the code is going to run
correctly but they're going to be slower
because we've instrumented more data
accesses than we then we need to have
done so what we developed to try to
improve performance is what we called a
decomposed STM API where rather than
talking about individual read and write
operations we have operations to
indicate our intent to read or write
from a to an object or to give an
address and an operation to recorder a
value that we're about to to override so
going to do is that instead of having
the STM runtime system perform these
different steps of writing to the
different logs we will expose these as
separate operations exposed by the
system and will allow the bytecode to
native compiler to optimize the
placement of these operations to try to
keep the overheads of the system as as
low as possible so let's look at what
happens during the compilation for a
couple of examples the the first one is
reading from a from a field we're
reading from a field in object p and
store it to a local variable X and that
would be turned into two operations in
the in the bytecode to native compiler
the first one is
doing the logging work associated with
reading from the object that people
thurs to and then the second and then
several operations during the actual
data access and then the second example
we're doing a store to a field in that
object and that turns into three steps
in the compilers intermediate code one
that opens the object for update which
means writing to that updated object log
another one that is logging the field
that we're writing to so that going to
store to the undo log and then we do the
actual update and the rationale for
decomposing the operations like this is
that it gives us a lot of new
opportunities for optimizing the code so
in the swap example we cite out in the
in the naive code that the that produce
the early during compilation with each
of these field accesses expanded to the
open call and then the data access so
the two leads here and then the two run
and then you can see there's there's a
lot of redundancy in this we're doing
the concurrency control for reading an
object p twice so the optimizations
going on during bytecode to native
compilation are able to eliminate this
the second read by doing a affords data
flow analysis to check which objects
we've already opened for me to access
the same is true for these updates
because we've we know we're updating
object p before this first field is
accessed and so we can avoid the extra
work on that same object for the second
field then in fact we can notice that
we're reading from p and then updating
it and so we can just acquire read
access right at the very start of the
atomic block and then that grants us
write access as well and we can
eliminate the open for right and the the
later open for read so we get quite a
substantial simplification in most of
the programs we've looked at this gets
us about a two fold reduction in the
overheads of using the the STM system to
instrument a piece of code and that's
largely by identifying this kind of
redundancy where the transaction is
accessing different fields of the same
objects in this system with all
based concurrency control so the
compiled code ends up being being
substantially shorter we have the start
and commit boilerplate that I mentioned
earlier and then the four days is being
protected by the the calls on to the SDM
system to do the Pearl object logging
before we do the update and then do the
/ field logging before we overwrite our
values in the object there's a lot of
extra complexity here um we need to
handle local variables in addition to
objects in the heap we need to handle a
references to field surpassed in using
that the byref features that are in the
internet bytecode we need to handle
method calls um to a large extent visa
there's a lot of details but the
transformation stunning in the compiler
a relatively straightforward so for for
local variables these are accessed in
in.net as in Java with a distinct set of
white coat operations to field accesses
and we instrument those in a different
way adding a second local variable to
hold the the old value storing into that
shadow local variable at the start of
the atomic blog and restoring form it if
we have a if we need to roll back the
atomic blog dandle method calls we
duplicate the methods that might be
called inside an atomic blog and produce
an instrumented version of those methods
so that we call from the if we're inside
an atomic block we call the instrumented
version every time and if we're outside
and make block we call the normal
version so that means we can do method
calls within atomic block and get this
kind of composition that I was talking
about earlier um for byref parameters we
have some integration with the garbage
collector so if we're accessing a field
indirectly then the garbage collector
provides a mapping from the address were
accessing back to the start of the
object and that then lets us access the
metadata for the for the object um we
talked about a few of the more tricky
cases that's a more specific tube dress
TM um
is an example where we've got a somewhat
contrived piece of code where we're
taking a reference to a pair object and
this TX suffix means that this is one of
these functions that the compiler is
generating so that will be calling into
this version of the clear function if
we're using it inside a transaction TX
suffix there and then within the
function we're iterating through ten
times and storing a constant value in
what fields and strong the the loop
index into another field now if we were
to instrument this code in the way i
just described we'd end up adding the
code to open the object for update at
the start here we do the the two
accesses to the fields and then we do
the two stores but we need to be careful
because a an optimizing compiler might
try to hoist this store of a constant
value out of the loop because that's
going to be looping very into it it'd
only be done once rather than on every
iteration and of course now that a
perfectly reasonable looking
optimization has broken the the use of
the STM we we're accessing the field
here before we've opened the object for
updating and before we've logged the
value that we're over writing so we need
to be careful about how the
transformations we add for STM are going
to interact with the other
transformations that the optimizing
compiler might do yeah
mm-hmm the question is what um what
actually needs to go on when we call
this opens up date primitive um what we
do in in bart request him is this this
open for update is the the steps on the
slide i had before the break where we
were looking at the version number in
this this object and recording that in
the the opened objects list the right
light set so this is going to involve a
fall about a dozen machine code
instructions that are finding the
version number for the objects are
allocating a new slot in the log and
then writing writing that version um
into the new slot so it's going to
involve the read of the version numbers
as part of that now what we do to keep
keep optimization safe and make sure
that other parts of the compiler don't
don't break the atomicity isolation that
we want is to introduce some some false
dependencies between different
instructions in the intermediate code of
the compiler so these is temp 1 and 2
are variables a pleasant at compile time
but then don't have any any one time our
component associated with them and
they're used to add data dependences
between the different steps of the STM's
work and then these data dependences
constrain what the the optimizing
compiler is going to do so conceptually
we have open for update generator a
value that we store into temp one long
for undo consumes as a as an additional
input the value out of temp one and it
produces a value in temp 2 and then the
actual store to the field consumes the
value in temp 1 so this way of
introducing a set of dependencies lets
us express the constraints between these
operations in a form that the the
optimizing compiler is able to deal with
because it already has to know about the
dependencies between different data
accesses when considering whether or not
to move code within the within a method
and so if we're going to move the store
to PA the loop invariant
store then we have to move all the
things that depends on which in this
case would be temp 2 which is the the
logging operation which in turn depends
on open for update so we could do a
transformation that's going to pull all
of those out they've been pulling the
open for object and the the two log for
undos and the store to the the loop
invariant field and just leaving the the
genuinely genuinely depend on the loop
iteration with the individual logging
operation there so we add these
temporary variables during compilation
and then just before we generate the the
native code from this we can we can
strip these out again we don't have to
allocate a a processor register to them
actually manage these values they're
just there to to express the data
dependences during during compilation
the second difficulty that we have with
integration between the SDM system and
the rest of the the tool chain is how to
handle the garbage collector because we
might have problems such as what happens
if the garbage collector runs midway
through a transaction and object is has
been made unreachable by the work that
that transaction is done well then it's
a later stage the transaction gets
rolled back we need to make sure we
don't end up with a dangling pointer
depending on how these are these
operations get ordered we might have a
contrived example such as this where we
have lots of work going on inside a
single atomic block and so it might be
quite reasonable to have a garbage
collection be triggered within an atomic
block we don't want to have to force all
of the atomic blocks are all of the
transactions in the program to be
aborted whenever the garbage collector
kicks in because that would mean that we
could never execute a program like this
now it might be very contrived to have
such a long loop running Orleans
transaction and doing conflict detection
between this work and lots of other
threads doing millions of cycles of work
that might have to be rolled back but a
more realistic example would be in a in
a modern language runtime system with a
concurrent garbage collector whether
concurrent collect
is running all of the time in a
dedicated thread and of course we need
then to integrate that concurrent
collection with the STM system so if
we've implemented it with the with
garbage collection framework at general
and hopefully that carries forward to
our systems let such as a current
collector now V so I said the idea of
aborting all transactions on garbage
collection is not attractive because it
means that long-running transactions
will never be able to commit and there's
not really a precedence for features
like that in a in a foamy language and
equally we don't want to just add all of
the transaction logs to the root set of
the garbage collector because there
could be lots of temporary data that's
been allocated within a transaction if
its long-running are that should be
eligible for collection so we'd like to
be able to to reclaim space that's used
by any any temper is that are a dead at
the other current point of a transaction
so be the intuition that we've followed
is to consider two possible views for
the heap and to make sure that the
garbage collector will retain an object
if it's our if it's reachable in the
world where transactions are bought and
also if it's reachable in the world
where transactions are commit and if we
do a validation of all of the
transactions before we start the
collection then that means we only have
to consider these two views of the heap
we don't have to consider all of the
different combinations of one
transaction committing or another one
committing we can just consider the case
of everything commits or everything
aborts because the validation will
guarantee there's no conflicts between
transactions and as at most one LED
lighting to any any given object at a at
a given time so what we do is to do two
passes over the heap with the collector
first of all a normal pass where we
consider what happens our if all of the
running transactions are able to
continue and commit and then the second
pass where we look at what happens if
all of the running transactions are
bored so in the example here
we've got the the dark how those are
showing normal references within the
heap at the light arrows are showing
over written references that some
concurrent transactions have been
manipulating so maybe there's a local
variable root pointer here and that
makes their spine of the list reachable
and then there's other bits of the heat
that have been manipulated by
transactions some of which are
unreachable from the rest of the heap
others of which have become unreachable
because of the updates his actions have
done so we start out by my validating
transactions as I said and rolling back
any that that have experienced conflicts
already and then performing a normal
garbage collection using the state of
the heap that the transactions have left
at it so in the normal terminology for
GC these these dark objects of the ones
that are reachable from the normal
routes there'll be some gray objects
which are ones that the collector is
currently scanning and then the white
objects are ones that are are not
reachable so far so we won the garbage
collectors normal and that identifies
that the spine of the Lester's is
reachable we then roll back all of the
work of the current transactions we keep
the logs so that we're not actually
aborting them we're just undoing their
effects temporarily and then we'll
restore again before we resume the
threads and we markers play any objects
that have been been updated by those
those transactions so in this case this
was a black object before that we've
updated by one of the transactions so if
the transactions were to be rolled back
this could become a root of some new
piece of the heap that gets reachable
again and then we leave on the
collection tracing from those grey
objects marking everything that's
reachable form them so we know at this
point that the spine of the list is
reachable if the transactions all commit
and the death of transactions all abort
then this additional old version of the
list at the top here would become
reachable again but the nodes down at
the bottom er are not going to be
reachable so we can reclaim those then
restore the heap are letting the
transaction to continue and then let
them then execute on
there's a a slight additional
complication for finalizes in NC
sharpened in java and these are a
methods that executes when an object has
got reclaimed by the garbage collection
so typically there's a thread that runs
finalizes and the garbage collector
hands off to it a queue of finalizar
methods to execute so we could write a
anatomic blog like this where we
allocate an object with a finalizer
inside an atomic blog and then we look
at what happens with this finalized
method maybe it's going to do some snout
but that's visible to the user and the
question here is what happens if that
atomic block is attempted multiple times
do we actually collect this object
multiple times and potentially run this
finalizar or is the rollback of the
transaction going to stop the object
from being being finalized about may be
in effect making it look like it was
never allocated in the in the first
place and in this case and in a lot of
the other ones where there's ambiguity
over the semantics though the principle
we followed is that we want atomists
into isolation so if the program we
wrote that atomic block that allocates
an object with a finalizer then the
programmer should just think about that
atomic blog running once with atomicity
isolation they shouldn't need to think
about the runtime system trying it
multiple times until it gets to commit
so we roll back the allocation of the
object we don't run the finalizer on
those those tentatively allocated
versions so we're just a wrap up today
by talking about the retry constructs
and how we go about building that from
the sodo a couple other things but let
me just continue with v try construct
and how we build that over the the kind
of barter guess TM system that I that
I've described um so here's a version of
retry using a fairly short example we've
got a buffer that this they're
destroying data into and setting a flag
and then the second third is going to
call retry if it sees that the buff is
not full
consumes the data and clears the flag so
semantically we want this atomic block
to be delayed until this first one is
executed and for efficiency we want to
avoid spinning so we want to block this
thread until it sees the commit from the
thread on the left-hand side the way we
support this is by adding a new
primitive to the STM runtime system for
weight transaction and semantically this
is the same as aborting but it's allowed
to block the thread for a little time
until another threat is committed an
update to one of the objects that we've
read from so this is going to help us
make the very operation efficient by
letting it block until someone commits
an update something is read from so no
point in executing the consuming thread
here until the produce has executed
retry compiles into a a call to wait TX
okay and as I said semantically this is
equivalent to aborting the transaction
so wait TX is going to block a little
while and then raise the the TX invalid
or TX aborted exception which will
propagate outwards to here and then
we'll real catch it and go around the
loop a second time the work within wait
is going to actually deal with the
rollback so that we've undone all the
tentative work the transactions as it
has attempted to implement this um
conceptually we add another header word
onto the object and we use this to
represent a queue of threads that are
awaiting on a change to the objects
fields now in fact is there's techniques
we pick up from other parts of the
runtime system to avoid us needing to
have this this succession of extra
fields taking up space and every object
in the heap so we we try to allocate
these extra words only in the case of
objects that really need them but to
simplify the slides I'll show these as a
set that distinct our header words in
the heap so we've sent ahead a word with
a wait list and we extend every
transactions record with a mutex and a
condition variable that are going to be
used to control waking and sleeping that
transaction
so the thread that's running that
consuming transaction along with its
normal logs for the locations it's
virgin written to it's got a lock under
and a condition variable then in the
weights transaction call we are using
atomic compare-and-swap to link this
consuming thread onto a waiter's on the
object and the thread is going to to
validate the transaction to make sure
that it's it saw a consistent view of
the objects and really should be going
to sleep and then it's going to sleep on
the condition variable in its
transaction record now when there's a
commit operation that commit is going to
in addition to updating the version
number in the objects that it's updated
it's going to check whether there's a a
non-empty list of waiters hanging on the
object header and if there is a list of
waiters is going to lock each of these
in turn and signal its condition
variable so that's going to do the the
support for blocking that we need will
be delaying the consumer thread until
someone's made an update to one of the
one of the objects that it was dependent
on and it's then going to be woken via
this this condition variable that we
have in it its transaction record ever
in fact is the technique we use for
managing these header words as based on
the thin locks idea from many JVM
implementations we start out by not
having additional header words on the
object and only when we access an object
inside the transaction do we add space
for the version number and only when we
block on an object using retry do we add
space for the for the wait list um in
fact it's rather than just having a
single link here we need a doubly linked
list that we thread through the
transaction records and the reason for
doing that is because we might have
multiple threads waiting on multiple
objects and multiple objects being
waited on by the same thread so we need
a slightly more complex a linked
structure to associate these but i'll
just use a single one here to keep the
keep the slide simpler
at the last a tropical talk about is
just one aspect of how we need to ensure
isolation and particular problem here is
one known as zombie transactions which
ones that have experienced the conflict
but not yet detected it and we need to
be careful about zombie transactions
because they might do all kinds of
things that are that reveal themselves
so for example they might enter an
infinite loop depending on the state of
values that they see if we're using lazy
conflict detection never get to that
final step at the end of the transaction
where they do validation so the
particular problem here is for example
we've got two transactions running in
different threads the one on the left is
running an atomic blog that reads from
two fields out of an object and then if
the values differ enters a loop and the
one on the right makes updates to both
of those fields strong the same value in
each so let's imagine that the are all
over the threads and system are
maintaining an invariant that a and B
hold the same values and because the
programmer just ought to think about
atomists into isolation this is a
perfectly reasonable thing for them to
write because the transactions running
in isolation that amiss you're not going
to see a distinct set of values in a and
B so this endless loop should should
never happen but with the runtime system
and the compiler that I've been I've
been describing it's possible for this
to go wrong because it could be that we
read from a here then there's a context
switch we run this second transaction in
its entirety and then switch back to a
again and read from be so maybe the two
threads night out at zero and we read
from the two fields that we read from
the fields again and we'll end up with
sing 0 for a and 104b see the values
differ and so enter the the loop so that
would be an incorrect thing for the for
the runtime system to do yeah
ah so the questions these are supposed
to be atomic blocks so so so there
shouldn't be an atomic context switch in
the in the middle and that the problem
here is um it we want to build atomic
blocks with the semantics of their
atomic but this is really fixing a bug
in the implementation that I've
described so far it's one of the areas
where the lack of atomicity in in the
basic implementation is revealed so so
so it's a one option as you say would be
when when making a context switch to
maybe to validate the transaction before
continuing or to go back to the start
and reacts acute it but the the problem
then is if we actually had a
multiprocessor machine we might be
running these on different processors
and it could just be that because of the
non-deterministic timings of the machine
maybe this processor is are interrupted
for some other task when this second
processor runs the the transaction on
are concurrently with it so we need to
to handle this case in the runtime
system and make sure that we detect this
this lack of atomicity in this case and
the approach we've taken with with
bartok STM is to actually add another
function to the runtime system API
called validation tick and to ensure
that the compiler puts calls to this
validation tick function in all of the
places where looping is possible and I
do is that this is going to guarantee
that we'll do validation in addition to
the the commit time validation and
detect in in this case that we're in
this loop and we've got in the loop
because we saw an inconsistent set of
values for 4a and 4b so the compiler
adds calls to validation tick into any
loop or combination branches that could
lead to lead to looping
are we optimize the implementation of
validation tick so it's as lightweight
as possible while still guaranteeing
that eventually it will notice a
conflict and we execute the transaction
so I'm going to stop there for today the
tops i'm going to talk about in the next
lecture are looking at some of the
semantics of a an STM system in more
detail so i kind of touched on some of
that with this validation example at the
end that there's lots of ways in which
the automaticity or isolation that we we
wish to provide can be can be leak and
leak out of the system a particular
problem is what happens if we're doing
io operations inside the atomic block
and we want to write to the disk or or
read from the user and a problem I
touched on a few times which is what
happens if the program is reading from
data inviting to it in transactions in
one fed but reading and writing to the
data directly in the second thread we
need to sort out what the semantics for
for those operations should be and what
we should do in the implementation to
handle that so in the next one set of
the TM lectures I'll talk about some of
those semantic questions and then in the
additional lecture which i think is
scheduled in between I'll talk about
some of the work we've been doing quite
unrelated to transactions in the bowel
fish research OS projects on some of the
language abstractions for programming
multi-core systems and apps are that
very different setting so a little bit
about recent research and bowel fish
next and then in the next TM lecture
mourn the semantics and how we provide
atomicity and and isolation thank you
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>