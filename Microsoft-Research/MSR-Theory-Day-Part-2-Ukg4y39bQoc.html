<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MSR Theory  Day - Part 2 | Coder Coacher - Coaching Coders</title><meta content="MSR Theory  Day - Part 2 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MSR Theory  Day - Part 2</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ukg4y39bQoc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
we're we're back and next we'll hear
about from Sebastian boo back with based
right here about the influence of the
seed in random recursive raps injuries
yes thanks given okay so this is going
to be a fairly simple talk in the sense
that i will talk about probably the
simplest possible model of random
evolving graph and i'm going to us
possibly the simplest non-sugar question
about it and we will see that the answer
will be not so simple okay so the star
of this talk is going to be this object
you a n so n is an integer un is going
to be a tree on n vertices that I define
as follows through the season 3 a random
tree on n vertices and i define it by
induction like that you a one is just a
single node the unique tree on one load
and you a n plus 1 so you a stands for
Uniform attachment so you have uan here
and then I'm going to add a new vertex
and plus 1 and n plus 1 is going to
attach to a nor ready existing vertex
which is chosen uniformly at random ok
so it just sends an edge like this to a
vertex chosen uniform nation ok now the
question so that's the model we are
going to look at and the question that I
want to ask is the following imagine
that you observe a snapshot of this
random Network at a certain time k ok so
observe a snapshot
at time K okay meaning that you observe
you AK the question that I want to ask
is does this give you any information
about the future evolution of the tree
okay so does this give information about
you a n as n goes to infinity okay so
maybe I'm going to stage this a little
bit more formally but it seems like the
information that I obtain that time k is
going to decay as n goes to infinity and
I'm going to be interested to see how
fast it decays and things like that that
would be the natural thing to do but we
will show more surprising result which
is that this information at the finite
time k gives information about uan for
any time step even at infinity so more
precisely what I want to do is that I
have you am and I condition on you AK
being a certain tree okay so I want to
look at the conditional distribution of
you am given that that time k it was a
certain 3s and I want to note that this
depend on us or not so the only a finite
number of trees on cable teases so what
I'm going to look at is I'm going to
look at two of this point okay two trees
on K vertices let's say s and T and I
want to know other two distribution uan
condition on ua ua k called s and you am
conditioned on ua k equals T do this
distribution in the limit become the
same pun or do they stay different so in
other world I will look at in other
words i will look at the total variation
distance between these two object and i
want to know what is the limit as n goes
to infinity okay so if this is strictly
positive it means that observing a
snapshot that time k at any finite time
gives me a lot of information about the
future evolution of the tree and the
serum that we
will prove oh but I will tell you a
little bit about how we can prove this
time is that this limit is always
strictly positive okay so let's call
that Delta of s and T by definition is
this thing and the serum that we proved
so it myself 1 and L done was we CDs I
don't know a postdoc here and Hannah
muscle and Mickey rats who was with a
graduate student and vanishes advisor
and it was my intern so we proved that
for any s not equal to T Delta s T is
strictly positive not equal of course
means non isomorphic okay to have two
tree is known isomorphic I need k to be
at least four okay so this is so that's
that this year your total variation is
just after I smartest right fess yeah of
course so yeah this this tree on n
vertices it's an isomorphism class right
so its of course up to isomorphism ok so
I could have asked the question do you
think this limit is going to be 0 or not
and the natural ancho should be yes the
limit of course is going to be 0 I don't
want to ask this question but let's see
why how come this could be possibly true
okay so i'm going to show you why this
could be possibly true so let me give
you an example which is which is going
to use heavy machinery already to prove
that even in this case is strictly
positive so let's say that s is a star
on k vertices okay so it's something
like that so it's star on K vertices and
t is a long pass okay to pass and K
vertices make that
okay so why observing this or that gives
me information about the future well
it's going to give me information about
the future because the diameter will be
a differently if K is large enough so
let me tell you two facts about the
diameter in uniform attachment trees so
fact one it turns out that the diameter
of a uan this is asymptotically as n
goes to infinity almost surely
equivalent to ill again okay so this was
proven by Peter in 94 so actually the
proof even though it was not the result
was not explicitly written already
appears in result of DeVry in the 80s so
that's the first factor case of the
diameter is this but here is a really
crazy one very very impressive so if you
look at the violence of the diameter
this is all of one okay so despite
uniform attachment being this completely
random process right so diameter is very
tightly concentrated it's basically a
log n plus a constant okay actually it's
not entirely true it's ill again plus a
constant log log n plus this burns down
okay and this was proven by adario berry
and read in 09 ok this was open for very
very long time it was first proven that
it was over flogged and and off scott
log n log log n square root log log n
and finally ofone okay so this is really
non-trivial so now let's see how we can
use these two facts to see that on this
example the total variation in the limit
remains bounded away from 0
alright so I want to look at the
diameter of uan conditioned on you AK is
a star and sorry I wrote things for the
diameter but these results are for the
heights they have also true which draws
a diameter with the two but let's use so
this is a height okay so there is a
natural you have to specify you have to
fix the root at the beginning alright so
the diameter of qan given that you AK is
a star well this is bounded by the root
is the first vertex in those two result
ok but don't note that in my description
there is no root ok when when I give you
when I hand you a tree you don't see
your route somewhere ok there is no root
but this resort are when you say okay I
specify a route so let's say what let's
see what is this diameter well here is a
picture right you you started with this
and now everybody is going to grow right
like that the diameter of course is at
most the diameter in a tree that most
twice the height ok and here the height
is going to be bounded by e.e log n plus
a constant so the diameter is going to
be bounded by 2 e log n plus some
constant wefi probability and the plus
constant is because of this result ok
good all right so that's that's clear
now let's look at the diameter of you
a.m. when you AK is a pass
okay so you started with this and you
have grown trees here everywhere of
course this tree is right if I just look
at them they are their distribution
condition on their size are the same of
uniform attachment given that size right
so now here you can see that the
diameter is going to be larger than I
can take the height of this one plus k
plus the height of this one okay so it's
going to be larger than k plus okay how
many vertices will i have here well with
reasonable probability i will have at
least n over K ok in this so it's going
to be at least diametral k plus 2 e log
n over K minus the constant of the bands
with not reply poverty but with let's
say with reasonable probability okay all
right so so now you see that the
diameter on this one is going to be
larger than this one as long as key is
darker than this constant where this
constant is just a universal constant
that depends on the variance of this so
we see that when K is large enough I can
tell if you want given an observation
which is a large tree I can tell you if
if you you started with that with s or
with T because I can look at the
diameter if the diameter is large enough
i will say ok you started with this one
that's that was in the past you don't be
higher moments I mean it's not necessary
ok just felt very yeah you can lead I
just do a zero Saturday the Pharaon so
no or not so so here you can just do
chebychev right and have a certain
constant that depends on the balance and
this will happen for 80 at this point
nine right off point 99 and then you
need this one to be a little bit louder
than point 0 1 0 so it so this is fun it
seemed
the way you described it it doesn't
quite seem to follow from these two
facts okay I wonder says it's absolutely
have x 1 plus lay your you're totally
right so the truth but I you know
sometimes you have to lie a little bit
is that there is plus some constant
let's call it be log log n ya in both
places with the same be and this indeed
does not follow from this but it is true
very slowly and okay it still works it
still does work yes absolutely that's
that's true that's right okay good so we
see that in this to example the socio am
is true now this is a very this is very
fragile right I mean I needed this path
to be very long and i'm comparing to a
star okay of course if i compare even a
very long pass to a very long pass where
i have added right if i could if i add
somebody here if I had somebody there
this proof technique is not going to
work the diameter will be the same
essentially so you need to go beyond
diameter to to see the difference in the
limiting trees so now I will tell you
how we prove it in general okay so the
general proof I won't have time to give
you the intuition of where it comes from
but but i can i can tell you if line if
you want and then i will conclude with
some open problems but i want to tell
you the general pop because there is a
statistic that can distinguish the seed
okay another point of view is that you
want to know what is this seed s okay
alright so the general proof is going to
go as follows so I need some definition
I'm just going to define a decorated
tree okay so decorated tree tau and the
scope like that it's a tree together
with a decoration okay and what is the
decoration the decoration it's a
labeling of the vertices okay so L it
goes from tau 2
the integers and the way we are going to
think about this labeling is that you
put arrows on the tree ok so imagine
that tau is this ok let's see this is
thao now the decoration is going to be a
certain number of hours on each node ok
so maybe I have two arrows here one hour
there and one hour 0 ok so that's a
decorated tree next I'm going to define
a decorated embedding off a decorated
tree into another tree ok so i have a
decorated tree i have another big tree
and i'm going to define the decorated
embedding which is going to be a certain
way to embed this decorate the tree into
my bigotry so decorated the embedding
let's go 85 are so Phi bar is going to
be defined as follows so I have my tree
T ok it continues here it continues
their continued there ok so this is this
is G all right my decorated embedding
the first things that I need to do is
that I need to embed tau into this
victory so here in the way I drew it
it's obvious that i have embedded tile
right here ok so tau is right there now
i need to embed the decoration I need to
embed the elbows so I had two hours
there what I'm going to do is that i'm
going to put i am going to choose two
vertices in that sub tree and i'm going
to put the arrow there ok so i need to
choose two vertices here and i put the
out there here i add just one hour also
i need to choose one vertex nuts in that
sub tree i put the other and here i had
also one arrow and I put a bit yeah ok
so this is a decorated embedding I am
bed the tree and then I embed the arrows
ok took the arrow and I embedded in the
corresponding subjects all right next
I'm going to define F taobao of T which
is simply the number of decorated
embedding of tau bar into G ok so this
is none
of these guys ok number of decorated
embedding of tau bar into T now the key
observation is the following the key
technical observation is the following
the expectation of F tau bar into a uan
if I look at the number of decorated the
meeting of a certain decorated tree into
you uan can be expressed as a function
of the expectation of F double prime of
U a n minus 1 for toggle prime which is
smaller in a certain sense the towel bar
ok so again I can express this it's this
thing ok the number of decorated
embedding I have a recurrence formula as
a function of the same expression the
number of decorated embedding but for
smaller sub trees so what is this
smaller it means that the size of top
prime is smaller or equal on the side of
town and the weight of tau prime is
smaller than the weight of tau whereas
the weight is just with some of the
labels so the total number of arrows
that I have in tau crime is smaller than
the total number of hours that i have in
top ok so this is very very easy to do
because this is just a few lines you
just need to work a little bit so now
what does it mean it means that i can
find the martingale in the span of those
things so in the span of the f of this
statistic so this statistic of course i
can compute them given a big tree i can
compute the number of decorated
embedding of a certain decorated tree
into tau and now because of this key
observation i just said that in the span
of this thing so in the span of the F
tau prime of U am the linear span when T
prime is smaller than
I haven't I have a martingale okay just
because of that now the key will be to
show that I can find nothing else like
that which are bounded in l2 okay so
they will have a bounded variance and
because they are martingale and of
course at the beginning they are
different okay if I look at the number
of decorated embedding of s into S is
different from the number of decorated
the meaning of s into T which is zero I
cannot turn bad ass into T so I know
that they are different at the beginning
they are Martin girls I will stay the
same in expectation and I have to show
that they are bonded in l2 and then that
will allow me to distinguish in the
limit okay so this is the proof now I
want to say just the open problems and
something about references so this proof
technique was not invented by us it was
invented by Nicaragua and his cross oh
so pure too mad you can a bunch of
French people God schmansky Scott
Chomsky and my no less cool yeah but
they are fridge so that was a few months
ago and they invented this proof
technique to solve an important program
that we had in my work with her Hannah
and Mickey from before where we asked so
what we did is that we asked the same
question but in the preferential
attachment model so in the preferential
attachment model it's the same
description but when somebody comes in
he connects with somebody chosen at
random but with probability proportional
to the degrees so if somebody has high
degrees only we are going to be more
likely to connect to him what we proved
is that this serum was true if SNT have
different degree distributions okay and
and the way we did it was sort of
similar to the diameter but for the
preferential attachment meaning that we
looked at the max degree and then these
guys came in and they
they did this except that it was
different in the sense that their notion
of decorated embedding is the local so
it's the same thing except that the
arrows instead of putting them in the
subtree you have to put them in corner
around around the vertex so vertex that
as a degree like this right it goes like
this and in what kinetic did is that the
arrows they embed them in this corner
like this okay so in some sense there
embedding his local you embed the tree
and then you embed the hours locally
around the tree in our case the
embedding is non-local and so it's more
complicated to show that these mounting
gets a bounded linear to but the proof
scheme in any cases was developed by
those guys now open problems so let me
define Delta alpha between S&amp;amp;T where
it's the same thing except that now the
model that we look at is that somebody
comes into the network is going to
connect with priority proportional to
the degree to the Alpha okay so uniform
attachment is alpha equals zero ok
degree to the 0 is 1 so you connect
independently of the degrees
preferential attachment is alpha equals
1 so now we know that this room is true
that our advice is always strictly
positive if our 50 or if alpha is 1 what
about all the values of alpha ok we
don't know this is open and maybe even
more interesting is what can be said
about this function alpha gives data
alpha of st is it monotone convex I
don't know ok so is it easier to to
seesee so is the influence of the seed
stronger in the preferential attachment
mother or stronger in the uniform
attachment model trivially one would say
that it's stronger and preferential
attachment but it's not so obvious so we
have zero idea on how to attack
question alright I will conclude here
Thanks yes on very simple question as K
goes to infinity with to the size of the
small piece does delta go to 100 the
maximum question so in this case the
answer is yes okay and that can be seen
by those calculation in general we have
we don't know of course but let me tell
you one more open question since justice
let's say Jesus ok it's a pass like that
and an S is pass like this except that
at the end you have a little fork length
so I wanted to ask how fast does this
does the TV between those two things go
to 0 as K goes to infinity okay but it's
not it the more I think about it the
more I think that even as K goes to
infinity the TV stays bounded away from
zero between these two things which I
was even wondering whether goes to 11 no
oh no no no I cannot believe that no
it's a sure it's not done to go to him
because right away there's some positive
probability of coupling now there's a
small bit goes to ye assuming against
another point as K goes to infinity
let's make this local ex seem to seem
too that's it no agencies to it cannot
go to one why not
but I waited the first time that you
touch the right hand side we positive
programming yeah I think this is what
you can you can copper them have it but
but it could be that it remains strictly
positive and and this type of question
we'd have to go way beyond this because
this is this is nice just because of
this observation which makes all the
calculation tractable but this is very
weak I mean it's not it's not at all the
best at this legal procedure it's not
even radial statistical procedure so
what's the problem with them being you
know in yours oh they're embedding would
absolutely not work so because because
it's local so it's local its its it's
telling you something about the degrees
and the degrees in uniform attachment
they are all over the place they tell
you nothing about what was at the
beginning so in uniform Atta is a key
new insight that we have is that in
uniform attachment you need to look at
sub trees instead of looking at degrees
which is that's it is a distance right
yeah so we looked at in this paper we
also looked at week limits so but in so
weak limits mean in the Benjamin isham
sense but in that case it's obvious that
this always goes to 0 because you only
make a difference locally we so this is
joint work visiting channel and being a
loop from ms are in asia and mink it's
from my ankle article university of
singapore so is this talk i will argue
why we should be doing competitive
analysis against a variety of benchmarks
as opposed to doing it with respect to
individual benchmarks so
so in the competitive analysis like from
the high-level point of view what we
have we have we we need to give an
algorithms that for some objective
maximizes maximize this objective for
any input and the integral part of any
problem any problem in within
competitive analysis the benchmark so in
what is the benchmark it's basically
describes the desired outcome which is
usually specific to a problem so you
could have a problem then usually this
benchmark is something like optimal
solution for a given input and give an
objective and normally what we do we
minimize competitive ratio which is the
worst-case ratio of the benchmark over
the algorithm and normally we think of
algorithm being handicapped compared to
the benchmark by handicap well some
examples are like online algorithms so
you should do something online where
benchmark is offline or I don't know
actually you can do it for mechanisms in
all going game Syria where the mechanism
must be truthful and the benchmark is
something that doesn't need to be
truthful or algorithm must be
computationally efficient in
approximation algorithms and F is just
like arbitral I think it doesn't need to
be computationally efficient but like
here it's important and really integral
part of the competitive analysis
paradigm is a benchmark and as I said
here well usually the benchmark is fixed
and we never think about changing it so
it's like we have a problem which mark
is given and here it is but actually
sometimes but this is quite rare
occasions people look at variance of
benchmarks so different variants of
desired outcomes
so for example you might have different
objectives like an a GT we have the
social welfare or revenue as an the
outcome you will be wishing to achieve
is different so this happens is
sometimes so people consider more than
one benchmark well even more air people
actually do like FML of benchmarks you
might consider like a family of
well-structured functions may be single
parameter maybe like an parameters but
some not very wild family I probably
have seen like a couple of paper senses
but by at large people do it very rarely
and actually I never seen results of the
following form where we look at very
abstract problem like give me any
benchmark or maybe benchmark from very
broad class of functions and tell me
something what would be your competitive
ratio is respect to this abstract
function so if you'll never seen a paper
of this one maybe there are some but I
know nothing and in this talk I will try
to convince you why is this kind of
question deserve much more attention
that we are paying to it so to give you
some context I will be talking about
this very nice setting of digital good
options and some close relatives of it
so in this setting we have one seller we
have n buyers and we have just one good
for sale and let's say it's a digital
good like this CD and we can make as
many copies as we like so we have
essentially unlimited supply here and
buyers they have some private values for
single copy of the items they just wanna
one chorizos am this is called unit
demand and here what we are willing to
achieve is some kind of truthful auction
so we assume that people this buyers
they submit bids and I'm so develops and
then the seller decide on who gets item
and how much they pay and he won ensure
that it will be of the best interest of
buyers to report truthfully to tell
there are two values
so this is kind of restriction on the
algorithm or auction here and as a
seller we want to mix in my maximize our
revenue so how much we buyers pay to us
and as as we are in this worst-case
analysis paradigm we want to compare to
some benchmark so this is essentially
unlimited supply setting so very simple
so you can imagine doing some kind of
variations of it for example if we have
a limited amount of resources let's say
two items or like some limited amount
less than a number of buyers so this
setting is called limited supply you can
also imagine doing something online here
like let's say we return back to this
unlimited supply case where we can make
as many copies as we want but now buyers
arrive online so they they do not come
all together they come sequentially one
by one in a random order and then we
need to decide on the location and
payments right away once they arrive so
for example the first guy arrives we
give you an item charge payment the
second drive arrives so on and so forth
okay forget about online options you can
also consider some more generalizations
and variants of this problem so for
example maybe you cannot serve them for
sure but you can serve them the certain
probabilities like in position options
you know you can give allocates on some
slots and then each slot will correspond
to certain probability of clicks or
eight and only certain vectors of
probabilities will be feasible so we're
going to mention some space of what's
possible vectors of probabilities so
this called general environments
actually they call like general don't
work clothes permutation environments
and like a good example of them is this
position options so quite important
setting alright so haven't talked about
benchmarks so for the settings people
have been considering
the most standard one is this one f2 for
unlimited supply an online case so this
is best revenue you can get with a
uniform pricing so imagine you said the
same price for everyone and then buyers
with a value above this this price will
buy so your revenue will be I times VI
but you see there is this technical
conditions that there must be at least
two buyers so this is because just
imagine that you there is one buyer with
value V ones there is no way to to sell
item to him and get his entire value or
even a constant fraction so there is no
constant approximation constant
competitive auction just for one buyer
so that's why there is a technical
assumption to get to get some
interesting results so for limited
supply and position options people
consider some kind of generalization of
this f2 benchmark this is called envy
free optimal revenue if all for short
where we again need to do this we bring
down the highest value guy so basically
the way people do it is by trimming the
vector taking the highest value guy and
bringing him to the second highest and
also since the problem might be like
with in some feasible region we consider
this enemy free optimal revenue
allocation achieved in at some feasible
occasion so I'm not going to describe it
in full details but like that's not
going to be a super important for the
talk but just give you some sense of it
in the limited supply case there is kind
of a simple way to bounce this benchmark
between f2 taking for the highest k
values so you have this in quadrant
alright so this was a problem okay let
me so this setting was around for like
roughly 15 years people have done quite
a lot of research route it so let me
just describe some latest sayings so
there was a work by Goldberg hardline
curling sucks about unlimited supply
auctions so they gave a lower bound of
2.4 the two against f2
and actually conjecture that this should
be tight so they construct assam worst
case distribution and calculated the
value was for this distribution of
inputs and for limited supply case
diviner and hardline gave us two factor
reduction from a limited supply to
limited supply case so and this
reduction is super simple remembers this
inequality on env3 benchmark is just it
was to to bring two times f2 benchmark
so this is essentially the proof so for
online setting cuts appears and Baracus
gave two factor reduction from off from
offline problem to online and for
downward closed environments hein
hardline had very very clever mechanism
and they showed that it's eleven
competitive and then nikhil came and
made it much more complicated so that's
kind of how quite elaborated version of
hein hardline mechanism but with better
competitive ratio 7.5 okay so basically
talking about our results just want to
emphasize that this simple idea of
looking at at the class of benchmarks as
opposed to like you know studying very
particular benchmark was give us further
along right so it really helped us to
get improvements over all these sayings
so for unlimited supply case kind of the
most important step in the proof was the
following thing so for the family of all
monotone benchmark so imagines that
somebody tells you any function that is
just monitor on and you want to ask
answer the question what is the
competitive ratios respect to this
benchmark then it turns out that you
don't need to look at all possible
worst-case distributions that you might
imagine trying if you want to use like
mini machs principle but instead do much
more narrow set like search within some
kind of small class of
worst case distributions so basically
that was kind of very you know general
statement that doesn't give you precise
numbers but basically given the step
second we actually managed to show that
for f2 you get this tight constant 2.42
and actually the analysis extends to
like actually variety of benchmarks so
you don't you can do it not only with
respect to have to but like actually
some family benchmarks if you want to so
that was quite helpful ideas are so for
the limited supply case again this idea
actually gave us improvement from factor
2 to this beta plus 1 and given that
beta is actually the best thing we can
get is this 2.4 it to its kind of
significant improvement and actually I
will show it the argument it's super
simple so for the online setting so kind
of very similar idea just gives gives
you dt plus 2 improvement over to beta
and actually you can do even better if
you kind of exploit this idea further
because basically you know here the
benchmark you use in offline world is
the same as you use in online world but
if you use different benchmark in
offline world you can actually improve
this constant even further so actually
it's very helpful to to switch gears you
know in offline setting compared to
online settings we use different
benchmarks and finally so for downward
closed environments we actually also
improves this constant 26 point 51 but
what is more important that our
mechanism is kind of much simpler than
the previous best known one so it's it's
essentially the original hind hardline
necklace with some with different tuning
of parameters plus single item Vickrey
auction so it's essentially as hard as
this one
so okay right ok so now I want to move
to blackboard actually yeah ok so
whiteboard and as we say in Singapore
inna also can so all right
so imagine that we have two benchmarks
let's say we have benchmark f1 is a
benchmark with comparative ratio than
the one and let's say f2 it's another
benchmark with competitive ratio I'm too
so there is a mechanism or auction or
algorithm with competitive ratio lambda
1 and there is algorithm optional that
work with comparative racial under two
so what you can say about their son so
if your benchmark is the sum of two so
what do you think what would be your gas
take the average of marks and well max
is impossible because it mentions that
f1 is equal to have tools and you know
you're Asia should be basically it
should increase x factor do right so if
you multiply your benchmark divided by
two should increase by two so well so
that's reduction where the Sun and the
proof is just one line it's super simple
so what do you do so imagine that here
we have algorithm a one here we have
Congress make you what do you do you
take on this combination of 81 and 82
with with different weights and because
this guy is a lambda 1 competitive to to
f1 so we can substitute this with f1
right so it's at least and this guy is
at least after fine so we get that this
listen tiresome is at least one of my
plus f 25 / + 1 + 12 g 0 lambda another
who Linda nervous hmm yes well of course
it but not precise so if you have
estimates you can get this estimate eh
any case there is this kind of lemma
super simple and only gives you
something you know for limited supply
case so okay show you
does it work
so well you know i'm just avoiding the
definition of any 420 but basically for
limited supply keys it's really easy to
show that it's at most f 2 of size sv k
plus K times e k plus 1 where we just
order guys this is sweet so there is
this upper bound and like certainly list
can claim that Jason unit so it's not
surprising fact for him because for like
limited supply case actually there is a
but quite simple description of this
sank you essentially to take a revenue
curve and basically take a convex in
develop of it and then take value at k
and then this statements just like some
simple fact about like single parameter
convex function this is it so nothing
fancy but once you're here you see you
already can get this improvement because
you can say well look let's let's say
that this is my bitch mark one and let's
say this is my benchmark tool so if this
is your first benchmark well you get
immediately competitive ratio p time but
if this is your second benchmark well
you can run simple BCG mechanism with k
plus 1 items you allocate kk k items so
this is feasible with your number of
items so you can do it and the
competitive fridge is just one right
so basically we get beta plus 1 right
away so it's kind of very simple
improvement and what is the present you
know like different groups of people
work on this and say you know missing
the simple idea I'm sure that you know
this family's quite well-known to you
know people doing you know yeah well I
mean comparative analysis it's it's like
it's it's super simple but basically i
think what was missing is this
philosophical point of like moving from
single benchmark to variety of them so
okay oh okay how do I
actually I'm almost done so and just
helped us slide Julia rice now it's good
to race so noon would have this good
system you put this green sank so that
it's good to race or if you dread saying
this is to motivate there is something
super important ok so the racing a few
lots of cool points that are good to
discuss here so white large we do not
study this classes of benchmarks you
know in this particular problem that was
quite useful you know helpful super easy
to do so maybe you should be doing it's
more often and like here are some points
the day see that a good general for
doing this more general problem it's
like imagine that you want to do some
kind of applications or like you want to
approach some managers and say well look
we have as a result you know then it's
good to have more flexibility you know
like saying that well ok handle not only
this problem but maybe something you
know around it so generally you know
doing it for a glass of benchmarks gives
you some kind of more of description
power and like you know as an example is
a digital goods auctions world well you
know it's of course goods that we can
handle this f2 benchmark but imagines
that we are approached like certain
people they have well right they might
say well look you have this two point
for the two approximation but maybe my
market is big like you know middle size
are large and I have like I can almost
for sure say that they will be at least
ten good bidders like high value what
buyers then you know maybe it's a good
idea to switch benchmarks and actually
you might be able to show better much
better in our competitive ratio and you
know that's but much better you know
selling peach so another thing is more
theoretical nature so imagines that you
want to do this kind of reduction so you
study a simple setting but like you want
to use this results for another more
general one or related and well then
it's kind of easier to adopt you know if
you have this general results and
actually that was all the way
good example for this offline and online
business okay say should still very soon
so and also the last but not the least
it's it's very helpful to worry no even
improving results because even if you
care about very particular problem about
very particular benchmark then maybe you
can decompose it and you know get better
results and this last point actually
leads to another question maybe you know
we can develop better Cerreta cool tools
like you know providing more general
techniques for you know getting the
general statements about composition of
benchmarks okay and actually quite
interested in this last question kind of
broad philosophical question like given
any setting how you know we would where
is a benchmark that's the thing quite
interesting and probably should look at
you know variety of them okay so thank
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>