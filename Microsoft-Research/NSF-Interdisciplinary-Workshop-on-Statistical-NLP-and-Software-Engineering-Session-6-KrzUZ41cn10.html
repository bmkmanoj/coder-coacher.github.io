<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NSF Interdisciplinary Workshop on Statistical NLP and Software Engineering - Session 6 | Coder Coacher - Coaching Coders</title><meta content="NSF Interdisciplinary Workshop on Statistical NLP and Software Engineering - Session 6 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>NSF Interdisciplinary Workshop on Statistical NLP and Software Engineering - Session 6</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/KrzUZ41cn10" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
um so we were hopefully going to spend
this hour talking about ontology xand
understanding and formulating semantics
for software and I won't thinking for
opening this session with a talk about
billing software anthologies thank you
thank you I realized I am the lucky
person that got the last spot speaking
spot of the day so I'll do my best not
to stem cell to sleep with yawning
already ok so my so what I was charged
with is really just to talk a little bit
about my research and what I'm really
going to do is try and show you some of
the areas that I think NLP that we're
trying to use NLP so I'm sure the NLP
people you know I hope you're going to
come and tell me while you should try
this and it would be better to do that
but I think this is going to kind of
provide a different kind of view of
software engineering and look at a
couple of different problems and I'm
going to talk about the kind of things
that we've done we've seen this kind of
slide three times now this is the third
time tau showed us some kind of like the
project artifacts and I'll show them to
us so I won't spend much time except to
say that this is the context in in which
we're working so there's lots of
different software artifacts and my
interest lies and making connections
across these so some of the things
people have talked about really focus on
one kind of artifact which is source
code and the kind of world we live in is
trying to make connections across all of
these different kind of artifacts so to
query across them or to trace across
them and actually traceability is very
very similar to project wide querying
because what we're trying to do is make
connections between things so a couple
of quick examples of what the kind of
thing we're interested in kind of
compliance questions or safety analysis
questions traceability is really
important in the world of
safety-critical software so in
safety-critical stuff where you're going
to start off with regulatory codes or
hazard analysis fault tree analysis
those kinds of things and you need to be
able to make the connections all the way
down to the code and test cases to show
that your software is compliant or that
it is safe for use
we've already had lots of people talk
about things like fault prediction bug
triaging is another one of these things
we have these different kinds of
software artifacts and we're interested
in allowing people to make queries
across them and one of the things that
we can see is that there are many
different projects stakeholders they're
all going to have different kinds of
queries or questions they want to ask
that will support their particular
software engineering tasks and they're
all going to ask their questions using
their own terminology in their own ways
and that's really what we want to
address in fact I visited have a couple
of Industry collaborators and actually
about eight years ago I went to one
particular collaborator and they told me
because of process improvement
initiatives and their companies they
they had to have traceability in place
so they spend a lot of time establishing
traceability but they never actually use
their trace links after they created
them so I wanted to know why and it's
one of the reasons is the barrier of
actually formulating queries that are
actually quite complex using a sequel or
something like that so one of the things
we wanted to do is to create this
natural language interface for querying
software projects so why this differs
from I think kind of some of the other
database net natural language interfaces
for databases is that as well as kind of
querying the actual data in the database
we want to be able to ask software
engineering type queries so it's like
very makes it very domain-specific for
example are there any hazards with no
identified contributing faults we'd like
our users to be able to answer those
kind of questions or list all
requirements related to heat sensor full
so these are the kind of things and
actually a couple more examples in the
minute so it what we do is we basically
present the users with the database
schema which we call a traceability
information model and it captures all of
the different software artifacts that
are available for them to query against
when I'm not even going to slightly
touch on today
is the fact that this data is not
sitting nicely in some relational
database so I'm just going to pretend it
is there today but there's a whole bunch
of engineering that has to go on in
order to actually dynamically in real
time collect the data from third-party
case tools may be distributed you know
internationally and all those things so
for now we'll just assume which is an
incorrect assumption that the data is
all here this way losing the skills we
currently use we have some other
intermediate formats but we currently
use SQL just as an intermediate format
and the we've also done some work in
going from that into kind of case tools
and things like that so it is not the
end it's not the end at all my
collaborator happens to be a database
person so it was a convenient kind of
place for us to focus on the up front
and I'll so yes are you later going to
talk about how this kind of data is
collected um I can but it's not the
focus of what I was planning on talking
about today it's another whole kind of
challenge but which we I can answer that
later so just to say that there's
different kinds of queries this is one
example of a query that somebody could
ask and if you look at it they're just
really asking for data that exists
that's a natural byproduct of a software
engineering lifecycle to be retrieved so
all we have to do is take that map it
onto these different artifacts you know
find a path that connects through them
generate our our sequel query for now
and return results a second kind of
query which really builds a lot on what
towers saying the other day is much more
analytical in nature so here's this
query it says who is the best person to
check the footprint classes in
components related to temperature
controls there's actually three
analytical functions embedded in that
one simple query we have a recommender
system which would have to answer who is
the expert we have a full prediction
predictor that can identify for prone
classes
then we have some kind of you know maybe
semantic analysis that will kind of look
for things that are related to
temperature controls so this is an
example of the kind of analytic query
that we're working towards tikki being
able to answer so right now tikki we
just take the query as I've learned
we're using the old-fashioned approach
but we use some kind of heuristics to
map well first of all we pre process we
tokenize we map onto the different
artifacts so currently we use a
heuristic approach to do this we're then
using some machine learning in the
middle that we're just working on right
now where we basically train tikki to
disambiguate when there's ambiguous
mappings but we don't have one big kind
of statistical you know machine
interpretation going on now it's like
heuristic with the benefit of some
classification so that's this area of
ticky natural language interfaces and
our goal here is to allow people to ask
these these queries against the software
engineering projects this turns out to
be you know a very special so
traceability which Earl has given us a
really nice introduction to so I'm not
going to bother with that thank you so
it turns out that traceability is a very
special case of a query because instead
of the user coming along and telling
what they want we basically have a query
which is made up of one software
artifact and then we're searching
against something else so the query
could be a requirement and we could be
searching yet source code or the query
could be a regulatory code and we're
trying to search against against
requirements and that's the example that
i'm going to show you and i'm going to
show you some of the NLP things that
we've been trying to work on to solve
this whoops I'm jumping to so these are
examples of tools that use basic
information retrieval and try to match
things up and this has been work I think
Andy's probably going to talk a little
bit more about information retrieval
methods tomorrow but these are things
that our community
as a whole has been have been working on
for at least a decade or more I
mentioned in my kind of introduction
that one of the things we started
thinking about about two or three years
ago is if you look at those information
retrieval methods we can trace from
requirements to code or all these
different kinds of things we usually
only achieve at the best about 90%
recall and precision that's kind of
around twenty percent or something like
that so that's kind of on it on a good
day and I should say one reason for that
is because we're doing search in a very
small closed space I think dawn or
someone had mentioned that we don't have
the benefit of many many people before
issuing similar kind of queries so some
of the things that you can do in a much
larger search space are not available to
us nevertheless we realize that you know
humans are able to generate quite
accurate trace links and so we asked
ourselves this question what goes
through a domain experts mind as he or
she performs the tracing task and that
was the beginning of our journey into
natural language processing so here's an
example here is a regulatory code and
then here is a requirement and we want
to know are these two things related to
each other and if we'd used ordinary
information retrieval then we possibly
might have created a link between them
but we also would have got a lot of
other links that were not related
because of some of the kind of less
important words there so we asked
ourselves this question and we found
that the domain expert will be able to
reason about the concepts in the domain
he knows you know what acronyms stand
four he knows when words a similar to it
have similar meanings he knows what you
know been like what is part of other
things so an automobile controller is
part of an automobile and he can reason
or she can reason about all of these
things and determine if a trace link
exists so this was our quest to build
this kind of much more intelligent
traceability sis
that would be able to return highly
accurate trace links I don't really have
time to go into our whole process but we
basically built it around this notion of
action frames which i'm sure the NLP
people are kind of familiar with and we
take the artifacts we pass them we
represent them in this intermediate
structure so an actual frame contains a
verb semantic type Samantha thematic
roles we assign each verb to both the
syntactic group in a semantic group we
use the syntactic groups in order to
identify it extracts the action frames
and then we use the semantic groups with
alongside a set of heuristics which
we've identified to reason about when
the occurrence of an action frame in a
source artifact and a target artifact
means that those things should be linked
together currently our model is a little
simplistic because it looks only at
single pairs and we know we can improve
it if we look at sets of action frames
at a current source and target artifacts
so this is an example I took out the
animation because it takes too long to
go through but you can see here we have
one action frame here's another one here
the verb is it belongs to the receptive
group and in the second one the verb
belongs to the transmissive group so we
have sets of heuristics here are the
heuristics for this specific receptive
transmissive pair and we compare we go
through the heuristics and if all of the
heuristics pass then we declared that a
link exists so what we found is that
whoops can bring this up these are the
results that we were able to obtain
using a demain centric expert
traceability system in comparison to the
vector space model so you can see that
we were able to achieve much much more
accurate traceability but there's some
problems the first problem is that one
of the things that I didn't mention is
we rely on the underlying presence of
ontology so we have to be able to reason
about things like you know the similar
meanings between two different concepts
and one of the challenges here so we
need ontology for this to work for a
very specific domain and some of the
ontology is just related to software
engineering in general but a lot of it
is very very domain-specific and a lot
of the domains that we're working in a
highly technical so you can't just go
out and find you know ontology that you
could reuse so for example this data set
here is actually from the domain of
positive train control and you know if
you go and look at for example some some
reviewers for papers said why don't you
go and use the transportation ontology
and it's completely not suited to our
domain which has highly technical terms
in it so for this to work we've
basically just created a new problem
which is that of ontology learning and
once we've learned the ontology we don't
know yet if the heuristics that we've
learned can be applied across different
domains we have some evidence to show
that they that many of them can be
applied if you that we've learned them
on one domain and we can apply them on
other domains but I want to just use a
little bit of my time now to talk about
what we've done to learn ontology and I
think that ten-year I think this is an
example of we think there's something a
little bit unique about what we're doing
from an NLP perspective but you guys can
tell me if I'm right or wrong okay so
our approach for learning domain
ontology first of all we have domain
documents and then we have project
artifacts and then we use a variety of
different extraction methods so we talk
about these in a minute but I think
they're pretty standard methods that
people use for ontology building and
then a secret weapon is traceability
links because when we started to think
about it we thought if you have trace
links for a specific domain then you
know that there is some concept
in the source artifact and some concept
but in the target artifact that are
related because somebody has said these
two artifacts are related and if we
given our existing ontology our existing
knowledge base if we cannot explain the
link then we have a really good hint
that we could go and search for a
relationship between a pair of concepts
so of course there might be many
concepts in the source artifact you know
maybe you know four or five different
noun phrases or something like that and
the same in the target so our approach
really seeks out the knowledge that
would fill in that gap so we think this
kind of really creates a semi-supervised
way of learning because we now have a
hint about something that exists okay
and then we use these methods which I'll
talk about in a second we create a
profile of candidate facts we've used
machine learning here so that given all
of the information that is we get from
the lexical syntactic patterns
Association remaining topic modeling and
semantic relatedness which comes from
wordnet we try to train R train our kind
of train this to evaluate which of these
facts are likely to be the ones that
cause that trace link to occur in the
first place yes corner the the chase
major if you take it out of your
approach what's yeah compromise up there
o war it's less guided because now what
this does is it tells us that given this
pair this maybe this required regulatory
code in this requirement that there's
there's some concept some pair of
concepts in there that are related and
should be put into our ontology so it
means that we can focus our search
efforts to find the concept that
actually is is the one thats related as
opposed to for example if you were to
just use lexical syntactic pattern
extraction you know you can search
through all the domain documents but
this kind of creates more of a
guided environment for it yes I mean
that the source of the target have kind
of their own latent ontology Xin what
you're doing with trace matrix is
basically aligning them um it could but
they they probably share a lot of if
they probably share a lot of facts
because I know when we we started this
it's I we saw that there's two different
kind of you know ways of thinking about
this one is the kind of the two parallel
kind of ontology is that you look for
the connections and then the other is
you just build the blending wonder that
the approach we've taken one of the
reasons we've taken that is because of
the problem that we found um in kind of
overlap so I'm going to focus on ptc
which is a positive train control we
were given um yeah you say just that you
weren't I was structured as your
anthology exactly what yes many layers
what judges yes understand what you've
all ecology um I'll show you kind of
I'll skip a couple here and saw your
picture of it sorry going forward here
so this is a really really little bit of
it but basically what we're interested
in is fact you know kind of relations
between facts we're not we only have a
certain amount of knowledge right now
about the relationship that occurs
between these hexes um right now we do
but obviously yeah with the lexical
syntactic patterns if we can find
patterns that way then we have the
opportunity to label these but kind of
skipping back a little bit we basically
put the human in the loop and allow them
to label those so this is not fully
automated but maybe demo has good ideas
for us coming along okay so one of the
problems we have here is sorry
yeah one of the problems we have here is
for example with this positive train
control our collaborator industrial
collaborators gave us 450 documents
about positive train control so that's
quite a lot they're quite lengthy and
you know we basically mind them for
nouns and noun phrases so we focused
only on that and then we did the same
with a small subset of requirements and
artifacts from the system and you can
see that there wasn't really much
overlap so a large percentage of the the
nouns and noun phrases that were found
in the software artifacts were not in
any of those 450 design documents so
basically unseen kind of concepts that's
one of the reasons that we think it's
more effective to try and build you know
focus our effort on building ontology
that's actually needed by the sufferer
artifacts and using the traceability
matrix for them like for the documents
on your table like how high percent you
then are confidential like the company
or yep this one is completely
confidential these ones are not so
they're kind of much smaller but we
deliberately included them because
they're ones that we can share with
people so the one that is the real world
one is proprietary always the case right
we actually now have access to a really
large data set from our in Indian
collaborators for which we have to fly
to Pune to go and work on it whenever we
want to you mate you guys may think it's
hard getting data sets but if you
actually need ones with requirements
something else and trace links it's even
harder so okay this was just basically
the same thing that I've said before
about leveraging the traceability data
we identify key terms right now we're
only working with nouns and noun phrases
obviously we can expand that we use
these different methods so we have a
number these are just example that ins
have a number of Lex
Oh syntactic patterns but as the NLP
people know this if you do lexical
syntactic pattern mining you get quite
high precision but very low recall in
terms of the facts that you want to find
so we had a number of problems with that
we also so in order to try and improve
our recall we also used Association rule
mining and topic modeling and basically
you know this gives us more over clue
about where the relationships might
exist so if we know some relationship
exists between something in the source
and something in the target and we can't
find it with our more accurate approach
then we kind of resort to something that
just looks for associations and then we
also used wordnet to try and understand
a little bit more about the semantic
relatedness using since X and and things
like that as I said we then made built
this profile and we trained it to try
and recognize correct facts women
correct facts for the NLP people one of
the things we've really had a problem
with and I'm sure this is easy for you
but isn't figuring out what kind of
phrases we should actually be putting
into ontology so it's like the longer
the phrases then obviously we're over
trading it and everything works quite
well but only for the test sets that
we're training it on and so we think we
have to so we're trying right now to
make her kind of phrases in the ontology
more general but we don't know really
the right way to do that yet as I said
we put the human in the middle we think
that ontology building you know you the
human has to vet this and kind of
evaluate it and so we present them these
facts and we ask them to kind of add
some information this is just a sample
of very little bit of the kind of facts
that we've created one of the things we
found for traceability purposes
I'm not showing this here because my PhD
student Jin is just literally finishing
it right now but we found if we train
infer relationships across the the kind
of different relationships in the
ontology that we actually get worse
results and if we look just at complete
neighboring facts so one of the problems
from the traceability perspective is it
seems to reduce precision if you kind of
do too much you know reasoning this is
something that we just started working
on right now though okay and ontology
alone isn't enough this is my last slide
after this one I think ontology alert
and alone isn't enough i already showed
you this slide and this is just to say
that reasoning over the ontology for
example here OPM is part of the
automobile segment is part of it and we
we have shown that we can improve the
tracing results simply by using ontology
but we really need these heuristics and
one of our open challenges that we are
challenged to work on and I really think
we can do it I hope is to learn the
rules so right now the heuristic rules
that we have established for relating to
action frames based on the semantic
groups those rules were built manually I
had a linguist on my team for a couple
of years and we spent a lot of time
building those rules but we think that
there's a way to structure them and to
learn them so we came up with this
structure and got a little bit stuck we
wrote it we use genetic algorithms to
try and search through the search space
to try and discover kind of like the
rules because this is a structural
representation of the rules but anyway
it turns out we had more possibilities
than the number of nanoseconds in the
universe so we have to figure out a
better way of learning this we have some
ideas and if anybody has any suggestions
for that I would be very very grateful
so that's anyway what we've been trying
to do in this area
and I think this is just a summary so I
kind of covered it so yeah it's just
some of the recent papers we've done in
this area and this is my PhD student Jin
goo who's I'm doing this for her PhD
topic right now so my question is did
you have a computational that was
vomiting um the link was for the
competition no not yet so this is an
example you know a lot of software
engineers the kind of homegrown NLP
people and we just learn I was telling
some people you know basically we go and
look for the out algorithms but we don't
know necessarily that we have
best-of-breed um yeah so if you were to
look into the future and suppose we have
ideal NOP to means could you just use
like the audience your ideal list what
would you like to help if possible and
then we could project it on what's
available on what could be the new
research directions because that's what
exactly what we're looking for here
forward looking forward what could be
improved or new methods developed to
help to do what do because this is
extremely extremely interesting and
challenging ah the main yeah it's been a
really fun cool domain to working um I
think definitely ontology young tools
for ontology building because for
software engineering you're constantly
changing to me however for example our
industrial collaborators that work in
the area of positive train control they
build multiple systems in that domain so
the it's worth the effort to build the
ontology which can help them with their
future tasks I would like you know help
ideas tools that would be useful for
building ontology and in specific
domains highly technical domains and you
know realize this is really challenging
but we think
we can give something to it as well buy
some of the kind of the semi-supervised
learning for example from the
traceability matrices that's the biggest
you know most important thing and then
you know maybe tools for helping us kind
of learn rules but I don't know if
that's just a once-off specific thing if
we learn it one time then it'll be good
for every domain or if it's something
that would have to be redone for each
domain I don't know think yeah so I was
trying to just follow up a little bit on
tania's question and one thing that
would be really helpful for me maybe
this conversation we can have in more
detail later but you know what's the
criterion for being a node in the
anthology I think I understood the least
a little bit better and sort of you know
how do we sort of get the next you know
kind of yeah ooh does that just not
align well with you know things you can
get out of an Opie tools or how you were
using her speech Tigers but I didn't
know your full suite of exactly how it
went and so like more details there a
lot I mean so I would love to talk to
you about that too because I think this
is something we didn't know the right
way to do it and so the first ontology
we build had really long phrases in it
which is obviously not the right way to
go and it optimized for our data set to
support traceability so that's I think
that's something we we don't know the
answer to that so in the end you know we
can build an ontology that has simple
phrases in it but in the end that might
be for us like using only wordnet to
kind of to identify synonyms and when
we've used only wordnet for traceability
purposes then the precision of the trace
links has gone down recall goes up but
precision goes so far down that in the
end it's a losing proposition so for us
we think we need you know techniques
until we need to know what we should be
modeling and you know we're for us it's
also kind of chicken before the egg
thing so we're trying to build something
and then we hope we can start improving
it but we've already reduced this the
kind of this
length of things that are in nodes and I
don't know right now we have only nouns
and noun phrases but we maybe there's
other kinds of things that should go in
there too I'm not sure I think it's all
good your ontology had a bit of a
hierarchy did that matter at all like if
you strip it out and just treat it
relatively flat yeah in the end based on
our last week's results which are not
here we're not even actually using the
you know the hierarchy or the distant
relations I don't know the right way to
say that but we're basically right now
just using simple facts like a is
related to B and one thing I didn't
mention my PhD student Jin is also
working on we had a paper a short paper
recently that generates rationales for
links so we have 22 in order for that to
work well we have to know the type you
know we need to know something about the
type of the relationship but yeah so
right now of course we like the idea of
the ontology but as the results that we
got from last week is just pairs of
facts actually work quite well for us
but you can of course to extract those
from ontology any life yeah so even
prepares of cats you can look at simple
relations like you have like God
something is a subclass or something is
exactly one other thing but you look at
more complicated relations like the edge
between those two artifacts can mean
something about the type of interaction
that they have right so is that
something that will be helpful for you
i'm wondering if you at all look at
doing something like that um we're at
the very beginning of this you know
we've so offer the first study we did
was we built our ontology manually we
built our heuristics manually it was
like a proof of concept if we have all
this stuff in place does it improve the
task we're trying to do the answer was a
resounding yes so now we've started on
this ontology generation and I strongly
suspect that so right now you know Jen
just told me last week that she got much
better results by only looking at single
flags but I strongly suspect that if
that if
we understood the type but the
relationship between them then it would
not be all or nothing and there'll be
some some relationships that we would
reason over and would be useful to us
and then maybe others like siblings are
not necessarily as useful for doing yes
thanks for a great that's not a
question that's not necessarily just
four chambered for anybody which is like
is Nell for example learning any facts
about things like Android API or the
receipt api we went to Medellin said del
you know like you know what does a
broadcast listen to do will it tell me
anything yeah I'm about to test it right
now okay like I think luke and I looked
at one another kind of skeptically but I
don't know it depends on what's on a web
I guess there'll be some things in there
but not probably everything that suffer
share people will be interested in okay
I think that's where Julian comes in
that's what you're going to do what all
these things are now so I would mean
maybe thats related to your question
like we did some work let's say a couple
years back and publishing using security
2013 basically fighting this
traceability from FD secretion from
genetics and the permissions mobile app
is requesting so because I initial
result then our floor work has been
funded by yourself on further network
that that work actually open up some
interesting direction in the security
community because in the past I mean in
a secure country they use testing for
NASA's for tackling secure problems no
one actually saw the power using natural
processing or text analytics for
difficult security problems and and
since settle quite some papers I mean
have been published by other groups in
the security top conferences in this
couple years people are catching up I
mean in the community I mean color in a
very competitive way everyone rushing in
in this direction it's very interesting
phenomena view any of you have inches in
that direction I mean talk to me and
unhappy chill always you
as in bodily that's also covers in the
shop and during area the amp discussion
you consider as a high level functional
requirement right and then the
permission would be security
environments so it's a somewhat related
to chase of energy issues questions I
wanted to add actually to what you're
asking about now is that um Nell learns
relations on top of an input given
ontology and so if in this ontology
there are no software concepts Nell is
not going to learn about software and so
I think that's where to some extent if
those things are in the web you know at
some point some others think of adding
them to the hematology but this is a
human we initiated act and if those
things are not in your ecology given to
know it's not going to learn about and
so again this is worth that Williams
whooping and Tom Mitchell's were
thinking of do you get with the program
is one thing that I was no barcode you
need an apology l thinks MVC is a
programming language so it's partially
on the phone I think so Miss he's a
programming yeah well we asked a lot of
just for fun when we were building Tiki
we are serial the questions we are
sticky it was kind of fun course sticky
goes that's an interesting question or
if it's a very generic answer huh is
anybody using old friends
if there's a paper from Easter people
use some oncologist of the testing yes
tonnelle or using alpha testing it's not
using our for testing or just testing
out his new generation okay i built an
ontology for telephony about 25 years
ago I think anybody uses it alright
thanks Jane</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>