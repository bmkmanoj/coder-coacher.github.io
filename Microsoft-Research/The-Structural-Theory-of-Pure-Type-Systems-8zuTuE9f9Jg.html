<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Structural Theory of Pure Type Systems | Coder Coacher - Coaching Coders</title><meta content="The Structural Theory of Pure Type Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Structural Theory of Pure Type Systems</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8zuTuE9f9Jg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
it's a great pleasure to introduce Cody
rule he's opposed docking same you he
works in type theory and improving today
he's going to talk about structural
purpose of pure type systems okay well I
want to thank Microsoft and everybody
for having me here it's really a
pleasure to be here so I'm from the
Department of Philosophy so I'm going to
talk about philosophy hopefully there
will be some intersection with computer
science and people will find some
relevance to what's interesting to them
so i mean the the title is a little bit
mysterious so i'm going to explain it of
course and really what I want to do is
ask philosophical question about the
notion of abstraction and it's actually
a series of questions and those
questions I show can be answered in the
framework of here type systems and I'm
going to explain what these questions
are what pure type systems are and how i
can use pew type systems to answer them
and to answer these questions I need to
examine something that I call structural
properties of pure type systems which
explains the title of my talk to a
certain extent but I haven't said what
structural properties are and then I
mean basically at the end I'm going to
give the main results and try and
justify the fact they do answer these
these philosophical questions about the
notion of abstraction okay so in my
original talk i had mathematicians and
programmers because i was talking to
mathematicians but programmers and
mathematicians basically i mean the most
crucial part of their work is
recognizing patterns and abstracting on
them okay this is really what we do the
most is try to understand these patterns
and say okay well this is an important
thing and I need to separate it and make
it
modular this is a trivial example but if
you have one plus X plus 1 plus y plus
one you can say oh well here's a pattern
one appears plenty of times and I can
sort of express this pattern by
introducing a lambda here and saying
well every occurrence of one can be
replaced by this abstract variable Z and
then I can apply this to one and it has
the same meaning as above you can
imagine if one is somehow very complex
computation then you could say oh well
by abstracting here I've saved time
because I only need to do this
computation once and the abstraction
allows me to sort of reunite all these
individual computations into one
computation but abstraction is also
useful for mental processes and the way
we do abstraction is in general this
kind of scientific method where we have
these concrete observations that two
plus four happens to be equal to four
plus two and from these number of
concrete instances we create abstract
instances and this is a very important
step to go from concrete observations to
abstract observations and once we've
done this step basically we have the
second step where we create a universe
labs a universal observation that says
that this concrete observation has been
turned into an abstract statement which
is universally true and then mathematics
tries to prove things universally but
based on these concrete observations
okay so I want to understand what allows
us to do this what is the process
involved in having concrete instances
turning them into abstract instances and
then allowing yourself to form a
universal statement about this what is
actually happening when
do this okay in particular when are we
allowed to make an abstraction and when
are we allowed to make a universal
quantification and an interesting
question I haven't really explained
sufficiently yet is what do we get as a
result what is the result of universal
quantification what kind of category is
in it I'm sorry what kind of category is
it in what's the nature of a universal
quantification is it is the proposition
2 plus 4 equals 4 plus two of the same
nature as for all X Y X plus y equals y
plus X I mean an obvious answer is yes
they're both propositions but there are
refinements to this answer where we
could say oh well really observing the
two plus four equals four of us who is
not the same as having this universal
statement okay so there's something
called the kirihara correspondence and
if you've heard of it that's great and
if you haven't that's not a big deal
what the Curie hard correspondence
expresses is that there's some kind of
relationship between Universal
quantification and function spaces okay
typically computable function spaces
okay this this is a really nice
observation because it says basically
building functions by lambda abstraction
is really the same thing as a as
performing the introduction for
universal quantification okay so we have
these logical operations that correspond
to programming operations so our
question about universal quantification
and what what was the nature of
universal quantification can be
rephrased using this correspondence as a
question about function spaces what does
it mean to build a function space and
what is the resulting nature of that
space okay
now to ask my second question about
abstraction and quantification I just
need a little background so the simply
typed lambda calculus is a very basic
programming language and in fact it's
it's so basic that it's sort of a
theoretical basis for programming
languages it's very that's very simple
so you have base types I'm going to use
the pointer so you have these base types
that express sort of atomic kinds of
types you have in your language and then
you have you have functions on these
types and in particular you have hired
or functions see here I have a function
that takes this input this f which is
itself a function okay so simply type
Mount of calculus basically has just
these types and higher-order functions
and that's that's all that the simply
typed lambda calculus is made out of and
something that's kind of surprising if
you don't know it is that in the simply
typed lambda calculus every program is
terminating so you can run every program
and you'll get a result and this is sort
of an important observation I'm sorry so
it's an important observation because uh
it it it gives you a large number of
consequences okay in particular it says
something like for example you can
decide equality between between two
terms of lambda calculus we'll see other
consequences of termination okay so we
have the something type line of calculus
and it's very nice and it has these nice
properties but it's not a real
programming language and for many
reasons and one of these reasons is that
there's no polymorphism this is one of
the basic requirements that you want to
have today is that you don't want to
write the same function twice in
particular this function lambda X X that
just returns its argument you should be
able to apply it to the number three to
get three and you should also be able to
apply to the to the boolean
roo and get true you don't want to write
two functions one which takes integers
for example and one that takes boolean
is was exactly the same code so you want
to add this feature to the language and
so the question is you have simply typed
lambda calculus how do you add this
feature of pulling morphism ok and
what's interesting is that there are two
possible answers to this question there
are two ways to add polymorphism and
they're fundamentally different ok they
all start the same way you add variables
at the type level so you have these
simple types and now you have type
variables types that can be instantiated
with other types and then you add
quantification where you say well we
have a function and it's of type for all
X X 0 X ok it's for any potential type
it has the type x RX ok now the two
differences between these approaches to
pulling morphism is what does the for
all here quantify over ok what are the
possible instances of X what am I
allowed to replace X by the first answer
says I'm only allowed to replace X with
simple types so no quantifiers and the
things i replace x with and the second
answer is any type including types that
have quantifications themselves and
these two choices lead to dramatically
different programming languages ok in
the first case we have fully immerse
them we can do this polymorphic identity
but it's conservative in the sense that
there aren't a fundamental way to add
new functions functions that really do
new kinds of computations in the second
case you have this incredibly powerful
system called system f which is a lot
harder to analyze but that has many many
new functions and in particular proving
termination for system f is
still true but it's a lot harder so in
the first case we've added pulling
morphism but it's safe in the sense that
there are no new functions in the second
case it's somewhat unsafe because you
get all these crazy new functions okay
and this difference comes completely
from what instantiation is you allow for
the universal quantification so this is
a very important point on what it means
to have pull a morphism so more
generally you want to know what kinds of
quantification will lead to conservative
extensions and a conservative extension
in my fence is something where you have
more expressive types but you don't have
new programs you can't write programs
that behave in a fundamentally different
way okay this is often desirable because
you want types to be more expressive but
you don't want to be able to write
programs that do silly things or wrong
things or you know don't terminate for
example okay I'm going to talk briefly
about dependent types because it's a
notion that underlies everything that
follows a dependent types I'm sorry I
dependent type the type which contains
term level information and I mean I hope
this example is going to be sufficient
to justify sort of the idea behind
dependent types here i have a list with
three elements I'd like to have a type
that can express the fact that the list
has three elements and to express that
fact it needs to contain a term so
vector n contains the term 3 which
expresses that the list 1 2 3 has three
elements okay and we can quantify over
these type level expressions as well
effect you'd want a function reverse to
work for any length vector so for all n
it takes a vector with n elements and it
returns a vector with the same number
okay so you want to be able to quantify
that okay and same question you want to
add these quantifications and you want
to know if adding these quantifications
is safe if you have no new functions or
if you've created something
fundamentally more powerful in the sense
that you have different functions okay
and to answer this question in a formal
manner I'm going to introduce and exist
I'm going to present an existing
framework that's called pure type system
and that really allows us to express in
a very fine-grained way what the
dependencies are okay what it means when
you quantify over a variable in a type
are there any questions at this point
okay so so a pure type system is a
framework of many different type systems
okay and it's a generic framework that
allows us to express typed programming
language but using the Curie Howard
isomorphism you can also say it's a
framework for expressing logics okay so
logics and program language are sort of
two different sides of the same coin and
one characteristic of pure type systems
what makes it a nice sort of playground
for understanding type systems that it
only allows universal quantification
okay it doesn't have it doesn't have
existential quantification it doesn't
have conjunction it doesn't have data
types it just has universal
quantification that's all it has and
universal quantification is a logical
notion the corresponding programming
language notion is that of dependent
function space
okay so a few facts about pure type
systems that sort of additionally
justify the fact that we're interested
in them one they're very expressive you
can actually find a specific pure type
system that is so expressive that it
allows you to express all of set theory
so basically all of mathematics can be
expressed using a particular pew type
system so some pure type systems are
just incredibly powerful specification
languages the relatively well studied
they were invented in the 80s and here i
cite barendrecht but he wasn't the only
inventor but this this this book is
basically the Bible where he explains
all the basic properties of pierre type
systems and they've been studied
relatively extensively since the 80s so
there will understand framework and
they're quite flexible you can use them
as sort of a a core ideal I'm sorry you
can use them as the core of a functional
language you can say okay I take it
through type system and I'm going to use
it to base a real world language like
Haskell or a specification language like
actor or cook to do that I'm going to
need to add some features but I'm going
to start by using a pure type system and
then I'll add features to this system so
studying pure type systems gives us a
starting point for studying these more
complex programming languages like
Haskell and cook however the theory of
true type systems is something that can
be really quite complex in particular
they were invented in the 80s but there
are several open questions which is
something that's quite unusual in type
theory I mean open questions and type
theories it's kind of surprising fact I
mean there are many open questions in
complexity theory but in type systems
there aren't that many
famous open questions and then I i named
a couple but it's not very important
what they are but but there are these
two open questions concerning pure type
systems ok so our questions about adding
polymorphism and understanding
quantifications can they be answered
using pure type systems ok this is a
rhetorical question because I'm arguing
that we can but to give my argument I
need to explain what it would appear
type system is an app you type system is
completely described by these three
things the first one is a set of sorts
ok just any arbitrary set that we call
the set of sorts s the second one is a
relationship between elements of ests
that I call axioms and the third one is
a ternary relation on elements of s that
I call rules ok and that's it that's all
you need to describe your type system
now of course I haven't talked about
type systems yet but once you have this
data you have everything you need to
understand how the type system is
described ok I am going to explain what
informally these pieces of data mean the
elements of s represent a category of
objects a type of objects ok it's it's
such type of such a loaded word that I'm
kind of reluctant to use it but every
element of s represents morally objects
that are alike in some manner ok this is
kind of vague so I'm going to give
examples for example star this star here
as an element of s is often the symbol
used to represent the category of
propositions so every proposition is in
star ok is in the category star ok and
box is often used to represent the
category of all types of all sets ok and
Yoda is traditionally used to rep
than the category of natural numbers so
Yoda represents all the natural numbers
okay so every element of s represents
like this a category of objects ok and
then if s1 and s2 are an A which means
that there is an axiom s1 s2 this
informally means that s 1 is a member of
the category s 2 okay remember that each
element of s represents a collection
category of like objects well sometimes
other sorts can be members of that
category ok so if s1 s2 is an a then s1
is a member of the category is two ok
and the third one is a little bit more
complex but it room it specifies in
which way we can quantify over
parametrized elements of a category ok
so if I have an element of s too but
that depends on a parameter of s1 I can
universally quantify that parameter and
it gives me a result in s3 ok i'm going
to give examples of this later but
basically this says that if a is an
element of the sword s1 and for each
element of a B of X is an element of the
sort as to then you can quantify over
all these X's and you'll end up in s3
okay
so we write PI instead of frawl but
that's just notation last Poland how
where does fine it says that the entire
for all expression yes yes okay I've had
this question before I should reduce the
space okay that this is this is one one
object which is the the universally
quantified statement basically we're for
every X in a B of X holds or an element
of B of X and all this is in the
category as three and a sword is three
yeah sorry about that there's my kerning
is poor okay so i write PI instead of
for all that's just a tradition um okay
so given a PG SP i'm going to introduce
formerly with the type system associated
to pee is ok i said p was sorts axioms
and rules and now i'm going to say what
the type system associated to those
sorts axioms and rules are and that's
really what we want to study we don't
care about the set the accident the
rules we care about this type system
that's determined by those things okay
so the first one just says that if s1
and s2 is an axiom then we can derive
the judgment s1 is of type s 2 ok this
is unsurprisingly that's that's what I
exactly what I said s1 s2 and a mint
okay and the second one is this more
complicated statement about rules which
says that if a is of type s 1 and if B
is of type s 2 under this assumption
that X is of type A then PI X a B is a
type which is in the sort s3 if these
three types are
our rule okay so these two rules sort of
tell us how to build these basic these
basic types which are the pies and the
sorts okay and once we have that we can
build terms okay and there are only
three ways to build a term which is
either it's a variable in the context
with this first rule bar or it's an
abstraction that builds a pie that
builds an element of the pie type okay
or it's an application where I have an
element of the pie type I have a term
that's of the domain and I apply that
the the function to the to the term okay
so this is a way of constructing pies
and of destructing them okay and you can
see that this looks like the the
universal quantification rule okay if I
have for all X in a be well then in
particular be of you holds okay if you
is of type a ok so this is really like
universal quantification and this is
similarly if generically for for an
arbitrary X and ay B holds then for all
X and AV holds okay but it's also like a
function type if given an X and ay I can
build an element of B then I can build a
function that takes an element in a and
returns an element of B and this is the
same if you ignore this if you have a
function from A to B and an element of a
and you can just apply it and get an
element be ok so that's all there is to
it this is completely what pure type
systems is except this conversion rule
which says that if two types are equal
in some sense then le any element of the
first type is also
of the second type okay and equal in
some sense means equal with respect to
this computational rule which is just
the ordinary BTW reduction rule or you
have lambda applied to a term just is
equal to that term where you replace the
variable by the the argument okay so we
have so we have four things really we
yes you have a kind of a type 2 beta
reduction why do you require a trying to
be aa sorted as opposed to getting it as
a as a property of beta reduction that
it preserves the source a beta reduction
preserve sorts that beta expansion
doesn't so this is kind of a sanity
check that says I haven't expanded
things and and introduce some some some
bill typed creature that would then
disappear when I beat it reduc reduced
there are some versions of pure ties
systems that don't have this requirement
but in general this is mostly a sanity
check we say being designed to be low
tide right
you could limit that expansion to only
well type it expansions but that I mean
significantly complicates the theory of
your dive sisters I mean one of the open
conjectures about pure type systems is
that this untyped conversion here and
the type conversion lead to the same
underlying systems it's it's completely
non-obvious it's it's quite surprising
because it seems obvious it seems
obviously true that if you limit these
conversions to well type conversions no
harm should come but it's actually very
hard to prove so so I'd say don't don't
concentrate too much on this I've added
it for convenience but there are
technical reasons for why it's there
does that answer your question we can
come back to it and this is this is
basically all there is there are only
structural rules that I've admitted that
I call the boring rules but this is all
there is to it just sorts and PI types
abstraction application variables of
course and then this conversion rule and
that's all there is to it that's very
simple type system but it allows us to
model this vast array of different
programming languages and at least what
it can do is the simply typed lambda
calculus so one way to model the
something that lambda calculus using
this framework is to introduce these two
sorts Yoda and star this is going to
represent a base type save natural
numbers and this is going to represent
the sort of all types okay and then the
type of natural numbers of course is a
type so it's in this sort of all types
so we have this axiom and now this rule
says that if um
if we I'm sorry if for each element of a
type we have the element of type then we
can perform the abstraction and it gets
a new type I'm sorry this was it looks
this was poorly explained this rule says
that if given the elements of a type we
can form a type then I can build the
abstraction that takes an element of
this type and returns an element of this
type and this still lives in star okay
so I this is basically the rule that
allows us to form arrow types like this
ok so I can form this identity function
on Yoda by abstracting over X and
returning X this is of type Yoda arrow
yota where Yoda arrow yota is just pi X
of type yoda yoda ok and the fact that
we could form this pie type uses this
rule ok so we have the simply typed
lambda calculus with this rule because
we can form these PI types using this
rule and these PI types correspond to
just function types all right ok now i'm
not going to go into too much detail but
i do want to stress the fact that using
this framework of pure type systems you
can build these very very rich systems
so i just showed that we can build the
simply typed lambda calculus you can
also build the simply light typed lambda
calculus where instead of having a
single base type you can declare these
abstract base types in the context ok
and this is just presented in a slightly
different way where we have the type of
old types has itself a type ok and
that's the only difference and in this
second version basically you can declare
abstract types that you call ABC and all
these are type variables but you can't
quantify over them
the next system we often call it Starkel
and star or type 1 type and it's the
same as the simply typed lambda calculus
except stars of type star okay the type
of all types is a type okay and it seems
relatively innocent I mean it's the same
as the previous one but it just has this
different axiom system f which allows
general type quantification it looks
like the simply typed lambda calculus
again except it has this rule which is
allows us to quantify over general types
okay so we can form this polymorphic
identity rule where we say for every
type x x RX is a type okay and we use
this rule to form that quantification
okay and then the calculus of
constructions additionally adds these
two forms of quantification and these
correspond intuitively to type
constructors like lists list which is a
constructor which takes type and return
the type and dependent types which are
types that can depend on values the
values here there is the type you say
well you're allowed to have types that
depend on values using this rule okay so
all these different rules allow
different kinds of function spaces to be
built this is the ordinary function
space of functional programming
languages this is pulley morphism this
is type constructors and this is
dependent types so we have this nice
little picture where every rule
corresponds to a kind of typing rule we
went out Lau of type construction ok and
then this u- is mostly important for
historical reasons I just wanted to show
it because it's it's very similar to
system f but it also allows polymorphism
at the kind level this is kind
polymorphic ok and then a cc Omega
is basically the core cook and it's a
little bit more complicated because they
have this infinite set of sorts as star
and box I for any I a natural number
okay and this has a bunch of rules where
you say star is of type box I for any I
and box eyes of type box J for any I and
J such that is more than J okay and it
has these complicated rules which are
generalization of the rules for the
calculus of instructions okay so it has
this infinite hierarchy of of sorts and
this forms the basis of the calculus
constructions so this mainly serves the
purpose to show that we can express all
these really powerful or really
interesting type systems just by a very
simple set of sorts rules rules and
axioms okay now normalization in these
systems is a very slightly if you had
box sub-zero's same s star
I'm sorry what line the the last time
what if
so the box you have locks survive
right here yeah
any one of those boxes right yes is my
question is is box zero the same thing
as far or didn't
no box hero is just right about star
yeah its star than box hero than box 1
mux too that's sort of the mental
picture you need this rule should that
the star has a special status right yes
yes yeah okay yes if your point was is
this star redundant now that we have all
these infinite boxes the answer is
actually no because of this rule and
thank you Leo for pointing that out
equal to start would that mean that oh
it strictly less than okay I was
wondering if that nectarine consistency
missed our home star well I haven't said
the stars and stars inconsistent yet but
yeah it would you basically you you'd be
you'd contain the system basically but
yes star has a special status you have
box I star star whereas here k has to be
bigger than the maximum ok so if star
was box minus one say this this rule
would be violated okay what does it mean
for pure types is to be normalizing it
just says that if you're well typed
using this type system corresponding to
appear to the pier type system then you
have a BD normal form okay that's what
it means to be normalizing a
normalization is quite nice because
first of all it ensures decidability of
type checking which is which is the
least you could ask of a type system is
that you could decide whether a term has
a type or not and normalization gives
you that guarantee it allows you to
compare terms which is necessary to be
able to perform type checking okay and
the second thing it implies is if you
view the system as a logic if you view
this pie quantification as a universal
for all and you think about these types
as propositions the normalization
implies consistency this logic it
implies that obviously false types are
uninhabited or that not all types are
inhabited which is in general
what consistency of illogic means not
all propositions are provable okay
normalization gives you that property
because you can look at normal forms and
you can prove that some types cannot
possibly have an inhabitant a normal
form okay so normalization is this
really important property that you'd
like to be able to guarantee for pew
type systems okay the thing is is really
hard to predict okay I I took all the
types of sins we had previously with
these axioms and rules and simply type
line of calculus is normalizing of
course in the two versions but then you
have this sort of similar system where
this is the only difference and all of a
sudden it's not normalize anymore okay
now in retrospect you could say well
it's obvious because type is of type
itself and so there's this kind of
circularity but I can assure you that
it's actually not obvious to find a
counter example that actually is not
normalizing so this came as kind of a
surprise system f which which doesn't
seem much much simpler than star star is
normalizing and so is the calculus with
instructions it looks really complicated
this u minus it's it's just a little bit
more complicated in the system f you
only allow this extra polymorphism over
kinds this is not normalizing okay this
was also kind of came as a surprise and
this crazy system that has this infinite
tower of sorts it is normalizing so it
seems like there's this sort of random
jump where you have normalizing
sometimes and not normalizing sometimes
and it's very difficult to predict which
one is going to be one thing that was
unclear last time I gave this talk it's
unknown whether this problem is
decidable or not nobody knows if there's
an algorithm where you put in a type
system and it outputs yes if it's
normalizing you know if it's not this is
just a very hard problem so how do we
check this problem and
the mathematician in me says well when
you have a hard question you have to
decide to not answer it okay you say
okay this question is too hard I'm going
to ask a different question and
hopefully this different question is
going to shed some light on the original
hard question so the different question
i ask is given normalizing PT esas what
are the operations that preserve
normalization what can I do to a pts how
can i modify pts in such a way that the
resulting pts i have is still
normalizing if the original ones are
okay and this is what i call the study
of the structural theory of pure type
systems I want to examine the set of all
pure type systems and understand the
structure of this large set okay I want
to understand the interaction of how you
construct new new pure type systems that
in ways that preserve normalization okay
okay here's the pts that I calm in log
ok because it's minimal logic minimal
implicit of logic okay so it's a very
very simple logic where I just have a
sort of all propositions and then I have
this sort of worlds which sort of is
just a sort containing the sort of all
propositions okay and I have this rule
that says you can build new propositions
as implications this rule allows me to
build implications now you may notice
that this is just exactly the simply
typed lambda calculus of earlier okay
but it's seen as a logic ok so i renamed
the sorts so there was more apparent
this is a logic ok which is just minimal
implicit of logic ok so it's a very
simple logic and in particular since it
normalizes it's a consistent logic so
you can you know that this logic is
consistent but it can only express
implications which is not that
fascinating I mean first year logic
students can easily understand this we
want to examine terms now so we build
this new pts which contains this sort
which is the sort of all sets okay I'm
going to look at sets of terms and I
need a sort to classify these sets of
terms now I have this other sort that's
going to allow me to build term
constructors functions that from terms
build other terms okay and so set is of
type univ which allows me to declare set
variables say suppose we have a set a
okay and these two rules which seemed
more complicated in the previous ones
are actually simpler I say that if I
have a function from set two sets that
lives in the new sort fun okay so once i
have a function the function space is
not a set anymore okay so i can build
the functions but I can't keep iterating
this okay which means i only have sort
of first order terms okay i can build
functions okay this this allows me to
build functions with several arguments
but these two rules only allow me to
build first order functions functions
that take a number of arguments in a set
and that return an element of a nova set
okay so this is a really nice pts that
only allows me to build first order
terms okay so i have a pts with simple
propositions i have a term language with
first order terms now what do I want to
do I want to build a new pts that allows
quantifying over these terms using the
simply the the simple logic binlog okay
and to do that I build a new pts which
just takes the sorts of min logon term
puts them together
okay and adds a new sort okay multiverse
which is unrelated to all the other
sorts okay then I keep the same axioms
and rules so I still have my terms on
one side and my propositions on the
other side but now I'm allowed to make
propositions depend on sets okay
propositions that depend on sets still
are propositions and this allows me to
form universal statements about terms
okay and these two rules wait what is
worlds already is these two rules allow
me to quantify overall propositions okay
I can quantify overall propositions
using this over a proposition so I can
say for all P P implies P for example
but the resulting proposition is of a
new nature okay is this conservative
extension I talked about earlier i want
to be able to quantify overall
propositions but then I want this to be
a higher level proposition a new
proposition the mid-level yeah it's the
type of problem you okay uh she so if I
quantify on well proposition then the
sort of of that type is its worlds ok so
now this these two rules allow me to
quantify overall propositions okay and
this rule allows me to quantify Oh over
terms to get a proposition that talks
about all all terms in a set just giving
you like a very good you know
variable energy that yes this allows me
to quantify once over all propositions
this allows me to quantify again overall
propositions so usually these two rules
come together I mean are you you could
have if you didn't know anything about
what these sorts actually meant
semantically you could try other
combinations and in the prop set prop
and may not make much sense but it's in
technically by it yes why I mean did you
design these particular instructions
because you were aiming for you know
first order logic yes yes but i'm going
to show in the next slide that there's a
theorem it allows me to say things about
these special rules so it's a serum that
takes these rules and say oh will they
satisfy a certain criteria the criteria
may satisfy is in particular implies
that my new pts is normalizing if and
only if the old pgs is we're normalizing
ok so these rules have a shape that is
simple in some sense it doesn't add
anything to the pure type system the
first rule I see is having some
interaction between the two pts right
yes the next two rules are all from you
know compositions of sorts from just the
first just you're the first three two
years ago yes
that's true but in sometimes these rules
allow more expressivity about
propositions but they don't allow us to
prove more propositions it's a
conservative extension so all the
propositions in the original logic that
we're unprovable are still unprovable I
can't prove any new propositions terms
and just take you your second and third
rule yes
that would have given me more food that
would still have been your you're going
to tell us about a theorem that would
ensure that that system is still
apologizing yes
so this this answers the question I
asked at the beginning of this slide
which is how do we add polymorphism in a
safe manner and this is the answer I
mean these two rules add polymorphism a
safe manner and since they satisfy one
of my theorems you're guaranteed just
syntactically that you can't break
normalization yes so okay so in more
detail I'm explaining that this rule
sets that prop allows building
propositions that depend on terms so if
I have a set variable a and I have a
proposition that depends on a I can form
this because of my set set proper rule
I'm sorry no I yes I can form this
because of my set set proper rule and I
can form this universally quantified
statement which says that for every X in
a P of X implies P of X now and I can
even prove it but that's that's a that's
not the important part the important
part is being able to express statements
that depend on terms alright so my set
that prop allows for these kinds of
propositions and the world's prop
multiverse allows us to additionally
quantify over p for example okay so i
can say for any p which is a predicate
on the set a and for any X in a P of X
implies P of X and this is of type
multiverse okay this is not a
proposition it's something that lives in
a higher world you had sex n funner than
seven prom oh yes there's a typo
ok said problem bro yes darn I missed
that one the first time around yeah yeah
said prop sorry so you see this is a set
and this is a proposition and the result
we get is a proposition ok so the
theorem is if then login term are
normalizing then this new fol pts I've
just constructed is normalizing ok and
in fact we can additionally show the fol
is a conservative extension which means
that there are no propositions which
were unprovable in min log and that are
now provable in fol ok we can express
new things and prove them but certainly
the old things haven't changed there are
no new provable propositions from min
log all right and in general ah so I've
basically said what I wanted to say but
I am going to show how we express
formally this theorem and the formal
expression of the theorem basically says
I can take two pgs is P and Q and I can
take their disjoint Union okay where I
just take the sorts and I suppose that
they have zero intersection and just put
them together and I get a new pgs okay
and the first theorem is that if your
type in this new pts then your typed in
one of the old pts is ok but this
theorem is a little bit subtle to
express because this context could be
mixed it could be a mixed context that
takes some types from P and some types
from Q so you have to sort of filter out
the the unwanted context this this this
proposition is actually non-trivial
okay and this theorem that says that in
the disjoint some you if your type belen
the disjoint some then you're type belen
one of the two it implies normalization
of the disjoint song okay so forming
disjoint sums is safe but I've done two
things I've formed the disjoint some and
then I've added these extra rules and
these extra rules i've added are all of
the form either skk like the set prop
prop rule i added where s is in one of
the pts s and K is in the other one of
the pts is okay these tuition is that
these rules if we add them for every
sort NP and every source and q creates
the pure type system which is the qlogic
of p terms okay p was the pts that all
this to form terms and sets and q in
mid-log was the pts that expressed
minimal logic and so by adding these
rules we formed a logic which talked
about p terms but which had propositions
from the qlogic okay the second thing we
did I'm sorry so the theorem is that
this new pts with these extra rules is
normalizing if and if if and only if
both pts is are normalizing so P and Q
are normalizing and the second thing we
did was allow quantification overall
propositions and to do that we added
this new special sort that I called
multiverse but that here I call SS
triangle k and then I added these two
rules okay which says I can quantify
over s for any k but I have to bump up
the result I have to end up in this new
sort and this allows me to keep
quantifying over
to quantifies several times over s okay
and I call the resulting pts p hat and
the intuition is that you can quantify /
s parameterize case using these rules
okay and my result again is that if i
add all these extra rules I'm
normalizing if in only if I was
originally normalizing okay so these are
two methods to combine pure type systems
whilst preserving normalization okay and
the proof I'm not going into it but it
involves identifying unique sorts
associated with each read X okay and the
read it the sword is going to classify
the read X and AH and we need to sort of
consider each read X individually so we
can erase all the read X that come from
one pts and just examine the term
cleaned of all these read X's and on the
other side we can just examine each
individual read X from the other pts
okay and then we need a commutation
result which kind of says well some
reductions can be done in one pts and
they won't interfere with any of the
read X is done in the other PDS okay so
this is very combinatorial proof and it
uses ideas from vanity and lesson who
who have the similar goal of trying to
enrich pts so that it could express more
things okay wow yeah I'm pretty early i
guess nobody is going to complain about
that so pure type systems can be used to
ask and to answer questions about
quantification main question we asked
was what kinds of quantifications can we
add to a logic
without risking inconsistency or without
making it more powerful in the sense of
more things are provable just more
powerful in the sense more things are
expressible my second observation which
is kind of I feel the real message I
want to get across is that it's
interesting to study normalization
preserving extensions okay often we take
a pts and we try to prove its
normalizing sort of independently of
everybody else we sort of put it in a
black hole we studied just that PPS but
what I'm saying is that we should study
combinations and interactions between
PTS oaths and this is an interesting
field of study because it allows us to
build richards type systems we were just
talking about f star yesterday and f
star can be seen as a very rich type
system which is made of these different
components that we put together in a
larger system which is very expressive
okay so um I've shown that certain rules
can be added safely I'd like to be able
to say okay using these proof techniques
these are all the possible rules which
can be added okay I think there are more
rules that are safe that can be proven
safe but I haven't characterized exactly
which rules can be added to a pts and
the question here is can we take systems
that are sort of built like this that
sort of have this term component in this
logical component and can we simplify
for example consistency proofs using
this approach often you want to show
normalization of the propositional side
but you have these terms that come in
and so you're scared they interact in
some manner and you have to show that
they don't I'm wondering if this result
is generally enough to be able to say
okay once and for all this is what you
need to show to be sure that there's no
interaction between the logic and the
programming side
a few of your type system okay so of
course an obvious extension is what
happens when we add inductive types what
happens when we add existential types
what happens when we make our type
system more complicated what point do we
lose these nice results and finally this
is more speculative it'd be nice if we
had a proof that was less combinatorial
often there are proofs of conservative
ities a combinatorial version which is
very hands-on and then there's a
semantic version which is often a little
bit more abstract but often much more
succinct and more powerful so I I'd like
to be able to understand a model
theoretic view of these conservative ed
results that's all I had to say about
this so thank you very much these are
the references if you want to see them
and I'd be happy to answer any questions
no there there there are parts of the
theorem which are reasonably
straightforward which are just rewrite
theory but there is a part that's that's
quite technical in particular this
disjoint some separating it's it's quite
technical so it would be it would be a
worthwhile effort I think to prove this
theorem formally I'm afraid I will have
much experience with proving formal
statements about about programming
languages and cook but yeah it would be
it would be worthwhile I've heard and
it's not sort of unfeasible because
there's been a lot of work on pure type
systems already
yes yeah there other systems but pure
type systems have been studying cook I'm
sure of that I don't know if they've
been studying in other things probably
octo I don't know he's a bell maybe not
because they're not as interested in
dependent types but but maybe there are
things he needs a bell there's some
people working on type systems that
to the system for example trellis which
chooses to include starveling start
letting on to this system being
inconsistent but tries to isolate within
that system a core that remains
consistent have you thought about how
you might try to do that in your setting
like have some part of the system that
is crazy but your absentee robot some
yeah so trellis is interesting because
it was part of the motivation for this
result because travis has some non
termination for example that's the
programming part and then you want this
logical part that's terminating and you
want to say oh well there's this
separation I mean you want to have this
system and you only have Q that's
normalizing okay but we can show that if
Q is normalizing then in this system if
you have someone that that comes from Q
it has a normal form so that's one of
the motivations I had you you want to
show this in trellis and it's hard but
but then there's this additional thing
where they have this inconsistent type
system but they say okay well if you
know after the fact you show that you
haven't actually used this rule then
then you're okay and I haven't really
thought about that but in general it's
just for convenience in some sense I
think if they could add universes in a
simple extensible way they would have
added universes they just say okay we we
put type type and it's convenient but
someday we'll add universes we won't
need type f anymore
I think of it only as a convenience I
mean it's also an expressiveness thing
you get to write not have any programs
because you may want to yeah but adding
type type those things you know I agree
I agree and you want the knob
determination to be in your term
language and not in your proof language
and yes this is this approach is sort of
has the ambition to be able to analyze
these types of systems but I think type
type is sort of beside the point when
you add a non termination you want to
add a fixpoint operator you don't want
to add type type because you can't you
it's it's an open question whether you
can actually write a fixpoint Combinator
and type type you can have non
terminating terms but you don't have a
fixed point Combinator so type app is
kind of it's an accident it's just a
convenience it it dispenses you from
having to think about about universes it
makes everything simple let's just make
things inconsistent this kind of an
inconvenience but yeah you definitely
want non termination here you want fixed
points and here you definitely want
termination because it's a logic and
this this work is definitely aimed at
saying things when P is non terminating
and when q is terminating I haven't
talked about this because it's a little
bit less pretty to express but you can
have a theorem to that effect what you
do have something about the case where
he is yeah yeah but it you can't just
say for all PQ is no one lighting you'd
have to say for all terms that are of a
sort which comes from Q that term has a
head normal form so it's a little bit
less elegant
okay well thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>