<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Charles River Crypto Day: On the Power of Secure Two-Party Computation | Coder Coacher - Coaching Coders</title><meta content="Charles River Crypto Day: On the Power of Secure Two-Party Computation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Charles River Crypto Day: On the Power of Secure Two-Party Computation</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CEQC-BWAeM4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
and we saved of course the best for last
we're going to have mood to tell us
about the power of secure to party
computation or as you all know it to pc
in the hips so much thanks near is it
clear to everyone my voice okay first
thanks Yale Microsoft near Daniel and
vinod for giving me this opportunity to
present this work this work is joint
with her Methos I from bar-ilan
University so let me start this talk is
about three primitives that we have
known and loud for a long time in
cryptography this is secured two-party
computation zero knowledge and
randomized encoding what I'm going to
convince you on a very high level
towards the till da by the end of this
talk is if my thing works yes it's
working awesome is I'm going to give you
a general transformation from secure
two-party computation to zero knowledge
I'm going to not show you today but
there is a transformation from two-party
computation two randomized encoding and
from randomized encoding to zero
knowledge ok now i want to stress that
we get into the specifics yes yeah so i
want to stress that it's easy secure
computation is actually a general more
general problem than zero knowledge but
if we use this general way of
instantiating zero knowledge from secure
computation you will have to rely on
oblivious transfer I want a
transformation that does not require
oblivious transfer as an assumption and
actually almost all our constructions in
this work require one wave functions at
some point I might need one way
permutations and I'll tell you then now
yes
yes so why do you say what do you need
oblivious transfer if you instantiate
zero knowledge as an instance of secure
computation then the assumption you
require is oblivious transfer and you
will also not get proofs you will only
get arguments so I want to I want to
take yes then that I'm saying that this
is trivial if I assumed oblivious
transfer again arguments not Proops but
I just want to stress here that yes so
we'll come to that so let me start with
am going to say I'm going to talk about
this transformation and this
transformation today and the other one
you can look at our people all right so
whatever results in a nutshell before
more questions get raised our first
theorem is let L be let R be an MP
relation given any semi honest two-party
computation in the OT hybrid then
assuming only one wave function I'm
going to construct a static
zero-knowledge proof for this relation R
where F is going to be something thats
related to our and I will also tell what
this black box means so given a secure
computation of a protocol for F that is
related in our I'm going to give you a
transformation where I use only one wave
function and give a static
zero-knowledge proof for the relation on
okay I'll tell you what static is when
you static is what we all know what zero
knowledge is the next theorem will say
why I specifically said static over here
okay so previously what did we know in
this in the space well we know the
classic zero-knowledge proofs for the
classic NP complete languages this is
what we learn in typical crypto classes
yes something that is related to yes I
I'm not telling you right now ok now
the second one which is also a very
seminal result in the space shows that
if you start from any information
theoretic multi-party computation
protocol or an MPC protocol in the OT
hybrid with three or more parties you
can transform this using a generic
compiler to a zero knowledge proof and
this was done by issue I kosher love it
ostrovsky inside yes yes that is also
one of the points about this
transformation but more importantly I
can do it from a semi honest two-party
computation as opposed to MPC which was
known before yes what I want to gain we
will come to that each of my theorems
have something to gain about and I'll
tell you what's the yes black box it's
not something you can get without with
the water on promising right yes that is
one of the things that you can't get I
mean I'm also saying that this F ok
maybe I can be a little more precise
this F only will make sort of a black
box call to our in which case you cannot
do any of these sort of you can't use
any of these zero-knowledge proofs
because here you have to know the
relation to construct these
zero-knowledge proofs yes yes yes yes so
we don't like to party doesn't have
information theoretic so I don't need
infant I don't need information
theoretic yes all right so let's go to
the second theorem which I like the most
but probably not the mainstream people
might not like that as much it requires
some taste given any semi adaptive semi
an honest two-party computation in the
OT hybrid again not quite the OT hybrid
with some more restrictions and I will
get into this later but I just want to
tell you what the theorem statement on a
high
is given such a two-party computation
we're semi adaptivity means some minimal
amount of adaptive security and adaptive
security is basically about telling when
a party is corrupted in an interaction
static means it's corrupted at the
beginning adaptive means it can be adapt
the adversity can adaptively decide when
to corrupt as well as there is an
additional case where an adversary can
corrupt all the parties as well okay and
semi adaptive is a specific kind which I
will get into later what do i construct
given such a two-party computation
protocol now again assuming only one
wave functions I can get an adaptive
zero-knowledge proof for the relation R
with similar conditions on the function
and I can also get an offline online
randomized encoding for F now this one
you probably have to take it with the
bucket of salt I'm not going to talk
about this now but you can come and ask
me after the after the talk what this
result exactly means here so i'll get to
that as well sorry for being very vague
right now so i want to say that
previously the only work that talks
about adaptive zero-knowledge proofs is
so adaptive 0 you just think of the
classic zero knowledge requirement but
in addition if I just want to sort of
take the essence given a simulated view
the sim you should also have an
additional algorithm that can explain
the simulated view as something that was
honestly generated for true statements
ok so you run the simulator it produces
a view but then after that there is
another button I can push and the
simulator should now give me random
coins for the honest prove are
consistent with this view so when I push
this button i give the simulator the
witness as well but it needs to generate
random points for the honest proven so
that's adaptive zero knowledge yes
this can be formalized in the UC setting
but I didn't want to get into that so
that's why I I don't want to talk about
it all right yes randomness of the
proven that is the hardest case I mean
all right the third result which is I
think a little more interesting which is
that given any MP relation R and any
robust randomized encoding that secure
against adaptive inputs I can construct
a black box construction of a four-round
delayed input commitment proof protocol
I know there are too many terms here let
me just break down a little bit so what
is delayed input this is actually
something that Silas mentioned a little
bit to get these very efficient round
efficient protocols you want is zero
knowledge protocol that has an
additional property where the honest
proven does not require to know the
statement until the last round okay so
that's the delayed input property and
commit and prove is again in the UC
literature people know when they see
what commit and prove is but roughly
what this says is I can commit some
string and then I want to prove
something about what is being committed
over here ok now the non-trivial part of
the statement is the black box
construction based on one way
permutation so let's see what we know
before previously so we can do standard
commit and prove from any the
information theoretic multi-party
computation or three or more parties
using I Kos now this does not satisfy
the delayed input property and I will
also tell you why it cannot sort of you
cannot hope to achieve this delayed
input property using the I casa proach
well if you want to settle for the non
blackbox constructions we knew how to do
this since the 1990s by lapid shamir and
feigl Apodaca mere and in fact this is
the protocol which is used in the word
that Silas mentioned for getting a
four-round concurrent non valuable
commitment they needed such a protocol
to use
they're to extend the three-round to get
zero knowledge property they needed a
delayed input commit and proof protocol
to get a four run on valuable commitment
yes I know the think of it that I know
the witness but I don't know the
statement so in the case of non valuable
commitments I know what message I'm
committing but later I need to prove
some relation regarding for instance in
his word you need to show these linear
relations among the things that have
been committed so you don't know what
the you know what the relation is you
just don't know what the statement is
because it depends on the second and
third message yeah confuser this word
black box so are you so it seems like
the statement is like making non black
box use of a cryptographic primitive so
are you giving like a are you changing
the statement so it doesn't it no longer
makes it so will you actually get an
officially if you if you formulate what
you want as a commit and prove call then
there is no like non black box in the UC
sense if I had this primitive called
commit and prove I can commit and then
later prove anything about this thing
okay about the about what value has been
committed over here are you gonna
explain it later what is delayed input
commission prove because I think it is
no I I mean that's as much as I'm going
to say what delayed input is so delayed
input basically is simple right i mean
if i have a four-round zero knowledge so
in the context of commitment prove I
know something about let's say just the
witness that I ok or rather let me make
it more simple I know the witness and in
the first round I want to commit to my
witness and then I only know in the
fourth round I know what relation I need
to show that this witness satisfies or
what statement the relation also i can
say that i know what the relation is
it's not a weird kind of setting it's
exactly used in the non valuable
commitments because they do something in
the first three rounds and in the fourth
wrong they need to prove something about
the value committed to in the first
round
and it's also exactly what I gave after
that shamir do where they like commit to
the Hamiltonian cycle first and then
they open like something we need to
later so what is the delay this is not
being purchased relations yes the
statement the relation is known yes yes
because I already start with our being
the NP relation and also it has some
implications two tokens if you use
tokens for commitments then you can't
quite the only way you can do commit and
prove is by using I mean with round
efficient protocol is by using such a
delayed input commitment probe which I
won't get into but it has some
implications to tamper proof hardware as
well yes like you purchase soundless eva
the bursary delays a choice of the no
distance or your studio yes yes even for
adaptive inputs which i did not mention
but also for adaptively chosen input
statements all the properties hold the
simulation holds somnus also what kind
of relations are you allowed to any MP
relation yes okay so let me I just want
to point out that there is another work
in the space where given delayed input
protocols that have been this there's
this recent work of olay at all but i
mean i should say chumpy at all that
shows how to efficiently compose delayed
input sigma protocols all right so the
two important like at least corollaries
of this work I just want to state it one
is combining the word that Silas talked
about a little bit at the beginning of
the stock which is by oil rose and
richelson and world if you combine their
work with or commit and prove protocol
we get the first black box construction
of a concurrent non valuable commitment
actually this is based on one-way
permutations I apologize in four runs
previous construction either required
more rounds or depended on the
underlying function in a non black box
with or it had
concurrency so it was it was restricted
in one of these three ways but here we
show concurrent non valuable commitments
based on one-way permutations in a black
box and another corollary which again I
won't talk about is we can combining the
work of God Gentry Holloway and Reich
over we can show that in the
tamper-proof model we can get a
three-round you see secure multi-party
computation protocol and so the work of
garg at all actually shows how to
construct a two-round in the common
reference string model this is sort of
the first work that shows in another
sort of you see set up model in the
tamper-proof model we don't know that I
don't know that or rather I should say I
don't know that and there is a specific
reason why we can't get it below three
round at least in our protocol all right
so let me start the definition of zero
knowledge I just like to present it so
I'm going to present it it says that for
every malicious verifier there is a
simulator s such that the view observed
by the verifier in a real world or in a
real interaction with the prover can be
simulated by this simulator and the only
additional point i want to say which i
already said before which got erased
again quickly that's because of my
animation I apologize but what it says
basically is that if I additionally want
the zero knowledge proof to be
adaptively secure then I need to show
that after the simulation has output a
view I should also be able to produce
random coins to show that this is
consistent with an honest proven okay so
that is an additional requirement to
prove something is adaptive zero
knowledge all right so let me for some
reason mine okay so the first theorem
let me just state it more formally what
I am going to say here so let R be an NP
relation suppose pi F is a secure to
party / computation protocol in the OT
hybrid for F which satisfies two
conditions one it should be perfectly
correct which means that it does not
admit in
bad randomness in the protocol and the
second is that it's you see secure
against semi honest adversities i only
need semi on a security and this you see
can be weakened but just for so that
it's easy for me to describe I'm saying
that it's you see secure against semi
honest adversities then I can show that
one way that is assuming one-way
functions there is a static
zero-knowledge proof for our okay so
this is the formal statement again I'm
going to say that F can be defined with
an Oracle call to our which is sort of a
feature of our transformation all right
so before i get into proving this result
i want to say this previous result of i
cost and sort of show why that does not
work in the two-party case okay so what
did they show they show that they
construct a zero knowledge proof for a
relation or given any n party MPC for a
related f and i'm going to show you what
the related f is so given an NP relation
the related f is defined as follows you
take as input end parts sort of think of
n chairs and the relation is evaluated
on the XR of these shares now how does
this zero knowledge protocol work the
prover in her head evaluates or sort of
similar emulates an MPC protocol with
the following function where w 1 through
WN are the inputs of these parties and
generates views for all these parties in
the first round it commits to each of
these views individually then the
verifier selects a random two pair like
a random pair of views among the n views
and asks the prover to open ok and sorry
before i go into this roughly the the
idea behind this protocol is if this MPC
protocol is perfectly correct and if the
prover can answer all the questions
correctly then it defines a valid MPC
view for this functionality and if this
MPC is perfectly correct
then the statement has to be true okay
so that is the soundness of this the
soundness is not negligible but it's
still good and simulation on the other
hand will use the simulation of the MPC
where the simulator basically just
guesses I and J and commit to those two
views correctly using the simulation for
the MPC protocol yes it will actually be
like one minus one over n N squared or
something like that yes and their work
has plenty of other constructions which
make it extremely efficient I mean if
you're looking for communication like
the number of bits transmitted that's
the work that you have to look at all
right so now how does one instantiate
this MPC protocol there are one of two
options that you can use one is used any
information theoretic MPC protocol that
is perfectly correct or robust as they
define but any such information
theoretic protocol requires at least
three parties okay it's not sort of
relevant to what we are saying because
we are looking at two-party computation
protocols but they also actually
construct something for sort of using
protocols like GM w which is defined in
the OT hybrid but however they still
require three parties when they are
using instantiating their MPC with GM w
this is because they have to verify
these oblivious transfer calls they need
to open at least two views in in this
case to verify that the OT transmissions
were correctly encoded you want to see
the sender's view and the receivers view
in these commitments so if you have to
open at least two if you want privacy
you need at least three parties so that
is why this approach does not work for
two-party computation protocols and I'm
saying does not with the star because I
presented this in the desert workshop
and you well after some time came and
said there is a workaround to use three
parties but start from a two party so he
shows that if you start from a two-party
computation protocol you can move to a
three-party protocol and then
instantiate it using random Ortiz
so I am NOT going to get into it but
there is sort of a workaround but
directly it does not work here okay all
right so let me give my construction
this is actually extremely simple what
is the function that we want the two pc
for yes so they use they can
instantiated with GM w in the OT hybrid
but the way they encode the OT channels
is the the sender encodes what the the
center sense on the OT channel in the
receiver encodes what it receives on the
OT channel now to in order to verify
that all these OTS were correctly
encoded for soundness proof you need to
open at least two views otherwise you
can never check that the OT was
incorporated into the views correctly
yes so the soundness will break alright
so how do we get a static zero-knowledge
move it's already half an hour so let me
go a little fast so the function is
going to be very similar to the the I
cause where you're just going to XR the
two inputs and evaluate the relation on
it so what is a protocol well the prover
is going to do a two pc in the head is
going to run this two-party computation
protocol where it's going to sample
randomly w1 and w2 such that w1 plus w2
is the witness now in the first round
it's going to send just the transcript
of the interaction so this is sort of
different deviating from the I casa
proach where the views were sent we are
going to send just the transcript of
this interaction now the verifier again
is going to say B equals 0 or 1 if it
sends actually one or two because my
parties are named one or two so if B is
one the prover opens gives the input and
randomness of party p 1 and the verifier
checks if this view is consistent with
the transcript and if b is two it gives
the input and randomness of p2 now why
is this sound well just using the same
this is just follow similar to the I
cost where if you give me correct input
and randomness for both these parties
from perfect correctness I will get
soundness now
simulation on the other hand I will
guess what bit it is and then use the
corresponding simulation I have assumed
that it is I have static simulation of
both parties p1 and p2 okay all right so
I'm just going to give you a very high
level just pictorial diagram of why this
is secured yes okay he already observed
this it's coming in the next slide
alright cuz it hold on yes it's still
half okay so I'm just going to tell you
that to show the case for B equals 1 we
will invoke the UC simulation for this
and for B equals 2 we use the simulation
for the second party there is a subtle
point that i'm not talking about which
actually I do need sort of some flavor
of you see securities because the inputs
for p1 and p2 are correlated they are
distributed depending on this w that's
why I need sort of you see security to
argue both these indistinguishable ax t
holes okay but now the question is what
about OT channels now in your 2pc
protocol you are giving this transcript
and the prover the two parties are also
going to engage in OT channels so what
are you going to do so let's say let's
I'm just going to give you with a single
example suppose p 1 and p to engage in
the following oblivious transfer where p
1 has inputs s0 s1 and p 2 has input t
now i'm going to incorporate it here by
for every OT i'm just going to make the
prover commit to these two inputs
separately now for the b equals one case
where I open p1's view that is P ones
input and randomness i am going to
decommit both these guys but for the
other one i am only going to decommit st
and this simple trick will help you
encode the the oblivious transfer and
the only thing i have used is
commitments which can be based on
one-way functions okay there is another
view which i haven't written here
another
way of looking at this is I am actually
using a randomized encoding of oblivious
transfer where this can be thought of as
the offline part and this can be thought
of as an online part and I will talk
about it a little bit little bit later
towards the end of my talk but there is
a way to see how I encode this OT
channels as a randomized encoding and if
you generalize this from ot to all the
way to the function you actually get one
of our transformations of randomized
encoding to zero knowledge directly if
you didn't follow that that's fine we'll
just go on with the talk okay all right
so this is how we get this is our first
theorem and I want to just say that a
simple corollary to this I mean this is
sort of where we started with this word
is that you get a very very very simple
zero-knowledge proof based on gobble
circuits and I'm going to very quickly
tell you what this thing is we use now
we don't need to do any secret sharing
let's just say that this is the function
now you can think of the prover just
giving the gobble circuit for this
function and commits to every input
label in the gobble circuit now the
verifier can say B equals zero you just
open the gobbling and if it's b equals 1
you just give the labels corresponding
to the witness and the verifier will
check if the circuit evaluates to 1 this
is actually a very simple zero-knowledge
proof based on gobble circuits and you
can also do soundness and simulation I'm
not going to get into it alright so
let's let me go to the the second
theorem where i show how to construct an
adaptive zero knowledge and this sort of
highlights the properties of where we
use the real power of two-party
computation we're going to show that
two-party computation has the certain
adaptive properties that will help you
get adaptive zero knowledge on one end
and delayed input zero knowledge and the
other both of which has sort of an
adaptive flavor and I'm going to see
depending on how much time I have I am
going to show you these transformations
so the second theorem this is a little
more involved i'm going to go into the
conditions required for the two-party
computation so suppose pi f is a
two-party computation in the OT hybrid
with the following properties pi is
perfectly correct just as before and now
I want you
security against two kinds of
corruptions now when I am going to in
the rest of the talk I'm going to have
sort of p1 and p2 have designated roles
in my to pc i am going to put a lot of
restrictions but you will see that it
can be easily instantiated now the first
one I need is a static corruption of p1
followed by an adaptive corruption of p2
this is what is actually referred to as
semi adaptive security it was introduced
by Gary vicks and zoo and basically it
says that i need a simulator that can
admit the following adversary it
statically corrupts p1 generates p1's
view and then at the end post execution
it can also give me the view of p2 after
I give its input ok and the other one is
just simple static corruption of p2 I
need these I need simulations of both
these kind of adversities I'm stating
them I could have just said full
adaptive security and both of these
things would have been subsumed but I
want to specifically say that I just
need simulation of these two adversaries
ok and now this is sort of the
non-trivial requirement that we need
where p 2 is the receiver in all the
oblivious transfer interactions and is
the only person that receives the output
ok now there are so many restrictions
that I have made and now the question is
okay what do we get we get that assuming
one-way function there is an adaptive
zero-knowledge proof for this relation R
how can we instantiate this to pc
actually you can instantiate this with
both the GM w 2 pc as well as gobble
circuits the semi adaptive security is
actually not it's not hard when you want
to simulate it you can if you look at
both the GM w and your protocol in our
case if i know the input of p1 to
simulate its view i can just do it
honestly and then for p2 all i would
have to do is sort of simulate the
oblivious transfer to get a p2 is view
okay and the other requirement that p2
is the receiver and all
believe yes transfer since OT is
symmetric that also works out in the g
MW case and there are even if you look
at textbooks in they they define GM w
only with one party being the center so
all these restrictions seem seem a lot
but standard to pc protocol satisfy all
these requirements okay so what do we in
diverted we know before we knew that we
can construct an adaptive zero-knowledge
proof based on one wave function and
this was done by linda lands heiress and
they actually their approach was given
an NP language l they construct this
primitive which is known as an adaptive
instance dependent commitment scheme
which I will define in a minute they
show using the Blum hamiltonicity
zero-knowledge proof they show how to
construct this primitive and from this
primitive they show how to get an
adaptive zero knowledge and the second
compilation also uses Blum hamiltonicity
first i'm going to show you that you
don't need the second compilation you
can actually achieve it using the I
cause approach if I have this adaptive
instant dependent scheme then I don't
need to use this Blum hamiltonicity zero
knowledge and why I am stressing this
Blum hamiltonicity is because I don't
want that i want to be able to use a two
pc for a function that just makes an
oracle call to the NP relation and i
don't want any of those okay alright so
what is an adaptive instance dependent
commitment scheme this is probably my
ugliest slight but bear with me so the
definition is that it has basically
three algorithms one is the real
commitment scheme that given an instance
from the language l and a message
produces a real commitment for now let
us assume these are all non-interactive
now the simulated commitment there is a
second algorithm which is the simulated
commitment that doesn't take any message
okay it is an adaptive input dependent
commitment scheme the simulator does not
get the message just with the instance
it creates something called a commitment
then there is a third algorithm which is
the adapt algorithm which after the
commitment is generated by the simulator
given the input witness and the
randomness used by the simulator it can
open this commitment as a commitment to
any
message okay and this is a little more
stronger than general adaptivity
requirements this algorithm should
actually give random coins consistent
with the real commitment scheme it
produces a fake commitment and then
later you give the input witness and any
message it should show that the
simulated commitment is was actually
generated by the real commitment scheme
you have to give me randomness for that
okay so what are the two properties that
we need from such a scheme one is
binding and binding is simply stated by
requiring that the support of the real
commitment for two different messages is
are disjoint okay and the nobody state
hiding as usual commitment are hiding
but i am going to give the special
hiding property which will imply
standard hiding properties of commitment
scheme so what does this say it says
that given the real commitment a message
and the randomness used to generate the
commitment it should be
indistinguishable from a simulated
commitment so the simulated commitment
takes no message the message and then
the adapt algorithm generates random
coins consistent with the real commit so
this is the special hiding property okay
so given such an adaptive instance
dependent commitment scheme we can
actually construct adaptive
zero-knowledge I'm going to do that
first and then show how to construct
this primitive from to pc with the
required properties okay all right so
I'm going to do this first I am going to
start with the I course as I said I can
use this I cross protocol I'm going to
modify it using this AI dcs to get an
adaptive zero-knowledge proof what am I
going to do I'm going to make this is
just the first attempt and then finally
you will see what's going to happen so
the prover is going to use the the
adaptive input dependent commitment
scheme to commit to all the views the
verify of pics to and then the proven
opens these two views okay so now if I
wanted to simulate remember in I cause I
just guessed VI VJ and I can open them
okay but no the simulator what it's
going to do is it's still okay with
I mean this protocol is still simulate
able because it does not have to really
commit the other views it just has to
commit I and J and this it uses the
simulation of the MPC to generate the
views VI VJ the simulator in this
protocol ok I am still not there yet I'm
just trying to build it from the I cause
paper now the problem right here is that
I can't get adaptive zero knowledge
because if I now ask at the end of the
protocol please show me that this
transcript was generated by an honest
blower I cannot open these real
commitments to other messages okay
because as I told you the binding
property says that they are all disjoint
I can't now suddenly open it to a
consistent view I committed to garbage
as the simulator but later I need to
open it and now given that you have seen
what AI dcs can do the simple fix to
this is just replace the rest of the
commitments using a simulated commitment
now at the end if I'm going to ask the
simulator to produce the view at that
point I know the witness and when I know
the witness I can run the adaptive
algorithm and I can open all the
remaining views consistent width and MPC
execution of what I want ok but there is
a subtle issue I need to given i use the
simulator to generate VI + VJ but later
I need to find views of the remaining
part is consistent with VI VJ this is
sort of true for information theoretic
protocols they are usually perfectly
secure and we have to show it for the
bgw protocol but that is easily
achievable ok alright so this is the
simple part of the of the proof where i
show that given an AI dcs i can get a
two-party i can get an adaptive
zero-knowledge proof and this part again
uses the function only in makes a black
box called to the relation which follows
from I caused all right so now this is
the the non-trivial part of our
construction where we construct a I dcs
from this restricted two-party
computation protocol ok so let's just go
recall what were the requirements that
we needed we needed perfect correctness
we needed simulation against a static
corruption of p1 and an adaptive
corruption of p2 which is pictorially
shown this way and a static corruption
of p2 okay and the function is going to
be as before that we use to even for the
further static case and p2 is the
receiver in all OT instantiations and in
and also receives the final output okay
so now as I mentioned before all
requirements are satisfied by both GM w
and yeah alright so let me be let me
quickly tell you what is our AI dcs what
is the commitment to zero a commitment
to zero is just going to use our first
simulation not all the way remember our
first simulation is a static corruption
of p1 and an adaptive corruption of p2
so it just samples random coins w14 p1
and generates the view and stops at the
end just before it needs to produce the
view of p2 okay so this is a you see
simulation so it's simulating the view
of p1 after the execution complete it's
going to give p2 but it is going to stop
just before that and just give the view
the the transcript generated by this is
the commitment the real commitment 20
just runs p 1 gives the transcript of
the communication now what is a real
commitment to one is to run the
simulation s2 from t2 s point of view so
I have a second simulator that just does
static simulation of the second party I
generate a random input for it and I
produce its view okay so now what is the
simulated commitment the simulated
commitment is just going to be actually
it is going to be real commitment 20
apologize for this mistake I was trying
to make these things fancy and I made a
0 to a 1 all right so now I want to show
the two properties binding and
hiding the binding property okay I
didn't write it but the binding property
follows because if I can give you a
single transcript and an input and
randomness consistent for both p1 and p2
just as before from perfect correctness
i will i will get binding property i
should not be if i start with the false
statement i shouldn't be able to
generate views for both p1 and p2
consistently and the to show that i have
an adaptive algorithm the commitment to
the commitment just basically follows
the commitment to 0 which is this
simulation by s1 but now i'm going to
use the fact that it can also simulate
the view of p2 post execution corruption
ok but now remember the adaptive
algorithm has the witness w which means
it can now tell what the input of p2
should be after knowing the witness it
the venue when it actually generated the
commitment it just made w1 as random it
didn't know what to set W to us because
it doesn't know what the witnesses but
now they adopt algorithm knows the
witness and it can now tell what the
input of p2 should be and it can produce
the view of p2 so in this way the adopt
algorithm given a simulated commitment
can give both views of p1 and p2 yes
lindell's Harrison the commitments give
is information theoretic for both hiding
and binding right it's like an instant
dependent corey rescue yes so do you
inherit the same property that you have
yes if it's perfect correctness yes we
do right now the I need to also show
that i need to show indistinguishability
the special hiding property I'm not
going to talk about it but I need to
show that the view output for the ok the
first part is easy to show that the
commitment to zero is the same since the
simulated commitment follows the zero
commitment algorithm that is easy it's
just direct
but to do the one it follows the zero
commitment strategy and then uses this
adaptive corruption of p2 only in that
case I need to show that it is
indistinguishable from a commitment to
one okay and this follows from the semi
adaptive simulation property of my to PC
that is why I had all these requirements
for my to PC ok because a real
commitment to one just follows s tues
algorithm and a real commitment a
simulated commitment when opened to a
commitment to one uses the semi adaptive
simulator now I can use the semi
adaptive you see secure property to show
that these two are indistinguishable and
it's a direct argument there is no
complication in showing this all right
so now we have got an AI dcs from any to
pc we know how to construct an adaptive
zero knowledge from any AI dcs
everything is clean it uses only the
function the function uses the relation
in a black box so we get a soundness
half adaptive zero-knowledge starting
from any semi adaptive semi honest to pc
okay alright so the next few slides are
going to be a little more ugly but I'm
going to try to do it at the high level
yes so you have operations you're not
doing anything fancy no lie canopy
relation just linear operations you can
get sound mishaps just normal cut and
shoes yes so is the point I'm going to
answer your question okay so I said I
can instantiate my two-party computation
with the our GM w now equal voce ting
just one bit meaning to just commit to
one bit of a message I need to run this
to pc protocol and the entire transcript
if you remember the commitment was the
entire transcript it will be s times
poly k where s is the size of the
circuit let us say that we use g MW in
GM w the the communication including
this oblivious transfer is going to be
size of circuit times polynomial in the
security parameter and then if i use for
the second part of it for the I cause
part of
use bgw that is going to require me to
get I need to do order s bit commitments
so this would give me actually an order
acquired poly k communication adaptive
zero-knowledge where s is the size of
circuit and i only get soundness half
but i want to say this already improves
lindell zerosum which does this car
production to car production to the blum
hamilton the city and its s to the 4 at
least and if you use this I cause it
becomes s cubed but it's still it's
still worse than this but we also show
and this is sort of the most technical
part of the paper that i am just going
to sort of tell at a very very high
level we get down we get negligible
soundness with just s times polychaete
ok now i want to compare this with the
static zero knowledge which i haven't
said I course gives the best
communication efficient static zero
knowledge for any NP relation they
actually show its order s plus poly case
so it's actually constant times the
circuit size plus something in the
security parameter but we get like order
s times Polly k and I'm calling it
linear rate although people object to
calling that a linear rate it improves
theorem to yes I just wanted to tell you
what i showed you before yields theorem
to but we can actually get theorem 3 and
this requires actually fancy gadgets
that we knew before and some we didn't
know and i'm going to tell you what they
are and if you are lost here that's fine
after that I'm going to come to
randomized encoding and probably we can
pick up again I'm going to be at a very
high level now ok so I want to improve
the communication complexity and roughly
the idea is we want a better AI dcs
before for equivocating equally locating
one bit we needed to spend a lot but can
we do it better where if i want to do if
i had a fixed polynomial in the secure
in the input call it t then can I do it
better with better communication
complexity
and that's what we show we show that we
can if you think of our adaptive
zero-knowledge we actually committed to
these views and these views as a whole
had to be equivocated in the eye cause
approach so that's why having a better
equivocation parameter is going to help
us get a more communication efficient
protocol okay the one of the basic
ingredients that we need here is we
cannot use the basic bgw that I Kos uses
they actually have a more fancy thing
where they start off with a very
communication efficient MPC to get a
zero knowledge and we need to rely on
that protocol okay we can't because they
show how to get directly negligible
soundness as opposed to this constant
soundness they get negligible sound
starting from a better MPC protocol so
we need to use that and we also need to
use IPS which is this issue I prabhakara
and so however they show communication
efficient to PC protocols based on that
we have to use some of their compilation
techniques over here as well but I'm
going to sort of give you an intuition
so far we have been using a semi honest
to PC to get this stronger statement we
are going to actually use the two pc
that is secure against a malicious t1
just one of the parties I needed to be
secure against a malicious adversary
controlling p1 and now the rough idea is
that this to get a better equivalent I'm
going to map this message m that I want
to equal 0 Kate into the space of all
possible random tapes of party p2 ok now
what does it mean that my protocol is
secure against a malicious p 1 it says
that over the random tape of p2 my
protocol will be correct so that is why
when I map this message space to the
random tape actually it's the random
tape of p2 it means that over with high
probability over the random points of p2
my protocol is correct which means that
if i start with the false statement
there are only very few
random tapes that the adversary can
assign to party p to that sort of
restricts the entropy of possible random
tapes that the adversary can access and
now to commit to a message m i actually
need to use an interactive hashing
protocol because i am using i want to
construct a proof so that is why it
can't be any hat I can't just use a
collision resistant hash function or
because in an information-theoretic
prove our could find collision so I have
to use an interactive hashing protocol
to get this ok and it still more non
trivial for the following reason I also
need an adaptive property which is that
later I need to be able to eat vivo Kate
my message as the simulator now the
problem arises in an interactive hashing
where we don't know of interactive
hashing protocols with which has this
adaptive property where I commit to my
message and then later for anything I
want to produce input and randomness
consistent with this and now we actually
there is this to round protocol of dang
at all to do this interactive hashing
and we weren't able to use this we will
only be we were able to show the
original navi protocol was adaptively
secure and the result of this is that
around complexity is now going to be
proportional to the security parameter
so there's a lot of techniques that are
that went into proving this sorry no yes
we need the permutations yes actually no
the interactive hashing has no it's an
information-theoretic primitive it has
nothing to do with you just want to
compress the entropy and it does not
require any assumptions novi was used to
construct a statistically hiding
commitment which requires it but this is
just the interactive hashing part you
had a question ok all right so now we
can step back a little bit so that
showed how to get a communication
efficient adaptive zero-knowledge proof
I know that I threw you off towards the
end of it you can look into a paper for
all the details this last part I just
want to tell you how to get this
delayed input commit and prove pro I
have I have like five to ten minutes yes
okay okay good so I'm going to go a
little slowly and i am going to there
are not many slides I promise you not
many technical details in the rest of
the slides I want to show you how we get
our delayed input commit and prove for
round protocol okay alright so first let
me define randomized encoding this
requires a lot of a lot of things okay
so I'm going to follow the definition of
haiku Sheila with 00 and applebaum issue
I crucial of it so for so for any
function f I'm going to define a
function G to be a randomized encoding
of this function f if the following
properties hold first that is correct
pneus it says that there is a decoding
algorithm B such that for every input X
whatever G outputs and you should think
of the second coordinate here as the
randomness used for the randomized
encoding this decoder the probability
that it does not output the correct
answer is negligible ok so which means G
is a good randomized encoding it's not
the same L it's not the same L I
apologize all right so there is a
privacy requirement which says that
there exists a simulator s that can just
with the output f of X can produce
something that is indistinguishable from
the distribution of this output of this
function G on a random string and this
is computationally indistinguishable now
I'm going to define two more properties
one probably people have seen and the
other is something that we introduced in
this work this an upgraded definition of
randomized encoding is one that actually
I mean this is also more practically
motivated is an online offline
randomized encoding which says that the
encoding function
be split as an offline part and an
online part where the offline part does
not need to know the input on which the
function is being evaluated it is just
for me to think about this gobble
circuits of the best examples do you can
generate the gobble circuit without the
input the online part are just the key
labels okay that is the easiest way for
me to think of online offline randomized
encoding now I'm going to define a
non-trivial property which I have not
formally said here it just informally
said here i need something known as a
robust randomized encoding this is sort
of similar in spirit to robust MPC
defined an eye cause and roughly this
property says the following no adversary
can honestly generate an offline part
meaning give random coins consistent
with the honest offline algorithm for an
offline part simultaneously give an
online part that decodes to something
outside the support of f ok now i'm
going to make this a little more simpler
if we were just talking about NP
relations over here and f is i mean the
the right hand side it is a predicate
let us think about it then basically it
says that if i had a false statement
then if someone gives random coins
consistent with this offline algorithm
for the offline part then you can no you
cannot give any online part that will
decode this to a one if it is a false
statement okay so there is it's not
possible for that's robustness yes
alright so we also need an adaptive
input secure randomized encoding this
additionally requires that the
simulation can be divided into offline
and online parts such that the simulator
without the input without the output can
generate the offline part and the online
part can be generated with the the
output f of X in addition there is I
mean besides I mean see this is true
even for online offline but I also need
an additional property which is
adaptively chosen inputs which basically
says that this needs to be true even if
X and f of X is decided after the
offline part is revealed ok now you can
ask do such randomized encoding exist
recently there was work by Hemenway at
all who show how to get an adaptive
input randomized encoding it was not
robust but we show in our work how to
make this randomized encoding robust as
well so it is possible to construct this
just based on one wave functions so for
our applications we don't need but in
general for randomized yes yes we can
use yes we don't need that you're right
wait yes that's right actually I don't
know how to use that because I don't
know how to make that robust I can only
make the work of a less robust because
of the one-time pad because a cheating
person can also just give an arbitrary
pad and do it ok all right so now for in
the last five minutes or delayed input
zero knowledge and then I'm going to
make it commits and proof first I am
just going to give you delayed input
zero knowledge using this adaptive input
randomized encoding ok so what is my
function f
my function f is going to be defined by
first I choose w0 at random and this
function is going to have w0 hard-coded
its input is going to be x + w 1 it is
going to evaluate the relation on X on w
0 X or w1 and also going to output X ok
and you will see why I need to output X
as part of the function so this is the
function I want the adaptive input
randomized encoding for now what is my
zero knowledge protocol in the offline
face all I'm going to do is give the
offline part and commit to the
randomness now the verifier can give 0
or 1 if it is if it is 0 i am going to
send this fixed value w 0 and d commit
to our what is the verifier going to do
the verifier is just going to check if
everything was done right this is very
similar to our if you looked at the
garble circuit construction I just give
you all the randomness involved in
constructing this offline but it's just
verifying that this is fine when B is
one it's going to give the online part
and now the verifier is going to
evaluate this randomized encoding
basically run the decoding algorithm to
learn what this right hand side is and
check if this value is 1 and also check
if the statement X is the statement that
you are proving if I didn't involve this
then probably the prover could give an
arbitrary statement and an arbitrary
witness that satisfies the relation it's
because I put this X in the output of
the function that the verifier can check
that the prover is indeed proving the
right statement that we care about ok so
now if you look at this protocol the
first round does not require the input
statement it just requires the
randomness and remember the offline part
didn't require anything it actually
required this w is zero but the w0 is
just chosen at random to define this
function f ok now the sunless half
follows just like before but we are
going to use the robustness and how do
we use the robustness because if you
reveal
these guys then you are giving me the
randomness consistent with the honest
encoding of the offline part as well as
you are giving me a consistent online
part that evaluates to 1 and this is
exactly prevented by robustness ok
simulation you can guess be 0 is the
easy case you can just do it honestly
the one you can use the offline and
online simulation algorithm and it just
follows and I'm going to quickly just
say how I do commit and prove and I'm
only going to get soundness half to get
it like to get so negligible soundness
requires more effort but I am just going
to tell you how to get a commit and
prove with soundness half its i'm going
to add as part of the output i am going
to add w1 in the first round i'm going
to commit to w0 and w1 this is the
commitment part i said i am going to
commit to the witness and later i am
going to show that this satisfies the
relation now with b equals 0 along with
this i'm also going to decommit w0 as
opposed to sending it in the clear and
for the other case i am going to
decommit to w1 and this simple trick
just gives you a commit and proof
protocol and this is my last slide the
perspective just to wrap up the sort of
transformations that we have in this
work we show that from to pc in the OT
hybrid we can get both static and
adaptive but based on one wave function
and the part that i didn't explain too
well is that inside this transformation
we actually rely on a randomized
encoding of the oblivious transfer
functionality itself and this is just a
simple corollary I just find that this
textbook garble circuit construction is
very simple to explain zero knowledge
proof and as I mentioned before the
ICO's approach does not work here at
least for our stronger results of
adaptive zero knowledge and delay input
delayed input zero knowledge and we sort
of need to use properties of two-party
computation to do this and the the last
part that I didn't tell you is I sure
there is another transformation from
secure two-party computation two
randomized encoding value in you can
just
Stan she ate this to PC with anything it
has to be of a certain form to get a
randomized encoding that is efficient
but it does give some sort of a lower
bound that you can translate from
randomized encoding back to it it helps
improving some sort of a lower bound and
finally MPC in the head is for like
static type of things and to PC in the
head is when you need some sort of
adaptive property thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>