<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>An average-case depth hierarchy theorem for Boolean circuits | Coder Coacher - Coaching Coders</title><meta content="An average-case depth hierarchy theorem for Boolean circuits - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>An average-case depth hierarchy theorem for Boolean circuits</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Kdja02Sj8kc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright good afternoon we're delighted
to have Leon can tell us about depth
hierarchy theorem for boolean circuits
Thank You Val thanks for the opportunity
to be here it's going to speak about
joint work with Ben rossman and Rocco's
video when Ted Simons and Rocco's at
Columbia so this will talk about circuit
complexity so very briefly let's recall
the broad goal is to derive strong lower
bounds on the size of circuits computing
an explicit function so let me elaborate
on two important words here the first is
explicit for this talk is not very
important it's let's think of an
informal definition as concrete simple
to describe functions so a non-example
would be you know a random function and
I guess formally and complexity theory
we think of you know an explicit
function that's one being in NP and as
for circuits the Holy Grail is really to
understand the power of polynomial size
and or not circuits the standard basis
or it's known as you know p / poly which
is not important but so will ideally
like to activate a function a concrete
and put the describe function that
cannot be computed by such circuits
which will separate p from NP but we're
still very far from it so the focus of
research so far and the focus of this
talk is on restricted subclasses of pcs
p / poly and in this talk will focus on
one specific restricted subclass so
what's this class it's the class of
small depth cooling circuits so this is
a brilliant circuit over the standard
basis of N or not gates we can assume
it's not hard to see that all the not
gates are pushed down to the bottom
although this again not important for
this talk so that's the this a circuit
and we're interested in function that
requires complex circuits and so what's
complex there are two measures I'm
interested in one is that which is the
number of layers you have the others
numbers sighs which is number of gates
you have just just this too and we are
going to make it even simpler and fix
one of them but this talk will think of
that pest constant say 100 and the only
parameter we care about is the number of
gates which is size and we are
interested in very strong lower bounds
on size exponential okay under this
assumption at a depth is constant okay
so that's our model small depth circuits
has been studied since the 80s and it's
really a story of success you know even
since the 80s we have exponential lower
bounds against constant that circuits
computing an explicit function so the
landmark result here is that of hostile
which we'll talk a lot about in this
talk
and it builds on the work of Ike I for
successor and yellow in the 80s and just
as an aside i should mention that it's
quite rare in you know circuit
complexity or complexity theory that we
have such strong lower bounds it's
really among our strongest unconditional
lower bounds in all of complexity theory
okay so that's and the techniques that
would develop the proof these lower
bounds they important beyond circuit
complexity i found applications in
pseudo randomness learning theory proof
complexity and so on and at a very very
high level in this talk i'm going to
speak about an extension of hostage
theorem and we do so via a
generalization of his techniques so we
hear a lot of a hostas arab his
techniques and how we extend both of
them okay so let me go into detail about
dialogue of this talk i'm going to tell
you about hostas theorem and two of the
extensions neither of which are due to
us both do to him back in the 80s one is
average case hardness and the other is a
depth hierarchy theorem i'll explain
what each of these means in a second you
can probably guess what the first means
ready and our main result is that we
achieve both extensions of hostas
theorem simultaneously so as the title
suggests we prove you know an average
case that perky theorem which again i'll
try to explain what that means after
telling you about our main result i
would give to applications one
instructor complex to fairly different
areas one in structural complexity
showing you know that the polynomial
hierarchy is infinite relative to a
random Oracle I'll explain what that
means and the second in a completely
different area in the free analysis of
boolean functions we answer a question
that's been floating around in the past
few years about a converse to a famously
know Mansour Nissan theorem which I'll
tell you about also and if i have time i
hope they have time i'll tell you about
technique which is that of random
projections which is a generalization of
Hustlas technique which is random
restrictions so i'll tell you about
random restrictions and what random
projections are ok so let's get started
with hostas theorem so hostas theorem he
proved exponential over balanced against
a constant depth circuits computing an
explicit function and the function is
very explicit the parity of x1 to xn it
really doesn't get there's no arguing
that this explicit concrete is simple to
describe ok so what does this theorem
say his theorem in his PhD thesis ah he
showed that for every depth to be
greater than to think of d/s 100 any
depth d circuit computing the end
variable parody function require size 2
to the n to the 1 over t minus 1 so in
particular if you ask me to build a
depth 100 circuit and make me compute
parody i need lots and lots of case
enter 0.01 so these are results we like
in circuit complexity it's a very strong
lower bound again a very explicit
function yeah its type of parity and in
particular beating this bound for
functionality and parity is a big open
problem yeah so there's our best lower
bounds against that new circuits ok so
that's hasta theorem parody require huge
circuits unbounded right sorry I should
have said that I'm bothered vennen but
constant depth yeah if it's bounded then
you cannot do much in constant depth
yeah sorry thanks thanks for that ok so
this is how the theorem simple let's
talk about two extensions both do to him
ok the first this average case hardness
so in fact he proved something stronger
you know two slides ago I showed that
you know constant depth circuits of you
know what seems like large size cannot
compute parity in fact he shows in this
thesis that you know depth these
circuits of the same size to the end to
the one of the agree with Perry on only
on a half plus little of one fraction of
inputs in fact the little one is very
strong exponentially small fraction of
inputs so this is hopefully clearly a
extension to slides ago I said that such
circuits cannot compute parody this
gives me more information is say that
such circuits cannot even correlate with
parity ok so just a few notes they're
just a constant one function a trivial
you know depth 0 circuit as agreement
one half with parity so this sort of
says that if you allow me to build a
depth 100 circuit you allow me sighs to
to an end to the 0.01 which seems like a
lot I cannot do much better than a
constant if I'm lazy I may so just out
with the constant I can even do an
exponentially small fraction better than
constant so it's a very strong statement
and this is not too relevant for the top
but that's an interesting aside this was
implicit in his thesis but the the exact
relationship between D and the size and
the correlation bound was only recently
pinned down by in Picasso at all in
hostile himself 30 years later okay so
there's the first extension correlation
bounce against parody let me talk about
the second extension which is that of a
depth hierarchy theorem and this will
take slightly more time in particular
need some notation AC 0 so b is the set
of all that d poly end sighs circuits of
functions computable by them so depth to
is not very interesting is the set of
all polynomials size or so and so and so
force also known as
CNF so DNS depp three circuits step 4
and you take the union of it at all you
get AC 0 which is the class of all
functions computable by its constant
depth Polly incised circuits in
particular parity is not one such
function ok so this is a cartoon picture
of ha stats theorem it says that you
have AC 0 which is all constant depth
circuits the impaired d-doesn't live in
in this green circle in fact if you want
to compute parity with a poli-sci
circuit you need depth roughly log in so
in a cartoon it's a set parody lips
outside this circle at that log in so
here's a challenge I want the same lower
bound against that p circuits so houses
theorem tells us that you know if you
make me compute parity with the FG I
need two to the n to the 1 over d so
here's a challenge I on the same lower
bound again step these circuits but for
a function and lives in ac0 that's D
plus 1 ok so intuitively this feels like
a more challenging task you want the
same lower bound against the same class
of functions but for a much simpler
target function in particular you want
is to be so simple that even just
allowing me one layer more depth I can
compute it in polynomial size so this is
hopefully also obviously an extension of
Hustlas theorem so and then hasta was
able to do it it's the so-called depth
hierarchy theorem and also in this case
she thesis here he showed the for every
depth d greater than 2 there's a
function f d the so-called substr
function which I'll tell you about such
a FD is actually quite simple it's in
depth linear size depth D plus 1 but if
you force me to use a depth D circuit I
will require an exponential blow-up 2 to
the n to the 1 over d and this is again
just recall the same lower bound we have
against parody ok so a few notes it
builds on the work of sip server and
hence the scepter function which gave a
super polynomial separation and now a
few years later gave an exponential
separation and was sharpened by hostile
okay and before y'all's work the
monotone case was solved by Chloe RL
it's the same theorem I just put
monotone everywhere there's monotone
function f d sub cerise monotone FD is
an AC 0 TT plus 1 by the low low and
only holds against monotone circuits so
it's over yeah and the hot function for
all of the above there's a sip sir
function which I'll tell you about but
before telling about that just very
briefly the conceptual message here is
that
why is it called a depth hierarchy
theorem is that you know it says the
depth D plus 1 circuits are much more
powerful than deputy you know you give
me a nice linear size depth Z plus one
circuit you make me decrease the death
by one I may have 2x blow up the sides
accidentially okay so what was the
deputy substr function the formal
definition is a depth D read ones
regular alternating monotone formula but
it's really the picture just says it all
you have alternating layers of n or n or
n or depth D the fannin is regular is n
to the 1 over d and it's read once it's
alternating and/or it's read once in
that you know the bottom layer and gates
or gates touch distinct set of variables
and it's monotone there no not gates
alright it's sort of the obvious that's
D formula it's sort of you know if you
made me write down a depth if I'm like
this is sort of maybe one the first one
I'll write down and in particular its
linear size right you any read once
formula it's linear size it's a very
nice regular structure that's a sip set
function so let's get some intuition as
to why the substr function is so
important for Deb hierarchy theorems so
here's a here's a challenge I've a depth
receptor n to the one-third fannin and
or an or and now it's nice and linear
size now you point the gun to my head
and you say i want you to compute this
in depth too ok so that here's one thing
i can do I focus in on this end sub gate
I rewrite an N of oars or events right
this is the Morgan we can do that but
not very efficiently right how do you
rewrite an end of oars and or advanced
you take one from every bucket so it's n
to the 1 3 to the N to the one third so
it's roughly two to the N to the 13
right and you write this gate as a or
events do this for every gate and now
you look you see that you know you have
or of or events and you can collapse the
two oars because in or force is all for
us it's kind of I don't know this one
way to do it but not very smart oh and
you can ask you know whether there's a
better way to do it right and off and
what has that shows is that you know
essentially this is the best thing you
can do if you want to compute depth
receptor with depth to just apply the
market blow up the size that's the best
thing you can do and same thing with
depth 100 computing it with depth 99
well you just at all anyway and the
little most nearly most nearly mad you
don't get you to enter one third right
get to
to enter Omega 1 over d right so it's
like you have low about to turn enter 1
over 180 construction point you don't
know anything Oh strictly better like
even just to save one gate yeah I'm not
sure that's a good question for depp
three i do not know if I can prove a
precise 2 to the n to the 1 30 lower
bound of all sorry is it critically can
you save one gate I don't know yeah I
yeah the lower bound is definitely not
delicate enough to capture that you
cannot but maybe the upper bound is yeah
I wouldn't say that this is exactly
optimal yeah yeah okay so yeah that's a
def hierarchy theorem and some intuition
is the Y sub serious the function look
at okay so what have you shown with
hostas theorem which is nice it is a
parody nan na g0 in fact you know dep d
what seems like large size to the n to
the 1 over d sighs circuits cannot
compute parity we have two extensions
that feel somewhat different one is that
depth these circuits of that size cannot
even approximate parody to 51-percent
the second one is that you know we don't
consider parity we consider much simple
function and we get you know the same
kind of lower bond against the same kind
of circuits so you can ask and hostile
ask this you know can I get the best of
both worlds can I show that there is a
function at depth D plus 1 such that if
you force me to use deputy circuits and
you allow me a huge size i cannot even
approximated right that seems like a
natural best of both worlds kind of
extension and now main reasons work is
we come from this conjecture of hostile
okay so i like to tell you about this
picture the rest off the top okay so
more precisely is no surprise we we have
a sub set function we show that for
every death degraded into it as a
function f d is the scepter function
which is in that D plus 1 AC 0 but depth
the circus of size 2 10 to the minus VD
they have agreement little of heartless
little of em okay you cannot do
51-percent and previous work Oh Donald
Webber in 2007 they proved the D equals
2 k's the proof you know depp three sips
sir you cannot compute it in depth to
you cannot approximate an in-depth to
and it is a starting point for us we
bought on the techniques and in
particular you get this is sort of the
base case for us so what we did is
basically a reduction a depth reduction
to dildo november
our proof of the depth D equals 2 case
okay to answer a question that it's
probably on your minds um this
correlation bound write a few slides ago
I said you know parity is very very hard
for AC 0 you know your correlation sex
and most exponentially small which is
and here it seems like we're not doing
much better we're doing we're not doing
as well we only get you know one of a
polygon 4d being constant so you can ask
why not exponentially small I have two
reasons one is just simply not possible
for the sip server function the subset
function is a monotone function and it's
a standard result that every sip sir
function every monotone function has one
of a poly and correlation with a very
simple circuit you know either dictator
and exile a constant so you cannot hope
to do this for the sixer function so
there's not a very good excuse you say
okay find another function a non
monotone function at depth T plus one
for which you can prove exponential
correlation bounds but in fact it's not
past home for any function to begin with
if you force the function to be in depth
D plus 1 which it has to because of the
name of the game yes it's a standard
result at any depth D plus 1 circuit it
has one of a polygon correlation with
one of the depth DP circuits that feed
into the target so there seems to be
some fundamental difference between that
hierarchy theorems correlation bounce
and parity in particular you know for
the second reason the first yeah the
second reason you know you cannot hope
for you know half plus exponential in n
to the 1 over G so it's essentially
optimal or constant yeah ok so that's
our theorem let me touch on two
applications of our result in two fairly
different areas once once in structural
complexity so forget everything about
circuits let's talk about Oracle's for
radicalization so part of our job in
complexity theory is we want to separate
complexity classes and you know we
haven't been able to do so for many of
them and the famous example is where the
p is equal NP so we haven't been able to
do it so we can consider a twist of the
question imagine a world where
algorithms have free access to some
magical function call it a ok you give a
an input and for free in unit time you
get answer so think of AAS three sets so
you have this magical Oracle that you
give it a three set formula and you snap
your finger and it tells you whether
satisfiable or not so in this world you
can ask whether p is equal to NP
it's a slightly different question but
it seems like a natural question and the
notation is that speed to the a equal
empty today that's P given an a Oracle
equal MP given an a Oracle so a priority
is not clear that this is any easier
then P versus NP but and actually for
this we have made a lot of progress even
since the 70s the the paper introducing
this notion of Oracle's Baker go and
salivating they noted that there exists
some Oracle for which you can separate P
and NP and this was improved the fewest
later qualitatively by benedict Gill we
show that you know in fact for almost
every magical Oracle a piece to the a is
not equal to mp3 so we are still far
from separating p % p by at least in
this you know the oracle sense of the
word this is a pretty satisfactory
solution why not only that's they exist
one Oracle almost every Oracle that they
are distinct okay that's great you
should you say almost a uniform
distribution say 99 percent a half-
little one almost every function you can
give its p is not equal NP and yet we
cannot that doesn't imply that p is not
equal NP now working so that's that
that's a lot of topic but then as a
caveat this shouldn't you taken as
evidence that p is not equal NP for
various reasons that we discovered later
not we but you know and they see ya yeah
so but that's a copy about it just
independently is sort of an interesting
question okay so we have resolved p
versus NP on these worlds let's move on
to other questions so here are two
statements that we also believe are true
they both concern the so-called
polynomial hierarchy I'll explain what
that means in a second one is that pH
the polynomial Harkey is my go-to p
space the second is a pH is infinite for
this talk is actually not really
important to know what either of these
statements mean oh really what the pH is
these are two statements like P versus
NP that we like the proof but we cannot
prove and two is stronger than one and
two implies p is not equal NP so too is
very very strong so we are stuck on them
but we can ask you know do these
equations hold relative to one Oracle
and if we can do that can we ask we can
ask do they hold relative to almost all
our goals
okay right to imply screams exactly so
too is a very strong statement so let's
let's see we had success on the P versus
NP question with respect Oracles and we
have much success here too yo in hostage
show that you know the weaker statement
that pH is my go to space holds for some
Oracle a there exists a magical function
such at PHS I go to pee space this was
improved by Ty and Bobby who showed that
pH is not equal to P space for almost
all articles a so the weaker question
you know we are very satisfied again and
yellow and hostile also prove that in
fact pH is infinite relative to some
Oracle a and again you can ask for you
know they conjecture that you know you
have the strongest of all these
statements that in fact the strongest
statement is true for almost all
Oracle's the ph is infinite for almost
all Oracle's a so this would imply these
results because you know ph being
infinite for almost all our clothes a
implies that p h naught equals p space
for almost all go say and you know this
this version says its budget just some
oracle and here we are seeing it for
almost Oracles and in this work we
confirm this conjecture and in fact I
like to touch on why this is a direct
consequence of our circuit lower bounds
and if you can if you may have guessed
from the names of people who proved this
these you know ratify station results
are established using circuit lower
bounds so let me touch on this
connection between circuits and relative
ization okay so there it is actually a
tight connection between you know the
class of circuits were interested in
which is you know bounded depth circuits
which we think of as very limited models
of computation you cannot even compute
parody and you know the polynomial
hierarchy which is a very very
expressive you know power off of models
of complication and there's a this
correspondence was noted by first
section citizen roughly speaking deck
differ by an exponential and the
connection is really really very close
you know depth three AC 0 with you no
and n gate on top corresponds to pi/3 no
depth ten AC 0 with an or gate on Todd
corresponds to Sigma 10 okay that's
really a one-to-one correspondence and
prickly I believe that this was the
original motivation for proving circuit
level bounds we wanted to use circuit
lower bounds to prove low bounce against
the polynomial hierarchy okay so let's
take a look at the paper it says the
title of the paper is parody circuits
and the point of no time hierarchy it's
a super polynomial
bound is given for the size of circuits
of fixed depth computing a parody
function okay and you say they say that
connections are given to relative
ization of the polynomial time hierarchy
so this is a paper and let's translate
it the first slide basically says that
parodies on in ec 0 and the second says
that you know so they prove a super
polynomial lower bound on the size of a
c0 circuits computing parity and I say
that if you can improve it the super
quazy polynomial then you have that pH
it's not go to pee space with some Maura
Connelly okay it's quite easy and so
they didn't quite do this but they noted
that if you improve this separation the
super quazy polynomial then you get this
separation you get and this was done by
yo in hostel in 86 and not surprisingly
they proved this by proving the circuit
result they proved sufficiently strong
little ones on the size of circuits
computing parody okay so in fact you
know we saw two slides ago you know you
have the circuit results in the two
extensions they correspond perfectly to
a picture in the relative ice world a
yellow and hast odd are they prove that
you know def de circuits of you know
large size cannot compute parody and
that corresponds exactly and this was a
motivation for them to show that pH is
not go to pee space for some Oracle a
you have two extensions one of which
says you can't even approximated that
corresponds exactly to the strengthening
of this theorem to say that the
separation is true for almost all our
cozy you have another extension that
says that you know deputy circuits
cannot compute not just parody but a
super simple function at T plus one that
corresponds exactly to the fact that pH
infinite patience infinite relative to
some Oracle and just like how you can
ask for the best of both worlds in a
circuit world you can ask for the best
of both worlds in the oracle world and
my confirming hostas conjecture we
confirm the conjecture that ph is
infinite relative to almost all our
goals okay I'm not going to touch on
this connection more except to say that
it's really a very very close
translation it's really a mirror image
we didn't even prove that it just
follows by standard standard techniques
so okay that's application one a sort of
retro and old school let me switch gears
to a different application now in an
analysis of boolean functions a
completely different so forget all about
Oracle's so let me start with a very
basic fact about circuits fixed a
function f consider following
simple experiment draw uniform random
acts flipper coordinate all right it's
so simple and I want to know what's the
probability to f of X is not equal F of
Y and i'm going to multiply by n this a
matter of convention don't worry too
much about it but if you allow me to
multiply by n it brings it to a number
between 0 and n and it's known as the
influence of F on also like every
sensitivity and it makes sense that the
name every sensitively makes sense right
it's average number of coordinates on
which your sensitive on so given any
function f I can ask what is influences
its low is it close to zero is it high
is a close to end it's just a measure of
boolean functions and a famous theorem
of linear mansoura nissan's shoppin
Bible partner says that if you give me
some more information more f you
promised me the f is computable by a
size s that d circuit less influence is
bounded by log s 3 d minus 1 and again
the regime of parameters we should think
of this as being poly N and D being
constant in which case elements is that
you know ac0 circuits have poly log and
influence which in the spectrum of 0 to
n we should think of as low so it says
the elements is that you know small
circuits of small depth have low
influence and it's a very important
result so here's let's look at you know
the usual suspects so this is the line
of all possible influences on the left
you have blow influence functions on the
right you at high influence functions so
let's start with high influence parody
is the world's most influential function
s influence n a random function as
influence and over 2 so very influential
and majority is not hard to work out
your influence is roughly Rudin for this
talk let's think of rude n is high ok so
that's high influence functions let's
look at low influence functions you have
the constant function which is very
boring its influence is 0 X 1 which is
also borrowing as influences one you
know these are not very interesting
functions and you have the tribes
function which is a dnf its influences
login ok so you have this spectrum with
all the usual suspects and boolean
functions lying on it and as you can see
on the right is canonical functions
canonical examples of functions that do
not lie in auc 0 there are you know
complex functions and LMN says that this
is not a coincidence you know again for
the range of parameters we should think
of you know sizes polygons or even
Kwazii polygon is that if the depth is
constant lmn see is that you know you
give me such a function it lies to the
left of poly
login so in particular lmn shows that
majority and random function and parody
unknown in ac0 so it's a strong theorem
about you know the stability of circuits
ok so LM n is great a question that was
asked by Benjamin E coli and SRAM in a
very famous paper about noise
sensitivity anibal influence and it was
repeated in a different from anne edano
calyin itami in the past few years is
whether the converse the element is true
ok what do I mean by that lmn Begley
speaking says that small depth small
sized circuits have low total influence
is it true that low influence functions
are basically circuits basically small
depth circuits it's not hard to show
that you know low influence functions
there are no instrument functions they
are not exactly a small depth circuit
but it's it's it was still possible that
low influence functions are essentially
small depth circuits and that you can
well approximated with a small dep
circuit so just be slightly more precise
lmn see if you give me you know the
structure that you have you know Polly
size or even Kwazii polynomial size and
constant depth circuits you lie to the
left of poly log in ok now you can ask
if you lie to the left of poly log in do
you have this structure are all poly log
and influence functions well
approximated by the same class of
functions if it's true this will be a
very very nice characterization of low
influence functions but to spoil the
suspense you know we disprove it we show
that our main result gives a strong
contacts on Paul to this which is
unfortunate in a particular area
question that came up during the times i
gave the sockets it would be nice to try
to save this conjecture somehow i'm very
interested in the structure off i'm very
interested in a structure of poly log
and influence functions yeah and roughly
speaking as an aside for experts like
log n is where free guts theorem breaks
down like if your influences below log
and frigates theorem gives you a very
nice structure but log n is where it
doesn't give you any information so i'll
be very I'm very very interested in the
structure of log n influence functions
but and I was trying to prove this all
summer but ended up this proving it
instead so yeah ok so that's Anna again
it's a simple consequence of all main
theorem I'm not gonna go into it it's
there's nothing there it's it follows
quite easily would be the system
function scale out yes us yes a function
sips a function of depth Z squared log n
okay yes some influence and what does
all mean results show it says that if
you're any circuit of that not just
constant but squared log n minus 1
cannot even approximate it so but
adjusting parameter is choosing you know
instead of square log and maybe
something else you got a log and
influence function that cannot be
approximated even by super constant
depth circuits okay so yeah again I open
problem is to rescue this somehow okay
so two applications one is two fairly
different areas one is in structural
complexity which shows that you know pH
is infinite relative to random Oracle
and second is answer this bks conjecture
repeated by o'donnell client itami which
is that unfortunately there's no
approximate converse to lmn okay so let
me actually talk about actual result so
for the rest of this talk let me tell
you about hostas techniques the
difficulties in applying them you know
and by that I mean applying them to get
our result which is an average case that
turkey theorem and how I techniques
overcome these difficulties okay in
particular let me give a very very high
rough structure of Hustlas theorem just
in one slides and pictures and I'll try
to say why extension one the you know
approximation version follows easily in
fact it's implicit in the proof I'll
tell you why extension to does not
follow easily and y hasta had to do
extra work to prove extension to and the
way he proof extension to I was
explained why it breaks extension one
why he loses average case hardness and
you know I hope to convey this tension
between extension one and extension to
if you want that extension one you
cannot get extension to and if you want
the extension to it was hard to get
average case harness and all our
techniques somehow are able to get both
okay but let's start with the very basic
hustles theorem in a picture let's like
recap his proof so one slide first about
his main technique which is that of
random restrictions it's a very simple
concept you take a boolean function f
you apply a random restriction to it you
get a simpler boolean function f sub rho
where rho is your random restriction now
make this more precise in the next slide
but it was a very important concept
introduced by super dos kya back in the
60s by even till today is a really very
indispensable to in circuit complexity
acid serum uses it and our theorem built
on it so let me tell you about what a
random restriction is
so a random restriction you have a some
parameter P think of it as small say 0.1
or 1 over log in and you generate you
know a string row and 0 1 star to the
end and how do you generate it with
probability P independently with
probability P you put down a star
otherwise you put you flip a coin and
put on other zeros and ones so the
string you get out is roughly a P
fraction of stars and in the one minus P
fraction is split half half between ones
and zeros okay this water restriction is
what does it mean to hit a function with
the restriction so the restriction of a
boolean function f by this string row is
the function where you know you taking
values for the stars and for the non
stars you fill in according to the
template okay so this is what it means
to transform F into F sub bro so as you
can see in Twitter feed this is you know
you do make the function simpler right
there was an n variable function now
it's a you know pn variable function so
let's see what this does to functions so
this is what a random restriction is so
here's hustlaz theorem again as a
cartoon it says that parody the red dot
doesn't live in the green circle it
lives at depth log in so how do you
prove such a statement you hit the red
dot with a random restriction and you
hit the green circle with a random
restriction and if you can come if you
can argue that two different things
happen to them then clearly the red dog
cannot live in the green circle alright
so in more detail you argue that parody
when you hit it with the random
restriction it remains complex it
basically becomes parody on fewer
variables but still very complex you
take AC 0 and you hit it with a random
restriction you argue that collapses to
a really really simple function a small
depth decision tree which roughly
speaking lies within here it lies within
like the bottom level circle and then if
you can argue these two then to finish
it off you just argue that you know
simple functions can compute complex
functions and you're done right okay so
of these three steps one is essentially
by definition of random restrictions and
parity is not hard at all three is a
simple exercise that small depth
decision trees cannot compute parity the
main technical work that hostile had to
do was the second step to show that if
you hit the green circle with a random
restriction it really like the whole
tower just collapses okay so let me once
lied about this main main technical
ingredient it says you know famous
switching lemma it
take any function in ac0 you hit it with
a random restriction with carefully
chosen p depending on the structure the
size of the circuit the depth of it
decreases by at least one so to prove
this theorem you hit it you know d times
and you argue that you know by hitting
it the overall restriction it collapses
to a very simple function okay so it is
one slide we'll come back to this later
but that's really the main technical
ingredient and this is the technique is
in seen lots of applications okay so we
just sort of sketch the proof of this
parody non in ac0 reason in particular
for every depth degrading and to you
know depth 100 circuits of large size
cannot compute parity okay and actually
I claim that we have implicitly also
established extension one you know the
proof implicitly gives average-case
harness that not only can you not
compute parody your agreement is a tiny
tiny fraction so let me tell you in once
like why this follows it's a it's a
consequence of our random restriction
the key fact here is that I'll random
restrictions hide a uniform random
string what do I mean by that I the
phrase we've been using is they complete
with a uniform distribution which I
guess is not very formal but here's the
formal meeting you generate this random
restriction row all right you zero ones
and stars and then now you fill in the
stars with zeros and ones uniformly at
random consider this ex-marine so at the
end of it you get a fully 01 value
string the obvious but crucial fact that
this gives average case hardness is that
you know the resulting string is a
uniform random string and this is sort
of why you know you have proved an
average case hundred we harness result
by hitting a function with you know this
random restriction you're implicitly
feeding it a uniform random input so
this is why you get and this is not hard
to see at all this because you know when
you're not a story or split between
zeros and ones where is it I won't go
into detail but this is roughly speaking
the crucial fact behind why you get
average case harness okay what have we
done we have sketched hast nuts proof of
his basic theorem we have shown why you
know extension one is essentially you
know implicit in the theorem let me tell
you the more interesting thing as the
why extension to is not that's not
follow easily from hostas theorem and
why by proving extension to it broke
extension one so here again as the state
hustlaz theorem and it's proof it's a
paradise on in ac0 and how you prove it
you show that you know when you hit
parity with a random restriction it
remains complex whereas you if you hit a
c0 with a random restriction you
collapse to a simple function and just
know that you know simple functions
cannot compute parody okay why can't it
proved a depth hierarchy theorem it's
because for depth hierarchy theorem you
know I want to separate it's not
delicate enough to separate depth D plus
1 in deputy you know that the Lightning
is too powerful it destroys all of AC 0
in particular you know I my heart
function say the cips our function Dyson
here and you destroy it right you try to
do the proof and you say I hit my heart
function with a random restriction I hit
the FDA c0 word random restriction it
shows that both of them collapse to the
small depth decision trees and it's not
it doesn't give you the contradiction
you want ah but this is not trouble for
hasta he he was able to do it by
designing new random restrictions not
yellow in color but blue in color
designed specifically for the sip sir
function to keep it complex okay so in a
picture what he does is that he comes
with a new one specifically with sips
are in mind so that he very carefully
keeps zipser complex he doesn't want to
destroy it and yet he still had to prove
that anything of depth one lesson zipser
still collapses to a decision tree so he
had to prove a new switching lemma for
the blue random restrictions and this
blue random restriction was tailored
very specifically for the sips or
function so this is very nice and put
clear here you see you're doing
something much more delicate right
you're contradiction comes in the fact
that a decision tree cannot compute a
depth to circuit you know it really has
to be very careful okay so in today's
flea just to say again it's a much more
delicate task rightful parody and AC 0
is a nice result but you know and put
your heart function was really hard to
begin with so you just have to you know
destroy AC 0 and show that you know by
destroying ac0 you do not destroy your
heart function by too much where's here
you're really trying to get very very
fine-grained information about the
structure of circuits right you have to
come up with something that destroys
that these circuits but preserves you
know your special function in that he
plus 1 so this was but how's that did it
so this is Perignon an AC 0 that is def
hierarchy theorem but he paid a price
the price comes in the fact that he only
get he only gets worse case
depth hierarchy theorem so recall the
key fact about the yellow the usual
random restrictions it was independent
across coordinates and the particularly
completes the uniform distribution
because you're hiding implicitly hiding
a uniform random string in the random
restriction Hasse's new restrictions
that's carefully tailored for the sips
of function you know your coordinates
are not independent they are carefully
correlated to keep zipser complex okay
and the distribution is only supported
on an exponentially small subset of
inputs and hence you only proof worst
case and on average case hardness so
just the summarize the difficulty that
we faced when we try to do this project
and high level there are three
requirements for average case that perky
theorem hasta has two things both of
which achieved two but not 3 1 you have
to keep the target function the hard
function complex to you have to your
approximator you have to destroy it and
three you have to do so in such a way
that however you're hitting them it
completes the uniform distribution okay
so hostas parody known is Perignon in
ac0 proof that's true you know his
famous switching lemma destroys ac0
circuits it completes through a uniform
distribution just because it's so simple
you know you flip a coin independently
for every coordinate but his you know
his yellow lightning was too powerful it
was designed to destroy all of AC 0 and
Patil it destroys the hot function that
you're supposed not to destroy ok so he
went faced with this he said no problem
I'm gonna define a new random
restriction that keeps my target
function complex in depth D plus 1 I
still prove that my switching lemma
still holds that collapses but the price
he paid was that he did it so carefully
and correlated the coordinate so
carefully that it doesn't your you prove
you're not it doesn't completely uniform
distribution and in this work we design
a random projection that achieves all
three and it's not hard to see that with
random restrictions you cannot achieve
all three and a key idea here was you
know random projections so let me in my
remaining time tell you a bit about
random projections and how how do they
relate to random restrictions and a five
time I'm not sure I do but I'll sketch
how projections achieve very all three
ok so again all technique is random
projections which generalize this notion
of random restrictions so a restriction
just recall you take a boolean function
f over x1 to xn you hit it with a random
restrict
you get a simpler boolean function over
x1 to xn a random projection on the air
hand you take it a boolean function f
over x1 to xn you randomly project it
you get a new boolean function of a new
form of variables y1 to ym so this feels
like a generalization because you know a
restriction is just with your new form
of variables are your old form of
variables ok let me be more precise in a
random restriction every X i if I just
said to a constant 01 or it survives you
know I've been denoting at star but you
can think of it as you know X I maps to
X i right that's what it means to
survive in a random projection every
exercise I just said the constant like
before or you can map it to a new brand
new formal variable Y J where J doesn't
have anything to do with X I so you're
basically changing the space of
variables and how do we exploit this a
very roughly speaking in our proof the
new variables the Y variables are much
smaller than X variables so we have a
lot of collisions right this is
something that you cannot do in a
restriction world we met many the many
different exercise to either 0 1 or the
same YJ and we map in such a way
depending on the structure of the cips
or formula ok so again projections it's
easy to see it's a generalization or
restrictions because every X I instead
of mapping to Y Juun frost that it just
maps to you the same X I ok so hopefully
i can give you a sense of why this helps
us be fast and i'll do so I will prove a
weaker statement I will I'm sure that
you know I'll show separation between 3
D&amp;amp;D and you can see here you have to
encounter same the same kinds of
problems because you know your heart
function is in ac0 no I'm gonna come to
that out yeah ok then skip ok good yes
when practicing please ok so let me tell
you about this projection the morning ok
so it's it's designed specifically with
cetera in mind right so you have your
depth 3d substr formula it has you know
and gates at the bottom let's look at
the Jays and there's some variables
here's the projection it's going to look
a little weird every X I in the Jade
tribe I said it either one or YJ so
again this is something you cannot do in
restrictions right you just said
although if you're not set to one you
set it to the same
variable Y J and again recall that J is
the name of the tribe so in the jf + 1
and you I decided one or YJ plus one
okay and what's the distribution well
independently if we want it to be
independent with probability one-half of
a condition or not getting the all one's
input roughly speaking why do we want to
do that we do not want the end gate to
be satisfied right if you put down to
all one's input the end gates yet
satisfied we want to keep zipser complex
and here we see that we have not put on
any zeros so for an end gate if you
don't do not put down any zeros and you
do not put down all once you keep it
alive in particular is always the end of
a non-empty subset of of inputs which is
nice which but one thing you should be
skeptical about this they claim that
this completes to the uniform
distribution because it's 0 when you put
down once and those zeros but roughly
speaking was going to save me is the
fact I've grouped all this together so
by hitting it with very likely to be 0
it's going to be uniform by anyway so
this is just one projection as a
standard and these step depth hierarchy
theorems you know the over and the
projection is just doing this over and
over again and if it if it's an order do
it with a dual distribution with or
gates with 0s my J's ok let's see why
this helps us there are three things we
need to show that this preserves sub sir
but that's essentially by definition I
hope the second is that you know we
still have to prove the AC 0 circuits
collapse to a simple function and a
third is that you know the restrictions
completely uniform distribution ok the
first I claim is by design and a
three-issue you should be skeptical
about so one why does it remain complex
well it's sort of designed with sips are
in mind so the Jays and you added map-21
and YJ and you are never all once so it
was always the end of a non-empty subset
of YJ variables and the n of YJ and YJ &amp;amp;
YJ is just Y J so this is designed
specifically so that you know the end
gate is never killed and in particular
every white every and gay just becomes a
new formal variable Y J so what happens
is you go from dep 3 D Sub Zero over X
variables to depth D 3 D minus one sip 0
ver y variables vary with probability 1
right so this is easy second one is the
completion the uniform right every every
coordinate is correlated in a way that
you know your condition are not getting
the old ones input
okay and the reaction should be that it
does not look uniform at all that you
only have once and y JS but as as you
will see it like the key here is that we
are grouping the y JS together so this
is I mean it's an easy fact but we are
super happy when we found out about it
is that you know if you put down but a
bunch of ones you group the y JS and
then you hit YJ with something very
biased to its 0 then the resulting
string is uniform and this is I mean
this is not this is a calculation of the
PMF but you know what I really like
about this it allows me to generate a
uniform random string in this two-stage
process where I put down a bunch of ones
I group stars and put on a bunch of
zeros and a group stars and put on a
bunch of ones so what's really nice is
that you know you're the usual way you
generate uniform random string is just
go coordinate x coordinate flip a coin
this allows me to just put down a lot
once first you know for my application
and then you know hit the remaining
things and so as a whole okay so
informally row which is very non-uniform
composed with like this to tobias
product distribution pops back to a
uniform distribution okay so that's nice
so I guess I'm still missing one part
but I've already given you a hopefully
given you quite a good picture of what
happens to the cips our formula you have
that 3d zipser is n gates at the bottom
accessing X variables and your goal is
to prove hardness of approximation with
respect to uniform you hit it with a
random restriction you go from depth 3d
to dep 3d minus one very nicely and your
job instead of proving harness according
the uniform distribution your heart you
prove harness according to the two to
the w bias product distribution over
your new variables YJ and again what
each YJ each of these collapses to a new
variable this collapses the new variable
do this collection is variable okay so
what's nice is you know you all your
target remains very structured and your
gold remains very structured your gold
goes from you know product distribution
to products to shoot in the product
distribution okay so the last step the
AC 0 collapses to a simple function I
wouldn't go into detail but as a last
slide as you would expect we had to
prove what hostel proved but for our
random projections so the key in hostels
are proof was a random restriction
argument showing that you know any
mission in depth in ac0 it collapses to
a simple function under random
restrictions well you would hope that
you know under one stage of what I
described just putting down once and
grouping things in YJ you know you
collapse by at least one in which case
we can apply it many many times we
couldn't do that for any for this random
projection but we could prove it if you
allow me to hit it three times so
roughly speaking this three is why I've
only sketched a 3d versus D separation
you know I used three layers on my
target to trade me one layer in my
approximator so you know if given you
know five days surely I can get the
contradiction but with three I can prove
I can prove that you know I get the
collapse so with that I achieve all
three so improving to diversity minus
one as your guess you know we change it
from red to orange you know a
significantly more delicate random
projection to ensure that we get a
collapse in that even number just one
random projection okay and we of course
once you change what your random
restriction is random projection is you
have to ensure that the two other
properties still hold that you know what
was somewhat simple in my sketch you
know that is the fact that your target
remains complex which was really very
neat in this in this you know example
but it gets more complicated and the
completion of uniform also so a big part
of the project was trying to juggle
these three balls we only get two in the
air for like five months then somehow
one day we got all three in the air and
we're super happy yeah okay yeah so so
just a summary we proved an average case
that hierarchy theorem which is you know
for VD you know Sadie goes hundred
that's a function that you know if you
allow me depth 101 I can compute it in
linear size but if you force me to use
depth 100 if you allow me you know what
seems like a huge size my agreements you
know lesson 51-percent and I gave two
applications one is that the ph is
infinite relative to a random Oracle and
a different application showing that you
know there's no approximate converse to
this you know famous and useful lmn
theorem and our main technique which
we're quite excited about is this notion
of random projections which extends you
know this notion of random restrictions
and will be very nice to find put
applications so thank you
additional question so yeah how do you
want to save the elements ah that's a
great question um I don't know um
something like so what you sure is
essentially if it's fully log n for the
sensitivity yeah it could see that high
complexity of in high right outside
exactly so do you want to say maybe if
it's the smaller than log n then it
kinda right so I very high level are
like any structural information I can
proof about log and influence functions
and sort of as I sort of touched on
login is a special number because
anything lower than log and we actually
have quite strong by a not an easy
theorem and all it's a famous theorem of
free card which says that your influence
is k you're essentially depending only
on 2 to the K variables so if you told
me a function as influence 100 i can
tell you oh it's not a very interesting
function you essentially lie in
dimension to the 100 right you right if
you Tommy influence a squared log in you
know you lyin dimension 23 squared log
in where does it break down if you tell
freaked out you know your influences
login it tells you you know close to an
end winter which doesn't say much so log
in i think it's a special number for me
because i really like to understand the
structure of log and influence functions
and this was very nice right bks and
o'donnell and client had Tommy they said
oh maybe login influence functions you
can depend on all coordinate but maybe
you're you know a simple circuit but
it's not your approximated by simple
circuit but it's not true one way to
rescue is pretty Doug I mean that's an
even more complex function you're so
good what is your lizard what when you
said Polly locket what I see I have a
log on influence function yeah I have a
log and influence function such that if
you if you allow me depth not just
constant if you allow me that square log
in if you allow me sighs not just Polly
n but two to the N to the square root
login I cannot approximate it look some
footy doggies i plug it right exactly I
again I called exile a log
right so wait the rescue is to allow me
more a lot broaden the class of circuits
beyond just small depth circuits so a
conjecture would be that login influence
functions are well approximated by poly
SCI circuits period you'll be very hard
to disprove because if you disproved it
yes you have you know separated p from p
/ poly and people yeah but right because
and Butler our function is clearly a
poli-sci circuit very surprising if this
notion of sensitivity was a tight
characterization for social complexity
me yeah yeah you'd be very nice but it
was hook could also be very surprising
yeah and in some sense i was results
show that it was too much to hope for
right this was it would have been really
nice if you know every log and influence
function is basically just a circuit if
you're a circuit load small depth
circuit your login influence if your log
and influence you're basically but yeah
exactly as you said it's maybe on
hindsight it was too bold but you know
it's not true but still one can hope for
some sort of structure of log and
influence functions I'm not sure yeah a
constant influence on you know squared
log in we have very good structural
information right thank you thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>