<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Welcome and Overview of the Azure ML Workshop | Coder Coacher - Coaching Coders</title><meta content="Welcome and Overview of the Azure ML Workshop - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Welcome and Overview of the Azure ML Workshop</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/JTafEI2Qr8g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
as Ken she had mentioned yesterday we
actually had a bunch of external folks
akademi from folks from academia as well
as scientists and I think we had about
I'd say about 50 people here yeah so you
had a pretty good full house and so far
the feedbacks been positive we were just
counting some numbers and seeing who
might be utilizing as your ml after they
had seen it and I think out of 14
recipients maybe about 11 of them so
it's good a lot of those folks did know
adjure so I had to kind of scan through
that as well so a bit of a learning
curve as a kid you mentioned I think my
relationship with this lab actually had
worked in MSR but I was working over
Redmond and I worked on a number of
engagements with Lucas and drew on some
of the environmental tool sets so what
attracted me to kind of come come back
and being moved into the ashram Alan
attracted me to move back with two MSR
for this engagement was really to kind
of start working with some of you in in
either learning about how you do machine
learning learning how we can kind of
incorporate some of those best practices
back into as your ml as well as
hopefully you know you folks get a good
taste of Adam out and say hey let me
give it a whirl and try for the work
that I do here so we typically the way
that we have been doing this is that we
did launch a workshop a two-day workshop
and back in June was the first workshop
before I joined the team and it was
given to both internal and a few
external folks to get feedback on the
workshop it was then replicated in tech
pre tech fest I think it was to an
internal audience so the idea is is that
the team wants to kind of roll out this
workshop kind of like a workshop in a
box and now start distributing it to the
various gos so the GE 0 is the cells and
technical people within those geo
locations can now start educating folks
on
machine learning so we've learned a lot
just kind of bite by going through it
yesterday my point is is that you know
feedback from you folks on the way that
we present the day's course is great so
we can roll that back into the course
make some adjustments before we roll it
out to the field so be your your input
would be fantastic so we typically start
the land and I should just mention to
kenji sent out three invites so there's
the invite for this hour session which
is more of an intro if you want to stay
throughout the whole day that the middle
section which is the meat of it is
actually you know with your laptops you
know going through the entire course and
then at the end there's an hour session
that Kenji sent to separate invite for
where it's just kind of an open dialogue
and conversation amongst all of us at
Microsoft about you know input into the
product what you saw as well as future
directions of the product sound good so
feel free to to stay all day or just
stay for this session come back later so
the first deck that we typically do is
we do an introduction to Azure machine
learning in what we're trying to do
there is a position to our external
audience how we take a look in view
machine learning as well as a kind of
priest sets how we actually design the
product and the workflows that the
product has fully has been designed for
so and I'm going to go ahead and skip
that so so really kind of this kind of
says you know machine learning computer
systems that improve with experience so
let's talk a little bit about what we're
seeing and what we're hearing you know
from the community and what we're
thinking about and how we make machine
learning accessible to a wide range of
audience and that's really what we're
trying to do here at Microsoft with this
product typically what we do is we
describe a couple of scenarios I
actually cut out a few some of them that
it's well known here for example the
Xbox learning stuff but we talked a
little bit about machine learning in the
context of the united states postal
service where you know last year the
US Postal Service processed 150 billion
pieces of email rather of mail far too
much for a human to sort but as recently
as 1997 only ten percent of the hand
addressed mail was sorted automatically
and the question is really why why was
it was that the case and the real case
is that because it's a really tough
problem it you know just imagine that
when you basically pick up a letter
that's been handwritten the address and
in all the different ways in which
people write address is in there and you
take into consideration all the nuances
of their script or their print and then
trying to kind of evaluate that
successfully is very very hard but this
is really such a good problem for
machine learning we could teach the
machine to read them out and and how can
the machine learn and get better over
time and that's as all machine learning
is all about so by providing feedback in
both in terms of humans training the
machine learning models and the machine
learning from the patterns in the data
over time we've actually been able to
get better and better and accurately
trained you know machines to basically
we'd handwriting so this is where the
learning part of machine learning comes
in data scientists created model based
on all the data that they had and how
people can write addresses they train
the model as more data comes in
correcting attempts at reading
handwriting when they're off and then
finally until the model has enough of
the history to draw from that we can
accurately predict and read handwriting
so today with the help of machine
learning over ninety eight percent of
all email is successfully processed by
machines today a really good conical
application this I would say is the
first public killer commercial
application on big data was web search
and with machine learning we can use all
the billions of queries and associated
clicks that we collect each month as
training data for the machine learning
system so i spent a few years for
example in bing search and as you
all know we collect volumes and volumes
of data every day 24 by 7 and we process
that data in very different ways one
example is you know utilizing machine
learning and processing data to
determine which links are most likely to
get collect right that's very conical
for this kind of scenario also
determining for example which items are
misspelled and offering the correct
spelling and kind of making that gasps
and that recommendation another slice of
machine learning is also what language
language did the person enter in and how
do I interpret that to kind of bring my
result set also what is the intent of
the user so can I look ahead and predict
basically what they may be at won't be
wanting to do with the query string that
they had entered within the within the
search string or any of these pages
malicious so there's a whole bunch of
pre-processing and machine learning
that's even done before we actually go
ahead and start displaying result sets
to the user we don't want to to to
communicate for example pages and
patient links that might be malicious
obviously also what's the probability of
a click on each ad right so now this
directly affects affects the amount of
money potentially that we can make as a
business right so we want to make sure
that we're actually ranking those things
we understand what the prediction is and
actually rank them accordingly and also
which ads to show and also in what order
again that affects basically the
probability of a click of an ad as well
as revenue and then lastly you know what
pages should be indexed and what pricing
optimization to revenue so basically
basically for every click and for every
search that someone does on through bing
we have a lot of different hard problems
to solve and you know you wouldn't think
that all this processing is going on
basalt
behind the single page but when you take
a look the entire being stack it's made
up of a stack probably about 20
different operations that are very deep
from not only doing some machine
learning but also for organizing what
material we actually surface up to the
end user when somebody types in a query
so machine learning enables nearly every
value proposition in web search lastly
and something maybe I can bring a little
bit more closer to home about talking
about the service is system logs so
these are system logs from exchange and
office 365 in our Dublin data center and
when the team I wanted to build a data
center modern utility they took all the
rules and all the triggers that
currently exist in system center that
they were using for managing this and
turned out that the system was getting
so many false positives and false alerts
and missing the really important alerts
they simply shut the system off it was
just completely unusable so a new team
kind of went in and they focused on
capturing time series coming from every
sensor on the rack so everything from
network cards to the heat of the system
all the way through to the response time
from the service itself and then
whenever a failure occurred they
typically ask the technician to kind of
classify the failure so really what was
happening is they're building a training
set for use oops oh sorry I got to pop
up here that new software was installed
the team was able to take that large
corpus of time series data and the
classification of the era and deploy
basically a machine learning service
that now today monitors all the feeds of
the services and with that as well as
the hardware and it predicts errors kind
of in advance on through a dashboard and
in instances accurately classifies the
problem saving the operation time and
diagnostics so so in bing if you've ever
got a chance to go ahead and visit some
of the sites where we
managed a lot of the hardware we
basically have technicians who
throughout the every day seven days a
week are going around and replacing
pieces and cards and we're now down to a
point where we can actually go ahead and
start predicting where potential
failures might be based on temperature
also based on things like temperature
utilization from a hardware hardware
perspective and start replacing they
started getting ahead of that so it's
super important to kind of keep the
business up and live and making sure
that our customers actually have a great
experience when interacting with things
like Bing or office 365 so hundreds and
hundreds of machines hundreds of metrics
and signals per machine and you know the
really quick question is you know which
signals correlate with the real cause of
the problem and then how can we extract
effective repair actions as well as and
and all this stuff basically affects
revenue it affects our s la's to
customers and so on and so forth this
obviously lots of other uses of machine
learning at Microsoft a lot of the work
that we actually do here in the
Cambridge lab relate to Xbox Kinect
Commerce fraud anomaly detection and
sequel Azure churn prediction and halo
and ed keyword bid prediction those are
just a few of the examples and the thing
to note too is that a dremel a lot of
the algorithms that ship with Azure ml
actually came from Microsoft quite a few
of them are in use today with in bing
for example with an xbox and what we've
been able to do with a lot of the help
for example from John Braun skills team
is actually go ahead and packaging them
up testing them and making them widely
available to our customers so it's
really really unkind of cool to see how
a lot of learnings that we've done here
within Microsoft are now being able to
move out into the public
so for us you know we see the promise of
machine learning it allows us to solve
really hard problems better we can
definitely extract more value from big
data in fact you know those of you who
are sitting on Big Data troves you can
start to ask yourself you know what can
we extract by applying machine learning
to get to detect patterns and how we can
use that data to kind of get extra value
and then lastly we kind of see it as an
opportunity to drive a shift in business
analytics as well so um in particular
what we're going to do is focus today on
predictive models and you know
predictive models really address
likelihood of something happening in the
future and when you take a look at the
breadth of different applications that
you can apply predictive analytics it's
it's quite broad everywhere from you
know turn analysis to managing customers
social network analytics for sentiment
you know is the training positive or is
it negative can we build a
recommendation service to recommend
products and not just make it available
to big companies but also small
companies as well there's a breadth of
applications where you can really apply
machine learning and what we're trying
to do with Asher is ml and one of the
key components of a dremel is where once
you've built your model and you've
trained it and you're really excited and
you you know basically it's working well
it's very easy to go ahead and publish
for example a service directly from it
expose the rest api and make that either
callable by other applications within
your ecosystem and or potentially put it
on a marketplace and sell it so that's a
little bit about how the acronym l is
starting to kind of position a little
bit of the product the team rather the
teams looking at this from the
perspective of making machine learning
available to the masses as well as
providing opportunities for people who
who have who are sending on data will
have some unique models to kind of
expose them externally as well so um you
know listening to our customers so some
of
things that we've heard as a team is
that access to quality machine learning
algorithms is really hard typically you
may you know if you're a data scientist
or a statistician you may be scouring
the web you may be speaking with people
who also do very similar things you get
an idea a notion about hey here's a good
algorithm for this you get it over here
here's a good algorithm for that and get
over there or you potentially you're
also kind of building your own or you're
purchasing very big packages for a lot
of money to try to find that good
quality machine learning algorithms to
support your business so it's hard the
other thing too is that you know when
you think about the whole intent process
of machine learning actually deploying
for example models into the world for
use you need to learn a lot of different
tools to complete the end-to-end
solution so from data acquisition
cleaning and prep to machine learning
and experimentation and then finally
it's you know putting it to deployment
we've done some analysis some studies
we've used some studies and we've
learned that a less than thirty percent
of all models actually go into
production which is which is a bit of a
shame it means that people are building
these things and they're just not being
utilized very well and part of that
reason is because of the economy and the
tool set and the different skills that
people have so for example from a data
scientist restitution the statistician
you're probably going head and utilizing
the tools for you know the data
acquisition the cleaning of the prep and
the machine learning experimentation but
yet it's a completely different toolset
that the person who needs to deploy it
is utilizing their thinking about how do
i secure how do i how do I kind of
deploy it how do I go ahead and I'm
scale it out and those are things for
example that thus a position is not
thinking about you know pretty much when
they're done they throw it over the over
the thing over the wall and expect
somebody to go ahead and put in
production so there's a cost to put into
production too that's additional dev
resources potentially as well so it's
hard and you can kind of when you think
about it that problem
you can kind of understand why probably
less than thirty percent do actually get
deployed so you know we believe that
data science must gets simpler and
that's what we're trying to do here with
a dremel service so what we you know
what we've built so far is basically you
know it's a fully managed cloud service
it's all browser-based there's no tools
or applications or code to install on
your laptop or your desktop it's fully
composable so modules to support
end-to-end data science workflow and
we'll talk a little bit about the
workflow in a couple of minutes because
it's very important because it's kind of
like the foundation of how we've built
the product but how we believe that our
customers approach doing data science we
have the best in class machine learning
algorithms the same that support xbox in
bing or are in ml studio and as I
mentioned earlier and we also have
support for our so we do recognize that
many customers today utilize our and
there's more languages coming fairly
quickly the other important thing too is
is that we want to promote collaboration
collaborative data science and by having
it as a managed cloud service it gives
us the opportunity to provide to our
customers a way in which they can kind
of for example collaborate on
experiments collaborate on models
collaborate on data so and we'll show
this in a few minutes but the ability to
kind of give permissions for somebody to
go ahead across the globe to work on
your experiment and just kind of make
that very easy to do without having to
again ship files from on a thumb drive
or a share somewhere or model and get
out of sync about what versions the
right version and then the other thing
too as I mentioned earlier is we want to
quickly deploy models as web services
for both rest and response and back
scoring so this is also is a very
popular kind of feature when I speak to
a lot of folks who are in this field
that excites people a lot
and if you do stick throughout the day
and you do go through the workshop one
of the things that will do is will show
you how to deploy for example a
classification model so the other thing
too that we want to do is wrap it
experimentation to create a better model
so we do know that you know data science
is often about which ml algorithm is
best and you know there's really no way
to kind of tell you know which one's the
best heuristics out of the box so you
have to try different ml agri algorithm
so the system built so you can
experiment quickly and you know take a
look at the results and if you need to
back out or try something very quickly
something different very quickly we have
the immutable library of models search
discover and reuse and supporting the
rapid try of range of features
algorithms and modeling strategies and
then deploy it so I want to kind of
transition real quick to you know how we
think about the workflow for example of
a data scientist in doing data science
so you know many people kind of look at
this and you kind of think about well
geez you just clean the data and then
you create the model and then you're
kind of done and we wish it was really
that simple but it's really much more
complex than that when you're doing data
science really the process model that we
think about is that you know you you
first sit down you define basically the
objective of the the objective and
quantify it with some kind of metric and
potentially with some constraints if you
have them and this really requires some
amount of the main knowledge right and
that domain knowledge you may have or
it's the main Moloch needs kind of seek
out as well and that takes a little bit
of time but getting that right is super
important next you want to collect and
understand the data and deal with a lot
of the vagaries and the biases in the
data so and sometimes you have to
acquire it and when you acquire the data
sometimes it has missing data there's
outliers due to errors and and it
introduces potentially some more
sophisticated biases
after that you know you then you start
thinking about the problem and frame it
in terms of the machine learning and
then you have some classification think
about regression ranking clustering and
some combination of domain knowledge and
then the machine learning knowledge is
starting to become useful and then you
start transforming the raw data into a
modeling data set so you actually
haven't even done any data modeling yet
right you have to think about the
problem you need to kind of collect the
data need to look at the data I work
with the data to get into a form that
you might want to be able to cut and
plug into a model so once you have that
you start taking a look at it and he's
saying you start training it testing and
evaluating taking care to control by Oh
Sees bias by vigilantly against target
leaks and this is kind of like the
machine learning heavy step so training
and splitting doing some feature
selection some model training scoring
and evaluation and the thing is is that
you know this process isn't just a one
time one time thing right so most often
what you're doing is you're iterating
steps 2 through 5 until the test metrics
are satisfactory and then lastly what
you're doing then is your kind of
deploying the train model ensuring that
the models reproduced faithfully in an
environment you're monitoring the data
distributions both model inputs and
outputs and you're retraining as
necessary so it's basically it's it's
it's it's kind of like this journey that
you kind of go through and what we're
trying to do when we built we think
about as your ml and the product is is
that we're trying to kind of support
that entire journey through one single
tool that doesn't require any product
being installed on your desktop or
laptop so so today's agenda if you do
choose to kind of stay what we're going
to do is we're going to actually follow
that workflow and we're going to go
ahead and touch every part of the
product to basically talk about how we
support data ingress and egress
data visualization transformations and
doing some feature selection will have a
brief talk on predictive models followed
by will build the classification model
and then we'll go ahead and
operationalize it so will actually turn
it into a REST API with request response
so let me just go ahead and just give a
quick tour of a dremel quick question
how many of you have even looked at the
product or using it no okay there's this
by more than half good good good so some
of this so typically what we do is um
let's go go through here just switch
here grab this real quick
yep
better
okay so let me go to the azure website
ok and go into the portal and login
so so I sure AM L is currently in
preview the team is working to putting
it into final production or GA best
guess is it's probably going to be you
know early next year we're actually
making a number of changes some of the
including user experience we're also
getting a lot of feedback from customers
so incorporating that into the product
as well but what we would do basically
is there is a machine learning service
down here and click on that and create a
new machine learning do a quick great
give it a workspace name
the workspace owner would be me the
owners utilize basically for managing
permissions on the location right now
with central south central us that's
only because it's in preview so it's
just right now limited to a single data
set as soon as it location as soon as it
goes into production I'm sure it would
be available in all of our other Gio
locations can you use your org ID which
are what's your org ID in this field it
needs to be a live ID yes and then you
want to provide it with the storage
account if you don't have one already
you can create the storage account the
storage accounts are utilized in two
ways number and really what that is is
its is Bob storage it's utilized number
one for just managing a lot of the
projects and things like that but it's
also utilized for storing any data that
you might bring into the system as well
so from a result as a result of like
data ingress or results so I'm going to
go ahead and create what's called an
azure ml workspace and as you can see
here I actually have several workspaces
so there's the one that I had just
created let's go into that real quick
and sign into the studio so M else to do
is basically the environment that you
primarily work within when you're you
know importing and exporting data when
you're doing data visualization and
transformations as well as experiments
and so on and so forth at the home page
we have your standard basically you know
access to help and there's quite a few
videos that are available in those
videos are growing every day also if you
go to the external as your website and
navigate to you as rimmel there's a
whole bunch of experiments there as well
on the experiments tab this basically
would show you
what experience experiments that you
have completed if you click on for
example samples you'll see a list of
samples that come out of the box so you
know whoops so you know direct marketing
a movie recommender there's a whole
bunch of different kinds of samples to
kind of get you started finally web
services if you were deploying and we're
going to deploy for example a model out
as a web service later today you'll be
able to see a reference to that manage
that through this page and then finally
settings which is just basic settings
like your workspace name description
authorization tokens and users if I
click over here as I mentioned one of
the things that we're really striving at
is to make it a very collaborative
experience that should people
collaborate on we're on a particular
workspace or experiment it's really a
workspace think of that as kind of a
container that's what we had just
created so and it contains both you know
data as well as experiments as well as
management types of things so here as an
example I'm associated with let's see
five workspaces so within those
workspaces there could be you know many
experiments as well as large collections
of data now I just have to create those
but if I want to for example invite one
of you to my workspace and workspace and
collaborate I could do that with your
live ID so that's where some of the
other ization tokens and the users kind
of come to play and it's very easy once
I'm logged in as me not only do I see
the workspaces but I can also go ahead
and click on one and flip to that one so
if I'm working on multiple with multiple
colleagues I can go ahead and switch
back and forth in different workspaces
let's see you let's just go ahead and
click on one of these samples
and so this is kind of what a sample
might look like for training testing
evaluating a binary classification for
an adult data set and actually we
actually go ahead and do this experiment
we actually go ahead and do this
experiment throughout the day your bring
it in real quick yeah mostly we've
working is your portal the menu just
selected there I would normally go to
change permissions for my subscription
which is very similar to what you're
describing giving people access to my
subscription my web services but you're
talking about machine learning
workspaces yeah yeah so is that in the
background modifying my subscription
permissions as well no no it's not so um
so so the way to think about it there's
actually two tabs up there right up here
if you look well one is basically what
you would probably see if you were
utilizing at Azure correct so on the
left-hand side you have all the services
ml studio think of that is kind of like
a nap in the cloud so so so really what
you're doing when you're basically
setting up permissions and in that
workspace or the ashram else to do it's
really for that application and it's
it's really only for that container
which is basically the azure Mel
workspace that you're working within so
they're they're they're separate from
anything that you might do for example
through your azure portal that you have
today right so so really what I'm saying
is is that I've created an azure ml
application workspace when I clicked on
sign on to Aunt Em else to do that's my
application so think of that as almost
like visual studio that's where I do
everything and what I'm really doing is
I'm granting people access to these
workspaces over these containers that
are managed by a dry mouth okay
so that's a let me see if I can just
pull up a quick example here
yeah okay yep
okay okay and so so throughout the day
what we'll do is we'll go ahead and
create some of these experiments and do
some data transformations and stuff like
that any questions so far take a look at
the slide deck here yeah so that's my
last slide that's at least for the first
part the introduction folks want to keep
going on yeah yeah okay well if you like
to leave feel free to else we're going
to kind of jump into this actual
workshop part</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>