<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Community detection thresholds and the weak Ramanujan property | Coder Coacher - Coaching Coders</title><meta content="Community detection thresholds and the weak Ramanujan property - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Community detection thresholds and the weak Ramanujan property</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/J24e93yEJYg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
blowin missoula and from the MSR India
Center in Paris will tell us about
community detection thresholds thank you
you Val it's a pleasure for me to be
able to give you this talk this morning
so what what is it about community
detection is basically the same as
clustering it's about identifying groups
of objects with similar characteristics
from within a global population and so
embedding is also closely related
objective you may want to embed your
individuals within a space and then do
clustering after having performed
embedding and so if i had to state one
application then i would say this is a
useful primitive for instance for
recommending contacts in online social
networks you might process the
friendship graph and then recommend
users to connect to people that
constitute their implicit community so
so much for motivation here's another
one but I'll not dwell on it so the main
character in this talk will be the
stochastic black model so it's a random
graph model whereby we have n nodes and
being loud and each node belongs to some
cut to some community specifically we
sample in an iid fashion spins for each
of the nodes so it's not might pick a
type out of K different types in an iid
fashion and then conditional on those
spins we decide independently to create
an edge between two nodes with a
probability that depends on the
underlying types so b is the this
probability that a function of that type
of the to EndNote Sigma using my V but
then this is scale but by s over n where
n is the population size and s should be
thought of as the signal strength in the
observation
it's pretty much the average degree of
the graph it's it's it gives you the
scale of the average degree in the graph
and so what we observe is this random
graph that is a realization from from
the stochastic blood model and we'd like
to recover the underlying communities as
much as possible so before I say a bit
more precisely what I want to cover
within the talk let me recall what
spectral clustering in its classical
version is it's just the fact of
processing this adjacency matrix I
extracting the eigenvectors
corresponding to the largest eigen
values and then you do an embedding
using this eigen vectors as having
normalized them if you pick our eigen
vectors you can embed the nodes in our
dimensional Euclidean space and then you
can do say k-means clustering or whatnot
and the basis of this and so what I
really want to tell you about today is
about a phase transition that occurs
when you want to do inference about
these underlying communities when we
have a very sparse graph that we observe
so other one average degree but before
getting to that I will do a deterrence a
few things about the case where we have
a little more edges to work with because
this will help me introduce some notions
of spectral separation which will be
helpful in understanding the idea the
remainder so let's assume to start with
that we have what i call a rich signal
that is the average degree parameter s
is at least logarithmic in the in the
system size and so in that case modulo
an assumption that you could distinguish
the different clusters that they are
statistically distinct which is not
really a big deal because if they are
not then this should be considered as
the same cluster
so then a classical spectral clustering
will work essentially because the
spectrum of the matrix a will consist in
a small number of eigen values that
stand out so the number is going to be
less than the number of the underlying
communities the magnitude of the
eigenvalues will be other s at least and
the remainder will be negligible it will
be out on the order of square root of s
and so in principle by by putting up a
threshold you could extract the right
eigenvalues a do the embedding and
moreover what what is true in this
regime is that the representatives of
the nodes in this embedding will cluster
according to the underlying communities
except perhaps for a vanishingly small
fraction of the nodes so here's a
simulation of this this set up with a
four blocks and well n is not going to
infinity here so we have some scattering
around where they are suppose the node
representatives are supposed to cluster
but still you you see the phenomenon
starting to emerge and so let me say few
words about why this this holds so
recall that the adjacency matrix that we
are going to work with is can be
decomposed into its expectation which
has this nice block structure and which
has a low rank on the order of the
number of blocks and the eigenvalues on
the order of the of the signal strength
s and then after a centering a you you
create this random matrix that you would
add to this expected value matrix and so
what we want to leverage is some kind of
spectral separation essentially thing
that the random noise matrix has a very
small spectral radius which will
tell that the spectral structure of the
bunch of the matrix is very close to
that of G and touch-up matrix so the
prototype for this spectral separation
is the so-called Ramanujam property
which is something that was introduced
in the 80s by lewbert's kettle which
essentially is defined for s regular
graphs and which says that the second
largest eigenvalue ought to be as small
as possible and that is on the order of
the square root of s so that's the
definition of a Ramanujan graph and we
know by Friedman's work in 2008 that
random s regular graph with high
probabilities almost Ramanujan in that
the second largest eigenvalue is close
to the bound in the definition of those
Ramanujam graph but what we need to
establish what I just described is
something else on a dress Ronnie graphs
this time so not necessarily regular
graphs and Phi go an effect in 2005
established similar property so long as
the degree now is at least logarithmic
we still have this behavior that the
second largest eigen value of another or
any graphs adjacency matrix is on the
order of the square root of the average
degree and related result is that if you
center this adjacency matrix then you
have a blowjob asian matrix whose
spectral radius is also on the other the
square root of the average degree so
this these are all relaxations of the
original Ramanujan graph definition so
you could say you have almost Ramanujan
graphs somewhat Ramanujan graphs and
we'll see further weakness of this
definition that will be useful for our
purpose so with this result in hand you
can go back to the stochastic block
model consider the adjacency matrix
after centering and using faygo and oh
thank you and show that it has a
spectral radius on the
of the square root of G signal strength
and this is of a lower order of the of
the leading eigen values of the expected
adjacency matrix so we can indeed say
that the spectral structure of the
adjacency matrix is close to that of the
expected adjacency matrix but what we
can say also is that if we let the
signal strength go down then this breaks
down because we know that the spectral
radius of the noise matrix will be
dominated by the largest degrees and for
all the one degrees this is on well the
spectral radius will be on the other the
square root of log n over log log n
whereas we may have s as low as 1 so we
know that classical spectral clustering
has to break down for a signal strength
on the order of log n over log log n so
but we may still do other things than
classical spectral clustering and this
is what I want to get to focusing now on
weak signal strength and an interesting
phase transition phenomenon in that
regime so let now let's now assume that
signal strength is of other one we know
then that we cannot correctly recover
the underlying clusters because we will
have isolated notes for instance and
there's no way we can tell which
community and isolated not belongs to so
we have to set up for less ambitious
objective and so the objective will be
then to achieve a good overlap so guess
community labels and make sure that the
agreement between the GE estimated
labels with the true underlying labels
is as large as possible and this is what
this overlap metric metric measures it
counts the number of nodes for which we
guessed right and there is a enough set
that is removed
it to take into account the fact that
you could assign to each not the same
type and that could not be a meaningful
anyhow so with this definition a 10 what
you might expect is that as you reduce
the signal strength then the best you
can do is to achieve some positive
overlap that is not one but slightly
less than one but that decreases
continuously until the point where you
don't have a giant component anymore
that could be the naive gasps but it
turns out that something more
interesting happens you have a
transition point prior to the
disappearance of the giant component
where the other lab has to be zero below
below which the overlap has to be zero
and still you have a giant component so
this is this intermediate phase between
the signal strength as zero and Sen am
illustrating here so this is what I want
to look at now and specialize in further
now on the simplest non-trivial
community stochastic block model that
you can imagine that is two communities
roughly equal sizes so the spins now are
plus or minus signs and we have just two
parameters the the parameter a
characterizes the probability of an
internal edge within a community so this
probability would be a over N and then
you'd have a second parameter B which
characterizes the probability of an
inter community edge which would then be
over N and so in that context physicists
desolate Alan in 2011 made a conjecture
that there will be a threshold doubt
depending on the parameters a and B such
that photo less than one the other lab
has to be zero so you cannot make any
meaningful inference about the
underlying communities the signal is
simply not useful to that end and so
this part of the conjecture was proven
in in
2012by mohsen nieminen sly and the other
half of the conjecture made by the
zealot I'll was that if this tau
parameters above one then positive
overlap can be achieved and in their
original paper they said that could be
achieved using belief propagation so
message passing algorithms and they have
a numerical evidence that indeed this is
the case and there is a more recent
conjecture by desolate I'll as well as
Marcel demon and slice so this is km m
and s said and jump the 2013 paper where
they come up with a spectral algorithm
which they call the spectral Redemption
and the conjecture that this one can
achieve positive overlap wen Tao is
larger than one but until november two
thousand thirteen there was no proof
that indeed the positive part of the
conjecture held and but now we are in a
much better state of affairs because we
have two truths so i came up with one
and then a week later most elements like
posted yet another proof so we have
plenty of course with two different
methods to achieve positive overlap
above the transition point so let me now
tell you how we disprove works and what
is the method used to achieve positive
overlap before a bit above the the
transition point so this is going to be
done using a modified spectral method
and the keys to introduce the right
matrix on which we want to do a spectral
clustering we are no longer working
directly with the original adjacency
matrix but instead we are constructing
matrix which counts adjacency at a
distance somehow and more precisely I
take a path length parameter l and for
each pair of nodes I and J I count the
number of self avoiding path in the
graph between I&amp;amp;J so this is what this
matrix B is about and the typical
situation is that
for node I I would have a tree like
local neighborhood in which case b li j
would be one only if the graph distances
is precisely l between nodes I and J
this is the typical case but if we have
cycles then it might be different for
instance that the second case here you
may have to self avoiding works of
distance L between I&amp;amp;J and you may
ignore the third case for now so the
main result is about the spectral
structure of this matrix which then
implies that we can do some clustering
and achieve a positive overlap so if we
pick the path length to be logarithmic
in the in the system size then the
spectral structure of this matrix is
such that there is a leading eigen
vector whose again there's a leading
eigenvalue sorry of the other alpha to
dl when i will face the average degree
in this graph a plus B over 2 there's a
second eigen value which is on the other
beta rays to dl where beta is another
key parameter in this model this is a
minus B over 2 and we know also d that
the corresponding eigenvectors are
aligned with vectors we we know quite
well for the first eigenvalue the
eigenvector is a line with the vector
obtained by applying the old ones vector
to this matrix B and in the second for
the second eigen value the eigenvector
is aligned with the vector obtained by
applying the spin vector to to this
matrix B and we have a third and
remaining I ghen vectors which are all
of essentially a square root of alpha to
dl so yes
see they're accusing arrows and subsea
games now again this is Cooper I need
see to be positive but I also need alpha
to Lucy to be led by one fourth so that
there is a constraint on see here which
has to do with the presence of of cycles
in the neighborhoods of the nodes but
that's the range of of parameter pollen
our values for C data I can cope with
and so the fact that the the third
eigenvalue up to the end to the epsilon
for an arbitrary positive epsilon is of
the other the square root of the first
is what I call a week Ramanujan property
and so the the final statement in the
main result is that the second
eigenvector correlates with the
underlying communities so I can do a
threshold in on the second eigenvector
and I will achieve my community
detection alright so I what I want to do
in the remainder of the talk is
described the key ingredient in the
proof and then conclude so and this is
just an illustration that it seems to
work in practice I tried it out and so
here you should see the other lab become
positive it's it's not completely
obvious maybe I should do more
simulations to confirm the theory but it
does not disprove it at least
so the key step is to introduce a matrix
expansion expression so in order to do
that what I'm introducing here is the
expectation of the adjacency matrix
conditional on the spins so it's simple
matrix with a century rank to if you
ignore the diagonal terms but so this
can be expressed in terms of the old
ones vector and the vector of spins in
this way and based on this it's useful
to introduce now what I call a centered
path adjacency matrix which is
essentially constructed as the the
matrix B was from the original adjacency
matrix but it's now constructed from the
center adjacency matrix so the IJ entry
is just the sum of our self avoiding
walks between I&amp;amp;J of the products of
these terms right and so once I have
this at hand I can write an expansion so
I can consider this and say well I'll
expand those products and group terms
according to the place at which the last
a bar product appears and what you see
by doing that is that after this last a
bar product appears you'll have only
eight on a terms and since you are
considering self avoiding paths here you
will have essentially terms that
correspond more or less to the matrix B
but to a corresponding to a shorter path
length so you essentially find that your
matrix B is this perturbation matrix
plus some expansion which involves the
matrix B with the lower indices and
perturbation matrices with lower indices
so this is the first step and this is
crucial because we can do some work on
this
Delta metrics whereas working directly
with the B matrix way is hard and so
indeed we can use classical tools for
controlling spectral radius of random
matrices to control these Delta matrix
and basically we can use this trace
method so we can look at the trace of
the matrix rise to some power and by
combinatorial arguments actually
leveraging 3d and Colossus work in the
80s I think so that does a paper by
Freddie an income loss which which does
this kind of control we throw in the the
additional ingredient that we are
considering self avoiding paths and this
gives us some some control on the
spectral radius in the end and
essentially what we we have is that this
perturbation matrix has a spectral
radius ignoring the first time that is
on the order of the square root of the
degree rise to yet so this is well when
key ingredient in there and then the
second ingredient is is what I what you
could think of as a local analysis you
just need now to work with the local
structure of the neighborhoods in this
in this graph and so the ingredient here
is to show that if you look at the the
sizes of the neighborhoods at distance t
as well as the sons of spins at distance
D this has some kind of a quasi
deterministic growth pattern and this is
what is written here in red so that's
the number of neighbors at distance t
this is roughly the number a distance L
scaled by by a constant plus some
perturbation and similarly for the sum
of spins and so from this you can so
this is an intermediate step I'm nearly
done so I put that together with the
controller of the spectral radius in on
the next slide so now if you look at the
supreme um
norm 1 vectors which are orthogonal to
the kanji data eigenvectors BL e + BL
Sigma applied to be raised to some n
minus 1 and here the e vector then you
can control that you get a square root n
term and but you get also an alpha to
the M of them to term and reason why
this holds is that these vectors here
are treating in the precise sense close
to the the vectors of sizes of
neighborhoods and spin sams at even
distances and so if you force x to be
orthogonal to add these two things then
it will be orthogonal to the first term
in terms in here so you will be left
with the perturbation terms here only
and so I put putting everything together
now we can show that if if we restrict
ourselves to unit vectors orthogonal to
the kanji data again vectors then BL x x
has an on that is on the order that we
are interested in that isn't the order
of the square root of the average degree
race to dl and basically this is a
combination of the the ingredients I've
I've just given so the expansion the
controls on the spectral ready of the
coefficients in the expansion and this
last fact so just putting it all
together gives the result so and the
rest is is much easier this is the the
most non obvious step I think in this
proof and you can conclude by by
leveraging coefficient crm and
controlling the norms of the conjugate
eigenvalues v metrics and this is this
allows to conclude about the spectral
structure and there is more work to be
done in order to show that the second
eigenvector correlates positively with
the
in community structure but this is again
the local analysis working on the local
neighborhoods of notes characterizing
how to behave relating this to a random
tree model that is the natural model for
those neighborhoods so I'm done and let
me conclude now and mention some outlook
so I mean the key message is that you
can recover this ramen hujan like a
spectral separation by using these kinds
of spectral expands of path expansion
techniques working with these metrics be
rather than with the the original
adjacency matrix so this may have
consequences beyond this this highly
stylized model for instance we have a
generalization of the conjecture when we
have a model with a not just spins but
also labels on the edges which is
something we introduced motivated by d
Netflix price data set where the edges
would be between a movie and a user and
they would be labeled with a number of
stars that the user gave as a rating to
that movie so we have a generalization
of this threshold phenomenon far from
those labeled stochastic block models
and it needs to be where work is to be
done to see if we can generalize this
path expansion to prove this generalized
conjecture and also this this technique
may be used to prove the other
conjecture made more recently by a km m
and s Zed Zed papers so I have not said
what spectral redemption is but I can
say in a nutshell so the way the the
proposed to identify
the communities is to form an
edge-to-edge matrix and you would
connect an edge to another edge in this
matrix if the they have a common
endpoint but you forbid so these are
oriented edges and so that the head of
the input edge should be the tail of the
output edge and you prevent backtracking
so you cannot go back along an edge so
this defines an edge to edge matrix and
so their conjecture is that above the
threshold it has one second eigenvalue
that stands out and whose I ghen vector
can be leveraged similarly Azaz what
what I've been describing so there is
hope that we could use the same method
that I used with the matrix expansion
and and the trace bound to to establish
this and then there are a bunch of
questions like I'm not entirely sure
that stochastic block mothers are good
model for all the applications III just
briefly mentioned so I would be
interested in knowing whether this is
the case for one thing you certainly
need to allow more flexibility like
allowing general degree distributions
which fanchu has done to some extent in
a recent paper with a chimeric a jewelry
but still it's not creates it's a good
model for the data we are interested in
and then there are plenty of other
questions the speed of convergence the
embedding dimension and so forth so with
this I will stop and here are the
references so this is the paper with the
results I was describing and here is the
other proof that is available of this of
this conjecture by a most certainly
managed slide thank you
so do similar models for the regular
regime so you thought so you can you
find some blow since there's some blood
matter than a regular grab and other
similar questions that you answered yes
you can not are you going to send
appendage of our participated so for
instance you could have some versions of
the configuration model so you could
sample so fix the degrees sample the
number of edges that are intra and Inter
and there may be different models for
doing that this could be done on a you
know independently throwing coins to
determine that and then once you have
decided which edges are intra and Inter
you do a random matching of this half
edges and here there may not be this
intermediate phase because the
regularity may help but I'm not entirely
sure you well seems to be a skeptical
that there will not be such an
intermediate phase my guess is that you
will
so there is one version where you say
each node will have three neighbors
internal and two external and for this
one I think maybe that there is no such
intermediate phase if you if you
randomize maybe it it makes this
intermediate phase up here
and another thing which we have been
thinking is what could be said when you
have more than two communities because
as you increase the number of
communities things become even more
interesting so there is something
happening when you have five of our more
communities where you have a phase where
the physicists tell us below transition
point all spectral methods will fail and
but still some non polynomial methods
should work and so we well we could try
to prove that we have spectral methods
working all the way up to that point so
these things are better understood in
the case of the reconstruction on a tree
and which you Val has done lots of a
very interesting works but so
translating what is known on the trees
and to the stochastic block model is
already a challenge and this
intermediate phase is quite a mystery
please remit you can offer fight so it's
specifically five oranges 45 sort of
known and football
I think 4 to 4 included this
intermediate this additional phase does
not exist at least for the symmetric
situation where you have let say for
Communities two parameters a and B for
intra and Inter edges then there would
not be such an additional face you're
talking images or you'll give examples
only for talking ended up 13 points
so right now it's written for 2 i'm
confident that it could be extended but
i have not done that so i'll be cautious
the case of trees there was a big gap
between
two
the number of colors even from this we
turned out that the spectral methods
were were sharp but it was much much
easier for two don't be silly
and then the fact that they break down
that's fine
should have an animal here
yes and discussing with Lancaster barova
was one of the authors of the original
conjecture she tells me she thinks this
will have an analog and in this heart
ranch no polynomial time algorithm
should be able to achieve positive
overlap whereas a maximum likelihood
would somehow but I don't know what is
the basis for this guess that they are
making
I believe it at the level that Maxim
like you look good and no spectral a
person who generalized hopefully no
yelling yes yes I I guess this has yes I
I asked her and I guess it has to do
with the work on the energy landscape
that they have been doing and I forget
the name but there was an attempt to
make message passing work even beyond
the known limit and they came up with a
survey propagation method and so they
developed and understanding of the
attractors of those iterative schemes so
I guess this comes from from there but
anyhow</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>