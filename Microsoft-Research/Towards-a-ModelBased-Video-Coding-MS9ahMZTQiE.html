<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Towards a Model-Based Video Coding | Coder Coacher - Coaching Coders</title><meta content="Towards a Model-Based Video Coding - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Towards a Model-Based Video Coding</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MS9ahMZTQiE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning it's my great pleasure to
welcome old friend professor Wonka and
the new friend to share and role play
meza so we have two talks and we'll
start with when's the talk so when is a
professor at a university pigeon
university and a member of chinese
academy of engineering and the very
recently he is a vice president awful
NSS for china not in this area and it's
a challenge so he's a big figure in
china and he was president of institute
of computing like a chinese academy of
science and also vice president of the
Graduate School of chinese academy of
science so the long title I want thick
Tula so he has been doing a lot of work
in video coding and he will talk about
some new research topic and also some
standardization effort one piece thanks
Jen you rather be to be here so today i
want to share with you about video
coding and some new direction maybe not
new direction some new stuff all the
direction birth to get some new staff
about the video coding i use the
model-based and there's a showcase in
last year in the gym we publish our
tripoli standard which we use the new
model so i will talk a little bit about
the scoop and the key result about that
standard than the summary so I think
video coding basically SD take analogy
try to remove the remove the redundancy
video sequences so think about how many
are kind of differently redundancy we
can remove basically we can think about
three kind of redundancy why is a
temporal redundancy another is a special
and deserved one actually is we call
that a coding redundancy so the system
the standard system just mix let's
rekindle technology into together to
make the system so because the user
multiplier technology so the system
normally called a hybrid video coding
system so current system basically use
the results the video in then so first
of all first part USD are transformed
technical to remove the the temporal the
special redundancy then there's a loop
try to remove the motion related
redundancy record at our tempo
redundancy then last one there's entropy
coding try to remove the the coding
redundancy so let's see is the universal
generation second generation and the
third generation of video coding
standard the flowchart so whatever you
know I Delta 26 press X or unpack acts
or some new standard actually all the
fruit chat is looks like we're saying so
the top of one are actually HDR
transform coding and the bottom one is
prediction coding try to remove the the
temporal redundancy and the entry code
being used for you know code that the
sequence is more you
visionary so let's use the state of art
for today's our coding you know
technology so the actually video coding
has made a big in fact impact to a TV
industry because for TV industry you
know L in a early time is a standard TV
and a day later on HDTV the two years at
23 years ago 3d TV you know from this
year the ultra HDTV so I think the video
coding a technologist base our fortress
progressive so will the technology you
know the coding ratio the the coding
efficiency start from 50 to 1 compress
compress ratio right now years are
around 225 or sometimes we said around
300 then next generation should be
something like 450 to 1 compression
ratio so but if we think about what's
the upper bunk DeForest acknowledged
then we can you know later on I will
explain the upper bunk that should be
very high so today's the state of art
only reach quite low you know the result
is so we still how quite in a big room
to do some new research if I understand
that the app bang so we can think about
to D matrix transform for example gave
our input matrix instance the HD
sequences one film one frame of
sequences so the resolution is 1920 x
1080 so then we can simply iono pull
some 0 then to make a square matrix so
then if we can find
find our transform to make this a
success then the Y become in our only
element here is nonzero either or zero
so with this transformer it's very clear
we can make you know very efficient
compress so actually a list values exist
so one of them is SVD then if thing
about the insert the dimension in these
sequences then the upper bound should be
much much higher than that because
normally when we do with your coding
coding we can you know use at least 15
frame for one group of picture sometimes
we can use 60 and if we think about the
much longer you know how the sequences
then we can make much money higher the
amount of you know transfer the the
compression so this is the idea how we
can make a deal you know yesu DD
inserted a dimension ye are longer
sequences of video with that we can you
not make much higher the 3d matrix
transform so the data is looks like
today in our from star is in 1994 year I
of 1994's is the first generation then I
think is the second generation which I
now finished the in at two thousand
three today I think most the system use
the mpeg-4 or I start to 64 this is the
second generation then he lives a year
actually there's a neo standard finished
called actually be unpacked hevc or I
start to 65 so which if we look at in
the HDD a resolution level is around
three hundred to one comforter ratio
then what's the next so if you look at
the you know roadmap next generation of
video coding should be uh you know
controversial in
601 for HD resolution of course maybe 10
years later HD resolution yes that too
low maybe is you HD so the convolution
will be a little bit higher than 600 to
1 so here is d you know folk so Lucy is
a standard TV a corporation the salon TV
comprise ratio so are there is a you
know even this standard is now change
opacity compression ratio Gathol is the
beater later later Betty be a better
it'll be the batter will say with a time
being such as in the unpack to a time
you now start for HD resolution the
compression ratio you know for one st
channel is about a fire make be per
channel but with have been in today we
only can we can use similar technology
we can use about you know 1.52 to make
be to comprise the same quality of the
video so Lucy icity I in our progressive
by the optimization of an encoder it is
not a contribution from standard but
it's a contributing firma encoded
optimization technology so people try to
make more higher compression you know
standard by using some technology so one
thing energy actually people try to use
you know the big block have data for
example in the early time only to type
of block of data be used for transform
or for prediction but would have been
for example in a certain generation
there's a lot of different type of Brock
appeals for the
you know for getting higher coding
efficiency for example 60 by 60 4 by 64
down to 32 by 32 and down to 16 by 16
and then to eight by eight so you know
with a lot of different combination so
you can find the right the right block
to to use that's for transform for
prediction for motion estimation and so
on we can use you know are very tiny in
our prediction by different direction
early time only for direction we can you
know a major it is match or not then you
can set the generation the direction
from for go to nine and the insert
generation actually DET ER shun go too
much much you know more is 33 maybe 32
maybe 36 and so on so with a lot of you
know direction then you can heat even
you can match that so which can save the
beats so this is the overall the
transform and prediction so for the data
structure we can use a you know figure
like this so there is a you know big
block and small block down to a very
very small block and also we're
different in our combination so let's
use a basic idea first generation second
in general and search generation video
coding technology has been used but if
we look at a detail for the technology
it must be something missed so there is
one thing if you look at when stuff is
today's video coding standard most most
30 years in our target ankhila industry
um you know TV broadcasting and so on so
by that there is a lot a limitation for
that industry so let's take an article
actually has been used for you know
simply used for video for seventeen
video and for internet with you so Lucy
is not good thing because the TV
industry has a lot of a special you know
seeing needed to to make their
requirement to a match their requirement
for example they count the clock very
accurate so if you delay even one you
know Clark then this a similar be
crushed so that is why the firmer route
is very important see so you cannot
change you from route during the
encoding process or decoding process so
if you want to change the the firm
annoyed you need a restart so that is
why you know you should let us take
nology for internet video is not
efficient so of course the today's
Internet the video coding algorithm has
made a lot of a change but it is not
standard it's a local or is you know
profit feature and for another missing
yes for video surveillance several years
video actually is very unique so I use
this technology for that also not
efficient so that is why we try to look
at a different application try to use a
different pic another combination to
make a much better in our system for the
special application of course people
very easy to think maybe we can use some
region based accounting major you should
be much efficient so in last 4050 years
people you know working in that
direction spend a lot of time and energy
but it results is not good because of
the day the video coding standard now
use
kind of taken out yet so but a lot of
the result researcher is already there
so we can use the idea for the
application like internet iveco d video
coding and 70s video coding ok so
there's another factor normally people I
one right paper we were mentioned SD our
perceptual coding because you know when
you code the video there's a distortion
so uh well same distortion which
solution is the best for you know
quality so people can you know argue
maybe we can measure the distortion by
PSN are the result is not good maybe we
can measure that by you know some matrix
so eventually people think maybe because
the already compressed video after
decoding is allocated by humans I so
humans you know reaction for the quality
is more important and so this at the
urgency a perceptual coding so with that
also a lot of research has been done
soul is a result poverty has been
inquiry integrated into the coding
system today so the GST about the video
coding then why model-based so after in
our explain why it is not good to use
the TV or the TV or entity coding
standard before in another video and the
47 is video of course that we can sink a
different way for 70 this video for
example then if we look at a watch you
know our researcher has been done for
the motor base the coding there's a lot
of job work good work has been down for
example
people has been working in geometric
partition for a hefty Cody for example
can use the triangle or use the mesh
network to describe the surface and so
on so I think later professor lower
maybe you know mention some part about
that but of course not for coding but
for image processing so listening so one
direction people has been done the
second wiring is very clear from
conservation point of view if can use a
good segmentation use that the
information that helped the video coding
also is a good idea of course a lot of
research has been done but the question
is do you have stables signature
algorithm for you know coding which not
don't need people in the loop so let's
use the question then the third one is
the object based the coding i signal is
our company is very easy to understand
and then is the knowledge based coding
unit we said knowledgebase actually is
icity you know the lesion analysis and
censuses so basically this direction
researchers you know focus on the face
related or talking had a radiator so
people try to model in the face
expression or talking face itself face
motion and use that to you know save the
beats let's also i related a little bit
of high layer than the knowledge based
in the semantic debates the cody so
which another only to you know descripti
surface itself also for the moment for
the face moment that can use the
semantic based technology then the r61
actually is something i mentioned that
for
show system human matrices related which
uses a perceptual coding idea then the
last one actually is a new direction is
a learning-based the coding so use the
data in the internet in the cloud use
more data get more knowledge use that
knowledge to you know support the good
coding algorithm so this direction has
been located as a very important thing
because the big data if you look at the
partition of the big data over eighty
percent of data is image and the video
and the special if you look at the video
part this surveillance video is a
majority in the big data you know maybe
our forty fifty percent have the data is
so nice video data so for this kind of
data if we can find a good compression
algorithm then we can see the you know
storage or can save the Train
transmission cost of course seventies
video also make a special requirement
for you know what kind of quality you
needa you know protect for father you
know pattern recognition we have find
the art you know emo system today use
the in the seventies video they use
quite a higher compression ratio is much
higher than the coding standard the use
in TV industry you know the only reason
is they try to say with the cost of
storage but it is not good because after
you you know compressed then if you want
to find something you find some special
people partisan you know object from the
seventies video you
finality is very hard to do that because
you has after the in a high country
racial compress you have loosed a lot of
feature then you cannot you know figure
out what's the you know the correct
result for example of course that the
resolution is another issue for face
recognition if the quality of resolution
is too low that is not easy to find DD
people the object of course for make a
better you know pattern recognition
you'll need a very high resolution and
the hot dear editor is the much higher
than today's system has been used
another user actually is for me to you
seventies video no money you know a
comprise is not the only target he
targeted is camera compressed first then
later on should be a do analysis DP
heavy or the people's be heavy or who is
that so but today the video coding staff
is only for you know make high
resolution high compression ratio but
for video content analysis job they do
in separately so now system none of the
system is considered to sing together so
just like the railway it is you know
parallel in all the way so it's not good
so what one of the reason is the all the
coding standard only think about how to
code the video sequences in efficient
not how to analysis the video efficient
so we try to make some combination make
a standard which you can you know take a
care to stuff okay so if we can do that
there's a very direct thinking
maybe we can get much higher compression
ratio by you know use our model here's a
background the foreground model which
should be you know getting higher coding
efficient then later on seems that we
have the background and and the
foreground then for the foreground is
related to the object so for that you
can make the analysis you know turn the
project the the task make it much easier
so that is the one thing we try to you
know put together so as I mentioned for
the quality the resolution of the image
is you know related to the pattern
recognition accuracy for example if the
so here is the face recognition ratio so
this is the the the compress how hard
you compress the data so normally the
parameter in the video coding we will
normally use the QP to describe the how
hard you have compressed data so the big
Q P means much higher come to a ratio so
if you look at that you can find out
basically I may be Q P equal to 10 here
you can you know get a 90 person an appt
recognition ratio but with the QP get
bigger so the commercial get down very
fast so that is why we should understand
if you want to you know make the
analysis a more accurate you cannot
comprise too much to everything so the
idea is maybe you can compress the
object much less
and that you can compress the background
much higher they're all role is it's
okay so that's an idea for how we can
compress a 7-inch video for that okay so
with this idea then what's the showcase
we have done in I trebuie standard
associate Association so the I Triple E
are 1857 is a working group we
initialized in the last year actually
with one year Emmy see so in a year to
2011 2011 so we are basically initialize
the working group then the working
people are officially start work in the
year last year in February 15 so I was
the armed each year and there's a vice
chair and security then are actually
after one year work this standard has
been finished so this is the order
process we have done to make Alice
standard it's also the process so Lucy
is the publication documentation for the
standard so basically as a lot of you
know officer involving illness product
illness standard so this standard cover
different scene can cover basically
there is that we call them a group or
may profile is a basic profile then up
on my profile there is a profile for
special application for example there's
a enhanced profile with special for HD
movie application so there is a mobile
profile for mobile application there is
a civilians profile there's two actually
lair why is the baseline layer another
is we call it as two layer higher layer
soul is leah is more efficient for 70s
video coding so Liz standard this
standard 18 feet are to be 18 15 is the
video seven is a profile you know
there's a definition about the parameter
how you can coding the service video
within the asset there is a some
parameter is very important for example
as a region region ID so there's that
our region numbers how many region how
many region you want to make it as as
interesting region of interesting so if
there is a to region then it never is to
then for the number film them for the
number of region each region you can
describe for where it started with and
and which parameter you have been used
later on you can based on that to make
the you know object will be heavy
analysis or you know the the tracking
and so on also for little standard can
support the camera many camera parameter
such as d the camera data can be you
know location direction and so on also k
integral many are useful information
like gpic information so you know before
this time you slimy if you want to make
a search use you know multiple camera
video then you need you know have a
system to figure out which data is is
captured from aware but whether this
information is a very nature so you know
where is the the camera ma
that because there's the GPS information
there so the colonel technology for
video 787s video are coding actually is
a model based basically idea is you know
there is a orange in the frame then from
the sequences actually we can calculate
a background if we can make the back
ground very good then we can figure out
you know after differential we can
figure out where is the default grant so
the foreground actually we can use that
for motivation codeine and for analysis
of course you need a coding structure we
can have a switch this weekend you know
you'll suggest the original videos
scheme or can use the background or
foreground the big the coding stream
scheme also we can you know support null
unlady fixed region of the camera also
the camera can be rotated the cans mean
smart for that so the background the
model is a little bit complicated to
build up and for sony's video also the
condition will be changing for lighting
you know wider and so on so also we have
some higher layer parameter set for this
query indeed different condition of the
you know video caption so here's the
basic idea how we can make the the
background so if you look at it as a
while on here so Lucy is a line Lucy st
you know the plan we have this inertial
here but basically we have changed the
data structure from orange and add a
structure in orange or normally yes life
the video is XY say
is timing in timing soon so X Y Z but we
tend end in a veal say Y X so let's hear
the z Y X view so you look at it here
you can find out it's a much clean then
left the one so this is much easier for
make the model for background model so
basically all calculation to you know
took to make the background the model is
unless plan in this space ok so Lucy's
the algorithm we have used for that so
here is the original the sequences will
call their training frames then by this
training frame we can look at the in
this direction so note not less
direction we can look at we can cut in
this one look at in this direction so
just like this so we turn that as square
then based on that we can you know make
the model update so if you want to now
the detail how that work we have
published several paper about that so i
can give you the paper so this is a
result that we have done you know by
that algorithm so let's see is the first
sorry that's something i write in
chinese the fact if first the frame and
alyssa is that the firm up for 118 so
this is the result so if you look at
that so the result is not that clean
sums you still remain there but you know
most of the arbor jacket has been
removed so Lucy is the the background
andalucia ste you know orange no.1 so
you can make the difference then you can
do you can figure out at the
for grant so the algorithm is just look
like so you'll get the sequences then
you can have the you know background
then you can have the foreground then
you can coding background and foreground
subject in different sequences then make
it a more efficient okay so this is the
are the format we have been used in our
trebuie 1857 then with that we can
easily to figure out the you know really
interesting of course the object is
quite you know sometimes it's tiny and
small then we can you know use algorithm
to make it more you know a little bit of
a larger region which is easy to deal
with for the codeine so for that we can
you know use that for real-time online
70s video coding also in most today's
system for example h.264 already there
then we can use offline process to use
that our transcoding you know which also
make a very efficient result for storage
and for later analysis okay so we have
used a little system to recommend video
17 system which for example by that we
can you know record video sequence is
dead of course it was d 4 grand d 4
grand we can you know just to keep this
region in very less compressed so which
later you can do face recognition more
accurate also can use restructure to
support the human behavior analysis so
there's a high layer event so well
region
then we can get the object layer then we
can you know make a much higher layer in
event a layer which is a mostly
multi-frame put together to make the
behavior description so a listener
actually can support you know if you
want to do the asset video analysis then
can support us relay here the tablet
year we call the index layer so by index
later actually it's very easy for later
retrieval analysis and so on then we can
have the object layer for so for our
object the layer it is a foreground
layer okay also we can have the oranges
the layer we call that this criminal a
year as a it's just like a traditional
in our process so then some people ask
is this model only working in I probably
1815 side where we said no now so 12 my
student has done quite good experiment
to use the model-based you know
algorithm over HEVC so the result is we
change nothing class a potom you know
folk around the background the model
there then you know here is the beach
saving so we saving 40 40 point seventy
eight percent of a beat then hevc where
the similar quality a similar video
quality that means we almost the double
the performance that actually we see
this is for of course for 70s video so
student my student also done same
experiment on conference video maybe I
think general more interested in tool is
why the result is not like that you know
impressive because it is only saving 13
points seventy-nine percent of a beat a
compare
to a QVC of course the one of the reason
against you know for loose the one the
background the region is a majority so
you can be make a more efficient to one
but for lose the one for conference
video you know majority actually uses a
human face so when you wanna move while
you change is change so you cannot make
a material you know background to make
the atom energy okay so this is the
first stage we also we already done then
we have our next in our step Saudi for
the the road map it looks like today we
have finished you know the 1857 2013 the
next year we plan to make version 2 so
version 2 so fs2 yes you know from the
performance problems view is equivalent
equivalent to actually vc so so I
believe the next year for video
civilians that we can have our terribly
1857 double D coding efficiency that
hevc on 70s video application we also
have the audio part system part and then
this one is quite unique we have we will
call that description part which can you
not support the analysis and synthesis
it ha and we also have the interface
apart ok so this is the major part i
want to share with you for the summary I
have a two-part why is the future
direction so basically today's video
coding use the block based technology so
make the coding efficiency improvement
then what I'm talking as the model-based
is a sum
belong to the knowledge-based then
there's a 130 I did not charge a SD
card-based use more data to learning
based and so on so I didn't talk about
here and it is also once the I didn't
hard he's the precipitate perception
table Cody which also some people
working on across the ILA's stage quite
a many paper already published the bed
only a very few taking out the
insecurity in this standard so I think
people were keeping their effort make
the video coding efficiency higher and
higher and higher of course we should
not only look at the broadcasting video
are coding standard also need to look at
the surveillance video and internet
video so we have a published some paper
related to the model-based the coding so
you ve you are interesting i can give
you the least so uh before finishing my
talk I think as general mention the
formulas year I have a new job the job
is a vagina so NSF China is quite young
so our introduce a little bit about that
so this relatively young is start in
1986 so I think the mission is quite
close to the M NSF in United States so
let's see is the organization structure
are we have another day so basically we
have eight department for different area
so the area six here's the information
science so I mean in charge of this one
also there is office so the general
office the planning office and so on so
the sort of one is science policy office
so so I'm in charge of this office
already so there's some other so the
funding
basically support is freezing why is the
research why is the support people and
this otherwise for to a environment
research environment so people we have a
quite different category of funding to
support young people as you know junior
senior junior people and senior if you
find so uh so we have different category
for our project also for the research
also we have different program general
program key program major program major
research plan and so on so of course for
the subtle there's you know different
category has to be you know a matching
different yo old so uh for the funding
they are you know a program category
there are general key and so on also for
the money for the amount of support you
know from some hundred K and from some
tongue 10k 40k and so on and to a half
meeting arm be another how many US
dollars so the arm be is in the private
one so for the total budget per year so
you can see from start the sfc and the
family is not that many by the time
being is grew up quite fast also it is
one teasing you can in our connector
with Chinese economic ruin for the
number of proposal the application the
actually last year is going to the top
is 170,000 proposal for year come to the
sfc Valusia it done because we have new
policy so each people if fear two year
has pissed
for one year in application so which you
know somebody you know approach to time
will fail stop somebody a prior one year
they automatically stop by and try next
year they think maybe they need to get
more good preparation than and do the
application so the for the evaluation
process basically of the proposal coming
into the SMC then actually we don't
accept the proposal from person we from
we accept you know we cracked from
institution so any faculty needed gave
the proposal to the I used to do
then we correct the the proposal from
institution then we're going to a
different direction different division
or department then there's you know
there's a the format review if the
format no match so the we're not going
to the review process so they are
totally a five percent of a proposal is
you know formatted and not good then
after there there's a peer review so
peer review will select the thirty five
percent from 95 then go to the panel
review then our panel review around the
twenty percent proposal will be except
then where you know guys your support so
I think that's the overall the process
of sfc thank you very much thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>