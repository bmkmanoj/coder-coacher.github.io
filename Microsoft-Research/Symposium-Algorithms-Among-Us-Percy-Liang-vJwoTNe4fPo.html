<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Algorithms Among Us - Percy Liang | Coder Coacher - Coaching Coders</title><meta content="Symposium: Algorithms Among Us - Percy Liang - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Algorithms Among Us - Percy Liang</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vJwoTNe4fPo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
but next we're very pleased to welcome
Percy Lang to come and give a talk on
the elusiveness of a specification of
artificial intelligence Percy is a
professor of computer science at
Stanford I'm sure familiar to many of
you as a core part of the machine
learning community and we're very
excited to hear what he has to say okay
is this your life
alright thanks everyone for coming and
thanks to organizers for having me so so
Nick talked a lot about used words like
AI take off super intelligent sentient
and these things and I guess the
question for me and maybe the
researchers in this community is what
should we as researchers be doing about
this so a lot of people I actually
talked to um kind of say well that's
that's that kind of interesting but you
know that's so distant you know we
barely have you know things working and
so well I'm not going to think about it
and you kind of saw a load of that
sentiment in the last panel and I so
there's kind of this chasm here and the
goal of this talk is to try to bridge
this a little bit and so I want to argue
is that there are actually a concrete
underlying principles that we as
researchers at a technical level can
actually try to do which maybe don't
necessarily mention the word super
intelligence but nonetheless point in
the right direction okay so um you know
as we know AI has been quite influential
and in the future it's going to be even
more so I don't need to say much more
about this but i do want to reflect a
little bit on what are we trying to do
so i think a lot of people are trying to
maximize accuracy right but what should
we be doing well in some sense we should
be maximizing long-term societal benefit
let's say but then the question is you
know I've written this nice equation
what is this function so this is what I
mean by a specification what are we
trying to actually accomplish so here's
our line of the talk it's centered
around specification I'm going to start
at kind of a low level and trying to
brought into something that and maybe
get more speculative as we go ok so the
split idea of the specification is
really powerful and it underlies a lot
of kind of how you build modular and
scalable software systems right so if
you have the specification that sorts
you understand what it does and then
people can work on implementing so
division of labor and it's not just for
kind of the systems is also for humans
it helps you scale a lot because it
gives you modular and scalability of
thought which is actually in some
even you know more important so what
does this look like for machine learning
so today we know we've seen a lot of you
know deep learning take off for example
and I think a lot of that has to do with
having these interfaces you can write
down a model and you can have automatic
radio and checking an automatic things
happening and this wouldn't be possible
if you didn't have a specification of
what you're trying to do and you know
this is actually kind of important at
the code level because once you try to
get more performance out of your
optimizer so you have a computational
crap and you want to actually optimize
it then you might risk the possibility
of computing the wrong answer so
verification is actually kind of
important so I'll just highlight one
thing that have been involved in is this
idea of formally verifying and
constructing algorithms kind of in a
joint way and using basically its tools
from theorem proving and there's a
number of challenges there which I don't
want to really go into but I just want
to highlight this work like how do you
represent the specification the first
place and how do you search this space
efficiently we have some preliminary
thoughts and you can ask me later okay
so moving on on you know computing
gradients and making sure that you're
optimizing a function correctly is all
nice and well but for example this is a
pretty well defined specification um but
you know what we actually want so the
specification for machine learning is
already a little bit more elusive right
you get some training data and you want
to output a predictor that does well at
test time so in some sense this is not
really a specification because it's in
the absence of any assumptions it's
impossible to verify and so you need
some assumptions on the classic thing
that has driven basically all of machine
learning is you know whether you look at
the theory or not this is kind of what's
going on you get some training set is
basically your test set or not yours
test set but you're Ted the distribution
of examples is roughly the same and that
is what allows you to generalize okay
and you can you know be a little bit
more clever and say well it doesn't have
to be exactly the same two
tribution and we can still generalize a
bit more but this doesn't look I would
say that the present theory doesn't
really address these very large changes
like disasters and adversaries so
there's some work on adversarial
perturbations of your input but I would
say those are kind of like you take your
input and you tickle a little bit right
you it's not that your imp entire input
just kind of goes you know it gets
completely disrupted and so here's a
picture that kind of you know there's
changes in those changes right so a lot
of you know theory and statistical work
currently focuses on know kind of small
changes between train and test
distribution but when you're thinking
about you know the long-term risk is AI
you need to think about possibility of
something dramatic changing at test time
and you need to kind of have systems
that can react to this and so of course
you know if you're trained and tested
which are completely different well what
can you do you're in some sense you
can't guarantee good accuracy but i want
to say that's okay and i think it
requires changing the specification so
instead of saying we want the
particulars that do well at s time we
want to say we want to predict something
and give an estimated accuracy of how
well we do so the model here is know
what you don't know some people say that
be aware of the unknown unknowns or and
i think this is kind of a very important
point you can't win in the original game
of just predicting accuracy if you want
to be robust you have to actually you
know say if i get some arbitrary input i
don't know what to do with i should punt
on it okay so and this is kind of a
challenge because at test time you don't
have labels by definition of test time
so you know you silent failures are
possible maybe that user changed his
mind and wanted to do something
completely different and these are the
worst because there's silent failures so
one thing that we've been looking at
which we go one of my students is you
know we don't want to assume that the
trained Hester distribution are the same
what we're instead going to assume is
that some the some structural assumption
about training and testing
being similar for example you have the
same setup of sensors but some of them
could you know be getting different
readings maybe you have some conditional
independence there and then the goal is
to give in a train model can you
estimate the labeled accuracy on
unlabeled examples so and this is we're
still work in progress we're still kind
of working out the details but you can
think about this as an unsupervised
learning version of model evaluation
okay so so I think this thing's like
this is a I'm just in one example of
something that I think you know is
really relevant to the long-term risk of
AI because we're dealing with these
unknown amounts ok finally I want to
talk about go back to you know where
these specifications come from right so
in our head we have all these nice
things that we want our systems to be
able to do but you know let's be honest
justifications are always going to be
incomplete even in traditional software
you just can't write down everything
that you want right so you know this is
kind of should set off some alarm bells
um you don't want to just go ahead add
you know and pretend nothing is
happening because for example let's say
you maximize clasificado your accuracy
right then you might end up
discriminating against on a protected
groups especially if you use a
discriminant classifier if you say don't
harm humans maybe you end up locking in
a room this example is from Nick if you
maximize paper clips you could end up
from you're destroying the mole or
something but no so there's different
levels of unintended consequences that
you can might imagine and you know and
these look very different but the
underlying principle is the same the
underlying principle is you have a large
space of actions your specification it's
in part partial see you just can't
pinpoint down the behavior it was a
really simple idea and if we're building
more capable a is the action space grows
and maybe we want to be over here but we
could be over here so there's a long a
lot of unpredictability here just due to
the nature of the game that we're
playing ok so as ml person i would say
let's just learn this
from data why are we heart conia in the
first place and data being humans here
okay so there's been a onion Nick
mentioned in verse reinforcement
learning there's been a lot of work I'm
coming from your robotics but also in
other areas and the question is what
would humans do and so you get some
human action sequences and you want to
infer the reward function or the values
or the specification but this also
requires some you know delicacy here
first you need a generalize in the right
way from this data and by the way who
are these humans anyway why should we be
trusting them okay so the point one
another way to say it is on you know in
terms of like the the statistical
language identifiability so most of
machine learning not all but most of it
focuses on a prediction so we're
basically saying I want accuracy I want
to classify that does well on
input-output pairs on my distribution
but I want to argue that if you want to
do inverse reinforcement learning we
want to answer we want to be answering
the why question right we want to
actually identify the projector or the
value function or whatever and you know
here's a kind of example diagram that
explains why this is so important right
the key is that the AI is going to
actually operate in the different
distribution than human so this connects
with a previous statement of made belt
you know how it's so important to be
robust to wildly shifting shifts and
distribution so if you train a
classifier over here you might you know
just fit a linear function or something
right um so you have no idea what's
what's going on over here so you should
you know either say I don't know or you
know you or have a model that can
actually identify the right function
it's not sufficient just to predict on
the distribution that your training on
okay so the second point is who are
these humans well let's ask the question
who's in control so there's a lot of
talk about any other control problem and
um so here's what's going on so we have
the behavior of the system and just
combination of two things the things
that the system designer wrote down
that's called
the model and then there's data if we're
going to be in this learning game which
argue we kind of have to be so behavior
is a large number of bits model is a
small number of bits by definition you
can't just write down everything and
data is also necessarily has to be a
knowledge am a bit so necessarily the
system behavior is dominated by the data
ok but so wait where this data come from
well it came from humans so wait what
determines human behavior well it's
actually the system because in the
modern world actually know a human
behavior is actually driven a lot by my
system so you have this neo feedback
loop and i would say that even today the
majority of behavior defined this way
the majority of behavior of a i even
today is not explicitly controlled by
designer maybe I shouldn't have said
that because now in tomorrow and in news
obvious a researcher says AI is on the
loose or something but ok um and there's
some attention to this already so Leon
Powe to a facebook I guess this work was
also done in microsoft is a studying
kind of ml in the wild where you have
users and you have advertisers and and a
lot trying to get a hold of these
feedback loops which I think are really
important to understand if we want to
say anything about how a eyes are
performing in the world and there's this
other paper which appeared at nips this
year by out of google's also addressing
similar issues about feedback loops and
other software engineer issues ok so one
point i want to make is that personally
I don't actually find the h AI agents of
view very useful because I think it's a
you know too much anthropomorphize a
shin right instead I think about in
reality I mean a I already today is
intertwined you know with humans and I
think in order to understand what's
going on we can't really just um treat
the AI system as you know a black box
study what's it's doing you have to
think about the whole ecosystem ok so
just to conclude on a lot of people
focus on accuracy but accuracy is not
the only game
in town so three things to keep in mind
i think as takeaways for things too I
think really make technical progress on
which I think will be for the better in
the long term no way you don't know you
want to build systems which back off
gracefully not silently fail or crash
catastrophic Lee I mentioned this idea
of in identification right as opposed to
prediction and you know I want to
emphasize this because so much of our
community kind of focuses on prediction
is that if you want to extrapolate you
know just focusing on prediction isn't
really enough because you're only you
can't just look at your training
examples and you'll smooth a little bit
you have to actually think about the
structural properties of your function
and then finally if you want to actually
study on the system I think you know in
some sense the data is a place to look
because I think that's where the number
most number of bits is actually comes
from intermediate in terms of deciding
on system behavior so those are the
three things i want to focus and i just
want to thank jigaboos i had a number of
conversations with and the future of
life for supporting this so thank
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>