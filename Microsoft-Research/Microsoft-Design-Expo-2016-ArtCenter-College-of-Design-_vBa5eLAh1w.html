<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microsoft Design Expo 2016: ArtCenter College of Design | Coder Coacher - Coaching Coders</title><meta content="Microsoft Design Expo 2016: ArtCenter College of Design - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microsoft Design Expo 2016: ArtCenter College of Design</b></h2><h5 class="post__date">2016-07-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/_vBa5eLAh1w" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next up we have Art Center College of
Design with transactor aux for AI hi
everyone I'm Lee I'm Ching we're from
our Center College of Design and we're
presenting transactor aux for AI
conversational interface imitate humans
but why computer have its own strings
and witness it has its own way of
processing the decision making and it
literally speaks a different language
computer needs its own unique identity
and we believe this new identity will
help the user better understand how
their computer works and the computer
devices would be also able to perform a
more customized task a more productive
search and also a more collaborative
interactions but to have a better
collaborations we need a Creole a lingua
franca what we're proposing here is a
designed language for AI based
computational actors like commit like
conversational interface this new
language mediate communication between
human and computational actions and also
it improve human to computation
relationship and in this way we can talk
with like something we talk of someone
from different country just like when I
talked with Lee I always use my body
language and instead of speaking
speaking English so we are arguing that
developing its user experience from
transparency will help to create this
new computational identity what what we
mean by
see is that users should be able to
understand what the computer is doing
and why in this way conversations can
become more nuanced and meaningful so to
create this new transparent language we
looked at creating a conversational
interface that communicates emotions by
producing a working see why we then
looked at how that interface might
respond non-verbally by building a chat
bot that only responds with gifts and
then looking at what a natively
computational form might look like
through a series of form studies so
based on our research we then developed
for individual working prototypes that
use light sound motion and behavior to
communicate non-verbally essentially we
transformed the current notion of cui as
a disembodied voice in a black box and
transformed it into a set of embodied
Network two objects these objects
communicate with the user through
distinct nonverbal distinct nonverbal
modalities this facilitates the
conversation helps the user understand
how the machine is operating so we
isolated each of these nonverbal methods
of communication into its own module to
better understand how it works the light
module shows how the computer is
listening to the user uses color and
brightness of LEDs to give a general
impression of how the computer is
receiving the input this is analogous of
how we use facial expressions in our
communication
the audio module reviews next computers
actions we've used tongues to indicate
that get the computer is currently
thinking and to communicate some of the
details of the task it is about to start
this is model after fewer words like
ping huh and wow so all these words
indicate how the indicates the speaker
has more to say the motion module
indicates the status of the text that
our computer is currently working on it
functions us postures and gestures doing
human to human communications revealing
the response to current task and the
behavior module it shows the general
status of the computer just like we can
tell if someone's stress of tired by the
behavior or the bag under de-ice the
using can tell how tax the computer is
by the speed of the fan cooling the CPU
so we think that this sort of
communication system can best be applied
to a higher level sort of ideation
process we have an example here of a
scriptwriter using the system to help
figure out some of the details of a
scene I want like a bright color with an
appropriate symbolic meaning can you
give me some suggestions green really
why Green
color symbolism databases eighty percent
green for ominous seen related results
death decay non-human monsters yeah but
I just don't like green for this what
about some color that symbolizes poison
in nature like poisonous frogs snakes or
something like that yellow and black
patterns hmm no I think I want something
really evil can you give me some eel
qualities crime immorality corruption
control ha um okay can we check these
against the color symbolism databases
read hmm yeah yeah I think that works so
our hope is that these four modules
light sound motion and behavior can
augment the standard voice output of
current CEO eyes with nonverbal
subjective indicators these add an
element of native computational behavior
that more closely resembles our
experiences talking with other people we
explore user experience for artificial
intelligence to create distinctly
computational identity which will help
users better understand and converse
with their computational agents and we
choose this form to move away from human
centric the tour a native computational
appearance additionally we want to
emphasize the physical interactions
between users and computers so the two
are able to trust each other learning
each other habits and grow a close
relationship this system aims to
communicate through multiple channels
and with redundancies it's transparent
user experience design helps the user
understand how the system operates which
changes their behavior this then allows
the system to understand them with this
altered behavior the system affords more
in-depth interactions which helps
produce a more collaborative
relationship so this work has raised a
few questions I'm just prototypes we
found that knowing more about what the
computer is doing and how it works it
makes the computer strangely more
personable so can we relate more to
computers by making them less like us
and with a more conversational
interactions how do we differentiate
demands and conversation and what is and
one can be the relationship between
machines and human with every
computational device having its own
identity what sort of characteristics
emerge as native
qualities or behaviors do these change
per device well the brand affect its
behaviors can the user change its its
characteristics we hope this project is
an interesting provocation that leads to
further user testing more
experimentation we hope ultimately that
it changes how we think about
artificially intelligent and
conversational systems thank you
provocative work as I always expect from
art center and thoughtful and I love
this idea that there are you know
artificial intelligence is exactly that
it isn't human intelligence it's it's
very different and the many different
kinds of artificial intelligence could
be embodied in very different kinds of
subjective inputs and outputs you've
really gone on a very daring path here
with this project in terms of you've you
know you've taken on some really
challenging sort of ideas and I think
pushed the conversation in a really nice
way so I want to commend you for that
there's really some bold thinking here
the devices themselves totally like big
Eiling you know fascinating things that
you know you can you can leave you a
little cold right now in terms of their
provocations about what could be ways to
express the artificial pneus of the
intelligence but you know I but they are
so unintuitive that you're kind of like
your puzzles at the same time right like
they're so kind of like they so
challenged the idea of human-computer
interaction that you're like liberty
find this very hard way of relating to
them so anyway I commend you for going
on such a bold journey and I think the
results are super interesting in
provocative so well done I echo what Rob
is saying I mean not I'm not speaking
when I say
about student work here but often with
student work you find them solving
problems that are not necessarily
current to present design issues and
this is actually one that's absolutely
current to the moment that we're in this
issue of whether or not we want these
artificially intelligent things to be
represented as human it's someone I know
for example that Microsoft is not a lot
about the thing that I wonder though and
the thing though I wonder about like
what is next about this is that like I
find a lot of these details actually
totally convincing especially like the
light is a way of indicating attention
span and things like that but as you
move away from skeuomorphic
representations one of the challenges is
that as soon as you get it get away from
that the mappings become much more
complex and hard to sort of grok unless
you have a code right so that requires
this user testing to see whether or not
this thing really means what you think
it means with real live users but do
enough of that research and then you end
up with skeuomorphic representations
like I'm speaking faster when I'm
nervous or whatever so I'm wondering if
you guys thought about like what that
next step is validating whether or not
these these these codes are actually
meaningful for people yeah so we based a
lot of our work on we did extensive
research into linguistics specifically
nonverbal communication and
communicating emotions through language
and we started off trying to communicate
emotions but the sort of computer analog
and so right now what we're
communicating what it communicates is
how the computer is working so like the
LED module will analyze what the user
says and it will report sentiment
analysis so we're essentially trying to
create analogues from nonverbal
communication in the computational realm
hi I'm not sure I understood all that
but um yes extremely provocative and
kind of crazy project delightfully so I
mean it also may be contradictory in
some ways because our models for
artificial intelligence and you know
even the way described it they are human
centric so but I was interested I feel
like it would have helped too I'm sure
you did this in your research but it
would have helped to be very specific
about what are the ways that computers
are really different from humans and I
wonder where that would have taken you I
mean for example um I think the the sort
of input output I mean just
understanding that a computer is going
through you know 600,000 database
records or say you know just if it was
transparent about what it was actually
doing i liked the goal of sort of
educating us about how you know what the
what the computer is doing for us and
how its serving us and it was
interesting in the video that you had
some of that sort of data feedback
layered on the objects and to maybe that
could have been part of the
representation as well anyway but I'm
you know totally intrigued to sort of i
liked the the conceptual art piece of it
but i also like you know how it's sort
of ya how it's asking it's it's forcing
us to ask questions about a i do yeah so
this there's a guy he died prematurely
but named Clifford Nass who had this
notion that we protect human properties
on two machines no matter how on human
like they are and so is but as that is
going to be more strongly
the present when things are actually
starting to speak to us in affluent
voice as if they actually were human and
this notion to counter that because what
brings out is that the all of these
assumptions that they know more than
they really do and they can do what they
can't and so how do you actually limit
the the conversation so that you were
constantly reminded and don't fall into
that trap which is just natural behavior
and you so you put my design a block
that constantly reminds you in a way
that you can't ignore and I think that
that's how I read what you're you're
doing and if you don't know his work
read it because it'll be it'll give you
lots of ammunition to go on further but
I think that this is a really important
thing to be doing and I think it's even
in cases we have to distort the voices
even so that I know which personality
has a few if I speak to in German you
can tell they don't speak German so if
you're a native speaker you're going to
answer me and broken German to work with
in my vocabulary and have to present my
limitations to you and if I spoke to you
with one key phrase I spoke fluently
you're going to come in on lost and and
because I set expectations but by
practicing being a smartass I I actually
messed up and I think that's true with
the machines so I think there's
something going on in conversation here
that's really important and it's really
interesting and I really liked cliffs
work and I'm glad to see they reflected
one way or another in what you're doing
thank you our Center</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>