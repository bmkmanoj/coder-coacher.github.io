<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Random Access in Multiparty Computation | Coder Coacher - Coaching Coders</title><meta content="Random Access in Multiparty Computation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Random Access in Multiparty Computation</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/FSXB38c28XU" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so today we're very happy to have semi
as ever visiting us so Sammy's a grad
student at the University of Virginia
finishing up very soon working with
David Evans and he's been working on
building one of the state-of-the-art
multi-party computation libraries among
other things and I'll let him tell us
more about it thanks so yeah im sue me
um I previously intern here with Brian
pronto I was working on verifiable
computation but yeahs Melissa said we'll
be talking about the rest of my work I'm
back in University of Virginia most is
on multi-party computation to give you a
brief overview in case you're not
familiar is the idea is that let's say
today if we if I meet somebody and I
want to see if we know other people in
if we have common increment incidents
acquaintances what do we do so on
facebook let's say we facebook has our
all our friend list and they will say
that okay these are friends in common
right we have a trusted third party who
takes all our data and then does the
comparison the idea is that we shouldn't
have to do that so if you and I have our
own own private information let's say
our friend list or are so that's the
genetic information and we're going to
see how closely related we are we should
be able to do that computation without
having to reveal our date data either to
a trusted third priority or to each
other we should be able to perform
computation directly on private data so
that's the premise of secure multi-party
computation is that we don't have to
reveal anything other than just the
output okay so the other applications
could include secure option auctions any
other data analysis algorithms neural
network algorithms and whatnot so now
there are ways of computing computing on
private data directly and computing
arbitrary functions on private data and
the way they generally work is by using
boolean circuits so there are protocols
that
take any boolean logic circuit and gate
or gate and whatnot and glue them
together and and finally give you a
protocol that will execute that circuit
so some of the input wires will be from
one party some of the input wire wires
will have data from the other party and
then you execute the entire circuit and
finally the output can be shared between
several parties between the part if you
want which is great but it is it makes
it kind of hard to use for a video
programmer so kind of my research goal
has been so far to make it easy for
normal programmers you use so if you if
somebody wants to use these protocols
now they will either have to be experts
in cryptography or experts in circuit
design which turns out to be non-trivial
even though digital logic designs
undergrad course in pretty much every
computer science curriculum so what we
want to do is sort of give programmers
the tools necessary so that they can use
these sort of technologies without being
experts in cryptography um some of that
has been in the form of a new language
with its own compiler so it's a language
that I developed it was mostly see like
language we take a few extra annotations
and keywords so for instance you could
have variables declared as of live which
are secret variables which will be any
competition done on them will be done
cryptographically then you would say say
that okay certain variables come from
party one certain variables come from
party too and then finally reveal the
values to both parties so you do that
and finally you get the whole program
you compile it and you get the you get
the protocol and they they execute it so
the program are the writing this kind of
code will not need to know anything
about what's going on underneath okay
now if you look at what's going on
around it in order to make it all work
you have the ability framework in the
middle but then my some of my research
has been both in the front end and back
inside so for instance it turns out that
certain algorithms which are fast normal
computation not instantly fast in MPC
and vice versa so we had to come up with
data structures and algorithms that is
actually fast in npc and make that
railways normal functions to programmers
and on the other hand in the very back
end we had to come up with ways of
reducing bandwidth usage reducing CPU
staged and whatnot for the actual
cryptographic primitives so that's been
sort of the outline of my research so
far in this talk will be mostly talking
about this side of the of the equation
so we'll be talking about how we can do
how we can do data access that's inside
NPC so the central question would be if
you have a situation such as this where
you have some memory access in a program
and you want to run this program in MPC
and whenever you have an array access
you're accessing location J and let's
say somehow this look G a variable is
dependent on secret in the air that you
want to keep secret so you cannot just
reveal that I'm accessing location J
because that will reveal some
intermediate results that you want to
keep secret the idea was that will only
come will have inputs that are private
the only thing that will review is that
final output the interim results should
not be revealed you have a question
sorry I'm sort of lost like finish this
competition happening is it it's in one
of two parties on wait so it's happening
it's a distributed computation so well
say if you and I are the two parties our
machines will be communicating with each
other and run some cryptography
operations such that the protocol and
the computation happens in distributed
fashion we both do some computation but
such that the intermediate values are
not really being short yes yeah
absolutely so yes I feel free to ask
questions by the way it's perfectly fine
that if we go up into your tangent that
you're more interested in and I don't
get you covered that's that's perfectly
fine and much rather cover something
that you guys are more interested in so
yeah if so something something as simple
as area axis is actually difficult if
you want to hide which location you're
accessing right the simplest way to do
it would be let's say even if you are
asking just one element access all of
them like if you scan through the entire
area just to hide which element you
actually interested in that would be in
the nine linear scan approach but you
just
taken an operation that was constant
time and expanded out to linear time
operation most programs would become
unbearable so regardless regards the
fact that NPCs already slow so it's not
going to work so if you want this
technology to be used programs that are
easy to write should remain remain easy
to write if we have to completely
rewrite programs that's a problem so the
way to solve that they're essentially
two different approaches right one would
be to transform the program or come up
with algorithm such that your program is
accessing memory locations in a very
deterministic session independent of
your input data if you can express your
program in that fashion then great your
area location is no longer revealing
private information the other approach
is randomized it you shuffle the data
around constantly so that even if you
reveal which location you're accessing
that's perfectly fine because that does
not really necessarily correspond to the
logical look identity of the element and
that might still protect your
information so that gives you an outline
of the two halves on my talk here okay
the first half would be to come up with
algorithms which are basically circuit
structures that will determine that will
give you a schedule by which you can
access data in a particular
deterministic fashion independent of
input data those are our pure circuits
but they only work for special cases in
the general case it's not possible if
you have completely general random acts
I can't help you there um but the there
faster on the other hand you have the
general random access where you keep
shuffling and in the data it will hide
any rent with any kind of random access
it will work all the time but the
problem is it is it is definitely much
slower you have to do some extra
operations there um so yeah before I get
started on the first type questions yes
Susan I think of this really of one of
the parties know something
this unit in something yeah it cooking
with the Sun and Khushi yeah okay great
so um surface structures so in this part
of top will be actually covering the
very basic data structures the stacks
and queues and associated maps they are
extremely easy normally it easy to
implement a normal programs but the
problem is if you have a stack and let's
say you're pushing elements into it if
some condition stacked up push X if the
your condition is secret then the length
of his stag becomes a secret value you
cannot review it and the moment that
happens you sort of have to now figure
out how to how to implement a step
without revealing where you are there so
the way we start represented inside
inside a circuit would look kind of like
this so you have some conditional push
circuit made up out of logic gates your
inputs will be the condition that secret
is some intermediate value X which also
secret it's getting pushed in you have
the old stack elements coming in and the
new stack and what's going out ok and
now what I'll come on what I will show
you is how to efficiently implement this
this push operation ok now what's an ID
approach well here's an really naive
approach we have the old elements a 0 a
1 a 2 a 3 we have the new elements of
the crimes you have the conditions and
these boxes are basically multiplexers
they will choose one or the other
depending on the condition ok so if
condition is 0 they will all choose
let's see the right hand side of their
inputs and pass it on to the output the
condition is one they'll take the left
hand side so if the condition is 1 X
gets passed into a zero everything gets
shifted if the condition is zero the X
gets ignored and the over values just
pass right through which works this is a
valid circuit for doing conditional push
operation the problem is of course we
are using a linear number of gays to
implement a single push with that's the
problem we serve trying to avoid the way
we saw
it is as far it's really quite simple
the ideas that we break up this buffer
into small pieces and we put empty
spaces in those buffers so that when
we're doing the shift operation we don't
ship out everything that it's basically
basically as simple is that so we take
this one row in the next diagram
consider just the top row that that's
just the one wrote the previous diagram
so the moment we're doing a push
operation we start with by making sure
that we at least have to empty spaces
right so we have five elements here ten
elements 20ms next level and for the
elements open to two powers of two times
five so we do to push operations we know
they'll succeed we'll only have to do
access only the first level there's a
level zero and nothing else so the top
are lying there top row that's um one of
these buffers okay so what we have what
we have is that we've taken this buffer
and divided it up into pieces so that's
level view that's level one buffer okay
yes yeah and we making invariance of how
many spaces we keep at each level so
after after 2 operations we know we
started with at least two empty spaces
so we know after 2 operations it might
be full depending on your conditions so
after every 2 operation we shift into
level from level zero to level one after
every for operation will shift from
level 1 to level 2 and so on and so
forth if you do that and count up the
cause um you'll notice that now well
let's let's do the counting right here
for each operation we accessing level 0
right so let's say five units of cost
for after every to operation we
accessing level one what level 1 is
twice as big so each time you pay 10 10
units but you are accessing it half the
time so 10 times half again 50 similarly
level 2 will be four times as big but
access for one for the time so at each
level yourself paying on average of five
units of cost
/ access you have logarithmic number of
levels because the level insides are
increasing each other nmsu have login
levels so what happens at the end is you
for each axis on average you're paying
five times log in cost essentially some
constant time log on cuz so that's
that's how you do step push and the
reason we have five is that we start
with at least two empty spaces if you
want to do pop pop operations then you
need at least two full spaces so that
you can actually serve up new elements
and then you'll need one extra elements
it just in case some of the conditions
were false and you need odd number of
elements yes something that first of you
is so few black president yes I might be
a nightmare vision yeah and then when
you smash everything over to the right
actually I know whenever we do right so
if 9 is empty next time we push 7 we'll
just go here and that's cuz you read the
whole days unions yeah this is leaner
scanning yeah how do you how do you deal
with arrows like you do a conditional
bush and then you do a pop and then at
that point the pulp might return an
error yes um refreshing so the you can
do anything you want so you can have it
such that the error would be a secret
condition so first of all in most cases
we just recommend that you write the
program in such a way that that doesn't
happen you maintain your invariants that
doesn't happen you can definitely have
some extra circuitry during a pop
operation will check whether or not it's
empty if so it will set a boolean flag
flag but then again whether or not you
reveal that boolean flag is up to you it
might be a enough oblivious boolean flag
that you only review at the very end
something went wrong I'm not going to be
all the result that can be done so that
can be depends on your preference yeah
yes so do you have a wall or bone this
yeah oh it's if you have if you know
that you have a maximal n elements in
the stack at any time
then you can just have login levels you
have to know that statically um well you
have to know something statically always
so for instance if you're doing and push
operations you know it will never exceed
in so statically you at least have to
know how many operations you are doing
because um I mean you don't have to so
let's put it this way if your if your
number of your you always have to reveal
how long your program is running that's
something you're not being able to hide
so if you can either reveal how many
operations you need or you can do extra
operations that's up to you yeah and he
else yeah okay so that's stack um
similarly I'm not going to go into
details but you can do queues in a very
similar way you'll just have a cyclic ex
extra arrows coming between them but the
result is the same so when you do the
evaluation we just compared with linear
scan here because that's pretty much the
only thing that competes yo over the wii
it that's what you expect the clog
there's no surprises here except for the
fact that except for the fact that it's
small we don't have a hidden giant big o
cast you know it's doable it's really
efficient and the best part is it's
completely circuit based so it doesn't
matter what protocol using there are
many different protocols with which you
can instantiate it there yells stmw you
can have Semyon as you can have
malicious whatever the same algorithm
would work unchanged even have it's very
critical agnostic and so yeah it's it's
good that way and the thing is that once
you have stacks and queues you can do
memory access for any kind of locality
so if you have an array here and you're
accessing at index I and in SJ and you
know that they will only be incremented
or decremented in small increments or
decrement then you can just break it up
into many different stacks and queues
and use stacks and queues erfect
circuits to access them in log in time
instead of using a generally this Ram
that would be much more efficient to do
it this way
wait since I see some friendly faces
okay oh yes like a bluish data
structures which are based on I guess
just normal around him again how is this
you say more efficient yes as you seen
my experience yes um the reason is
whenever you use over amps you aren't
those are not general circuits in the
sense that you have to serve review
which path you are reading from and what
not you introduce the external around
Layton sees and so you will need to do
extra steps if you want to go to
malicious security and whatnot so they
come into play where's this is pure
circuit anything that circuit it will
just run and there's no round-trip
latency nothing like that so yes yes oh
yeah one of the very basis what was the
precise condition condition of locality
lets you model andreas ah so um the
condition is that your whenever you
answer the particular index the next
thing is that you access needs to be
within some constant number of steps so
if you're constantly large you pay more
yeah right okay great the other thing we
have is a completely unrelated is bashed
operation if you do not have any
locality but listen you doing many
rights in one go or many reads in one go
and you can use oblivious sorting based
approaches to get log square n
performance but yeah these are sort of
the pure circuit based structures um so
the conclusion for the first out half is
that when you do not have when your
application is such that you do not need
perfect random access completely general
random access great you can there are
always specialized circuit structures
that you can use for sex excuse we have
like 10 x speed up for the batch
operation we have I don't remember a TX
or something and they are completely
perfect now let's take them over style
you can use it with any existing
protocols so yeah that that was the
first half before I go into the second
half questions
no good ok so that was for specialized
access patterns sometimes you have to we
can do that sometimes you have
completely general random access in that
case you kind of have to fall back on
Bolivia's ram now there has been a lot
of work in this most of the
implementations today that use oblivious
ram use freebase oblivious ram they were
first introduced by Elaine she and
others so if you look at the literature
there are tons and tons of paper people
have been working on it for a long time
is that these are what other people have
done and they have been implementing
hybrid protocols between now and Aram
just to see how they integrate together
and what the performance are which is
great and most of them have done all of
them have been a tree-based
implementations but if you look at let's
look at some performance numbers so
without doran what's the performance
number writing a single 32-bit integer
you'll need 32 logic gates great if you
know the location you know exactly where
they located raw y'all performance um
it's 1,000,000 gets per second is
actually low number two you can get at
least three or four going upon a gigabit
per second but let's let's go with order
of magnitude 1 million gates per second
great so right speed you do the division
you'll get 31,000 rights for a second
okay if you know the location the
location is not dependent on private
data right if you have to hide access
patterns let's say you have 12 or 16
elements of 65,000 elements you will
wait get you the math wrong I did the
math wrong I did the math wrong you'll
be doing around this recipe will have
four XS per second so you will be doing
you'll be doing around two seconds per
axis right so let's serve the order of
magnitude if you do not reusing complete
linear scan like know where I'm
whatsoever now let's compare this to
keeping in mind the error in this
I'm sorry about that listen listen
compare this to previous work of over m
performance so this is from ccs of last
year this was circuit struck circuit or
am minimizing the circuit size for each
or m axis that's sort of the best you
can do for NPCs as you can see if you
have 2 to the power 16 elements who are
access times around one second right so
at this point it is almost in the same
order of magnitude as a linear scan
that's where the break-even point is so
if you have less than that there is no
point even using oblivious ram because
the plane linear scan of accessing every
single element will be faster / axis and
this is not even taking into account the
fact that you have to initialize the
previous rampras or like if you have an
oblivious ram structure you at least
have to touch each element once just to
initialize the structure so not even
taking that into account arm so okay so
that I guess the response to that is
okay great I mean Oh Rams are
asymptotically better so if you go big
enough or I'm should still win out yes
Lawrence should still win out if you go
let's say 20 18 out of 20 should i do a
20 is like a million elements which is
okay yes it will definitely win out but
think of what that means um it means
that let's say for let's say 20 24
million elements per axles you have to
spend around two seconds if you have a
million elements just to initialize
that's just to write each element ones
you need two times a million seconds
that's two million seconds that's about
in two weeks little over two weeks just
to initialize if we what happens is if
we want to provide this as a tool to
people and say that hey you can use this
to do arbitrary computation but if you
need random access by the way you need
to wait two weeks just to initialize the
data it's hard to source LMP see two
people week so we serve have the strange
situation where yes or am so provide
advantages
only four applicants so slow we're even
MPC wouldn't be used or its orbit for
smaller cases or amps are still not
usable so what happens is that for many
cases people just wouldn't use oblivious
ramps at all they'll just use plainly in
your scan which is which created this
weird stigma against oblivious ram but
hey this is too slow nobody must use
this which we don't want so the goals
here for our case is that we want to
design an over m which provides benefits
at much smaller size and you know can we
initialize quickly you don't need to go
through that for initialization so those
two goals here um so yeah I will start
now describing how this om works for
just four elements in question so far
the go okay so let's say we have just
for lms this is the Waksman network for
shuffling so if you have four elements
so these deadlines are the data data
wires and we want to just shuffle them
this is just a Waksman network which
means if they either swap or leave the
elements unchanged or sub absorb
elements if um if i have secret control
bits controlling them 0 on one control
bits i can use them to permute these
inputs into any any given combinations
so if you need to permute for lms you
mean five switches okay so the cost of
shuffling four elements would be around
five units or five be lets say because
it could be cpu car Scooby networkers
whatever five minutes for shuffling four
elements um so here's how we can
construct an orm so just four blocks
right you come in on four pieces of data
you shuffle them once it's shuffled now
if you and let's say there is to the
side there's some map that says okay
element one went to a point equation 3
and r elementary went to question two
and whatnot so there's a small like two
good map of local gangs so once it's
shuffled if you are accessing a certain
element and you reveal the fact that you
asking this position that's fine because
it's been completely shuffled you don't
know which original element actually
went there
so we can actually reveal that hey I'm
accessing that element and you were
paying a cost of B and that's it the
next time you access an element you have
to reveal you kind of have to access two
elements the same element as before and
some other element because you don't
want to reveal whether or not it's
repeated access so now you're paying a
cost of to me the next time you pay a
cost of tree be because you access the
same elements as the previous two ones
and a new one you can see where this is
going so what we are going to do is not
go to for be again and just shuffle it
again and then keep going so for every
we do three accesses and the shuffle
again we do three X's and then shuffle
and 3s and shovel again so every tree
axis we are paying costs 25 b + b2 b3 b2
love you loving me which is kind of
interesting if you compare it with the
linear scan linear scan would pay a cost
of 4 b / axis 12 x 3 whereas we're up
paying 11 b by three so just at four
bucks we are already doing better than
linear scan which is much better than
the previous previous schemes that we
saw weight and there is no extra
initialization other than this shuffling
which is obvi if you do hope you do the
first one portion yes it also you don't
win but then um instead of paying your
cost would be 15 by 4 so this is better
yeah how do you go to the costume
finding which one taxes ah so you just
have a small bit vector which is a two
bit value for each flower each position
with this constant deeper n given in a
block size so yes yes it's kind of soft
in the rug yes um so the idea is that if
you have a large enough block that
wouldn't matter in practice if you are
accounting for I don't know we'll have
the graph but if you I can't function a
network bandwidth block size of 36 bytes
is good enough so if you have larger
than that you can always just divide
into larger blocks and is that yes yes
so you have a multimeric application
with it the data is just like bits or
something like that and you just have a
bit here that maybe too much into
expensive simply because of the metadata
like he said yeah is that way so what I
would recommend in that case is to
divide up into several bits and then do
a linear scan on each of them lots of
several bits yes yes yes yes yes yes so
um so the two alternatives you are
proposing is that one would be scan all
bits and the other would be divided into
four blocks and the Skandians can
between and with just each of them right
so yes that that will still win out yes
different way um so yeah that's that's
basically the scheme if you so what we
did is that we generalize this into not
just for blocks and blocks right so we
generalize it and unfortunately the
asymptotic complexity is worse than
other other existing over m schemes so
other existing orem schemes would give
you be x log in or log square and
complex by xi log square and lock you n
complexity ours is much worse i'll just
square root n time something but in
terms of concrete cause it still wins
out well I'm I should have the graph why
don't I have the graph oh there we go so
um if you do the comparison so yeah we
did the measurements of 2 to 4 11 to 20
or 16 we did our own implementation of
circuito ram this is actually done by
the same author as secreto ram but
anyway our CC basin implementation
because the previous one was Java it
this one's faster by by a factor of two
and we see that this is the linear scan
circuito ram and our scheme ok so yes
eventually circular does went out at to
be or 16 but it's still it's still
better for the smaller cases where you
know you don't have to spend inches and
large grants
and I'm talking about initialization
this is just access so in our case this
is all the costs there is in sake door
in case you still have to do multiple
write operations to actually initialize
the data you don't necessarily want that
and in fact if you look at
initialization we sort of computed our
only asian cost as the cost of shuffling
yes that's all there is but yeah I mean
there is a fixed 100x gap between
circuit aware I'm insulation and there
and ours yes oh yes it kind of wings out
in our implementation the break-even is
somewhere here so yes yes yes yeah yeah
the dist languages yeah and language
difference plus the language difference
also implies we can do various low-level
things such as so Oh Rams always
introduce round trips right since they
introduce round trips we can do things
like at the TCP level we can disable
mangles algorithm and that there are
these are things that would aggregate
let's say you're standing in two packets
of data tcp at the kernel level would
abrogate these two packets and send them
off to reduce bandwidth the problem with
that is that once you send one packet it
will wait for the next package and if
wait in the order of milliseconds we can
execute many gates in one millisecond so
that doesn't pay out it actually helps
to just disable that porridge are you
did too ok great we spend more than a
week yeah I feel like there should be a
wiki of these tricks that we don't have
to reinvent each time but yeah yes so um
that's the bandwidth costs if you want
we can talk a bit more about some of the
things that we had to do to change fixed
you actually make this happen so we only
showed showed this okay so sorry I'm
going to live without a folder but if
you look at previous work like I said
all implementations were three visio
grams but there were in the other cloud
basic and cloud-based or not in the
NPC's there are other kinds of words the
hierarchy columns were already there and
the main difference between them is as
follows in the hierarchy kilograms um
the initialization is pretty much as
cheap as ours so it's just a shuffle
that's all there is however each axis
requires a hash function to be computed
by the client in our in npc setting that
would mean a hash function being
computed inside a circuit so that's a
problem so this is part of OMS use
freebase your grams they avoided that
what they paid for it was in high
initialization cost so what we did in
our case if you think about our approach
is that we serve merge them together so
we don't we don't use the three-way
structure ours is kind of a hierarchical
structure except for is limited to two
levels but at the same time we don't use
a hash function we use the tree base of
nested relocation table kind of approach
where there's there's an asado ram that
a recursive around that will give us a
map of which element goes where okay
that's why we get the performance
improvement yes yes it can dove is
actually um so what happens is so it's
hard to see here but what happens here
is that this is sort of the first level
of the hierarchy here and once you keep
using elements these are the elements
that end up in the stash their get moved
from level 1 lift the first level to a
stash them in which is being Lina scan
each time so in some sense this is a two
level hierarchy right here but I saw
druid in
different way yes kind of like it yes
it's a square root so then in title of
the paper was revisiting square root
around so yes absolutely ah so yeah um
if you there were a few other challenges
we had to fix such as creating the
position map itself so if you think
about it you have a bunch of elements
you do the shuffle and then we also have
to create the position map right and the
position map is essentially an inverse
permutation you think about it we have
to know that if you're looking for
position we were looking for element 0
we need the map to say element 0 is in
position two so we'll have elephant zero
position to right so this shuffle
operation will also need to produce this
and for the first case it's actually
fairly easy right so you have some
shuffle circuit that does lots of swap
operations what we do is that we are
subtag knees with metadata 0 1 2 3 4 is
in sequence we run them in reverse
operation in riverside with the same
swaps and so if this the 0 1 2 so if two
ends up there we know zo maps push into
and that's how we compute this this
column here that's fairly easy the
problem is that the next time around
you're doing some operation that gets
composed with the previous fermentation
so now if that element goes here that
does not mean element 2 is mapped here
this reverse permutation doesn't get you
there so one way to solve this would be
to the use of Livia sorting so we could
do tag them with 0 1 2 3 again and then
sort them using these values and they'll
give us an inverse permutation but
starting again is n log squared n that
will add another log in factor to the
complexity we didn't want that so what
we did instead was come up with a new
protocol that just in versus a
permutation so this is a secret
permutation that we do not want to
reveal and we want to compute its
inverse permutation how do we do that um
well we actually use similar techniques
in secret sharing and whatnot it
not to novel but the idea is that so
this is the permutation that we're going
to keep secret the inverse of this is
the output we want pie so how do we do
it the way we do it is that we have two
parties Alice and Bob Alice locally
generates a random permutation pie a fee
Dylan uses that to permute this this
result is the compost composition now hi
a and pry universe this gets revealed to
Bob so Bob sees the original permutation
shuffled in some manner that it doesn't
know so that's the safety review once we
have that Bob can locally compute the
inverse permutation of that get this and
finally we have another permutation
circuit so Paille here and pie and
inverse here and since it's locally done
we can do the permutation and get just
by so with two permutation network
switches and login instead log squared n
we can we can compute the inverse
permutation um so yeah that's how we did
the over em and we go and the conclusion
here sorry conclusion here is we revisit
a well-known scheme I've said it's an
old scheme I'm not entirely new but we
show that this actually can be employed
in sensitive with really low any
children cars and the break-even point
is as low as 4 elements so the hope is
this can now be widely adopted and
people can use our MC normal without
going too much yes yeah OSHA sorry hmm
this is certain of to check that is yeah
yeah it has to check it has to check
that they are actually inverse of each
other and whatnot yeah yeah it shouldn't
require sorting now if I mean the
asymptotic complexity will be maintained
but yes you'll have over Ed's yes
so but it's a break-even point you mean
with the linear yes with the minister I
mean act small sizes that's pretty much
the only thing you need to worry about
there is no other words right now yeah
that's it I guess download use tell me
how it is if their complaints yell yeah
is your language um yes they were
developed around the same time yes um
it's it's more lightweight in the sense
that it's a really thin pre-processing
and it gets translating to see so you
can pretty much see what code is being
generated it's not too different from
what you write so the pros and cons is
that a blue heum is a completely fresh
charge right it's clean slate they have
their own language and they can design
it however they want in our case we have
a lot of C baggage deal with the good
side is all the sea libraries are pretty
much available for you Lee you have
dynamic nice i share a it's a Malik you
have the simple things like networking
you have threads those are things you I
don't need to invent like you don't have
to wait for me to implement that in the
language that they're already there in
Oblivion that's not the case yeah
and so I didn't get a question so you're
talking about having all the power see
available right that's in that sir both
no no both both even if you want to do
private computation but you want to
split it on many two threads that's okay
um we'll have to we'll need like a few
like five line wrappers around period
but it anybody can write it it you don't
have seen the compiler or anything it's
you can just have it yeah it's almost
nothing you need to do like the
synchronization primitives like mutex
the semaphores like huge library of all
these concurrency primitives that you
don't need to mean then you should be
able to just use whatever is already
there with some rappers but that's
something you can write it's they don't
require modification but yeah and your
tools like existing tools like profiling
tools see where you can program is slow
GCC profiling tools will work here you
have debugging tools there are eval
grind will work on this doggone it was
extremely useful here so things like
that does not have to reinvent it yeah
yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>