<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Path to Mobile HD-Audio Communication | Coder Coacher - Coaching Coders</title><meta content="The Path to Mobile HD-Audio Communication - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Path to Mobile HD-Audio Communication</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gRlw7ig3-MM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning everyone we're kind of past
the legal five minutes so I think we
should start it's a great pleasure for
me to introduce our visiting speaker
today professor peter vari and looking
at the audience and most probably at
knowing who is going eventually to watch
us online it is needless to tell who
professor various I will just finish the
introduction with his current job title
is the director of the Institute for
lymph rented the digital signal okay the
Institute of communication systems and
data processing in RT WTH aachen
university with without further ado
Peter you have the floor yeah thank you
very much even for inviting me and hello
to all of you it's now in 2013 20 years
then we had the first true digital
mobiles in commercial gsm networks and
one of the first mobile was the motorola
3200 i don't know how the name was
chosen but that was approximately the
price in Dodge mark and the weight was
500 and Eddie grams and during the first
years of GSM I would say the main focus
was on reducing the size and increasing
the talk time of the mobiles and in the
second ten years we saw that the
capacity computation capacity of the
Mobile's was increasing so much that we
could do other things just like having a
phone call we had the cameras we had the
calendar and they had the apps nowadays
it's not a mobile phone anymore or let
me say mainly it's a mobile
it's a mobile apps computer and the
price is not really what you pay in
Germany that's a matter of advertisement
of the companies but the weight is about
110 grams or reduction size and in
weight and the dramatic increase in
terms of complexity and capabilities and
now the question arises what can we do
to improve in the future and there are
different approaches one is I would say
the distinguished British approached by
the company virtue which is connected to
an Okie are very precious devices are an
alternative solution from an Austrian
designer jeweler the King's button
iphone but that's not what I would like
to talk about then I said we have now 20
years of mobile phones we have seen that
it's still a phone you can still use it
as a phone but you're in the last 10
years we have not seen too much progress
in terms of speech quality and that's
the topic of my talk the path towards
high definition telephony so let's see
what is high definition telefonia would
go through some issues like speech
coding as such and HD worries and
model-based bandwidth extension that
might be important keyword I will
address error correction and have some
ideas about a future step at the end
now we have the plain old telephone
system which is 22 history in the old
analog days the capacity of long whole
range transmission links required narrow
frequency band per channel and this is
why we have this old limitation to the
telephone bandwidth which is 300 Hertz
to 3.4 kilohertz and we know how to use
the telephone but actually the
intelligibility of syllables is only 91
% that is not too much and quite some
often we need a spelling alphabet on the
telephone because we don't get the right
syllables HD voice is at least 7 kilo
hertz but we include also the lower
frequencies down to 50 hertz the
technical term is white band but the
marketing people invented the term HD so
everyone understands what it is and here
we see the bandwidth which is increased
significantly but there's even more than
white band there's also super white band
up to 14 kilohertz so the low
frequencies increase naturalness and
comfort because the fundamental
frequency of speech is mostly not
transmitted on the telephone and if you
include that it sounds more natural and
you can distinguish between the daughter
and the mother on the telephone that
might sometimes be important the higher
frequencies contribute to clarity and
intelligibility and if we increase even
further we can improve brilliance and
quality of music
quite often only the minor part of the
speech spectrum is transmitted this is
the telephone band this is an unvoiced
sound and we see even more energies
beyond the telephone band and if we
include that in terms of white band or
HD coding we will significantly improve
the quality and the intelligibility of
syllables so we have these categories
narrowband white band super white band
sometimes it's called hd+ and full band
if that is needed or as a reference now
I would like to address speech coding or
more and more we are talking about
speech audio coding speech audio signal
processing and that for the time being
in the mobile phones we have pure speech
coding and the simplified explanation of
what is the mobile phone about is given
here there's a model of the speech
production mechanism of the vocal tract
we have the vocal folds and we have the
vocal tract and that can be described by
a model where we have a generator and
the filter time during filter and this
is what we see at the receiving end in
the mobile there is a the model of
speech production that is implemented
and over the air we transmit the
parameters which are needed to drive the
model and at the transmit side we
extract from the speech for model model
parameters so actually it's some kind of
naturally sounding vocoder what we are
using there but it is more and more a
mixture of parameter coding and waveform
coding but most important codecs we have
in the gsm mobiles is the very old full
red codec from 1988 it was very simple
and then we had improvement in terms of
technology the microelectronics became
more powerful and ten years later we
have what is called the adaptive
multi-rate codec and later on we have
had to
add the term and be narrow band so it's
telephone bandwidth for sampling rate is
8 kilohertz it's much more complex and
it has different bit rates it goes down
to four point seven five and the maximum
bitrate is 12.2 that is the codec which
is preferably used in the mobile phones
that's also called the enhanced full
right codec 12.2 kilobits per second and
it's based on the model of speech
production in terms of code excited
linear prediction we have here two
stages of the filter the vocal track the
vocal folds the gain and some excitation
generator which is a vector code book
and what is transmitted over the channel
is the vector address typically it is 40
samples that is 5 milliseconds again
factor that is filtered to produce 40
samples so that seems to be very simple
the secret is how to extract at the
transmit side the best vectors the gains
the coefficients such that we can code
it with a very low bit rate and still
get excellent quality at the receiving
end the motivation for designing the
adaptive multi-rate code egg was not to
improve the quality the motivation
behind that was usually we have a full
right channel in GSM that is 22.8
kilobits per second including source
coding and error protection and if we
can keep that rate and reduce the bit
rate for speech coding we can increase
the number of bits for arrow protection
that's what's happened with the mr codec
if you have a full rate codec the
bitrate is always 22.8 if the mobile is
outside we use the enhanced full
rhetoric highest bitrate highest quality
if a channel gets worse maybe that the
mobile is inside the building then we
the channel gets bad and the increased
dramatically the error protection and
have still reasonable quality
but the quality it will never be better
than if we use the highest bitrate so
the motivation and the objective of the
AMR narrowband codec is to save money
from the point of view of the operators
because if you would like to improve the
in-house coverage you could install more
base stations outside the building
inside the buildings so it's a
reasonable and a good solution at that
time to improve the service quality in
the mobile networks by introducing the
adaptive multi-rate codec and it can
switch very quickly between the
different bit rates every 40
milliseconds there's a half right
channel where the bitrate is just half
of that I will not go more into the
details now we have seen high definition
is at least seven kilohertz and there
are some examples like skype and I guess
this is the first time uses became aware
that telephone could be more than just
the telephone quality and there is voice
over IP the Opus codec I should adhere
the windows life messaging system and
errors and we see there is already
standardization very very long ago in
1985 we designed the first white pen
codec the ITU standard for ISDN it was
designed for ICN networks to increase
risk quality and now the patents are not
valid anymore and we see the first
products and one of the product is
called decked plus that's why the
digital cordless telephone and it is
used in combination with a sip protocol
over the internet but it's difficult to
use the normal normal customers I'm sure
will not use that because you have to
combine the telephone with a rotor and
to have
all software and you have to know
someone who has it so it's by far from
being the standard in the fixed network
so far then we have in the in the 3gpp
domain what is called the a.m our white
band that's the next standard adaptive
multi-rate white pant standard
interestingly was ready in two thousand
and one more than 12 years ago it was
designed at that time we had no 3rd
generation and no 4th generation it was
designed for gsm it could be used in GSM
it was never used in GSM and there are
some activities to introduce that in 3g
and in 4G mobile networks but they are
for some quite some while there are some
Mobile's on the market which have the
aim of white band and it is used but
only for ringing tones not for the
communication but that might change now
let's try to get some idea about the
quality this is narrowband quality the
Senate quality in GSM slow-cooked
hippopotamus in red wine a recipe for
special occasions provided that the
hippopotamus feels comfortable in red
wine no slow-cooked hippopotamus in red
wine a recipe for special occasions
provided that the hippopotamus feels
comfortable in red wine now a question
is well this is a significant
improvement but could we do more so it
does it make any sense to improve in
terms of bandwidth for speech so let's
listen to 7 kilo Hertz work bend slow
cooked hippopotamus in red wine a recipe
for special occasions slow cooked
hippopotamus in red wine a recipe for
special occasions provided that the
hippopotamus feels comfortable in red
wine and clearly the naturalness
increases into transparency even more
but we have not only speech we also have
music let's
to gsma music
so we could even in the mobile networks
transmit audio quality there are some
colleagues to do that and the bit rates
are such that we can transport them in
the 3g networks there is only packet
transmission in the 4G networks LTE we
have packet transmission so there would
be no problem to introduce that in
principle the objective of the mr white
pen codec is to increase quality and
intelligibility for the first time and
interestingly the bit rates go down
according to the AMR principle to 6.6
kilobits per second then it can be
filled up by error protection the
quality is not as good at 6.6 as at 24
kilobits per second
if you try to find out where in the
world is HD Voice you find the global
mobile suppliers Association and they
keep track of the announcements of the
operators and the the latest count is
that there is HD Voice launched or
announced in 61 mobile networks mostly
3g in 35 countries in the world if we
look to Germany it's not that clear they
have a pretty good coverage for 3g and
4g for two main operators it looks very
similar and all of them are saying we
have HD voice but if you go to the shop
no one can tell you how to use that
because it's partly installed in the
network and it's not everywhere because
we have different suppliers for the
infrastructure and it is obviously the
strong effort to implement HD visor and
the network in some countries we have it
life like in France in UK there are
several networks 3g networks which offer
HD voice and meanwhile we have plenty of
mobile devices which can do that and
this causes the next problem interesting
problem for speech processing community
if we install HD voice in the network we
have to modify quite a lot to give you
an example a German wide coverage of GSM
requires about 19,000 base stations and
if you install such a new codec you need
a new speech codec and you need a new
channel codec in the mobiles that's not
an issue because you buy a new mobile
but the base station is there and you
just need a software update at the base
station but it's like with the pcs if
you ever try to update your PC which is
10 years old
to install the latest software that
might be some problems so it's more than
trivial to introduce HD voice in the
network because you need a lot of
modifications and protocols the coding
part is installed in the mobile
switching Center you don't have so many
that's not so critical about the base
stations is to a point and if you have
done that you have two separate worlds
the customer buys a new mobile and he
knows hopefully a few friends who also
have the HD service but there is no
cross connection in terms of quality
between a narrow band and the white band
terminal and it will take quite a very
very long time until or if ever the
whole telephone network has been
converted to HD voice and then we can
study all kinds of interconnections
between HD and narrow band Mobile's over
HD and narrow band networks for example
to such a guy who has the new HD mobile
phone so if he is happy we have the
complete chain in HD but if the user at
the other end is narrow band he gets
only narrow band quality even if the
user here is connected by a 3g network
that could be 3g LTE that could be gsm
then it can take the profit of the HD
capabilities because it transmits only
narrowband noise and narrow behind the
speech then it might be that the HD
terminal connect is connected to a
narrow band network then they also have
only narrowband quality and so we have
different solutions now I would like to
study these cases the case a is the
happy case where we use the AMR white
band codec or the amyl white band plus
codec
then in this situation we try to improve
we could try to improve by the keyword
is now bandwidth extension we transmit
to adjust the narrowband signal and in
the mobile we try to exploit the model
of speech production and some
characteristics of the human ear to
artificially increase the quality
eventually the intelligibility from an
information theoretical point of view
that's very questionable but we have
here a specific source and we have a
model and they can do something I will
demonstrate that if the mobile the
narrowband mobile is connected via the
3g network we could also implement this
artificial bandwidth extension in the
network therefore I say I'm saying it's
two cases b1 and b2 doesn't make a big
difference the question is where is the
processing power if we have only the
narrowband network but two HD terminals
it seems to be that you can do nothing
but we can do something if we succeed to
transmit in a compatible way side
information for artificial bandwidth
extension well we could use as in the
first case be one artificial bandwidth
extension at the receiving end but the
quality improvement is limited as soon
as we can transmit additional site
information which drives with bandwidth
extension the quality becomes much more
better some of the Codex have the
element of artificial wideband extension
as part of the standard already so the
idea is the narrowband network let's say
transports only PCM or an AMR narrowband
codec and we embed some information we
will see how to do that and we try to do
that in the compatible way such that a
narrowband terminal gets narrow band
quality and will not be disturbed by the
embedded in form
which can be used by the HD terminal to
expand the bandwidth the first case just
receiver based that was scenario b1 or
b2 where event with extension is in the
network it tries to estimate some
characteristics of the speech and to
expand the speech artificially it's a
mixture of speech recognition of
estimation and speech synthesis and in
listening tests I can tell you the
listeners clearly prefer artificial
boundary extension and in certain
occasions of you have background noise a
dividend rate extension even increase
intelligibility one approach of my
former PhD student parallax was purely
based on linear predictive coding what
we are doing here we receive a
narrowband speech let's say that's
already decoded it's PCM and the first
step is to interpolate from a 2 16
kilohertz then we apply a pattern
recognition approach where we extract
some features we have a statistical
model the goal is to estimate the
spectral envelope of the wideband speech
so at the end the wipe and speech will
be reconstructed by applying a wideband
synthesis filter and the goal is to
estimate from parameters which are
extracted from the narrowband signal the
envelope of the wideband signal and it
uses a codebook the codebook could be
for example just the LPC the RV lsf
quantization codebook for the LPC
information it uses verizon bias
estimation and what we get is the LPC or
reflection coefficients or capsule
coefficients of the white band filter
and we apply the analysis filter to the
oversampled narrow band speech what we
get is the oversample residual signal
and if the signal was
limited to 3.4 kilohertz the residual
will also be limited to 3.4 kilohertz if
the prediction goes quite well and let's
say if the voice was unvoiced we have a
flat noise spectrum I'm up to 3.4
kilohertz but we need it up to 70 loads
so it's it's not too difficult to
imagine how to expand the narrowband
flat noise too nervous to a wider flat
noise just by spectral replication or
spectral the translation if the speech
is voiced then we have here and narrow
banded harmonic narrowband noise with
more or less constant spectral
components it has a harmonic structure
and it's not too difficult to imagine
how to expand that to a wideband
excitation by spectral repetition
folding modulation whatsoever I can tell
you the extension of the excitation
signal is very easy and it's not
critical at all the art or ventev
extension is how to estimate the
envelope and then we can apply this
wideband excitation to wipe and
synthesis filter and get hopefully
decent quality so this is a little bit
about the theory you get some idea that
is pattern recognition and the
conditional estimation I will not go
through the details and would like to
play one example what we see here is a
spectrum and the it switches between
narrow band and the artificially
extended signal well three or four
months run along and it was well into
the winner now I had been to school most
all the time and could spell and read
and write just a little and could say
the multiplication table up to 6 times 7
is 35 and I don't reckon I could ever
get any further than that if I was to
live for
her I don't take no stock in mathematics
anyway so the quality is significantly
better and if there is some background
noise tests indicate that even the
intelligibility is increased the second
approach for artificial wipe and
extension is to embed information to
hide information in a compatible way in
the bitstream that works with scenario
see and we will see it two different
versions how to implement that we add
some site information so we transmit a
narrowband bit stream or narrowband
speech samples over a narrowband
telephone network the normal narrowband
terminal should not be confused by this
hidden information and the bit for Matt
to stream the frames and all that should
be the same as before or let me say at
least according to the specified formats
and the HD terminal could extract the
hidden information to do much better
bandwidth extension with the transmitted
side information no increase of the
bitrate no modification of a bit stream
format and I would like to discuss this
with an alternative version how to
expand the bandwidth the first one was
to use purely LPC based techniques LPC
analysis filter expansion and synthesis
the second one is to split to the signal
with wideband signal into a lower and an
upper band so its up end processing we
need not to do anything with a low pass
band but we try to recent a size at the
receiver the upper band the high band
from 4 to 7 or 8 kilohertz but the
bitstream is according to narrow band
signal what we have here is the basement
let's say the aim our narrowband codec
at 12.2 kilobits per second we get the
narrowband signal its sample at 8
kilohertz we have the filter Bank a two
channel filter Bank which does the
interpolation job to obtain the enhanced
signal sample at 16 kilohertz and here's
the extension band synthesis and first
approach is to hide data by watermarking
techniques of steganography in the bit
stream for example 2 kilobits per second
that's quite a lot but we don't need so
much for white band extension or not not
much more to extract some parameters to
do he have the bandwidth extension and I
would like to explain that once more
using the MMR codec the simplified block
diagram here the vector code book the
gain factors and this filter which has
two stages as we have seen before but
the point is to exploit the properties
of the vector code book or the vector
search without going too far into the
details I can say that at the transmit
side finding the best vector is done by
procedure which is code excited linear
prediction or which is called analysis
by synthesis or you could also say trial
and error because you'll try out which
is the best excitation and there are
many many different approaches how to
design a codebook and there are few
approaches how to design a search
procedure in a code book which is let me
say specified by the street kind search
it's not it is not a code book which is
stored but it's constructed iteratively
by some search procedure and this is the
optimization criterion ageism matrix
where they have the impulse response of
the synthesis filter
the vectors have a length of 40 that is
5 milliseconds and this has to be
optimized and in the standards there is
for complexity reasons and non
exhaustive search because in any case
the code books are very very sparse the
dimension is 40 and typically the number
of code book entries is 10 to the 2 to
the power of 10 1000 roughly here the
dimensions is only 2 and in the code
book we have here obviously only four
entries to explain the principle so as
far as code book and the first idea for
you to use watermarking techniques could
be to split the code book into two key
different code books no that's too first
a code book to use yeah
to split the code book such that we
let's say use the green code book either
or the red code book we just separate
into code books and the hidden
information is one bit if you use the
green one the bit is zero and if we use
the red one the code of a bit is one and
the receiver can find out which entries
have been used and he knows the
information which has been transmitted
the disadvantage is that the
quantization error increases because we
have reduced the size of the code book
but as the code book is that sparse we
can invent a second code book of the
same size and then we have no loss in
terms of quantization errors and the
receiver knows if the red of a green
book is used which bit is transmitted
which polarity or sign of the bit is
transmitted now and this can be
implemented in a modified non exhaustive
search because if we study the AMR codec
we see there are at least 1,000
possibilities to specify a codebook of
size 1000 1000 or let me say two to the
power of ten means we can hide 10 bits
in the code book address of a vector of
length 40 and as 40 samples is 5
milliseconds that is to kilobits per
second so this information is used to to
drive the banquet extension at the
receiver and here it's very the serpent
approach the high band signal is here
produced by controlling the time
envelope by controlling the frequency
envelope by controlling the excitation
generator which produces noise or some
periodic signal and the bit stream is
extracted in the decoder in the part
where the code book address is decoded
to find out is it the red or green so we
have 1024 different colors and the color
says which is
the ten bits which are just transmitted
so I explained that already and let's
study some example this is narrowband
speech and this is extended speech with
the side information of 1.65 kilobits
per second we have taken this because
this was as indicated somewhere became
part of the standard of the extension of
the g 729 dot 1 codec their bank geyser
designed this the solution and bush
including channel coding to kilobits per
second the bandwidth is extended from
narrowband to white band and he used
that module to expand the AMR codec but
hiding the bitstream in a compatible way
now let's listen to one example the
first test is to which extent gets a
conventional mobile narrowband mobile
confused or disturbed do the listeners
recognize that there is something which
has been modified in the background he
suffered terribly from a speech defect
he suffered terribly from a speech
defect faulty installation can be blamed
for this faulty installation can be
blamed for this and actually you don't
recognize the modifications only the
very experienced listeners sometimes can
distinguish there might be something
different so it would be allowed to do
that and then we can embed the two
kilobits in the vid stream of the MMR
codec and we can compare the narrowband
receive terminal and the wideband
receiving terminal in terms of quality
to administer medicine to animals if we
could clear very difficult matter and
the end sometimes it never very to do so
to administer medicine to animals is
frequently a very difficult matter and
the end sometimes it's necessary to do
so and that sounds much better or
significantly better than
they artificially expanded signal where
we don't have site information at all
but the drawback of that solution is we
have to transmit the bitstream as it is
as soon as we have transcoding in
between let's say a call from a mobile
to a different network and if there is
PCM for example in between the hidden
information gets lost but if the
transmission is tandem free which is one
of the options in GSM then it would work
and the nice idea would be the operator
just has to sell to two people to mobile
phones without modifying the network at
all if they are in the same network they
would from the very first usage of a
telephone have white mint quality but
there is a second solution and the
second solution is to avoid this tandem
problem and to hide the signal in the
samples not in the bitstream and the
idea is just the following here we have
the white band spectrum and we take the
spectrum from from from four kilohertz
to 6.4 for a certain reason and we
compress this and place this in the gap
between three point four and four kilo
Hertz if you have a narrow band signal
and if you have clean telephone LAN
passes the stop band frequency of the
band pairs is 3.4 kilohertz between
three point four and four we can
transmit something else so in-band
signaling but in band compressed
transmission of the frequencies here if
it is a periodic it will be compressed
and you could also say it's pitch
scaling or spectral compression
and we do that in the frequency domain
the detailed solution will be explained
next week by Ben geyser at the I casp
the processing is based on DFT domain we
have first analyses with a large window
and the second analysis of a high band
signal oh sorry first of all we split
with cigna into a high band and into a
lobe and if we decimate the sample rate
from 16 to eight kilohertz and then we
have here short analysis and here a
longer analysis and they inject this
spectrum in the high band we do
resynthesis and there's more windowing
and overlap to obtain what band speech
this is the wideband signal we clearly
see that there is a lot of energy here
especially in unvoiced sounds and there
is less energy in the voiced regions so
if we do compression here and it is more
or less noise like we can expect it's
not so critical because we don't have
too many harmonics here this is the high
band we take this and we compress it and
place it in the range between three
point four and four I said we take the
high band from four to six point four
and decompress it by a factor of four so
we can replace it here in this gap which
has a width of the six hundred Hertz
this is the narrowband signal where we
did not apply that we did not apply the
telephone bandpass you see in the true
speech it goes up to here but you here
would be the 3.4 kilohertz limit here
and we will replace this as you see and
it looks different I go back and forth
it looks different but even if you
listen to that it doesn't sound too too
disturbing
oak is strong and also gives shade cats
and dogs each hate the other but the
normal terminal would have some
telephone bandpass it would not allow to
offer these components to the user but
what we see is the insertion of the
fricative sounds this is a comparison of
the reconstructed white band
approximation and the original wideband
signal the original wipe and signal does
not have here a gap between three point
four and four kilo hertz so that's the
true wideband the narrowband signal has
a gap because there's a cutoff frequency
at 3.4 kilohertz and we replace the high
band here and the gap does not is not
annoying at all we know that from
different codecs that you will not hear
the gap and therefore we can expect good
quality so let's listen to be extended
oak is strong and also gives shade cats
and dogs each hate the other and the
uncoated and dogs each hate the other oh
sorry I repeat it once more because oak
is strong and also gives shade cats and
dogs each hate the other oak is strong
and also gives shade cats and dogs each
hate the other it might be that you can
recognize slight differences but usually
you don't have the a/b comparison and
the quality is pretty good now we have
different options to improve the quality
in the networks by coding better source
coding compression hiding information
whatsoever but then we have a
transmission channel with arrows
the question is can we keep the quality
even if you have bit errors so we have
to study the bit error sensitivities and
maybe we have to use all the tricks
which are known from channel coding and
one interesting solution is doable
coding because you can just apply that
we receive side and the very special
interesting solution is we call that
turbo error concealment so that is the
idea of turbo coating applied to a
channel decoder and the source to code
usually a turbo decoder has two
component decoders one helps we ever in
an iterative procedure and this concept
can be applied to a channel decoder and
the source Dakota or let me say
parameter decoder I will explain that
this is the transmission model we have
at the transmit side we extract some
parameters let's say any codec we have
channel coding we have modulation and
transmission and at receive end we have
a soft in soft output channel decoder no
real turbo decoder so far but just soft
in soft out it's a component of absorber
Dakota because it can accept extrinsic
information extrinsic information means
what do the other bids know about me as
a bit the processing is as follows the
soft our channel decoder produces bits
and it produces reliabilities
reliability is saying would be which is
the probability that a bit here is one
is right or wrong and usually it's a
described by the log likelihood values
and then we calculate here also called a
posteriori probabilities not on bit
level but on parameter level because
what we extracted here is parameters LPC
coefficients vector addresses gain
factors and these still have some
redundancy if you study the first LPC
coefficient in a sequence you will see
there
clearly correlation if you study the
prediction signal of a predictive coder
and even if you have perfect prediction
you would say well the output is white
noise even in white noise we have still
redundancy because the white noise even
if it has no correlation has a certain
distribution usually Gaussian
distribution and that is still
redundancy redundancy on the level of
the samples or on the level of the
parameters and this is extracted here in
this block this simple equation
describes at the end what what happens
we calculate a posteriori probabilities
we give something back on bit level I
will explain that on the next slide so
there is some iteration between the soft
channel decoder and the first block of
the soft decision source decoder and
after stopping the iterations we know
the best a pre a posteriori
probabilities so that means we have
let's say a parameter V and the
parameter V might be transported by free
bits so if it is free bits we have eight
possibilities at the transmitter there
is a quantization table if it is scalar
quantization with eight entries so these
are the entries in the codebook and
these are the eight a posteriori
probabilities which you have found after
iterating here so we have received three
bits and we are interested in the
probability if X let's say group a free
bit is fixed which is the probability of
over first or second preferred entry
number eight and then we do conditional
estimation in terms of minimizing the
mean squared estimation error and it
turns out we just have to multiply the
code book entries with their a
posteriori probabilities if the
transmission is perfect if there is no
bit error anymore because the channel
decoder has repaired all the bit errors
then only one of these probabilities
will be
and all the others will be zero so the
summation does just the table lookup and
is exactly a compatible with a standard
if the transmission is completely
disturbed let's say only random bits
then it will turn out that the Apostle
Yuri probabilities have all the same
value 1 over Q or 1 over 8 and what we
get is the average of the code book
entries and if that was with parameter
with a sign and a symmetrical
distribution we ever it will be 0 so we
have graceful degradation so that
improves significantly the quality by
exploiting residual redundancy on the
parameter level that is the distribution
and the correlation of parameters and
from that we can feedback extrinsic
information on bit level to the sauce
decoder let's assume we have a situation
with three bits and the channel decoder
head finds out that bit number 2 and 3
are 0 and 1 or should be 0 and 1 in one
iteration and the channel decoder asks
the source decoder what do you think
about bit number one the source Dakota
says where these free bits are belonging
to a parameter which has a certain
distribution which is known and we know
of the bit assignment in the
quantization table so if you bitten 2
and 3 are 0 and 1 we have two
possibilities obviously that your first
bit is one or zero but this probability
is larger than this here and then we can
take the quotient and the logarithm and
this is a language with channel Dakota
understands that so log likelihood value
which is fed back to the channel decoder
and in this way we do it erations across
the channel and the sauce decoder and
the improvements are quite impressive
this is tape lookup decoding this is
source decoding if we rate over the
channel quality as a quality measure the
parameter is an
not the speech or audio SNR we take the
parameter SNR of a gain factor of a
parameter as an hour of an LPC
coefficient and if you do the iterations
we come very close to the theoretical
limits using the turbo like process
applied to channel and source decoding
one example let's take speech one
iteration means actually no iteration we
just won't have one pass through the
decoder two iterations to further his
prestige he occasionally reads the Wall
Street Journal to further his prestige
he occasionally reads the Wall Street
Journal to further his prestige he
occasionally reads the Wall Street
Journal or let's listen to music
you
yeah so we let me say have solve the
problem we have good codecs we have good
ideas to hide information that we have
very powerful channel decoders then the
question is what might be next the next
step well this is just the one statement
it could be binaural telephony and then
we would need stereo headsets steer your
coding and transmission and you might
ask what is is it good for one situation
I think you could imagine is you would
not like or you cannot travel to a
meeting and you would like to
participate in the meeting such that in
the meeting instead of you there is a
dummy head or at least two microphones
and we have to channel transmission and
you are in the environment be with the
mobile and you can listen at get spatial
information and for example the
environment a would be the meeting room
at the airport and the environment be is
at the beach for example and we have
produced a nice demo and you see it
makes a really fun to participate in
such a binaural audio conference if you
listen to of that here by headphones you
get some idea which information you
transmit I would say it's just the
opposite philosophy of what we are doing
today today we try to suppress the
background in the background noise and
the acoustic atmosphere here we do the
opposite and we transmit it but the
audio bandage is more than just
telephone bandwidth and it makes really
fun if you apply that to groups in that
case we have a group a and it will be
and only in each group one has a master
headset with two microphones and all the
others have three the headphones the
connection here might be vilas and then
you everyone can talk to everyone
even maybe you attended our demo at the
last I bank it's very amazing you look
to the left and CEO he's not here in my
room he's somewhere else and this might
get a great acceptance not only for the
professional application of the audio
conference but even for groups of young
people now my conclusions is that mobile
phones will i would say hopefully
surpass the speech quality of fixed line
telephones because all the ingredients
are there to improve the quality we have
the standards and the networks provide
sufficient capacity to transmit that and
it will become easier to introduce new
codex because in the 3g and 4g networks
there is no dedicated speech
transmission mode because it's just
packet transmission and then it will be
much easier but nevertheless even in the
new world of the 4g networks we still
have the old fashioned old telephone
network and we have interaction of new
and old mobile phones and then we have
the compatibility problem even if it
seems to be that in quite a lot of
networks we there is HD voice on the
move i would say you have to distinguish
between announcement and real public use
but then we will see the discrepancy
between narrowband and white band and in
that situation bandwidth extension might
help to improve the user acceptance
someone who is buying a new mobile phone
can get some improvement from the very
beginning independent of the situation
which is in the connection presently and
it could bridge the gap between
narrowband and HD and that could be
improved significantly if we hide
information if we do with transmission
in a competitive way let me say over a
GSM more oh um test Network eventually
Justin
latest proposal to do frequency
compression and my impression is that
could be a shortcut shortcut to HD
mobile telephony and but the real step
could be the future binaural HD
telephony as close as being there yeah
that's the end of my talk but i would
like to cite some ideas to statements
about what is HD there is one of an
analyst he says the expectation for
quality in the public on cell phones is
so low people say it's good enough but
there's on the other side the mobile
manufacturer peter iceberg he said it
will be the most significant quality
upgrade in telephone history and i
expect it will be something in between
but hopefully much closer to the most
important quality upgrade thank you very
much you tried some of the young
those demonstrations with the artificial
the bandwidth extension in different
signal-to-noise ratios and different
voice yeah settings have those curious
to hear if we have a demo how it
actually sounds in 16 years yeah I can
tell you it's it's not as good we are
working on that and the first idea is
what should we do should we first
suppress the noise pre-processing or
should we imply the noise suppression in
the parameter estimation so it's like in
speech recognition and it it looks like
we should first of all try to get rid of
the background noise and then it works
quite good then your next question might
be what's about music yeah it's not that
that good if you have music there and
music in the background then the pure
artificial bandage extension does not
perform that well but if he can transmit
side information it's like a codec which
spends not too many bits for the higher
frequency band and we know that the ear
is not that insensitive there
other question is okay from the moment
you switch from the traditional
transportation to the deep you digital
besides having arrows in the bits of
your transmitted data which is less
common in the digital networks but then
you will face packet drops or packets
arriving too late hmm and how eventually
this is going to resolve to keep the
quality I even in certain I can drop
rate yeah the steganography transmission
is not limited to buy a bandwidth
extension you could use the capacity of
two kilobits per second for example to
transmit any information and one
interesting solution is to support
packet substitution to have redundant
transmission one of my student made some
investigations in that direction that
really helps to improve packet but then
packet error concealment but then we
have spent this information we will not
use it for wideband what buddy goes
further and from vibrant we can extend
to super wide band and we have some
capacity which could be used for packet
arrow concealment
basic question them when with the alien
archaic there are significant artifacts
introduced by the code of yourself
presumably the presence of these
artifacts has the effect of concealing
other problems like chattel errors or
poorly placed microphone or a fully
designed microphone and then as we go to
HD voice those artifacts going to be
reduced and the user made them become
more aware and other problems like a
boarding place microphone in chatham
only do you have some insight as to how
the users of ways to go to change and
how the irritation of other artifacts
that used to be insignificant they have
become small or more detectable yeah
that's a very interesting question and
let me say if you are in a video
conference video audio conference and
one subscriber comes by Auto telephone
you clearly significant difference
between and hear the difference between
the audio quality of of a subscriber a
and the telephone quality of a
subscriber be but you need not to have
such a complicated translations in a
normal telephone conference which we
have almost every day are quite often we
experience what is happening in the
telephone network during the last 10
years the telephone quality is not
getting better it's getting worse and
you you know the people which are on the
phone personally and you clearly find
out oh that's probably a mobile and
that's a terrible and speaking mobile
phone and that's a terrible desk
telephone in the office room you hear
the reverberation I expect that the
users are really aware of the
degradation and that we should do
something and that should be applied to
the whole chain and it starts in at the
acoustic front end you address the
microphones and the frequency responses
so we should improve that we should not
make them cheaper but I'm realistic I
know we cannot replace all the devices
we
if they're so we should try to improve
by intelligent signal processing let me
say intelligent equalization at the
receiving end are better pre-processing
of a digital signal I expect there is a
lot room for improvement even if we have
their an AMR codec in between yeah but I
think this is very interesting the
question for the near future questions
for a super bendy that would be
additionally improvement but I think
what we found is that if you only a cell
phone like that the microphone is so far
away from him
frequencies of
the ER we are we have to distinguish
between at least three different modes
of usage that is the normal handset mode
then we have the hands-free mode and
then we have the headset mode and
presumably you will not get the all the
improvements in each mode if you have
the headset you clearly will get this
improvement or if you have a audio
conference situation with big loud
speakers so that would be at least a
third fourth one
a few years back there were studies
about artificial white back extension
but user fatigue and so sometimes you
hear the first time it's impressive
something's there that wasn't but if you
keep using it over the time you may
change your opinion you may actually
prefer a clean narrow band versus you
know artificially something I'm not
referring to the case where you embed
information with that extension is
actually intelligent to design but you
have any comments on that yeah there's a
big big test it emerged from the list
our project and ballista workshop last
year and there was a common effort to
make a very deep comparison of different
approaches of artificial bandwidth
extension and the results are very
encouraging if you would like to know
more details about that I could send you
of the paper I don't have in mind where
it was published it is out meanwhile
let's think again L speak up</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>