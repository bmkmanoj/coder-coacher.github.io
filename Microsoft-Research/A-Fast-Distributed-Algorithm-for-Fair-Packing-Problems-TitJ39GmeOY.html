<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A Fast Distributed Algorithm for α-Fair Packing Problems | Coder Coacher - Coaching Coders</title><meta content="A Fast Distributed Algorithm for α-Fair Packing Problems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>A Fast Distributed Algorithm for α-Fair Packing Problems</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/TitJ39GmeOY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi everyone now it's my treat
it's my pleasure to welcome Alena
Manischewitz from Columbia University
who's worked on fair packing problems
and fast suited algorithms thank you for
the introduction so I am a PhD student
at Columbia University this is a joint
work with cliff Stein and gills this
month the work is on auto fare resource
allocation and I will explain very soon
relatives but let's start first with
some applications when it comes to fair
resource allocation the most well known
problems are those coming from network
congestion control or network rate
control and indeed this is where
fairness problems have been really
mostly studied but there are many other
applications where we could care about
fairness more recently there are
problems in resource management and
resource allocation in data centers you
can pose almost any operations research
problem as a also fair resource
allocation problem I'm showing care
health care scheduling but there also
other instances of problems like air
traffic control or allocation of
cadaveric organs etc one instance where
fairness problems arise that is not it
did not really immediately clear that
there exists a connection our market
equilibria problems and I will actually
make this relationship more clear as we
get towards the end of the talk so let
me start with the one example of this
where we can care about fairness to a
different extent so this is a very
classical example that is very often
used in classes and communication
networks so this
thing is we have one very long path that
uses n minus-1 capacitated links and we
have n minus one short that's shown here
in orange that use only one capacitated
link and each link has a unit capacity
the question we want to ask is how do we
allocate flows in this network how do we
allocate rates to this routes now one
thing is that if we're doing anything
reasonable we would give the same rate
to each of the short routes because they
just see the same constraints they see
the same Kadesh conditions now one
objective we may want to have is just to
maximize efficiency in this case
efficiency means maximize the sum
throughput so take the most out of the
network if we were to do that then we
would give zero units of flow to the
long route and one you need to flow to
each of the short routes this gives us n
minus one efficiency but it is very
unfair especially if the long route user
was actually paying something to get
something sent through this network on
the other end if we really want it to be
as fair as possible one thing that is
not too difficult to see is that in that
case we would just give everyone half a
unit to flow but what happens in this
case to our efficiency is that we have
lowered it down by a factor of about to
be a little bit vague right now but you
can see here that you're actually using
all the links here to the maximum extent
and you are giving everyone equal amount
to flow the third type of objective we
can think of this okay you know like if
we are very fair efficiency goes down if
we are very unfair efficiency is better
so maybe we
want to look at some trade-off and
intuitively the long route is using too
many links it uses too many resources so
maybe they should get something
proportional to what they use so in that
case we we could assign one over n units
of flow to the long route and minus one
over and you need to flow to the short
routes and our efficiency would actually
be at least asymptotically close to the
maximum efficiency now if we were to
somehow parameterize fairness on a scale
from zero to infinity then talking about
the previous problems that I shown you
the first problem should really get zero
because it had no fairness guarantees
the second allocation should be
somewhere in the affinity because it was
as fair as possible and the third one
should be somewhere in the middle all
right so this is just like intuitively
speaking the questions of measuring
fairness or measuring inequality are
actually not very new back in 1970s
there were questions asked about
measuring inequality but in terms of
inequalities of income distributions so
the problem there was to rank different
income distributions and the parameter
alpha was called inequality aversion
parameter the functions that appear in
this type of work are a little bit
curious and I'll tell you why on the
next slide so 30 years fast forward in
the domain of network congestion control
there is a definition of alpha fairness
what is nice about this definition is
the lemma that says that there exists a
family of concave objectives that we can
maximize and actually reach this alpha
fair resource allocation
now these functions are the same
functions as I shown you in the last
slide they may not be very easy to
remember so the way to think about them
is as functions whose derivative is 1
over X to the Alpha so a very high-level
intuition is that as X goes to 0 the
derivative goes to infinity so you
really want to push all the locations
away from 0 and as alpha gets larger you
really push the allocations away from 0
to larger extent now for the three
examples that I mentioned in the
beginning the first example is actually
the case of alpha equals 0 it is called
utilitarian in this case we only have
linear objectives the second case is
known as maximum fare allocation which
is the most egalitarian
way of allocating resources and the
third example is known as proportional
fairness and it happens when alpha
equals 1 now the intuition about trading
off efficiency and fairness is not only
an intuition there has actually been
work in the last couple of years that
quantifies this trade-off under
different metrics the problem that this
talk is about is also fair packing it is
a class of problems where the feasible
region is a polytope determined by
positive linear constraints now the
problems with such feasible region have
been really extensively studied for
linear objectives but not as much as
least not with the convergence
guarantees for this more general
objectives these objective functions are
concave so in centralized manner we know
how to solve this in polynomial time the
focus of this talk is to look into
distributed algorithms that have a
synchronous
updates so this is something that arises
very often in in practice and even if we
didn't have a really distributed setting
we could parallel eyes computation and
get really fast algorithms yes
so when alpha is zero actually did this
with a plaintiff maximizing the sum of
the laws not the Sun but what all people
zero when alpha equals one there yes
you're maximizing the sum of the logs
zero is the linear objective yes okay so
the main result that I will talk about
is an epsilon approximation algorithm
that is very robust it has many nice
properties so it can run in a
distributed fashion it allows a
synchronous updates it only reacts to
the current state of the network
it makes local updates it can start from
any initial state which also means that
it is fault tolerant and it can it can
allow for a constant number of variables
and constraints insertions or deletions
the convergence time of the algorithm is
poly logarithmic in the input size and
polynomial in the accuracy parameter
Epsilon I will tell you more precisely
what the actual convergence time means
later after I introduce some notation
what I should point out here is that
this is probably a synthetically that
the dependence you should expect for
this type of algorithms because at least
for linear programming in this setting
there are lower bounds looking at the
related work when it comes to maximum
fairness there has been really a lot of
work but one thing to note here is that
when we have maximum fairness
these problems are not anymore really
convex optimization problem what we get
is a multi objective problem where we
are looking at the whole vector and
these problems typically have more
combinatorial structure at the other end
of our alpha line there is work on
packing linear programs most relevant to
this talk is to work by our book and
conduct car but of course if we have
linear programming we can only support
linear objectives there is no
straightforward extension of these
results to the alpha fair setting in
terms of work on network congestion
control there has been a lot of work in
the last almost 20 years most relevant
to this talk is work by Kelly what is
interesting about this line of work
there is no guaranteed convergence time
as a function of input so the
convergence time that is shown for these
algorithms
they're usually continuous time
algorithms is that you reach the
solution you reach the optimal solution
after some finite time but there is no
guarantee that this happens in
polynomial time as a function of input
more recently there has been work on
network utility maximization this work
can solve the the problem I talked about
after some scaling but in general leads
to convergence time that is at least
linear in the input if not even
polynomial talking to Nikhil we have
actually observed that one of the cases
actually also equals one is equivalent
to the problem of market equilibrium in
ITIL markets with Leon T of utilities
and there has been a work from stock
2013 what we have observed there is that
the dependence on epsilon of this type
of algorithm is better than this work
but the dependence on input is worse so
it is at least linear whereas here it is
poly logarithmic so I will move now
you talking about model and in some of
the preliminaries so first of all this
just makes the analysis easier it's a
very standard thing to do in linear
programming just to scale all the
constraints how do you scale them so
first you divide both side of each
constraints by the right hand side to
get one on the right hand side you
divide all the constraint matrix
elements by the minimum element by the
minimum nonzero element and you scale
all the variables but by the same amount
what you get when you do that is that
actually in the scale problem any
nonzero entry of the matrix is at least
one what does give you is that for any
feasible solution your variables must be
between 0 &amp;amp; 1
does everyone see this right ok why can
we do this we actually showed that this
preserves the approximation guarantees
so if you want to scale back you will
have the same approximation guarantees
and the scaling is really just for the
purpose of the analysis the algorithm
can be around on the original instance
objective as well as the constraints so
the what I will show later is that when
algorithm runs the constraints never get
violated unless they were initially
violated but after Polliwog number of
rounds they are always satisfied what I
mean is that the guarantee on the
objective function is the same so if
multiplicative you get the same
multiplicative if additive you get the
same additive the model of distributed
computation I will talk here in terms of
sellers and buyers just for people who
have worked in some market problems to
be easier to just capture the main idea
so for every
variable we say that there is a note
associated with that variable and we can
call it a buyer for each constraint
there is also a note and we can call it
a seller now between variable and the
constraint there is an edge if a
variable participates in that constraint
if it has a nonzero coefficient so we
add edges for such pairs and add a
coefficient over an edge equal to the
coefficient with which this variable
appears in the corresponding constraint
the type of information that nodes have
is every buyer every what we need on the
variable side we need upper bounds on
the global information the information
that is collected in each round is the
the price of the constraint variables so
it would actually be enough just to
collect the relative congestion so the
variables collect information only from
those constraints in which they
participate they don't need global
information for the constraint our
seller sets a price that is the function
of the global problem parameters and of
the relative slack or relative
congestion I'm calling it relative in
the non scale problem it would be
relative here it is just an absolute
slack it is this model clear so if we
were in network congestion control
problems what this would mean is that we
would need to in each round each node
would need to collect the relative
congestion on each of the links it uses
on their path important for the analyses
are actually KKT conditions so just to
get clear what what the net
SHINee's with each constraint we will
associate Lagrange multiplier that I
will just refer to its dual variable so
if you write the KKT conditions they're
just the standard thing you have primal
feasibility dual feasibility
complementary slackness and the fourth
condition you get when you maximize the
Lagrangian this fourth KKT condition
will actually be the most important one
for the algorithm so let me tell you
what the algorithm is but before I get
there I want to give you some intuition
so I'm writing at the top the KKT
condition that I said would be the most
important one so there are two
algorithms that seemingly won't look so
similar on the left is the algorithm by
Cali at all from 1998 it is for a
particular instance of alpha fairness it
is for alpha equals 1 known as
proportional fairness the algorithm is a
continuous-time algorithm how it works
you describe all the updates in the
network by a system of differential
equations one thing to notice here is
that the updates of the primals of the
variables are actually guided by any
slack in this KKT condition the dual
variables are chosen as some unspecified
monotonically increasing function of the
so for for a dual variable I it is the
left-hand side of the constraint I in
linear programming we need some proper
initialization we start with some
feasible solution and this algorithm
actually has discrete updates what
happens in each round is that the dual
variable is set as exponential function
of this relative slack of the
corresponding constants
and then what algorithm does
whenever the KKT condition and the top
is not satisfied
it makes multiplicative updates to get
closer to making it satisfied this is
not completely multiplicative because
there is a step increase Delta FX J's
are very small because if they're zero
we wouldn't be making any progress or
when there is a decrease that there is a
multiplicative so how the convergence of
these two algorithms was shown and for
the first one that there is no really
dependency on the input size it's just a
finite time convergence a certain
potential function was used called the
Lyapunov function it's just a bounded
monotonically increasing function if you
look at the potential function for the
linear programming the first term looks
similar in the second term not so much
now in linear programming it is quite
standard to choose dual variables as
exponential function of this constraint
slack if you use a similar idea for
alpha equals one here if you choose an
exponential function here and you plug
this into the potential function you get
the function of the same form so this
was one of the first observations that
we made when we started working on this
problem and this somehow gave us the
intuition that we can get good
convergence with discrete updates with
something that looks similar to the
linear programming algorithm now the
algorithm is indeed very similar to the
linear programming algorithm we don't
need a real initialization we only need
to restrict each variable to some domain
between Delta J and one so if a variable
for any reason
outside of this domain we just put it
back the choice of the duel is only
slightly different we have some C in
front of the exponent one difference
that does not seem so important really
is that when we make a decrease it is
not always it is not always
multiplicative because we are setting
this lower threshold we may be making a
decrease that is smaller than
multiplicative whereas in linear
programming it resolve it as at least as
large as multiplicative so this actually
raises one challenge in the analysis one
thing just to notice here for a linear
programming the variables are always
between 0 and 1 in the algorithm here
they will be between some Delta J yeah
but you would vary there is a reason why
you cannot really do a step increase
here because your KKT condition looks
different what you can show here by the
step increase is that that the value of
the left-hand side does not change
significantly changes by some small
multiplicative factor however the
regardless of how the variables update
in this case you would lose you would
lose that yes you will make a step
increase but but your X J's here are
allowed to become as small as possible
it doesn't mean that today if they go
below Delta they will go back
going down going down they get a very
robust algorithm so they get all these
properties of self stability they don't
really get self stabilization but they
get statelessness they get solution is
feasible as long as they indicate it
gave somehow the right intuition what
was going on in terms of the potential
function I don't know but there's a
duality gap right in this case you have
this scaling here for the linear
programming and for more general alpha
it's not really kept the case of lp's
comes from the softmax and mean writes
essentially yeah which is the right
yes.can
everything here is can be rewritten in
terms of the derivatives of the softmax
and that's what I mean
in some sense I mean the exponential
potential sunsets
yes it was just an intuition
so the algorithm Ian just once again the
way to think about it is we're trying to
satisfy this KKT condition we choose
duels as the exponential functions of
the constraints we look at the value of
the left-hand side of the KKT condition
if it is somewhere around the the
right-hand side this gamma is just a
function it's a fraction of Epsilon so
if it is close enough we don't do
anything if it is far enough if it is
like much smaller then we increase the
xj to get closer we increase it
multiplicatively if it is larger we
decrease xj multiplicatively unless it
goes below this threshold the Twix upset
now I will quickly tell you what the
algorithm parameters are they're a
little bit complicated so I don't think
like anyone should think about them for
the rest of the talk too much but just
if you want to get a sense of what they
look like so some notation this is
really what you would expect from the
notation so W max is the maximum weight
W min is the minimum weight and a max is
the maximum element of the matrix so the
parameters are delta j's are this really
complicated thing there is a motivation
for the choice of delta j on the next
slide we actually prove some lower bound
that each component of this allocation
vector takes but we end up choosing
something that is much looser or pleased
about ordering loser for technical
reasons later alpha was one weight it's
a zero
it's the zero so you're the reason
people have this exchange so in that
case what are you setting your Delta Z
to be so you cannot go all the way down
to linear programming with this you need
to be a little bit bounded away from
zero because the the lower bound goes to
zero so you are
why no merely bounded but there is the
dependence on one over alpha so alpha
cannot go all the way down to zero
alright that that's that's one catch so
the C that multiplies the exponent is
conveniently chosen if you look at Delta
J the only difference in terms of J is
just this W J when you raise the whole
thing to the alpha and you divided by
Delta J you get the same thing cap is
just 1 over epsilon times the log of the
input yeah mine is epsilon over 4 and
beta they determined these
multiplicative updates that R 1 plus
beta 1 minus theta are conveniently
chosen so that the left hand side of the
KKT condition does not change too much
it changes by a factor of 1 plus minus
gamma over 4 so we actually prove that
if some X star optimally soles of a fair
packing then each element of X is
bounded from below as a function of the
input now of course you don't need to
grasp like what all the letters here in
this equation if you try plotting this
as a function of alpha it is actually a
continuous function I don't know if the
bound is tight but the bound changes
quite dramatically between 0 and 1 when
alpha
is greater than the one that there is
much less change and it's alpha goes to
infinity you get something that is
roughly 1 over an a max square ni is the
number of nonzero elements in I'd
constraint just talking about the order
of magnitude yeah okay so let me move to
the more fun part
just convergence analysis so I'll give
you a very high-level overview of what
happens so the first thing we show is
that if we started from an infeasible
solution we get two physical solution
test if we were at a feasible solution
already the algorithm will not make the
solution infeasible in any round the
second condition we get for free just by
the choice of duals the third condition
for complimentary slackness we'd show it
holds in approximate an aggregate sense
after some poly log number of rounds and
then that is actually sufficient so
these first three KKT conditions are in
some sense preliminaries the most work
happens about showing some things about
this fourth one the way the proof of
convergence works we choose a bounded
non decreasing potential function if you
won't be surprised what it is and then
we define some stationary intervals and
show that if we are in a non stationary
interval then the potential increases
significantly if we are the solution is
epsilon proximate so the first line says
if we started with the feasible solution
we remain feasible and I want to go just
quickly over proof because it is
relatively simple
it appears in the similar form in our
book and can occur this one and like the
something that will appear in two slides
from now
what I want to point out if I gave you
the parameters you could go line by line
and get the same proof but one of the
challenges is really finding these
parameters and making them work so the
proof works as follows you select the
first round in which the solution
becomes infeasible
now some notation we just denote by X 0x
right before the update that made it
infeasible and next one just right after
the update now the only way the solution
could have become infeasible by the way
the algorithm worked the only
constraints that we could violate our
the packing constraints so this became
greater than 1 for this to happen
at least one variable that appears in
the constraint has had to increase right
how would have otherwise gotten larger
than 1 for the variable to increase we
just by the way the algorithm works we
had to have this for the word KKT
condition now from one round to another
the way that multiplicative updates are
chosen this term can increase by a
factor of at most 1 plus gamma over 4
combined with the previous line this
gives you something that is actually
even strictly less than Omega J on the
other hand if you want to bound this
from below you just select one term and
you choose the term in in which you have
the dual that corresponds to the
constraint that got violated since we
did a scaling KJ since it's nonzero it
is greater than or equal to 1 so we can
take it out we have that X J's must be
greater than or equal to Delta J again
by the way the algorithm works and and
we just write out what Y eyes are the
way we chose the this is where I need
the Delta J it not to be 0 ok so this
thing is at least the WJ
the constraint got violated so this is
greater than zero so the whole thing is
greater than WJ and we got the
contradiction those are J that's not a
problem yeah because it doesn't show up
there yes okay so the next well imma
show see if we started with an
infeasible solution we reach a feasible
solution relatively fast code I won't
get into all the details of the proof
but just how it works is after its most
one round we you know if this effects
was what violated the feasibility it
becomes positive after its most fun
around so the only thing that could get
violated it remained violated already
packing constraints now the things we
show here is that none of the variables
that appear in this constraint decrease
so they cannot bring this down all the
variables that appear oh this should be
actually increased none of the variables
that appear in I Inc increase all the
variables that appear in there greater
than 1 over an a max decrease since they
decrease they're large enough to
decrease multiplicatively after just log
based 1 minus beta allen max they they
will 1 over n max that they will get
down below 1 so combined with previous
lemma
we we get that after at some point the
solution is always feasible what another
thing to point out is that you don't
really have this in linear programming
and it is not too difficult to show it
that they are you need to start from a
feasible solution to remain feasible for
the complementary slackness or third KKT
condition we show that again after some
Polliwog number of rounds we get that it
calls in approximate and aggregate sense
so the actual all the KKT conditions are
written for each by I so
notice that this is written over the
some of my eyes and and it is
approximate so what is left to deal with
is just the famous for it KKT condition
so let me tell you what the potential
function is this is just a reminder of
what the KKT condition was mentioning
was what the algorithm was and what F
alpha czar so the potential function is
just a more general version of what we
had for the algorithms that gave us the
intuition
now the intuition about why this
potential function makes sense is that
if you look at partial derivatives with
respect to X J's and you just group this
conveniently what you get here is just
the slack of your fourth KKT condition
and that's what guides the updates so if
some XJ increases it must be because
this term is actually positive so the
potential function increases if some XJ
decreases it must be because this term
is actually negative and the potential
function increases once again so the
idea is whatever you do whatever updates
you make throughout the algorithm
execution potential function always
never decreases it's right to say okay
so the main idea for the rest of the
proof is since we have detect each XJ is
bounded in some interval what you can
show is that you know there that there
are bounds also for the potential
function they may be polynomial a large
this gap may be pulling on really large
even exponential in alpha but it isn't
so the algorithm makes updates as long
as at least one KKT condition is not
approximately satisfied now if you want
to analyze this as
is algorithmic updates it may take a
very long time before algorithm stops
making updates so the actual idea for
the convergence is well the algorithm
may have actually converged before it
stopped making updates so the type of
the convergence that we get is that
after it most
you know pas log number of rounds at
least one round holes in the epsilon
approximate solution and the total
number of rounds where we don't have an
epsilon approximate solution is bounded
by the same term so these are the yes I
mean you can also ask a question why
don't we stop after we reach this date
so if you were running algorithm in
parallel you could but here you don't
have a global coordination I'll see in
the next slide so for alpha less than 1
it's 1 plus Epsilon ticket if in this
many rounds we just need to make up some
small enough that's ok for all 3 equals
1 w is sum of weights
thanks epsilon and this many rounds here
why is it 1 minus epsilon alpha in this
case the objective is actually negative
always I intentionally didn't put alpha
in the convergence time bound you will
see in the next slide that you don't
really want alpha to be very large or at
least you shouldn't expect for a very
large alpha to have a very fast
algorithm so ok if you look at what this
function functions look like for
different values the fall for this this
is why there
three really proofs for these three
cases of alpha when alpha is zero it is
just a linear function it also increases
to one that this function you know
becomes a little bit more curve the the
gradient becomes larger and larger like
closer to zero and as you get really
close to one it goes all the way up to
the infinity so it has the same shape as
alpha equals one but it is translated
all the way up to the Infinity for alpha
greater than one again you have the same
shape of the function as it also equals
one but as you approach alpha from above
this function goes all the way down to
minus infinity what happens and now the
video will show also increasing from
something close to one to 100 in in
steps of one so what happens is that
this function becomes really really
steep really really fast so it's alpha
equals 100 it almost looks like a step
function so this is the reason why it at
least using some of the conventional
methods you wouldn't really expect to
have a very fast algorithm because at
least for the first order methods you
need either that the gradient is bounded
or that the gradient doesn't change too
much or the second derivative is danced
okay I'll do a quick proof sketch for
alpha equals one I should have mentioned
so some of the preliminary results are
an archive they don't contain this part
this is in part one reason why I'm
talking about this but they will be
posted relatively soon so a heads up I
will assume that I start from a proper
it properly initialized solution I don't
really need this it is possible to
extend the proof to start from any
initial solution but
I just don't want to complicate things
too much so since potential never
increases the what you start from is
actually the minimum potential so Delta
J's are really small so you have a huge
slack in each of the dual variables so
you will get something that these of the
order some of the weights times log the
maximum potential happens where if
bounded from above by X when X is 1 what
you get in that case is just 0 so the
total increase in the potential is sum
of the weights times log now to get the
convergence bound that we want we need
to show that in each stationary interval
the increase will actually here have
stationary rounds that the increase is
this W possibly times some polynomial in
Epsilon and possibly over some poly log
of the input so this is what we are
shooting for one thing that we need to
show is that I won't go over the proof
but so I have mentioned at the beginning
that there is a problem when we are not
making multiplicative updates and in
this I will call the variables bits that
are close to Delta J that if we were to
make decrease wouldn't have we wouldn't
do it by a multiplicative 1 minus data I
would call those variables small the
other variables I will call large so
what the next lemma says is that the
increase in the potential due to
decrease of small variables is dominated
by the increase in the potential due to
decrease of large variables so whatever
small variables do is dominate it but by
what the large variables do is this
clear I'm stating it is one lamb it's
actually at least two but just to give
you the actual idea
for the increase in the potential we
showed the following result as poss just
is those X J's that increase and we have
like the same notation for before and
after an update so we show this result
well let me just tell you that if here
if we have a large gap in our KKT
condition if the gap is at least 1 plus
2 gamma we would have gamma times this
increase well it will see it soon and
then just let me remind you that the sum
of weights is capital W so we define a
stationary round in this way why one
thing we show is that actually these
stationary rounds are going to give a
large potential increase
so if around is non stationary in case
you know this first part of the
definition is violated we need both to
hold for the definition to to be valid
what happens then is that we just get
that the potential is greater than or
equal to W over tau I'll remind you what
tau is a bit if the second condition
doesn't hold then just come by combining
these two things we we get that the
increases actually gamma times W
now I'll remind you that tau is just
that the order of log squared over
epsilon squared so what we get in a non
stationary round is that we have indeed
a large increase in the potential and if
you recall what our tol increasing the
potential was combining these two things
you will actually get foley login input
order polynomial in epsilon if this is
just the main idea it's clear
another thing that that I won't really
show but I tell you how how we show that
the solution is actually absent
approximate we show that in each by
looking at the duality gap we show that
in each stationary round this is bounded
by some constant times epsilon times
capital w so the right hand side term is
bounded by using approximate
complementary slackness which which was
one of the preliminary lemmas and the
second part of the stationary round
definition the left part is bounded by
using part 1 of the stationary round
definition and actually a lower bound
and this proof that no of this term that
I won't get to go into but that this is
just what they mean in the A's
now in the rest of the time I guess I
have only a few more minutes right five
minutes I just want to get to the
relation between this sort of problems
in some of the markets so I expect most
of you know what Fisher markets are but
I'll nevertheless go over it so in
Fisher markets we have buyers in one
side and Goods and the other their
buyers are indexed by J and Goods by the
X IJ is the amount of good I allocated
to a buyer J and every buyer has some
money it gets some utility of a bundle
that gets allocated to them and there
are some prices of goods so the market
equilibrium of these problems is
captured by Eisenberg Yale conducts
program that looks kinda similar to our
alpha equals 1 case Eisenberg Gale
markets were in introduced in 2007 by
Jane and was Ronnie there are just a
generalization of Fisher markets where a
buyer may be interested only in a subset
of goods and for some subset of goods
may want good
in some specific ratios so these are
actually just the markets that solve
Eisenberg ale type convex program which
is just a more general convex program
than the previous one if you want to
interpret alpha equals one case as a
market you could do it by choosing
linear utilities we have the teach buyer
once only a specific subset of goods and
in specific ratios the level borrow an
interpretation of was irani which is a
building a product so here there is a
number of goods and one buyer maybe
wants to make a cake here so the buyer
needs the goods in specific ratios maybe
one third should be flour one for tags
one for it sugar and then whatever is
lost
left cherries and the buyer doesn't
really want eggplant so they want to
make as many cakes as possible but they
they need goods in specific ratios and
of course their other buyers who are
interested in other subsets of goods for
me the easiest way to look at the
connections between these three problems
is by looking at metric flow problems
because this is where actually the alpha
equals one case came from originally if
you want to interpret these problems as
natural flow problems the the problem is
as follows for each variable you have a
source and sink Pierce and a fixed
number of paths and you fix flow over
pads in specific ratios so your
allocation is the total total flow
between the source and sink pads between
the source and sink pair peers Eisenberg
Gill markets are a more general general
version of this where again you have a
source and sink Pierce but you want you
can split flow over the paths anywhere
any way you like
and for linear utilities you would be
fair in in terms of the total flows but
you can have some other utilities the
Fisher markets are a special case of
Eisenberg L markets but but not with the
problem above where once again you can
split the flows over as many over in any
way you like over the pads but only one
edge per pad is actually capacitated
whereas in these two cases that there
can be arbitrarily many edges the 30
past eight so to summarize I have talked
about a fast distributed and very robust
algorithm for the class of alpha fare
packing problems this problem arises in
many applications some open problems are
whether these techniques could apply for
ongoing Eisenberg L markets and this
could be important for example for the
development of automated online market
another question is whether some of
these techniques apply to or extend to
other types of convex problems so that's
a date are there any more questions
I think I'm exactly on time even though
we started three minutes later
No okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>