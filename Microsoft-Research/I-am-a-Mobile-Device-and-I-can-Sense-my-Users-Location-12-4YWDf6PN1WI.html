<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>I am a Mobile Device and I can Sense my User's Location [1/2] | Coder Coacher - Coaching Coders</title><meta content="I am a Mobile Device and I can Sense my User's Location [1/2] - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>I am a Mobile Device and I can Sense my User's Location [1/2]</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/4YWDf6PN1WI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
we we excited to have he wanked today he
is a PhD student at UIUC works with romo
to roy chowdhury who is quite familiar
to many in ms ah he himself is no
stranger to ms are his intern here twice
he today would be talking about his work
on multimodal sensing gesture
recognition and indoor localization oh
thank you yeah good morning it's my
pleasure to be here to talk about my
research work which is using mobile
devices to sense a user's location and
let me start by saying a few words about
the background of this research in a
matter of 10 years from 2005 to 2015 the
mobile phone has transformed from a
basic communication device to a smart
device that performs sensing computing
and communications and today smartphone
has 14 sensors on them more than 5
communication interfaces and even mostly
PU power then the Apollo guidance
computer the London man on moon right I
given these devices are always on and
always gives us the in various devices
as a general-purpose human sensor
capable of zooming into our lives
understanding our daily activities
preferences and behavior patterns at a
Silicon Valley has been calling this the
quantified self essentially suggesting
that the data from these devices can be
used for call inferences about ourselves
and ultimately be able in a wide variety
of applications so a few applications
are already on the market let me just
talk about a few examples using the
accelerometer data on the smartphone it
is possible to count the number of steps
that a user has walked and many calories
core application
have emerged and the neural smartphone
has the skin conduction sensor that can
matters the heart rate and enables many
mobile health applications and of course
GPS gives us the driving direction right
well this were really cool and important
the furious bike but now they seem
obvious and user expectations for the
next generation of mobile application is
much higher and if we want to deliver
better applications for the future
research is necessary to us robust
efficient and practical influencing
techniques are humans and here are just
a few examples that are still quite hard
today finding your users in their
location right estimating a poster of a
person and triking precise hand gestures
and various forms of context awareness
so my research focuses song developing
influencing techniques using the
multimodal sensor data for mobile
devices such as smartphones and smart
watches and that believe this in for
instance can enable new kinds of human
centric mobile applications for example
consider business analytics so if we
understand this user's location posters
and gestures then we can understand the
users shopping behavior in a grocery
store and interestingly this is already
happening extensively in the VAT our
clicking patterns so most movements are
out driving a billion-dollar business
called web analytics and I believe our
footsteps in the indoor environment is
indeed like the clicking streams online
and our when we look at a cereal box in
a grocery store it is indeed like
right-clicking on line item so this
physical and vibe analytics are really
similar but still this physical
analytics is still not present today
simply because we don't have the ability
to understand the user's location
posters and gestures suppose we have
this location post
after inferences building blocks then I
believe we can be able this physical
business analytics and in many other
application open up for example
understanding the location and
orientation of the phone can be able
oakmantle reality for indoor museum
right and sure you do also consider
using the infrastructure cameras and
things this might be a more direct
indicator of grey too hard that's not a
possible solution right so you run the
camera using a camera that's not a
possible solution yeah but there were
other challenges such as like chlorine
something else right so they're
different trade-offs yeah so a
gesture-based control can be done by
just varying a SmartWatch and finally
this virtual gaming a water reality
around the corner and that they are
emerging and this understanding the
posters and gestures of users hand can
be key building blocks for such
immersive gaming experiences right and
if you look at its building blocks
across different models the common
denominator is really the location right
the location of the human body the
indoor localization and the location of
the arm imposed estimation and the
location of the hand and fingers for
precise hand gestures so my talk is
really about how we can leverage the
smart device sensors to do this macro to
micro localization on human body so let
me start with talking about indoor
localization so the question about
indoor localization is essentially where
am I in the indoor environment and there
has been a huge amount of work on this
topic and let me just quickly sent over
the key ideas so the first question is
why not we just use all the localization
technology for example GPS well probably
the GPS is that a GPS signal do not
penetrate well into the buildings and
even some that do that bounces too much
in the indoor environment that leaving
the gps receiver
Mike receive at all and by if I turned
out to be a reasonable alternative right
especially given its wide availability
and it's probably the most popular
approach that that's far let's assume we
have a couple of FX points in the
environment and now when the phones run
the Wi-Fi scanner they can get a list of
Wi-Fi signals as the user walk around to
receive the signal strengths if you
change so therefore the signal can infer
the user's location but to make this
happen somebody has to go to everywhere
and then build is mapping between a
signal strands and the user's location
that takes a lot of effort and even
worse this might be changes our time so
therefore to ensure a high accuracy we
need to periodically calibrate a signal
and build this map ok and Wi-Fi is not
only approach that people have
considered we also look at deploying
beacons for example blue to speak and a
song begins for the stump peak in case
subtype people deploy a couple of stump
beacons in the environment and then we
can use smartphone microphone to
calculate the using climbing to
calculate the distance between the phone
and the beacon receiver right from that
I can triangulate and fear a user's
location and Bluetooth speaking this
data approach that has a smaller range
and then when the user pass by the phone
can hear the whisper of the Bluetooth
speaker and then can figure out the
location of the phone right but the
problem is speaking based approach is
that the huge deployment and
installation costs right so therefore
many companies like Google Cisco Intel
Samsung they insisted on us to provide a
system that is software based and
scalable so under this context we
started thinking can we do something
that do not rely on the infrastructure
so that seems possible is also around
the same time that the smartphone has
this book has this motion sensors
accelerometer converse and Rosco so we
start thinking can we use this motion
sensor themselves to figure out the
user's location I supposed to relying on
a Wi-Fi l-acoustics
signal from the environment so that
seemed possible because when we use the
accelerometer data but I'm going to use
a walk the phone bong stays right that
should tell us the steps that a user has
walked if you just use simple filtering
techniques right and also the compass
will give us the direction the in which
direction in which the users walking
right so if we combine the direction and
distance we can estimate this actual
path that a user has walked so we tried
this we collect some data and then it
turned out we failed miserably because
so then we come back to literature and
we found this match there call that
reckoning and that reckoning is
essentially fundamentally difficult
because our environment has this my toes
our round and this matters cause the
converse data to fluctuate and the user
play via the phone the phone also
bounces right there for you know all
these together arrows together that
makes this directly in tracking deviate
from actual path over time right but
actually in the past when people do not
have GPS that reckoning has always been
used for ships and planes to figure out
their location for example in 1922
Charles Lindbergh has landed in Paris in
after a nonstop flight from New York and
that time there was no GPS and trans
limber just used that reckoning and how
could how could he do that it's a such
long trip and he just used that the day
reckoning the triggers that he obtained
fixes from the stars and use that to
guide themselves right so once we knew
this we started thinking hey can we
magically bring some landmarks of stars
through in no environment but we had
this when a user walks the moment he hit
a landmark we could recite the user's
location and a user can direct me from
there and we can keep doing the same so
therefore all the time this new
estimated pass in this green line is
much closer to the act
pass that would be awesome but a problem
is that in indoor environment we don't
have the Stars or landmarks right so we
start looking into our environment
nesting and start thinking or can we
find some landmarks and at first we
cannot find any but then we collect some
data and then go back to life and if we
suddenly realize that if we see you
through the data through eyes of the
sensors right then we can find many
unique patterns in the environment for
example we find this unique magnetic
fluctuation and that could be
potentially used as a landmark and out
of the curiosity we also track where
does this happen they turned out this
happened near a water fountain and we
also observe other patterns such as
accelerometer data so we find some
overweight and last weigh-in decks are
mere data and and by the way our smart
from today have the barometer aidan that
can matter the pressure changes so we
also observe this pressure changes along
these dyslexia regular pattern so it
turns out these titles are caused by the
elevator and at this particular sport
right when a user pass by does the
cellular signal drops significantly and
then again comes bike so it can also be
used as Lautenberg and there are many
other examples such as x 5 fluctuation
turning around encounter taking stairs
and so on so false so we can use them as
lund rock to help us calibrate the
user's location but of course we cannot
pre-define all these patterns because we
want our system to work all over the
world in all the buildings we don't know
whether their buildings have this water
fountain I'll have the elevators so the
idea is to automatically learn this
pattern from the environment yeah so
using this call idea we developed a
system called a lock unsupervised indoor
localization and we need to solve 33
money design questions 1 how to
automatically detect landmark and second
how to localize the landmarks and third
how to localize the users
and our solution to all these problems
interdependent and recursive but let me
try to explain them one by one so let me
start by talking about how to
automatically detected landmarks so
let's say consider using walking in this
building and let's say you just put it
next to five minutes that we have a
reasonable estimate of user's location
say perhaps from that reckoning but this
is a rough estimate but we will soon
relax this assumption and display even
that reckoning is bad how we can boost
through our system let's say we have a
basic estimate and then a same time we
can collect the sensor data from the
user so therefore you have a location to
censor tuple as more and more people
walk in its environment if you have more
modest such to post right and then we
can instruct features from the sensor
data and then we can get this location
to feature tuple right because we are
interested in the scent unique sensor
pattern in the future domain so we run
and unsupervised the classroom regular
amount that so this is just an
illustration but in the system we have
multiple features there is a higher
dimension but the idea is that the same
pattern here in the same cluster view
share the same feature pattern but
that's not enough because we want to
know where does this pattern really
happen in the real word but we can do
that because we already have this crew
the location SMA so we can map this
pattern back to a floor plan let's see
one example I say this right points so
it turns out is right points also happen
in the small cluster in a geographic
space right so which gives us a sense
that it can up it can be used as a
landmark but not everything is as good
as this for example if you look at its
blue patterns it happens in multiple
locations so the way to do bees that is
that we can leverage the Wi-Fi signal
but this is different from Wi-Fi base
the indoor localization you don't need
to manually label the location and Wi-Fi
my ping as well as you know the Wi-Fi
signal of this to class are different
thus enough to distinguish them so you
either use Wi-Fi is to come to a free
right and some pattern like the screen
one it just
happens everywhere so I turn all this
panel is because when they used walking
they also create a unique pattern but
walking decided Ã©rovir that's not
helpful at all so just because it's a
sense of the main cluster known as the
linnean is a landmark and because we
have this feature become sure this work
best in sort of narrowly constrained
hallway type of environments what about
like a mall where the hole is much much
larger than some of the examples that
you shot yes so the system will work
better in a narrow corridor are not open
space by the systems to keep working
those scenarios but visa a little worse
accuracy people in the mall for example
oh yeah it's not a daily factor that
because we saw that when people walk and
walk around the Wi-Fi signal could
fluffy a little bit right but this
magnetic signals quite a stable steel
and the initial pattern of the users
walking past monster custom we test our
system in the we also tells us from in
the engineering building office building
of different places and we also test I
was just made a shopping more yeah and
yeah so if if we try to play with these
features we can a january different kind
of landmark week we you know system we
use this inertial landmark meaning we
use the jars go panic accelerometer data
we also have the magnetic landmark and
Wi-Fi landmarks so because our
environment has so many sensing data and
they are unlikely to be evenly
distributed so and also we can always
uses Wi-Fi signal TTYL tower area into
sub zones right so our assumption or our
I have a hypothesis that we are in our
environment I have enough landmarks for
us for localization so that just means
we have found the stars in your in your
environment and we can use this for
Kurata Caillat calibrate users
occasion and then provide high accuracy
I theme and what's this set of sensor
signals to TC don't change over time
yeah so the sino in the short time skill
that doesn't change but in a long time
it does change our time so what we do is
that after a period we've regenerated
the landmark such data sino can keep it
tuned right to the state of the latest
environment that is possible because we
have this data is automatically
generated in right so there is no man
you offer to go there label label again
and again so potentially what we can do
is at the end of day you regenerate and
that should be worked for at least one
day changes and you're an inclusion
providers hmm for example and the Wi-Fi
signal i think it it should work for at
least at least one or two days and
magnetic signal that works even longer i
think it works from modern one or two
months drinking fountain or something
like that yeah the way the vanguard
signatures from Jaret Wright certainly
that in those cases a beauty instructor
changes in that could change but type
your legs quite a stable what's the more
of your system yes so we we need to my
little able to places to figure out the
APIs to the location so walk around the
place manually is that so hold up would
strap right supporter yeah so I i will
talk about how to boost rat in a minute
but we need to manually label the bear
is the beauty entrance and one of the
like stairs or elevators but you don't
go there let's say I can stand here and
the label what is the building entrance
of building 42 on the assumption but but
the the thing is that we don't need a
detailed map how label where's the walls
we just need to
you just need to tell me what to
information where's entrance there is
one of the elevator that's already how
our requirement maybe you'll get to it
later I don't know are there any
applications to hold environment um yes
I think they are addition to the home
requirement for some believe my room you
want to automatically turn off the
lights oh you want to you want you know
trike the age two people alone at home
how this thing how things go like oh
yeah I think there will be mine
applications as I say yeah yeah I think
well hope you burn your by five at least
you can rely on the sensors to track
your sams should scare so what if many
people are using Wi-Fi hotspot so I'm
damn movies over it which impact yes I
proceed what if whatever I using a hot
spot and they are moving so then it does
this scenario what is the accuracy right
so in our system because we can rely on
this you know stop counting and tracking
and we also rely on magnetic inertia
patterns so we don't rely heavily on the
Wi-Fi so that means we only use the most
stable Wi-Fi say you know we can afford
that because we will rely on other stuff
so the only highly you use holistics
selected by if I say you know I use the
cruise features so that increased
accuracy for not another area yeah yeah
so but that sounds good but wait right
so we assume that we have a reasonably
good that reckoning but what if that
reckoning system is not that good which
may be always the case in the real word
right so what happens then so our idea
is that other let's say the user walk
past three sensor patterns like this
right blue and green and different user
will walk the same path but just be
out of the tracking error this possibly
going with that word from each other or
what time but the initial point
shouldn't be too bad it's reasonably
good for the initial point that that
reckoning so if we can use those traces
to figure out that this right pattern
actually happened in small area they
should be recognized as a landmark and
then we use the centroid of the landmark
as the estimate but this is just initial
estimate is not accurate at all but it
is not this is not perfect at all but
the reason that's made and then because
this errors from different devices
different hardware and different phone
different user step size counting they
are uncorrelated so if you pull out the
real world data and this is one example
right this right square is the true
landmark location and each of this blue
points shows the estimated estimation
from the thai reckoning pass so as we
can see here they are really
uncorrelated because of the hardware
noises and tumor step size and out
patterns right so their central it can
be used as an initial estimate and from
that but the problem here is that this
blue and the green patterns cannot be
recognized as landmark because they are
scattered in a quite large area we are
not sure what will happen right so but
we can do is since we know the first one
is a landmark we can recite user's
location to the first one and then that
reckoning from there now the second one
is blue one becomes have any reasonable
smoke area right and then we can
recognize it as a landmark that we can
keep doing the same and then finally
recognize that that the last one is also
a landmark so in other words we can
gradually grow the landmark from the
region of the building and then finally
feel the whole building in a
bootstrapping face but this estimates
are not perfect they have errors and but
the good news that we always have users
walking our building so we can leverage
this new user choices and fit new user
traces to our system and to improve the
estimate of landmark location so here's
how we do that let's set a use a walk in
the beauty and then
we can pure we can always find by
there's a new landmark and we can also
find a safe landmark and if we can
update the lug nut list right and then
when you know use a walk in the building
the landmark location estimation we
become better and which in turn we
improve the user location error because
the user rely on the landmark to recite
themselves right if you have a bad
landmark of how better user estimation
as more and more use a walk in the and
then we have new data from a four hour
system this landmark location error and
user location error both decreasing over
the time and we demonstrate our suvi we
test our system in modern say six
buildings including shopping mall
university and office buildings and the
test our system in using five different
android models these modern 20 users and
currently is running live in our lab CSL
and even though we use the landmark
generated a half years ago is two can
work robustly and to get a quantitive
evaluation of the system we collect the
ground choose from the shopping mall ECE
and the cs buildings and this graph
shows the result yeah and x axis shows
the error a meters and the y axis shows
the cdf and different lines shows the
system performance or a time and yeah
and different light shows this is
performed our time and we can see that
ass in performance improves and our
after around two hours walking we can
achieve a meeting accuracy of 1.6 3
meters so your summary right so our
nature has diverse state that guided
charles lindbergh to finding his way to
Paris and then our in our man-made
nature our inner environment also have
the diversity that can be used to find
landmarks and then help us improve our
indoor localization system accuracy and
unlock achieve a media accuracy of 1.6 3
meters with no infrastructure costs and
no
calibration sure earlier your summaries
numbers kind of averaged over all the
places that you test it okay so in a
place like this what would you expect
nice like that more uh your place like
this I think a dyke receive will be
worse than the corridor scenario we
don't have the exact number for that
right now yeah yeah yeah so we we test
our system after publishing the paper we
continue working on this work for
another wire and optimize different
things and we deploy our system in
different buildings and here is one
example the users using our system and
what KDC on the phone screen is show is
showing on the left part of the video
and then a user pass by room 206 and a
lock system I can you know precisely a
capture this and we also have a bike and
a server that can automatically
calculate all the landmarks from
different users from full of beauty and
collect data from different users and
generate landmarks and also avira lies
the choices and do all the management
localization management and we
demonstrate our work to different
companies at different places and TKE is
elevator company who interested in our
system because they want to use our
system for your elevator scheduling they
have the elevator in wall street again
at a super tall building and people are
tired of waiting there for the elevator
for a long time where they want to use
indoor localization to schedule your
elevator and do this dinos we assume
that the phone is in user's hand and the
users looking at a screen and walk like
this and but you know demo to Intel they
did try our system at different places
they try to put a phone in the pen
pocket in the shirt pocket and all kinds
of place an arm at not an orang tation
and the system just a fail in those
cases and this reminded us the indoor
localization is not just about
navigation you cannot always assume the
phone as a user's hand and you look
this and then the world is tracking so
the question is how we can steal
estimated uses walking direction even if
the phone is in users pocket and other
different places and different
orientation right so if we solve this
challenge this is another mo basis of
paper but because sometime interest I
cannot go into details but I've just
show a very brief demo of that so in
this video the green line shows the
estimated walking direction from the
user and then rather use a walk in a
user try to hike it a system la they are
trying to change the orientation of the
phone and we still can estimate the
false on the phone and then quickly
analyze a use walking direction so is
and then we integrated system and unlock
together and then Samsung purchased a
research license of our work and they
are interested in pushing this to their
android platforms so is that I i I've
you moved to the next part but before
that any questions you said your
accuracy was 1.6 3 meters yeah in case
yeah so again i'm not totally familiar
the spaceman but I do see recent worked
on this on his own organizations using
Wi-Fi it they talk about decimeter they
will feel of a decimeter yeah how does
the UH so yeah I'm aware of that money
system can achieve by director say right
but typically they were required like
deploying infrastructure deploy hardware
oh you need to water I've the detailed
Wi-Fi information such that it can
provide that accuracy so when this is be
known for like Asia is that if you you
can take one approach which is then you
apply professional hardware which you
can guess anyway level accuracy fact you
can we are both is not here put building
the product fit system
long been back which we get any music or
sound stuff for me and so the other one
with Kyle and such and all those guys
it's just such a yeah there I visit the
plane extra piece of hardware the excess
months yeah so indictment into those
cases emails may now scale up to all the
buildings easily yeah I actually missed
I'm sorry i thought was 1030 is it yeah
exactly what is it weekly service yes
yeah the beacon is I think our system is
stealing some sense rely on the
directing you rely on this step counting
and the direction estimation right so
even though we kind of saw the problem
you change the orientation put it
different places but the user behavior
they could be not as our expectation
right they can just check the forum like
this like I'm talking right and then the
system may think you're walking so I
mean sometimes we can still rely on
Wi-Fi to as the lower bunk but those
cases the system need to handle careful
a user behavior may not always expect it
possibly think so you said that it by
pink but if the user is just trying to
locate right now they've been walking
around the mall 10 minutes they can't
find that store now than when I'm
localizing and so you'd have to keep all
these sensors on for example yeah other
passes so people another battery drain
so in those cases yeah b cubed a sensor
on the tracking is not really a problem
because it's relatively unstable place
even this in the pocket right but what
about energy we don't have an energy
number but i think it's continuous
testing a quite popular and I know many
of you have work on kingda sensing
products and new numerous marfo have the
additional hardware that can add
additional cpu light a beta cpu that can
precise this easy task such as sampling
and do some simple simple calculation so
using that that
you reduce your energy costs yeah so
yeah let me move to this post a post
estimation problem so here what we want
to do is we won't understand the post of
the user and this is working this via
small basis so can we track the armed
poster using just a smart watches ray
and to buy a poster I mean the 3d
location of wrist and elbow and there
are a couple challenges first of all
there there are noises in the sensors so
accelerometer jazz club right it's not
perfect and our time these errors will
be accumulating so you cannot just use
double integration and also is
accelerometer data is only on users
raised has smartwatches on the wrist so
how you can you infer elbow location and
you don't have it seems we don't have
enough data and then the third one is
that we don't have twinning it we don't
want to tween the user on a specific
site of gestures such that we can work
for those gestures we want to do
freeform Chester's so those are the
challenges we are facing but this arm
poster tracking problem is not new at
all and many researchers have look at
this for example from the politics of
biology domain signal processing domain
people have been looking at this problem
and the most of clothes work to us is
one work that also trying to use the
SmartWatch to figure out users post so
what they do they'll enrich you a couple
of opportunities first of all our our
elbow is always going to be on a circle
around by our sugar right and then the
the wrist is on another circle to run
about our elbow right so based on these
two constructs we can actually narrow
down the search space quite a lot and
then people also borrow the medical
domain information because our arm have
five freedom angle of freedom right foot
and then each of them has the range of
constraint for example in this field
fall here our arm can only move from
zero to 150 we cannot move in a negative
way right so if we combine these
constraints and
together we can narrow down the search
space but that's still not enough so
that's why they also a trained priests
out of 15 adjusters and then they can do
a pretty good job there right but what
we want to do is we want only use the
small wash but we also want to do the
freeform gestures so there are a couple
of opportunities via going to elaborate
first of all we once we know the
orientation of the watch that can be
very very valuable to us that can infer
the user's wrist and elbow location and
second of all if you used acceleration
from the watch that can show some
information about a user's movement if
we combine that we visit like hidin rock
model then probably we can get a better
estimation right and of course we can
also leverage data structure to improve
the speed of our tracking system so let
me first explain what do I mean by watch
orientation but Walt's orientation I
mean is three axis pointing direction of
the SmartWatch and now we we found that
so for a given orientation basically we
which we try we iterate all angles
possible and then from that we can find
a sub side of combination that satisfy
this particular orientation visited
subside Sita we can map this theta to
the possible location of users raised an
elbow sure three here to here right yeah
what is what is this isn't that's
another one yeah those are uh yeah
famous rotation so uh here I think we
have loved be spiced back yeah see see
ya so here we have three what
there's one this one here actually so
this is that's one come to hear so then
you do this it comes to the upper part
so call it there yeah oh yeah so and
then so basically from these five angles
we can try all the combination and see
which one satisfy this orientation
constraint and from that we can map by
bike to the point claw and see okay
these are the possible locations that
satisfy this orientation constraint so
an hour key observation is that supposed
to be no the three orientation of the
watch the possible reason the elbow
location are quite limited for example
right in this case when our rotation is
like this the possible raised my elbow
will be like that's right so you as
showing this green and wright dots and
it's quite limited so let's try to
quantify that i see how good is this
opportunity right so we we can easily do
this because we can always try different
combination and see how it goes right
the metric we have is the area of the
point cloud I here and / the whole
sphere area what is the ratio if the
ratio is load and that's good news to us
and we plot this CD f x axis shows the
ratio of access to the duration of y
axis shows the CDF and we found a
meeting case we typically have nine
percent of the severe so that means is a
really small area right if you just use
the centroid probably and do reasonably
good job but what if how do we know that
how can figure out the Jesus Movement
means in this constraint within this
narrow down area right so the idea sure
you just go down here put your theater
9400 really bad right I mean it's thirty
percent forty percent like it could be
anywhere test fear right so yes humana
cases it's not a good that's true and
I've you just explain how we can improve
this
yeah so the opportunity is using the
accelerometer data and from that we can
get an inference of that uses the raised
moment let's say that what bonding
sample right when the user is like
punching like this so the orientation of
the watch doesn't change at all right
but your L we're going to move by
current path right and so the tracking
the deny you might serve you think you
don't move is a static point um but
since we know the acceleration of the
watch so we should do better than just
give us that a guesstimation so that's
the intuition so how we have library to
external mirror data here so the
questions to understand is the root the
real sequence right from that sequence
this is like a location a and B and C
from that we can actually infer the
acceleration and we also have the real
word acceleration from the users watch
and from this choice for any given
choice right we can from the to location
we can infer velocity from to velocity
we can infer acceleration so basically
the question is how we can combine this
eve word acceleration from the
SmartWatch these what the acceleration
that trees give us and then we combine
this together and consider the noise
model and then figure out what is the
best possible estimate so and then the
the thing is here we can what we can do
easily is that we can use a third outer
hitter Mark model right so we can
combine three stays together and then
you know if you could if you consider
three days and then you can track the
acceleration that from that it can
combine its together to beauty the arm
traces right but problem is that this is
slow and this third order header Brock
model cannot be solved efficiently so we
need to reorganize these things to make
that efficient algorithm can apply so if
we combine is three locations into one
stain here then we can use that that
becomes a first outer inner mark model
then we can use a VD coding diagram
which is sufficient for decoding first
orders hidden Rock malo so so the idea
is to build three adjacent location to
one state and
n because two adjacent location will
tell you the velocity and then from that
actually each state itself you embed
this acceleration information and if you
also have this acceleration measurement
from the watch right so we can combine
this together and also take this noise
model into consideration from that we
can infer the trace we also consider the
continued eating because your tree is
going to be smooth right so this oral
liking should be the same and we also
consider the point cloud limitation
given this orientation limitation at
this particular time your possible
Canada's view be in their range Derby
yeah I'm Derby's already squared in the
number of states and these are this
estate explosion you know it's like a NQ
give Owen totally increasing the number
of states or what you're going to repeat
how does that right so why this why does
this benefit in terms of price everyone
I think what are y'all staying is likely
right cuz bitten something like this is
to not go to reduce through some kind of
being searched so you don't actually
look at all that we could have a pass
why would you use your not using
multiple states here right you just you
have a first order yes did you mem right
so right so previously if you consider
three stays separate late then that'd be
a third other so we merge them together
to use maybe if you have three stays
probably how to improve phosphate such
that in exponential time now at least if
we can do it in polynomial time but yeah
are you actually going through the
review all the states if we better I'm
try to reduced it in the next slice a
look like a site let's say we have a
possible locations right and then the
tee time steps then our state number of
you p and q right and then the running
time you'll be enter paradise ready and
only be a huge number like a thousands
possible locations on a severe so that's
not quite as static oh and how we can
reduce the number of states so done so
be between we we try to reduce the
number of states by piyush will only
look at at two adjacent locations from
the to locate two locations actually
now for each state you can encode the
velocity not acceleration though but we
can always build this acceleration
transition into the state transition so
now from one state to another state this
transition it shows that the
acceleration right now you can move this
acceleration from the observation to the
transition now at this point you can you
know advise and then the advance forward
then we can have of course we also have
this community and this orientation
constrain but we can reduce the state
number to enter power to and now we can
do enter power full autopilot IT and we
can even do better so because we have
this continued across train because like
this stays has to be smooth right so
that means in a bit be decoding each
stage my name of them view be zero and
so if you can reorganize this such that
they happen this continuous trunk and I
will we label the start and end points
then we can further reduce our own
complexity so then we can get something
like oh and power of three what about a
mighty scale hmm tracking you don't try
to run it run something of a team search
you just run the most promising k paths
nothing like that when I don't know feel
it so so even in cube seems large and so
are you running it in Cuba with my large
n on a phone then so there's like this
or not form no no we run that on the
server the bottle there now hardest I
thought was right you know what when you
watch your Irish so they are to do a
trade off their to system design point
well one is you can achieve real time by
using a simple method that's just a
youkai to the centroid of the quanck a
lot that can be done in real time and
then the other is for you you off
loading the data to the cloud and then
that you give you an offline result for
other purpose let's say I understand
your activity over the day precise you
know hand active
recognition but that cannot be done in
real time I thing ever transition
probabilities answer how do you
determine the transition probabilities
to begin with for your agenda audio
training agent how do you generation
right so this transition probability
actually here right so it depends on the
this noise model basically and the noise
model we do that by putting the watch on
the table and then we see what is the
variance and from that we generated
parameters yeah
okay yeah and then this figure shows the
eye I crochet I x axis shows the error
and y axis shows the CDF and this tool
this black line shows the real-time
accuracy which means we just use the
centrois which is not always working
right and this right line shows what we
can do offline using the header mark
model I think what you're saying is
right it may not be the biased and
fastest master but it gives the leading
theory that it can give you the best
estimate it is not in real time yet this
mean a bunch of work in the community
motion capture world where they'll
actually done similar context kilometers
as well and the way they solve a skating
problem there because you know how in
Victor we look at all the paths using
dynamic programming and you get the N
squared stop using all paths at every
point you can just pick the K most
promising path it's a standard thing
called a beam search so you focus on
that so then you can do the issue a much
faster so you might want to try that it
might yeah I think that's far as it goes
all would be so this notion of getting
full estimation price of orders as we
got the motion capture community using
that and things all the similar insights
they miss models but will you speed it
up in up to yeah watch well I don't know
what the watch what we eat early not in
n squared at that point so it is quite
as what you're standing right meow you
might be able to ship it is it is about
a new man at this right we ended in this
counseling right now currently if for
one minute choice if you take 10 minutes
to precise it's like tonight's time on a
server on a server mmm but suppose we
have a more computer power probably
can't do it better oh you can charge to
you know try to use different beam
forming a Hydran commodity coding that i
could also speed out back
but I think you near future I don't
think this is really possible on a watch
foot off line right anyway yeah and we
have uh yeah sure do you say how did you
make the ground yeah Oh you's gonna
connect use keynote yeah yeah is ok me
going back to the question about
determining transition probabilities
that you could put people in front of a
connect and also have the watch on and
have them move and then before date that
way right did you guys do that so if you
do that then the there there are not
many problem because the acceleration
tracking error also depends on what
orientation estimation so all this mix
together is hard to require in a
recorded precise water orientation so
that also you know have impact on how
good is your acceleration right elbow
position right yeah but your watch is on
the tour first of all you're authorized
under it and even if later here and try
to add any this key nag is not that good
yet to give you precise accelerometer
level model you know not that good yet
right it's kind of doin its frame rate
is sufficient for that you can see
acceleration kind of a similar but that
model is not good enough because not
that precise right let's say you have a
two millimeter a two-centimeter error
but that if you have a large impact on
your act or omission you know estimation
but connect can now gave two centimeter
accuracy today especially food it's kind
of tracking be quite good so for sure oh
maybe not maybe I use the leaders hey
we're using a cable that's that's okay
they take it off yeah so but that maybe
if that's good then we can do that too
right is we can build a better model
possible right yeah then we have this
demo so this user is using the
smartwatch and then trying to write in a
scare ability in Eire and then writing a
b c d and this reliance shows the
connect and then this doll shows what
our system tracking result is so even
though here we let it user right you
know ABCD but you know system we do also
do freeform gestures and all kinds for
your evaluations in a paper what should
I learnt this directs oh this is a
brochure was offline so this is a pop
fly Reese on what would it look like a
queen you write on the way uh we have
that we have a video online too and
they've interest you can check it i
think i believe that too we have a
side-by-side comparison of brookline
offline and crunches yeah and so the
offline accuracy here is around eight
nine centimeter and the online I'm sorry
yet and this online real-time tracking
is about 12 to 13 media accuracy yeah
and is that I want to very quickly talk
about the last piece of work which is
about a hand striking hand gestures I
spent only one minute about this so the
question here is can we use this much to
understand what user is typing on a
keyboard right so that will be a
security problem the privacy leakage
because we use them in wash to track
steps or calculate calories the what if
the user can use the Smart Watch to
understand what you're typing so we have
a cup of challenges right first of all
as before right this noise the sensor
data in an underwater noisy and secondly
your wash location is not necessarily
your finger location your test you tap
ASDF your wrist doesn't move at all
right and third we don't have the right
hand data we have only one hand watch
right and then we solve this and also of
course we don't have training it will be
a text embody this guy won't clean the
typing for us alright so we solve these
challenges using distilled into a
machine learning karma filtering and we
also borrow the English word structure
from dictionary and they combine these
together and we have the result in a
paper but you shot when you type a word
longer than six characters our sims our
system average shot list two words that
will include the word
you have just type for example if you
have confident and out of 5,000 words in
the dictionary we can rank confident in
a second and so in summary I so our our
devices have this computation and
sensing power and we can use those as a
sensing any computer computing lens for
a society and is possible by using
motion data precisely we can use this to
build interesting inferences on humans
and my research focuses on design is
increasing techniques using a multimodal
sensor data from the mobile devices and
do this a location poster and gesture
estimation and our research go the
automatic go is building the system and
has impact and beyond that work I have
talked about I also work on auto
localization contacts awareness search
mobile security and a gamma reality and
moving forward I plan to spend on this
human influencing techniques research
for several years but have you brought
into not only a motion sensor I will
talk about I will do other research to
other sensors of sensing dimensions and
I've you do both bottom-up and top-down
research for the bottom-up part have you
not only do this indoor localization of
posters i also want understand the finer
grained you know a finger gestures cross
a crossing and other behavior analysis
and i also look at its privacy problem
because as that project has shows that
right there privacy challenges even
though it is sensing a good but it's a
double-edged the store they can you know
have privacy and concerns and then i
added top dog i have you apply i will
try to elaborate this lower level system
building blocks to build the systems
applications such as a common reality a
smart home vehicle analytics analytics
and mobile house applications I've is
that I I'd like to thank you for your
patience and
I'm happy to take any question in the
comments thank you what do you think is
the single biggest opportunity here that
space that we talked about talked about
many things what do you think is like a
very short yours right yes sure what do
you think is a single biggest better
opportunity that you can make in this
space push your stomach shipment things
like ISIL operators in Louisville
sensors it seems like everybody is doing
something on the other and lots of stuff
has already happened so what's the
biggest possibility in your mind I think
I think of I think I will focus on
mobile house and physical analytics that
will require many underlying techniques
that's do not write a today and also we
have this variable devices and hollow
lands right and all these devices
together how can we leverage those
together to build a detailed fine grain
inferences so for mobile house made me
and not be sure but if you have some
sensors on your head I think that could
maybe I'm not pretty sure of course
right and have never played with that
but I think maybe you can use the sensor
data to infer your detailed activated
recognition and you can combine those
sensors visit or smart water and
smartwatch and mobile phone together to
do something interesting and you think
we're great out in colocalization are we
done no yet i think is still out there
of course yeah and okay yeah are you
done caminar localization and i think
they're interesting ideas in the
collaborations are definitely I'm
open-minded to work on that but I'm not
saying I you like how to work on that
for a couple of years I'm not sure yeah
all right thank you so much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>