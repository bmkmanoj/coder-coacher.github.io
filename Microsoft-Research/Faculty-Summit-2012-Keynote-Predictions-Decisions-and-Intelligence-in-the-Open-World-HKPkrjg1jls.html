<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit 2012: Keynote: Predictions, Decisions, and Intelligence in the Open World | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit 2012: Keynote: Predictions, Decisions, and Intelligence in the Open World - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit 2012: Keynote: Predictions, Decisions, and Intelligence in the Open World</b></h2><h5 class="post__date">2016-07-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HKPkrjg1jls" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you very much well it's certainly
exciting times and all the people here
in this audience know firsthand what's
happened over 25 years with our research
and our students and so on in fact what
we can assume now in terms of the amount
of computation and memory the data and
connectivity is awesome unexpected when
I put myself in my graduate student
shoes and in particular I think the the
learning and reasoning prowess the
algorithms we've developed over the
years some are old and and and retooled
others are our novel are leading to new
opportunities and directions I like to
start with this picture of a graphical
model that I worked on as a graduate
student that was plonk in the center of
a department at Stanford that was you
might say ground zero for logic based
reasoning methods applied to real world
problems like production rule systems
we're just the time I've started my
dissertation work there's a lot of
disappointment in the failure of these
logic based systems to grapple with the
complexity of the open world I came into
Stanford thinking boy you know how
probabilistic reasoning and uncertainty
must be central in in cognition in the
way the human mind works and must be
foundational in generating a
computational model of intelligence and
I was very excited to work with a team
and it was expanding a couple different
campuses at the time to develop
probabilistic models and this particular
model here was designed to capture the
expertise of an intensive care unit
physician about the problems that might
be encountered in ICU medicine where
those nodes are random variables that
you typically can observe especially at
the top part of this graph at the bottom
or some observables and these arcs
represent probabilistic dependencies and
we SAT with an expert for a week to
build this graph and SAT with him
probably for another week to basically
put probability distributions that every
single end of every single art there now
it was exciting in these days was we
were developing algorithms that would
let you take any subset of findings here
that you could see
like blood pressure or heart rate of a
patient co2 input and output and so on
and reason about the likelihood that
this patient was suffering from a
pulmonary embolism or was maybe a kink
tube in the ventilator machine telling
us all the probabilities that we
couldn't see directly and this was a
marvelous artifact and the algorithms
were beautiful and this graphical models
area is one type of representation that
really extended our abilities to
represent insight and knowledge now over
the last 25 years we've developed
methods to learn these kinds of models
and other kinds of models directly from
data and one form of machine learning
for building graphical models basically
searches through a tree of possibilities
of all possible structure is generated
typically heuristic ly because it's an
intractable problem typically to
generate all those structures and
applies a score the kind of score you
might give to a distinction in the world
like a patient being ill to each model
being the correct explanation for the
data finding the best one and that one
becomes the model that's used for
diagnosis typically in real time the
models indicated to be the best and so
on now what's exciting is that this area
has been active and sometimes for
example you can go from just
probabilistic association to causality
and use methods that will tell you the
likelihood that an arc is a causal arc
of course in a cause in a causal
situation like in health care where some
factor like a patient's behavior
increases the risk we can actually do
interventions on the world and change
outcomes so it's very exciting area that
we've been investigating more lately now
a very important notion that I don't
think is stressed enough in all with all
the enthusiasm about machine learning is
that we need to typically go beyond just
predictions in the world to actions and
the idea basically is we want to
consider a pipeline of data
predictive models that give us
probability distributions about things
we care about to actions in the world to
to decisions that have high expected
value this is not just about a
feed-forward flow here it's also when
you have a decision model and a decision
context it tells you a lot about the
nature of the model you need the
tolerances you have and also if you need
to get more data for example in
situations where more data will give you
a better predictive model active
learning methods take advantage of the
decision structure to focus attention on
the data that you need to extend those
models ideally especially you pay for
those data points in time or dollars so
i went to dimension a few exciting
directions just briefly to frame a
couple of deep dives I'll deal with you
in three areas I'm very excited about
causality as I mentioned an active
learning which I refer to just now I
think those are very exciting areas a
lots going on in those spaces and a lot
lots more to be done another area that's
receive less attention is the notion of
lifelong learning where I build a system
artifact and have it sit in the world
for a prolonged period of time for
example accompanying the lifespan of a
human being and having it understand
what it means to learn over time where
context might be shifting or oscillating
for example and it's not just you know
empirical studies and experiments
there's some deep principles about
lifelong learning what gets thrown out
what gets discarded what gets wickets of
brought in in real time then there are
new kinds of methods being developed
quite different but related to the
graphical models i talked about one of
which is called deep learning and with
deep learning the idea is we have a
stacked representation particular one
approaches is with using neural
essentially the same neural net
technology that was used you know 10 to
15 years ago and the idea basically is
we can either induce variables or in an
unsupervised manner or in a supervised
manner with labeled data build these
models with large amounts of data the
recent interest in energy has been on
systems how can we actually scale up the
and threw mums of modularity of various
kinds and approximations to these big
search spaces to understand how to share
out the effort across large numbers of
CPUs and it's a very active area I
should say that this area a couple of
years ago was pioneered as a
collaboration between Toronto and MSR
Redmond in its application to speech
recognition and the kinds of accuracies
seen were big jumps and discontinuities
from from the best methods of the time
apply before this technique was looked
at carefully with large amounts of
computation and data now available as to
say that might say that the the
demonstration that some of you saw
yesterday by Rick Ratched on speech to
speech was in part enabled by this
recent jump you see basically from 1993
2011 we had a initial drop i'm looking
at a conversational recognition task
called switchboard data which is the
same data essentially we trained the
system you saw yesterday for people at
the 21st century meeting but for about
15 years or so we've been on a plateau
until we recently see this there's
change and it looks like all indications
show that if we keep on going we're
going to see continuing word error rate
decreases over time and we're not sure
exactly where that's going to go but you
see where the human error transcription
rate is and a few people I've spoken to
who know this area doubt we're going to
hit that eventually which be very
impressive now another exciting
direction is the idea of we have new
forms of data I'll call these ambient or
in stream data resources let me give you
an example of ones that we work with as
a collaboration with colleagues at MIT
and we got accessed about two years ago
to all of the cell phone communications
data just counts of calls at cell towers
from a six-day period in Rwanda where an
earthquake happened at day 3 outside of
rwanda in Congo and just by looking at
140 cell towers and the surge of calls
over time that happened in each cell
tower we were able to with some
interesting learning techniques combined
with expectation maximization figure out
where the epicenter was a few miles
outside the epicenter just a few
kilometers just from watching the cell
phone towers over time and we can turn
that around with a little bit of
decision analysis decision theory to
compute by looking at disruptive the
continuing disruptive areas where we
should look and do reconnaissance under
uncertainty all from this ambient data
so the other interesting thing in our
world is that that this machine learning
and reasoning technology is now behind
the scenes in daily life on the desktop
in the car in the living room people
using Windows 7 might be surprised if
they don't know about this to learn that
the system is learning about them as
they work with applications over time
and this is also refined in Windows 8
and in surface called Windows super
fetch and the idea is over time by time
of day and day of week the system is
learning about your actions and is
learning to prefetch applications into
memory before you touch and ask for them
so you have a faster response time in
the car released in north america right
now every a few minutes in 72 cities we
have models that are providing
predictive predictions about the flows
on every single surface street mostly
those that are not sensed by any sensor
at all through a generalization process
we developed
and these are being used in bing traffic
and this is default on Windows Phones
the way these models are built is we
take a bunch of GPS data in this case we
started with Seattle for about a million
kilometers 100,000 trips taken and we
weave together models we weave together
the GPS data with highway data to build
models that predict how traffic is going
to flow you need to really understand
how traffic is slowing on every single
Street typically to really do a great
route plan a star or Dykstra
combinations that I used in practice
this shows a a path from my home in
kirkland to a place across the lake in
seattle and as people from seattle know
the big question is like which bridge do
i take where do i go around the top to
seattle and it's saying here in this
case that there's it's a 15 mile route
24 minutes as the is the best route if
he didn't use our predictive models but
the fictive models are telling you to
basically take it will take about 50
minutes in current conditions and
therefore if you take the route
sensitive the traffic sensitive approach
you'll go over the top and that's
basically 13.1 miles it's longer
typically but it's faster now only the
living room about 10 years ago our team
started playing with a strange thing
called the depth camera this is andy
wilson here at HCI person who realized
it was some power to the idea of using a
depth camera now going from this kind of
playful research playing with a ball by
sticking your hands into the screen with
a depth camera to an actual product is
an interesting path and it's a cross
laboratory story that really leverages
machine learning in a deep way at the
time the obvious way to go from a depth
object to an actual motion or sculpt
skeleton for tracking for game purposes
was by matching to a kinematic model and
it turns out that our our lab and
Cambridge was doing some long-term
research
and how do you take videos and segment
them and pictures and segment them and
the new object recognition and tagging
for example take this picture up here
how do you go from the street scene have
automatic systems that learn to assign
pixels to parts of the world that are
semantically relevant to human beings
and just at the right moment this
challenge problem landed in the hands of
Antonio and Jamie and so on and they
basically did the same thing it's not
like a sheep and grass now but this is
pixel part of a shoulder or a chest or
right elbow and then this method is used
to actually create the robustness that's
required in that product so what did it
basically now that that's what that
background some things are exciting some
what's happening in the world now and
living rooms in the cars and and yeah on
our desktops and labs focus on several
directions that I think it would be
interesting to this group first I'll
focus on some work in healthcare I'll do
a deep dive in healthcare and talk about
some work there next I'll talk about
tooth ematic i call them visionary goals
that excite me really let my passions
and i'm hoping that people being
indications of a path that were on in
each of these spaces first in healthcare
obviously we the big story about health
care is that we've dropped so much data
on the floor and we continue to do so
across the world in health care clinical
health care admits the genomic explosion
which is very promising we're still
losing a lot about the behavioral
aspects of health the way health care is
delivered and a lot lot about outcomes
about about five years ago we started
looking at a particular challenge called
readmissions challenge patients that are
discharged from a hospital bounced back
within a month to the same hospital
typically with the same problem the
question was could we address this
challenge with these methods and we had
just come into ownership and shared
ownership of a large dataset of the form
that we had never seen before especially
putting myself in my graduate student
shoes of for example 10 years of
emergency department data really rich
300,000 visits to the emergency
department and everything you can
imagine about the patient care and
situation diagnostic codes medications
vital signs laboratory results fees and
billing information even the the MD
codes who the md's it that that work but
engage with this patient so it looked
about 25,000 variables and start this
building models with the graphical
search methodology I mentioned for
example a model that can predict a
patient in the emergency department ed a
will be admitted bounce back and be
admitted as an inpatient in 30 days to
the hospital and of course that when you
build these models just people that
don't work in this space what you do
typically is you and there's there's
lots of variants of this and lots of
procedures for refining this but
basically you take a training set which
is usually most of your data and then
you hold out a test set and that test
set is usually usually the most recent
set and that's going to be a set of
patients for example that is most like
the patient's you next see in the world
and then you run your your model that
you've trained with the test set and you
see how well it does in terms of a true
positive rate and a false positive rate
and this ROC curve as it's called
receiver operating characteristic curve
tells you gives you a sense for how
different operating thresholds will work
in the hospital for example I want to
operate my my classifier such that I'll
cat that'll capture seventy-six percent
of the patients at I realized that if I
do that I'll be I have a false positive
rate of twenty six percent so that's an
ROC curve we typically try to get the
area under the curve as much towards one
as possible we also learn about what
what what are some important features
that system is discovering for example
the idea that a patient staying in the
ER 14 hours or more is a bad sign for
them for them staying out of the
hospital we all know that heart failure
is a particularly challenge but the fact
that English sentence saying dialysis
anywhere
in the document is a bad sign for
staying away from the hospital we took
this work and working with the the
health care unit at Microsoft now carid
i'm at the joint partnership with GE
built a system called readmissions
manager and the spot up several more
issues with tractability where we were
told by the by the delivery team that's
kind of slowed up we can't do a thousand
variables but you back off and so we
have to use methods that will go search
through spaces and we'll catch introduce
constraints what if we only had we can
use now 50 features or a hundred
features what observations you can make
about each patient what's the optimal
you can do and after a while you make a
trade like we'll go with 66 features and
here's the RFC trade for that value and
the fielded product will basically
present for every patient being ready to
be discharged a likelihood and this is
sorted by likelihood of being readmitted
to the to the hospital once we fielded
this we are really who stole the jury is
still out hospitals run this thing
locally without experts what about the
data differences in definitions of
variables do we need a universal schema
we actually get an ROC curve in every
new install at Microsoft Research to get
a sense for what's going on with that
system and then there's the interesting
question what we do if we had access to
data across hospitals could we do better
and it turns out that you often can now
I mentioned we built a whole bunch of
different models right now I'm missing
to focus on a couple of them I think are
interesting one is a new kind of model
we call surprise model with supplies
modeling we've done a lot of work in
surprise model including traffic
surprises in this case this is a
clinical surprise model we actually
build a database of human surprises and
we train and test off that so in this
case a we capture patients who are
discharged and bounce back within three
days to the emergency department with a
diagnosis that was nowhere on their
chart
imagine that being a physician in the ed
and you're told when you this model does
this inference at discharge time for a
patient oh by the way this patient has a
high probability 0 point 9 to 10 0 to 1
scale of bouncing back to the hospital
in three days with a diagnosis that's
nowhere on the chart you want to take a
peek you think that since we're
reasoning now about that the borders of
the physicians knowledge where we're not
going to be in a situation typically
where we're telling their position what
they already know so call this a
surprise model and it's a these are fun
miles to build the cost they reasoned
directly about the stuff people are not
very good at catching one area is that
we that nice i think is a real
opportunity area for getting for doing
new work in machine learning is
combining a rich history of time series
data with the deep knowledge we have
these days of how to do a temporal
machine learning and we've been looking
at the challenge problem of hospital
associated infection turns out that one
in 20 hospital visits probably in the
world but in the US for sure lead to a
hospital associated infection 20 billion
dollars a year cost believe it or not
it's in the top 10 causes of death for
any cause in the united states this is
an ROC curve for one of a common a
common infection called c difficile oh
it turns out that and this will be a
nips paper coming up this this December
which will have in our site a little bit
earlier than the conference we thought
to ourselves this is a collaboration
with a an intern that that I continue to
work with is it MIT Jenna wings if you
look at susceptibility and exposure over
time in a hospital they must influence
infection rates these two variables but
these accessibilities and exposures are
time index they change during the course
of a hospital visit surely they do and
we actually an a basic idea here is that
imagine that a patient comes in and it's
seen in different places in a hospital
it's imaged it's goes to the o.r and
back and so on ends up in an intensive
care unit for recovery so there's a path
to a hospital and we now
have the data to look at this over time
we have the lens the lens on the
resolution to see this by pushing
time-space with new methods we ended up
going from a point 69 area under the
curve to a point 8 and what goes on here
is an example is that any location in a
hospital we have the ability now to
compute what we call the colonization
pressure in that wing of the hospital
how much of this infection was around we
know all the patients and their
diagnosis so here's a particular patient
here anonymize over time and they go
through a hospital on a visit and we can
go through and over time look at the
spikes in infection of certain types
across this time range in different
wings of the hospital to see for e4f and
understand these rooms and we can build
models that weave together in a time
indexed way hundreds of variables to
come up with better predictors now that
cake and acceleration the structure of
exposure and changing acceptability over
time it's a very interesting opportunity
area for us to look at given the boost
we saw in going to time and when I
mention that there's a really
interesting challenge problem in all
areas we apply machine learning except
the the simplest areas of simplest
perceptual areas which is action in the
world when doctors see that probability
coming up we've often heard but we've
gotten feedback from our customers what
does that mean what do i do always say
well that's a risk score of thinking
about this patient more deeply well it
turns out that in many areas of Medicine
there's a bunch of work on different
kinds of interventions that might be
done for example how do you minimize
readmissions you might have a post
discharge home based visit program you
might have a Wi-Fi scale patients can
stand on that protects their weight over
time are their compliance with drugs
might have an education program all
these programs cost money and the idea
is if we know about the cost benefit
ratios we can build a decision model and
come up with a decision threshold and
guidance about what to do about those
numbers
so we we've have a study underway right
now in Washington DC on congestive heart
failure right next to the right in the
middle of this work now I just heard
that in China there are a hundred
million people now over the age 65 this
is on CCTV this week while the exercise
machine watching television I was I was
stunned by the number of how many elders
there are in China that undoubtedly many
of whom suffered from congestive heart
failure about six to ten percent of
people over 65 wrestle with heart
failure it's a problem that puts
patients on edge they're sort of stable
but outside of the hospital but they can
easily crash into the emergency
department requiring an intensive regime
often referred to by clinicians as our
tuning up which takes about two weeks
and their multiple interventions have
been posed for this at different kinds
of dollar values so to really build a
decision model we had to go to our
database at the hospital and we had to
basically figure out what does it cost
forget about for now just health quality
help but talk about what it costs to the
care about eighteen thousand dollars and
a patient bounces back to the hospital
they stay about eight and a half days
and we can use these numbers to action
build a decision model and compute a
decision threshold at what probability
given a cost of intervention should we
be paying for that intervention on this
particular patient and the fun thing for
us is we have this whole world in the
machine learning where we take
predictive models we do test and train
just a train and test to make it more
sequential in this case we can say train
and test but now on the test set watch
what happened to these patients and
actually do an intervention if the
system tells us to and reduce the
probability by what the system tells us
it will be reduced by by the study and
run a whole train and test set with a
decision model rastering over each
patient making a decision for each
patient yes extra care interventions no
let them go without that is often
uncertainty before you do a program and
how much an intervention costs and how
much it will affect readmission and the
idea is we can actually run that now and
pute and I really like this idea what is
the expected value of putting this
decision system in a hospital if you
believed that the intervention will cost
four hundred dollars and reduce the
admissions rate by thirty percent and we
can complete that in advance so we have
actual dollar values and these are also
aligned with health in this case about
what the expected value of the system
operating over time will likely be so I
want to just now go from a domain it
does give you a sense for an intensive
domain were working with giving you a
sense for some of the newer methods
we're playing with and the frustrations
of doctors who get numbers for example
and trying to come up with a decision
plan the two visionary areas now the
first one I'll talk about is
complementary computing this is the idea
of a vision of humans and computers
working together with a much deeper
symbiosis in the spirit of JCR Licklider
who often an unsung hero of many of the
the ways we work now with computers the
internet itself JCR Licklider was a
visionary in the 50s and 60s he was very
active who really thought deeply about
collaboration connectivity he dreamed of
the internet early on and he's talking
now or he's talking back then about
things that have not yet been
implemented like new kinds of symbiosis
so as one example imagine someday a
human being is faced with a problem here
this blue blob and imagine a smart
computer that looks at that problem with
all perception and reasoning and
background knowledge and says you know I
can decompose that problem into alpha
and beta and by the way I'm going to
communicate that to you that I've done
that and I'm going to claim that i can
do beta better and help you out but i
want to leave alpha to you as the human
being and then this cycles around in an
intensely close connected collaborative
way potentially with new kinds of visual
representations well machine learning
and infants are going to play a really
critical role in this kind of symbiosis
no doubt how can this be done it's an
important air
and one that we've been investigating
one that I've been very passionate about
let me say that we've done several
projects in this space where data
learning and decision-making becomes
core and how machines and humans work
together very quickly typically where
the machine can complement the human
problem solving in a valuable way we
have applications in conversational
systems in in systems that do
translation I'm gonna talk right now
about a recent of study we did in
citizen science that was published at
almost this year you can read the
details online that actually uses
decision theory and machine learning to
help citizen science efforts along how
citizen science is an area of
crowdsourcing or human computation which
is a rising area too many nodding heads
people are following this where people
often volunteers will help scientists to
tag data for example or classify or
discover new things with their own
volunteer effort so for example we were
working with the Galaxy Zoo team based
at Oxford Oxford in Chicago Galaxy Zoo
is one of the biggest crowdsourcing
efforts in astronomy for example there
have been there's a sloan digital sky
survey which found a million galaxies is
too many for experts to look at 120,000
quasars a quarter of nine stars and if
you volunteer you get to look at an
image after you get trained up and the
galaxy or a star and you get to give
your vote for what you think you're
seeing and there's a certain set after
certain set of votes are received but
tech a label has given us ground truth
this is what we think this is and thank
you for the citizens for helping us
label an unlabeled galaxy it has never
been seen before by human eyes even how
big the data set is so the volunteer
database that's been built is almost a
million galaxies 34 million votes
involving a hundred thousand people
students some of some amateur
astronomers and so on now with the crowd
since system we were exploring how can
we apply machine learning to enhance
this task to learn from both machine
vision and votes we discovered that
the Sloan survey people had applied a
vision algorithm to each of those
objects now vision algorithms are
tireless they don't care if it's a
million galaxies they can go through
will zip and provide probability
distributions over what they're seeing
from a whole bunch of features people
are scarce resources so we thought
deeply about if we have machine vision
looking at every one of those galaxies
and we have human voters how do we weave
them together in an ideal way this is an
example of many tasks wear a weave is
possible and here come the actual
challenges and we want to use machine
learning to figure all that out well it
turns out we can learn from a portion of
the database how to do ideal fusion of
both the machine machine perception and
the human effort to do ideal routing and
stopping rules from to knowing we don't
need any more votes for example on a
galaxy here's some of the astronomical
features and how they're defined by the
by the vision people working with the
astronomers and there's one of four
hundred features the idea is to build a
unified model that actually reasons
jointly about the implications of
machine identified perception and human
votes it also predicts the next vote any
particular individual will give to a
particular task and all at all times
what's the max likelihood of what this
object is once you do that it turns out
you can do routing and the other kind of
fun thing was we could actually look at
this big database of people and combined
experience with the computer vision
features and current activity like right
now how long have they been on what's
the dwell time between their problems to
route tasks so we can actually find
people who are most qualified at any
time to be looking at a particular
galaxy as well as if someone's not doing
very well we can actually set up an
educational system that says check these
two things out these are different do
you see that and make them better at
what they're doing now I'm not going to
go to details hear this but fun
a we do these detailed studies we do we
can basically for twenty three percent
of the votes that ninety-five percent of
the full accuracy of the system and for
four to 10 of the votes we can go all
the way and therefore we say with saving
an enormous amounts of human effort here
by using this machine learning and
decision theory to route tasks to people
now I'm going to end with the last
challenge area I call integrative
intelligence I saw yesterday at the 21st
century talks and the questions we heard
lots of interest among young Chinese
students what's the prospect for deeper
AI human level intelligence concerns
with even more optimistic / pessimistic
concerns with robots taking over the
world we have heard a couple questions
on that yesterday we believe that
there's a lot to be done in the space of
delivering on deeper experiences of the
con you'd have working with a human
collaborator and one of the approaches
we call it intelligence viacom position
where we leverage a tapestry of
components look at the synergies and
dependencies among these components and
we ask the question might the whole we
bill being somehow more than the sum of
the parts and the comment here the side
comment here is that back when triple AI
the association for the advancement of
the I was a young conference in nineteen
in the 80s they worship sort of a one
main machine intelligence conference
that everyone went to whether you did
vision or speech learning planning you
had one conference but with the
maturation of the field by the time I
became president I said in my charter
well I would nurture the independence
but i also would seek synergies and sink
sink seek to bring back to counter the
sim triple centripetal certificate of
the separate mad maturing fields so you
know CDP our conferences are full of
vision people the conference itself is
as big as the main triple a conference
now if not bigger
ACL conference for example in double ACL
all the robotics conferences icml and
speech KR and inference is it possible
that there's been there have been
maturing advances of the kind we saw in
speech tux that might change error rates
that when you bring these pieces
together might give you new holes
because people aren't thinking in an
integrative manner lately and we think
the answer to that is a strong yes and
our team and i think i think andrew eng
is here with the stair robot effort very
similar efforts to sort of can we bring
these things together in new ways so the
project that we have as our primary
project in space we call situated
interaction and we say that someday you
know computers will understand in that
let's expand from that small diagram i
made that show the Alpha and the beta 2
alpha 1 to alpha sub N and beta and so
on lots of subproblems lots of
coordination going on let's say in a
surgical setting or even a smart
billboard where a system recognizes
there are two people and understand
someone has a Starbucks drink in their
hand or you're in a kitchen scenario and
a robotic system says now okay pour that
slowly okay now get the sugar by
watching and tracking the situation and
I always love this picture because I
think that it's quite possible that we
will have grandchildren that will be
going out for an event the movies at
night that will be quite comfortable
leaving their kids at home with the
family robot and you might tell the
robot call me if there's trouble let me
know if this trouble and you're very
confident that robot will provided great
experience education and the kids will
have even a better time alone then when
you're all hanging out together as a
boring family so as part of this work we
started looking at some social
computation what is it that
this does by the way welcome to our
lobby at building 99 Microsoft Research
in redmond here's a view out to the
reception area the receptionist and
people here are coming to ask for tasks
of various kinds and with proper
disclosure signs up and so on we
reported about a week of data to get a
sense for what is it that the
intelligent receptionist does with
people and it turns out it's quite
interesting it's a multi-party
experience where someone's asking for a
shuttle and someone else is coming in
waiting and the receptionist might say
what kind of you for you well while
their first person is waiting are the
two of you together and so on who else
needs a shuttle and we started thinking
about representations graphical
representations of the social situation
in terms of how people are engaging
connected disengaging waiting
rehydrating and it's a very the things
we assume are just normal casual queuing
and collaborating in simple ways are
very rich challenges to represent
computationally and we both a kind of
some hardware with some software this is
the schematic view of that colorful
chart where I had components up speech
and vision and so now we're showing you
kind of a more of a schematic view by
electronic shop and by putting this
together we can sort of start thinking
about what it would be like to build an
automated receptionist and I know some
of you have seen this because we feel
this about two years ago but it's always
good to get a refresher I'll show our
little segments of this for people that
haven't seen this before just a little
piece this red dot here is where the
avatar here is looking and you'll see
there's also a notion of of pose where
the system thinks people are looking
notice also the outfits what people are
wearing formal casual casual you'll see
in a second why that's important but in
general the system uses that information
to to make sense of things i'll show you
how that works do you need a shuttle yes
which building are you going to I forget
where are we going I think it's building
nine you sure yes so you're going to
nine right yes and this is for both of
you right yes i'm making a shuttle
reservation for building 9 42 people in
case you want to correct anything say or
press start over are you visiting
someone yes i'll help you register in
just a moment so I'll stop there but
there's a longer segment there which
shows all sorts of interactions where
somebody waiting this just actually when
that person came in not it like pointed
their head toward the person and said
and nodded and said I see you hang on a
second let me finish up and recognize
need attentional status of the first two
people turn to one another and this was
the nice time to take a break in a dress
that other person courteously looking at
the formal clothing as a sign that the
person was visiting the snow and
possibly dresses that way of Microsoft
unless they're visiting somebody so the
work is continued with fast-paced work
looking at for example trivia game
scenarios requiring new representations
to control the timing of the give and
take let me show you a little a little
experiment here with people that came in
off the street to help us of a question
game next question look is the only
country with a one powered leg what
color is it
it's a grain do you think thing yes
that's right so far we had one correct
answer now on to the next question in
the USA hospitals have a Red Cross what
time do they use in the air at world
solid blue circle is that correct no so
what's the correct answer red crescent
moon yes that's right so what happened
there is when that last young lady said
red crescent moon the agent just turned
to the guy and raised her eyebrow and
just with the gesture you know he was on
and trying to confirm someone else's
answer it's a collaborative engagement
in this case now we took the best of
breed of what we had and which is the
blue box here multi-party engagement and
dialogue and said can we create an
actual daily usable system by my door as
an administrative assistant and we
actually added to this core
functionality other projects now each of
these boxes represents several years of
work and publications predicting the
cost of interrupting me as a worker
predicting where I'll be next and how
long it'll take me to get there whether
I go to a meeting or not well whether
i'll forget something what's the message
urgency voice mail or email coming in
and gave the system new perceptual
abilities face ID room acoustical
analysis is their conversation occurring
for example voicemail email inputs
calendar location and this is what I see
when I come to work in the morning
huh
higher no one has stopped by to see you
since we last talked and outlook mobile
manager is still down so i'm not seeing
messages from your email catch you later
bye-bye so inside that system it's
continuing to run cost of interruption
it's computing where i'll be next if i
start a conversation it computes how
long until i finish the conversation in
my office for impromptu meetings for
example using work that we published at
UA I at 2004 and we just do a couple of
vignettes really quick to show you how
the system works to get a sense for it
hi are you hang on a second does it help
you better understand that so we have
the head that's living by my door for
you okay okay okay oh sorry he's not
right are you looking for air yes are
you Dan info yes I miss virtual admin I
know he has meeting scheduled with you
but his late from his previous meeting
in building 34 he's no longer on his
laptop so I expect you'll be back in 10
minutes or so you can go ahead and wave
it all but if you'd like Oh we'll come
back in a minute okay I'll make sure it
might himself when he returned alright
thanks x so it's jeff right did you go
okay
hello hi are you here looking for Eric
yes eric is having been founded chat
right now when I expect it should be
over in around 10 minutes would you like
to wait or a bit sure sounds good he
should be too long yes I'll see you
later then bye mine so this isn't it up
and running and I have to show you this
one segment which happened impromptu two
weeks ago when an intern on her day
before her last day at Microsoft wanted
to come visit with me a little bit a
little bit humble and timid mature why
exactly but she came by and I saw her
hovering walls in another conversation
and she actually engaged with the system
and watch her reaction to first time out
of the blue seeing this crazy thing by
my door and how she works with it there
was actually another student who had
come sitting in front of her that she's
engaging with a bit too but it's fun to
watch to get a sense for the future I
think then we go hi are you here looking
for Eric yep
yes eric is talking with someone I can
feel I'll take a lot oh hello I don't
think he'd mind a brief interruption
right now we'd like to show go you could
show back in 15 minutes or so and we
could see if he's available then okay
another option we could set up an
appointment help would you like me to
check his calendar to see if he has any
fruit time later today yes all right his
calendar shows that he's fully booked
today I'm not sure but I don't think
you'll be attending the meeting august
calendar today at one-thirty p.m. I good
man Selena no fair day work for you sure
great like me to write this on his
calendar oh no feel free to stop by at
that time here yes I'll see him later
then nice meeting you so she actually
ended up with the relationship with the
robot in a little bit of time they're
the same platform has been fielded at
Microsoft for search and we've had it on
just we just getting doing testing and
training and testing right now which
says the elevators are robots and we
should be able to track people's
intentions and compute whether they want
to use the elevator or not and if so
elevator door should be rather like the
doors on the bridge of the enterprise
and Star Trek they should just open for
you as you walk to them it's kind of a
magical experience when we've been
testing this even the elevator problem
except really interesting challenges so
what the machine learning algorithm has
told us using optical flow features
about where the interestingness is it's
not in front of the elevator it's to the
sides these are where the positive
weights are and turning this over right
now with a negative weights are with the
system is learned to where to look
perceptually to figure out if somebody
for their track for their flow going to
use the elevator or not and we think
that these technologies will not only in
the future be in front of you as
explicit in
intelligences they'll not only be
collaborative working side-by-side in
very explicit ways that alpha and beta
and working with you and getting your
tasks done extending your abilities but
also be like as in windows 7 few of you
knew that this machine learning and
decision-making in that system in the
memory manager but our grandchildren
will expect elevators to not have to
have legs jammed in them to open doors
they'll expect the intelligence to be in
our environment in deep ways that won't
even stand out as interesting it'll just
be the way things are so I'll just say
that applications of sensing learning
and reasoning are still in their infancy
infancy infancy infancy they'll be
interested ented to people in society as
we mature these methods over time I'm
sure these technologies will review this
slide deck will be viewed 30 years from
now as like a Franklin stove technology
I was trying to get coal into a stove
and the theme that I like to point out
is that we start with principles and
curiosity we build applications both in
mission-critical and in playful ways and
often we end up with new principles
typically as we try to take our current
methods and we face the constraints in
and needs of the real world so I'll stop
there
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>