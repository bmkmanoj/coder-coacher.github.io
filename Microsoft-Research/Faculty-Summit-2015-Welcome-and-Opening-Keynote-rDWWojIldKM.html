<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit 2015 Welcome and Opening Keynote | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit 2015 Welcome and Opening Keynote - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit 2015 Welcome and Opening Keynote</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rDWWojIldKM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning welcome again to the 16th
faculty summit I saw you a lot of you at
the reception yesterday hope you had a
good dinner and got a lot of sleep
because we have two full days of great
talks panels research showcase a lot of
things you know the program is in this
book I think most of you got it I'm sure
you know if you thought about it you
recognize we kind of tried to model
after a Broadway play bill so it has the
program and then it has these ads on the
side so you should check out the ads
those ads actually point you to the
various demos in the research showcase
and so on so we'll have a great day of
talks here in the evening as usual at
the end of the first day we have a
banquet normally at least in the past we
used to take you on this wonderful boat
cruise on Lake Washington but guess what
no more bored they sold the boat they
probably figured that we were all
causing too much trouble or something I
don't know why but you know Seattle has
a lot to offer it's not just the board
one of the things that Seattle is famous
for which some of you might know it's
dale chihuly and this great work of
glass art so we're going to actually do
the banquet at the Chihuly garden and
glass at the seattle center buses will
reave right after the you know fireside
chat in the evening now we always try to
make it fun and do a great experience
but the real business is here the
conversations you have with each other
with us the talks and the panels and
discussions we want it to be stimulated
and we also want you to use this and we
want us to use this with you to increase
our connection between yourselves and us
and each other and to kind of build and
foster a community as a research
community now there is a lot of stuff
that's going on I'm going to have a few
announcements to make throughout the day
I'll come every now and then and
announce one or two things but first I
want to call attention to a couple of
things that's a photo booth you might
have already seen it if not go check it
out take a picture of yourself be as
crazy as you want put it on Facebook
Instagram Twitter wherever else these
things are done I'm still old-fashioned
side I don't know quite what all the
social network channels are these days
there's also a game you look at the back
of your badge you'll see about the game
check out the game
there's actually a very attractive price
to win I won't tell you what it is but
it's a surprise and but you know do
check out the game the game is really an
opportunity for people to interact and
get to know each other and learn about
things and the program is with you check
it out I know as you go through the day
ok and of course the research Showcase
which is where the demos and some of the
other interesting things are being
offered will be there tomorrow so that's
just the beginning but let me not
belabor your time because I know you're
all eager to meet our first speaker let
me introduce the first speaker and my
boss dr. Jeanette wing now Jeanette's
known to all of you more than me
probably because if ever you wrote a
grant proposal to NSF in the recent
years she was the funding director for
CSI so you probably came across it or at
least she probably saw your proposal on
our desk and she probably has a good
opinion about you or a bad one I don't
know but now of course I'm bringing
around as the corporate vice president
for research at microsoft research now
Jeanette's you know as the very
interesting character she works
tirelessly it's a little bit dangerous
to have a boss who you know takes 20
minutes to reply to email no matter what
time of the day so you pretty much have
to be on your toes all the time oh well
anyway it is here she's going to talk
about Microsoft's unique role in the
computing research ecosystem thank you
good morning I'm Jeanette wing on a
charge of the basic research labs for
Microsoft Research and I'm like to
welcome all of you to the 2015 microsoft
research faculty summit we have a fire
hose agenda in store for you or for you
and I invite you to soak it all in
before I forget I'd like to thank the
microsoft research team who put together
this fantastic program and who also has
been working tirelessly behind the
scenes to make this event run smoothly
so now is an incredible time to be in
computing technological advances
continue to accelerate at a breathtaking
pace speak into the theme of this summit
artificial intelligence advances in a I
are going to touch every aspect of our
lives as the Domus device gets smarter
and as machine intelligence compliments
and expands human intelligence the
sharing economy has given us a new verb
to occur and it's not just about hailing
a taxi but for instance in China you can
uber to get a foot massage trans in
hardware and devices are pointing to new
cluster considerations using FPGAs and
GPUs and do wearables on your head on a
wrist honor in who knows where next
companies in sectors such as energy
healthcare manufacturing and
transportation are becoming software
companies because more more of what they
build and how they do them will I a
software and the systems that we build
are going to need to achieve a precise
notion of approximate correctness
because users want systems to be
reliable predictable and states despite
the fact that our systems work in the
real world where the environment is
unreliable unpredictable and unsafe
and final lady videos from biology to
the arts are daring to ask questions
they never asked before in exploring the
power of computing and the prevalence of
big data itself answering these
questions their push us in computing to
invent new technology new models new
tools that methods new algorithms and
new experiences what is behind all these
technological advances basic scientific
research basic scientific research has
made possible today's technology and
will create tomorrow's i would like to
unequivocally state that microsoft is
committed to open long-term basic
research we Microsoft Research is an
open research environment we publish go
to conferences share tools and code and
freely interact with the external
community like all of you in academia we
support long-term research we understand
the value of sustained investment in our
people and their ideas because you never
know when an idea is going to be ready
for prime time and you never know when
an idea will disrupt the world microsoft
research provides an environment that
gives our people the freedom to pursue
ambitious research agenda research
agenda that takes patience and
perseverance to pursue and we give our
people the freedom to pursue
curiosity-driven research where
serendipity and luck are often factors
to success microsoft research is also
committed to our long 24 year history
and deep friendship and partnership with
all of you the academic community we
love hosting exactly visitors and
student in terms in fact this year alone
we have hundreds of student interns
worldwide spending their summers with us
in fact we think of you in academia as
an extension of ourselves as much as we
hope you see us as an extension of
yourselves more broadly I'm very proud
that Microsoft Research plays a unique
role in the government academia industry
research ecosystem the tire tracks
diagrams which some of you participated
in creating including our very own puter
Lee published by the National Academies
argue the importance of this research
ecosystem in information technology on
society and honor economy sustained
investments in basic research by the
federal government and by companies like
Microsoft have led to billion dollar
businesses that's what those long
colorful stripes down the diagrams show
and the wispy lines in between the
colorful stripes depict the flow of
ideas and people going back and forth
between academia and Industry and
sometimes government that has enabled
these billion dollar businesses
Microsoft Research plays a unique role
in this ecosystem because first as I
mentioned we support an academic style
research environment but also because
we're in a large corporation and in the
sense of the environment that we support
standing 1,200 people strong we are able
to support a diversity research styles
from
single investigator two teams of
scientists and engineers working
together to achieve a shared vision that
no one person can achieve alone and
we're also very inclusive we support of
breaths of research areas covering
almost all computer science and fields
beyond computer science but most
importantly to you microsoft word search
is the home for PhD talent that want to
pursue a fruitful and productive
research career and at the same time
through the reach of microsoft products
and services to all of our customers
have the opportunity to impact the lives
of billions of people so let's invent
more tire tracks together so that's how
I wanted to just frame the rest of my
talk I'm going to go into three
vignettes three research stories I
selected these three because they
actually speak to the theme of the
conference if you listen really hard
you'll hear machine learning a few times
also because they make concrete some of
the trends I mentioned in my opening
remarks but also because they're
wonderful examples of collaborations
with you in academia so let me start
with the first story on image captioning
before I get into the story I want to
put it in some historical context when
artificial intelligence was born in 1956
at the dartmouth conference its founders
including Minsky and mccarthy and
newland simon realized early on that to
tackle the grande i challenge which was
to get a machine to simulate the
intelligence of humans was far too great
to do at once so very quick
eh eh I subdivided into different fields
all of which have become on it their own
right fields in computer science and
artificial intelligence so we have
computer vision and speech and natural
language processing and machine learning
and machine translation and robotics and
so on what has happened recently is that
because of techniques that cut across
all the sub areas including machine
learning especially deep neural networks
deep learning all networks and so on
these fields have started to converge
and now there's a sense in the air that
navy weeds community are ready to tackle
that grande i challenge again and so it
is in this context i want to explain the
image-capturing work which really
represents the lines of vision and
language coming together along with the
newer field of q and computation or
crowdsourcing try working on which was
very instrumental in this work so let me
start with the problem the problem is if
i give an image to a machine condom
machine generate a sequence of words
where that sequence of words describes
appropriately what the image is all
about so let's see how our system does
here's an image and there are two
captions a man standing on a tennis
court holding a racket and the man is on
the tennis court playing a game one of
these captions was generated by a
machine and one of these captions was
generated by human so how many people
think the first caption was generated by
machine
well you're right let's do another
here's another picture a woman is
standing near the road with a dog on a
leash and a blurry photo of a woman
walking down the street so how many
people think the first caption was
generated by a machine you're wrong but
it goes to show that our system pretty
good so to explain a little bit more
about this image caption work I'd like
to ask meg Mitchell and Larry sit Nick
to join me on stage and they're going to
answer a few questions so meg and Larry
thank you so Matt tell us a little bit
more about this pipeline of activities
that allow us to generate these captions
right so as you can see in the picture
here it's basically split up into three
stages image processing caption
generation and global reranking where we
take the output of a convolutional
neural network which is pretty exciting
and becoming quite common in computer
vision work in order to predict a bunch
of words which we actually call visual
concepts that we believe to be in the
image and then we use maximum entropy
language model to generate each word in
sequence the fun thing about using a
maximum entropy language model instead
of a vanilla language model is that we
can pack in all the visual information
and feature eyes it and then after
generating a bunch of captions that we
think might be reasonable we look at
global matching between each caption and
the image using a model called the deep
multimodal similarity model in order to
try and find the caption that is closest
to the image in continuous space and we
output the first one great Thank You Meg
so one of the important inputs to this
system is something called the microsoft
common object
in context image data set or we call a
Microsoft Coco and I'd like to ask Larry
to explain the genesis of this data set
and also how it by sharing it with the
community we were able to expedite the
progress in computer vision and the like
yeah this uh the idea for Microsoft Coco
really started two years ago for summer
internship and we were really inspired
by imagenet and how for those of you
familiar with the mention it was a huge
data set of images which really
turbocharged to the computer vision
community along with deep learning for
the image classification task and what
we wanted to do was basically the exact
same thing but for object detection and
for object segmentation and at that
point it didn't exist any data sets of
that size for that so as as a data set
as a data set progressed and we got more
data we had to do more types of data we
had to do evaluation servers and whatnot
the group started getting bigger and
bigger as you can see there's a wide
variety of different people across
academic institutions and other
industrial research labs and several
students that have joined the effort now
where does Microsoft Coco stand today
right now we have over 160,000 images in
the data set we're hoping to double bit
this year with two million segmentations
this is a lot of segmentations and if
you think about if your segment sigma
got all these different objects we have
devoted over 100,000 mechanical turk her
hours and creating this data sets that's
a huge amount of work put forth by the
truckers and creating this now one thing
is interesting is the the captions now
this is there's kind of an interesting
story behind this and it would it
started out from was last summer we
wanted to have an internship where we
wanted to explore image captioning but
we looked around we tried to find some
data that we catch your new training
from we couldn't find a data set that
was big enough so we did be working with
a cocoa group we said well can we just
annotate all the cocoa images and that's
what we did now we didn't really think
of this at the time but basically the
cocoa group they did the annotation and
images and not only gave it to us but
they just basically published it to
everyone and we didn't know this but
when CBPR came around I think many of
you know this story but there was a lot
of groups a surprising number of groups
actually picked up on these captions and
there was an four or five different
papers submitted and then accepted to
cvpr this year and is a really big hot
topic at CBP are now one of the things
one of the
the negative things that happened was we
weren't anticipating it actually taking
off the way it did so we didn't give
people evaluation protocols so all the
papers were evaluating the different
approaches using different different
valuation metrics so again with the
cocoa team we work together and we came
up with an evaluation server so that way
all the papers could then smit the
results we'd have apple dapple
comparisons but then it turned out that
the automatic captions themselves
weren't that indicative of which systems
were working better than the others
because it's hard to evaluate whether
captions good or not so then we had a
caption challenge at cvpr this year we
actually a human's come and generate you
know judge these captions and that was
really popular and really interesting to
see and then coming up at Isis TV this
year we're going to then have our first
object detection segmentation and key
point challenge and we're really excited
fantastic thanks Larry so Meg let's go
back to the image capturing work in this
evaluation criteria problem what was the
most difficult technical challenge you
had to overcome and getting the system
to do so well yeah so one problem in
generation is trying to find a really
good objective function and the
difficulty when you're working on
generation is that there are so many
possible things you can say how do you
measure how right something is and what
does that even mean so we ended up
working with a blue metric which is
common in machine translation work but
we also really prioritized human
evaluation as well and that ended up
helping us quite a bit and sort of in
this space a bunch of new metrics came
out of this one is the cider metric
which was spearheaded by devi Perique
who's in the audience and that uses a
consensus over a bunch of references the
other is delta blue which is spearheaded
by michelle galley and is at ACL this
year and that uses human scores across
it's a generalization of blue that uses
human scores for captions great thank
you so I open this segment talking about
the convergence of some sub areas and
artificial intelligence for instance in
this case
and language so Larry do what do you
anticipate possibly a new cognitive
skill that humans are good at that might
be the next step in incorporating in
this image captioning work well the this
work that the QA excellent the this work
here is bqe is done with deputy Rick and
drew batra both at Virginia Tech and
what's really interesting about this
project is it not only combines you know
vision and language but also combines
common sense reasoning as well so if you
look a couple of these examples you have
a does this person have 2020 vision now
the answer that question you need to be
able to understand which question
question means you gotta understand what
2020 vision implies and then you got to
be able to detect whether the person an
image actually has classes or not I'm
very similar for is this a vegetarian
pizza this really does combine many
different aspects of AI together and it
also has a great side benefit where we
can actually evaluate it because it's
yes or no but for many of the question
some of the questions are numbers or
colors of that sort of thing but it
makes it much easier to evaluate and we
don't have to worry about some of the
messiness that we had with the image
captioning task very interesting Thank
You Larry and Meg I
I encourage you to go to the research
out case and the toss at both Larry and
aggregating today in tomorrow so my next
story actually comes from computational
biology itself a field that has emerged
over the past 10 or 15 years as computer
scientists and biologists have been
working side by side to discover new
biology and to push state-of-the-art
computing this particular work is on the
use of statistical machine learning
apply to gene editing and its joint
between Microsoft Research and the Broad
Institute of MIT and Harvard this work
is really picking up on this
revolutionary gene editing system called
crisper crisper stands for are clustered
regularly interspaced short palindromic
repeats so we'll just call it crisper ah
it started actually many years ago when
bacteria researchers discovered
weird-looking sequences of DNA and
didn't know what these sequences were
for what they were purposes and what
they're good for and it wasn't until
2007 when a yogurt company discovered
that there's a natural defense mechanism
by bacteria against viral attacks and
then molecular biologists in 2012 were
found a way to go up this naturally
occurring bacteria defense mechanism to
find a way to edit any gene in any
organism that's why this is a
revolutionary technique because it is so
general purpose so what I'd like to do
is ask Jennifer list garden up on stage
to join me she will talk more about
crisper gene editing yogurt maybe and
statistical machine learning Jennifer
thanks so right as you mentioned
crispers about gene editing which is
about
eating or changing parts of your genome
and this has long been a goal of
molecular biology because it would help
enable things like precision medicine
and drug development and as you
mentioned it has sort of a fascinating
story the development of the system
because it comes from a
naturally-occurring defense mechanism in
bacteria and so it's kind of neat the
way it works sort of depicted in the
picture there is that bacteria has
essentially a scrapbook of memories on
which it can store viruses that it's
been infected for infected by before and
then a second part of the machinery is
that it has essentially like a genetic
repair kit which consists of scissors
and glue and so what happens is when a
bacteria gets infected by a virus if it
recognizes it because it's been in the
scrapbook then it can deploy these
genetic scissors to go to the virus and
chop it up there by disabling it and so
as you mentioned researchers have
managed to hijack the system to do
general purpose gene editing and the way
that works intuitively is that they
essentially create a synthetic viral
memory and they can therefore trick the
cell into performing like any cell and
any organism as you said for any gene
basically to do their gene editing of
choice wow so where does statistical
machine learning fit in all this right
so it turns out that for a particular
gene edit that there are hundreds of
these synthetic viral memories that
satisfy the constraints of the system
and only a few of them actually work and
so that's where things like machine
learning statistics come into play
because we can essentially by using
statistical modeling approaches help
bypass very laborious expensive
large-scale experiments Wow terrific
Thank You Jennifer I wanted to just say
that the predictive model that she just
talked about that was done by her
colleagues and her herself is actually
available online on off this website and
I understand that it's actually
replacing the model that the Broad
Institute has been using and has already
been is like accessed every 20 minutes
which is astonishing for the community
that's right that's right and there's
also some interesting things when we
were doing
modeling for example we one of the
challenges was to figure out how to
encode these synthetic viral memories
which are actually pieces strings of DNA
and you need to encode them in a way
that the machine learning model can
recognize it and so what was interesting
is in finding new and coatings we found
in coatings that not only improve the
predictive performance that actually
yielded very interesting biological
insights and so one in particular was
the thermodynamics of this synthetic
viral memory which again as a piece of
DNA and so in particular what happens is
this this piece of DNA the synthetic
laurel memory comes near a target region
and if it recognizes that the sort of at
the very end it creates a bond and if
the bond sticks and it can elongate this
bond sort of like a zipper and so as you
might imagine the thermodynamic
properties here might be important and
so we can basically show that in our
predictive model great thank you Thank
You Jennifer my next story is on a
project on safe cyber physical systems
cyber cyber physical systems or systems
that have a computational core that
interact with the physical world
examples are self-driving cars embedded
medical devices robots and anything and
everything having to do with the
Internet of Things what's scientifically
challenging about making cyber physical
systems safe is to actually prove
properties up about citizens that have
the reason where you have to reason over
both continuous and discrete variables
at the same time because for digital
systems we can represent the behavior in
terms of boolean's but for real-world
systems we have to represent that our
behavior in terms of physics which is
often represented of course in terms of
sets of differential equations so that's
a scientific challenge um this project
is relatively new to it just started in
November what already has grown into
this multidisciplinary effort and
multi-institutional effort you can see
on the right the logos to some of the
universities that we're partnering with
it's a very exciting project and what
I'd like to do is to ask eat ask Ethan
jobs in to join me on stage
he's bringing his favorite
cyber-physical system with him so you
have to explain why did you choose
drones to be the platform for cyber
physical systems right so this is my
friend the drone I think it's a great
example of what you can do if you can
make commodity robotic system safe so
this thing costs about 1,500 bucks
relatively inexpensive for a robot it
can jump the Space Needle fly about 40
miles an hour but if you think about
what you do with these today it's mainly
limited to the hobby market and the
reason is we we don't know yet if
they're safe so they're limited by what
they can do because somebody needs to be
in control of them manually if we can
give them safe autonomy we can sort of
unlock the potential of something like
this great I'm so set this here so my
friend here hi um for those of you who
know me who know my background in formal
methods verification of course i'm going
to ask a verification question of ethan
but so basically the team has structured
the system into four layers and what I'd
like to ask Ethan is if you start from
the bottom layer where you have the
real-time operating system all the way
to the top layer where you have the
drone planning its route and making sure
it's not going to bump into anything
walk us through the layers from the
bottom up and tell us what is the key
property that we actually want to verify
to ensure the safety image of the entire
system right so in this side here you
see a drill moving through an
unstructured environment placing
something which we may talk about in a
moment into the environment so that's a
pretty complicated mission that we want
the drone to do to accomplish that we
have to get a lot of things right so the
very bottom layer we need an operating
system that's memories safe that's real
time that has protocols that can
communicate with the environment without
being hacked at the next level we need
sensors robust sensing because these are
the eyes and the ears of something like
a drone if sensors fail though the
system can come down in fact this even
happens in you know commercial aerospace
unfortunately the crash in 2009 of air
france flight from brazil was due to a
sensor failure so we need to understand
how we build models of sensors so that
we can validate the software that
consumes that data
layer above that is the control as you
talked about the control software is in
charge of setting something like a drone
into a particular physical state some
height some velocity that control
software needs to take into account the
physics of the drone so when we validate
that we need to use tools like xiii
combined with tools to reason about the
continuous dynamics to make sure that
composition works correctly and then
finally as a high level you want
something that can you know plan a
mission like this for you so that you
can do something interesting at scale at
the high level we want to ask questions
like if you plan this mission can you
justify why you took that course of
action particularly if you have to do
something like like avoid an obstacle or
make a trade-off between two difficult
decisions and you promised at one point
that you would slip in machine learning
and computers oh right yeah yeah so of
course it both in the sensing we have
machine learning to build models of what
sensors can do and how they can fail
vision is a key sensor also at the task
planning level machine learning is
something that she was quite often to
generate these plans that say you know
this is how I'm going to try to
optimally complete a mission Thank You
asian so now for something completely
different I'm about to now avail what's
underneath this black cloth and I don't
expect any loser oz because you're
probably looking at this what is that
this is the world's most sophisticated
mosquito trap okay even mosquito traps
mosquito the cyber physical system okay
right great so if we can make a drone
safe can that make the world safer
that's what we wanted to ask and we
started to look at using drones to
detect emerging infectious diseases as
they move through mosquitoes but so the
idea is can we put devices into the
environment that can catch mosquitoes at
scale bring them back so that we can
analyze what what pathogens have passed
through a mosquito that requires us to
make a psychophysical system like a
drone work well it even required us to
make the most advanced mosquito trap
which is itself actually a
cyber-physical system that uses many of
the components in the stack that we we
discussed earlier so if we can roll a
video I'll show you how we came came on
the design of this trap and the
feasibility study we did to understand
you know is something like this possible
at any moment in video the video any
moment of video kosher okay so we work
with the island nation of Grenada to
manually go fly drones and catch
mosquitos approximately every five
square miles in the island what this
allowed us to do was to was to sample
the pathogens we could see through a
mosquito using existing look through put
manual sampling wall flying a drone
around every place where we put a trap
we can then go back and correlate what
the drone saw using vision and machine
learning to build classifiers to stay if
you were to release a drone in a novel
environment where should it go hunting
for mosquitoes and then eventually we
would like to get to the point where it
can put a device like this into the
environment which automates a lot of the
fuel biology that you would do on the
end so in the end you get something
scalable high throughput pretty
impressive the demo tomorrow by the way
we'll have live mosquitoes in here you
can see a catching them bring your bug
spray malaria uninfected mosquito great
Thank You Ethan again for more go to the
research showcase tomorrow he will have
why mosquitoes and you can see this most
sophisticated mosquito trap in action
catching mosquitoes thank you thank you
so much
so now i want to make to a major
exciting announcements just to keep you
in more suspense let me remind you of
what i was saying earlier that we very
much welcome at our partnership and
working with you in academia including
sometimes when we have resources that
are hard to attain or impossible to
attain in academia we want to share them
with you and so it isn't a spirit that I
want to make these two announcements the
first is a request for proposals based
on project catapult project catapult is
led by Doug burger microsoft research
and collaboration with Derek Chow of the
Bing hardware engineering team their
observation was at data center workloads
need to simultaneously satisfy a number
of demands including computational
capability low-cost flexibility low
power usage and so on and project
catapult designed and implemented an
fpga-based reconfigurable fabric for
data centers and they were able to show
for a very critical component of the
Bing pipeline how to improve the
importance of that component I almost a
factor of two so I'm not going to talk
anymore about project catapult because
Pete early tomorrow afternoon in the
plenary session will tell you more about
it's masterful design it's incredible
performance and the potential of
large-scale applications what I do want
to mention is the request for proposals
we're providing the academic community
two kinds of resources one is a catapult
base or an fpga-based cluster that will
be hosted at the Texas Texas Advanced
Computing Center and it will be
available to anyone who writes a
proposal to us and that proposal gets
selected we're also providing catapult
boards specifically these boards that
the cannibal team has
invented to two of our partners in
Switzerland EPFL and eth zurich those
researchers will be able to actually
play with the hardware itself so the
website is on the bottom there's an
email address to which you can just
submit your proposal there's no deadline
there's just rolling submissions oh
please oh please look for that my second
announcement is the hololens academic
research grant request your proposals so
we already announced this two days ago
and this is incredibly exciting for us
to be able to share with you so the
hololens is a device and a technology
that was actually announced in the
spring along with the windows 10
announcement it's a device that you wear
that allows the goes beyond virtual
reality and goes beyond augmented
reality it supports what we call mixed
reality because you're able to
manipulate in space 3d holographic
images so we like to call this
holographic computing and what I'd like
to do is first show you a video from
case western reserve university to see
how they were able to use this
technology in the classroom we've been
teaching human anatomy the same way for
100 years students get a cadaver then
they look at medical illustrations and
it's completely two-dimensional and the
human body isn't microsoft hololens is a
holographic computer that you wear it
enables you to bring your digital world
into your real world
at Case Western Reserve University we
are focused on solving problems and
creating new knowledge my job is to
teach and I really think this could
impact almost everything that we teach
people with Holland you can see the
muscles on top of the skeleton all at
the same time you can bring them in and
out and exactly understand where things
sit you can take any anatomical heart
and show any of it you can move it
around you can make you kind of
translucent so you can see through the
outside and that really helped me
understand like how cardiac anatomy
worked I actually had a moment where I
found the aortic valve and it was the
first time that I'd actually seen the
aortic valve in relation to all the
other anatomical structures you know it
was a way of seeing it that you couldn't
do with an actual heart
I think this will improve students
confidence in learning anatomy
dramatically by creating simulations
with the hollow lens that lets them have
an experience where they can feel that
will be the best way to learn because we
don't allow people to fail too much in
real life medicine with hololens you
could imagine having a class standing
around a model almost like a tour group
in a museum where they're all
interacting completely naturally I spend
a huge amount of time to make sure they
become the best professionals because
it's all of our jobs to make the world a
better place working with case western
reserve university to create this
paradigm shift so that we can leap
together with students into the future
of education we believe that hollow lens
is going to enable us to do that we
talked about being able to use it to
teach art history we have an
anthropology department to that I think
will enjoy this technology anytime you
change the way that you see things it
changes the way that you understand them
as soon as you can change somebody's
understanding then they can change the
way they see the world
great thank you so one of the reasons
we're working with the hololens teamed
in putting this request for proposals
the academic community is we really want
your creativity to participate in
inventing the future if you will in
terms of you know what can you do what
can you imagine doing with this
technology and the other reason we're
putting this request for proposals out
is we actually want to encourage
academics to actually do research in
holographic computing so we are going to
be awarding five awards at a hundred
thousand dollars each along with two
devices and the development kit and
please go oops please go to the website
and you'll learn about more details
about the schedule the eligibility
requirements and so on so let me close
now and just say the future interests us
to invent together thank you very much
good your net wow those amazing um you
know those breathtaking so let's give
another hand for tonight each year
microsoft research helps hundreds of
influential speakers from around the
world including leading scientists
renowned experts in technology book
authors and leading academics and makes
videos of these lectures freely
available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>