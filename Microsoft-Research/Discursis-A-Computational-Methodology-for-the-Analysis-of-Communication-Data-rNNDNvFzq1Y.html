<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Discursis: A Computational Methodology for the Analysis of Communication Data | Coder Coacher - Coaching Coders</title><meta content="Discursis: A Computational Methodology for the Analysis of Communication Data - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Discursis: A Computational Methodology for the Analysis of Communication Data</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rNNDNvFzq1Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
all right everyone we'll get started
thank you very much for coming along to
this afternoon's talk I'd like to
introduce you to dr. Daniel Angus from
the University of Queensland in Brisbane
Australia he is a lecturer in the School
of Information electrical engineering
and information technology and the
School of Journalism Yoon occation and
he is a member of the new center for
excellence in the dynamics of language a
twenty eight million dollar federally
funded Center in Australia about to do
some absolutely amazing things to do
with computational methodologies and
various forms of language and a lot of
health stuff as well he's been working
on this amazing piece of software called
discursive for about six years now
partnered with a range of academics from
various aspects of the communication and
other disciplines psychology and health
and speech pathology and others and
trying to find ways of doing various
sorts of visual text analytics it's
really interesting new kinds of
technology and I hope that you enjoy
this talk all right Dave yeah thank you
very much Sean so um I I'm gonna try and
keep this fairly brief and do kind of
the 10,000 foot view of everything that
we've done with this technology in the
last little while but please break in
and ask questions as I go if you like or
otherwise save them to the end and and
hopefully got some time for some
interaction so as Shaun explained the
discursive program has been I guess my
baby forearm for about six and a half
years now but it couldn't be possible
without also the the work and by my
colleagues Andrew Smith and and
professor Janet Wiles Janet was the the
director of the thinking systems project
which funded on this particular piece of
research for many years and now she's
also one of the thread leaders on this
new our Center of Excellence so we've
got seven years of funding to do more
awesome research in this area of
linguistics and and hopefully you see
some very good things coming out of that
in the next little while so discursive
is motivated by one
thing and that is the idea of
information visualization and
visualization is a really powerful tool
that we can use to help not just explore
understand our own data but also
communicate our findings and our
analysis and interpretation to others
and so we really kind of took this this
idea of this two-fold kind of purpose of
visualization and and use it to motivate
the design of our discursive tool so the
idea that it's a tool for analysts to
analyze their own communication data but
then it's also a useful tool to help
those analysts communicate their
findings to external audiences as well
so it really serves those two purposes
so today's talk I'm going to briefly
introduce you to another similar
technology called LexA Mansur like
Samantha was developed by my
collaborator Andrew Smith and he
developed this many years before we
started work on discursive and let
Samantha is a technology that underpins
a lot of what discusss does in the
conceptual modeling and natural language
processing realm then I'll introduce you
to discuss and I'll take you through
some examples of discursive and how
we've applied it to a variety of
communication datasets and and then I'll
take you briefly at the end through some
work that we've been doing in taking
from the visual back to the the metric
space so how we quantify some of the
visual patterns that we're seeing with
the actual tool so let me start at the
visualization method now before I get
started too much into this I want to
just briefly introduce you to a what we
mean by concept so I'm going to use this
word concept a mouse or use theme during
the the presentation I want everyone to
I guess be on board with what I mean by
that so what we have here is there is a
set of words these what we call evidence
terms in this case we've got bark cat
breed pet and dog now these words can
occur in in some text or speech and our
model that we're creating here this
conceptual model is the idea that the
concept dog can be invoked by any one of
these particular evidence terms once you
reach a particular threshold of effort
and the idea that these words here are
all related and the thickness of the
lines I've drawn there give you a sense
of how much that particular term
provides evidence for the presence of a
concept dog so the idea that it within a
text if we see some of these these terms
it might imply that the concept dog is
present in that particular section of
speech or it might be a tweet or it
might be a status update or a forum post
but any of this text that we're
interested in analyzing we're looking
for these evidence terms to invoke this
concept of dog you can have evidence
terms that invoke different concepts so
the idea these are not exclusive
relationships bark in this case can
invoke the concept tree as much as it
can invoke the concept dog with these
particular models we create this from
the data itself so given a corpus of
data of text data we we build the
concept map from the text itself and and
try and use a Bayesian statistical
approach to to model well what are the
actual salient concepts and what are the
evidence terms that make up these
particular concepts one of the things to
note here is that I mean in this
particular artificial case I've given
you here of this concept of dog it's not
always that we get a concept name that
may make sense to us as an analyst
immediately and so we allow at our
actual interpreters to rename these
concepts how they like it's a good
example of this if I was to say well
here are the evidence terms Venus Mars
Saturn Jupiter what concept does that
bring in people's minds planets solar
system right but what's going to happen
with the particular statistical model
we've got here is you're going to find
that the highest weighted evidence term
made that might be Venus is going to
name the concept
so the concept might be called Venus but
in actual fact when you look at the
evidence the bag of words with it it
makes more sense to think about it as
planets so you have to interpret these
concepts to make sense of them a little
bit alright and that's
just the nature of the technique we use
to do the modeling so this particular
approach is used by LexA Mansur which is
a software commercial software tool
developed at the University of
Queensland and LexA mentor came out and
it's its purpose was to give it a text
and for it to discover what are the main
topics within that text so the idea of
profiling and surveying almost a
physical landscape of concepts right so
the idea that if you've got a text and
you're interested in well what are the
major salient concepts within that text
LexA Matz is a tool to help you do that
and not just what's in there but how do
these things actually relate to each
other so how do concepts organize
spatially and and how do you actually
determine how these things relate and
you can also do things such as if you
put a conversational transcript in there
you can actually find out based on the
speech utterances of the participants in
that data who's talking about what so
we've got a doctor/patient conversation
transcript here and this is a
visualization from the LexA Mentor
Program so within this this is a doctor
and a patient the patient's name is
David in this case of course that's not
the patient's real name but but what we
see here is that they're discussing a
variety of concepts and the concepts
that we've taken from the data are are
all these black words here these are the
nametags so this tell us where are those
particular conversational participants
situate within the conceptual space and
the proximity implies relatedness so
this is it uses a force directed layout
to lay out the concepts in that space
and it also adds these themed circles so
these try and do a higher-level
aggregation of concept groups ya know
it's different to LD a so LD a doesn't
tend to give names and and these kinds
of rich descriptors like you'd get in
LexA mansur like some answer is far more
driven I mean and it's a as I said it's
more of a Bayes
inspired statistical processing
algorithm also LexA mentor does
different pre-processing than what Lda
does it's often with Lda the
pre-processing you used to determine the
the topical breakdowns is quite specific
but you could I guess in one way you
could consider it LD a like in a way
that you're still with LD a you're
building the idea of evidence kind of
terms to a particular topic slice within
your data set the other thing here is
that it's it with LEC's an answer it's
it recognizes that language such as this
aligns to power law distributions with
frequency of particular terms and such
and so what it tries to do is it tries
to come out with a set of concepts which
sit within a particular area of that
power law distribution so rather than
you say I want ten topics from this it
would suggest well within this corpus
you have provided they seem to be 50
emergent concepts
dropping out naturally from the data so
you don't actually tell Lex and enter
how many concepts you want it kind of
bubbles up from the statistics of the
language itself what it suggests are now
unfortunately like Samantha's concept
engine is proprietary so and I don't
even know the full details of it because
I'm not an employee of like some answer
so it's it's there are some particular
tweaks within there but I do know it is
a Bayesian inspired algorithm and it
does particular pre-processing on it to
give this particular list of concepts
but the important point here would like
some answer is that what we're seeing is
that the doctor here is in close
proximity to things such as David
protective spray home these are the
concepts that the doctor is talking
about and when you drill into the text
underlying this and this is the good
thing about the tool is it allows you to
inspect every one of these concepts and
see it in context so you can see well
what is the text that's actually
supporting this particular concept and
so what you see there then
is that protective and spray this is
talking about paints and protective
clothing all right and this is this
patient in this particular case is gone
in complaining about dizziness and so
because the doctor is kind of picking up
on these particular concepts here and
mentioning them a lot it would seem that
doctor understands what's actually
causing and suggesting that it might be
paint and and the lack of protective
equipment that is might be the cause of
the dizziness that David is presenting
with and this is actually what was the
root cause of this particular problem
what we don't get here though is a sense
of the temporal dynamics of the
interaction so what you get is you get
the topics and the concepts that have
been discussed by the two parties in the
conversation but you don't get a sense
of the ordering of where they appeared
in the conversation itself so that's
where we came in with discursive sand so
we're fortunate enough to get on this
particular grant called thinking systems
which gave us some some room to be able
to kind of push into this space a little
bit to see well hang on
can we actually extend the lexer mansur
model to do more of this kind of
temporal processing and temporal
unpacking of the communication so we're
interested in this and as an analyst if
you've been given some kind of
conversational data forum transcript
some kind of social media feed what you
might want to do is see the global
structure so from end to end now it
might be an hour's worth of conversation
or it might be you know days worth of
Twitter data what's the kind of 10,000
foot view of the entire data set as a
whole are there critical time points
within that is there a point within say
a negotiation within a business meeting
where you know a critical thing happens
that then means the deal is is broken or
you know it's that something else has
happened and can you divide the
conversation into sections to then break
your analysis into the various
components and and these kinds of
periods of the conversation that might
naturally kind of drop out so that's
where we came in with discursive so what
we do is we take
conversational transcript and it's
simply just formatted as a
comma-separated value file you just have
each line with text on it and you can
add other information such as a
speaker's name and onset length if
you've got it and and these kinds of
pieces of data so we place it down the
diagonal and this will become apparent
in a sec while we while we do this so
what we also do is resize the squares
located sequentially down this diagonal
according to the amount of text in each
of those now as I said you can use real
timing information if you have access to
it but otherwise it uses a heuristic
which is simply the number of words
besides the squares and in this case
we've colored the doctor in blue and the
patient in red so this is the patient's
one of the patient's initial turns
talking about having dizzy spells and
and such for many years and and these
kinds of things now what we do is
underneath this is we color this in
according to conceptual overlaps between
the turns in the speech so this is and
this is the real kind of heart of
discursive is that what we've done is
we've taken each turn and we've looked
at the terms that are occurring within
that and use them as evidence terms for
the presence or non presence of
particular concepts
so once you've coded every turn in the
conversation according to what concepts
are there then you can do pairwise
comparisons across the entire data set
to work out where are their color
currencies where these particular
speakers are repeating the same concepts
and it's interesting that if you do this
and you do the full pairwise comparison
through this now naturally there's this
is a symmetric comparison we're doing so
we only have to show one half of the
diagonal but what you begin to see is
this structure and there's this
interesting structure that's emerging
from the actual conversation here and
when you actually start drilling into
some of the features of this structure
some things start to pop out so one of
the things I'll draw you to before I get
talking too much about the structure
here is that there was a finding from
Beckman and Frankel in 1984 about doctor
patient console
and and they said and they suggested
that these consultations where the
doctor allows the patient to elaborate
early in a consultation on their
concerns and do so for more than 18
seconds tend to lead to statistically
better outcomes
all right so diagnosis and also the
patient's understanding the concerns of
what's going on interestingly some
recent data suggests that in America at
least most of these and early parts of a
doctor patient consultation are less
than 10 and sometimes 5 seconds in
length and now one of the interesting
things with the visualization is you get
to see this very quickly right who's
kind of having those turns early but not
just that what you're actually seeing in
is Square here is that there is
conceptual consistency amongst those
first few turns all right so we can
actually look at that and suggest that
well even though the doctor is kind of
interjecting between those turns that
group of turns taken as a collection
seemed to be on the same topic all right
or set of concepts so we see kinds of
features in these so this we call these
engagement blocks this is where you're
getting these multiple speakers or
repeating each other in the short-term
and you get these blocks attached to the
diagonal which suggests is a short-term
structure here where people are
repeating each other close in time and
we can actually look vertically to see
all right so if these initial turns here
are setting the agenda of the
consultation and if this is where the
patient is talking about what their
problem is what you might like to see in
this particular context is that those
things are actually referred to through
the remainder of the consultation it's
no good a patient going to a doctor and
saying look you know I've got all this
dizziness and I'm really concerned I'm
wondering what the dizziness is caused
from and then the doctor going on to
talk about cancer or something right
that's not maybe not related to
dizziness or something else and move the
consultation away from what it was the
primary concern so you can see this by
this echoing
down here in the recurrence plot and so
all of these blocks of color suggest
that the Associated turns down the
diagonal are actually repeating those
concepts that were mentioned early on
now interestingly if you go below this
engagement block that I pointed out
earlier you notice what we actually have
is a lack of recurrence you've got this
white space and when you drill into the
consultation transcript you actually see
why this is the case because this
engagement block here is where they're
talking about David and how much David
is drinking and whether is using
recreational drugs and it turns out that
David's not really doing this much and
so yes you get a lot of this
conversation around concepts of drinking
and drug use but they are not
necessarily related to the dizziness or
the doctor decides at that point in the
consultation no this is not going to
lead us to the diagnosis this is not the
root cause of the problem and so then
doesn't talk about them anymore
and you see this because that white
space suggests that this remaining part
of the consultation doesn't make
reference to drinking or drugs and then
at the end we see this quite interesting
structure which is this horizontal
stripe which we called in this
particular context summary stripes and
this is where the doctors offering some
kind of diagnosis and summarizing the
consultation that's happened to that
point now we looked at a lot of these
these consultations in the system and we
found that a lot of these visual
patterns were were present in good
consultations consultations where not
just that the doctor had arrived at a
diagnosis but that the patient actually
showed signs they understood what that
diagnosis was so it's not just enough
that the doctor knows in their own head
and through their own speech that
they're they've arrived at a diagnosis
you need the patient to understand what
is wrong with them as well all right so
we we found these particular patterns in
those kinds of consultations the last
thing I'll show you as far as visual
features that we have in discursive we
also allow and put in this thematic
overview down the diagonal and so this
gives you a very very quick way of
summary
like I was saying that 10,000 foot view
of the conversation what's kind of
happening therm Attica Lee through the
consultation in time so if we actually
we take a good example on the left hand
side and we take a poor example on the
right hand side have a look and visually
inspect and see what you think is
different about the two of those
particular cases and as I said these are
only two cases I'm showing you here but
this these were patterns that were very
much apparent within the entire corpus
of of consultations we looked at so on
the right you might see that we'll where
is the patient
right remember I was talking about that
first 18 seconds being incredibly
important well it seems that that first
18 seconds or so is taken up with mostly
the doctor talking about things and the
doctor repeating themself but not
repeating the patient and then later on
we see very little summarization of the
consultation all right we see some of
this engagement here this is mostly
around once again this kind of check
list style interaction where the doctors
asking about drinking and drug use right
this happens again in this particular
consultation yeah surely the measure of
these are those two examples is interior
to the conversational acts themselves
and what you've done is you obscured the
interior T of those conversational acts
and evoked the visual patterning as a
criteria to judge success so in the
right case how could I possibly know
with your claims aright I would need to
know what the specifics of that
particular interior organization of talk
about the particular instance about you
know the person on the right who is a
patient might be interacting with that
doctor subsequent to hover range of
different regimes such that they don't
need to say much right how can you
possibly make a judgement where you take
out the evidence and we render it thus
and then pretend that's the evidence so
these particular consultations were
assessed by under a range of regimes so
the the converse
when I say assess as good and poor that
is not me taking the visual and saying
all because these particular pattern us
us us to believe you but there's no
evidence in that except a visual cue
which where you're asking us to take on
credit but the evidence for the merits
of that credit is in the talk and you're
not showing the talk I'll show you an
example in a second if you like but I
want to get clear first the idea that
there are particular visual metaphors
that present within particular cases and
this is the thing we did the systematic
study of this this is the papers in
plots one if you want to read the
details of this and how we went about it
the idea that these were assessed under
the communication accommodation Theory
regime and were and that looks at things
such as discourse management and looks
at a whole range of behaviors
accommodation so the idea of
accommodation particularly in a health
context is that that the the physician
needs to listen to what the patient is
saying and repeat that to them some of
those concepts in some way now when that
happens now it is possible that it
happens in a way that discusses wouldn't
pick up because they modify their speech
in a way that yes at some broader and
and taking background context into
account
they might say and use particular
evidence terms it means yes you don't
get the recurrence appearing but in
looking at so many of these as we did in
this case they did these consultations
that had been assessed as fitting into
these bands of good discourse management
good accommodation good patient outcomes
good you know adherence to treatment by
the patient and actually asking the
patient's themselves to rate the
effectiveness of the consultation itself
right and the patient's feeling as
though their concerns had been met and
that it was good talk and that all these
things had been met that was the visual
pattern that was apparent for those all
right and for those where the patients
felt their concerns had not been met
where we saw a lack of good discourse
management right they fit into that
right hand visual pattern now I agree
there are cases where
you can get particular visual patterns
where it could mean both say good
disgust management and poor discourse
management right depending on the kind
of speech these are a particular
conversation constructed in a very
particular way in a very these are all
first presentation consultations as well
so this is the first time the doctor has
spoken with the patient I might I would
definitely do this very differently for
second and third and say you with your
family doctor that you've seen for 30
years and you might not need to say a
lot to know and there might be other
cues there other than speech that you're
picking up on to to sense that there is
a there is alignment going on or such
but as a first step just taking the text
it was apparent to us particularly in
this case and in other cases which I'll
show you in a second that there are at
least interesting features there and
features worthy of further exploration
right when I get to it in further work
we're looking now at picking up things
such as prosody right so looking at
audio cues right and how do we actually
model audio cues such as prosody such as
say f-zero and other particular features
of the audio which can get us some of
that richer context you're talking about
and and pick up some of those micro cues
so the way in which you might use
sarcasm would modify the the meaning and
so semantics alone won't give you that
but if I press on I might I might show
you some examples where this is a bit
more apparent
so in this conversation here this is one
where when we showed it to our colleague
Bernadette Watson who she's a
psychologist at UQ and she collected a
lot of these particular cases I showed
her the visual and she'd done over a
hundred of these particular recordings
with many many different doctors and
this this kind of answers your point to
a degree I showed her this consultation
and she told me exactly who that doctor
was when she looked at that as soon as
she saw that that visual said Dan I bet
you I know who that is
and she told me yes this is this
particular doctor big
that doctor she'd nicknamed the doctor
the lecturer all right and they were
very that very repetitious their
behavior was that they would repeat
themselves a lot and a lot and lecture
their patients and what you see here is
this kind of back channeling of our aha
ahÃ¡ our heart by the patient and the
doctor being highly conceptual
conceptually consistent repeating the
same thing again and again and again so
that manifests that behavior manifests
in that particular way so let's just
look now at some other examples of other
conversations we've looked at these are
dementia conversations so those with
aged care residents who are have some
kind of form of dementia and we've been
working very closely with our colleagues
in the center for clinical research to
examine this data and and what's coming
out of this are guidelines for how we
might actually go about training care
providers to provide and and try and get
meaningful conversation from people with
dementia dementia is one of these these
terrible conditions where it affects
centrally a lot of the language
production and and what we see with that
is that affects social bonding right so
it's difficult for families then to come
to terms with that because they lose the
ability to converse and to bond through
conversation with those family members
so this kind of research is critically
important in ways in which we can try
and encourage that that are better
conversations more meaningful
conversations so we put this data into
discursive again and and what we found
were there were these particular
features in a lot of these consultation
are these um conversations sorry with
these people with dementia and with care
providers that had done some of this
particular training and what we're
seeing is that this is actually really
good conversation with people with
dementia the idea that normally there is
not a lot of conversation you don't get
a lot of a lot of speech from the person
with dementia but in these cases in
these little sequences were finding that
the the person with dementia was giving
these discussions
around there their childhood and and
other kind of aspects of their life
which and this is one of these these are
weird things with dementia is that how
it affects memory and so you find that
long-term memory is something which can
be picked up on more readily than
short-term memory right and so they lose
some of that short-term memory and that
ability yeah which just means it could
be the care provider stay on the same
topic very well and that's exactly it so
if the care provider staying on the same
topic and this is what we're finding in
this was that when the care providers
persisted on a topic for it for a time
they actually then were able to get in
some of those instances meaningful
interactions so they actually got some
speech from the person with dementia now
there were some topics though where the
care providers persisted and it's not in
this example here but in some of the
other data we looked at where the same
thing was happening but then they
wouldn't elicit the the end response
from the person with dementia and we
examined the kinds of topics that they
were talking about and persisting on it
was those that were personally relevant
to the person with dementia that they
would eventually get a response for more
often than those which would say about
the weather or about the local football
team on the weekend that did well or
about the local shops or something like
that these more short-term you know less
kind of personally relevant these topics
that they're persisting on the care
providers persisting on are tapping into
these more kind of long-term meaningful
memories all right we liken this and as
a metaphor to walking through a rose
garden right and the idea if you're
walking through a rose garden and you're
nimble and an able-bodied you kind of
run to the the rose bush in you and you
look at its value oh wow come on have a
look at this this is fantastic and by
the time that person you know who's less
able-bodied than you has caught up
you're already running over here to the
next bush and going ah and this one over
here is great and so the same way with
this conversation what we're saying to
the care providers now through this
research is slow down right so those
normal kind of conversational rules
about if you don't get
elicit responses so in a normal
conversation if I bring up a topic and
someone doesn't really feedback that
topic or show interest in it you move to
another topic because that's that's how
conversations formed but in these you
can't do that right you need to give
that those people time to catch up so
that they can actually begin to respond
now look it's a lot more subtle and
nuanced than than that but we've got a
couple of papers in this area now if
anyone's interested in in accessing
those and to learn more about these
these kind of clinical are skills
training that's going on now through uq
another good case of this arm that we
looked at this is some data we got from
collaborators at UCSD and this is with
autism case studies and these are
matched pairs with autistic children and
and and typically developing children
and what we see in these is that there
were a couple of cases or most of the
cases with those with ASD you would get
two kinds of behaviors almost like a
bimodal distribution where you would get
very little interaction between the
adult interlocutor and the child with
autism so they're they're put into a
room and the adult is told just have a
conversation with this child they're not
told whether the child has autism or
they're typically typically developing
the data does suggest that the adult
picks up very quickly though which kind
of can't they fit into but in any case
what we see is we see two behaviors not
a lot of topical kind of convergence or
exchange and then all of a sudden if you
pick a topic that that or the child
moves to a topic that they're interested
in talking about in this case it was
video games that's it they just repeat
that for the remainder of the
conversation right they fixate on that
topic and keep repeating it again and
again and again whereas in a lot of the
typically-developing cases we find more
of this kind of mutual exchange and
movement around the conceptual space so
there's not this fixation on say one a
set of concepts
as I said that's the visual and taking
the visual arm is one thing now within
that in those particular context and
this is the really important thing and
when I start talking about metrics I
always put a caveat here that you don't
want to look at metrics in isolation and
particularly not with these rich social
interactions you need to always examine
the data underneath that before you
start moving into this metric space but
in any case I've shown that there are
some particular visual features which
occur within particular data sets and
for these we're interested in ways in
which we can actually begin to do things
like data mining and other kind of
processing on it to maybe pick out some
of this structure so this is and and the
approach that I'm using here is what we
know is a recurrence plot right so ours
is rotated so we can align the text in
it in the software which I'll show you
in in a minute
but traditionally recurrent supports run
with the origin and the left hand side
up the page now what we see here is two
particular systems this is a weather
index or weather pattern index the
Southern Oscillation index which is very
important in Australia and this is a
human ECG recording and what you see is
this particular dynamical structure in
both of these time series right now
those are very different systems to
conversation but there are examples of
the way in which physicists and other
scientists have applied recurrence
plotting and these same people came up
with a set of rules around how to
actually measure some of those
structures so things such as entropy
determinism lamin arity trapping time
these kinds of measures which can begin
to pull out some of those those visual
features and come up with numbers to
describe the dynamics of the system so
with ours it was a bit different because
the difference here is that these
particular systems are unique right so
there is one measure here that they're
measuring and they're recurring in time
but we have interacting parties so we
need different metrics to be able to do
that and so that's exactly what we did
we came up with our own set of metrics
inspired by these same systems but to
describe this social interaction our
patterns around concepts and how
concepts have been
deployed so here's an example of a
broadcast interview this is from
Australia it was a program called enough
rope by Andrew Denton and Andrew Denton
would interview each week some kind of
famous person or otherwise ordinary
person from the street and in these
particular cases so this one is
Professor Brian Cox
I'm sure you all know sir the the
physicist and he works at CERN and on
the right hand side we have a
conversation with Rene Rifkin who was
convicted of insider trading in
Australia and and and did jail time for
that particular crime and and these
particular conversations are known
within the media discourse analysis
schools as an expert interview here and
an accountability interview because of
the nature of the social identity of the
guest alright so in this particular case
and when we actually looked we looked at
about a hundred of these conversations
across these different kinds of
categories and we found that within the
experts they did this kind of thing
where you see a lot of self repetition
and these big turns right by the experts
so Andrew Denton is the the interviewer
is allowing them to explain their
theories and thoughts and just gently
steering them through often on the same
topic to try and move the conversation
along it's a very kind of this this
interesting exchange now that's very
different to the kinds of patterning we
see here with someone who is a convicted
criminal who is sometimes more evasive
and and and shows very very different
behaviors now in doing this we can begin
to count some of these patterns to begin
to see how these things fall out at some
metric level and in doing that across
our hundred conversations we got these
kinds of distributions so what we found
was the accountability interviews mostly
sat in this bottom quadrant here where
it's dented repeating his own concepts a
lot so if we go back to the visual here
these kinds of patterns here where
Denton is having to ask for peak
questions again and again and again
and but very very little of the guests
repeating their own content alright so
by evading the question in different
ways they won't be repeating their own
concepts whereas you look at experts and
experts entender situate in this
particular upper quadrant where they're
very good at repeating their own
concepts over and over again right and
establishing a narrative and going
around that now interestingly we don't
get and celebrities are an interesting
case that fall across a wide array right
and I mean celebrity as a category is
fairly broad as well you can have it
celebrity can be everything from say a
sports personality through to an actor
through to a celebrity chef so this is
quite a broad category but some but this
is still going on this particular
research but it's interesting how at
least four experts and accountability
we're getting some some clear at least
at this preliminary stage differences
between their behaviors at a metric
level now these are not just for diets
I've shown you up until now mostly these
two party conversations I just finished
up by showing you an example of some
some new work that we're preparing at
the moment where we're looking at
broadcast interview a television
programs so these ones this particular
one in Australia that I'll show you is
called SBS inside so SBS is the network
and inside is the name of the program
and it's very much set up very similar
to what we have here so you have a host
where I'm standing and then you have an
audience in this kind of configuration
where you have a mixture of experts and
laypeople alright the experts they the
producers actually contact ahead of time
and and bring them in for the show
specially and fly them into the into the
city where this is filmed and lay people
they pull them off the street they find
them through other ways to fill up the
rest of the auditorium and give it this
kind of amphitheater this you know big
kind of live television feel now what's
interesting in this and it's been
studied by other other scholars is the
idea of what what is the purpose of the
layperson in that particular context and
there's a lot
talk that the lay person is marginalized
and that their talk doesn't really
matter or that their talk is only there
to try and make it look like well there
are these experts and but they're
connecting with the real person on the
street right we're not all just these
academics and such that don't connect
with the common man that you know this
is a bridge to to get through to that
now in analyzing these particular
discourses with discursive we found with
this metric analysis that we're getting
these kinds of configurations now this
is just done in Jeffie and what we've
done is we've measured the degree of
conceptual similarity in the speech
patterns of our guests on the program
the ones in red are the experts and this
is around our it was a program around
emergency rooms hospital emergency rooms
she had a lot of doctors and and and
hospital administrators and they tend to
repeat each other speech a lot the
thickness of the line indicates the
degree of conceptual overlap these lay
people that do get to speak tend to be
on the outer right so thin lines
connecting them now there is one
exception here and that is this person
Susan can dalish the exception being now
she was the one who at the started the
program they often show video a
pre-recorded video of someone's personal
story and Susan candless was the one
whose story was told very early on it
was her son who had acute appendicitis
and it actually ruptured before it could
be taken out because she got sent to the
wrong hospital and waited for ten hours
or something
in an adult hospital and they couldn't
operate on a child right so this story
was told early and as a result it was an
agenda setting device that was then
picked up on by a lot of these doctors
later on that would refer to it as our
year and in that case that we heard
before all right but it's interesting
because there were plenty of other cases
presented by these other laypeople here
but they weren't picked up on with the
same valence that that first story was
so as I said this is still research in
preparation at the moment but at the
moment is fairly interesting findings
how we can actually begin to show and
visualize what is only yet been talked
about in in journals and such
in text we've never actually seen this
kind of interaction play out in a visual
form such as this so that's a
force-directed layout so we use I use
Gaffey and I just used the open awed
algorithm within that which is like a
spring based stress layout so yeah so
the clustering is meaningful in this
sense so they're their actual position
relative to each other does imply a
strength of connection but it's an
incredibly highly dimensional space so
there is still a lot of stress within
these networks because you can see there
is a lot a lot of connections there so
I'm going to show you just a quick demo
of the the program itself there's more
details on the website as well that you
can go and check out for yourself and
all the publication's are linked to up
on the website as well so let me just
flick across to the program
so this is it running now I've got a
whole set of projects already loaded
it's fairly quick to run a project it's
only a few seconds to actually build the
conceptual model and get it running so
we give a a variety of interaction
within this as I said the text
underneath that is the really important
thing and so this is what we tried to
keep fairly present with the interaction
with the particular tool so when you
hover over one of these particular
utterances within this speech that we've
loaded you get a view of who is it the
number of the utterance and the concepts
that have been tagged to it you can
click on that and straightaway you get
the actual underlying text from that
particular turn now if you're interested
not just in a single turn but you're
interested in how two turns connect you
can click off the diagonal and then you
see that's utterance five and utterance
eight they connect around the concept
trying and you can see why that's the
case because five uh Turin's five is
saying I'm just trying to give a
metaphor here to get us kicked along
alright that invokes the concept trying
and it's not it is a probability but we
invoke a threshold so we say that it has
to get above a certain threshold to be
invoked but beyond that then yes it's
it's a waiting no no we're not showing
the probabilities yeah so it's it's we
could reveal it how many full it would
be for an analyst just kind of going
through a whole text like this I'm not
sure but you can get it with a data
export so yeah you can get it otherwise
but then if you're interested in a
section of text you can actually select
a whole section and then you see these
sections of speech and this shows you
why we've rotated the discusses plot
away from the traditional recurrence
plot so we can actually do this kind of
stair casing effect with the transcript
lined up with the actual recurrence plot
itself and these are the metrics I was
talking about below
so we have given them names these names
defined in the papers that we point to
on the website what they actually mean
and so when we say something like
engagement it's not necessarily
theoretically grounded engagement that
someone may use and say social
psychology it's a summation of
recurrence elements if you want to get
super technical but it seems to make
sense that appoints to some form of
engagement in that sense there's
structuring the lecture and the Timnath
thematically there are topics would you
come back to have you have you
considered sort of taking it sort of
these these longer lectures being
university lectures being public
lectures a sort of understanding is the
automatic progression is this type table
yeah so we've done we've done analyses
of things like theses so my students
have put their feces into the program
and looked at them because with
something like that or an academic paper
for instance you might be interested in
the structure so the introduction points
to results that are to come and the
conclusion should then tie so you
imagine maybe a good like a conversation
or a lecture even should tie back to the
original kind of stated aims at the end
and so you might see this long range
recurrence elements at the end where it
all ties it back to the beginning so
you're absolutely right you don't have
to actually have an interaction for this
to be useful you can do monologues you
could do another area where people are
interested is putting say play
transcripts and such in there so you
know Jam Shakespeare in there and see
what that looks like and whether there's
a particular semantic structure to the
way that ideas and and and and the
concepts are developed in time within
those particular pieces of of drama or
literature so yeah absolutely it just
needs to have some kind of temporal
structure that you're interested in
trying to get that hard at is how the
semantics are developed within that and
that's that's the real key here as well
it's about the semantics so we're not
capturing in
system things such as I guess we're not
capturing physical gesturing yet we're
not doing prosody we're not doing these
things we've just started and work to
try and get the conceptual level right
as best as we can and now we're looking
and particularly with this new grant
that we've been fortunate to get we're
beginning to look at the audio aspects
of this yeah you could we're thinking
things such as yes oh I'm stress and
pitch and intensity and is that I mean
there's a whole host of qualities that
you can extract potentially from the
audio signal but then therein lies the
the danger right because there's a lot
of features and you need to make sure
you select the the ones which are
meaningful and and you're not just then
creating patterns which don't actually
infer some kind of grounded
understanding of what is actually going
on so just because people are aligning
in pitch does that necessarily mean that
they're engaged or so there needs to be
some theoretical grounding around that
how you might offer a contentious
reinterpretation of a practices so I
wonder if you do many many years ago
show Clough a man of shape of a great
would cost to speech at fairness if what
you're offering here is kind of
versatile speech out there in the speech
that first its response to shave loss
analysis which shows that you could
determine pertinent meaning only through
an analysis of the sequential
organization of meaning so what a prior
tone came to me was manifest only in the
subsequent terms and was a key lacunae
in suspect x3 which doesn't have that
and the speech acts theorists would say
well we're not to worry about particular
evidence we're interested in creating
creating they're a theoretical edifice
and then the question then is well
what's the purpose of the refere
diversity if it's not helping you focus
on the evidence and shekels said I'm
dismayed because surely if you're
interested in conversation for example
you'll be interested in what's actually
done in the conversation not in the
production of a theory which leads you
away from the mechanics the features the
nature the practices the social
organizational features then happily
conversation to have the or
they have what we had mr. said in speech
that theory is the theory about speech
acts as being some kind of canteen
objects well likewise here we have a
kind of vision of of communication as
being some kind of catching visual
apparatus and one led to believe almost
the visual apparatus is a better measure
of conversation worse possible even that
the visual could be used to tame and
other strictures of a conversation and
and the possibility is that for example
doctors should be told to abide by all
of 18 seconds or even worse that doctor
should bear in mind in their
conversation an 18-second wrong now if
they abided by that last fall that rule
must only be accountable and sensible
and plausible in a theory if it's
manifest in their orientations but I
don't see how your model allows that
manifestation to be made visible your
model takes you away from the evidence
in such a fashion that you lose sight of
the evidence ah I I respectfully
disagree about it taking away from the
evidence because the evidence is still
here write as much as you can right
we're working with a transcript right
this is this is what has been taken away
from that particular conversation and
now if your tchen it you might have an
audio recording and a video recording as
well but say the only evidence we have
of the interaction is the text
transcript itself the program itself
allows you to go back to that at any
point in time that you like and that's
one of the the important aspects of this
is it doesn't if we try to not to move
you too far away from the data itself
now the way in which you interpret the
visual features that are present within
that is what I mean about the theory
that you want to bring to bear on that
so if you're interested in the degree to
which and and your your particular
theoretical perspective says something
about discourse management I mean you're
interested in the the amount to which
people say the same things right then
this might be a tool that can inform
that and and allow you to examine the
data with that kind of in mind to look
at examples where that is going on all
right but as you say you know if if your
particular perspective on how you judge
a conversation is you know and how you
want to examine a conversation
doesn't involve you know if if your
perspective on what a conversation is
doing is not one around all the concepts
is what gives it meaning and what people
are talking about is is what gives it
meaning at Sun at art some other level
and it's about some other cue or some
other kind of social construction of
meaning or so of that then probably this
is not going to help you anyway
because if you if you think that the
your what people are saying is
immaterial to some other level of
connection that's going on and the words
it doesn't matter what people say like
say you know married couples when they
when they talk it's immaterial what
they're saying it's the way in which
they're saying it right then this is not
going to help you and I make no promise
that this is the the panacea in that
senses by saying that you're taking the
sort of patterns in the structure of
conversation and you're adding is sort
of a shallow semantics to help that but
the deep semantics of some truths
presupposition relevance consequential
deduction it cannot really be touched by
these things that's a whole other matter
of course absolutely and that that's a
that's a perfect summary I mean this is
this is a first attempt and I think this
is the other thing that I think the
solution if there is such a solution to
ever be had that gets at that rich
semantics it's gonna take baby steps to
get there right and and I guess it's
something I find frustrating within
social science and some of the
humanities when people kind of look at
these tools and and Balch and go oh
there's no way you could possibly ever
take the complexity of human
communication and get it in here just
look you know that how poor our tools
are at obtaining sarcasm or or how bad
they are at detecting you know this you
know and as an example of that it could
never be done and either I guess the
engine but the engineer in me says well
no yet this is one step in the way to a
system which can begin to do this and
your points I know you you probably
they're provocative points to get us to
that that better system which can try
and takes
that into account saying if you look at
organized talk listen to talk listen
look at reading we robots and stuff on
reading you can see that there is an
organization to it which is visible is
oriented to is manifested is based on
conspicuous features and they can be all
documented now get getting from from
that into to to other sorts of questions
you might want to be interesting with
it's not it's a difficult exercise but
there's a great deal on the organization
of talk and my concern here is it
it's how distracting the tool is for you
and whether the whether that price of
the destruction is too great which is it
what's nice as summarized here but to
say that there's not not a great deal of
understanding about conversational
organisation is not right there's it's
massive amounts of it right but that
this is not telling me much about
conversational and structure as
conversation is really organized what
it's doing is offering something
different which is which is a bunch of
perplexed voice offering with because
what it offers seems to distract me and
strat one from looking at the scene in
matters of conversational organization
okay I guess my experience in there and
with the data that we've looked at
through the lens of this particular tool
today and and it has been done with
people who are well versed in these
particular conversation analysis and
discourse analysis you talk about is
that they do find some value in it at
least the idea that you know if you take
an hour's worth of conversation and and
take the transcript of that I mean can
you consume that in one one glance right
how many times you need to listen
through that to gain an understanding of
it like that you know and then scale
that again and again again to end up
with say hundreds of hours worth of
conversational data to deal with so the
idea that yet I mean the different
things you might be interesting but
doesn't produce a better understanding
the conversation to look at the the the
visual tempo of a conversation took an
hour in in in a single image is an
interesting thing as
not telling me much about the
conversation is telling me something
about aesthetically renderings and that
can be followed but I don't know what
it's telling me I don't know what tell
me about the conversation itself okay
yeah so suppose there was a conversation
that never ended like a chat room or
Facebook Timeline is this bus so if I if
I used your tool on the first two hours
and then used it again on the first four
hours in those two visualizations with
the first two hours look I didn't so no
because when you when you build the
conceptual model within this it built it
off the data that you've provided it so
that's within the transcription so the
addition of data wouldn't change the
conception will change the conceptual
map because it's it's bottom-up now what
you could do is you could fix the the
language model on one set of data and
apply that to to others but therein lies
some danger because language is a
dynamic construct that changes and
meaning changes in time so you have to
be really careful and this is this is
this kind of where this I think may be a
middle ground needs to be found is where
top-down kind of ontology --zz need to
meet these bottom-up so you know you
look at all the ones who deal with
grammar and and such and those who
develop things like word net that these
you know dog and cat are related and
everyone would agree that dog and cat
are related is because they're animals
but what about Bob and Fred alright and
what about these so these these other
these are the words which can take on
different meanings depending on the the
very very and it they can take on
meaning within an instant within a
conversation and then alter meaning
again a few turns later so that that
those dynamics as temporal dynamics of
how meaning is constructed through the
way in which we converse very very
interesting things to study and things
that we are interested in looking at
with tools like this getting at in a bit
more detail so yes so for the moment
just for practical reasons because as I
said you need to start somewhere we
build the concept model off the entire
text but we're currently researching
ways in which you can actually
dynamically construct this so
particularly with things like social
media and Twitter and and that so you
can actually adjust meaning in time and
continually refresh that that concept
model to encourage you to real any of
the details of lexeme answer I'm not
being an accountability aw myself but I
still can intuitive sense of what sort
of thing it is and what it's actually
doing so it clearly must have some
influence rules for relatedness between
words there's clearly be able to
identify words lists whether there's up
there lexically ambiguous of more than
one possible meaning and consider all
those meanings and somehow put them
together and form a cluster and it's
it's seeking the relatedness of the
words into account on the one hand but
also the time axis there must be a sort
of combining information Bayesian is why
these are the static model and the
semantic relatedness info and producing
a cluster and then think well we seem to
have a cluster here and we seem to have
another plastic year it may be
overlapping a bit is that what it's
doing yeah kind of so what it does is it
applies so first off it strips that stop
words because they tend to appear with
regular frequency through most language
Sophia and or and that they're thrown
away so then you're left with what
you're left with generally uses about a
two sentence window and it rolls over
the text from end to end and what it's
doing is it's guess no no it doesn't use
any grammatical information so what it
does do yeah yep so it builds a table of
currents and occurrence and then through
that it Den applies a Bayesian inspired
set of algorithms to build a set of
priors
and then infer from that those groups of
terms that seem to kind of travel
together through the text they might
suggest the presence of a singular
concept right and that's where the real
secret sources is the idea of how you
from a group of words to a singular
concept to to kind of cluster them
together but it is as you say like think
of it like clustering is a good way to
do that and then once you've done that
it's then about trying to figure out
well how then concepts relate to each
other right and that's where it comes
about the idea of where you get evidence
terms that bridge between different
concepts they're evidence that those
concepts might relate in some way and so
after doing that over the entire corpus
you're then left with a set of concepts
which have a set of weightings of
evidence terms underneath them all right
and it's and it's through the when we do
the discursive approach then in those
turns we're looking for the presence of
particular words to invoke and once you
get enough of these evidence terms that
are weighted high enough that would that
would trigger to say yes this concept is
present here in this particular turn all
right and then you would actually code
each turn and then you can do the
pairwise and we just use the cosine
similarity score to compare the vectors
with in that sense fundamental cycle
linguistic work applying Bayes theorem
Bayes rule to releasing this between
concepts and between words index so you
mean it's an experimental work
we're local and clever persons into a
proprietary algorithm is there some
fundamental work about the phenomena and
how useful they are the reliable oh yeah
absolutely
yeah and I can point you to the research
the points of that yeah absolutely so
what's actually inspired this is
inspired from some literature in
cognitive science and and and such so
the idea that yeah there is it's always
difficult when you say oh there's a
human analogy or it's like how the brain
does it you know that's such a complex
system that you can't say that's how it
does it but certainly through some of
that yet it is inspired the development
of these so that the nature of it is
quite beautiful in my eyes because it
doesn't try to assume that the system
isn't complex it embraces the complexity
of the way that texts organizers and so
it's the algorithms being you
you treat it as a power-law distribution
as text is right zips law says that you
know the way in which word frequencies
work and yet there's a lot of approaches
within this field of natural language
processing that assume that it's a
linear relationship or such and so that
that's a bit strange when you know that
it's actually a power law distribution
at its heart might end with the end of a
embracing complexity that I really
appreciated and tell you much for your
questions a nice provocative speech and
obviously it deep provokes good so thank
you very much in detail thank you guys
thank you having me</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>