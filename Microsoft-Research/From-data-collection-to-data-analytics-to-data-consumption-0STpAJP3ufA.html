<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>From data collection to data analytics to data consumption | Coder Coacher - Coaching Coders</title><meta content="From data collection to data analytics to data consumption - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>From data collection to data analytics to data consumption</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/0STpAJP3ufA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hey there my name is Seth Juarez we're
here at the microsoft research faculty
summit 2015 I'm here with David Raquel
thank you for having me on the show tell
us a little bit about what you do my
research is about understanding how and
why people provide information in
different settings and then thinking
once you have that data how do you a
great that into something useful and if
you get there something useful can you
figure out how people utilize that and
market intelligence to to make decisions
and allocate resources and so it's
thinking about that path data collection
data analytics to data consumption now
this is an interesting field because
made silver brought this 24 in the
previous election and it's all the craze
to start predicting but you're telling
me that it's a little bit different than
what he did some of this stuff you're
doing and NATO bird does a great job and
taking a lot of the data that's
available and trying to figure out a way
to make it digestible and make it
consumable and I think that we really
handle a lot more on that first step as
well which is to think how is that data
coming into play and how can we make
that even better so if you think about
polling people go out there and
traditionally in a lot of data that need
silver and all these other pull
aggregators utilize it's based on this
idea that you want to find a random and
representative group of people this is
extremely costly it's an extremely slow
process and we're sitting there with all
these people opting into internet polls
and one of the challenges we wouldn't
say is can we actually make that data
useful can we figure out ways in which
we can get the right question to them
and design the question in a way that
really extracts the information we want
can we work on actually incentivizing
them in this opt-in environment to
provide meaningful data and then once
that data is collected then could we
turn to what are the estimation
techniques now going to be for this new
type of data and we're going to be on
that for fun and hopefully the stuff
that we're building here will be turned
over to the nade Sobers the world in a
couple years as that standard data that
they're now using how are these polls
going to be presented to like your
average user so what we see is that
people like opting in and people like
providing information but right now
because the research community has not
getting this type of polling seriously
there hasn't been any sort of effort to
think about well really watch questions
maybe could be most valuable for this
different type of community and so for
example traditionally we've always ask
people about their intentions would you
buy these pair of jeans would you vote
for this candidate well we're working
and turning on the head and thinking
well who do you expect this to win this
election do you think your social
network will be buying these types of
jeans we see that actually by just even
changing the question that been very
effective rather than returning just raw
counts or simple averages it's going to
be running some very very meaningful
modeling and post ratification over that
data to turn this really
unrepresentative opt-in sample into
something that's actually meaningful
that's actually a really strong
statement that you're able to surmise a
distribution by simply asking a few
questions one question how do you do
that what we see is that the way we've
been testing these concept of
understanding and how well we list it
it's actually a fairly new idea in
academia because it's been tough for
people to explore this way we provide
people some background information give
them some time to forget it or not think
about it and then we ask them in certain
different ways to be gurjit eight that
back or make expectations off that we
see which methods are most efficient and
these kind of complex sounding but
actually pretty pretty neat-looking
distribution builders kind of following
on this method of dropping balls into
buckets it works with a nice day for us
that's fantastic now inherently when
we're taking any kind of sampling
there's bias and you talked a little bit
about some of the background processes
you're doing how do you eliminate bias
and what are some of the background
processes you're doing once you get this
information so any single pole whatever
you do any time you engage with people
it's not going to be fully
representative of the population and
even if it was there's going to be bias
and how people are responding by
different modes or just because of the
conditions of the day and so this is the
same type of thing that affects
telephone poles it affects door-to-door
polling and we need to understand
number one you know we have a smaller
sample than the full world what does
that mean number two we don't have the
coverage to cover everyone number three
people respond or don't respond and they
make a choice there the number four
there's all sorts of error that can be
and biased that can be incumbent with
simply just the way we ask a question
and what we do is we look at how people
respond and rather than simply accepting
that this is representative of all
people who look like them or all people
in a certain segment we model and we
basically run a series of regressions
over the demographics and all the ways
that we can describe them all the ways
we think that they could be different
than the general population and through
that we help learn how different traits
influence our correlate with different
types of answers for different questions
and that helps us understand better
exactly how the population we see may be
different from the general population
and the standard method really kind of
puts the head in the sand and just
assumes hey this methodology worked are
just confront bias head-on looks at it
and says we're going to try to find
those variables that define it and we're
going to ask about those variables and
then we're going to essentially post
stratify those away by modeling and post
ratifying over our general population so
let's talk about prediction lab this is
something that you're working on what is
it and what is it for so the prediction
lab is a way in which we can bring
together a lot of the research that me
and my team have been doing on a lot of
separate different things whether or not
is this polling type work and also
prediction games which are built off of
prediction market intelligence and so
the idea is that we finally want to
build long-lasting durable
infrastructure that could stand alone
but more likely and more hopefully power
a lot of different types of solutions so
you sit there and you think about
something like opt-in polling that may
be a widget on your favorite website it
may be somewhere where you just kind of
go separately and answer questions or it
could be think about all the different
silly games that people play online we
want to build a way in which they these
answers these questions can then be
turned around in something useful and so
when it comes to this idea
of supplying the right question to the
right people to thinking about how
that's it should be designed thinking
about different incentive structures
that can answer these questions we want
to build both the front-end and back-end
technology that could hook into anything
and actually supply that for people so
that rather than seeing raw counts when
you answer your silly internet poll over
who do you hate more Britney Spears or
Lindsay Lohan or whatever the the newest
question would be sure you can actually
rather than just get the ball counts you
actually get something that is modeled
and post ratified on the general
population or maybe even down to people
of your demographic or another
demographic that you care about it's
building that all in one place that we
can service not just the Microsoft
community but also hopefully something
that could be an enterprise solution
down the line so prediction lab feels
like it's a front end way of delivering
polls and a back-end way of making sense
of it is that right that's exactly right
and so we definitely stand alone and we
definitely have all the front end
technology I think that some of the
things that would be more exciting to a
lot of researchers is going to be what's
on the back end so it's both talking
about this idea of modeling and post
ratifying but in the prediction game lab
part of it part of the lab what we're
really doing is focusing a lot on what
we'll call combinatorial market maker
the idea here is that we create a game
system where people can come in and make
predictions and when they make
predictions they influence the
predictions of everything else that we
have in that game and so what makes this
unique is that most predictions are done
independently and when you do
predictions independently you have a lot
less dispersion of the information
because there's only so many questions
at so many cancer if you connect
everything then when someone answers
question here it affects all of the
questions around that's great the second
part of it is that it helps give us
answers to questions that we previously
didn't know I see the relationship
between different outcomes and so I like
to point to the Great Recession of the
late 2080 2009 we knew independently
that bonds were risky
there wasn't a full understanding that
there is nearly one hundred percent
correlation between a lot of these bonds
and once one went down everything was
going to go down together understanding
correlations is actually something which
is just simply too hard to do in the
past because the computation necessary
to do it is actually approaches
impossible and so a lot of what we're
doing is actually approximating it we're
looking at the dimensions that are most
important first and then building
outwards and actually having an active
learning algorithm that figures out what
it needs to be checking on next and it's
really exciting to see because we really
think this will actually really change
the way that people think about
predictions and rather than thinking
about them as independent outcomes but
think about them as this whole ecosphere
of possible things that can happen and
how they relate to each other this is an
interesting topic because I was recently
reading something on the New York Times
or some other journal where they said if
you want to continue reading answer this
poll and and that's like a really
interesting way of they're not ads but
their polls but now on the back end what
are some of what did some of the work we
can do to sort of take this crowd source
data to make it more powerful so the way
to make it more powerful is to be
thinking that every time anyone has an
interaction what is the best interaction
in terms of the researcher and one is
trying to optimize engagement and number
two is trying to optimize the data that
they're providing in that question and
so this is a constant sometimes
complimentary thing and sometimes
trade-off that you're thinking about to
say that you have so many times you can
engage with people how do you figure
that out and it all circles back to the
idea that you want to be agnostic you
want to look at individuals and say some
people may answer simple questions some
people may answer complex questions some
people may be thrown into some sort of
detailed game situation you want to be
able to figure out based off of the
things they've done the past and the
demographics they have that aren't
shared with other people you've seen
what you can do to maximize those
engagements both for their engagement
and for the information you get from
them and that's really where the
technology is moving then that's where
they where that you're going to see a
cosmic shift a huge disruption in
21 billion dollar industry that is
really built on technology that 75 years
old now it's built on the same
technology that Gallup and Roper and a
few others pioneered in 1936 before the
computer that can vide the advanced
statistics behind the data collection
and before the internet which allowed us
to reach people quickly and efficiently
so just in closing what's the future for
forecasting given all this stuff you're
doing the future for forecasting is
going to be wide and it's going to be
deep and so whereas forecasting right
now is much more narrow on a few types
of questions you can answer and and it's
very much at a high high gregation what
we're looking at down the line is is the
ability to answer whatever question
you're interested in and at a depth of
demographics or other breakdown that is
unimaginable at this point it's moving
from a world in which maybe people were
predicting who would win the
presidential election to a world in
which you can think of any combination
of any states or which is 2 to the power
of 51 possible outcomes or moving to the
idea of how any demographic is going to
vote in any sort of combination stage
which is you know much larger than that
to thinking even about the conditional
outcomes of Elections on a host of
economic and political indicators so you
move from a very very tiny world a very
high-level tiny world to a very wide and
deep world well this is really good
thanks for spending some time with us
thanks for watching and we'll catch you
next time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>