<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Oded Schramm Memorial Conference: Day Two, Session Four | Coder Coacher - Coaching Coders</title><meta content="Oded Schramm Memorial Conference: Day Two, Session Four - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Oded Schramm Memorial Conference: Day Two, Session Four</b></h2><h5 class="post__date">2016-07-14</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PLYg4kitaE8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">next speaker starts fair enough who will
talk about the the title you can see
here SLE percolation and scaling limits
so it's it's a great honor to speak here
and I greatly admired at that and his
his mathematics and of course most of my
mathematical connections with that that
was through percolation and a silly
though almost if interaction at least of
course before I've read his choco
packing papers and the complex analysis
stuff and I was trying to remember last
week when I first heard about a silly so
actually I realized that I first heard
from Tatiana who returned from a
conference where that was speaking I
think about first in higher dimensions
but he then said that in dimension 2
there is this approach with lobner so I
tried to Google actually that was before
Google okay I tried to search on the web
and the only thing I found was a
research proposal on his web page so it
was still 98 which which says at the end
that I intend to try to prove that my
construction and did describe the loop
arrest random walk scaling climate so I
tried to since there was no text I tried
to reverse engineer from this was
initially is and I still kind of regret
that I wasn't able to to do it nicely so
I I had to wait you to the paper I
peered some time later
so that was one one year later and that
was actually one of sort of my nicest
experience in reading papers its you you
kind of feel like putting together a
jigsaw puzzle and there are these pieces
which Seema like from different worlds
they're completely different then
suddenly like everyone clicks together
and this this was certainly I'm actually
very envious it it's it must have been a
very nice experience to invent a sleeve
as the moment you realize how this all
come together this all very different
things
and and then then shortly thereafter the
first papers of Greg and vanderlin and
no debt and it's that and then actually
understood that this is going to be a
very exciting thing and I actually
remember because that was always sort of
a humble person I remember that I when I
first realized that how excited I'm
about this this was in this first asila
conference in Strasbourg where it's so
nice and it's it's it's just thank you
very much for this great experience and
now and I was trying to understand what
the conformal field theory is at that
moment where I'm sort of still trying
but I said well it seems that we now
finally have there but you need to
understand the - oh and this thing of
yours it would describe over there and
said oh no no I'm not so ambitious it
should give like percolation and loop
arrestor and a walk but maybe uniform
spanning tree but not much much more and
I said no but it's it's sort of sure I
mean your lemma it applies you said he
thought for a few min said oh yeah
indeed it does and that was actually
very nice and so people people people
were saying if you thinks about how he
did mathematics so I kind of my my main
impression that he always had this sort
of two qualities that he posed the
correct questions and he brought the
correct tools which is very visible with
the silly but it's it's also in in many
of other his contributions so he starts
with some question other people post and
then he modifies it and it then makes
much more sense and so it was like with
the silly so you can so I'll try to
speak about the scaling limits how it's
said in the title and he actually made
so this was in mind so from my viewpoint
one half of his great contribution that
he posed the correct question he took
this very nice object a random kerf and
its first it's it's not too much it's
not the whole few theory so it's it's
kind if you can touch with your hands
but on the other hand it
nobody cares all the information and
then he brought incorrect toaster oven
revolution so so people were saying that
he reinvented it so III think he he told
me that actually he kind of he knew
working in complex analysis about it but
he never thought about it in this
connection and then he was thinking
about these perimeters composing random
maps and then actually immediately
gathered random maps which you can post
and the first two coefficients I
additive so immediately come to a fact
that if you have this Markov property
then the first coefficient will be a
Brownian motion and then so we don't
need longer theorem for that you need
longer theorem to say that if you know
behavior of the first coefficient you
know everything and so he said that he
like observed it and then he said that I
must have seen this somewhere and and
then I think he was to in Jerusalem so
there was a library so he went and he
discovered the papers of of Lautner and
but I'm sure without long he would have
reinvented it anyway and so people were
saying that you kind of always liked to
invent his own proofs so actually I
think it wasn't sort of kind of I don't
know arrogant think oh or something it's
it's more like he wanted to have a hands
of a feeling of the subjects and he
preferred having some proof which
doesn't use some esoteric machine you
don't have to read long books but
instead uses geometric intuition and
that he went much more but it doesn't
mean that they were like simple using
simple technology usually it was sort of
hands-on and maybe down-to-earth about
was silly in some sense is down-to-earth
but it's it's sort of with some
interesting twist and it was not not not
necessarily with the proofs so I
remember that like many many of us used
his pictures or his computer program so
I remember that first time I used his
program I need the picture of
percolation so I used this this picture
let me maybe scroll a little bit so it's
a base file so
what what what he did is that he used
that the PostScript is a full scope
programming language so this is actually
a small program and PostScript which so
so this is just a small part of it this
is how it works there are some routines
so in PostScript you have evaporators
you have loops so you see for example
this is for exploring the perimeter
rotation left rotation right and he
draws the random thing and then the nice
twist which he has here is that he
didn't want to sort of he wanted to have
well if you ever needed a picture for
percolation paper of something which
happened so much surely you know that
usually you have to test the ten times
before almost rule actually happens and
you get a picture which look generic so
here so he had this routine picture
which would produce picture and that
then there was a common clue so what
happens if if you run this file if you
press page oh it's one page file but if
you place page down oops okay so if you
press page down it just enters this loop
but it produces a new picture you press
page down produce new and it's produced
Nowell so I didn't know that and I need
the picture for for a talk expository
talk so I send it to the printer and
went off to lunch and well the printer
also is a full-fledged computer it has a
processor which in the sense pass
cryptic language so when I returned back
a year another year so an hour half
later I I discovered that our system
manager was very upset because he
several times tried to stop it but I
mean UNIX was listening it back and
there was you know this big printer like
a Xerox machine which has a few boxes
full of paper so what I had after was I
had about like 2000 pictures like that
and I had to do something with them so
that was very nice because I always
could easily just find a picture to
illustrate any phenomenon and well which
has probably lead to more than one in a
thousand and I used them as a scrap
paper so that's yeah ok so this is no
but but then actually I deleted this
loop thing because it turned out to be a
bit counterproductive
so so the other thing is is so as I
remember at that he was always a very
positive and we're a bit and understand
understood preparing yesterday that of
all my memories of him
oh it's except for this terrible day a
year ago Oh a very very positive so it's
what was vanderlin saying so I'd said to
show some pictures to last pictures I
found my mobile phone so this was at the
world war meeting a year ago and we
had a midnight seminar about the future
of a silly and being a bit well so odd
that is laughing well I won't say the
complete story but one of us made the
statement that silly is the most
ridiculous thing he has ever seen and
then added turned to me looking for her
personally
but it describes say scaling climate of
percolation and the answer was well but
percolation is even more ridiculous so
this is what he's laughing about and we
had we had excellent food scooch
discussion there and then the last time
I saw him was a year ago in Montreal and
he was also sort of very upbeat and
happy actually it's not visible in this
picture but he had this this thing on
his head it's like from a bikers costume
with the flames and crossbones and he
was sort of explaining that you know a
friend presented to me and I I have to
wear something on my head I'm a bit yeah
well so that was a very very nice
conference and actually Stefan and Diane
Carrasco organized I can sort of a silly
conference which goes a bit a wider this
year in May so we'll probably put
together a web page and send an
advertisement next week so those of you
who are interested in the silly or
related things with Rogner Falls please
please come all those who are not yet
interested please get interested so it's
in a ETH Zurich conference center which
is in Swiss Italian Alps so it's it's a
view view from that that place so it's
like a number wall folk but in the
mountains so so the title I now I think
I've switched to the blackboard so
I I will be discussing skill increments
of percolation and we were discussing
them with audit on and off for like
about eight nine years and excellence
what what when didn't mention that when
oh that was writing papers alone he put
more personal comments in them and email
him and put more personal comments so
this is what he thought about the the
scaling climate I like actually some
touches that I'm not sure that we have I
have the foresight to decide on the
definition now but maybe we should
attempt it for the rise who knows what
will happen and the thing is that I am
NOT
I don't think low as he writes I don't
think we have any idea the Phoenicians
for the scale increments because in part
it depends on what you want to do with
it maybe you want to connect it to a few
theories so maybe you want to do some
noise sensitivity things over here
spectrum like Christoph and Gobber are
doing who we doing with a debt or maybe
you want to calculate the dimensions so
so I don't think why skew I mean that he
wrote a few years ago probably four or
five years ago but I don't I don't think
we actually have an optimal definition
now so I will be discussing one possible
definition and it's sort of a joint work
with the debt which which is for one
specific problem for one sort of noise
sensitivity and I want just to add one
thing I like about the silly it's not
even the sort of it gives a definition
of the scale increment but that more
that it's sort of hands-on you can it's
it's very nice to prove things with so
it's really made the more important not
as a definition but as a as a tool and
if if if if you want other definitions
that can be used to do other definitions
as well so now I think I'll take I'll
put this thing up
Wow has intelligence of its own so so it
starts so III I will sort of discuss a
theorem which
can be essentially stated that the
collation in the plane is a black noise
and someone already mentioned the word
noise here but not giving a definition
so it's so I'm not going to give a
definition of a black noise I would say
bit what is noise so it starts with the
work of serial son and very chic so you
draw two or three exposed to his papers
by citizen which I highly recommend so
what one of them is his talk at the ICM
which has half about it and the other
one there are two versions probability
surveys and some floor school is the
same warmest mandolins course about the
silly where he discusses the what what
is is a noise and in his language
essentially noise is a continuous
product of probability spaces so he
mostly works with the spaces indexed by
a line so you assume that you have a
let's say space Omega with the Sigma
algebra F and some probability measure
mu and then there are Sigma algebra F
indexed by real numbers with the
property that F is the limit of those
algebras if she goes to minus infinity s
goes to plus infinity then this algebra
FG s a translation invariant and also
that if you take algebra TR then it's
it's a sum of algebra G s and s are so
it's so f s are so so one thing you can
think about is the white noise that that
would certainly so it's it's kind of a
random object indexed by a line which is
kind of infinitely divisible and
translationally invariant so so the
obvious example is white noise
but what they did they constructed some
more interesting noises which there is
still some calls black noise because so
his his motivation is that the the white
noise spectrum is constant so you see
all frequencies and that's that's the
white color and black noise you don't
see any frequencies so there is no
linear response so we have to have some
more difficult machinery to to detect it
so I don't go into exact definition you
can read the solutions papers it's a
it's it's a very nice experience and so
they construct some example we use using
the brown and the web and so there is an
original paper turns on and were shocked
and then there are some papers of cereal
song and the questions they they ask
there is whether you have some object of
this type index not by real line but by
a plane so of course you can do white
noise on the plane so you can have white
noise on the plate by K you have more
complicated noises indexed by a plane
and the the canonical sort of so other
interesting examples interesting
examples on a plane so what what you
would supposed to be having there
instead of these properties that if you
have to so here there are two disjoint
intervals and sum of Sigma or job is
Sigma job of the big intro so you should
have if you have two domains say you cut
the main G in the two part G Plus and E
minus you would want to have a property
that FG is the sum of F G Plus and if FG
minus
and so I think that series on ask this
question this sunflower school whether
you can get such a thing from
percolation so in percolation certainly
you would have if you construct some
scaling climate of percolation you would
have this property translation
invariance because any reasonable well
the models translationally invariant and
then you would have the property that
the percolation pigeonhole plane you can
exhaust it by domains so the the main
question if if you have recollection
picture in some domain and you cut it in
half whether whether you can reconstruct
the whole picture and the there are of
course potential difficulties so but
also difficulties are I don't know it's
not visible for either slow or what
where is the line well under which it's
not reasonable it's okay or I should it
will even write higher that line is okay
okay so so what what so the potential
difficulty is that there is some
information stored on this line so so
basically there are there are two
questions one question is how would you
define Sigma algebra F so what is the
percolation configuration because there
were several definitions proposed in the
in the terms of like sets of all curves
as crossings sets of interfaces you can
do some height functions also for for
percolation and the second thing is that
how to prove that there is no
information supported on the line so now
so we're asked not to get technical now
I get technical no that's that that well
it was a joke so now I'll try not to get
technical it just so that you all looks
up at the blackboard so so some first
some motivation why there should be no
information stored on the line so maybe
two remarks one remark is that for
percolation the
by probability of being so the dimension
of private all-points so dimension of
their I have a toast it's more than one
so it's three quarters so it's it has to
do that with the probability to have
from some scale to another scale to
black arms and to arms of the opposite
Cour so if you have let's say this is
size one and this is size epsilon then
probability no matter what is the
measure of the latest probability is
moderated by epsilon to the power five
quarters so the dimension of the set of
pilotos is three quarters so what
happens that if you take a line then
basically the probability that you touch
a PI over two is zero because life has
dimension 1 pi widows has dimension 3/4
3/4 plus 1 is more than 2 so there are
two independent cells so so if you throw
a line on the percolation configuration
it's there is chance zero that you hit
the Perito and vice versa if you fix a
line there is chance zero that you'll be
there so this actually has some color
that you cannot take an arbitrary curve
here if you take curve here which has
dimension bigger than five quarters then
the whip I might also need so you are in
trouble so there will be some
information stored on the line so if if
I denote it by alpha so if whose Dorf
dimension of alpha is smaller than five
quarter we seem to be okay and the other
remark it's it's a sort of so this this
is sort of this such sort of arguments
they go back to early work of a debt and
to berate errs on the sensitivity of
percolation what how much flipping you
can do so that you don't change their
crossings and the second remark is that
if recollection is about crossings and
we look at the crossing so if we split
it into two parts
well there is there is
exponent so if you look at the expert
the probability that probability that a
cluster touches given box so this it's a
expecting half plane then this will be
actually this is comparable this will be
comparable to absent to the power
one-third so the dimension was north
dimension of the cluster intersected
with the boundary of the plot so it's
Custer in G Plus only it's equal to
two-thirds so if you have two clusters
to be clusters which touch this from
above and below dimension is 2/3 here
dimensions to serve there and 2/3 plus
2/3 it's bigger than one so you have two
independent sets of dimension 2/3 there
is a positive chance that they will
touch so it means that if there is a
crossing then there is a positive chance
that there is a crossing which only once
intersects this line and in this case if
it only once intersects this line by the
first remark there is no sensitivity
there is oh no there is no information
stored on the line you cannot flip this
because it's the probability that that
on this line you get by vatos is zero so
in the in this in this case so there is
a positive chance that there is no
sensitivity to this line then you could
do this so this is sort of an easy
counting car gameand and this is the
actually I want to ask a question I
still don't know da so that I did
somehow didn't like this question so
that I would ask another question which
he liked with the question which I liked
is it always true that if we have a
crossing then you always can optimize it
so that it results the line only finally
many times so is it true that
probability of having a crossing is the
same as probability of having a crossing
which intersects only finally many times
number of intersections of this crossing
let's say gamma intercepted alpha is
equal is finite
well in finance real we always get to
find that number of crossings no this is
this is odd so in fine tram it's the
question is whether it is tight and
because here I what didn't really
specify whether I'm working with the
final trio and uniform estimate so I
that was implicit or I work with the
scaling climate or subsequently on
scaling climate yes yeah that's that's
that's that that that is actually what
what is likely to happen that infinite
rearm you don't you probably won't have
a finite number of crossings but what
what you would get is that there are
finite number of groups of
infinitesimally close crossings that's
possible but I don't know I'm not sure
it's it's kind of zero one law question
is that you have a an event which has
positive probability so this doesn't
have the full probability or not
so can you optimize because in general
percolation crossing it has dimension
bigger than one so if you take the
leftmost course in his first dimension
4/3 it will intersect this line
dimension 4/3 minus one one-third so
when a counter said if you take the
shortest crossing I think there is no
physical prediction but numerical
estimates show that it's 1.15 so the
shortest crossing will have dimension
intersection of dimension of point 15
but here we want to optimize in a
different way not the shortest not the
left most but the best with respect to
this particular line can you optimize so
that it will have only finally many
crossings so so I I don't I don't know
but it's it's it's a nice question and
actually it's if if it's true it would
simplify most of what I will be speaking
about and also it will give a sort of
much more straightforward construction
of the scale increment because to be
very easy to blew the squares together
you can't oh well that's that's what
that's what I what I just said
so it's let's have a vote democracy so
who thinks it is not typed who thinks it
is tied four to one I mean that's the
problem with democracy only well
whatever well the trial will be our
representative for this question yes yes
yes yeah yeah that's that's that's this
yeah that's the secondary mark yes oh
it's it's you know it's sort of the
middle or zero one law let's say no
image you can name it after ahsoka Mahal
phase zero one law about tell
sigma-algebra send for all sigma
lubitz's through that any reasonable
event has either full measure or zero
measure so this has positive measure so
it has to be food so it's no way because
there are the possibility is that you
can minimize that admissibility is that
some capacity kicks in some complex
analysis that you have intersection set
which is zero of some capacity and then
it is okay if it has positive capacity
then it's not okay to glue two things
because what I was speaking about that
you can glue two things and determine
the configuration if this would be true
the route for the terminal configuration
will be very easy you take think above
you take all quadrants or loops and then
you ask whether you can combine this
infinite way so for example this would
be okay one two three four jumps and
that's it
if if if this conjecture is not true
then you very procedural fatigue
procedure exists there is
non-constructive proof then constructive
procedure would test this this set of
jobs for some sort of capacity criterion
and it would be interesting for a
complex analyst but probably very
difficult yes yeah because there are two
independent sets of dimension 2/3 well
you need more okay okay there yeah yeah
yeah yeah yeah I'm not that that's a key
I know that I need more but I have more
yeah that's that's it's absently
decorate decorrelated yeah so it's yeah
at least once once I checked it and it
seemed to be okay I don't know it's if a
unless of course this is time-dependent
this problem then so so so so the thing
which we shall be speaking about let me
maybe start here so the theorem the debt
is that for scaling limit of percolation
of critical percolation critical
percolation on triangular lattice or any
subsequent limit subsequently limit on
square lattice
you have this property so the the
sigma-algebra
in G is the sum of two sigma-algebra sin
G + and G - so it's and so well I mean
strictly speaking you pro also have to
trade sigma-algebra of measure zero sets
so this this is there a form or and so
III I mean so here for my scaling limit
I I just mean that what we take we take
the Sigma algebra of percolation on a
lattice and then we we take the limit as
the limit of Sigma algebra and then
after the profile say bit how we
actually construct it because that will
be important for the proof because in
the proof one specific way is used so
the proof one actually has cask has to
be careful here because since we are
speaking if if if we do the discrete
version if if we just sort of try to to
use this estimate to show that there are
no Paiva toes on this line it works for
the discrete version but since we pass
to the continuum limit there is some
trouble there because you might have two
different configurations which converge
to the same configuration the continuum
limits so there for the latest with mesh
epsilon the distance between them says
square root of absence so they get
closer and closer
so actually what one has to do one has
to show that if you have two
configurations let's say Omega 1 and
Omega 2 so that Omega 1 is approximately
Omega 2 like of Alpha Epsilon of Alpha
let's say distance is s of alpha and
then there like Omega 2 is and Omega 1
resampled completely independently in
neighborhood of alpha
so sort of independently the same boat
near alpha then with high probability
with high probability the risk crossing
chronometer one if and only if there is
crossing can Omega 2 so the discrete
version would be a so there is crossing
in Omega 1 if and only if in Omega 2 so
the discrete version would say something
like that that the upper limit as the
mesh goes to 0 of the percolation
measure in mesh so this is percolation
or on a grid with a with a step mesh and
then you take the event that let's say
the probability that there is a let's
say it like that probability that there
is a crossing given condition on the
sigma-algebra of F and G minus s
neighborhood of alpha is between Epson
and my mind ception that this limit is 0
so if if you if you know this Sigma
algebra then you would know up to
epsilon that the crossing TD exists or
doesn't exist so so here now if we prove
it draw there are two parts one has to
do one has to tackle that we can we
should resample near alpha one has to
tackle that which we can move it off of
alpha and then when this is done one has
to sort of say that well this takes care
of one crossing event and
that this crossing Kewell's indeed in a
nice sense generate our sigma-algebra so
that there are three problems so first
the top chapter this is okay when you
perturb of alpha when you complete your
step on em near alpha and then say that
if you just checked it for one crossing
event it is enough that the collection
of all crossing events in nice way to
raise the Sigma algebra so maybe so what
do we have so I I will I will just sort
of go very fast over this and then we'll
go to the scaling limit so here there
are two parts so well one one part is so
what what one does one introduces
another configuration let's say Omega 1
prime so this is we just resemble near
alpha and this is we perturb a little
bit of alpha so this first part is okay
so the first part is okay by this v
quaters estimate so this goes back to
our other noise sensitivity papers so
basically what you do you so let's say
the probability that there is a crossing
in omega 1 but not in omega 2 and you
take this band of which s around our
curve alpha so what what you do you you
cut it into squares of size s and you
start very simply the squares 1 by 1 so
the total number is 1 over s so it's
basically at most 1 over s probability
that the same happens when you re sample
n square so it's it's probable value
let's say there are this you actually go
from Omega 1 to Omega 1 1 to Omega 1 2
etc etc and then you go to Omega 1 1
over S which is Omega 1 prime so you
just start resembling the squares
one by one and what happens if that very
simple a few squares and now we're
sampling this and crossing disappears
reappears well it means that in this
square we would have a private oh for
our configuration so we'll have pitch
like this so probability that there is a
mr. pirate Oh in this square small
square Q and probability of having a
pirate oh it's s to the power what was
that five quarters so it's as to the
power one quarter so as that goes small
this goes to zero so this is not
problematic and now the second part if
you go from Omega 1 Prime 2 Omega 2 so
now you have two configurations which
are same here but I perturbed so let's
say this is Omega 1 and Prime and this
is Omega 2 Prime their perturbed off of
the line so now one has to be careful
because if I just do it in a damp way
like here then indeed we can easily kill
something because we can for example
have a crossing which has a small part
here which is important for the crossing
so it goes for example like that and we
perturb it by up so and this part
disappears and there is no uniform bound
on epsilon because it can have arbitrary
small ones so what what one does one fix
is another parameter so let's say there
is a which s and there is a which s
Prime and then what one does one takes
well there are there are two Sigma
algebra see there is a sigma algebra F
of G minus alpha s there is Sigma
algebra of day of F F of G minus alpha s
Prime so this has less information
because you you take away more things so
it's contained in this and one
introduces another Sigma algebra
say SS prime which basically has all the
information here maybe let's let me put
a list in blue plus whatever you have
parts of the clusters which which are
sticking down from this up to the place
where they might touch this boundary so
it doesn't have completely this tree but
it has whatever can be important for us
and with this one has stability because
if if s is much smaller than s prime
these things they they will become they
will have good control over them and
they will become stable because you we
we no longer we no longer care about
such small such small things and we are
no longer care about things well there
are two types of things there are things
which don't reach the bottom and things
which reach the bottom so the things
which reach the bottom they are long
enough so that stable on the epsilon
perturbation if epsilon is small enough
if it's smaller than s prime and the
things which don't reach the bottom we
don't care about them so it's it's based
basic basically this thing so so in if s
is much small s prime if let's say
distance between Omega 1 prime and Omega
2 is much smaller than s whatever that
means
in inside in some sort of metric then
then there is a stability again by the
arms estimates so now this is basically
the idea this is short part but the more
interesting part is that one even wants
to have a proof from that so what what
we what I sort of described here is that
you if you completely know the collation
picture here and there you can
reconstruct whether you have a cross in
cannot with high probability now the
question is this enough to reconstruct
the full percolation picture so if you
know all the
sings is it enough well if you know all
the kids enough but here it's like for
every crossing quick up to Epson can
reconstruct this crossing trend this can
accumulate so you have to have some
control over it and this this brings to
this quote from my debt which which also
has to do with the definition of
percolation limit so we we discussed it
many times and so as his quote from his
show so he prefers a definition where
you already have some limit not assuming
anything difficult so I in a sense
preferred always that you would work for
percolation is very easy to do something
like Rousseau same or well so
immediately have that crossing secured
the perimeter is curved so you already
have a lot of things now added maybe he
was looking forward to two other modes
saying that it's it's sort of it's it's
it's a bad thing to do this it's better
to have something where you have a limit
not not assuming much it's it's more or
less the same with constructive Brownian
motion you can you can first prove that
the brown and motion trajectory will be
held there continuous and then prove
that it exists and of course it's easier
to prove but first you have to do some
difficult to occur you can first prove
that it exists as a as a measurable
function and then prove that it is
actually continuous so in so what that
prefers prefers this approach and so the
definition which which he liked and I
think sort of he was thinking about it
long before a silly so okay so that
definition
you take so in in a sense the way
percolation model was from elated was
the question about crossing rectangles
so take the space of Oh rectangles to
power to cut rectangles and the
probabilities of crossing them so you
take let's say so I just called them
quads what Q is a map from square or a
continuous map from a continuous map
from a square into our domain no so you
think of such a thing
and now the regulation configuration so
let's say the collection configuration
Omega Omega is the set of Q which are
crossed
meaning that between two horizontal
edges there is there is a crossing so so
this works in the discrete setting and
then of course percolation murder mu is
a probability measure so me with some
mesh absent is a probability measure on
on the space on the space of
configurations
I haven't said what is the topology and
then you pass to a limit now so this is
this is interesting because we had big
arguments about this so III my idea was
it again you should use these properties
of smooth while not of smoothness but of
continue to her the continuity of
crossings and that was saying this this
is an overkill so he came up with the
abstract construction which was only
using the ordering of the quadrangles in
the plane so there is an obvious
ordering that if if I do two quadrant
goes like that so this is the second one
and this is the first if there is a
crossing over first there will be a
crossing over second
so what one can draw more more
interesting example so it's it's that
well this this is also a quadrangle so
it's so there are there are more
intricate things but this gives us an
order so you say that let's say well
first of all you define that the space
of Q G is a Q a space of OQ with uniform
metric metric and then you define that
q1 is at most q2 if a crossing crossing
q1 implies so let's say crossing q2
implies crossing q1 so here it's on the
opposite so this is Q 2 this is Q 1 and
then you can since we have this metric
its uniform matter just of the
embeddings we yeah there is there is
actually here I mean the same quadrangle
is given by a few embedding so we
consider them separately so this this
gives another slightly better or the key
one is more than Q 2 if neighborhood of
Q 1 is smaller than neighborhood
neighborhood of Q 2 so for example such
thing won't work because you can perturb
slightly so one has cross again another
not but the original I drone is either K
and what else you say that so I've just
finished with the definition and then I
won't prove anything say that s in this
space of quartz quartz is hereditary
some subset is hereditary if if Q inside
s and Q prime smaller than Q
Plus Q prime belongs to s and this is
the property which percolation
configuration has because if you crossed
the big part then you cross the small
quad and then HD is the set of s in Q G
which are hereditary and G is minimal
the poetry generated by and Andhra one
has to construct two two to take to two
types of sets so let's say for open
subset you you take the sets of s such
that they don't intersect don't
intersect you so that intersect you
because it's a stable property if you
intersect something open it stable and
for closed set so it's enough to take
points you take such s that so four
points what should be stable that X does
not belong to s and then the well this
is the space so HD who is T G where G is
where percolation leaves so the
interesting thing is that indeed we
don't it's it's a very abstract setting
you you you can start so the way most
things approved about this that is for
example it's a compact hausdorff space
so this proved only using this mountain
is the property of percolate
so essentially you start with any
topological space which which has an
ordering you do this construction and it
will it works and I remember that
so we're discussing this and then when I
had said first dot C
he said that we expect that the
following very general result is well
known but haven't located her reference
so it's it's again hitting there in the
earlier commands and exercise since
tried i i i found one reference it was
in my general topology notes from the
university but I can't find the book
so so so so maybe maybe it's it's it's
some hearsay
so now so this this this is this is how
it works if I get into it it's it's
rather technical so I wanted them to ask
a question which was a favorite question
of a debt and also of myself so what
yeah this gives you limits and
subsequent show limits and then this is
enough actually to set up the thing here
that this is enough to set up things
that actually sampling finite number of
quads is enough to reconstruct with
probability epsilon the whole picture
so it's this this sort of compactness of
this space and then if you want to show
that the percolation so this gives you
some sequential sequential C limits of
percolation easily if you want to show
that there is a there is a unique limit
for triangular lattice then one has to
run a silly branching Casilla so do
something one has to do something so
this is one has to do technical work do
we didn't know anything which which
would be sort of straightforward so the
nice question is is what so where was
one question I've written yeah okay so
let me maybe raise the noise from
blackboard
so how much much one needs to construct
well this space and this Sigma algebra
so let's say F and relation measure mu
in the space age so what what what one
does for triangular lattice one uses the
property that we have the formal for any
given crossing we have locality to have
monotonicity
so this is the only properties which are
used in principle you can use that some
continuty properties to they they
simplify the life some sort of continuty
so the question is whether you can take
away the card the card the formula so if
you have some percolation measure in
this sense so there are this measure on
crossings of the quads which has
locality property which husband well
when x the property makes this stop
working we will do it what one is to us
so that it gives you the critical
percolation
let's take a grab I'm not reading it
break and then they will have questions
that you're about both
our next speaker Scot Sheffield SLE
scaling limits and the Gaussian free
field first I want to say one thing
about Oded in that he was unusual in the
extent to which he helped other people
solve problems if you you know look at
the you could maybe divide up you know
the problems he worked on there were the
problems where he actually co-authored a
paper then there were problems where he
really contributed something very
pivotal to someone else's paper and
maybe he didn't want to be a co-author
he didn't want to write up but he was
happy to help with someone other else's
paper and there were problems where he
you know wrote it up in a Mathematica
notebook and sent it to people or wrote
emails very detailed arguments there
were problems that he solved and
communicated directly with individuals
there were problems that he and his
co-authors totally intended to write up
one day knowing as these things usually
go that you know other things might end
up taking precedence and then there were
problems that he had no intention of
ever writing up even while solving them
and was just did because they were
enjoyable and and they were people
learned something in the process of
working on them and you know even when
you go down into layers 2 3 4 &amp;amp; 5 you
know you find there are things that
would be in other people's level one you
know he really had remarkable results at
all level and the and you know the
published results with his name on them
are only a really a small part of I
think what he accomplished in and gave
to us um today I'm going to talk about
proving things converge to SLE so SLE
you know has now been the topic of
several hundred papers building on
you know Dead's early weren't
constructing SLE and you know the
problem of proving discrete models
converts to SLE is just one aspect of
that but it's a I think a very important
one and it's one you know when people
visualize SLE often what they have in
mind are these you know these discrete
models with scaling limits and it was a
very I think a very important part of
the of the field and so you know dad
sketched out some ideas in this
direction in his first paper and the
real hard work was done by Lawler from
vendor by the three of them in first
approving the first gaming limit result
for a loop erased random walk and an
uniform spanning tree and so the the
method used in that in that paper was
the same one that was later used in the
other papers oded worked on with with me
on proving things converged to SLE and
you know and variants of this were were
used by Stas as well in convergence
proofs with you know maybe modifications
of two and three but the you know
essential idea is well you you start you
want to prove something converges to SLE
what do you need to do well first of all
you have to say what convergence means
and you have some discrete paths you can
define and you would like to show that
these discrete paths get close to some
sort of a of a continuum random path
and the first thing you need is is well
as some sort of metric on closeness and
and so the way I'd like to think was
first we'll look at the low of noir
evolution and um so if I pick a point in
the interior of my domain to call the
center we Khopoli map to a disk so I
have this at this point in the center
then as I draw this path I can look at
the low of noir evolution function W sub
T that essentially tells me at each time
when I can formally map back what is the
image of the tip of the path and as we
all know by now just knowing w sub t
lets you reconstruct the path and so if
I have a sequence of discrete paths WN
converging to some other path per thing
I might say is well this path is close
to this one if somehow these functions
are close and and so the local
revolution perspective gave him a
natural metric on this set of paths you
know these two paths are close if they
are have about the same capacity time
and if I you know that the end points
occur about the same capacity time and
if I draw the two paths the to Lovan or
evolutions W sub T's I find that the
supreme amidst install and so that's a
definition of closed paths are closed if
in the low of no sense you would say if
this is smaller or informally he would
say you know view from this point these
paths are harmonically close together
you can't see the difference between
them viewed from this point
okay so so this gives us a metric on the
set of curves and then the first thing
you might try to do is is prove well so
this is actually a second thing step two
you might try to prove that these random
paths converts to this one in law so in
distribution that means weakly with
respect to this particular metric and
and then once you've done that you might
like to strengthen the topology to a
more natural metric where you would say
two paths are close to each other if you
compare them at Rice the two in such a
way that for all time the two paths
don't get far from each other and so
oded sometimes call that the strong
metric on on paths so you could start by
proving convergence in this woven or
driving function metric and then proceed
by continue and strengthen the topology
and prove convergence in this strong
sense but what Odette always felt was
the the most important step was this
this step one which is what he then used
to do step two and three and Capone was
just find something about the continuum
martingale or the continuum SLE that
looks like something in the discrete
picture and this is you have some
martingale so what would that be well
for example in loop race random walk
it's something involving the greens
function and and so you have a point you
can look at a greens function viewed
from the tip and you have some some
function that's varying as the path
changes and if you can show that that
function is a martingale for SLE and it
is approximately a martingale for the
discrete version then there's
magical arguments that let you just from
that information so the driving
functions converge so I think a key
observation of this well more than an
observation of this this lolicon burner
paper is is is this this principle that
having this some kind of martingale
observable just this one object lets you
then deduce that the driving functions
are closed and and this is a beautiful
argument and you know III don't have
time to to really prove it and would be
the wrong person to do it anyway but I
will at least show you the paper so here
it here it is the this is the the paper
by Lawler
shramana and Burnett was in annals of
probability and this was you know part
of a hugely productive string of papers
that in between roughly 99 and 2001 by
by these three authors and well you can
only see from the contents here what you
do you know you uh you define a loner
with evolution you defined a discrete
version and you you give some background
and you recognize the driving process
using these magical tricks and then you
strengthen the convergence to a stronger
topology and that gets you loop erase
random walk vinyasa le and similar thing
for the piano curve the boundary the
uniforms banning tree first you get the
driving function then you get uniformly
continuous and then you're done and you
need various estimates and okay I don't
know this it gives you a nice raw rough
sets what's in the paper you can all go
read it of course alright so
here are a few of the the SLE scaling
limits that one should have based on
various ideas from from physics and and
math so first Kappa in two and eight
these are the campus come in pairs one
being sixteen over the other by this
duality relationship so so two and eight
were handled in this original paper and
the next thing is you know eight three
and six which is related to self
avoiding walk and and critical
percolation and so so this self avoiding
what well okay now that you've seen all
these I'll show you my my color-coded
version so so these are things that
they're that are solved so critical
percolation so this you know I guess you
say is is due to two Smirnoff so there
was a you know there were some more
detailed arguments for the the latter
steps that were given by by kami and
Newman later on you know filling in
parts that starts didn't completely
describe but you know dead always felt
that once you had step one the rest was
kind of easy you know at least at least
for him and and he felt that you know
that uh you know one stars had written
this Michael Pollan very instead the the
extent you that SLE was essentially done
and he he wrote always referred to it
that way and said that you know it's
done that that proves it because you
know he knew exactly how to how'd it go
from there they're so critical
easing cluster boundaries and FK
clusters is is working progress by by
Stas
and this cap equals four harmonic
explore and Gaston field level lines
were works that uh III did jointly with
Stas and double diner model like put in
green because I Oh wit though dead
that's right
and double diamond model I put in green
because I I I have a hunch that Rick is
going to to solve this some someday soon
now but anyhow it deserves to be in
green I think okay so well before I
arrived at Microsoft I I was I was
sending Oded or emails during the summer
telling him that I would really like to
think about level lines of the of the
Gaussian free field I thought it was
very interesting I had doing my thesis
with with Amir I had worked on random
surfaces and I had read some things
about the Gaussian free field and and I
know from talking to Oded and and Rick
earlier that there were there were some
connections between the Gaussian free
field and there was this conjecture for
the double dimer model that that you
know we had talked riot talked about
with Rick and and Oded and they had you
know known about for for a while which
is that you know this should look like
SLE for and and again it was well you
know and the problem of course is that
we could not quite get to the level of
step one you know we had the martingale
in some sense we had the discrete
martingale what we couldn't estimate it
couldn't show it it was approximately
the continuum martingale and but you
know based on this I was sort of in
emboldened to think that well
okay all I have to do is come up with
some model where I can do step 1 and
Odette has assured me that everything he
has done will work and steps 2 &amp;amp; 3 will
just fall into place so they sort of
freed my mind I was a little intimidated
by steps 2 &amp;amp; 3 so I could just focus on
step 1 and and so I started to think
about this let's see okay I started to
think about this this harmonic or this
Gaussian free field and I you know sent
to him all kinds of emails during the
summer most of which contained ideas
that you know we're half-baked and
wouldn't work and he would explain to me
why why they wouldn't work you know some
you know it seemed like well can't you
define the level lines of the gas-liquid
field right in the continuum you just
you know you you take zero boundary
conditions and you condition on say all
the level lines hitting the boundary and
you know you've got zero boundary
conditions on them too and so
conditioned on that you you repeat the
process and somehow this fills up and
gives you all the zero level lines and
and you know and he explained it this
structure just simply cannot be right
because you know you're just going to
repeat and everything's going to be zero
in the end and and you know you know the
expected you know like the variance of
the average height on a disc like this
and you know that as you're observing
these zero level lines you're learning
information and it can't be the
conditional expectation is they'll still
zero when you're done no matter what and
so so there was there was clearly
something wrong with the picture and you
know despite many tries and and finally
at some point decided that we had to do
something more along the lines of double
diver make this model look more like the
double diamond model where we understood
it and and we had in mind
stas his argument on the hexagons and so
we thought well let's try something with
hexagons and
and that's where we we came up with this
this harmonic Explorer so I guess I I
well no I guess I that was next we came
up with it the idea of taking so let me
look let me first give these references
and then I'll move on with that
discussion so our first reference is
scaling limits of Lu price round and
Joaquin force planning tree by Schrom
and then next this Lawler strawberry
paper these two were with the scaling
limit results that I worked on with Oded
this is in green because it's not
finished yet but it's part two of this
paper that hopefully will be finished
and this is in green because this is a a
joint work that I'm writing now with
Nike Sun which was something that I
think it was sort of was started
thinking about with no dead to go in
this big paper and it kind of ended up
on the chopping block I think from
Odette's perspective maybe it was in
category three or four you know he
didn't want to want to finish it but but
it was something that you know I thought
was was was quite nice and now we're
trying to Nike and I finish this up and
so all I'll mention that as we go so
okay so first of all the so the discrete
Gaussian free field well you have a
function on a graph you define an energy
which is proportional to the sum over
all edges of the difference in the
function between one a neighbor and one
endpoint of the edge and the other
squared that's sort of a you know l2
norm of the discrete gradient if you
will and you define that energy in the
discrete gas if we feel it's a random
element of the set of functions on this
face where the probability is
proportional to e to the minus this
energy over two
and because this energy is a quadratic
function this turns out to be a Gaussian
distribution for particular covariance
and um here's an example of what it
looks like if you fix the boundary
conditions to be zero and just look at
the the fluctuations this is a random
Gaussian function and so we had this
idea that if we could just set take some
boundary conditions where we set zero
boundary on one side and positive
boundary on the other side of some
lattice and then we try and you know
lattice and then we color according to
the sign of the of the function so black
means the function is negative white
means the function is positive if we did
that then there would be a picture like
this where a dual picture that would
look kind of like percolation and and so
we'd have this natural path which is
sort of an interface between negative on
one side and positive on the other and
you know so and somehow it's you know
it's zero in the middle so it should be
something like a level line of the free
field and and that's what we did we also
had variants using if you set the
initial boundary highs to be something
else then you get something else besides
SLE for but the theorem here we proved
if you take these these magic initial
boundary conditions then the interface
converges to SLE for and okay so and
here's a picture of this we take these
boundary conditions - down to one side +
on the other side we draw the interface
here's another view of the func
so we're seen as a function you can't
quite follow the interface but it's
there
here is the expectation given the values
of the in on the interface and you see
it's roughly constant on one side and
constant on the other side and and so we
realized that if we could prove that
this really was roughly one constant on
the other side and roughly one constant
in the other
so we really had this kind of constant
height gap between the two sides then
that would be enough to give us the
control on the martingale we needed that
would give us step one and and this
machine that oh dad had built would then
churn through steps two and three so so
we we proceeded to prove was called the
the height gap lemma so we went you know
we use the exact same steps one two and
three that were in lawler
straumann barriner and but we took this
the martingale to be this function which
is the harmonic extension of minus
lambda on one side and plus lambda on
the other side of the path and that's
something that turned out to be a
martingale for continuum SLE and a
martingale for approximately a
martingale in our case okay so um here's
a picture of the zero level lines from
the boundary which was just kind of
pretty we were also able to describe
this game in limit of this um so this
paper you know I started this with Oded
in the in the fall of 2002 while
finishing my thesis as I mentioned and
um you know I kind of a busy time I had
my first child coming in December and
and as thesis I wanted to get done but
it was it was really so exciting you
know it was like a drug I was an addict
you know coming to work on this and and
kind of by uh you know February March of
2003 we sort of had convinced ourselves
it was going to work and as we came up
with the sort of fair distribution I
said look I've still intimidated by this
these steps two and three I'll just do
step one and you ride up steps two and
three and we'll divide it up that way
and you know it turned out that
one was more challenging than I'd
anticipated that ended up being the the
core of the paper and eighty pages and
highly technical and at some point I did
have to you know return for assistance
and you know it was you know very a
collaborative effort finishing that that
that's that step one which was very but
but very enjoyable um I want to show you
some emails from just while we were
finally finishing up step three in in
2006 so three years later after many
distractions including other joint
papers with each other we were ended up
somewhere between six and eight joint
papers together depending whether you
count the ones that have not appeared
yet but so you know these are fairly
mundane emails as we go through and and
try to decide how we're going to handle
this step three you know what are we
going to do you see Rick and stassi's
name here see oh you missed its Donna
looking up and and hope you all could
follow this you know at some point we
decided we would leave out the
identification of lambda till the second
paper which it is that second paper is
still pending but uh should come out
soon Oded says we can decide to say a
few words there's a trailer about how it
is done in the next movie I mean paper
at some point he you know came up with
his own version of the topology
improvement and so it's at some point we
sort of had competing versions of this
this lemma and well we ended up going
with his version
the problem was we wanted to prove his
convergence also when you have other
boundary conditions so you know not just
plus or minus lambda but some other
boundary conditions and in that case it
turns out the path hits the boundary and
and this step three actually became very
subtle in that case and it was supposed
to be the easy case but it you know we
had to do a lot of work to prove it and
um we ended up giving up in deciding we
would not prove it for the boundary
hitting case we would only prove we
would prove convergence into strong
sense for the the general case and for
the boundary hitting case we would only
prove convergence in the driving
function metric and um so let's see if I
can get this to show some of these
discussions
so you know I plan to do everything in
another paper but he said this would
take a long time maybe we should make
the topology upgrade pending some
modular result I'm not so careful of
using other technology and doing this
all directly you know are later it's
also we'll have to rely in some sense on
these earlier papers but I think our
primary goal should be to release a
clean paper proving the contours in at
least one form converges to SLE 4 we
want we can also refrain from submitting
it before we are happy even if it's well
with the rest of our plans because
you'll be excited explicitly in the
introduction and no we want you know
back and forth on this I have about 15
pages of emails which is just sort of
you know these mundane sign deciding
what we're going to do how much we're
going to prove and what we're going to
leave out and exactly the paper already
ended up being 130 pages and you know
what are we going to cut out and at some
point you know I gave in and decided we
wouldn't do the most general powerful
part but do you the part we could
actually finish and you know I read over
your version you know it's it's shorter
especially since some of the results
could be needed as preliminaries and
mine anyway but it's less general
there's a trade-off as we knew between
how much we can gain and how much we to
be gained by having more general and
well modular proof of course we can
pledge to include a more general module
hoop in a later paper which may even be
better and that and you would get more
in tension that way but the utility has
to be discounted based on what so i
rambled on for some time based on the
distribution of the amount of time to
completion the discount interest rate
okay probability will never get finished
etc we of course can make reasonable
arguments both ways and owed Ed's
response to this was very terse he just
wrote right since the more specific new
Geopark schemes essentially finished a
shorter let's go with that and you had
enough to feel comfort
and I said well okay so and so we went
with that but um but the longer argument
is is now something that I I'm I'm
working on with Nike and they say this
is an excellent young student you should
all get to know Nike son who's just
starting she just finished at Harvard
and his starting her ph.d program at
Stanford she's been working with Amir
over the summer and she's going to spend
a year in in Cambridge but you know what
was it
the essential thing where we're working
on which ended up on the the chopping
block of the work with Oded is to say
that is it possible that just knowing
the Logan or driving convergence is
actually enough yes okay
alright so I know okay almost a baton
yes so I'll give a quick description of
this so um so so first of all they're
they're these known examples where you
can have paths that kind of it goes up
and down and then back inside itself did
you say us a continuous simple path but
it's sort of wobbling up and down like
this in such a way that it looks really
close to a straight line in the loner
sense and yet in this strong topology
sense it's very not close it's wobbling
all over the place and so so what we
know with with Odette is that well if in
fact you knew that you had Logan or
driving function convergence for both
directions going forward and backward
then you can rule out this sort of funny
business because even though the loner
driving function in the forward
direction of this looks normal in the
backward direction it doesn't and
and it turns out there there is
something similar that holds although
the story gets quickly more complicated
with is it's something very similar that
holds for four non simple SL ease which
is essentially that if you can show it
for a generic point on your path
converges to SLE no matter which
direction you parameterize it in with
respect to the the loner driving
function metric this automatically
implies that the whole path converges in
the strong sense so in fact all you need
a step one and two once you've written a
30-page paper giving this general result
but basically now once you have step one
and two three follows automatically okay
I'll leave it at that
I think we're opening the floor for
questions to the last two talks
especially if you want to have one
speaker about
to the other well okay maybe I should
thank again the organizers and Oded and
uh it's a pleasure to be here and a part
of this and I think you know I I've
often wondered if you could do an
experiment what would happen if Oded had
just finished his first paper on SLE and
had left the rest of us to work this out
on their own how how long would it have
taken us what would we have achieved um
I mean it it certainly would have been
even with all of us in this room I think
a lot harder and you know and
unfortunately now in some sense we're
getting to play out that experiment
since we have to go on without him for
the next ten years but uh you know we're
fortunate to have had him with us and
we're fortunate to have been part of
this conference so thanks to the other</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>