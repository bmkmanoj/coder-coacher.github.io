<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Dyadic Projected Spatial Augmented Reality | Coder Coacher - Coaching Coders</title><meta content="Dyadic Projected Spatial Augmented Reality - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Dyadic Projected Spatial Augmented Reality</b></h2><h5 class="post__date">2014-10-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Df7fZAYVAIE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">spatial augmented reality
next create augmented reality
experiences by projecting 3d graphics
users physical environment
we present a projected spatial augmented
reality system that supports separate
perspective views for two users in a
face-to-face arrangement or dyad virtual
3d objects are rendered so that they
appear as if they are hovering in the
space between the two users we envision
the system to be useful in a variety of
dyadic collaborative interactions for
example in a combat style game a player
can summon a fireball to their raised
hand and throw it at the other player in
another game players can toss a tennis
ball back and forth both players see the
correct view of the action
you
our system which we dub mano-a-mano uses
three standard video projectors each is
paired with a v2 Kinect for Windows
sensor to of the projector camera pairs
are mounted so that they face each other
covering the opposite sides of the room
the third covers the space in the middle
this symmetric configuration of
mano-a-mano
allows for multiple simultaneous views
by assuming that each user is unaware of
graphics projected on the wall behind
them or on their own bodies instead
those graphics are intended for the
other user for example an object such as
the globe is rendered twice once for
each user here we see the desired
rendering for the first user and their
corresponding view in the room here is
the second users rendering and the
actual view in the room
an automatic offline calibration
procedure places all projectors and
depth cameras in the same world
coordinate system here we see the point
cloud of the static geometry of the room
collected from the three depth cameras
the quality of the registration can be
inspected directly by enhancing the
edges of the Kinect colour image and
projecting that back into the room we
expect projected edges to line up well
with real edges
the dynamic geometry of the user and
Kinect body tracking is used to create
interactive dynamic projection mapping
applications interactive experiences
such as games are easily scripted in
unity 3d the unity editor also gives a
convenient overview of all sense
geometry and virtual objects in the room
it is easy to map a 3d model to appear
as if it is in the users hand or in the
middle of the room above the coffee
table
note how the dynamic projection warps
the graphics on the other users body to
deliver the correct impression of the
virtual object here the designer places
an interactive globe in the scene which
appears to hover in front of the user it
is rotated by touch
with a simple catch and release
mechanism based on Kinect body tracking
two users can play catch with a tennis
ball
you
Unity's rigid body physics simulator
models the collision of the tennis ball
against the real objects in the room in
a combat style game a player can summon
a fireball to the raised hand and throw
it at the other player both players see
the appropriate view of the action when
a player lands a fireball on their
opponent this is detected as a collision
of the fireball with one of a number of
spheres which approximate the opponent's
shape damage effects are displayed on
the user these follow the motion of the
user through the use of optical flow
based motion estimation in the Kinect
infrared image to evaluate our dyadic
projected spatial augmented reality
system we conducted to user performance
experiments the first focus on whether
participants can perceive projected
virtual objects at the intended distance
and size rather than simply as a
projection on the wall participants were
shown a virtual cube of one of three
sizes and at one of three distances they
reported the apparent size and distance
of the cube in one condition the
participants could use a physical marker
placed in the scene to help judge
distance in the second condition the
participants judged distance without the
help of the physical marker in the
second study a grid of sixteen labeled
spheres were rendered to appear between
the users participants determined which
of the spheres was indicated by the
other users pointing gestures this
pointing task explores whether the dyad
has a rudimentary shared understanding
of the layout of virtual objects between
them and thereby a basis for more
advanced collaborative interactions
please see the paper for user study
results mano-a-mano is a unique spatial
augmented reality system that combines
dynamic projection mapping multiple
perspective views and deviceless
interaction to support dyadic
interaction with 3d virtual objects most
importantly users are able to interact
with 3d virtual objects and each other
without cumbersome devices that obstruct
the best qualities of face-to-face
interaction</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>