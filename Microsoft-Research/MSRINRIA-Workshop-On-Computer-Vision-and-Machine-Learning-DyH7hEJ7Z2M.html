<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>MSR-INRIA Workshop On Computer Vision and Machine Learning | Coder Coacher - Coaching Coders</title><meta content="MSR-INRIA Workshop On Computer Vision and Machine Learning - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>MSR-INRIA Workshop On Computer Vision and Machine Learning</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/DyH7hEJ7Z2M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay so i'll be talking about a couple
of papers which is a joint work with a
lot of other authors who are shown on
this page so two of these papers are
published one at ICC V last year and one
is just freshly out for cvpr this year
and they are all about extending random
fields to become more expressive models
and ultimately also to make progress in
tough computer vision applications so
why random fields random fields have a
big history in computer vision almost
three decades was retaken two more and
recently around ten years ago
conditional random fields have appeared
and i would say for many of the heart
structured labeling tasks such as post
estimation semantic image segmentation
image segmentation defs estimation
optical flow this now more or less
defined the state of the Arts with
different rates of trade-offs regarding
performance and runtime and what all
these tasks have in common is that we
want to make structure predictions so
ultimately given an image we want to
make predictions of multiple variables
jointly so the current state of the art
a computer vision is still a little bit
disappointing because people spend a lot
of time on their unary terms if they use
a random fields I spend the time
boosting classifiers using SVM's using
kernels using a decision trees all kinds
of fancy models for the unities and then
when it comes to the paralyzed term they
just pick one out of five for own terms
have one or two parameters and tune them
using cross-validation and that's a
little bit disappointing because the
real structure of the model happens in
the pairwise term not in the euro so in
the ICCB paper we basically show a more
flexible version of a CRF where we
overcome this restrictive form and and
we overcome the reason why the X
restrictive form has been used in the
past which is basically the difficulty
of estimating the parameters so if you
choose a flexible form for the paranoids
potential it becomes very hard to
actually set the parameters here to set
the functional form of these
interactions and so people use something
like contrast
sensitive smoothing potentials and
there's one parameter which you can tune
but if you say in your network to define
the interaction it becomes very hard to
estimate these parameters especially if
you say instead of just a pairwise
interaction one pixel away you would
allow interactions a couple of pixels
away it becomes a lot less clear how to
intuitively set these parameters so you
cannot just reason we want to smooth our
prediction like you do for the contrast
sensitive potential but suddenly here
it's no longer so clear what you what
the interaction really should do or if
you have a sort order potential only in
very restrictive applications you can
make the point for say and forcing
curvature unfortunately second order
smoothness but if you're in general
allows certain other interactions it
becomes lost lot less clear how to how
to set these interactions and so what we
did in the icy TV work is essentially
offer two things offer a flexible
presentation using decision trees so
here's for example a pairwise
interaction there are two random
variables and XS the observed image and
we have to find the functional form of
an energy function defined for the two
random variables and the image we
observe and how we do this is by using
by using a decision tree and we store at
the leaves of the decision tree we
actually store a small table and the
table is addressing for every possible
combination of these two random
variables the actual energy values so
what we do is then we observe an image
patch associated with this interaction
we go down the decision tree and then we
instantiate that energy table as
effective interaction in the model so
what this is going to do is although the
decision tree is shared in the entire
model and repeatedly used in the entire
model because the image is different at
each place where the interaction is used
we end up with different leaf nodes okay
so it's basically a very complex way of
tying parametres globally in our model
and it's very efficient a test I'm a
test time we just leave a late the trees
and then we have a normal CF program so
this is just a normal CRF essentially
with a very flexible form for the
interaction and this extends to unary
interactions powers interactions and any
other higher-order interactions of
course it becomes more complicated to
store these tables
so this generalizes the unary random
force you normally see and people use
these right is just a model without
powers interactions generalizes random
forest it's just a tree that has a defs
one doesn't make any tests based on the
image it always has a single interaction
here it's no tree and of course in the
more flexible ideas and to have a tree
for these interactions and then the
model becomes really impressive the key
problem we address in the ICCB paper was
how to actually learn these models so
that's the reason why people have not
used more expressive interactions before
and essentially we use a very old
technique we just use a so called pseudo
likelihood approximation which is
essentially if this is our random field
model we take a single random variable
and we conditioned it on its mark off
blanket and we do this for every random
variable and just treat these the
condition using the ground truth so
basically here we have some labor ground
who's in the training data we
instantiate it and it now becomes a
small conditional model which is
tractable and very efficiently
computable that was the key idea very
simple but moreover besides just the
simplicity and efficiency it allows us
also to use huge training sets because
we can suddenly subsample structured
models so if you have a model with a
million pixels we can take for an image
of a million pixels we can just take a
random sample of a thousand pixels from
that model use a suit like dude
approximation only for these cells and
pixels and obtain an unbiased estimator
for the suit like yield of the entire
training set so this is very efficient
at training time however in the ICCB
pepper we had only very small scale
applications and they were sort of a
little bit contrived to show that the
model is really expressive and can model
certain structures so we had the tasks
we made up Chinese character in painting
so you're given a Chinese character but
there is an occluding box and you need
to in paint you need to remove the gray
box this is really difficult because you
have binary random variables and you
need to model things like stroke with
need to model preferences for horizontal
and vertical strokes which happen in
Chinese characters so it is quite
challenging task and actually if you see
the MRF basically that's just some
intelligence moving
it's a very densely connected mrf so
it's not a simple MF but the decision
tree field it can do more meaningful
completions so that's nice but it's so
fun artificial task we r T Jamie
provided his data to us and we basically
showed that by modeling this conditional
pairwise interactions we can gain
improvements am and for example here the
structure on the arm speed are modeled
and this is just because you have weak
local evidence so if you observe defs
image and you observe the arm like this
and you just observe basically a patch
here you don't know where on the arm you
are but if you have a random field you
can propagate this information so you
can say I don't know what I am but if
this is a shoulder and this is a hand I
know I'm the elbow basically so
performance increases training is
sufficient so even though we have a
couple of million model parameters we
can estimate them from this was 1500
images quite efficiently and this is all
nice but after the icv paper we were
excited about the model but disappointed
with some other aspects and the next
part of the talk is basically about
addressing these aspects so in the ICCB
paper we train this decision trees and
the weights these tables we have on the
leafs independently which is not very
satisfying right we learn the tree
structure and then only at the end week
we take into account all the model
interactions when we learn this one so
ideally we would like to learn a jointly
the tree structure and the weight of the
model should all respect the overall
model we use the suit likelihood
approximation I think we got away with
it but it's it's we got criticized in
reviews for for using this but I think
the more the most problematic aspect is
we have solved the training problem but
the test problem is quite difficult so
for these Chinese characters for 100 by
100 model with 307 edges that takes rank
20 to 30 seconds to do inference which
is just much too slow and now i show how
to all overcome these these problems and
this is the cvpr paper we have this year
so the first thing is we replace a model
the discrete random field with a
continuous one and a very specific
continuous one a Gaussian CF so a
Gaussian conditional random
that means we can do efficient inference
efficient inference by just solving a
sparse linear system of equations and
this can be done by conjugate gradient
50 durations in real time essentially we
are going to do joint training so we are
going to use trains a tree structure
that defines the model by using a single
objective function so every decision in
the model splitting the trees which
feature tests to use what other
parameters in the nodes is made in order
to minimize the singing objective
function and that seeing objective
function is no longer the suit
likelihood it is really an estimate of
the it is the empirical risk of the
training set so we do empirical risk
minimization and by using different loss
functions we can optimize for different
losses but the basic idea stays the same
we still have trees we still have
interactions we still do tests on the
images and depending on where we reach a
leaf we have a leaf model and this leaf
model defines an energy function this is
all the same but now the energy function
is no longer table it is really a
function okay it's a specific function
is a quadratic form quadratic form was a
positive semi definite matrix q and some
linear term which depends on some basis
functions and weighting matrix the basis
function could be for example filter
responses so we basically have a linear
quadratic model in each leaf of the tree
and every interaction is going to select
one of these small quadratic forms and
we piece them together by just summing
them and this defines a whole quadratic
form for the entire image and this is a
Gaussian the Gaussian energy the
conditioner random field at every pixel
we now have a vector in RG for example
for denoising we will have D equals 1
but for colorization we will have D
equals three or four other applications
optical flow we would have D equals two
so this is completely free to choose we
are going to do joint training and not
going into the details here but the we
found joint training to be really useful
so what we are going to do is when we
grow these trees we again use a greedy
strategy like Antonio showed but we
select the test by which to split the
data in order to maximize the decrease
in the objective function and the
objective function is really the
empirical risk
and this makes a difference so we can
see here for example if we train them
separately independently this is a blue
curve we reduce the error much slower
than if we use it if you directly train
for the loss and so it eventually
flattens out but we essentially make
much more effective use of the training
data and this is on the test data so
these curves on the test a cat's not on
the training data and we show that this
is efficiently computable for any
differential loss function so this is
another technical contribution of this
paper we show essentially that the
entire computation needed amounts to
computing some sufficient statistic
locally and then just using the
sufficient statistic so it's it's still
as efficient as before we have some
applications in the CVP our paper join
detection and regression for this de
formal registration tasks colorization
of grayscale images again I would say to
be fair it's a little bit like the ICCB
paper we show how flexible the model is
we show that it can do quite fancy stuff
but there is not a killer application so
to say so we said okay for ECC me you
have to do a killer application we have
to solve a computer vision task okay and
the computer vision task we solve I
would say is image denoising so image
denoising is a crowded field basically
they expect two decades and there are a
couple of benchmark methods that we
compare against so there's a locally
sparse coding you probably know this
there's a recent work of year Weiss and
don't know his first name so on I ccv
last year the expected patch likelihood
basically these are on par with each
other and the state-of-the-art
approaches and there's a little bit ola
approach p.m. 3d which is also really
good and these are realistic of the art
and they are sort of more principled
markov random view based methods a field
of experts but unfortunately they don't
before perform so well in practice so
now the interesting thing for image
denoising is if you take all these best
performing methods okay you have a noisy
image and you you give them the
knowledge of the ground truth per pixel
independently you choose the best
prediction so you're cheap basically you
know the ground rules you have these
four predictions from the different
methods you pick the ground whisperer
you pick the best performing model
per pixel you still have a residual so
these methods are not not really perfect
the denies image looks great right it
has to improve on every single method of
course but now the really interesting
thing is if you look at which pixel have
you for which pixel have you selected
which model of these four you see some
structure and you see some structure
some regions are really noise it's
almost retina which model you pick and
some other parts of the image there are
some consistent patches where you prefer
one method over the other right and so
this is encouraging in two ways the
first way is in this very random parts
you can probably profit by just
averaging these models because the
residuals are likely uncorrelated so
model averaging could improve
performance there in the patchy areas
you could improve by finding out trying
to predict which model is better so if
you find these consistent patterns given
the image you can actually improve so is
one of the motivations of of how we
actually get good denoising methods the
other one is I said we can optimize for
different losses so for image denoising
that different not losses the peak
signal noise ratio mean absolute error
structured similarity information
weighted structural similarity all kinds
of different errors and we can optimize
for them explicitly so we can I think
it's the first time that somebody can
explicitly optimize a model with many
parameters like millions of parameters
for predicting well instructed
similarity so when we do this and this
is a structured noise models it is not
additive course a Gaussian white noise
where there's a structured noise like
just on the lens we can learn to remove
it using for optimizing for structural
similarity and we can learn to remove it
for mean square error and depending on
what we optimized for we are better in
their respective performance measure so
this is a test image and this is
encouraging because it says the loss
metas if you want to be good at PS and
are you better optimize so Pierre so now
if you want to be good for structural
similarity you better optimized for
search as a narrative and all the
existing denoising methods correct me if
I'm wrong don't explicitly optimized for
loss they propose an algorithm and then
basically measure different losses but
they don't optimize for that loss
there's another contribution we use a
very solid experimental setup also
because people previously have just
literally done 60 or 68 images
over and over again they give the
individual images even names and this is
not a proper experimental setup so we
use the proper experimental set-up over
different noise levels using clear
training validation test separation we
use statistical hypothesis tests to
prove that our results are significant
we evaluate on the test set only once
once only and we use different features
we use filter bank responses but also in
some of the models i will show you you
we use the outputs of the other
denoising methods because we have a
conditional model we can do so we can
just plug the outputs of other models in
yeah yes we synthesize it so this is
basically have different settings so the
I find the more interesting setting the
structured moistening right because
other approaches could not address it
easily and we can learn the noise model
the perceptual similarity metric and the
natural image statistic model so we can
all jointly learn this so this is I
think the contribution but this for this
experiment just to be comparable we use
additive untranslated white Gaussian
pixel independently so like the most
analytics thing you can write down this
is a result table let me show you the
zoom up here we basically perform
outperform every other method overall
noise levels in PS and our x 0 point 25
DB which is huge and so we have two
meses basically RTF all is using all the
other predicted outputs from the other
methods as features but this is really
slow because we don't experts basically
it takes 15 minutes per image so we also
have one weighs just PM sweetie users
use this input and even that is
outperforming the other approach is
significantly if you just take the
uniform average of all these four
methods you also improve on each so this
is the first point I made of the
averaging effect and actually we r
perform all methods on all the
performance measures so peers and arming
episode ever structures in the ranking
on every of the 200th test images on
every image and every performance
measure we are better than any other
base line method visually is this EP ll
the best performing method for this
image I think you can quickly see even
on the screen here that this
our predictions better it's smooth aware
EP LLS patchy okay yes we tried on we
have jpg d blocking experiments and we
have a simulation synthetic noise of
dust on the lens so like a bigger
occluding noise real nice there's no
angle right in a smells no question
right so the approach is based quite
heavily based on learning and machine
learning so we would need in order to do
this on a real chromatic noise from a
webcam or something we would have to use
pairs of ground truth and noisy images
which are probably easy to create by
just increasing their exposure time
we're actually working on this for other
applications so but not in this
experiment so we really wanted to just
close that pixley independent noise
chapter okay so this is basically almost
it's just a reason for why we actually
improve the loss function metas we can
optimize for the loss function and we
can make use of all the existing
denoising my sensors future-proof if in
case you come up with a new denoising i
said we just added to our model and i'm
pretty confident we will be kyo method
so cause a recursive argument but yeah
we went clever use we wait the existing
methods image dependently and then
correct the residual so now we have the
best of both worlds right we have a new
state-of-the-art in image denoising we
have every efficiency we have the joint
training we can optimize for the loss
and we are very excited about this and
thank you very much for your attention
think we have one minute for questions
otherwise we can go straight to lunch
who's left to do for any of us what's
left to do so okay so the reason why
this is efficient is that it's a
Gaussian model right but there are real
computer vision tasks which are just
ambiguous so given the image the true
conditional distribution the predictive
distribution is not unimodal and in our
model it always is guaranteed to be me
doodle unimodal so there is we our model
is still miss specified in this
scenarios I don't think denoising is one
of these settings but they are probably
others other things like optical flow
say think of a zebra strip on the on the
street you can either match left or
right so there is some ambiguity and I
think in true multimodal settings we
would have to extend from a quadratic
energy function to maybe a more flexible
model which of course would be a
trade-off again in terms of can we do
inference in it can we do the parameter
learning in it but promising so that's
left to do a lot of other things left to
do but some of them I I keep to myself
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>