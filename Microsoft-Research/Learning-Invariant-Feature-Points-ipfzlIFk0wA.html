<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning Invariant Feature Points | Coder Coacher - Coaching Coders</title><meta content="Learning Invariant Feature Points - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning Invariant Feature Points</b></h2><h5 class="post__date">2016-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ipfzlIFk0wA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
good morning everybody it's a great
pleasure to have Pascal for with us
today and Pascal has visited us several
times at MSR in the past I've seen
several of his talks over summer I mean
he's a professor at EPFL in the computer
science school of computer science and
communication and he has been there for
almost 20 years now nothing since 1986
Pascal heads the computer vision group
there and his colleagues he works on
several topics feature learning feature
matching object detection tracking in
video human body modeling and Pascal has
co-founded two companies or picks 40
which many of you may have heard of does
dense aerial 3d mapping from UAVs and
has the other company that is founded
playful vision they build tools for
video analytics for several sports
scenarios and so Pascal also happens to
be an avid glider pilot and yeah so
today he's going to talk about learning
local features so welcome Pascal thank
you yeah so I've been yeah I've been at
EPFL for almost 20 years now and for for
about 15 of these 20 years we've been
worried about interest points and of
course I mean I probably don't need to
explain why the importance I've played a
very very crucial role in many
applications in computer vision and by
and large it started and at the end of
last century was David Lowe and since
then there's lots and lots and lots of
citation lots and lots of papers we've
all been essentially running after David
well actually fairly limited success
I mean sift 17 years on is still pretty
good and
most of these approaches we all use
essentially the same pipeline and the
pipeline is you start with an image you
run the future point detector for every
feature point you compute an orientation
you use that to warp the patch you
complete the descriptor and you can
compare compare those descriptors so
over these 17 years I mean there is a
gazillion papers and this is really
important
dot dot dot and they are also so these
are papers over the whole about the
whole pipeline and they also great many
papers including ours about there's
elements of the pipeline so the future
the local future detector actually about
orientation the orientation not so many
I'll come back to that and lots of
papers also about the descriptor and
we've all been guilty of the same sin so
we develop one of these algorithms we
test it on some database and we are very
happy because our ROC curve is above
that of the others so we get cvpr and IC
cv or some such paper which health was
tenure but doesn't help that much with
science because in my experience what
happens is once you take your little
block and you put it in the whole
pipeline the overall improvement is not
that big which essentially is why sift
is still around so that's kind of the
background and of course in these 20
years something else happens the
invasion of deep learning so I belong at
Mis confess to this very doing Ling
group that still bit skeptical about the
whole thing
ah that's kind of the way I perceive
them however I mean you have to live
with your times and if you can't be done
well
so that's what we've been doing and
actually what they do is they offer a
way to reformulate this whole pipeline
into one formalism the the CNN main the
deep learning formalism and then in of
itself I don't think that matters all
that much but the reason it matters oh
it's going to matter is then you can
engineer the various elements so that
they work well with together and that's
where the benefit is going to come from
and so that we can put at the end when
more set of graphs are our performance
is better than the others which is so we
are still guilty of the same thing okay
so let's go let's look at these three
elements the feature detector the
orientation estimation the matching I'm
going to reformat each as a CNN and then
we'll put them together
okay so first the key points how would
you detect them
and this actually all started a few
years ago from a problem like this one
you take two pictures of the same scene
as in this case it's Frankfurt in
Germany and you try to match them and
they've been taken at different time the
times of day actually one is by night
the other is by day so a really strong
elimination change and their sift
doesn't work you cannot really Oh Cerf I
mean it's the same thing kind of thing
and why doesn't it work well what the
failure point is here is if you look at
a little window here but you will find
is you don't find the same interest
points in both images because the
illumination is so different and so at
that point if you have even the best
descriptor in the world it's something
to help you really need to find the same
key points in both images so that's the
problem we've addressed by trying to
find
something that would truly be invariant
to light changes and of course to
geometry as well when you want
invariance to both and so that in this
case for example the key points we find
so of course we don't find exactly the
same but we find enough are the same so
that we can do our work so how do we do
this
well what we are going to do is to use
webcams that are fixed and take the same
scene over and over again but over a
period of time so that condition change
and so that gives us a bunch of images
we are going to superpose them and of
course even with a webcam it vibrates a
bit so it's not exactly the same
viewpoint but that's easy to correct for
so we can assume that one point in the
image is really the same physical point
in the whole stack and then we're going
to do something extremely simple is to
say we want to find the points that are
highly repeatable so in this case it's
we're going to use surfed in fact find
sift key points or anything else it
doesn't really matter and in each column
where the point appears often enough
we're going to this a good key point are
now going to train a detector that finds
this key point in all the images not in
most of them in all of them
and then separate those key points from
everything else and it turns out this is
not particularly hard to do you just
have to you define a loss function so
that says I want essentially the same
response in a column
it's either always 1 always 0 and given
what descriptor you want you also want
the response of the descriptor to be the
same so you can train it to be to work
well but say sift and turns out this is
fairly easy to implement with a shallow
net that gives us this point detector
that we call tilt so that's that's
training a test time we just run it on
the image dune on maximum suppression
and get our results and then we can
actually use it to register images that
have been acquired at different times a
day so here are some example this is
their scenes and we try to find for
example where this is this actually is
there but we can use different versions
of this one and show that we can
register in a very stable fashion no
matter what the the weather was that day
so here an example of a video where we
do this over the space of a year yes it
vibrates a little bit but by-and-large
it stays where it should be so for
example if you we think but since we're
going to talk about drones later that's
a point the drone has to fly every day
in any kind of weather ok and of course
we can do this in a more you know we run
on the usual databases we can show that
we outperform in terms of the usual
repeatability measure we are to perform
the others and one small detail there
are three versions of till here because
what I've shown is just a regression
problem so you don't have to use a CNN
to do regression actually when we
started in the dark days of before CNN's
this was a tree gradient boosted tree
and yes as usual we have the same
experience it works of course but we do
get better performance when we do it for
the cni yeah they are the odd
the subtle that P is also a CNN so it
says it's a better CNN it's not so yes
I'm going to do that for the detector I
don't remember the numbers but for the
descriptor I've talked about later it's
about four times slower so it is slower
but it's not massively slower and since
I mean you and this understand the
hardware now there's all this hardware
that's optimized for CNN's that's coming
out so I don't think it's going to be in
this shoe around the x axis tend to be
very simple regular yes to do iris
corners right old car like a few matrix
modifications yeah they were very fast
so we've used a lot the one that's
called fast
right right right nicely because yes
this is really uh this only has one
layer it's a really simple way yes one
question about this so if understand
correctly all these datasets are mostly
from the same perspectives exactly
delicious things but have you also tried
getting other datasets with perspective
changes in truth okay so for this no we
haven't but for what I will show next
yeah so we could go back but I'll show
you in a moment that we use for the
tourism datasets and perhaps we should
have done that there but we didn't
okay so in short we can we really want
our key points to be repeatable and we
can train a regresar to do this for us
okay so that's was number one number two
let's talk about orientation of patches
and if you look at this list that I
showed earlier there's something fairly
striking so lots and lots of paper
lots and lots of papers almost nothing I
mean we may have missed one of course
but we really tried we only found one
and if you look at all these other
papers they do mention them in sift of
course mentions orientation in terms of
the dominant orientation the histogram
but it's no it's it's one throwaway line
somewhere in the paper so it's important
and it has been largely overlooked and
what I'd like to show now is by actually
looking at it a bit more closely you can
actually get a boost so first before I
tell you how we do it what does it mean
what is orientation it's actually if you
think about it the word the orientation
of a patch is not very well defined
because here's an example you have a
patch and you have what is your
attrition that patch I mean they at
least two dominant orientations at this
one so you have to pick one but which
one okay so in fact our definition is
going to be just as arbitrary but it
will serve our purpose which is we are
going to try to find the orientation
that gives us the best matching
performance because that's what we want
to do in the end and so what does this
mean it means that we are going to have
a Siamese Network so that's given a
patch or given a patch of the same thing
is always going to
returned the same orientation and that
orientation is the one that will allow
given the particular descriptors again
let's say we are using surfed or
anything else but safe twelve time being
we want this our network return this all
this thing called orientation we want it
so that the distance between the
descriptor is minimized because that's
what we'll use to do the matching and we
train the regressor to do this and one
one catcher about this is to train it we
need to do back propagation means we
need derivatives so we need to be able
to differentiate this expression and if
you think of sift while sifting is not
exactly differentiable so what to do
well but to do is to compute numr to
pre-compute numerical derivatives before
you start makes it make a big table and
use them in the computation so it is it
can be done we've done it but it's
actually a bit cumbersome and we'll see
a bit later that if you replace sift by
or CN n that is differentiable it makes
you implementation a little easier
exactly
so the descriptor is given at that stage
so we have several version of the patch
and it will predicts an orientation per
catch and it helps so for example in
this case we are using safety to the
matching but we compute the orientation
either using the standard dominant
gradient of the normal your stick or our
ours and we do get a lot more correct
matches in that case so this is not
quite as significant but we've we've
tested it to as usual on the usual
databases and what we see is that if you
get to we used as one of the standard
matching performance measure the old
Mikolajczyk and schmidt thing you sift
you get this kind of performance if you
use if you use our intention instead and
the same sift we get a boost and there
are two versions are forever our thing
so one uses the the usual real you
activation function and this one GH h g
h h uses an improved version of that
where the thing is piecewise linear
where you actually optimize for where
you put the breaks and that gives you a
further not that large but visible boost
I think because it's a richer it's
simply a richer description and than
before and the same thing for using vgg
bgg is the Simonian and zisserman one
which is the one I think that does a bit
better and sift now and we get again the
same kind of boost which is we use the
published version or the published
version plus our orientation estimate
yes
okay so in short orientation is
important it's been overlooked and if
you pay a little bit of attention to it
and try to compute it with a view to
boosting performance you do ok so last
step the descriptor there's there's a
certain way these feature learning
methods are are trained there's a task
that you have to honor on the validation
set you were given patches and you have
to basically predict the correct match
so the validation and everything needs
to be at a patch level all the previous
ones if I understand correctly be
feature learning is always going to look
at this world of patches but not under
on the high level problem of matching I
think I see what you're saying and I
think we we do this we still have the
patch level but we are the everything
I'm talking about right now is patch
level and let me I'll get back to your
question when we talk about training the
whole pipeline okay so the final thing
which is how do you do how to computed
this the descriptor that essentially
minimize the distance between
corresponding matches and maximize the
distance between non corresponding one
and so I even have the word patches here
so really it is patches it's just again
that you can do with the Siamese network
and then appropriate the appropriate
loss function yes there is this but
there is balancing and there's also hard
mining and all these issues are yes
they are addressed so actually that's
why this one I have the the actual
network on on the slide and and I'm
tossing over the details but I know that
other when they did this is spend a good
long time trying every single I mean
that's actually a fun is very
frustrating but this kind of work is
this is the final result it works and
they used no no this particular they use
ten H instead of real you because it
works better and why is that well I
don't know but that's the way it is and
it took them I mean many months to come
up with that particular thing that's as
a job and one thing so there are no
fully connected layers in this thing
and yes I mean essentially what you said
no Malaysia and hard mining is key you
don't do it it doesn't work but when
it's done you don't need to retrain it
again I mean this is essentially
replacements or sift of course which
captures the biases of the particular
database you've trained it on and so
just to do a bit of again testing we use
this time we use the brown data set the
liberty data said by Matthew brown and
and company so it has actually three
sets of patches true from Liberty and
natural de Mai essentially architectural
things and the third one is from
Yosemite so it's a these two are similar
this one is different and we train on
two tests on the third and these are the
kind of results we get which is on this
data set actually we don't do that much
better than bgg it's sort of comparable
and actually you can understand why I
mean so usual the the one we do worst on
I mean we do worse we're here we're not
completely at the bottom but we're not
winning is if you train on Liberty and
not today you train on Tuesday that's it
that is similar and you test on the
third one that's different it doesn't
work I mean it doesn't work as well it
works better if you train on Yosemite
and Liberty and test on the trade names
and it does work better or silly I think
this data said do you have a number of
I'm not sure they're all that
representative so when you go to
different scenes then we do better we
generalize better only the training data
sets are changed and does it make sense
it's it's a matter of yes we should in
the end and I was ok I was visiting
David Lowe yesterday at Google that says
in the end which we train this on there
for Google Earth thing and and the
problem is I don't I don't have the full
database and I don't have the computer
resource to do this but yes you should
these are the publish no PGG this is so
Simonian Andy it's yeah it's I think of
all those we've tried as baselines
that's the one that works best
ok so
okay so we can again we have now the
third piece which does well on its own
it generalizes and so that was the
question the earlier question in terms
of computation time on ordinary hardware
it's so it's well so it's no it's
actually a bit phone before it's more
like five but what's a factor five
between friends I mean once NVDA gets to
it it'll go away okay and this is a
potential replacement for sift okay so
now we have our three pieces they all
CNN's so check we are deep and now we
can put them together and this is the
pipeline we the end pipeline so
essentially we we have the three
elements and we need to glue them
together and the three elements are
differentiable by definition they are
CNN's but since we want to train the
whole thing we need end-to-end
differentiability which means the
connectors have to be differentiable
also and that actually can be done so
the two main ones are when you do keep
on detection you do non maximum
suppression so it's actually an arc Max
and we replace arc max by some Vedas
called soft arc max which is equivalent
to putting a Gaussian on on the thing
and it makes it differentiable and the
cropping and rotation operations we use
spatial transformers which also are
CNN's and so we get our desired end to
end differentiability and now of course
we have to train the whole thing so we
key points and non key points we need
pairs of corresponding matches to
guarantee that we get the same
orientations and we need pair of
corresponding and non corresponding
patches so what this means we actually
have going to have a bunch of loss
functions to
guarantee all these things which is
going to make for a really complicated
landscape and what we train it on all
these food or tourism data set so that
gets back to your initial question we
didn't do it for tilled we could have we
should have but we do it now for the
whole complete thing and the two we've
used just for convenience purposes the
one that were available one is images
from Piccadilly Circus in London images
from the Roman Forum we run an sfm a
structure for motion pipeline and we we
essentially keypoints our positive
essentially are going to be points that
sift found in several images on which we
can reconstruct 3d points and we can we
project these 3d points in the other
images so that we can actually make it
find points that SIF didn't find but
this is a bit limited so we will find
points that sift found in some images
but not others points that sift never
found we will not find either so that's
probably a limitation that I mean we we
could think of a way of doing this
better but it's not done okay not in
this work but something we can discuss
when if I talk about drones so we have
for to train a drone detector and there
the problem is it's very hard to do all
these illumination effects so in a
really realistic way so we found that
you need actually yes or combining with
synthetic helps but you have to be
clever about the way you mix the the
synthetic and the real and I have maybe
afterwards I have some other slides
about that I could show
and okay so here's a training
architecture so we have the pipeline and
we are going to be not a simple Siamese
now it's a quadruplet Siamese it's bit
painful because we need to capture all
this basically we're gonna train for
matching patches around interest points
patches are on an interest point that is
not matching and something that's not an
interest point at all and we want
different behaviors for all these things
which is why we need is for branches so
they are Siamese meaning this w here
means that the ways are shared and we
have it's basically we optimize
something that's a sum of loss functions
that encode all these things and the end
result is we have something that's
really ugly and that we just gone train
from scratch but at least we we tried
and it doesn't work or we were not able
to make it work and so we are not going
to train it from scratch we are going to
design a specific training procedure
which essentially goes in Reverse we're
going to train for the top so first we
train the descriptor using the original
sift matches so the final thing of the
network using no I've shown you the
Siamese Network you train the descriptor
now that the descriptor is trained you
can train the orientation estimator
because the orientation estimator is
trained given the descriptor and that's
actually a bit easier than what we did
before because as I said now the
descriptor is differentiable we don't
need to pre-compute stuff so the
training procedures a bit simpler than
before but initially we fix we do the
back prop but we fix descriptor so those
ways of fix
then now these 2's train we can train
the detector which as you may recall
operates given the other two and and in
all of this it works so it's
comparatively easy to deal with because
we have this end-to-end
differentiability and then when the
whole thing is trained you can do fine
tuning and optimize all the ways
together if you want
we tried but it turns out that it
doesn't make it improves a little bit
but it's not terribly significant it's
because all of these things are trained
are if you think about the descriptor
the orientation was we trained to find
the best orientation for the descriptor
we want to use well I assume that the
metrics are related through eventually
like how many features match with the
entrance you have to go from the end for
what you're trying and train of the same
I mean it's just I'm not sure how we
would do it you know if you start from
the top you actually start with what you
care about
yeah and in some sense if they are
population I think the honest answer is
because it seemed that fall at the time
yeah I'm thinking about lingual people
start seeing what's if to another
feature point straighter detectors the
first they worked on and then they
worked on the orientation on the
descriptor that's how I thought it's
alright you know the descriptive onto
the matching without a matching don't
have this loss function so I think even
when you don't have crafting the
detectors so using the descriptor to
each other yeah ok so this is the
quadruplet thing is the training at run
time it's easier is we have essentially
there's many layers and what we do is we
actually run the detector by itself so
the lower levels of the net on the
pyramid and do non Maxima suppression
because here we don't care about
differentiability anymore we just want
interest points so we do that and then
on these interest points we run the rest
of the network the one that computes the
orientation and then the descriptor and
that essentially gives us at the end a
descriptor in the usual sense of the
term that we can plug in into your
favorite application so here are a few
comparisons against the same display is
that when we use our approach we get far
more correct matches than when you
served and we've actually trained that
of course on as usual on all the usual
data sets whether we've tested that on
though all the usual data sets we here
is so that's Frankfort same same idea
yes
and the inevitable bar graphs so we end
up with not substantial jump and
performance by sexually optimizing all
these elements so that they work
together and there are two versions of
our approach so the one I'm calling
Piccadilly the that that's depending on
which it's the same pipeline it just
retrained it on one data set or the
other and again if we had access to say
what's the Microsoft when that's right
now another know the your data set your
it's not the equivalent of Google Earth
big map right okay one of those for the
whole world and the computational power
to go along with it I suspect would be
worth trying that these bars would go
further up it's ok so I should it
doesn't work as well because it's I it
would be I don't have the exact but
since they are really I think if you
didn't do anything it would be like all
the others I said the intro components
are better but when you put them
together they they have a learn to speak
to each other so you will you would be a
bad at the same level as everyone else I
think so how much forever
you need like X I don't have the GPU
anymore because and I'm just doing
feed-forward right so right so how much
RAM do you need for to represent each of
the 3 part of X a photo screen some
networks I haven't really thought about
that and now you know why I'm asking
right yes I know what you're asking
but I think that that's not Furio right
right so I think I mean we are going to
try to do a project with a small Irish
company that has what they have is
something that look at USB key
except it's not memory it's uh it's a
processor yeah and so they're not the
only one that they happen to be the ones
we know well movie uses already so I
think for them it's no problem
yeah so if you put that on your drone
yeah it's done
but then what's the link is because now
everything has to go for the USB bus
okay so these are okay yeah I don't know
the answers to that but that's oh yeah
okay and something that's okay so we
have 17 years have gone by and sift is
still essentially competitive with vgg
being number two yes yeah where they use
triplets when they train the network for
correspondence might be a minute from
Oxford and they advertise that if you
have one positive and two negative I
works better than having pairs yeah but
it's I think that it's yeah I'm not be
familiar with this specific paper but I
think that's what we're doing we have
the two positive and the one negative
and we the fourth because we there are
two kinds of negative it's it's an
interest point it doesn't match or it's
not even an interest point so it's it's
a it's the same flavor at least
okay so to conclude we so we have
implemented the whole the whole pipeline
and to end its CNN now it's we can train
it and we cannot perform the state of
the art again the key is that I think is
that because they are all CNN the
various Cubans can talk to each other
and be optimized to work with each other
and that's I think where the power of
the approach comes from and so we are
putting all this all this is on the web
so the detector by itself the
orientation estimator descriptors and
this is coming it'll be there soon and
of course we hope that you will play
with it and tell us what you think about
it and I think that's it thank you very
much
a few minutes one question so we have
time so descriptors matches an ultra
distance or is this like a custom
distance or in this case a cell to
distance okay but it's not
he doesn't have to be so what is the
what is the processing time of detection
is in dark technology as I said the
numbers I have this is about say factor
five as compared to sit for the whole
thing I mean because it's all CNN you
replace your standard algorithm by your
CNN and okay so it computes more on GPU
and that's soon enough I suspect our
phones will have something that burns
see an answer which actually is of
course going to reinforce the dominance
of CNN since start doing hardware
specialized hardware for it anyway this
paper the only nice thing I remember is
the name it was called ESP sift do you
recall this world they were basically
doing spatial pulling across the whole
pyramid and they take away from that
paper remember was that traditionally
sift was handy to hear the detectives
and engineer to find the yeah in the
pyramid Utica scale and you made the
patch from that layer of the right and
then build your descriptor right instead
the major modification they were
suggesting was take take the patches
from the whole whole pyramid essentially
across all scales and then computer
descriptor but the descriptive
calculation is still a histogram and
normalization let's see and they should
they also showed like remarkable the
boost and accuracy just by it I think
knowing doing that and I was curious
because here it still CNN is still
learning to take the patch from yeah it
doesn't have this component because at
some point deep in the bowels there is a
scale projection similar into there
so yes it's more it's still original
sift like it doesn't have this component
I think the detector somehow because
it's a CNN I think the advantage of CNN
Sarah that they have this receptive
fields which are much much larger right
and so I think the detector stayed when
you when you get it responded sort of
location in your board of the receptor
that have the fields are probably pretty
large we work on I have a dimension
somewhere else it was 64 yes okay so
here there okay so the dimensions the
patches we work on a 120 828 and we
build a descriptor for 64 within that
128 by 128 we look for an optimal 64 by
64 and we build a descriptor for that so
that might help I mean in some sense
implicit then maybe maybe implicitly
it's doing something like what you
described yes there was a paper from
Thomas Brooks group where they converse
with with C and then this year I plan to
grow also so basically we don't ask very
intense
module and it's critical more than we do
shape and will be change the first part
that is the detector and buy something
carefully their domain size or be under
detection part we saw that we do
measurements events for our Oaks 14
fiscal data sets
I'm kolodziejczak but later we compared
for a photo tourists data sets and we
see that the benefits are not that big
so I think we don't do better than this
whether the promise of castle nikolicic
oral dataset was really very specific
it has biased so you have to be a little
bit careful about Fisher from Thomas
broke screw it's quite big in with more
extreme deformations no for Blair zoom
perspective or fine so for this
intercept we do better but one reason is
so so maybe we because we've used it I
think it came up last year
it's from Oxford from Paul Newman's and
famous group where they have basically
taken their of Namaskar and we haven't
yet around how do you wrong way nursery
um you're learning are popular for like
the same route for like every day of the
year for many years so it's like hundred
terabytes right so you have like you
extremely precise like you know what
like you know partners as well as like
you know sure so basically this the
whole reason is because they want it
like this
protest like you know can are algorithms
to invariance okay so maybe that sounds
interesting is a huge data sets alright
like you know again computation of
challenges right like how many GPU
SEMICON Russia comes up so how would we
take something like that so instead of
passing like I say all right I know that
exists X right and then so so the Holy
Grail yeah well you want me to solve the
whole thing
your thoughts are like how I
architectures like these right is there
a possibility pushing in those levels or
I hope not
the only thing I can say I don't know
because that would put us out of a job
I still hope there is a some room for
actually thinking about how to organize
the problem yeah to get the results we
want but in fact like in this well it
looks like you have to do a lot of
legwork trying to understand each of the
components think it's implicitly there
so when you ask why did you do it this
way I didn't give you a very good answer
but I think it's also because then are
we we are used we kind of know having
played with this for 15 years that
that's probably the right way to do it
but we use color the the oxford data set
has color in it which actually is one of
the reasons that it's I think the one we
train on Oxford is better than the one
we train on the Roman on the Roman Forum
because it's more colorful but we are
not using it in a smart way so my my
colleagues have been just - it would
probably yesterday this</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>