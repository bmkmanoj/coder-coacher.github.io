<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probabilistic Programming: Generative Probabilistic Graphics Programming and New Research Directions | Coder Coacher - Coaching Coders</title><meta content="Probabilistic Programming: Generative Probabilistic Graphics Programming and New Research Directions - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Probabilistic Programming: Generative Probabilistic Graphics Programming and New Research Directions</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/UHOLC2FaLF8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
so my name is 0 / 0 and I worked have
been broken by the year professor
Tenenbaum lab at MIT in brain cognitive
science department and computer science
and artificial intelligence laboratory
and my supervisor was dr. Vickers
machine huh and I'm going to tell you
about explorations in true blue stick
programming I'm there is much
preliminary work will be presented today
and there are is there any questions
please immediately asked me and some of
this since those things are not
published yet so we are going to publish
so but some of them are published so we
will see and I'm going to ously to
introduce probabilistic programming
which has recently attract much
attention in machine learning and
computer science communities then I will
demonstrate to generative probability
graphics programs models which we
contributed to develop this year and the
first can we text from simple captures
and the second can find rose from Rio
guralt images with more compute yes it's
connected to computer vision so it as
approaches Jenner to probability graphic
programs and it's it's not come to
computer vision as people usually and
classically understand it so I will
touch this how is different how it's
connected to computer vision and other
things then I will touch briefly to
other research directions I'm interested
in a pass the scaling up general purpose
approximate inference in probabilistic
programs using parallelism which is
based on our preliminary work this year
and also i will briefly touch a match
loner term pass to automatic programming
we are general-purpose approximate
inference in probabilistic programming
settings so what's produced a
programming is I should like to describe
it using these two bullets here's its
compact compositional representation of
probabilistic models for example I hope
many of you know what it is it's
legendary allocation model famous enough
and this is graphical presentation of it
so people when
it can understand what happens what
connections here were dependencies and
this is the same representation of this
model but it's code representation it's
about three hundred lines of C++ code so
this is for humans this for computers
and it's considerably harder to
understand what happens here so now I'm
going to show you third representation
of the same model and it's written as
probabilistic program and it's just 10
lines of code and it produces the same
result the same inference which happens
in return C++ code which one sings that
goes that is give sampling and this is
mhm meta posthaste and inference but
there is no problem to make an engine
and we already have premiere ago where
instead of metropolitan we use Gibbs uh
you mean this one this via its yes of
course of course so we have alpha and
now it's fixed alpha hyper parameter 6
better better / hyperparameters fixed
this is topic document object
distribution this is topic your
distribution and this is when we get
your for each position in text and you
can see direct correspondence for this
legendary allocations but not what sorry
the arc from the edge from alpha to tita
oh is this one a research ok because we
use in document topic distribution in
setter we use alpha hyper parameter so
this is direct dependence 30 depends
directly on alpha and when we create
symmetric distribution there is direct
dependence on alcohol perimeter so
another good think that from
probabilistic code you can very easily
from
probably stick wat you can very easily
create this graphical representation
graphical model and secondly what
privacy program provides you it's
automatic influence where
general-purpose techniques example Gibbs
metrical hi stink smc sequential methods
and many other sex so let's consider
puristic programming on very simple
example bias network it's resistant you
can write in church church is produced
language o people here heard about it
and of course it doesn't show you the
whole expressiveness of this churn
universal language but this great
example to explain how short jokes so
I'm going to show here what happens in
church and I know how much you familiar
with it so it is boring to tell me and I
will just keep this part if not i will
continue so i don't know but around the
context in a good i'm ok great useful
gonna be actually also build a cop's
programming language but we use more
impressive see like okay i can be
written morons and you have done
building francis and so on but I so I
think we should go to details and I'm
going to find great just not to make it
boring ok so this is bias network in its
graphical representation and this is
probabilistic code which is
corresponding to this by Center for
example we have note mvs and it's
distributed to be a categorical
distribution with prior or point 10
point 9 and node V MCH depends directly
on AVS so it makes sense seeing sample
MPs from category category distribution
with parameters yes so previously in
church it was defined herein wait so I'm
showing now venture code venture is a
secret project in quad secret which is a
new probabilistic language discs ended
from privileged to clean which church
and we are going hopefully very soon
published paper on it and make venture
open source but not yet sorry so I'm
talking about church but many since i'm
showing really based on the nature so
sorry for this confusion it's just
because they're not as fast as a good
like of course ok so statement yes in
churches have mhm query so image query
you have a bunch of this is a yes this
is also danger i can rewrite if you want
this in church if is ok yeah now this is
also venture co thank you thank you for
this ok so this is clear and how
inference happens in the simplest
framework in torture random DP
implementation which is based on this
paper so if you i will sell sense a
presentation i will provide the
presentation and you can read about
random DB implementation of the engine
for church in light of eight
implementations by wingate at all a stat
2011 so how it happens you make us the
forward to valuation so sample from
prior all notes you sample this from
prior then you sample this from prior
condition on this one and so on and you
send a little notes one so for each not
to receive its value then you remember
all this random choices values tuesday
database then you pick up a random
choice and make proposal in it for
example you can pick up at uniformly
randomly example you pick up this one
and then you run the whole program reuse
of all the random choices whenever
possible so you can reuse this one you
can reuse this one you can read you can
reduce this one because it has cheap
changed but you can reuse this one and
just probability change we
the north which it directly depends on
has been changed doesn't make sense so
you can reuse all things excluding this
one and then you calculate a major
substantiation metropol has been
algorithm so you can calculate the
probability of all the execution you can
calculate the probability of new
execution and you also should consider
the transition kernels and transition
kernels is one divided by number of
random choices if you select random
choice uniformly randomly its local
kernel which we applied here how you
make proposal what new value have been
proposed here and then there is a new
randomness which hasn't been created
here because this is just the simple
bicêtre there is no any conditions but
because churches during universal
language generally you can't have
conditions and then you if you repeat
step from third to fifth you hopefully
converge to from prior to posterior or
one on Thursday observed statements it's
something which you also evaluate but in
current settings you just forced the
outermost random choice to be equal to
some value so let's return for example
to this slide one moment
for example to this slide you can see
that we make bunch of assumes and then
you have observed get short for document
52 for position at document three and
you observe world after mobile you can
see that get your it is a lambda
compound procedure which in its body
evaluate samsung code so when you
evaluate all evolution happens here and
just the last random choice which can be
forced is being forced so even in this
case is not the outermost point yeah but
in your choices ya in church just
doesn't have yes yes because there is no
observer you're doing adventure yes I
can show you how it happens if you want
here so you can see that we want to
observe that this is equal to optimal by
let's say automobile has IG in number
five example if you liberate each word
from 0 to 500 after wireless fix so this
has been evaluated and we evaluate found
some get topic Lord simpler get the
vapor sampler is another compound
procedure which returns to categorical
so this categorical will be forced to be
equal to five so this is how it happens
doesn't make sense so when for document
number 52 for position sorry this is
like what we call biggest fear if you
ever meet at visual exact okay okay so
sorry watch my part of this i will just
write down okay okay i can write down
too late okay or if you remember
again something promising programs using
showcase matically how to take something
ladies on mobile propagated backwards to
the right place and to the 4 sinker ice
chips em been produced a programmer
Yujin program analysis is ready 30 this
is a stash and because no support is ok
but this interesting so what's you do
the four secret it's not clear to me as
to why the next slide when you calculate
the Pete are you okay why that is
correct because what by singing this is
this one a boat is biased because now
you're forcing automobile to be that
value while x or whatever it is to be
equal to what a movie right okay so much
you force a value is Yura so it's not
like a regular yeah but I don't see any
bias because I mean you are forcing the
value of it's not it's not you're not
sampling from a distribution and then
rejecting the sample rate you are
actually saying that I wanted sample we
would not know I agree but in MH there
is there is no it should nobody tells us
it should be Simplot we just calculate
so we have some space and calculate the
way for that is bit yeah but we have
space of all executions is all possible
executions for this flattened additional
allocation model and we have this point
and this point this is a two different
executions yes p PX 0 10 PX knew that is
once you say you want a particular
sample value equal to a quick autumn
okey then it basically says that you
like this sampling your name is happy
because you want to reject all samples
which do not have automobile right now
we don't reject them we just don't go so
you don't reject them but you don't want
to generate them in the rain so which
basically introduces of ice
I agree but in terms of mathematics I
don't see where it makes a big
difference in fact in our paper we your
proof for them so you are actually
producing the math doesn't work out if
you sort of just force values we equal
to force variables to equal to seven
samples equal to certain values like do
we have four more here that's funny the
other issue is you are also memorial it
means right okay so it's right here why
it is you have a formal proof as to why
this is the correct value why this is
really neat converge to the supposed to
here knows paper doesn't have yeah about
that it will converge to posterior I
don't argue in general cases because
there should be navigated to converge to
posterior yeah in fact if you don't
place a weight these samples accordingly
you will not converge the posterior
that's what I'm see ok let's try to
understand is it connected to a grade
ECG or is it connected to some problems
to this probability it's connected to
both because inside in the door is a
usage allegory at the fixed point you
want to basically say that the fixed
point that you can do is you need to go
steal I agree but this we have this
verse erasure sir okay
we have X old which is all the dick you
shun we have X new which is new
tribution and let's say let's write
simple program
okay let's make a very simple program ok
ma placated back pain let's have a very
simple program which is X sample from a
binary distribution with mean p okay
let's say point five okay why you sample
from a bologna distribution is no point
five and then you observe let's say X or
Y like the posterior for this is 1 130
okay I joint distribution and let's say
I want to compute the Joint Distribution
of X and Y now in order for this to
happen you get a basically force my to
be equal to a2 for example when it
depends on what X is X is to you don't
have to fold everything right is this
off your the force one yeah but how it
will happen in venture in danger if we
consider this for example each is a
rejection same thing will happen which
is correct decisions am pleased courier
or yeah okay I go horse yeah I'll be
careful yeah but if we are talking about
logic like this yes this we want to your
convention so only if you don't have
never happens all yeah general
conditions just 10 so what conditions
are you talking would so this will
happen in venture usually rejection
simple because you can't force inside or
exactly yeah so is this i agree yeah
okay okay yeah i agree and okay a lot of
appeal is an instance of this reddit
equality constraint so you say x equals
automobile is a specific thing no no 44
after viola TV box and I can I mean I
can discuss with you why is correct
firstly actually the example of that
would be x equals 2 you can do that's
what you say observe x equals 3 and six
easily you can write observe AC okay
okay is that you don't really think it
would imagine that's what you can do it
I can but by forcing X to be too yes
however now true will be just forced to
be text just will be true will be forced
us to his room you have created with 8.5
as unfortunate you can't just force to
your day to the point 5 oh what a min to
wait because a new venture of each
sample should be associated in the
weight which penalizes the fact that you
are biased you have posted to be a
certain value so in this case a if you
have you for sex to be equal to true
then the weight associated that sample
you would be pointing in the constant
you cannot replace X shows up a random
variable that will be point 5 with x
equals 2 that's incorrect I you can say
let me for sex to be too but when you
add up a 2.5 that is that can you repeat
please right if you if you transform the
program another program in which you
erase the first statement X assignment
will appoint five okay with x equals
true okay then it's not that I agree we
don't do this so instead of what we do
we have we just force x to be true out
of a point yeah but I mean when we see
here with these probabilities of also
for sinks we add the switch because they
really yeah Rosa you mean p the airs old
+ PX news a have this weight of also
forced to others okay baby we can
disturb yours are like but the point is
okay that's one point one question I
have even when i read the judge paper
and maybe you fix this adventure is you
have a formal proof which basically says
that this algorithm here computes the
very concept is busy I mean you say that
right I mean it basically computers the
but yeah anything not yet me and we have
a published yet paper on nature exactly
because well it just doesn't have it is
curious turn over the venture next day
because what profits that came in say
that the algorithm that you're proposing
like this forward evaluation remember
our choices blah blah blah and so on
okay just compute the posterior
distribution represented by the property
promised approval we have an algorithm
which is trying to computer the
situation brain okay you want to say
that that algorithm is indeed computing
the posterior distribution over the
return expressions of the promise leak
program so do you have a correspondence
between the algorithm and the objective
which is the posterior distribution we
have draft of it we have draft of the
draft of the proof
okay so
and s on probabilistic programming is it
fine so we can move to two examples it's
approximate version image interpretation
using GP GP generate realistic graphics
programming and it's based on paper by
yashwant sinha potatoes Kulkarni to
first go thurs by me and by Professor
Roger Tannenbaum and force accepted for
names for full or presentation and first
let's dive computer vision which was
very successful and very successful in
recognizing objects characters a lot of
alphabets drawing boxes and computer
vision is great it's very
well-established area but they use
efficient bottom-up approaches for
example feature extraction segmentation
and to the best of our knowledge there
are a few limitation surfaces for
examples they require large training
purposes as well as lots of training
label data they are difficult to build
for example including the software
engineering aspect and they hard to
modify the required loads of feature
engineering engineering complexity
exists and the accounts in variability I
will touch this in the next slide in
additions humans can do considerably
more than modern bottom-up approaches
and algorithm example humans can infer
cell level or global understanding from
once image or milk and also tracked
object relations that for example if I
will do this with capital go down the
chair strength of floor and other sex
and computers and question can I do as
well as fluency and there is also much
variability in to distance for example
you can see many examples of captures
and you can see that how much
variability it is and how hard it is to
create some bottom-up approaches which
will do with all this variability you
also can look to this picture and then
can we make a bit light off oh it's fine
okay you can see that for optical
recognition system is hard to understand
what's written here but for humans most
probably can guess it is 140 peaky
beware
and we are proposing a new framework
which takes a step of hydration some of
these limitations and this country can
take consist of the High Septon
generator example very defines the model
we define sim parts parts objects on the
image and you define control variables
for example blue or variants I will
touch what it means then using this
Valle's from Sahai second generator
values of this variables you use
approximate render to generate the image
from your approximate render then you
have data you have real-world image and
using the heist a comparison Yusuf
probability how it's probable that you
receive real-world image if you have the
generated image and if you have control
variables for example blue and noise and
for example the high 16 generator can be
written in venture like this and the
heist a comparison can be written like
this for example when you compare the
image you have the generated image and
you get red channel from this generated
image you get pixel five cent from this
generated image then you add noise and
use normal gaussian distribution to add
noise to this villa for example some
noise tambourines exist and you can pair
it you force it to be equal to 70 37
it's from the real image valid they
actually want you found out that
posterior or the original image yes i'm
using photo or serious yeah and you want
to see your car I are is what what we
want to converge the posterior what
latent variables values are because we
want to maximize this probability
rafters begin so we want to infer
related variables and I will show what
280 variables could be in two examples
so was i I need your hair yeah I are
it's genuinely yes
what is it and you'll observe statement
will say I are equals ID oh yes but it's
been made with some noise by the IRS ID
is noisy version of my eye that's what
about the roughly speaking years I sorry
ID is noisy or shine even a nicer
version of ir yes and from them you want
information please yes so this is
components of GP GP it's probabilistic
programming together with generative
models it's automatic inference from
probabilistic programming its computer
graphic approaches because we don't say
it what am I prefer which you should not
view and let's consider a simple example
so sorry for google so when you create
google account you have capture and you
should solve it and this car frame yo
creo so you have the high signal
generator i will show you in a second
generative model this is a proximate
render so you generate something like
this
so this is from the staff proximity
render based on values from the model
parent Phyllis three doesn't go okay and
oh i see when i press this sensor it
stops to work sorry edges and is to
target and you see that it converge
sosta high stick and persian happens so
this is the generative model for this
capture example we have maximum number
of letters 10 we have of course so is
your goal then what what latent
variables are you say that's a deep
would capture is what I see there it's
actually ID pack so the picture that I
see there is like one moment where's my
mouse yes this is ID and this is IR and
sorry for colors is a inverted for I irz
inverted and you want even further was
your latent variable is no I are latent
variables is not I are latent variables
as this one's so in latent variables
exactly the description of this image
for example one latent variable is the
position X of the letter so you want to
make inference how many letters you have
here what letters IDs are abc15 this is
for example glitch we want to make it a
generative model you have some
information go back to TV slicing that's
an invasion since your data looks like
five letters you have maybe five eight
variables for what the letters up no no
sorry something like what is that I
always think it's not correct I'm sorry
so this is the generative model how it
is so this is the generative model for
this example so in generative model you
have maximum number of letters so yeah
even in this example it's it starts from
10 and then it makes inference itself to
how many of them directly
how many of them are present guys yes
you can eat each one of those and you do
the present elapsed yes that flexibility
here I see and three two of them has
actually a disposition yes it's a
natural inner sighs yes its rotation
it's grief what letter it is what your
time in fluid actually off those 10 what
is the value of what is the posterior is
present what is the posterior for boss x
what is the procedure for boss why what
is the posterior for science that's what
is great you're totally right so this R
sin part and you can see for example
using publicity programming you can very
easily just add rotation yep this is the
heist this is surrender approximate
render and this is the highest
comparison and you can see examples so
we created a set of captures and they
converged so we compared our results
with the state-of-the-art optical
recognition system tesseract and this
our actor received two searches seven
point seven percent of recognition on
this data set we came up with and our
system contains 74.6 percent of
successful recognition and you can find
it in the paper and here you can see
again the convergence so this it start
from prior you just put randomly all
things and then step by step of
metropolitan and gibbs it converge to
the capture to to posterior based on the
observation on given ID doesn't make
sense this example if if it is i am good
the orgasms actually know what I may
actually seeing as it once i am actually
getting as more and more iterations of
MH i am getting more and more precise
estimations of posting that's how it's
done for the away active status is you
have a generative morning with all these
parameters and so on and essentially
that's the input to capture and you want
to basically say that whatever you
generate plus some noise is equal to
that peers and conditioned on on that
observation able to estimate the
parameters and then once you estimate
the parameters right these are the
images you are getting for every
estimation thing progress every
everything that you are showing there is
different value of I'm different various
for the family hopefully the variables
other right go directly and as you do it
much more and more you are getting more
precise values with reference over alpha
speaking it yeah why don't we talk about
precise in terms of convergence arafa
speaking is actually I think what serums
mission is why you are you just like 1am
service all I've asking many answers
what is this why you should hold it as a
video what every frame about every
fridge is one twice for ingredient yes
there are two issues I mean the two
answers to this question why I'm not
sure in just one frame because first of
all it's inference and it takes time to
come to answer and you want to see how
it comes ah it's your son yeah yeah it's
iterations yeah and second answer is
sometimes then open is the real life
there is no just one answer there are a
few answers and I will show conflict and
Emma motorable you have seen it but so
the visors greeted in there is no one
answered but what does that correspond
to with respect to be infringed on oh so
the bar I got was well as you do
mhm as you're estimating parameters in
every iteration where every frame
basically shows you for that choice of
inferred latent variables that's the
imagery but if there is no one answer
that is a problem cannot be solved by
why I know this I don't I'm maybe around
by the decree because in interference
inference happens and adjust you if
there are two answers and if they're
circa GCT if you used to just move from
all answer to another that's a
difference moving from one answer to the
other is basically just the process of
influence thank you sir by go ahead is
suggested it's your reporting two
different answers oh I mean if you want
you can what you can do it just kill no
no that's not what's happening here I
agree yet hear it hear it converge to a
okay I agree totally agree with you here
emigrant okay so because of time because
i want to show so demos I'll go this I
will very briefly will touch this slide
so what happens here we just want to
show this high status testing the model
with much enough blue and global blue
and a noise in the model we receive
better convergence so if there is lost
elasticity it doesn't converge but if it
there is high status CCGs there is
enough noise and by noisy in Gaussian
blur and if there is not enough blue on
the image like this it converge but very
high specificity and also cases the
actual just think about this has the
stochasticity of you modeling generative
model yourself yes in the generative one
on the image process yeah mhm is the
same for owners and second problem is
final Road and left out of rotten right
off road it's a classical data set of
this problem kechi dataset bunch of
frames and the framework here looks the
same we have the highest we have the
probability graphic program which is
that
16 generator we have approximate render
and then this generated image you
compare it with real-world image so this
is a generative model for this example I
a must be first example about that that
you have recognition ok one moment I'll
show Japan a short time so we are trying
to find where there is a road where it
is right off road left off road and
lanes so this is problem for driverless
car so he doesn't make sense now yes my
daughter back yeah yeah in Russia the
same so yah yah yah yah hi good uh
generative model yeah and this
generating money also incorporates the
road and FM vegas valley road the road
left and right so don't understand it so
basically is the information you're
going to use that anything that the car
pro through his role is the kinds of
things that yes yes yes if they are
actually poised to something in fact the
car value that means that it's wrong
does the kind of it
what use are you mean why we are solving
this problem what is it what is the
integral definition overall Oh intuitive
definition of the road is a circa or
condos where pal car should go through
we're gods must go those statements are
actually bear the car actually been
those are the existing oh sorry I got
before I just saw some philosophical
point of view in terms of generative
model it's a bit different so we use the
one train image so we by hand a mark
where this road left off road and rafa
right off road let's let's start from
this so let's see how it happens we have
one train image of course of course view
so in data sets are about if I'm right
400 images in the dataset yes I in
sequence we use one train image and we
test on a few tourists images about 50
but if your question about thus they
find the fact that we have sequence
matter this is the question it doesn't
matter why because in computer vision
they they used to consider each frame
separately rapid speaking not to use
information from the previous image on
this one which is bad in terms of of
course if you have posterior from the
previous image on the next frame a
stereo on the next image will be very
very close roughly speaking but because
in computer vision they used to consider
each frame separately we do the same
thing and we compare when and when we
compared with Staters our techniques we
do the same but of course if it solves
the real program problem we should get
benefits from the fact that we have
sequence so what we do we have this
image and first we using k-means
algorithm we reduce number of colors we
reduce information up to
for g20 colors from this to this and
then by hand on one train in which we
mark our where is the road lanes and
where is the right of road and left of
road we've oh khuda ya for one train
image is done manually this will
your escape yes and then we for each
part of four we have histogram called
color cut a book called The Book of this
frame so this histogram is just
histogram for this road would change
colors other inward to proportion
they're located in this region doesn't
make sense is that easy to the source
one image now I usually doesn't hold
them reduces yeah I mean even till we
consider the different Road it really
took a for example setting so for Europe
has changed for example night has come
it will not work where and is this is a
limitation sorry but this is standard
classical data set which people do
account for example there is another
paper i will show you so what you go
take you seriously want to market you
have observed
and then what you what you believe I was
ready we will we have strength to this
400 images and the problem is classical
using a few train images we want to
predict for all others where road is
located so the problem formulation yeah
I'm going to discuss it of course here
roughly speaking how this previously
program programming we have generative
model and this connection to bottom up
approach which I'm describing here is
this color code ebook we solve the
problem what are you doing s I don't
know in we don't learn latent variables
for because latent variables or latent
variables for terrain image Rafa's
beginner provided by humans so we still
interested to figure out latent
variables for terrain image I'm sorry
for tests I'm sorry for test image we
are still interested to figure out rate
latent variables for the terrain for the
test image okay yeah what are you doing
with the painting Oh use making use of
the beam
vu yes so here this is a generative
model for 12 test image we are
interested to in fuel rod we draw height
lane position slain size and we are
provided with this color histograms from
the terrain image so I i see so I just
wait look upon this is that your
generative model and let's say any
latent variables some of them they
inferred from from the training set the
rest of them you want to be singing for
each of yes I'm Sinkin I mean we we can
turn this in this way it must
methodology methodologically I don't
know if we should do it I mean I I see
what you were you're proposing I don't
know miss at the logical it should be
stinking since we're not I don't know my
concern thank you so I like to consider
this that we have some prior information
about the girl which is based on one
train image and then we have just test
image or text images and we had the
problem formulation how it works what
you'll say what is your current
connection between the latent variables
or the training images there is no
legend good very good for the test I
think what is saying is all the
information that you get out from the
training set we go into the fire for the
generative model and all the added
information is inferred for each of you
through it estimates testing so what are
training eater you guys is going to put
it as marketers prior knowledge
because what the purpose is to talk
about it's not here it's not clear
really curious how you convert the
training set information into pipes I
ship that's why we were thinking you
know your body in Fort Worth think I
mean I'm sorry the other thing I'm
confused by is that I thought in the
test image you don't have actual marking
of the road you don't have to that's
what we're finding fur here for the
customers we don't come you don't have
right so if you don't somehow use the
information from the training images I
just think in terms of exactly your
problems to program the observe signal
is when you have the test data you don't
have an observe statement for the test
arrived we have four test data we have
observed decision or one of the others
get about the testing we are the best we
have okay maybe I don't judge described
the model is not to take training what
what the others if it is up to you the
colors oh but you don't know about the
end though that's the game baby yeah I
will describe the full sync okay and
then we see actually know the last
example you gave me is Vidya hey yeah i
mean i hope this off it will become
clear when i will describe it okay okay
so you understand what this means for
terrain image this color okay so we have
for this straight one train electric yes
oui oui by hand divides them for
foraging now we have one of four regions
the road and this road in this region
there are 20 different colors and we can
receive the histogram of this region or
y-axis
y axis is number of colors to NJ and
y-axis is the person is probability of
receiving color number one in this
region as I say exact number of others
my ex is actually fraction of image with
that kind yes fraction of colors visit
this image visions it's immature for
each color how much fraction it occupies
yes it's not an image sir in this region
yeah in the region you still have
diabetes yeah oh yes yes I see so role
will have one characteristic three
you'll have another characteristic just
so you know characterizing region by its
color composition great great how is
that ok ok ok great and now you can see
the samples from geometrical prior so
these are just samples from geometrical
prayer and liquid sees it as much
variability so roughly speaking road can
be everywhere make sense
and then when we have rode for example
here for example here here what happens
now imagine that this is a test image
and imagine that we put a rod here and
we extract the histogram of this region
of this test image and that we just
using multinomial distribution using
noisy comparison we compare this color
color book extracted from train from
test image with color cut the book of
the same region of train image and this
was you compare into the hash detectors
and here you can see a typical semblent
image so we remember that IG the real
world image is I are rendered image plus
noise he remembers and if you use
multinomial and rather speak and this is
generated image from the generative
model without noise steel by the way so
you can see that this is lanes and you
can you see here this histogram for each
of region does it make sense great ok
and this I results and you can see that
to be there is state-of-the-art approach
8le at all 2008 and they receive
decoration sixty-eight percent if you
use the one train image we receive
sixty-four percent I feel if you use 15
train images we use the seventy-four
percent and then we use just maximum
likelihood over a few train images runs
doesn't make sense
and people are basically report on
understand any good you use the trading
business to calculate you know I guess
priors for each of these color
distributions and then give me a
destination you would want the inferred
color distribution to be somewhat
constrained by a noisy approximation two
pirates that you got training center
that's the solver solid obviously
programs to your pathetic can you repeat
it yet so basically you have is that you
think what I gotta get which I think we
have a bunch of training set and from
these training sets then for each region
whether it is Rho order upside of all
these regions you are calculating the
distributions for your for your color
look at the books and then when you give
me a new image you don't know the
classification as well right but you
want to write a model such that the
classification in regions
you want to generate the classification
using a generative model such that if i
take that classification and calculate
the color or book for that
classification by confiscation you mean
fine inverter road is located there yes
okay by the vendor should fly generally
you want to find it okay to that the
gelatin water will generate that but you
can put a constraint saying that I i
wanna i want to sign on the
classification such that if i calculate
the color code book and the color code
book will be a noisy variant of the
color code books that i've seen very
close it was about 20 closed wait closed
that's pretty great thank you sorry no
no my I'm sorry okay so now I finish
these examples and I'm going to touch
briefly to since so first work is based
on preliminary work with vicars fancy
encourage a food which they now sell
some of these other people and it's how
to scale up in France and heuristic
programs and we have Universal inference
machine and we want to be to make it
faster to make inference tractable and
do you remember this machine network and
do you remember the to make proposals is
not but really we don't want to run the
whole network because well as of this
nose hasn't have not been changed
probability of this part and of this
part have not been changed and only
probability of this guy has changed has
been changed and probability of these
two guys have been changed because they
conditionally directly depends on this
guide and here we come to the notion
from graphic from graphical models of
Marco blanket and you can try to use the
same second sentence of charge but a bit
advanced because we have the fact we we
should do this effect that in graphical
models they are usually fixed while in
our case they can be changed because you
can have conditions because church is
universal and
so I will and what was the work of like
at least one vehicle a day so exciting
changes you know he does when he does
the sampling rate only a subset of
variables have their probabilities that
changed and it seems wasteful to
recompute the properties for all the
random variables see this Markov blanket
what it's doing is using these
separation and so on and so forth
basically say that here's a part of the
network which does not depend on the
rest of the part which means that you
only d compute values for variables
which are ya good it's great and really
you can if you save dependences of this
guy who's its children are you can
calculate these probabilities and you
don't should have to reevaluate the
whole program calculate probabilities of
hormones and you can see that we made
this preliminary oak and you can see
that in random DB implementation where
we're around the whole program it grows
quadratically where we increase linearly
number of data points while if you write
handwritten sample should go linearly
example this is isaac model and if you
use our cavitation traces engine where
we track keep track of dependencies we
receive linear growth and you shall use
this number of samples per second that
were worried no no this is average time
for one mhm skin and one image scans or
let's say in hmm each run on the whole
model let's say an hmm you have 100
related variables steps and do you one
scan will be good go in for example in
Gibbs over all these things these things
you can
passing on me we're using the blanket
and you elected yes yeah kind of blanket
version of it because it's not correct
for us to talk about blanket because the
truck show graphical model can change in
our case because you have conditions but
yeah it's your intuition agree and I
second sink as well as in graphical
models if you have track of the
dependencies we can make inference in
two parts which are not corrected
connected in parallel approximate
influence and we also have very
preliminary results on it I wrote
enclosure version of charge bench be in
charge and you can see that we receive
this standard curve this is ideal curve
an increased number of threads and
average speed up increases linearly and
what we have you can see here and we
think that this drop-down appears
because we don't deal this memory as it
should be so we are really interested in
this and we sink we received good
preliminary understanding that
approximate indifference happens and can
happen in ventures enemies in shorts
agents we react people is that in such a
number of independent parts that you
have to tell you how much gates
I agree on I agree I agree but if you
think of what you just told if you think
is connected to this I don't think so
because we had big enough malo so I
agree with you about this but I think
this is because we don't feel his memory
good enough exactly is across my face
instead I'm occurs when with with this
optimization without this optimization
so when you compare babe are you
producing the same answers yeah good
question so we care for yeah that'll
cover just go Andy sorry can I switch
off the light how it works here have you
done soon for some reason produce other
colors by the game in there are also
curls here I mean this I don't know why
I know notebook I see it again this is
goes here so rather speaking you can see
that if you use one core it goes this
way if you have two course it goes this
way faster and if you have four course
it goes here you can look on my notebook
a film and yeah so it converge faster
and even if you I describe this
preliminary oh and I also want to
describe so if you have questions here
please ask and it's 12 what was you oh
yeah of course I mean second is just my
personal research proposal draft yeah
yeah great great great okay and i have a
few demos which we like to present to
people this is car fifteen demo do you
see the slides what's written implied ah
so this is the very classic version
curve fitting we can put points and you
find the line so the model described
this fall as follow we can we have
coefficient C 0 C 1 full design we have
linear function as a compound procedures
the lambda function just plus C 0
multiplied c1 X where X is 1 into the
argument we also have noise to add the
hostages to the model and each point is
observation of because it's samples from
pass from distribution using metaphors
hudson algorithm so the point is not to
maximize the probability the point is
just to receive samples from
distribution using basically what what
it means is that the basically know some
stable equilibrium for the system
actually just go somewhere and then
because yes if you keep money imagine
unless you get all of it yes yes yes so
you're thirsty part yes yes and i think
it's very beautiful because as I told in
the real world there is usually there
are two beautifulness beauty sinks first
is that you in the other there are
usually a few explanations second one is
that you a note you don't become stuck
and local minnows
so this is clear right I can show
advanced curve fitting demo so this is
the same confident but now we have
polynomial up to fourth degree and we
have first degrees of three series and V
also set points and it samples different
explanations again and you can see that
the radius of the circle is noise and
for example this is lying like this
right and guess what will happen if i
will put here point yes I mean degrees
been made in France on online yeah I you
she explanations have been changed so I
mean I don't do anything but it just has
changed explanation from polynomial
first degree so linear also another new
one yes pull the other baby why it just
became outlier because in the model we
have outliers yes and this also has
became out there because the one hole is
Kia yeah so we can either warm tests all
decided but there's no plan yeah yeah
and model is just this up to listen so
about maybe 20 lines of wind of change
your code so I'm saying actually that if
you don't have not basing viewpoint and
I'll play this article is that what your
point is no if I do this quite sign
something oh yeah yes but it is not the
major point I want to provide the major
point I want to provide this probability
programming is good into sense because
it's compact composition representation
of model and second because you can get
benefit of automatic inference
techniques
which people can advance and generally
use does too but I thought actually the
third one right like for example I can
now have a bottom said it's unclear i
can decide the model of pliers and
nothing changes it's very easy for me to
change the program also have our pliers
highbury which man can I the moment I
infant invent outliers like if I we're
in optimization I now do a new
formulation LP formulation or something
like a raccoon that in order to I mean
in some sense you know it was the point
that actually you don't have to double
the new inference algorithm which also
includes outlier site which you would if
you add SVM you're a separate paper
great yeah so the routers yeah we use
number of papers may go down so your
students and be it yes and last example
actually I should be avail isn't this
work I should be able even first
ourselves as you may have part come on
again so on so I using spite of all our
good comments view like this for great
and this is last time I therapy picture
where you have clusters and model is
again from here to here it's classical
Chinese restaurant process mixture and
you see here how inference happens and
how do Oaks up and you got you seek
point here right and let's i will add
point here and you can see that there
are a few explanations for this point
now right and you can see that sometimes
it's off sorry this I'm sorry Susan
Chris
so you see three points here in two
points here and if i add point here it's
either separate or they connect it so VC
different explanations okay yeah i'm
done with x presentation sent very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>