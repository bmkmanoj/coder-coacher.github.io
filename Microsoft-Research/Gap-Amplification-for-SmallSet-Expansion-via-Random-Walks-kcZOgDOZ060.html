<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Gap Amplification for Small-Set Expansion via Random Walks | Coder Coacher - Coaching Coders</title><meta content="Gap Amplification for Small-Set Expansion via Random Walks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Gap Amplification for Small-Set Expansion via Random Walks</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kcZOgDOZ060" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so today at alleles from will tell us
about this from all set expansion
conjecture it's a little is a graduate
student at UC Berkeley and now she's an
intern ian and microsoft research so if
you want to prove or disprove the
conjectures it's the right time to do so
talk two hear after they talk about it
thanks for the the very optimistic
introduction costilla um so hello
everyone thank you for coming to my talk
um if at any point you have questions
please ask because I know the crowd is
of varying backgrounds but I'll begin
with a couple definitions to level the
playing field so I'll begin but defining
the expansion of a graph and or of
assets in de Graaff so basically the
expansion of assets in the graph is a
measure of the connectivity of the graph
it's the number of edges leaving the set
divided by the total number of edges
inside the set in a deregulate um the
the you know the notation of the
finishin is not that important but
please please remember this notation
because I'm going to be using it
throughout here you can see an example
the step circled in red is relatively
not expanding in the set circled in blue
is relatively expanding set and then
it's interesting to ask what is the
minimum expanding set inside a graph so
that is the question that is the
parameter is the graph expansion you can
ask ok what's the minimum extending side
and side of grass in this case it's
again the set circled in red and you can
kind of generalize this to ask ok say
that I don't say that I want to only
find non expanding sets of a specific
side i say i want to limit two sets of
size you know one sixth of the total
number nodes in the graph what is the
minimum expanding set of that size so
here we can see in this example that
although there might be a non expanding
set inside the graph it's possible that
all sets of size 16 don't expand their
do expand a lot um and so this is an
interesting extension of the problem
okay and so and so you can define the
problem a uniform sources cut which is
given a graph find the minimum expanding
set and this is np-hard but we have
several approximation algorithms for
this one of them is is cheaters
algorithm and this algorithm is going to
be pretty important than the talk it how
simulator is anyone would anyone like a
refresher if two years algorithm okay
I'll get your refreshment you girls
algorithm so Cheers algorithm is
basically an algorithm with the
following guarantee say you give me a
normalized adjacency matrix and the
vertex and um I will return to set this
has expansion its most this quantity
relating to the vertex and then
adjacency matrix so this is like the
Rayleigh quotient of the of the vector 0
normalize meaning that it's stochastic
okay you said a vector V yes if you're
either you said a perfect for you oh I
meant it back there yes um okay and the
way that the algorithm works is you take
the vector and you order the vertices um
or the entries of the vector according
to their size from least to greatest and
then you output the set that maximizes
this quantity right so so you look at
the first you know vertex and if this
minimize and then you take the first two
vertices third vertices and you up at
the set that minimizes this right and
the analysis works basically by choosing
a probability distribution over the
index its which you break the set and
and you know you bound the expectation
and that gives the desired approximation
ratio okay so this is something that I
will use later in the talk as well
there's also other approximations for
example Layton Rao in or out of phase
Ronnie and they're better in some
regimes um but that I won't discuss them
today okay so now there's the problem of
approximating the UM
sets of sighs its most Delta right so
this goes back to the expansion profile
and and the question is what can we do
with this okay so so there's some
algorithms known one of them due to
someone who's sitting in this room in
part or two people who are sitting in
this room um and and the the point is
we're not we don't have quite the
chiggers guarantee here right so in the
case of Brigham Anderson to Tully we're
off by this factor which is okay if
Delta is constant but it gets bad if
Delta is really small inversely
exponential and here for the algorithm
of Icecrown and Travis on there's a
trade-off between how good the expansion
approximation is and the size of the set
so if you're willing to act but a larger
set you can get a pretty good
approximation of the expansion okay so
why why care about small set extension I
so I could I could give you reasons in
you know an industry like I'm facebook
and I want to you know test a product on
a small group but but actually there are
better heuristics for that like choose
New Zealand you know so so really what
the reason we care is because of theory
so small so expansion um is kind of
embroiled in this important question in
theoretical computer science about
tartness of approximation so some of you
have probably heard of the unique games
conjecture um if you have heard of it
but don't remember a tour if you've
never heard of it don't worry but but
the point is basically the unique games
conjecture asserts that a problem called
unique games is np-hard to approximate
within a certain ratio and if unique
games is np-hard we have reductions from
it to vertex cover into a bunch of
constraint satisfaction problems think
like three set in Mexico but this is
really it like a huge family of problems
and we know that if the unique games
conjecture is true we have optimal
approximation algorithms for vertex
cover and all the constraint
satisfaction problems in small son
expansion is one of the few problems we
know that reduces to unique games so if
we can show the small set expansion is
hard that would imply that all of these
problems are hard to approximate and we
have optimal bounds
and and vice versa there's kind of a
weaker reduction from unique games too
small said extension this has some
assumption on the unique games instance
that you have namely the small sets
expand more um and uh and so showing the
small set expansion is easy to
approximate within a certain ratio could
have implications that I mean it has the
application that some version of unique
games is not not difficult I'm throwing
dabbed on to this whole picture okay so
so now in order to understand the rest
of my talk to you will need to
understand this notion of gap problems
um I got problem is the following say
that I am hitting you a graph and I
promise you that either all sets of sat
or there exists a set of size Delta V
this has expansion less than some
parameter C or I say all sets of size
Delta V has have expansion in fleece
tests this is known as a gap CS problem
I model it with small so expansion
because that's the one that we will need
for today um and okay and denote this
problem in the following way so an
algorithm for the decides between a see
ask a problem which tells you which
scenario you're in gives you an S
oversee approximation algorithm
this thing I go back to the previous
life yeah
confers
okay you're thinking this is bigger
let's see uh yeah yeah yeah it's a
minimization problem okay right yeah so
if you can distinguish between these two
cases you can say whether you can get an
approximation for the sector okay and
gap implication is when you take a gap
problem and you reduce it to a different
gap problem where the gap is wider so in
essence you're taking an approximation
saying it's hard to approximate within
alpha and then saying okay this is this
reduces to approximating within beta
where beta is an easier thing to
approximate so here you can see in the
example of small cell expansion this
would be like taking is that the kind of
expands but not that much sure is that
the kind of expense but not that much
and then really widening the gap to set
that expands completely and asset that
expands almost not at all okay and gap
amplification is a useful tool improving
hardness with proxima shin results if
you want to show that a problem is hard
to approximate width ratio beta what you
can do is you can take a problem that is
hard to approximate width ratio alpha
say you know some problem is hard to
approximate with an alpha and then you
can do gap amplification until the ratio
becomes beta right and that's in that
implies that um the problem that was
hard to approximate within alpha reduces
to the beta problem and so the beta
approximation is also hard and another
reason you would do gap amplification is
if you want to show that a problem is
actually easy to approximate within some
ratio so you can take a problem the
problem of approximating within ratio
alpha and reduce this to approximating
within the ratio beta see a gap
amplification and if you have a beta
approximation algorithm you've just
disproved that it's hard to approximate
the problem with an alpha and in our
case we would be happier with a result
like this or because because we don't
know I mean we don't know a problem that
is hard to reduce unique games but we
could hook small cell expansion but we
could hope to take small cell expansion
with with the ratio that we want reduce
it to a ratio that we already know
because of the approximation
rhythms and then show that it's easy
okay so and and for for the first reason
it's important in a in these two
settings um label cover is very
important problem and also unique games
and gap implication results are known
for both of these problems and the way
that you prove gap amplification results
um oh sorry so okay so so the way that
you proved gotten play vacation results
for these is you do something like you
take a graph tensor power of the
underlying instance I'll explain that a
little bit more later um we our method
is not that and is a nice benefit we
don't have any growth of the vertex set
and stuff like that so it's kind of a
novel gap reduction or gap amplification
ok so our result is a gap implication
results for the small side extension
problem matching the known unique games
gap amplification result um if you want
if you want the technical you know
theorem this is it basically if we have
a function that grows slower than root
epsilon we can reduce between epsilon
and F function to any constant and and
data um but ok but this is actually the
main idea ok so so let me go back to
this to this graph tensor power so
normally to do to do a reduction to do a
gap implication in label cover or in
unique games you take an underlying
instance which is a graph and then you
take its sensor power um taking the
tensor power essentially amounts to
taking the Cartesian product of the
vertex set and then adding edges between
two vertices in the paragraph if both of
the endpoints have edges in the
underlying graph as well so here you can
see the tensor power of this edge which
is a simple graph ok so then you would
think that since unique games and small
cell expansion are kind of related
probably that you you could try to apply
the same sort of
idea in order to achieve gap
amplification for small site expansion
because this is the way that gap
amplification is done for unique games
okay but there's an obstacle when you're
doing this so the obstacle is the
following say say I started with a gap
that falls into the to the no case that
falls into the case with every set with
size Delta has expansion that is too
large right but say that there is some
set with sighs Ruth Delta this has
expansion that's in the yes case right
that that has pounded expansion and now
i take the tensor product of the graph
and i look at at the product of the set
with itself ok so this set will have
size Delta in the new graph right in the
in the tensor paragraph but on the other
hand its expansion doesn't change very
much so if it had expansion epsilon here
it has a special expansion about epsilon
here and so that means that we can we
can fail to reject graphs that we should
have rejected right we can we can fail
to in this case we can say oh yeah
totally this has a set the size of most
Delta that expands both most whatever
and on the other hand here here we don't
ok so this is this is a problem ok so
what makes sense for for gap implication
in small so expansion random walks seem
like kind of a good idea here because
sort of by definition of expansion if is
that is not expanding then the
probability mass of a random walk
today's trapped inside the set for a
very long time like here but on the
other hand if a set is expanding then
that means that a random walk started
from that set will spread really fast
across the graph and so we can try to
think of taking the graph powers in the
matrix power to do the reduction instead
of taking the graph tensor power which
corresponds to the random walk
okay so that's what we do that is a
reduction so we start with a given a de
regular graph with a lazy random walk
matrix m we are graph that our output
graph is going to be the teeth power of
this matrix and so essentially what that
means is we take the original vertex set
and on it we put edges with the
probability of starting at vertex a and
ending its vertex p um here the the
reduction parameters are not very
important right the main point is it
okay if we choose if we choose the
parameters carefully we can amplify the
gap ok any questions at this point
before so he had self loops for the
matrix am yeah yeah and as M is the
matrix with self-worth already added
change something like the vortex haven't
even seen you're just stealing debates
long exactly yeah yeah so it's sure if
you start with zero weights on a non
edges there must be some limit damage if
you never fight
there is no is that well so so we can
get this gap amplification right for
some for some parameters it's
meaningless right like for example you
know when when this becomes 1 or ever
division oh I see so so this is assets
that expand by its most a and for its
also expanded by police be and it maps
to sets that expand by the most half TA
or sets that expand by police tvs word
ya got dolls will become Delta Phi right
oh yeah Delta Delta maps to a new value
method any other yeah so maybe this is
actually the better way to think of the
limiting um if if you choose t too large
then the set size becomes really really
small yeah
other questions the ohmic specific
console is it oh yes well it's not just
this is a constant it's also is it it's
a lower bank hey guys what I mean no no
it doesn't have anything else yes
there's some pickle uh that's made on
this yeah yeah completely yeah it's one
hundred percent structural I will get to
that okay okay so the proof proceeds as
follows so first we have to show that if
you have a set that did not expand by
very much in the base graph when you
take the power of the random walk matrix
it won't expand that much in the in the
final graph and then we also have to
show this if the set expanded to begin
with then after T steps that they're in
lazier and and walk it will expand even
more so we get upper and lower bounds
for the expansion of the set after
applying the graph power and the this
proof proceeds in the following way
first what we do is we say we proceed by
contradiction and we say if I said did
not expand enough in the final graph and
after T steps of the lazy random walk
then there must have been some step at
least one step in which it didn't expand
enough along the way um and then what we
want to do is we want to take the vector
corresponding to that set and applied
cheekers algorithm to it but there's
some technical difficulties because the
support of the vector might be too big
and there we use a method similar to or
a broadcaster to to reduce the support
of the vector and get the set okay for
the for the first part in which we say
that non expanding sets don't expand too
much we can apply this this bound which
is known and a vise ground and Travis on
have a particularly nice exposition of
it when you're trying to prove something
a little bit more sophisticated and so
so maybe I'll tell you guys a little bit
about how this goes in case you don't
know but but in the end
it is this you can found the expansion
using a power of the extension so what
do you essentially do is you turn this
into a problem about positive
semi-definite matrices um the lazy
random walk matrix is positive semi
definite and for any positive
semi-definite matrix p and norm one
vector X you can show that this
quadratic form is larger than the
product of these two quadratic forms so
essentially if you look at the expansion
after T steps of the random walk it
should be greater than the expansion or
it should be less than the expansion
after one step in the expansion after
there after t minus one steps um and and
then what you can do is you can turn
this into to a problem about eigenvalues
um you can you can view this sum which
is actually this quadratic form as an
expectation over the lambda I to the K
and then you can apply chebyshev simon
equality because the matrix is positive
semi definite and all of the eigen
without victory or augen values are
positive not negative Jensen no well
maybe you could apply those things in
equality well I thought you wanted to
use connects to your lambda I to the
cake like them yeah you can do that it's
it's this it turns out to be the same
like this is just an inequality that
says if you have you know ordered and B
and you take a product like this it's
positive but I think you can use
convexity
if you don't have to like the water
should not be it's a
yeah the positive positive the
positivity is important yeah
is about to be important evolving which
discusses as a lot if the positivity is
important to this proves but not the
delicious intensive if something is
utter even though so I'll given this
proof does depend facility but but the
basic inequality there that is just
reversibility I'm just need
reversibility yes for this poor Wall E
the evidence x550 x is bigger than when
I expiry X to the power teams if they
are like that mean body work's and then
if you have maybe tonight you guys up
but it's a next actually it's a special
case of the seed Oracle projector which
is not known but that special case is
known from the fifth yo from the 40 to
50 I wants it touche I'm like a whole
list of references and it keeps being
rediscovered man x no girl on Tommy we
discovered any fault you roll it up and
then found it has no him earlier
references thanks okay okay so so in any
case this suffice is for the upper bound
on the expansion of asset in the target
graph given a bound on its original
expansion ok so now now in order to show
that sets that already expanded in the
original graph expand more in the target
grass what we do is we say the following
well if by contradiction is that did not
expand enough after and after T steps of
the random walk then we look at the
probability mass of the set each of the
different walks and we say okay well
there must have been at least one step
of the walk in which there wasn't enough
expansion so and we tried to what we
don't try to identify that set but just
the existence of that stuff is enough
okay so let's suppose by contradiction
that there's some set s with bounded
size such as its most the expansion is
bounded by beta in the in the target
graph okay now let one sub s be the
indicator vector for us and what we're
going to do is we're going to try to
extract from s asset that did not expand
enough in the original graph and get
from that a contradiction okay so so we
know that um 1 minus beta is less than
this quotient just by definition of
expansion because 1 minus this is the
expansion of the set s okay and then we
can translate that into the statement
about norms of factors and now what we
do is is we say okay well if this
product of ratios right if we look at
the product of the norm of V 1 over V 0
where where VI is the district the
distribution over probability mass of
vectors at the ISTEP then if we look at
the quotients of each of the steps we
look at the product what we end up with
is is the quotient from the beginning to
the end and and this is actually the
quantity that we dealt with before which
we have a bound on because of our
assumption that the set did not extend
enough okay and then we know that at
least one of these terms has to be
bounded by the two over teeth route
okay so so now what we hope to do is we
have we have this vector and we have a
bound on on one minus its we have a
bound on its Rayleigh quotient and and
we know the chiggers algorithm can give
us a set with expansion its most route
that
um but but the problem is that this
vector might have really large support
right like this vector might have you
know all n vertices have nonzero support
and then chiggers algorithm might output
a set the test size and over two and
that's not the way we want we want to
bound the number of vertices in this set
okay so we can we can troubleshoot this
issue in the following way we take our
vector and we pick some threshold theta
and for every entry in the vector less
than theta we just set it to 0 and four
entries greater than or equal to theta
we just subtract theta and then using
some bounds on theta and the two norm of
V which we get via the expansion we can
conclude that the Rayleigh quotient this
um which which is used in intriguers
algorithm to get the bound is bounded by
the by the Rayleigh quotient of the
vector before threshold reducing our
threshold effector did not affect its
its Rayleigh quotient too much okay um
so so then we can just use our previous
bound right we have an upper bound now
on this really quotient and from there
we can apply cheaters algorithm and we
get a bound on the expansion of our new
set and we also have a bound on the size
of the new set using markov inequality
or what have you okay and then and then
essentially by selection of parameters
we can get the result so we have the
following result um small sub expansion
with sets less than or equal to a or all
sets expanding by by at least be if size
Delta reduces to an instance of SSE
where for all set sir sighs for Delta
over TV squared the UM sets of size half
there's exist excessive size half
ta or all sets are greater than T V
squared and it's clearly polynomial time
because all we do is apply you know T
steps of random walk and the way that we
do this was first we showed that non
expanding sets don't expand too much
then we showed that expanding sets ended
up expanding a lot by contradiction and
basically what we did is we we bound the
expansion of a the J step of a random
walk starting from s and we controlled
the support size of the vector by fresh
holding and then we apply chiggers
algorithm so pretty simple okay and then
in order to get our kind of more human
readable result you can just set the
parameters like this and and you get you
get this result which is analogous to
the unique unique games but um this is
the best non-gaap application for unique
games but you know it's not like I think
this isn't the main the main message
then I think you know the main idea is
you can do gap amplification using these
random walks this little human readable
slightly what is ether oh it is it is
any any constant you want so for any for
any ADA that you want here there exists
some epsilon if you can reduce from
epsilon related like this I don't know
what it is about me but i prefer the
nonhuman yeah this is it no i think then
on the non-human readable version is
kind of like a you know the victors
write the history books kind of thing
yeah sir okay so I'd rather not say um
okay so open problems from this I think
I think there's a lot of open problems
but a lot of them seem very difficult so
the first the first open problem which
was the original open problem for this
work is can you get the more amplified
gap amplification for small side
expansion and also it would be
interesting to get a tensor power-based
gap implication for small set expansion
or in and walk based gap implication for
unique games so so a little bit more
about each of these problems okay so if
we can amplify the gap from small set
expansion with all sets or with existing
asset expanding by at most epsilon or
all sets extended by at least 1 minus
epsilon to some gap version of SSC that
we know is easy to approximate then this
would refute the hardness of the more
constrained version of unique games and
that would be a very interesting result
because it sort of sheds light on on the
unique gains conjecture and and maybe on
the difference between small said
extension unique games
yeah we did not achieve this gap
implication
another another interesting thing to do
would be to get a tensor based gap in
plif again for unique games or a random
walk based sorry I tensor based gap
amplification for small cell expansion
or a random wit walk this gap
implication for unique games the reason
being that you know we think I think a
lot of people think of these two
problems is relatively equivalent so
it's strange that the two the two
problems aren't amenable to the same
kind of gap implication um in in
applying tensor base camp application
too small so expansion one needs to
overcome this issue with the
completeness the problem you know you
can get new non expanding sets just by
applying tensor products and I've
thought a little bit about this but I
haven't been able to resolve it in and
on the converse side maybe it would be
possible to get a random walk based
reduction for unique games which I've
also thought about a little bit and this
would also be nice because the random
walk based reduction does not amplify
the size of the vertex set and so this
could lead to better gap amplification
because the the size of the graph won't
be a limitation as it is usually but the
obstacle that one runs into here is say
that your base graph is is disconnected
has um has several components and say
that one of the components has a really
really good assignment and the other
component has like a so-so assignment
then when you uh you so what do you it
would be natural to do is to take the
label extended graph and to apply the
random walk to it until the and until
the problem gets harder or I mean easier
but but the problem is that for the
perfect completeness component when you
apply there in and walk it doesn't get
any worse right so if you have a
component of size a third that is
perfect that's the lower bound for how
much you can amplify the gap um whereas
you know if in your other component
things get worse and worse it doesn't
make very much of a difference so
overcoming this problem also would be
interesting um I thought about this a
little like maybe
II one can put some kind of expander on
the whole instance but that didn't seem
to work out so if you have any ideas
about this I'd be happy to discuss them
and yeah thank you questions is one
difference to the defecation or any
games is also that like it maybe it's
just always said it if you want to
reproduce the gap no you want episodic
episode it's supposed to one and the
basin that um funny I defer to it gets
hot oh yeah sorry I think for the unique
games it should have been 1 minus the
corresponding so I guess I mean most
expansion you could hope that you can
help define the gaps great why anyone
and do you think about and something
that's like a and I guess I'll get a
manager I mean one or second floor that
is that I guess chicas inequality the
way you usually use it I said it sort of
concentrates on expansion close to zero
right but they are also the variance of
she goes inequality that deal with the
whole range of expansions of all oh so
one what's do so just wondering if you
try to increase again from how to +1 no
we didn't we didn't we thought about a
little bit we didn't
as I thought so you're using Louisiana
walks is there other is there any reason
to suspect that some kind of Drew
corrected random walk or other I've read
and walk with thee together you can be
able to play other shadow you're like
inequalities that come with those right
walks and give you some other ratio or
not that one of the run box it's a great
break that ran a walk like you walk you
won over some biasing by bigger you're
right so so this I mean all the results
that I presented today we're 40 regular
graphs but actually we also have we i
mean we have analogous results for um
for you know any degree distribution and
there we again we do always are in a
walk actually more questions
but famous people</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>