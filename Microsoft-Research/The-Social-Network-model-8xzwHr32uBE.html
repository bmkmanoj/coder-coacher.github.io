<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Social Network model | Coder Coacher - Coaching Coders</title><meta content="The Social Network model - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Social Network model</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/8xzwHr32uBE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
welcome everyone we're very happy to
have yonatan sermon from Berkeley who
will tell us about social connectivity
okay so thank you for having me and
thank you for coming so the name of the
model i'm going to talk we call it the
social network model and so the first
part of the talk the main part will be
about my master thesis so this is joint
work with the type in germany which was
my adviser and gaudy Kozma bought from
the vitamin institute and later i hope
to get to talk about the work still in
progress with the ben morris LM sly and
one of Ben Marissa student chew on
kindle okay so yeah those we start
several independent random walks on some
given graph and for instant we may
assume we start with one walker in each
vertex at time zero I have a very nice
picture for that okay and it's totally
worth that okay and it went to walkers
which the same vertex at the same time
they are declared to be acquaintances
okay but they don't stick together so
the workers don't call as they continue
independently we just keep track of the
fact that they met each other ok so this
induces the an equivalent relation which
is having a path of acquaintances so we
say the two workers have a part of
acquaintances between them say call them
a and B if I met somebody you met
somebody you met somebody met be so we
study the evolution of the equivalent
classes of this relation and in
particular we occur we care about the
first time in which there is only one
equivalent class okay
and so as I mentioned this is the
workers don't colors but we can view it
as a coalescence process of the
equivalent classes right this time
increases they become their become more
less and less equivalent classes so it
is perhaps plausible to argue that this
model captures some aspects of a real
evolution of real social networks at
least of the of the sizes of the
equivalent classes yeah not so much of
the internal structure because there is
no reason to see some you know the
degree sequence like you would expect
but yeah but anyway we don't make any
such claim and we didn't try to prove
such claim okay so a bit more precisely
at the underlying graph graph in which
the workers work we call it G ok and we
always assume it's connected so I'm not
going to mention it every time and we
don't have problems to deal with the
loops and multiple edges so we allow
them and so in this part of the talk we
only going to consider the case that g
is the finite so we denote the size of
the graph by n and we're actually
interested in the synthetic behavior so
implicitly with some sequence of graphs
with size tend to infinity ok and all
the result results are in terms of with
I probability and so yeah I'm I didn't
say that so this presentation is the
very old day so I didn't improve it and
I didn't update so I'm sorry for that so
I'm going to discuss only two starting
conditions the third one is less
interesting so either start with exactly
one worker in each vertex or start with
the at vertex V with a Poisson number of
workers and do it independently for all
vertices and at vertex we use the end
times the value of the stationary
distribution at vertex V and this is
with respect to simple random walk ok
and we called the Poisson starting
conditions and this is normalized in a
way that they expected none
 will be n and right for regular
graph this is simply placed on one
everywhere and okay so the workers
perform independent lazy simple random
walk because we want to avoid problems
of parities and bipartite graph when
some workers will not be able to meet
you meet each other and buy less a
simple random walk yeah the usual
meaning that either you stay in your
current position with probability 1 F or
move to one of your neighbors with equal
probability right unless there are a
loops or multiple edges and then
obviously deputations ok so the
acquaintances graph at time T we denote
it by GT but it should not be confused
with the G the underlying graph in which
the workers work it's a graph in which
any vertex corresponds to one of the
workers in a bijective way and we draw
an edge between two workers if they have
met up to time T including ok so this
enable us to use the language of random
graphs instead of equivalent classes so
obviously the connected components of
the acquaintances graph at time T are
exactly the equivalent classes right of
the having a path of acquaintances
relation so as I said we care about the
time in which there is only one class we
call it the social connectivity time so
we can now describe it as simply the
minimal 84 which GT is connected ok so
one example to illustrate what I said so
far but also to illustrate another
important point so let's say we give the
workers numbers these names so these are
the names of the workers and let's say
this all the acquaintances that that
were made up to time 3 then we say that
Walker one and woke up forever path of
acquaintances between them and we allow
such a path but notice that the edges
were not added in a monotonic
with respect to the time manner right
but but we allow that okay but
monotonicity in time for other
previously studied models is required if
you want a model spread of information
or an epidemic because obviously a one
cannot infect another person with the
deadly disease today if it's only get
exposed to that disease the next day
okay so a comparison of our work to
previously studied models so apart from
the monotonicity in time we don't
restrict ourselves to nice graphs like
CD or trees or expanders okay but more
reported importantly is the monotonicity
in time for instance consider a cycle of
size n so if we start with one infected
individual the time and we need until
all individual get infected well
deterministically it at least of order n
but actually it's of older which is
theta of n square over log n okay this
is not trivial but but this is the order
and now we can ask yourself what's going
on in the social network and model in
the in the cycle so it turns out that
the answer is much much faster than this
and you can start thinking about it well
while I'm explaining the solution so for
simplicity I will give the starting
conditions where in each vertex we have
one worker at time zero and in
continuous time because it avoids some
technicalities but then to remain the
same in any other combination of work
type and starting conditions ok so let
vnu be two neighbors
and we look at their nearest neighbors
from each side at their C log n nearest
neighbors then C will be determined
shortly so let's call the edge between
them e yeah ah ok I'm sorry i meant that
the the ok so this is the neighbor of
you then we have u1 u2 and you we have
you see log n yeah
so okay so we think about these two
groups as a set as two armies that are
trying to force these two guys to be at
the same cluster by doing a tongues
motion okay and because we do continuous
a time and simple random walk we can't
have the case that two workers at some
time our ear and then exactly at the
same time they switch positions by
opening above each other good yeah but
but in the lazy simple random walk case
you have to deal with that and you get
the same answer maybe with different
constants so it's enough that at least
one worker from this army will end at
this side will cross Ian state USA and
the same thing for one worker from this
army and if you're going to do d which
depends on see obviously log square n
steps then you can make sure that the
probability that this doesn't happen is
at most say n to the power minus 2 and
then you can just do Union bound overall
at most an overall end neighbors so with
I probability we get the social
connectivity time is it most of all the
log square n and it turns out that this
is the tight this is also if we do a
small constant epsilon logs where n
steps then the with I probability there
will be a lot of edges that no worker
I've crossed which once you have to like
this you know that social connectivity
of it has not been achieved yet
okay so the main results are poly
logarithmic upper and lower bounds and
the social connectivity time assuming
that the family of family of graphs we
work with is a bounded degree okay which
might might be a bit surprising but as
you saw even for the cycle you
intuitively you don't expect it to be
log square but but that's the answer and
before discussing eating more details
and I'm going to present only the proof
of the upper bound which is more
interesting I want to mention some other
secondary results I'm receptive at the
time so this is result in terms of with
I
yeah we believe the cycle is the worst
example at least up to concerns and we
have good reason for that I will get to
that so some other results
now I didn't see that with I properly
that wouldn't you quite sure yeah okay
so the first thing we considered just
because it's easiest was the complete
graph so it turns out that the answer is
log N and it's very concentrated around
it so without probability its log n + 1
+ little of one and and if you're going
to do one plus C step then ok so this
converging in double exponential rate
with the sea okay after three steps we
already have a giant component with I
probability but two steps are not enough
okay so there's some analogy between
these results and a non result about GNP
and which are that add the threshold for
connectivity for gene p is log n over n
and also there if you add a constant C
ear then you have this double
exponential a convergent in C and in
both cases the threshold for the
bottleneck for achieving connectivity
are the isolated workers okay and when
you think about it at least this result
make a lot of sense because after login
steps the marginal in both cases are
similar and when you think about it the
acquaintances graph after login steps
the edges are in a sense almost
independent so y Aristocles not very
surprising okay so one question which I
returned to is it makes sense to guess
that perhaps the complete graph as the
lowest social connectivity time right
add up to negligible additive terms so
this turns out to be true in the case
that the graph is regular not
necessarily of bounded degree but in
general this turns out to be false
you you you can push you can make it
lock and with constant that you can push
it arbitrarily a close to zero but but
there is even a one pathological example
that we found in which its
asymptotically lower than long log n
okay consider you can push our trailer
it has to be possible I the agonizing
get something
okay so this is actually some log to put
a power smaller than one that the assam
okay so in the spirit of the analogy to
GNP then g3 behaves very similar to a GN
2 over N and I I don't have enough time
to to explain why and g2 is very similar
to GN 1 over N and in turn to turn this
heuristic to real proof it was very
useful for us to use a type of softness
and evil Paris about the multi-angle
approach for the critical random graph
ok the acquaintances graph after three
steps and and it for the complete graph
we started with one worker in each
vertex and that's the only example we're
lazy simple random walk we defined it
that you just pick a the next position
out of the uniform distribution and this
is cleaner in that case and so perhaps
without giving more details and I can
explain more about this analogy
somebody's really interested otherwise I
just continue now I think I just
continue ok so for so now it's not very
surprising that for expanders you get
the denser is Theta of log n so this is
an old presentations or something else
is written and the idea is that
obviously if after three steps on the
complete graph you get a giant component
and after all the above log n steps you
will get a giant component for expanders
but this actually can be improved and
you can get it after a constant number
of steps and this is due to the work
that is now in progress with Maurice
lion and kin but once you get this giant
component you can run the process for
another some constant time log n steps
and you get the picture which is which
looks like this
so you already have some giant component
and you think about them as predators
trying to catch the rest of the workers
so any worker which is not in the giant
component we think about it as a prey
and the event that so now let's
condition on a path that the Walker not
from the giant component a performs con
so the events that the walkers from the
giant component meet this guy are
conditionally independent right once we
condition on the path that the pride
performs and a second moment calculation
using spectral analysis shows that after
C log n steps the marginals are that
that they catching are some seat tilled
log n over n so the probability that
none of them catch him becomes 1 minus
that to the power number of workers and
by by choosing see to be arbitrary large
you can make this become a 1 over n
square okay now you can do Union bound
and another result with in some cases in
improve on the general bound that we
have for bounded degree graphs is in the
case that the graph is regular then we
can show this bounder olds right I'm
talking about the second theorem and the
idea is to do a coupling between the
situation on the graph and the in the
situation on the complete graph so
basically basically we perform a log n
samples but we don't look at consecutive
steps we wait between samples and the
waiting time is always a six-time the
mixing time times log n to the base tool
okay and by waiting that long we make
sure that the each sample we have
looking total variation distance very
near just one step on the complete graph
yeah so this this is for the different
starting positions so this is for
starting with one worker in each vertex
and this is for the starting conditions
I didn't tell about but actually both of
them so this is yeah but it's also true
for the poisson starting condition
actually but you have to work harder
oh this is a very naive argument any
example that you need more daring
ordered teammates i'ma single rope now i
donÃ­t such and simple
so so right so now we get the n samples
that together in total variation
distance just look like n samples on the
complete graph and now we just use the
result that on the complete graph after
this many steps social connectivity has
already been achieved with I probability
okay so in some cases right if the if
the mixing time is synthetically smaller
than log log to the five then this is an
improvement
okay so as I said the presentation is
not updated in the lower bound at the
lowercase C does not depend on d I
already told you that if the graph is
regular then we can just take a 1 minus
little o of 1 because the complete graph
is the best out of negligible terms up
to and in general we can relax the
bounded degree a condition very file in
the lower bound so as long as the
minimal degree the minimal sre value of
the stationary distribution is at least
some constant time end to the alpha
minus 2 for some alpha between 0 and 1
we have such lower bound for some a
lowercase C that depends on Alpha okay
and for the upper bound a the big case
see depends on d if i'm not mistaken I'm
sorry for not being sure I think it's a
order d to the fall and for regular
graph the proof right now give a d
square and you cannot remove the
dependency on d if for sure it should
depend on the it list by order to be I
have an example that shows that okay so
you can't improve the dependency much
more and in and actually the proof as it
is written works a so for any day right
when you change this to be some
universal constant time d to the phone
so whenever d is the poly logarithmic
the upper bound is Polly logarithmic
okay so I'm only going to talk about the
proof of the upper bound so so the wire
is redundant I'm sorry for that so we
defined a probabilistic ball around the
x with a probability parameter P and
time parameter T to be the set of all
vertices such that a lazy simple random
walk
starting from X as probability at least
p to hit up to time T okay so these are
in a sense the vertices that we are
likely to hit in the near future so a
fact that is important is that whenever
the maximal degrees d and we look at
some set of vertices which is not all
all of the graph then the expected
exiting time from a is it most eight
times d times the size of the set
squared okay and in the regular case you
don't even need the D so easy corollary
is that the probabilistic ball around X
with a probability Palomita one over m
and time parameter for M square can't be
too small okay it has to be at least of
size M over 2 D and to see that and okay
so start this lazy simple random walk
from X and run it for twice the exiting
time okay twice they expected exiting
time so we run it for it most this many
steps which is exactly 4 m square ok so
we run it for it most twice the
expectation and we exit with probability
at least one s but a the outer boundary
because of the maximal the greedy
condition is that most of size D times
the size of the probabilistic ball right
outer boundary I mean outer vertex
boundary so it turns out by averaging
that they need to be some vertex out of
the out on the outer boundary that we
eat so the f is because we exit with
probability 1 f and the size of the
outer boundary is M to the 2d but we
have this D right from here
statement
yeah okay so what I'm what I'm saying is
that we exit from the probabilistic ball
with probability 1 F if we run the walk
for a fall to the M square steps and
then by averaging we must have some
vertex on the outer boundary that we eat
with probability that's the statement
yeah okay okay I got you sorry
okay so we start by assuming by
contradiction that this is not the case
okay and if this is not the case it the
okay so we assume that then the exiting
time from the probabilistic ball and G
complement is at most 2 m square okay
using the previous fact and now we run
the walk for fall M square steps so we
exit with probability at least one F and
then there must be some vertex at the
outer boundary which we ate with
probability and right this is for
exiting size of the outer boundary which
we upper bound by D times the size of
the set and this turns out to be 1 over
m at least one over N sorry by the
assumption that the probabilistic ball
is small so it turns out that this
vertex at the outer boundary should have
been inside the probabilistic bottle but
that's a contradiction okay so this just
ignore it's a complete mess irie I will
run right rewrite everything myself
okay so H stands for heating so it's
minimal t such that X you t equal v mu V
is minimal t such that X UT is equal to
Y V T so both x and y are independent
lazy simple random works okay one
starting from you and one starting from
V &amp;amp; M stands for meeting and we want to
relate the distribution of these two
quantities ok so now denote by n WT the
expected number of returns to vertex W
up to time T oh it's simply P and I want
to TW w and okay so now we can say that
the probability that they need before
time T over 2 okay is at least like the
probability to hit V up to time T up to
something and that something should be
not what is written there but close
enough s sub V sub W and WT plus 2 okay
so this always odds but a to understand
these quantities so this quantity so
this is always at most some universal
constant time addy I guess time square
root tea okay when when the maximal
degree is d okay and this can be
improved in many cases and you can prove
that it's actually a for the constant
whenever say you have a uniform upper
bound on the effective resistance
between two vertices okay but but for
our purposes this was enough to get the
upper bound of the theorem okay so all
of this would including the inverse is
the worst case is 1 over square root tea
okay
so the proof I'm just going to give a
sketch of the proof then the idea is
very simple and so whenever we look at
some joint path that they meet after K
steps and we can always reverse this
path right and that's why we get the D
term okay and then we get some path from
u to V okay so instead of running
overall a path here we run over all
paths that don't a form a cycle here but
that's only working our advantage for
proving such an inequality okay but but
but why do we get this term because when
we reverse the path we don't get
necessarily all the path from from u to
V that we need to consider here because
we can add a lot of cycles here right so
the not a cycle by sea as long as a k
plus 2 k sorry plus the site a length of
the cycle is smaller equaled until then
this is another path we should consider
but the when we sum over all cycles the
contribution turns out to be exactly
this right if this is w so I'm part
there's one delicate point that I didn't
mention ok so now I can explain the idea
of the proof so using the probabilistic
ball we fit we fix the parameters oh can
i race
and we fix the parameters a right we
always look at pdx1 over m4m square we
fix em to be some something of older say
a log n so we know that the size is also
for the log m that's by the first fact
right first call re and and then we know
that if we have a picture like this two
workers inside some probabilistic ball
around X then the probability that to
start here and hit V is at least by the
verse ability a 1 over m square 1 over d
right just by going okay so now we do it
for 8 m square steps so first foal m
square steps is first to get 2x and then
another forum square steps to get from X
to v ok this is very wasteful and lest
we are considering the path and ok but
this is just to start at you and hit V
but now we wanted to say let's say we
have two independent lady simple random
walk so what's the probability for them
to meet each other in now for M square
steps so by the previous lemma it turns
out the disease of older instead of 1
over m square it's 1 over m cube okay we
have this square but this we use this
with the square root in the previous
lemma okay so okay so we fix this m ok
so every time when we say Neil future in
what's comes or near future is the log
square steps and likely is 1 over log to
the cube ok and be so we know that the
probabilistic balls are never empty
right because there are sized a log n
let's do for instance Poisson starting
conditions then we know that the number
of workers is distributed like person
they tough Logan this is because the
Poisson starting conditions are
stationary over time so by the
concentration of Poisson random variable
around its min we know that with I
probability all the all the
probabilistic balls are very occupied
all the times and so we can do Union
bound over at most n probabilistic balls
and say a log to the power 10 times and
say that always all the probabilistic
balls are very occupied and from this we
can it we can learn deterministically
that the picture must look like this but
i'm not going to show this it's going to
take me a few minutes that for any class
a up to the social connectivity time
there must be some probabilistic ball
such that we ever walker a form a so you
is in a and some walker not from a
inside the sample with ballistic ball ok
with ok so this it turns out to be
deterministically once the probabilistic
balls are very occupied in all times now
to conclude the proof ok so let's assume
for a sec of simplicity simplicity we
may condition on the probabilistic balls
to always be occupied without
distributing the distribution of the
works so this is just a technicality
because anyway what we conditioned on
opens with I probability so we think of
every forum squares as a small trial to
to make our a plot our social class
unite with some other class ok and we
always have a probability of success in
a small trial which is T these of all
the 1 over log cube ok but now we can
look at say two log n over P consecutive
trials
so always we have success probability at
least be so the probability that all of
the districts are failure is end to the
power minus 2 okay by setting see to be
too and so we have every time at most n
classes so by Union bound over the
number of classes it turns out that if
we look at this many consecutive small
trials as one big trial then in any big
trial we can say that with I probability
all the classes unite right with at
least one other classes right so the
probability of failure in one big trial
is at most 1 over N but once we have
this we are done because all we need is
log n consecutive successful big trials
but because deterministically if we have
AK consecutive a big trials which are
successful then all classes are sized at
least 2 to the K all right
okay so we just need to do Union bound
over log n steps and in every time we
fell with probability 1 over N so we can
do this Union bound okay so this gives
you a bound which is a so we do a log
web log n iterations each iteration uses
log n over so P was a log to the minus 3
and and each trial uses auto of log
square and steps and what you get is of
order log to the power 7 yeah I'm sorry
for being too technical and pity about
the details okay so that's the proof of
the upper bound let me see how much time
do I have I have at least 10 minutes ok
so now I can talk a bit ok so first of
all we only prove this theorem for a
bounded degree graph so there's a reason
for that and you can consider the case
that you have to complete graph and they
are connected by single edge all right
so obviously you need a order of n steps
for this edge to be cross so the social
connectivity time is a further n you
cannot improve the theorem ok so how do
i I don't need the presentation anymore
how do I I know that actually I have a
few conjectures here to show
so the first one is that yeah so always
that the social connectivity time for
any starting conditions is the order
that must log square n so the cycle is
the worst case and what we do know to
show is that in the bounded degree case
after log square n steps and Walker
meets a order of log in other workers
okay with I probability okay and we have
some ideas out to use that to show to
show that social connectivity occurs but
we still haven't done so so we're fairly
certain that this is true
yeah but yeah I don't have time to
discuss it and so another conjecture and
okay so we can start with the K London
workers and each one of them
independently can start the stationary
distribution so we conjecture that in
the case that the underlying graph is
vertex transitive and the expectation
will be monotonically decreasing in the
number of workers okay and similarly you
can start with Poisson lambda workers
and also we believe that this will be
monotonically decreasing in lambda and
it is important that the graph is vertex
transitive otherwise this is not true um
ok all right so can can we lift the
curtain screen thank you
ok so now I'm going to discuss as some
of the results of the work with the band
Morris Island sly and Chongqing yeah I
guess you also with guess if I start
with wanted every guy and compare that
restoring with to it every guy is it
justice no but but this is trivial if
you include that acquaintances at time
zero with by our convention we do that
yes so there is kind of when you when
you do it with at least with K workers
and you change it between k to k plus 1
there is the trade-off between how much
this extra guy is going to help you
compared to the chance that this guy
will be the last guy which is isolated
in a sense if it's not that if is not
the last one which is isolated it can't
make thing any worst right it can only
help you so there's a trade-off yeah and
actually we thought about doing the
Poisson lambda thing and taking
derivatives and maybe get something
similar to population where you have a
voice or osos lemma but here you will
have a positive contribution and
negative contribution according to what
I just said ok so now about the infinite
setting so we considered a so for if G
is regular so just do Poisson lambda
opposed yeah Poisson lambda in any
vertex and if it's if it's not regular
then do Poisson lambda times the degree
in any vertex independently ok so as in
the finite setting this is a stationary
overtime and now the questions we need
to ask are different ok in the final
setting west when does the social
network become connected but here for
any finite T there will always be
infinitely many isolated workers so we
need to ask a instead of when does it
become connected is it true that
eventually any two workers will have a
path of acquaintances between them ok so
that is it true almost surely so that
was our conjecture at least when the
underlying rough is a bounded degree but
it turns out that the picture is more
complicated than that
ok so is effects is that like in
percolation for any given deal including
to infinity and the existence of at
least one infinite cluster is a zero one
event and if the underlight Arden
underline graph G is vertex transitive
then saying that you have exactly K
infinite clusters is a zero one event so
we have this er QD city and moreover we
have some weak form of insulin tolerance
and for continuous-time work we have
actually insertion tolerance so we can
rule out a cave which is finite and
bigger than one so this is exactly as in
population ok so in the in the amenable
case it turns out that the answer is the
positive so g amenable so for any lambda
and g infinity is connected almost
surely ok which is like saying
eventually i need to walk resume it and
for this we use the result from
calculation and you have to do some
stuff in some cases but but this is
fairly easy but the non amenable case
turns out to be interesting so a denote
by uhaul the spectral radius so this can
be defined just as well once you prove
that the limit exists that this is PN X
Y or X X for instant 1 over N so once
the limit exists you can set the
supremum by a super multiplicity and in
the NAM enable case this is strictly
smaller than 1 okay so it turns out that
if two lambda plus 1 times law is
smaller than 1 then a
we have more than one class at time
infinity okay and again if G will be
vertex transitive then you can say that
almost surely you have infinitely many
clusters at time infinity okay so I I
want to explain this result and we also
showed that if lambda is large enough
then you have uniqueness okay and
there's monotonicity so property so
there is a critical value it's some
lambda critical for uniqueness a time
infinity but I'm only going to discuss
this because this is the most surprising
result so it turns out that you can look
at the process in some slow motion
manner and then get that the cluster at
the stone slow motion man or at least is
too hastily dominated by branching
random walk okay and the idea is that we
started some vertex V and that stage 0
and then at stage one we look at the
workers that the guys from stage zero
met okay and then it's stage two and we
look at the workers that say the workers
that were edited stage one we go one
step to the past and one step into the
future and see which guys they met and
the workers from stage zero we only go
one step into the future and in general
at stage T of the process the
exploration process and let's look at
workers that were added at stage I but
time J so I mean this is the stage with
respect to the exploration process and
this is the time with respect to the
actual lazy simple random walks okay so
what we explore is the workers that they
met a time j + t minus I this is the
future step and we met we explore the
workers that they met at time g minus t
minus I as long as this is non-negative
okay so well at least there and and when
we've done this exploration process up
to time infinity what we get is exactly
the cluster and we follow the projector
ease of all the workers in the cluster
in every time okay that's what that's
information we get so the contribution
that we get here and eat at least
unconditionally should be Poisson lambda
ok but we only interested about what are
the new workers they need workers which
are not already part of the exploration
process so for this we notice that this
is too hastily dominated by Poisson
lambda because we only care about the
new workers though it's basically you
can a you can divide the path so let's
say ill we reach the vertex quality w so
instead of looking over all pass the
switch w at that time we we look on the
other subset of death right and we used
the composition of the poisson random
variable so it's clear that this is too
hastily dominated by Poisson lambda and
then right then then we get the this is
Stassi dominated by branching random
walk with expected number of children in
a Poisson to lambda but we have the plus
one because we don't die after we give
birth ok and then if the expectation and
if this is smaller than one we get the
expected number of visits to to to to
the original vertex V is a finite which
implies transient and and if the
branching random walk is transient it
means that there are some vertices that
it never visits but because this
branching random walks actually it tells
us we follow not only the walkers we
meet we follow all of their trajectories
including time zero so if this process
never reaches some vertices it means
that the guys that started that vertex
were never part of our cluster that's
that's
I'm done sorry for keeping you longer
further questions is you have a question
yes so weird a lot of questions about
infinite clusters but the main
conjecture that we still don't know how
to approach is is it true that whenever
pc with respect to population okay
independent bond percolation that
whenever pc of g is smaller than one and
then AG infield sorry then exist till
such that GT as an infinite cluster okay
so we know that to be the case for a CD
for anything bigger than one and we know
that for any lambda the just the
critical T depends on lambda and we know
that in the non amenable case but that's
it yeah for any lambda bigger than 0
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>