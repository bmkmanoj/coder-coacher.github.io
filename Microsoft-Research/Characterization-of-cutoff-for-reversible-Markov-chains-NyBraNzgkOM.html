<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Characterization of cutoff for reversible Markov chains | Coder Coacher - Coaching Coders</title><meta content="Characterization of cutoff for reversible Markov chains - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Characterization of cutoff for reversible Markov chains</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/NyBraNzgkOM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
all right good afternoon everyone so
this question of cut off in markov
chains is one that has occupied me as
well as john in the AL for some years
and now with the jonathan joining in the
fray we have another jump in the
understanding of this so please Jonathan
so today I will be talking about joint
work with really passive who is also HD
student in the statistic Department of
UC Berkeley and above about
characterization of the type of
phenomenon in reversible Markov chains
did you lose your mic hi okay and the
object we study our versatile markov
chains environment state space within
alpha phi omega irreducible reversible
lazy ones and we denote the transition
matrix by the stationary distribution by
pi reversibility is just the condition
that pi x PX y is equal to pi y py x for
every two states XY mistake space and
laziness is the condition that the XX is
at least a half or any state X and the
notion of distance we consider is total
variation which by definition is a
maximum over all sets mua minus mu a and
the distance of x from stationarity time
t denoted by dt x is just the distance
of the distribution of the chain at time
T started at X from PI and then BTW is
the worst-case distance at time T which
we just take maximum over all initial
States X and then the epsilon mixing
time is just denoted team except salon
is just the minimum time T such that DT
is at most epsilon and when epsilon is
equal to a quarter we don't write it
which is standard notation the phenomena
will be talking about is the cutoff
phenomena
so we consider a sequence of markov
chains and we say that the sequence
exhibits cut off if the epsilon mixing
time minus the 1 minus epsilon mixing
time is little o of the mixing time for
any epsilon between 0 &amp;amp; Cotter WN is
called a cut of window if it's little
off the mixing time and we can write the
epsilon mixing time minus the 1 minus
epsilon mixing time as some constant
depending only on epsilon times the cut
of window for any Epsom twin zero and
quarter so I'm saying a cut of window
because it's not uniquely defined as one
can readily see so to see a graphically
what cut off Sam stew is just this
picture of DT as a function of T where n
is denoting the end chain in the
sequence so there's an abrupt dropped
for nearly 12 nearly zero at a very
small window around the mixing time some
historic background this was first
identified for random transpositions by
diaconis and shasha Annie and 81 and
then for random walk on the hypercube by
david aldose and many chains are
believed to exhibit cut off but usually
verifying it formally is difficult and
until a few years ago there were just
few examples which have been verified
formerly the name was coined by Alderson
diaconis in their seminal 86 paper in
which they raised the following question
which they refer to as the most
interesting open problem which is
finding abstract conditions which are
sufficient for the occurrence of the cut
a phenomenon
so I'm going to discuss now one
necessary condition but first I need to
make one definition so lambda 2 is the
largest non-trivial I ghen value of P
meaning a smaller than 1 the spectral
gap of the chain is just 1 minus lambda
2 and then the relaxation time is just
defined to be the inverse of the
spectral gap so fellas 2004 the product
condition which from now on I'm going to
abbreviate and right prod see which is
the relaxation time being little old the
mixing time so the name product
condition comes from this equivalent
representation is necessary for their
occurrence of the cutter phenomena in
reversible Markov chains and fortunately
it is not sufficient so relevant
examples were constructed by Aldo sandy
go back so this raises two questions one
of them is find a general families of
Markov chains for which the product
condition does imply cut off and the
second problem is find an additional
condition C such that for reversible
Markov chains cut off is actually
equivalent to C and the product
condition so in our work we make
progress in both fronts so we do
establish such a condition see and we
show this for new family of Markov
chains namely weighted random walk on
trees so excuse me for a dark background
so this is all this example for showing
that the product
so this is others example for a chunk
that the product condition does not
imply cut off so what we have here is a
path of length 10 m and then we have two
parallel paths then we have two parallel
paths of length and each we have fixed
bias towards the state y which is given
a non lazy step you move to the right or
towards why if you will with probability
two-thirds and to the left with
probability third okay given a non lazy
step on the long path the lessons
probability is fixed as above and along
each of the past the laziness
probability is fixed but you have more
chance to stay at the same position
along the top pads that okay so first of
all the relaxation time is of order 1 so
this can be seen just because in the
muck of theoretical way since this is an
expander the expansion is bounded from
below all the stationary measure is
concentrated around why and it's not how
to establish that the mixing time the
distance from stationarity time t is
essentially the probability that Y was
still not hit by time T and that the war
starting state is X and then by
considering the two cases in which the
last exit out of Z before we eat why was
into that path or that path one can show
that the distance from stationarity is
bounded away from zero and one in these
two choices of x ends there is no cut
off so really the issue is that the
heating time of Y is not concentrated
and this leads to not to do to this
sequence not having cut off
okay so now i'm going to talk beyond the
context of cut off and just the context
of mixing and so the definition of
hitting time of a set a is just the
first time T in which the chain belongs
to the set a so already in the middle of
the 80s aldose established some relation
between hitting time of war sets and
mixing but this was greatly refined by
parison Suzy and then also independently
by Oliviera and they showed that for any
irreducible reversible lazy Markov chain
and any Alpha between zero and one half
the mixing time is up to an a constant
depending only on alpha but not on the
chain of order of th alpha where th
alpha is the worst expected hitting time
of a set of stationary measure at least
alpha so it's a worse coupling sense we
look at the worst starting state and the
worst set then the case alpha equal a a
half was conjectured by teleson proven
one year later by Griffith al so in our
work we don't work exactly with this
notion of were set and with expectation
we relate DT a mole directly to a you
know kind of the same maximum you see
over here but we look I thought i fixed
that there's the X mixing year I'm sorry
at the tales of the distributions of the
heating times rather than the
expectation and we define two in two
ways equation 2 so first of all we allow
alpha also to be greater than one-half
and moreover we relate our notion of
hitting time for set to
mix epsilon not only to tea mix of the
quarter and the relation we get is typed
up to an absolute constant which is
independent of Alpha Epsilon so this
raises a natural question how come we
were able to extend this beyond alpha
equal half and previous result were only
up to a parameter half this is because
too many fail actually when you take off
a bigger than a half so
isn't it enough if I say that we have
two clicks joined by an edge I think
that people only smart people dead
serious so imagine that what you're
seeing is two clicks of size n joined by
a single edge and actually instead of
there analyzing this example which is
already quite simple we will analyze a
degenerate example with analysis is very
similar but the same conclusions will be
drawn so our state space is two states
and we have a frog and to lily pads and
our frog is quite content with staying
in its current lily pad but in every
time unit with probability 1 over n it's
it jumps to the next to the other lily
pad then deterministically any set of
stationary measure greater than a half
is hit at time 0 in a very degenerate
manner but hitting time of any worse set
of size smaller equal than a half namely
the lily pad that the Frog did not start
at eating it is Arden is essentially
like mixing and moreover the spectral
gap is 2 over N and the mixing the
epsilon mixing time is determined by the
relaxation time so a to this rise to a
natural things so one should expect to
things that any refinement of the result
by Paris Seussian Oliveira should
include the term of the foam till the
log epsilon and this also shows that its
natural to consider a tenth of the
heating times rather than the
expectations if you want to talk about
the epsilon mixing time and not just the
mixing time and okay now a little bit
about relations between heating times
and cut off so this was already hinted
in the literature and
most notably in the context of birth and
death chains so it turns out that for
birth and death chains concentration of
fitting times is crucial so what is
known in that context is the ignition
sort of cost and show this for
separation cut off and ding glue between
pairs for total valuation cut off that
the sequence of birth and death chance
exhibit cut off if and only if the
product condition odds and there's only
one way to draw them oh the little one
so a birthing that chain is just a chain
in which if you have a n states then you
can label it 12 m and a PJ I is bigger
than 0 if and only if I minus J is
smaller equal than one that's the
definition of a berth in that chain so
you know this might be weighted so one
example can be a chain similar to others
example but now we don't take two
parallel paths can be a two-third to the
right and third to the left so this will
satisfy the product condition and thus
we love cut off
ok so we extend the result to a weighted
nearest-neighbor random walk on trees
and our result is it can be extended so
that the tree structure can be relaxed
and I hope do it to get to that later so
a more precise version of our result is
that for any lazy markov chain on a
treaty that has at least three vertices
the epsilon mixing time minus the 1
minus epsilon mixing time is at most 30
a square root of epsilon inverse times
the geometric mean of the relaxation
time in the mixing time and one can
readily see that this implies that the
product condition is equivalent to cut
off and the cut-off window is at most of
length the geometric mean of the
relaxation time in the mixing time so
comparing these two previous results
then we actually get a slight
improvement in the rate of convergence
and compared to birth in that chains and
in that paper dinglebat skin Paris show
that in certain cases the length of the
cutoff window is at least of order of
the geometric mean of the relaxation
time in the mixing time thus one cannot
get a great improvement over what we got
and so loud
lower bound does it the exam so this is
I think theorem 2 or 2.4 and it's only
written like that and I don't remember
from the proof itself what was shown but
but the the method i think is similar
and you use a one-sided chebyshev
inequality so probably it's symmetrical
or below work in the defensive zone okay
but if it was obtained by one sided
chebyshev inequality than it should be
symmetric I think it was symmetric that
it was of this over the leg we had a lot
of talk about and you put it one of the
school and I was just wondering what's
been so Sundra that you anything oh oh
you mean I I don't remember I'm sorry
took me a while to understand question
you did you violate you keep this a big
Omega notation in the paper so I yet
defined formally our notion of heating
time of four sets I just said that it's
related to tails rather than
expectations then okay it alpha is just
an abbreviation for it alpha quarter for
a fixed initial state X it alpha x of
epsilon is the first time T in which any
set of stationary measure at least alpha
was not eat by time T with probability
at most epsilon and then if alpha
epsilon would just be maximizing over
the initial states so I want to argue
that this can be related or compared to
the mixing time in some sense so one
direction turns out to be a trivial the
probability to not hit a set by a
certain time is that most the
probability that the chain is not in it
by that specific time well a little
algebra and
inition of the total variation distance
tells you that this is at most pi of the
complement of the set minus the total
variation distance worse case at time T
and again the phoenician chasing tells
you that this inequality shows that heat
1 minus epsilon over 4 of 5 epsilon over
4 is at most epsilon mixing time so this
gives one side and in simple words in
order to mix the chain must first escape
from small sets more precisely with the
sufficiently large probability and we
think of that as the first stage of
mixing and it turns out that loosely
speaking at the second stage the changes
mixes it the fastest possible rate up to
a constant which is governed by the
relaxation time okay and the title of
the slide to mix escape and then relax
to make it more precise if you are the
products language
ok so the what's written here is true in
general and the clean version when we
fix alpha to be half so you will
consider hitting times of sets of size
at least half and then the epsilon
mixing time is close to hit half to
epsilon and to hit F epsilon over to but
there is some time shift which depends
on the delectation time and log epsilon
and under the product condition we can
just ignore those terms as long as
epsilon does not tend to zero too
quickly and a more a more refined
version of this inequality allows us to
consider larger set the insides half and
it tells us that the epsilon mixing time
is at least well this approved before
and this is well known and follows from
two lines of linear algebra okay again
some term that involves the relaxation
time and log of 1 over 2 epsilon and
heat 1 minus epsilon over 40 k the same
1 minus epson over 4 step the plots of
the world
well log epsilon is negative yeah so up
to up to a small time shift and near
there is some small difference in the
parameters and also here area the
epsilon here we change epsilon a little
bit we see that hit capture captures mix
tea mix quite well and what's more
refined about this equation is not only
that we allow to consider a hitting time
of large sets is that with a little bit
of fork one can show that the right hand
side and the left hand side are up to an
absolute constant from each other which
is independent of the chain and of
epsilon but this requires some algebra
ok m so we define the notion of it alpha
cut off to be the case that it alpha
epsilon minus 8 alpha 1 minus epsilon is
little all of it alpha quarter for any
epsilon 20 and quarter so in a sense the
main abstract result we have so this is
what I said before about the conditions
see that this in addition to the product
condition implies cut off a sequence
exhibit cut off if and only if it
exhibit it alpha cut off for some alpha
between 0 and 1 and the product
condition odds so this is in the case of
reversible lazy markov chains
so the case alpha equal to a half
essentially follows from the first
inequality in the previous slides one
have to do a little bit more than that
and noting that it i'll hit half is of
order of the mixing time and practice
you have to do a bit more than that and
to recover the full equivalence here for
general alpha we showed it under the
product condition if you have hit alpha
for a certain alpha then you actually
have it baked sorry it alpha cut off you
get it betta cut off for any beta and
all of them occur around the mixing time
so hit beta would be of all dirty would
be a tea mix 1 plus minus theta loved
one okay so now i want to explain the
main ideas I just need to give a few
definitions first so for a function f
from the state space to our we define
pity of F to be well this is what you
expect but it's also the expectation of
f of X T given that the chain started at
X this is bad I I i already deleted that
so there is no G for any function f
define a pie of F just to be the
expectation of the f x 0 if x 0 is
sampled according to pi and the two norm
square of f just to be a pie of f square
and and then the variance of g with
respect to pi will just be the two norm
square of G minus e pi of g
yes so the well-known l2 contraction
lemma tells you that for any reversible
irreducible a Markov chain a lazy and
any indicator of set the variance of PT
the indicator is at most e to the minus
2t over till L you said that user cuddle
for etl fun for some ipads and it's true
for any adventure under under the
product relation yeah
and this is clearly not true no
okay the many tool we use is the Stars
maximal inequality which is very similar
to Stein's maximal inequality apart from
giving a sharp constant and it says that
for any irreducible well that's a
partial statement star actually proved a
much more general version for any
reducible reversible Markov chain and
any function f from omega 2 l.a so we
define the maximal function f star to be
just the supremum over all times of PK f
of X supreme over all K in absolute
value and the statement is that the two
norm square of F star is at most aight
the two nom square of f ok and it's
what's nice about this inequality is
that you have started doing both in the
statement and in the name of the
inequality so it's easy to remember yes
yes that's the way I define the two
knome ok ok so the next two slides are
the most important ones in the entire
presentation so I'm going to define an
auxiliary set for each set a and I call
it gsam it's the good set for a after
time s within m standard deviation from
stationarity more precisely we defined
Sigma s to be what we add before in the
l2 contraction lemma so that's by Delta
contraction lemma and then a formal
definition of gsam is the collection of
all states G such that for any time a
still greater equal than s pgs skilled
of a minus PI of a in absolute value is
at most M Sigma X if we want to get
precision here to be it
at most at least epsilon precision then
we need to choose us to be the
relaxation time x log M over a epsilon
and we argue that the size of G is at
least one minus eight over m square okay
the proof is a one-liner you just
consider the function f s which is P of
s indicate of a minus buy a then from
the definition the complement of G is
the collection of all states such that f
s star of x is greater than M the two
knome of FS and then we apply stars
maximal inequality that's it
okay so how do you use that why why why
is that good set so good Oh fix some M
greater than square root 8 so I just
want this to be a non-trivial bound and
the claim is that we can bound the 2
epsilon mixing time by heat 1 minus
eight over m square epsilon plus some
time shift that was s from before so the
proof goes as following just denote this
st by the previous claim we know that
the size of g is at least one minus
eight over m square so by the definition
of T we get that for any initial state X
the probability that we did not eat
g'bye time t is at most epsilon by the
definition of heat more precisely okay
so either choosing the worst X in a
gives you a quality so the distance from
stationarity time t plus s would be that
well this we can bound in two parts one
case is by considering the case that the
good set was still not hit by time T and
on the case that the good set was hit by
time T then taking maximum over gns
stilled we got that this is at most okay
so there is a maximum missing year and
that Plus that well the fact that this
is epsilon is already written there and
the reason that this is a bed most
epsilon follows from the definition of G
so to get that formally you just apply a
the Markov property and conditioned on
the heating time and the state in which
G was hit
ok so in question
okay so that that essentially
established the establishes a version of
what i wrote before with the alpha
equals half but playing with parameters
you you can get anything in any Alpha
really ok so now talking about trees and
so T an arbitrary three finite and we
consider Markov chain on it a lazy one
which is just waited newest neighbor
random walk so a bike on go of cycle
condition every markov chain on a trail
is reversible ok so the question how to
use our absurd characterization so how
can we use the tree structure to
determine what are the worst sets Oh an
easier question would be well how do you
do it for a berth in that chain so I
will redraw it
luckily I already have a drawing of a
birth-death chain
Oh
guilty
so consider J the first J such that the
set one up to J epsilon as pie measure
the maximal J such that this s by
measure it most epsilon okay so starting
at one this is obviously the worst set
to escape from up to picking the side so
it might be starting from n some
interval okay so for a three everything
is very easy but how do we generalize
that Omo over oh yeah for birth and
death chain sorry if we look at phi
condition on this set then starting from
this distribution the chain mix is
quickly okay this follows from several
considerations one of them is the l2
contraction another one is that using
some known facts one can show that every
set is heat quickly starting from this
distribution okay so this is PI
condition on the set appearing here well
I'm arguing that if the chain starts at
X then the chain will also mix quickly
studied from X so a formal way to see it
is comparing heating times compared to
PI right because by the Markov property
in order to hit a set on this side of
the path and the chain first has to
reach x
John okay so that that's a way to use
the birth and death structure so we can
do the same for trees that's the
intuition okay so few definitions we
call a vertex Oh central vertex if each
connected component of the tree when we
take that vertex out so this needs to be
V I'm sorry as stationary measure it
must has there can be at most two such
verses but there's always at least one
we pick one and call it the root so
loosely speaking trees that satisfy the
product conditions are just one with
ones with some kind of global bias
towards the center of mass the central
vertex formerly once that the heating
time of the central vertex is
concentrated from a worse starting
position so given that description a
counterintuitive construction shows that
one can construct such unweighted trees
that's due to person Susi okay so like
in any tree the would induce is a
partial order so for any vertex you this
will denote the paths from you to the
root I mean the unique and non
backtracking one-shot s 1 and F of you
would be the parent of you and then we
say that u prime is smaller than you if
it's on the path from u to the root and
then W of you would be the induced sub
route at at you so here the induced sub
route at x is exactly this set okay if
say that's the route right here that's
the definition clear
nothing
so if that's X and that's the central
vertex then everything right here from
that vertex father away from the root is
the induced that would be W of X
everything here and so we call a vertex
X a beta vertex a beta vertex if the pie
measure of the induced sub tree at the X
is at least beta and as before 4x4 the
same reason if you start at the beta
vertex you mix quickly and I already
give that explanation for birth and
death chains I'm going to skip at
okay so for any state X we can look at
the nearest by a beta vertex which is an
ancestor ancestor of X we denote it by Y
beta of X and we argue that the variance
of the heating time of the nearest x
beta vertex is at most till L times T
mix of avila so if you believe that then
what we get is that under the product
condition the standard deviation of that
would be the geometric mean and ends the
little of the mixing time and this will
give us concentration and I'm arguing
that such concentration so we already
argued that if you start here you mix
quickly a little of the mixing time and
I also argued that getting here appends
in a concentrated manner and I'm arguing
that this implies cut off so are you
so we argued that started from here the
chain mixes in little o of tea mix and
we argued that getting here is
concentrated
I mean I have my start at the leaf it's
saying I'm just thinking it the mast
these trees have from that point to
supply this is because we see the
equations of exactly sentences and
coincidence we had a hitting time the
fence was also their children I'm Steve
mix but I'm not saying this is the truth
just saying this is what's good okay so
that's that's the picture from any bed
vertex X you get concentration here if
you don't get concentration it's only
because you get from year to year too
quickly anyway and once you hear you
commit you mixing little ol number of
steps and if you use these two arguments
together you get cut off so formally one
can take beta tending to zero
sufficiently not quickly to make that
argument work so in the percentage
changes there is a formula for hitting
times so eating time to bring the sum of
geometric variables and Percy and the
runs our first use that and we use that
but here we don't use the corner lot of
typos brother some direct calculation of
the variance of anything times also yes
which I'm going to sketch right now so
the concentration followed from a claim
about the variance so now I'm going to
sketch the proof so it's it's enough to
show actually the bound in which we
Revere the expectation rather than the
mixing time because this mixing this
expectation could be at most being
generous twice the mixing time that
that's easy to show okay but actually
this eating time consists of a lot of
independent crossing time of edges so
if this is X 0 this is X 1 X 2 then
getting from here to here is just like
the time it took you to get from here to
here and then the time once you got to
hear it took you to cross this edge and
so on but by the mark of property this
crossing time of edges is just the sum
of independent random variable and so
this isn't the crossing time of the edge
x i minus 1 X I so if one abound the
variance it's enough to get a bound on
the second moment of the individual
crossing time of the edges and then
actually using non results and some
second-order cuts formula estimate gives
you that the second moment of the time
it takes you to cross from Y to its
parent is at most four times the
expected crossing time of the edge time
the relaxation times time sorry and then
summing what we get we recover the claim
so yeah so it's simple m ok so few
concluding remark is that one can fix
the initial starting distribution and
then everything still works but now you
need to define mixing with respect to
that initial distribution and heating
with respect to it so for fixed starting
distribution one can show that cutoff is
equivalent to concentration of hitting
time of war set in expectation the
notion considered previously by pursuing
Oliveira but this is not true in general
if you don't fix your starting position
a distribution so we have a counter
example so laziness with probability
one-half is not we don't really use it
that strongly so it's enough to have the
condition that the spectral gap is a
smaller equal than one minus the
absolute value of the smallest
eigenvalue
you that's essentially all we use and
yeah so essentially you you you it's
enough to to make a lazy step once every
relaxation time number of steps to
completely avoid paradiso t issues
please ok I'm going to skip a few things
forgive me so I said earlier that the
tray assumption can be relaxed I'm going
to make it more precise right now so
previously the concentration of hitting
time in the work of dinglebat skin
palace used some representation of
hitting time results of mcclure go and
cuddling that is very specific to birth
and death chains and ends everything was
very fragile apart from that the the
birth and death structure was used in
other places and we actually can relax
the tree structure assumption just to
assume that there is some auxiliary tree
but the chain can actually move a
bounded to bandit distances along the
tree ok under some mild technical
assumption so for instant in the mail
technical assumption a weaker sufficient
condition is saying that to any neighbor
of the tree there is some probability so
P XY bigger than Delta for any X
neighbor of Y in the tree and P X y
equal zero if the distance with respect
to the tree between x and y is bigger
than some fixed number are
so that's a sufficient condition it's
not quite the condition we give in age
the our dimensions are not break oh the
existing argument that i presented yeah
one we the one about trees did yeah we
define an abstract class of change the
template where what would I even break
if i head and into the graph to go did I
jump let's say just skips off to it has
to break because of also Oh what's the
counter example so it where the variance
the variances are the variance but well
its argument why was it didn't seem so
fragile that if you had the very serious
time is written as a sum for variances
along beauties so I palaces and temples
immediate easy if you have a shortcut to
the center influenza so should I show
out this example again or without all of
it inside I just asked me where the
truth will break
okay open problems and so what can be
said about the geometry of the war sets
in some interesting examples so notice
that in the trick case we didn't really
identify and say this particular set is
worse but we found a collection that
offsets among which one of them would be
worse so that's more or less what I'm
looking for and assuming transitivity or
someone atomicity so one question can be
if f2 satisfied pf2 is lambda 2 f2 so
it's an eigen value eigen function of
the largest eigenvalue is it true that
the worst set in transitive graphs can
be written like that for a certain c so
c will be c of epsilon and this will
have pi measure epsilon roughly so this
will imply a cut off in several
interesting examples another question
would be can we approximate eating time
of four sets by escaping time of balls
intransitive graphs and we really have
freedom that we consider balls of pie
measure epsilon but we're trying to
approximate much smaller sets and yell
I'll stop here what was the general
provision to have it alphaCAT oh that
essentially that a were set in some
sense it's eating time is concentrated
and usually expectation we would catch
it at least if you fix your starting
state then cut off with respect to that
starting state is like Evan
concentration of hitting time for a set
with expectation is worse expected
heating time is worse for that starting
stage
but what does that mean the mixer exists
fix the sentence is the hardest to do it
sitting by was into said with respect to
this specific time because you want to
fix oh now now we're talking about
expectation I said if you fixed it
you'll face the time you want a good
time look at the sample okay exim eyes
is the expected time okay for different
stars and a sturdy any time is around a
variable be constantly
the food crazes badly in the others
okay that there are some subtleties and
can discuss it they offline okay okay
other questions so is this foundation
implied by some kind of viper philosophy
I don't know some fact about triangles
being thin or something I was started to
look into that vaisala body oh I guess
if you take a hyperbolic manifold and
taken edge so this condition is too
strong it's not implied by pretty but
probably a good velocity should be
enough oh so let's talk about it because
our condition is much milder than that
okay that's just something that you can
write in less than 10 sentences I think
there is a what's the trade-off between
the mildness and the length of this did
you uh you can write in what sense
traitor ever 13 what are you trying to
compensate for okay</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>