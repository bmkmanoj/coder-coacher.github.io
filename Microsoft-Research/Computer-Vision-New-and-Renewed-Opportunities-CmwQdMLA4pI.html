<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Computer Vision: New and Renewed Opportunities | Coder Coacher - Coaching Coders</title><meta content="Computer Vision: New and Renewed Opportunities - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Computer Vision: New and Renewed Opportunities</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/CmwQdMLA4pI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
thank you now I have a new tool to
progress my slide hope it'll work oops
so my topic is vision what is the vision
vision is here's a scene and we have a
device called camera and we take data
called images and then what the vision
does is from image to figure out what
the scene is now it sounds as simple but
obviously it's very difficult problem as
you see here guessing the reality from
projection is pretty tough problem now
computer vision is indeed one of the
earliest problems in artificial
intelligence as you may know it started
in blocks world hand I project and
vision program vision computer vision
has been tried from early on for with
the quite intensive effort but
nonetheless it turns out to be very
difficult and there's a very well-known
episode that Minsky said that vision
must be very simple you a graduate
student can solve as a summer project
and it turns out it's so difficult that
even after 40 or 50 more than 50 years
we are still working and I'm happy that
it has been solved because I made a
career on it by the way actually when I
when I asked the Marvin about this he
said he didn't mean that but anyway that
is a known episode oops it doesn't
now why is it difficult well the one is
the sheer number even the vga video
produced 20 megabytes per second when it
comes to high-definition TV 160
megabytes per second so we have to
process this much data indeed it is
often said when compared with speech
vision is two dimensional we have a lot
of data and so forth and that's true
even though I'm not sure that the sheer
number is that a difficult oops then now
as to the number there's an interesting
fact simple fact I say a large unit
consists of a large number of small
images now learning is very popular
today so if you're shown one
high-definition TV image two thousand
pixel x 1000 pixels then in it oops in
it now I have a habit of showing the
diseases ah in it there's a 10 by 10
image here and the next and so forth so
there are two file actually 1090
positions this way on 990 so in total we
have we must have seen roughly 2 million
ten by ten sub-images given one
high-definition TV so by just seeing 11
image you must have learned two million
ten by ten images that's a lot of
learning but there's another simple fact
I say that is let's ask how many 10 by
10 images exist now imagine one pixel is
made of 8-bit black and white pixel not
even a color 8-bit so 256 different
image of one pixel image so if it's 10
by 10 then 200 power of 10 by 10
which is 210 of 240 let me prove how big
this number is this number is far bigger
than this very important number for
human being which is imagined for safety
human being has been was born 1 million
years ago maybe little later but say
just for safety 1 million years ago and
even day one imagine 10 billion people
are living on the earth probably only
500 people at that time that's my guess
and imagine they'll are individually
watching every day every hour every
minute every second 30 frames per second
high-definition TV each of each each of
them is watching different Channel not
the same channel different Channel and
in total human being must have learned
10 of 31 that's far far smaller than 10
to 240 now you might say no the world
with China there are many more people
maybe so oh well let's make it 11 you
may say no human eye is not 2000 by 1000
it's worth of one medium pixel x 1
million pixel maybe so that will
increase this number 12 but that doesn't
make this number nowhere near 240 so I
have proven very important point which
is humankind has not yet all of 10 by 10
seen all of 10 by 10 images I call it
Canada's theorem by the way I have never
seen anybody yet who could refute my
theorem so I believe this has been
proven so this means that this implies
that we need actually a fairly bald
assumptions to solve any vision problem
so that is actually the meaning in my
fine the sheer why doesn't ok number
aspect but why vision is really
difficult is actually more than that one
is 2d 3d degeneracy image is a
projection so 3 dementia work is
degenerated so basically we're asked you
know 2 times 0 is 0 what was the
original number it's impossible in a
sense in a sense and while you you may
say that well from this for example this
one the world is 3d picture is to thee
from 2d we ask which of these buildings
a father now we may say it's obvious
this building is father and we ask why
because that building looks smaller
nothing wrong to have a small building
in front of a big building you may say
oh no this building is including this up
building nothing wrong to build inverse
l-shaped building is built so actually
this inverting projection is
theoretically obviously impossible now
another difficulty is doesn't work oh is
signal compounders pixel value is the
result of compounded physical phenomena
for example this pixel from you is this
is dark that is because the of this
cloth is dark this is wider than here
that is not because the cloth is wider
but because more light is on and as a
picture you can't tell which was the
reason somehow we should be able to
recover that and that is obviously a
very tough question
context which is artificial intelligence
favorite topic when you ask what is this
and then say people say car now you ask
why is this car people call say because
it's on the road now in this obviously
the context is playing a big role
because if you remove all of the context
this is the thing it doesn't look like a
car and for sure oops for sure this is
this context which is the road is making
that small thing appear as a car but if
you ask then why is this a road that
most people say because there's a car on
it and well that doesn't help us to
solve the problem so that is the kind of
problem that we should we should discuss
we should attack oh listen I hate this
and so in summary computer lesions
fundamental difficulty part from a sheer
number is this cyclic dilemma in one too
many problem as I said from projection
recover reality is one too many problem
and in that we have many chicken and egg
cyclus cyclic problem such as distance
once we know the size the real size of
the object of course the appearance will
help you to know the distance but if you
don't know both neither then we have a
consulate dilemma so is the case of
occlusion for example if we know we know
my hand is ACLU's my face but in order
to do that know that you probably have
to know this is my face otherwise you
cannot tell this is not part of the face
so so
that is and another thing is manual
coding in early on the typical approach
in computer vision was what I named
let's program what I think I'm doing
when he never given a picture we thought
oh what is the pic what is three and
they say Oh pic tree is green fan on top
of brown Fang so we wrote the program
what I call let's program what I think
I'm doing approach and everything was
like that but unfortunately we each of
us is a vision expert but does not know
how we're doing it so that approach
didn't work as well as we thought search
explosion is essentially when we turn
the cyclic dilemma to a search problem
which we should then the search tenth
explode very quickly and computer
computers have been too slow for that
and very important thing which I think
people have forgotten early on in
artificial intelligence is the lack of
understanding how to use physics in
vision I think the physics has been
neglected for a long time in spite of
the fact that physical process optics
geometry etc and noise is indeed
dominating how the picture is taken and
so that those are the reason why the
problem was so difficult and nonetheless
I think we have made some progress and I
like to go over a little bit of progress
by using only my and my CMU colleagues
work sorry if I don't use your work
because I'm not I couldn't collect all
of the example but I collected example
from our own work so let's go with that
so face recognition for ego this is my
PhD thesis 40 years ago and today it
seems that my own usual joke doesn't
work i think when i give a talk and
always they say probably none of you
were even born
I wrote the PhD here it seems that many
of you were born or even before me so it
doesn't work but anyway 40 years ago
this is my pieces and can you tell it's
interesting 40 years ago when we process
one image successfully by our program we
could write a paper and it passed and he
processed 10 images we proudly said with
a large-scale experiment comma we shown
we have shown XYZ now at that time the
one of the most one of the proudest
thing I had was this program was
actually tested with 1000 images at that
time and but nonetheless it's only 33
people about 75% of recognition rate but
since then myself actually other people
have done the quite a bit of phase this
is our work detection which we use every
day now on your cell phone and camera
and this is 1996 98 great time and
actually it's pretty good today this is
very common and if you look at it of
course detection we say face detection
precisely speaking this should be called
face image detection because obviously
this is not face see this is face image
my program does not know that so it's
probably detect that as a face and know
that as not a not a face but a face
picture is of course pretty difficult
task and today the more difficult and
common problem is called alignment that
is actually no individual component in
the picture and we have done some
program made some progress and the
program is actually available online if
you send a picture picture we process
and you get their back and it works
pretty well
and I think a Chinese student sent in a
very beautiful picture is so cendien
have a Japanese person obviously a very
meticulous he wanted to have what i call
stress test of our program and this is
what these guys sent like this and it
took two hours to process this image
about 500 actually this picture is much
bigger than this and it's successful we
could do that and then then of course in
real world it's actually interesting
many people have do extreme expression
and this kind of program uses so-called
knowledge how the face you know the
parts line and so forth and position
relationship size of relationship and
sofas and these example really violates
some of the very common ratio for
example this guy the distance from here
to here here to here is usually about
the same from here this guy is about
twice as big as this one so it's not
easy because if you allow them to be a
legitimate face then then a lot of faces
which are not legitimate we are now
recognized as a face so you have to deal
with that problem correctly to de
finally I think we have a pretty good
alignment program which which actually
does precise all posts all pawns
three-dimensional and occlusion robust
in the sense that all of the occlusion
and not only that the result I think I'm
very proud of it because it's it's just
like almost hand generated and more than
that it actually knows the occlusion so
when you do this this program actually
doesn't output this portion
program knows this is not a face this
part is not a face program knows this
part is not a face and so forth program
knows this part is not a face therefore
it doesn't try to output eyes and so
forth so I think the occlusion is in
this simple example is we are getting
handle on it and face recognition today
is actually amazing and if you look at
this progress last five or so years
actually a human recognition rate given
this type of image which is full image
face itself and background is about 99.2
I think computers are actually getting
there and if this rate is the case then
you see within a one or two here this
great will surpass the human and that's
where we have today and I think it's
getting oops will you go back yeah so
face application everywhere today camera
cell phones internet security and as I
said computer face recognition is as
good as humans and indeed if for most
serious applications human performance
computer performance is actually better
than human for example given a database
of 1.6 million mugshot recognition rate
is as good as 95% you cannot do it
because we cannot look at one point five
six minutes six million people let alone
even hundred people i'm not sure if we
can do it correctly so face is pretty
under control and more is coming and
this is
the problem that we have because which
call obama speaks Japanese and we create
Obama's face which is easy movie
industry does that all the time but the
point is that input is down lately
passively by step please without putting
any dots most of you guys on camera I
think we can do it you know I'm saying
the computer face recognition is
difficult don't nobody wanna see giorgio
maggiore vomits endorses ja ja ja
statement look all the time thanks for
him the next topic I'd like to talk a
little bit about is multi camera vision
20 years ago 19 early 1990s I started a
multi-camera research and I had a strong
conviction that the stereo should use
more than two cameras in spite of the
fact that human has only two eyes I
think that his accident I think we
should have had more eyes that's my
strong belief so he started two three
four and and so forth and then we built
1992 five camera system 256 x 250 i 8
bit depth image in 30 frames per second
that was one of the earliest machine
which amazingly consumed 5000 what 5,000
it's hot actually when we turn on the
whole room do you need any
the heater it was so hot and then we
built 51 camera system here circa
nineteen ninety-five at that time we
didn't have enough bandwidth to take all
the 51 cameras input into computer in
real time so we did what we did is we
bought 51 VCR video tape recorders and
the corner and all these cameras were
synchronized and time-coded each frame
and after the experiment we took video
out and put it in the digitizer another
one digitizer and because each frame is
time coded we know which frame on this
state corresponds to which paint on this
but can you tell I can tell you when you
have 51 VCRs even doing the experiment
is very deftly off because when you
start you have to push 51 start buttons
my students complained professor your
robotics professor please develop robots
to push the button I said no and he's
asked why I said because students a lot
cheaper than robots so anyway that's
this story on that by the way I had a
strong conviction the large number of
cameras is come when we wrote a paper on
the five stereo camera it was rejected
and the reason was this camera which
uses five this stereo system which used
five cameras will never be used in the
world because it's so expensive that was
the rejection and it says this is this
can be built only by takeo canara who
has so much research money but not not
in real world
that's this is true story indeed that
was the rejection letter that I received
and it's so funny that the world changes
so quickly and then from that inside of
that dome the what happens can be
digitized I call for d digitization
because X Y Z T and once it's digitized
you can actually synthetic court and you
can see the view from anywhere and based
on this one we did some system which is
named I vision by broadcaster CBS which
is used for Super Bowl broadcast in 9
2001 you know movie matrix I haven't
seen it myself but I was told it was you
know main character jumps and you can
see around spin around him that is made
this way all these dots are cameras and
in the center which all these camera
focus the actor performs and at the
right timing all the cameras take
picture at the same time and they are
concatenated as a result you think as if
the time is frozen you're spinning
around it so the idea is to do the same
with the football field but the football
field odd and of course you can't tell
where the interesting thing will occur
therefore each camera is replaced by
robot camera which actually track the
particular point and this is what we got
will you play now during today's
coverage of Super Bowl 35 CBS Sports
will introduce a new technology called I
vision
it provides panoramic coverage sorts of
the amount of sex in the if a matrix
casting I met it is very nice guy the
upper tots camera seven degrees each
camera feeds and these are actually a
storage today promptly the see images
are the computer calibrated and
assistant eight assists show any spinal
aplenty pc from all angles within the
cameras 220 degree rain initially not a
of carnegie mellon with the soils where
the blends 30 cameras into one dynamic
panorama this is a gigantic robotic
system you have to have perfect idea of
the direction position of the cameras
and the relationship of the amount of
zoom amount of focus to the command that
you give from the computer and that is
one of the hardest job
here it is this is an example during the
warm-ups taking just a moment ago the
pass from banks to Davis look at the way
can whip around we're all looking
forward to it by the way it can be used
in instant replay situations into the
case of a challenge you're wondering
what it is this is what it was so this
is how it works quarterback he drops
back look he's he's a big Lane look at
that big lane so he steps up into it
what string guilford nice look off looks
to his left
nicely
can see the receiver down the field yeah
so I usually say that I'm the only
professor that has ever appeared on the
Super Bowl there's a lot of story behind
this now so today multi camera
technology are used in everywhere indeed
our system was 51 camera system the
Super Bowl was 33 camera system there
are 200 500 there are a lot of them
today and entertainment as you know
camera multi camera system that will
allow you to get the picture everywhere
in focus can't picture and if you can
actually if you have a Foley foliage for
which tree lines by having a
multi-camera you can actually see
through for some military applications
and surveillance we know that is common
and today actually we are actually
looking at even a larger number of
camera calibration this is the design
1000 camera system each dots in this
room a camera today we have actually 480
combined and with this certain
performance can be taken and digitized
and can be modeled I think the guy is
spreading the papers we can actually do
a lot of modeling of events inside see
so one of the things that we are looking
at is to use this kind of system to do
to study human communication so for
example we have we got the two
we're going to have with a
high-definition very high display we are
looking at about 8,000 by six thousand
display and you are here and you think
that you're talking with a beautiful
girl but actually you're talking with me
and this one is actually synthesizing
converting the reality and so that I can
control the timing the manner that the
person smile nas and see how you change
your reaction in other word when you say
I like him because he agrees with me is
it because he or she looks actually
agree with you or the way you say the
same thing we can change it as we like
and that the kind of thing that we're
looking at autonomous driving 30 years
ago this is what we started it was
initially was about one centimeter per
second it's barely moving and this is
CMU's near and this is
ordinary and when a child comes out car
stops and the story is that the guidance
the child is a son of the programmer who
coded to stop at the dangerous situation
and actually this system later 1995 so
it is what almost 20 years ago we
actually did No Hands Across America
campaign 20 years ago so we drove this
3,000 miles from Pittsburgh to DC
ninety-eight percent of which was
computer vision controlled 20 years ago
it was very interesting but not one
hundred percent so it's not usable today
if it's if it's not under percent indeed
we are sitting at the driver's seat and
holding not holding the steering wheel
like this just in case you can hold it
so actually it's more tiring than
driving yourself that's what we had
another interesting story that I have is
that we you know Jay Leno the famous
comedian he had to use this system when
this car was driving across America he
uses you know newspaper article as the
source of joke and he said here is an
article he said carnegie mellon
university's researcher developed
autonomous driving car which allows you
for the first time to take your hands
off the wheel and drink a coffee read
newspaper or makeup and he said why is
that world first in Los Angeles people
have been doing that forever
that was his joke so that was
interesting and we actually have fun now
today this is mike 2007 mill house is
our CMU's wet Whitaker's work with
actually hamilkar eyes this is complete
autonomy even we even a human for safety
is not on the car it was very
interesting that the progress is being
made in about 20 12 wheels so today
driving assistance is with us or traumas
driving is in sight and the vision wise
lot more coming in a sense of robot is
getting the genuine understanding of
what is going on so far or the program
that has been developed is very limited
to understand the lane where person or
other car is not the total understanding
of the scene so I think the carnegie
mellon university's researchers Munoz
and Masha Allah bear they were actually
having a program which given this road
seen not only know where to dry but also
other things scenery understanding which
is indeed the real sense of driving
because by that you can guess where the
person might come out or this is old
this is a child therefore it's more
dangerous and so forth possible case of
change the action and so forth and that
is coming and what we have today one of
the things that I'm interested in is new
augmented reality and I'm let me talk
about this for the last topic which we
are doing right now which called new
augmented reality that combines
projector and vision in one device and
enhanced vision human vision so in a
sense it's augmented reality but it's
not augment reality of what we tend to
hear that is you have a cell phone and
look at the thing and the cell phone
says oh this name of this building is
such and such it's called augmented
reality I call it no it's not all men
reality it is all commented display of
reality reality is not augmented you see
this play is omitted what we are
interested in is augmenting the reality
so what does that really mean so in
driving this is rayne this is what you
get the rain looks very white and blocks
your field of view it's annoying you
know why because the rain is raindrop
and the same is true with the snow are
highly reflective they act as a comp
convex lens and collect the light and
return that's why it looks white you
know in other word head light hits the
rain and returns so what we should do is
when rain comes look at where they are
and control the beam in such a way that
the beam will not hit the rain then you
should not see it okay
now you may think that's a serious silly
but actually it's not that difficult
imagine your projector and camera is
placed at the same place so your line
the projectors line of sight planetside
means the direction of the shooting the
light is the same as returning of the
camera ok so send the light very briefly
take a picture then the rain should
become white dots and imagine that we
can take we can process that image and
know where the rain dot is in the
picture with zero second delay time then
what we should do is turn off the
projector so we change now the headlight
to projector basically you know this
that projector the same projector turn
off the beam that corresponds to the
dots ok but actually takes a little time
so by the time we are ready probably the
raindrops will be a little lower yeah
therefore what you should do is turn on
the lights above it side safe this is
safe he is very safe very safe very safe
very safe almost safe almost now this
place is not maybe not as much because
the wind they make this this way so if
you shoot the light it may hit ok so
that's a strategy and indeed if you look
at take a picture with one millisecond
then rain for sure looks like a dots
because the rain is about 10 meter per
second no faster than that ok ok so
as you I got the idea what you should do
is we have projector indeed that that
projector the same projector and the
camera with the half mirror and
processor in between so we modify the
projector by the way projector works
most of the projector about up to 60
frames a second that is only because the
need is that the projectors the mirror
the small mirror goes as high as 2,000
frames per second so we modify it so
that it works and put that in together
with the camera with a half mirror by
the way the brightness of the projector
is about 4,000 lumen which is even
brighter than the headlight of ordinary
cars and we we built our own headlight
and put it on a car oops put it on a car
then you see rain disappears
oops snow too but this is not real so no
this is snowflake and in a slow motion
you see it's easy in slow motion this is
about the speed that you have to deal
with in computer vision today it's not a
difficult task so once we do that oops
that's really I hate this we go back
yeah I'm back I'm back yes we can think
of better theor 12 which is up beam low
beam you see when you're driving you're
supposed to up liam is easier to drive
but when the car comes you from from you
turn to the low beam because the high
beam will make you the driver of the
other side momentarily blind do you know
that period of momentarily blindness
takes longer for 55 years older about
five times longer eight times longer
than 16 years old so many of you are in
problem so what we should do though is
we don't need to turn to the low beam
all you have to do is to turn off the
beam which correspond to your eye then
you don't think it is a high beam no let
me see this is doesn't work yeah so like
this so this will make always up beam
headlight and indeed it works on coming
this is the others other car it doesn't
look like a high beam this is your be
your car it's always hiding in fact
if you don't if you don't we we turn on
and off the this is high B see if we
don't make that capability if you turn
off that capability it looks like IBM
but if you turn on that capability it
looks like a low beam to you but that
guy is always high V okay so I think
sorry I actually designed to be about
finished in time but the rear view is
the same rear view when the guy come
from behind it's annoying so all I have
to do is turn off the beam which
corresponds to the rear view of the car
in front of you and then the guy in
front of you can actually see you
clearly ok like this but you always have
you and if you have turned actually
combined with the radar with a camera
then detect a person in the fog now this
is tough one somehow we have to let him
that the person know there's a person in
the fog now showing this doesn't help
because then when you drive you have to
look at the display that's that's more
dangerous yeah you have to look you have
to it appears to you that the person is
visible now one way is of course is to
send obstacle our spotlight but since
it's a fog it may or may not work so one
possible idea is we have actually more
projectors on the car and converge the
beam so that that particular position
get the higher one ok
for that you need a bun you need a
baseline and the cars baseline which is
about 1.7 liter may or may not be enough
so we may have a hypo like this and then
we may be able to focus on the point or
eventual solution is put electrode on
you're here and the processed image will
be fed to you I then to your brain then
you'll see a person through the fog now
that's a futuristic idea and you may not
even it may or may not want that
solution but anyway so as you see this
is not augment reality of display this
is a real augmented reality so finally
sorry over on I think future various
points I think it's obvious your bigness
sensors low-power processes real-time
access internet and so forth will
actually bring us a new brand of
computer vision which is somewhat
different from traditional sense of
computer vision that's what I wanted to
say thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>