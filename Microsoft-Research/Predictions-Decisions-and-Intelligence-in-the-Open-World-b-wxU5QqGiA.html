<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Predictions, Decisions, and Intelligence in the Open World | Coder Coacher - Coaching Coders</title><meta content="Predictions, Decisions, and Intelligence in the Open World - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Predictions, Decisions, and Intelligence in the Open World</b></h2><h5 class="post__date">2012-08-17</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/b-wxU5QqGiA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so it's a it's really great to see you
all here and it's a really great
pleasure for me to introduce our first
keynote speaker I was some of you know
me I'm really attracted to quotations
and I thought there was one by Sir
Winston Churchill that really fits our
first speaker and his topic of his talk
this morning true genius resides in the
capacity for the evaluation of uncertain
hazardous and conflicting information
seems like it could have been written by
our our speaker air corvettes this
morning eric is in fact one of the
world's most important researchers on
problems and ideas and principles
related to sensing and decision making
under uncertainty he is of course for
his distinguished research contributions
in career a member of the National
Academy of Engineering a triple AI
fellow a fellow also the American
Association for the Advancement of
science and the other triple AI the
american academy of arts and sciences it
besides really amazing and important
long-lasting research contributions
erica is also an amazing mentor to many
many young scientists around the world
some of whom are now not so young and I
serve into the community he was the past
immediate past president of the triple
AI he is on the advisory committee for
the NSF computer science Directorate and
the member of the CCC Council and last
but certainly not least the deputy
managing director for the microsoft
research lab here in redmond and and for
that I'm really grateful because of
course we work extremely closely
together and so please join me in
welcoming our first keynote speaker Eric
Horvitz
well thanks for that very nice
introduction Peter so it certainly we're
in incredibly exciting times I have to
pinch myself once in a while when I put
myself back in my grad school days at
Stanford in the mid 80s to late 80s to
think about the competition memory we
now have the connectivity and data and
most of all the learning and reasoning
algorithms we now have to to work with
data make decisions under uncertainty
and so on I thought today I talked a
little bit about some opportunities and
directions in this realm back to my you
know late 80s at Stanford we were really
excited about this idea of capturing
uncertain expertise with graphical
models Bayesian networks where these
random variables at representatives as
circles here are connected to other
random variables with these are accepted
dependencies and this took us a team
anglo Bionic and others you know about
about two weeks to build by hand where
the numbers came out of the mind of an
expert anesthesiologist and once we
built this network this graph which
represents distinctions you worry about
in ICU intensive care medicine you can
run them by putting any observation in
here blood pressure and CDP things you
could see running Bayesian network
algorithms and picking off probabilities
of things you couldn't see like
pulmonary embolus so these are very
exciting grass but they were very time
consuming and hard to build now in the
90s and into today there's really been
an explosion of learning methodologies
to learn these kinds of graphs from data
and learn other kinds of models as well
here are three variables and you can
connect open to a variety of different
ways and one approach is called Bayesian
structure search basically looks at all
the different combinations using
heuristics to inform these structures
and has a score to score the the power
of that model to explain data and finds
the best model and that model
typically is when you use to actually go
out and actually make predictions in the
world of these states you care a lot
about that you can't usually see
directly and of course there are other
procedures as well beyond making
predictions capture here by this alisto
Graham here from data we also worry
about actions in the world in the open
world what happens when you you you base
your take preferences and these
uncertainties that are inferred from
these models and they can take action
it's a the set of innovations has been
marvelous in the space of going from
predictions to actions as well in fact I
like let's think about a data to
prediction to decision pipeline often a
couple exciting directions first of all
this idea that all of a sudden baseline
connectivity and communication systems
we have these ambient might say in
stream data resources that just are
available this hit home for me a few
years ago when we got access to a cell
phone data set that just basically had
densities of cell phones at different
towers in Rwanda and she's Kapoor and I
working with with Nathan Eagle looking
at what we can say about what happens to
these cell towers and communications
more generally when there's an
earthquake about a six point 0
earthquake outside of Rwanda not far
away the lake evo earthquake and and but
can a half million phone calls watching
the anomalous calls on these cell towers
only hundred forty of them from this
earthquake let us with some interesting
probabilistic methods pinpoint within a
few kilometers of the epicenter just by
watching the surgeon phone calls at
different cell towers as people
responded naturally and we can take a
decision model on top of that and
compute regions of the country we would
want to do surveillance on
reconnaissance because of just standing
disruptions based on the uncertainties
there just from ambient data among
exciting technol directions in learning
right now our causality really getting
to the foundations of course science
does a really Cosby or do a and B
co-occur with a cause up upstream called
sea
active learning thinking a lot about
about how we can grow a database given
the costs and benefits of the collective
collecting data lifelong learning
building systems that really understand
that they're being used over a period of
years to decades and serving the
population of people for example and
then recently this is protective of work
in deep learning this is like the that
you might call this the third wave of
neural nets where you know the idea of a
neural network has but that's
biologically inspired has been a
long-term dream and it's been
foundations of intuitions but recently
we're seeing notions of taking these
these multi layer or cascades of
networks where we build inferences at
one layer that become inputs to the next
layer and so on and we're actually
seeing significant gains which are
actually surprising and give us a sense
that maybe the something to be said
about looking very carefully at this
third wave of neural nets lots of
itching directions going on there so
today I thought I would focus on four
efforts at Microsoft Research several of
which our work are developed closely
with our partners at several
universities and other government
agencies and centers infestation health
care citizen science and then some some
heart problems are facing and trying to
build and dress the dream of intricate
of AI or a long-term dream of building
intelligent systems and I think for each
one I'll capture some themes that I
think are interesting to this group and
I chose some society relevant topics I
think people will resonate with them
they also resonate with some of the work
that the microsoft research connections
team has been funding over the years
externally so first the transportation
want to discuss the work this work which
is going on for about seven or eight
years now at microsoft research
highlights the notion of the power of
heterogeneous data sources and user
models so about five or six years ago we
were very interested in the seattle
traffic problem everyone from seattle
knows that we had the worst traffic in
the world I thought the Bay Area was bad
until I got up here so we started
looking at that
looking at sensors in highway systems we
can get multiple views on traffic from
the highway systems we can get incident
reports from the Washington Department
transportation like Nick here is
reporting on what's going on in terms of
Lane coverage and so on we could go out
to the web for all these reports weather
reports major event schedules we could
grab a large map of road topology and
properties every single road is captured
and of course day and time and build a
large database that we can then use to
make predictions and we can like we
could use that Bayesian structure search
to build up one of these graphs that
will tell us four different parts of the
highway the likelihood of a clog for
example then filled it on on on portable
smartphones of course people's pockets
and provide this kind of an inference
here where you see this little wedge
here showing the max likely time that a
jam will last until it melts as well as
the system's competence so this was
reasoning about its own confidence in
sharing that with people as a lot of fun
and excitement deciding to build the
system but we all started learning about
the value of these systems in people's
pockets well what do people use them for
exactly turns out that most people in
Seattle fashion themselves as seattle
traffic experts they don't need to have
inference to tell them it's you know a
rush hour or any night going of kirkland
from redmond is going to be packed and
terrible on the 405 north so we actually
started thinking about the user
perspective on machine learning which is
a machine has a world model and it's
making inferences for example about
traffic a human being this seattle
traffic expert lots of experience is
looking out and she or he have their own
inferences and could we build systems
that could have a model of what people
thought and then consider an estimation
or approximation of what people think
and what it thinks for a gold standard
and work with people to share a most
important information possible this lets
well work on models of surprise can we
learn with machine learning algorithms
what will surprise people now and in the
future and the idea here is we have a
human forecaster who understands we know
major events whether time and tell you
time and day and holiday or not we could
take slugs of 15-minute segments of time
over period of
of years and build an expectation model
and then find these exotic flows and
clogs in the highway which are like one
in a thousand or one and 100 we set the
threshold and then we want to store a
database of human surprises about CL
traffic in this case our system has a
bigger perv you about what's going on in
the world including accidents happening
the dynamics overtime sporting events
that the expert might not know about the
topology of the road and so on and we
can actually correlate the human
surprises with not just what's where the
system knows now but what it might know
ten minutes ago or an hour ago so we're
going to go back in time now and here's
the core idea can we build systems that
I can hold up one day and predict when
i'll be surprised in the future and so
with the machine learning with this and
now in the same system on the same cloud
service we overlay a surprise
forecasting model that's humming along
with the base model and it knows that
most people in seattle would be blown
away by this clog here at this time for
example or here and what this means here
is that you will be really surprised in
an hour this will be wide open right
it's predicting surprises so if instead
of looking at your device and checking
it we can have a proactive device that
lets user preferences set up and say
just tell me when i'll be surprised in a
half hour on my route home and this
brings up the idea of a human dimension
for learning it's not just domain is
also the people using systems now that
work actually on what's called Smart
Folder to a clear flow project which was
the grand challenge of can we take
highway data and a lot of GPS data
collected by people working with us
about a million kilometers throughout
Seattle our road warriors and build
models that could actually reason about
unsent roadways based on their
personalities and topological
connections in that big graph called the
seattle road system and this work led to
bing maps current traffic system that's
humming right now as we speak every few
minutes flows on 60 million streets
across North America
updated in these major cities so if
every Street has a little probability on
it as a certainty Anna na and a road
flow we can then generate directions the
big question around Seattle here is do I
go across 520 90 or so I go around the
top and if you use Bing Maps or your
Windows Phone this is all default now
and standard and I've gotten one
complaint about the system from a senior
engineer at Microsoft who came up to me
and he said to me it's giving away my
secret I get off and get back on again
over here and so this is the standard
recommended route by the system so let
me with the health care now as
transportation I've been really excited
about the prospect of facing these
high-stakes daily challenges in
hospitals working across cultures
medicine to your science and the notion
of coupling prediction and decision
making as with it with a team including
former postdocs from msri Princeton in
Stanford and folks work with at multiple
hospitals so about three years ago there
was a very widely cited New England
Journal of Medicine article that said
from 2004 data that twenty percent of
patients who are discharged from
hospitals bounced back within 30 days
and if you look at this these these
costs as avoidable or mouth pecs is
avoidable that's 17 and a half billion
dollars of avoidable cost per year we
got access to a large data from a large
hospital in washington DC top 10 urban
hospitals in the united states and they
had a beautiful system that they've been
ahead of the curve here collecting data
for about a decade for example they had
300,000 emergency department ed visits
of all rich this internship which
information including admissions
discharges transfer labs diagnostic
codes procedures vital science and so on
so we actually said let's bliss lets you
see if we can predict a readmission is
their signal in all this data concern
about 25,000 variables with our with our
machine learning tools we built several
different kinds of models what this
model says here is that
it predicts someone's in the ed and gets
readmitted in 30 days ed a 30 and the
system discovers the kinds of variables
likes to use tip that would be most
discriminatory here including gender and
diagnostic codes and visit gaps between
visits at the hospital and so on age and
so on we can then build what's called a
receiver operating characteristic curve
which shows how thresholds will dip that
we set on what the system tells us will
lead to different true positive and
false positive rates with a training set
and a little test set that we hold out
to build these curves and you can show
these to physicians and say this house
how well the system that I built will
work on your data we can also say here's
here are some features that have been
pulled out by the system which describe
the most discriminatory evidence for
example the fact that a patient has been
wrestling with a malignant neoplasm
cancer or has a heart failure diagnosis
these are well known challenges for
recurrent visits to a hospital but most
people even experts wouldn't think that
staying 14 hours in emergency room or
looking at all text in a record that the
word dialysis appears or the word fluid
appears would be bad signs for staying
away from the hospital but our
algorithms we figure that out and
leverage that information and over the
last two years or so we've built several
different kinds of models including
models that predict readmission and
various kinds in different various
horizons models that predict that a
hospital hospitalized patient will
acquire a hospital associated infection
within two days or three days and so on
this was a big challenge in hospitals we
also have built new kinds of models now
you've got you guys are all surprised
modeling experts we did a surprise model
what's a good surprise model for
healthcare and this model here was one
built from data of the form that says
but leads to models that make
predictions of the form the ED physician
is told the patient you're discharging
right now will likely bounce back within
three days with a primary diagnosis
that's nowhere on
chart do you want to look and the system
might that might too we reason about the
borders of human knowledge here as
opposed to telling experts what they
already likely know last year we
translated this research into a real
world system amalga clinging to the open
world I'll just mention mention a few
comments about this translation as it's
called in in the in the health health IT
industry first of all it's protract
ability we had to back off of those
25,000 variables looking at how well do
we do with 463 of them or 37 and look at
these curves and performance trade-offs
we also have to worry about can you
really take the same system and pull a
string in different hospitals and have a
train locally without experts in the
loop and that's still a standing
question in fact microsoft research for
every install gets these curves week
that's part of the deal we look at the
curves and we're in touch with the team
deploying these in the early years of
this there's people from Southampton
here today we just deployed in
Southampton in UK so the stelae shaking
hands there yeah this is basically
provides a probability of a bounce back
this is Pete this is a record sorted by
patients who might recur come back to
the hospital within 30 days and the next
phase we took this work was into this
whole notion of decision making and this
is where we are now we're saying okay
what do doctors do with that number
they're seeing this probability of
readmission might it be avoided so we've
been working with us the whole set of
positions on what you might do
differently what are various kinds of
programs and interventions you might
take advantage of to reduce they were
likely to readmission turns out there's
a literature of people trying this or
that I tried this post discharge program
of education I work with the family I
realized this patient had poor self self
care because of their socio-economic
situation and what psychology and so on
and the idea is we want to take this
predictive model here probably a
bounce-back given evidence which my 400
variables are 25,000 variables and
reason about a decision model or create
a decision model that can do the right
thing
under uncertainty that maximizes
expected value or minimizes costs their
variety ways to frame that that decision
problem what I want that this mentioned
today briefly you would have a lot of
time up here today is that I'm very
excited about the notion of building a
system from data that has a predictive
model you've built with the machine
learning algorithm a decision model that
might work that will take his inputs how
much money you might invest in a
particular patient and what's the
promised reduction in readmission rate
might be and before you filled that
system run it in the same way we run our
classifiers now but now it's a whole
data to decision to action pipeline with
a train and test for the whole pipeline
and even its uncertainty about in these
numbers and there's a lot of uncertainty
in the medical community run the whole
system with those test patients for
different points in the dollar we reduce
readmission rates space given the
uncertainty there and tell the DC
hospital if you believe you have an
intervention that will cost four hundred
dollars that can reduce the readmission
rate by by forty percent when we run
this model with the classifier running
with all its noise and the and it volts
power and the decision model here's the
total savings you might get and read off
this curve so where we actually
computing the expected value of
immersing a system in the open world
before we deploy the system and what
this work is ongoing right now with
clinical trials being kicked off in the
DC hospital here what a fifth gears now
and talk about another case study this
is a this area of work on citizen
science that we've been engaged in over
the last several years is an exciting
one for us in that it touches on several
topics including how do we deal with
large-scale data in science which is
growing so fast that scientists
themselves can't keep up with it it's
also an area for the science and the
computer science so we're very excited
about called human computation and
crowdsourcing we have a track today that
Ajay Kumar has has organized
I want to highlight in the citizen
science work in the particular study
we're doing our excitement about
computer science principles and methods
for joining human and machine
intelligence together as well as in one
system having predictive models and
decision-making that plays several
different roles so in citizen science
volunteers my are engaged to for example
help tag galaxies flowers to classify
various kinds of objects spot birds for
example per season even do things like
discover new objects in from
astronomical surveys and in fact that's
very working in with the Zooniverse
folks were very cooking very closely
with people who have actually been
working on building citizen science
platforms for classification and
discovery in astronomy and there are
microsoft research connections folks
have also for four years funded these
folks in their in their core effort the
motivation is simple though he's an
example so the Sloan Digital Sky Survey
several years ago did an automatic
survey of the heavens and discovered
about a preferred digital encoding about
a million galaxies 120,000 quasars and
225,000 stars closer in our own galaxy
and created it they said this is this is
far too big for any astronomer to look
at how get people to help us classify
these galaxies into different categories
that would take a little training course
online might be it would it be a sixth
grader or a high school kid or junior
astronomer that you know that goes out
every night and tries to find his his
his the comet that might have his name
someday these people all could be very
valuable to astronomy they created a
system for Galaxy Zoo which let people
do these galaxies and a data set came
out of this study of nearly a million
galaxies 34 million votes as to where
people thought what people thought about
these different galaxies and engage a
hundred thousand participants and this
work with with Asia Kumar leading up the
effort Severin hacker who was a CMU
intern with us
but the two summers ago crystalline
taught who leads up the effort in
Zooniverse and our fun Smith give a
sense for the Galaxy Zoo interface
here's what you face if you become a
junior astronomer or i could say citizen
astronomer this might be senior as well
you look at a blob identified by the
Sloan Sky Survey you try to classify it
after you take a little course even
classifying whether it's you know a
clockwise or counterclockwise pinwheel
and so on a star maybe goes you found a
new object for example now we notice
that there's also this the sky survey
itself was available we could actually
gain access to for every one of those
blobs most of which were unforeseen like
we've never seen before by human eyes an
automated machine vision based survey of
that that object these are just a
sampling what these look like Petrosyan
magnitude colors Petrosyan radius
inverse you know these are almost it's
Latin to people outside of the
astronomical field that the what the
camera is seeing so we said I wonder can
we build methods using machine learning
and decision making that would fuse
human and machine perceptual effort want
to join those together the same time we
want to optimize the whole process by
which how galaxies are routed to people
based on their abilities and the need
for votes versus stopping of stopping
rule saying we have enough votes so
we're going to enough imagery on this
object here to the celestial object
let's move on to another one now so the
idea of optimizing task routing and
stopping and so with a system called
crowd synth and now Zion which is its
descendant from a real world platform
we'd like to weekly said let's break
this problem apart into pieces let's
think this through we have a machine
perception system that's going to going
to look at the sky take the sky survey
data these know these these the 700
features we have people who are now
trained to do votes
and we have imagery flying by can we
focus the information from both the
cameras and people's votes put their own
perceptual systems after they learn how
to classify galaxies and optimize where
votes go and where objects go so that we
can actually make the best use of people
now it's the people who are the scarce
resources here the camera can run all
night doesn't mind about you know
whether it's a million or two million
galaxies so wait ahead and ran this
these models and what you see this is a
little hard to decode but the important
part about this model we built in this
case this is only a piece of the model
there are many more variables actually
this is the most important ones is we're
fusing together features from the camera
with observations about the workers and
their voting over time given different
objects and current status of votes on
this particular object to generate
probabilities of what the actual reality
of this system is for this galaxy when
the answer when the true answer is known
as well as what the next vote will be
now you need both these variables to run
a decision-making system that the
sequences of actions and makes decisions
about where to distribute attention in
the system and went to stop now just
give you a sense for how powerful this
methodology is for the future of citizen
science and this should be a given you a
sense for where this is heading what you
see here is the accuracy will on the
system with all votes in there's a
little cost benefit information here
because we looked at cost even though
most galaxies do people come on for free
but we looked at different pricing but
the idea is with the crowd said the
algorithm with just about a little bit
more than half of the votes collected we
showed you can get almost complete
accuracy so the future in this work is
we can actually start thinking about how
to more generally even beyond citizen
science how do we join Uman intelligence
and machine intelligence in ways that
make the best use of people and the best
use of machines and by the way as the
machine competencies are evolving the
border will be involving as well I'm get
several projects in this realm
when one less comment about citizen
science is this model here shows in a
separate study that Severin hacker and I
did when he was an intern how the
correct answer coming from a particular
volunteer is influenced is predicted by
what the computer vision algorithms
tells us about the blob what the
experience is we've seen over cross
session with this user in how well
they've done and being correct and
incorrect in their in their work before
and even their current activity their
current dwell time how long they've been
on how many objects they looked at
tonight what time of day is it where
they are in the world now think about
the implications of this here's a
volunteer in this case and we're going
to reason about for any object in the
system whether this person would be
helpful or not now if you think about it
one thing we could do is we could route
tasks that are most effectively solved
by that person most efficiently let's
say spiral galaxies to this volunteer
but even more interestingly which has
implications for online education let's
take examples of celestial bodies that
this person does not do very well at
could we have machine learning and
decision theory guided educational
experiences that focus on making that
person better at just the places they're
not good at we found through online
volunteer activity so implications here
also for education online education
systems that might someday build models
like this beyond citizen science so in
the last a case study or effort I want
to talk about I want to focus on the
dream of building richer machine
intelligences there's some great quotes
Rick Bastian recently gave a talk and he
he quoted what Marvin Minsky said about
five or six years from now we're going
to have you know we're going to
basically replace human beings with all
the intellectual and scholarly
activities they do
and this is back i think in 1968 or
something Life magazine article even
herb Simon who many was you know many of
us know and and new and deeply respect
for his contributions in core additional
behavior and artificial intelligence
thought that we be much further along by
now it's taking longer I think we're on
our way one approach to this dream and
on our group we have some sister groups
at universities right now is
intelligence via composition of
competencies I'll mention that as a
theme here as well as the what you learn
when you try to feel systems that are
situated in the physical world and
they're taking action in in the physical
world this work is with Dan bows Ajay
Kumar you know and the ms thompson and
paul quotient several others on the team
so the basic idea of interpretive AI as
i say well you know there's been great
advances in NLP now people some people
here just got back from ACL in in korea
it's the monsoon there we have a great
work and planning inference learning
vision these the latest advances of
these different kinds of you might call
them pillars of competency of a larger
intelligence or intelligence system are
typically revealed in in conferences
like cvpr or ACL or icml you AI or KR
and the idea is could we get further
ahead by trying to the best of breed of
these areas and weave them together we
might see that the whole is more than
some of the parts i might even learn
about the integration but the synergies
and dependencies so the situated
interaction project really takes as a
perspective a pretty audacious goal and
it is when people work in teams together
what would it be like to build an
intelligence that's a team member for
example in a complex surgical setting
whether multiple collaborators someday
technologies that can understand a group
in front of a billboard i worked with a
group interesting ways or imagined it
that you're using in your kitchen
someday that is this ambient and as
you're going through recipe with a
friend you know you're being assisted go
ahead pour it now slowly it's just
racking the physical the physicality and
the goals and intentions or who has
young kids imagine going out to the
movies and saying oh no problem I'm
leaving the kids with Robo and he's
going to engage them a little bit
education will get a call as a problem
so as to start this project off a few
years ago we actually set up cameras
with disclosure and signs in our lobby
at microsoft research building 99 and
just to get a sense for how does a
receptionist work with multiple people
coming in and with tasks quickly build a
system that might be like a receptionist
someday in particular for this study was
situated interaction with multiple
parties at once in a dialogue system and
after looking at some videos and
thinking this through you know how do
receptionist work with people at once
shuttles for example how does he or she
find out who's together for example
let's say I was thinking about
representations now fairly rich and over
time the temporal dynamics looking at
joins and people in and out of the frame
tracking goals as they might be morphing
over time or remaining stable suspended
goals multitasking in these environments
even social graces for example when
somebody walks in even though you're
busy might and receptions might not and
saying but wait a second I know you're
there and beyond the software in
representation we sort of thinking
through let's build up kind of a
representative platform now some people
have seen this video before that I'll
show now but we built a approach was to
try to see if we could do some of the
things that a receptionist does also
snip of the city
with this kind of context where the red
dot is where this elaborate r is looking
and this was our first go at this and
just watch how the system is recognizing
multiple people and working with people
that are not part of the scene that are
coming into the scene yes which building
are you going to I faced building on you
sure yes so you're going to nine right
yes and this is for both of you right
yes I'm making the shuttle reservation
for building 9 42 people in case you
want to correct anything say or press
star over are you visiting someone yes
I'll help you register in just a moment
okay excuse me sir yes you will be on
the shuttle 53 so that was an initial
foray and we use that to figure out the
competency and the end and the gaps and
problems with trying to work in the open
world one thing that was kind of
delightful is that we realized that
people weren't used to systems that can
see multiple people and engage a group
and that was almost like startling and
magical to people and it just it it
frames the direction we're heading with
computing in the world being more social
we did things like studies with users
brought in a usability program for for
example how could a system this is like
might take this is not jeopardy Watson
style this is where we're trying to be
Alex Trebek and understand how that
works
power plant what color is it green do
you think things yes that's right so far
at one correct answer now on to the next
question in the US hospitals have a bed
for what I did
solid blue circle anyway we can really
learn a lot about how a moderator might
work with people and I get a social
setting by watching how they work with
each other whether they're talking to
themselves to the system lots of
learnings there we actually also set up
systems in like bike off ears and
Microsoft people can win a win a prize
by playing this trivia game we have
great footage that's but you know again
filmed with with with disclosure and
learned a lot now now the current focus
of our work in in this area is called
the assistant in terms of a platform let
me give you show you what I what I deal
with in the morning but this business my
normal morning cup coming into work by
my office here
I just don't it last week hired no one
has stopped by to see you since we last
talked and outlook mobile manager is
still down so i'm not seeing messages
from your email catch you later viola
now this assistant is building on the
same platform now it's a really
interesting set of tasks to support
derek and people that come to see me
given my calendar but what's interesting
is we're leveraging components that
don't get old even when they're six or
seven years old we presented the
coordinate research at you AI about
eight years ago we built the system that
can reason about and forecast a person's
presence and availability over time even
what time how much longer until i read
email until they're in their office if
they're conversing how much how long
will the competition last this system
has been running straight for about
eight years and we said what we're
building a platform to be an assistant
let's give that that system as part of
the integrative intelligence that
component we also had a system called
busybody that can in a separate piece of
work that was published as cscw about
five years ago that reasons about
attention interruption that computes the
cost of interruption at any time and
let's give that competency to the
assistant so let me show you a little
bit about how the system works as a
couple of vignettes here that capture
how it runs
each vignette captures a different
notion here what it's doing a competency
yes are you can and hope just I this
virtual evidence I nokia meeting
scheduled with you my place from his
previous meeting in building 34 is no
longer on his laptop so I maybe 10
minutes or so you can have any way into
all that if you'd like although come
bugging me okay I'll make sure it
likability returns alright thanks XD so
it's just hello hi you're looking for
air yes Eric did that even come to chat
right now but I expected to open around
10 minutes would like to wait for a bit
sure sounds good he shouldn't be too
long yes I'll see you later then by line
by
hey I'm usually more nervous yes I'm
here for the jimbo mommy with her yes
are you family bleep yes I am Green
expecting you will you be joining the
meeting yes all right I'm let her know
you'll be joining his meeting with dan
if you don't mind leaving around Bergen
born minute I'm sure did not even
shortly yes I'll be elated that so these
scenarios go on and and they're quite
rich and interesting for example I think
it one scenario so much trying to
schedule with me my schedules blocked
for the day but the system using
coordinate says I don't think Erica's
tending will attend the meeting at four
o'clock I'll pencil you in but like for
that telling me that I'm really what
it's doing and it has a Bayesian model
of meetings that I'll attend versus not
even when they're on my calendar
something we all might find useful and
also as a nice reminder model and those
were to remind me about like meeting
rooms and so on that runs with the
system beyond the alchemy of cobbling
these systems together it really
resonated with the dream of learning new
things and if you look at the stream of
papers and results on this and it's been
a cauldron of innovation within turns
over the last several years great
interns have worked on this the system
Steph Rosenthal was here last summer
from CMU and others but the idea
basically is learning about the whole
notion of things like information value
which is a decision theoretic concept in
streaming settings how do we learn and
combine multimodal streams that are
coming full unfurling over time and so
on so I get really excited when we can
take a hard challenge and learn new
things in new core computer science
results while trying to build a system
that works with books in the real world
let me just say that the same platform
right now just got hooked in last week
to Microsoft building 99 elevators the
is the same situated interaction
platform slightly modified that is
promising to make the Microsoft
elevators in its lobby like Star Trek
doors both opening when you walk up to
it but recognizing intentions and even
holding the elevator door open and
someone runs to catch it without
requiring you to jam your leg or arm
into the into the doorways the 20th
century concept and it's kind of
interesting you think about the hard
part of this problem we already had our
platform the hard part of the problem
was the otis elevator guys the Tyson
Krupp guys and Microsoft real estate and
facilities people that you want to talk
to our interface let me see who you
might ask and this is a variation italan
JH what we solved all the challenges we
blew a fuse last week looking things up
an actual old fashioned fuse but we're
now in the at the point where we're
learning from those button clicks are
that supervised learning signals of the
future so I'm going to end by just
mentioning it's a real tiny bit which
very important topic it's a whole nother
lecture or talk or conversation that
should we should all be having about
privacy data and machine learning during
my talk you probably seen you see
medical data fly by you seen people
walking in lobbies of buildings you've
seen you know volunteer astronomers
being rated for their competency behind
the scenes there's an urgent need for us
to tackle as as as a computer science
community and for full and associated
communities the challenge of privacy
data to get the most out of machine
learning both for a variety of
applications so it's it's an urgent area
but I'm very optimistic I think this is
not I don't think I don't think doomsday
here in fact several great piece of fuse
science work are coming out some
architectural some in the HCI space but
others in notions of decision theory for
managing the costs and benefits of
sharing information and making that
clear to people with one with controls
differential privacy notions of adding
various kinds of distributional noise
plus a noise and making and proving that
it's okay to do that abound the the the
the error in answers at a notion that i
referred to as protected sensing and
personalization which is growing an
interest at microsoft in microsoft
research and other centers we have a
colleagues at Stanford example monocle
am pursuing this kind of work with
protected sensing and personalization
the data mining Center is owned by the
user it's their own stuff and they can
share all sorts of interesting nuance is
all their email for example and all the
reasoning decision-making occurs within
the borders of somebody's own devices
several example demonstrations and
protests over the years really resonate
with the notion of this protected
sensing and personalization several
years ago Jay meet Yvonne and Susan
damai and I actually when Jamie was
still an intern at Microsoft festered
from MIT I went to David Carter's
students thank you David for forgiving
us Jamie it worked on peace or
personalized search and with P search
the idea was that a system would Bravo
over an index and look at email
documents web activity even GPS Wi-Fi
and accelerometer data someday build a
local store of that information to run a
personalized rancor and we did a search
for diplo i did a search for Lumiere the
the bing engine would bring back a whole
bunch of results and the personalized
rancor in the secrecy and
confidentiality of one's own computing
world would do a reranking based on the
context and interests and so for example
you know if i put lumi here and i get
all the stuff about Lumiere restaurant
and Lumiere HD but but the personalized
ranking would give me what i was looking
for based on my email store and what
I've been talking about and what I've
been doing in my documents one other
example is life browser
you know Richard fireman said there's a
lot of space down there when you talk
about nanotechnology well there's a lot
of room for innovation and data mining
with one's own stuff that we barely
scratched the surface of life browser
crawls over your hard drives keeps all
inferences as private and then generate
big time lines with across multiple
streams of information with the notion
of a memory landmark the idea that like
I can do inferences about what things
are most important and a volume control
to go to the most important things with
everything again all being done in the
privacy of one's own world and there's a
lot of work that can be done in this
space and in combination with cloud
services that will bring a lot of the
power of machine learning to life for
people by the way a life process of
distant runs active learning once in
while even as a dialogue about memorable
landmarks for example it asked me is
this PhD oral exam that's definitely
Rosenthal had was that a landmark and so
I could say oh yes that was and this
isn't gets better and better over time
but it's all done in the privacy of the
box same with pictures and images with
active learning so let me stop there it
takes from questions also summarized
that the applications of sensing and
learning and reasoning are still very
much in their infancy I've mentioned the
like for studies with some themes I
think I see unprecedented value coming
to people in society from these
methodologies and what I love to do is
take principles try to feel them in the
real world and we learn new principles
and the cycle continues so I'll stop
there thanks very much
hold it up THX hi this is Kim a leap
jewel de from I fifth working group and
also global supercomputing now there's
been a lot of efforts in machine
learning like inductive inference
genetic algorithms and a basic idea is
from you get and you create an algorithm
for classification and you can use that
algorithm to actually classified data or
you can use that to generate a certain
class of data there depending on the
algorithm you created but the results
tend to be too simple for certain
categories of goals for example try to
learn beautiful music try to learn what
beautiful poetry is or try to learn what
a good a good beautiful mathematics is
and you're another approach is basically
you handcraft the algorithm and you use
that to to to create the music that's
also very difficult I mean Doug line try
to do that in math you know others have
tried to do it in music and the net is
that the algorithms are way too complex
to what the machine a machine learner
produces I mean is the model adequate
for for the lofty goals I mean a well so
it is it or is it too simple so that
it's it's really founded on what what
you can achieve so I mean yes why here
you're saying and I resonate with this
night idea that we still are early on in
our ability to do many wondrous things
that people do that might be true
forever on classification the way I have
to I have to beg to differ about the
power of machine learning to learn the
nuances
of the essence of humanity in a really
in a way sometimes better than people
can do for example understanding from a
large corpus of voicemails which people
when they call me know me well I
wouldn't myself but I can point that it
but Ike would be able to sort of right
then any rules about that and system
figured that out by listening to prosody
now it takes a training set where I say
well I know these people really well and
these people i don't know well and the
system figures out for example in my
case that the maximum duration pause in
a voice incoming mail message was a was
pathak mnemonic as they say in medical
school but was discriminatory for
someone who knew me very well all the
work we see on sentiment going on on the
web can I figure out what the sentiment
is in text so sometimes we find that
surprising outcome of defining some
audacious goals with data sets that are
tagged to give us the information we
need for for algorithms to go through
and find for example the one word fluid
in the medical record which physicians
wouldn't have figured out was a not the
best sign for staying out of the
hospital now generating is different
story and and but I'm very optimistic
but i but i did this claim that we're in
the early days of all this as I
appreciate your question oh okay thank
you hey
any other questions all right yeah oh I
see over here Jim hendler chair of the
computer science blue marlin at rpi come
over here oh there you a gym there's the
big number one up here yeah one hell
yeah um you know our cumin you meant in
some of Jamie's work you mentioned some
of the other work you're doing with very
large data sets and large pieces of
information that can't be shared outside
the walls of the building and I guess
really i thought since tony mentioned
this is one of the themes the whole
issue of collaboration said things is
there any new thinking or their new ways
we can be approaching how our students
are going to learn to do the kinds of
things you're saying at scale without
somehow finding a way to create either
modeled data sets or something that can
be worked on jointly between us so my
first reaction is for that ambient data
i mentioned earlier there's a lot of
there a lot there's a lot of large-scale
data out there now public public that's
public that can give students lots of
exercise in working these methods
through a lot of with the same data sets
a lot of undiscovered paths Twitter
feeds for example it's just full of such
richness it's very exciting to look at
even keyhole at a time onto that massive
data this the variety of initiatives
underway for example on healthcare the
Center for Medicare services is working
to set up a whole data office focused on
sharing with the academic community how
are they going to solve the the HIPAA
challenges in someone I up for research
right now maybe new legislation
microsoft research connections evelyn is
evelyn here worked on a program to share
out bing search logs when they were
appropriately cleaned and that you know
sort of managing that kind of bias not
be introduced in the analysis but
actually licensing that with the
licensing program to academics who
showed up a couple times with really
fabulous results and programs and
workshops about that data twice I do i
do here the pain in not being at a place
like microsoft with massive
coming in that we have access to we have
problems under way but also send us your
best interns yeah so it seems to me that
your research has always kind of had
this had sort of significant privacy
implications and I guess that I guess
how you manage that in the past is by
sort of balancing utility and and
privacy at the same time right maximize
as utility as much as you can can you
tell me about the principles used you've
used for achieving that balance well
most of the work we do has that that
would involve privacy incursions does
not impact the outside world that
prototypes typically and so on for those
that do we come up with with new
approaches over there Brian white and I
just published a paper on looking at
mobile phone data we could happen to
have GPS on it we actually in a very
early stage of our analysis removed all
GPS and just looked at absolute
distances between hospitals and that
phone so there there a number of variety
of mechanisms that can be used for that
kind of thing when you get some
remarkable results with data that would
not be identifiable identifying back to
the utility question I should say more
generally I believe there's a lot to be
learned and a lot of opportunity in
designing systems that figure out what's
the most useful information to optimally
provide a personalized service for
example to users that's that's the least
invasive preferences of the user and
andreas Kraus one of the fellowship
awardees today work with me when he was
an intern at Microsoft on a piece of
work that really lightens my heart with
possibilities for really addressing the
hard problems of privacy because it
showed while using some of the really
nice concepts that Carlos
tryn and andreas developed a sub
modularity that you can actually find
really non-invasive pieces of data and
inform people about them that were quite
ideally discriminatory you didn't need
everything so I love the idea of being
able to make that trade in our system
someday we have a jer piece on that
online it's going to read about that but
in general we think hard about about
privacy we also have a privacy officer
we're thinking of setting up an Ethics
Board of our own like an IRB of our own
for research purposes we the Microsoft
people here in the audience will
remember an email I sent last week it
was the result of several conversations
with our with our legal team with our
privacy folks and with researchers and
the office of directors at Redmond about
what would our policy be at Microsoft
Research Redmond about putting a sensing
and learning prototype into a lobby or
the elevator how should we handle that
to do what we call dogfooding for the
sake of research and we put we put in
place a certain set of procedures
including the ability to opt out with a
fluid anonymous email that's to an
anonymous site i hope i answered several
dimensions of your question which you
implied it in your question yeah I have
a question that follows on on that this
is it would hope he still at ISI and Los
Angeles so as you put together the
individual functionalities into
increasingly sophisticated services and
as you embed them into society rather
than just give them to scientists and
things when things go wrong it seems to
me more and more people are going to get
angry and not just that Microsoft but at
that particular thing if your personal
assistant tells me oh I have to wait for
15 minutes and I see you in the office
doing nothing i'm going to get pretty
pissed off so as when we see a real
person there we do something about a
certain agency and responsibility when
we see a piece of software there we use
computer scientist we don't care we just
say well the thing is screwing up right
but
increase in credit increasingly it seems
to me maybe Microsoft is going to have
to some a bit large corporations that
make many different software products
going to have to create some kind of
agency with responsive legal
responsibility for each product
separately saying my personal assistant
software has a certain legal persona
which is different from my car helping
software which is something that can at
least I can imagine that's the way the
world would go is there any discussion
of this kind in Microsoft so there's
always reflection about the implications
of new kinds of automation there's a
fabulous NPR piece last week about FDA
getting interested in regulating medical
apps on your devices because aren't they
making decisions that aren't they be
taken seriously and so on so there's
always been an interesting border
between and and there's there been
different perspectives and these evolved
with technology and society back into
privacy after just say this again I was
when we studied privacy quite deeply
here interesting to see benjamin cardozo
this beam court making comments about in
the late 19th century about flash
photography causing privacy incursions
or in the 1920s people discussions about
would we ever allow someone else to ring
a bell in my living room this newfangled
thing called the telephone and now it's
in our pocket oh my gosh so I think I
think things will change over time in
terms of what we expect and failures we
tolerate when it comes to my agent by my
door I think ed muttered which runs a
tight ship but not that tight people
just walk around or something they come
see me anyway so not not to worry about
that piece but yet I think people have
raged it in policy implications societal
implications psychological implications
of technologies at Microsoft at multiple
in multiple product teams and in in
research oh this is a lewis acid
University of Washington thank you for
right here number one all right okay
thank you for a great talk so
I'll just Chris you could tell us a
little bit about what do you think are
the technology or other challenges to
push this to the next level is it the
quality of the data is it di mano
compute power or is it the algorithms or
what do you think are the big technology
challenges push this further so why
would a great question and by max you're
talking about things like the assistant
you saw at the end what is that so I'm
learning a more general in general is ha
my sense is you know to be fair all
those things you mentioned I do think
that competition allow and memory and
connectivity and sensing will have had
unexpectedly great outcomes in terms of
the boost we get in things that we look
at as intelligent there's still a lot of
headroom for algorithmic work every once
in a while we get surprised some
modularity I think was a surprise if I'm
looking at my andreas crossed right now
we used to do things we thought they
were your Ristic sand we found out later
that maybe they're they're well founded
with nine houses result for example
other work in that's happening right now
in the deep belief networks deep
learning cascades of variables where one
layer is doing inference becoming the
input to the next layer there's some
interesting magic to be decoded there
and some of it may be related to and
have influence on decoding us what's
going on in our own sweet book or texts
in the rest of our brains which excite
people as well those those results I
think are still not fundamentally
mysterious and nobody has a really great
understanding of what's really going on
in terms of why we sing better results
than with prior methods that leap I
showed you with Bing mobile search for
example is quite surprising to me
personally so I think all them
algorithmic Headroom but really
celebration of the power of the
computation the networking and the
memory last question so this is semester
from industry Wisconsin so I want to do
you visit the privacy aspect and I'm
glad I put it a slide on that so one
thing that I find generally in the
research side is that people don't
understand the implications of sharing
data for example if I'm a scientist and
I want to share data to collaborate oh
do you think do you have some thoughts
on how do you make somebody who's not a
machine learning expert or computer
science expert saying okay if you share
data setting these are going to be your
privacy risks or implications what do
you think some of the techniques could
be helped there yeah this is one of the
reasons why Cynthia to work who works in
differential privacy in fact McSherry
like that methodology because even with
repeated queries to a database they can
say things about the the extent of the
risk your photo mat you're bringing up I
honestly a fundamental fundamental hard
challenge which is communication even
the entailment what it does mean when
you for example share information over
time in particular in multiple episodes
different forms the even entailing what
that means and then just grabbing it to
somebody with caveats to me that's like
I'd like to end this meeting by saying
that's a really hard challenge you just
brought up I have some faith in our HCI
folks and in controls and combinations
of the method that i mentioned to
address those issues but the the way you
just frame the challenge I think is is
opposes some of the some of the hardest
problems for privacy I'll stop there
thanks
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>