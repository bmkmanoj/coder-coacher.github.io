<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>An overview of Multipath TCP and its applications | Coder Coacher - Coaching Coders</title><meta content="An overview of Multipath TCP and its applications - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>An overview of Multipath TCP and its applications</b></h2><h5 class="post__date">2016-07-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/k-5pGlbiB3U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
it's my pleasure to welcome
Costin Costin works tenuously bucharest
and gives me a number of things most
important of which is multiple TCP this
work is won a number of awards it's
cutting the party heavily in Europe
hopefully will arrive here soon thanks
hey
so yeah this is started you see lol my
PhD and it's joint work with a bunch of
people have bolded the ones that are
most important to this work and but
there's many many others that
contributed so alright the context is
that the networks are really becoming
multi path these days we've got mobile
devices that have multiple wireless
interfaces each of them with different
coverage properties different energy
consumption different throughput data
centers you know I'm sure I'm showing
the recent and now you know they've
they've got many servers within any
given rack you've got servers connected
to the top of the racks which then you
have many racks and then or redundant
topology connecting these racks together
and then between any two servers you
have many paths that you can use to
communicate
finally online providers such as
Microsoft Google whatever they multi
home in the internet to get better
redundancy better performance and so
forth so and then the client could
connect to by using any of these network
connections so the littles are
multiplied but we still use TCP today
and I mean 90% of the applications use
TCP so this is basically almost like a
monopoly and the reason people use TCP
is because it offers this very nice byte
stream abstraction you know reliable
delivery and all it also matches the
offered load with capacity in a network
and that's quite nice
the trouble with TCP that it's
fundamentally single path right it was
designed to bind the connection to two
source two to two IP addresses if any of
those addresses changes then the
connection goes down even in the network
you cannot really take a multi path TCP
connection and place it on multiple
paths because the ends get really
confused and the performance drops
significantly so there's a fundamental
mismatch between the multi path networks
and the single path transport and this
creates problems and let me just show
you two instance problems that is great
so here's me commuting from sorry that's
not a microformats commuting from home
to work listening to my internet radio
and I'm using my 3G connection and then
as I get to work there's Wi-Fi so I
would like my my phone to switch it to
using Wi-Fi because well it's cheaper
economical it's cheaper from an energy
point of view and so forth now the
trouble is today when I do this switch
all of my connections will die and
that's not nice
another problem is in data center so I'm
showing here a factory data center where
the servers are at the bottom each rack
has only two servers this is just for
just two purposes and then in this
connection if the red servers want to
communicate they can choose any of the
four paths they have available and they
say let's say they choose this path of
the third topmost which they could have
chosen any of the other paths and
normally the way this is done is by
using a protocol called
equal cost multi path that will
literally place a flow randomly on one
of the available facts now let's say
that the black servers want to
communicate to they were also choose a
random path and there's the probability
that these two paths will collide and
then if you have a collision the the
effect is pretty bad each of the
connections will get half of the
throughput they should be getting and as
idle capacity as well in the network and
this happens in a network that was
provisioned to to behave like a full non
blocking switch right so the theory is
that each of these connections should be
getting one gigabit and in this example
they're not and you might be wondering
well yeah but this is a contrived
example does this really matter so we
set up with a very simple experiment and
the experiment is this every server
chooses a single other server at random
to send to and each server will have one
outgoing connection or single incoming
connections so and we call this a
permutation so we do the simulation and
here are the results on the x-axis I'm
showing the flow IDs ranked by
throughput and don't want the y axis I
have the throughput so the theory says
we should be getting one gigabit for all
of these flows the practice is rather
different okay so the averages flows get
something like 400 megabits there are
some flows that are lucky and they get
close to one gigabit but there are some
flows
are really unlucky and they get 100
megabits and this is because of the
collisions alright so as you might have
guessed from the title of this talk the
solution to all of these problems is
multipath TCP and what it is is really
just an evolution of TCP that allows us
to use multiple paths within a single
transport connection before I go on and
tell you what we did and how much
participe looks like and so forth let me
just briefly discuss some related work
so I've showed you a few point problems
the first impulse we have when you see
pouring problems is to come up with
point solutions and for instance we can
we can solve mobility differently right
you can go about it at a different layer
forest by using mobile IP that was
standardized a while ago but it didn't
get any traction and you could solve it
at an application layer for instance by
using HTTP range and change your
applications to deal with mobility the
problem with changing application is
that it's it's a lot of effort if every
application needs to have built-in
mobility then that's a lot of complexity
of putting in the application so the
best place to change this and a
transport you don't have the context of
the IP level you don't have the context
of the transport so it turns out that
the best level to do this that is a
transport layer so and there's been two
proposals to this end so snorer at all
proposed migrated TCP which is basically
what it says it can just move a
connection from one IP to the other and
also HTTP has this has this capability
to now all of these come with this with
this mindset that mobility should be
about fast handover when I have a new
interface I should quickly hand over to
that interface and then I'm good right
what you'll see later is that we think a
better solution is to do something like
a slow handover when you have multiple
interfaces you should use them all the
time because the the their performance
is my fluctuate quite dramatically and
then if you do a fast handover you might
suffer okay now you can solve data
center collisions differently for
instance by having a centralized
controller that knows all of your
switches and that knows all of your
flows if you know all of
flows then you can compute a placement
of flows to pass that doesn't have
collisions and then you can implement it
and this is what hadera proposes but the
problem with this is that it doesn't
really scale that well you need a really
tight control loop to do this in real
time and to get benefits and finally
okay multipath tcp is not a new idea it
has been proposed at least half a dozen
times all right so I think the first one
to propose it was Christian who Tamar in
1995 a DAT F I think it was Microsoft
and there's been as I said half a dozen
proposals ever since so what's different
in this work from the previous works two
things really
first the context you know in the past
four or five years we've really seen
multipath networks you know smart phones
took off and data centers took off the
second is is our goal so we set out from
the beginning to have a deployable
multipath TCP so what we really want is
to take existing applications run run
them over this new well this is this new
protocol but the application should not
be changed at all they shouldn't even be
recompiled right they should speak the
same circuit interface to the stack and
the stack should do somehow multiply
underneath okay now that's all fine we
also wanted to work over today's
networks if you require network changes
that's a showstopper right nobody's
gonna change the route of just because
you have a new protocol so we really
want to be able to run through today's
networks and finally if there's a path
where TCP would work we want this new
protocol to work also because if it
didn't then users would complain you
know the Internet has gone down what's
happening here right so these are very
sensible goals but it turns out it's not
yeah deploy its new DCP without having
to change both sides
sigh yeah that's that's also feasible
actually when when we started out this
effort it was within a new project
that's called trilogy and one of the
partners started it exactly with this
with this idea that you want to change a
single end it turns out that it's then
you're quite limited in what you can do
if you change a single end and that
thing died for some reason I mean we can
take it it's a hard problem
I mean it's you're really very limited
in what you can do okay so you know fast
forward we have a Linux TCP
implementation that implements the
current protocol draft the protocol
draft is in the final phase of
standardization at the ITF so it should
be an RFC soon so this thing is already
happening it does support legacy apps it
works over today's networks and we've
tested it right so but you know I'm
getting a bit ahead of myself
so here's multipath tcp there's a lot of
components to it I don't have to talk
about the more so I'll just leave out
these two part flow control and encoding
control information if you want we can
talk about it afterwards okay so when we
started off this work I and I don't
think mankind leader realized how
difficult it can be so he came in 2007
and said I think we should do multipath
tcp it's like a good idea and you know
and the reason he started that work is
because in theory there were a few
results teaching us how to do congestion
control and it was like the big sort of
breakthrough but to be able to do the
congestion control you needed a vehicle
to carry the the byte so that's the
protocol really so he said why don't you
think about the protocol then on the
beginning I thought well this would be
just one month I'll get it done and then
I'll move on to the interesting stuff
like the congestion control well it
turns out it took five years and the
reason it took five years is not because
I was stupid but it's because we're
designing in an Internet architecture
that nobody really understands so here's
the here's what we teach our students
you know you have this very nice
protocol layering you've got link layer
addresses that are visible only to one
link and then on top of it IP works
end-to-end route
four packets based on the destination
dresses and on top of that TCP does
reliable the transmission and you know
in short in order delivering and finally
the applications use this interface
that's really nice accepted it's mostly
fiction okay the reason it is fiction is
because of middle boxes and I'll use
this pirate skull to denote middle boxes
so how how big is the problem anyway so
we did a study that we presented 9mc
last year to understand exactly what
what's the scope of the problem so
here's the IP header at the top and TCP
header at the bottom and the theory says
that as the packets get routed to the
Internet to fields to change the TTL and
the header checksum and that's it okay
now we know that there are network
address translators right so those
change the source IP in the source port
for Advantech outgoing packets and the
destination IP and the destination port
for incoming packets so we know that
these get changed okay now there are
firewalls that randomize the initial
sequence number because some of the
stacks are weak and they choose a
predictable initial sequence number so
what this means is that on the outgoing
packet the sequence numbers get changed
on the incoming packet the acts get
changed right so these two fields also
get changed in the Internet now it turns
out that for any particular field you
find in here there will be the middle
box out there deployed the changes it
right so the real picture looks
something like this and you'll be glad
to see there's some white space in there
I only left it because it contrasts nice
you know it's not true those things get
changed though so so in this context
when you're designing a new protocol you
have to be really defensive because
otherwise it can really bite you back
everyone I mean middle boxes will set it
to zero even Linux will set it to zero
when it comes in right so you don't you
really don't want to put any origin data
it's you to get it to get pushed in band
someone thought they'd say hey security
has at some point and just decided that
you know urgent point okay so let's
start with what the protocol looks like
so a multi-party
the connection starts like a regular TCP
connection with a syn packet except it
carries a new option that's called MP
capable and this option also carries a
unique connection identifier designated
by the one that's sending the the syn
now the logic cut the passive open these
are the server in this case is if the
scene has multipath capable and I'm
doing multipath then I'll just enable
multi passes to be for this connection
so what it does is it gets the thin
replies with the scenic with an inked MP
capable and its own local unique
identifier for this connection and it
says okay now we're enabled we're good
the client the active open or the client
has the same logic you know even the
cynic has multi path capable then I will
enable multi path TCP and then I send
the third back and this what I've shown
here is your regular way of negotiating
a new TCP option right all the TCP
options we know this is how they're
negotiated all right and after you've
done this then what you have is a soft
flow setup within a multipath TCP
connection so both ends will basically
know that this sub flow is part of a
connection and they would have a local
identifier that's unique for that
connection now at any point in time both
ends can add new sub floors to this
connection right the sub floor can come
from the same ip address or different IP
addresses it doesn't matter the only
requirement is that the v tuples of the
different sub flows differ so at least
the port numbers should differ across
different sub floor okay so now if I
want to add another sub flow I send the
guiness in like a regular TCP except the
option in the scene is different it's
called join and this tells the server
that this is an existing multi pass
connection we're adding a sub flow to
and it's not a new connection and the
journey will contain the unique
identifier of the server for this
connection and this allows the server to
be multiplexed this request and place it
at the recognition now these unique
identifiers are actually used for
security purposes but I will not cover
these this in this talk okay so the
cynic comes back with the join the third
rack and finally we have a new subfloor
and this can go on as many times as you
want you can Finn's up flows if you need
the sub floors can die and they just
time
it's not a big deal the connection keeps
going on as longer than a single
subfloor that's not timed out yet okay
when the last when the last subfloor has
time not finally the connection dies or
when you do an explicit teardown all
right now that was pretty easy right but
it was too easy
the reality is a bit different so still
in this case where the scene has come in
and now we're sending back the cynic
with the multipath capable and the
server thinks we have enabled multipath
for this connection our study in IMC
shows that hold on okay now we can have
we can have a nice middle box in there
so I'll study and IMC shows that 6% of
exit networks will actually remove
options they don't know and if you look
at port 80 14 percent of these networks
who remove unknown options so if it
happens that on the way forward the
option got through but on the wait path
or on the way back the pass was
asymmetric and it didn't get through
then what you get is the scenic coming
without the option and now the client
thinks multipath is disabled for this
connection and the several things is
enabled and what happens after this is
really complicated I won't go through
this but it's just not good okay so so
you want to fix this and the fix is
pretty obvious you know what you want is
in the third back if you enable multi
pass this if you want to carry some
multipath specific coefficient telling
the server that yes I did get multipath
TCP enabled so the logic changes of the
server says if the scene has multiple
capable and the third rack has this
multiple specific option then you do
enable multiple TCP in this particular
case the ACK will not contain the multi
path ops option so the two endpoints are
in agreement we're not doing multi
participe okay so this really shows what
you need to do if you want your
connection not to break in today's
internet right to achieve go 3 which was
if
TCP work slow connection multi pass TCP
should work you really need to fall back
to TCP
if something goes wrong right in this
particular case with we fall back to DCP
in the negotiation itself but multi pass
this if we can fall back to TCP during
any time
during the lifetime of the connections
so if at some point the multipath
options don't get through anymore
because say the path changed then
multipath CCP actually does flow back to
TCP and from that point on it doesn't go
back to multipath it just stays TCP but
it doesn't break the connection okay all
right so the lesson is it used to be
that we negotiated a new new protocol
options between two endpoints nowadays
you're negotiating between two endpoints
and an unknown number of intermediaries
and unless you take this into account
new new negotiation will actually fail
and this applies not only to multipath
but any extension to TCP one you might
want to do okay so now we have multiple
soft flows how do you actually send data
on these sub flows right and let's let's
start with a primer of TCP I mean you
all know this but it's just to contrast
with what you do with multipath so TCP
gives sequence numbers to every byte and
Jen and then place the segment of the
wire so in this in this example I'm
showing actually packet sequence numbers
for simplicity but you know there's no
difference in concept so okay the
sequence numbers help the receiver first
of all pass data in order to the
application right and also detect if
there are holes and so forth so this
allows the receiver to implement the TCP
contract which is reliable byte stream
delivery as the packets are coming in
the receiver is generating X and the X
tell the sender yes the packet got there
and if it didn't then you can retransmit
and so forth right I mean we all know
this okay so the easiest way we can
think of implementing multiple TCP is
just taking all of these segments that
TCP creates and placing them on
different paths that's like the strawman
design right that's what everybody
thinks of when you just you think about
multiple you know we put a segment one
on the top path we put segment oh yeah
middle boxes we put segment to Adam
bottom path and so forth okay now what
you will see is that this path only sees
segment two and four and this path only
sees segment one and three okay so they
see something that looks like a TCP
connection with holes in it right now
the the forward segment will
get there fine it's not a big deal it's
when DX come back that thing starts to
get messy
okay so f1 will be generated and then
act 2 will be generated right the
problem is this path has not seen
segment two
all right segments have not seen segment
one okay this path has not seen segment
one because it saw two and four right so
now we can see Act to which cumulative
legs both one and two and it will be
upset all right it turns out that a
third of the X status we try we we
measured in our IMC paper will actually
correct these X draw or drop them or
reset the connection so one of these
three actions will happen right so in
this particular case let's see it
correct the AK right so what will happen
is that it will it will correct it to X
zero because that's the cumulative
Achatz
it has seen and on the top path it x3
will be corrected to AK one okay
so although all the segments got to the
receiver the sender is not aware of this
because the Pats are correcting the X
right and this clearly does not work
because we're stuck now because we don't
know how to make progress okay so what
does work we really need a sequence
space for each sub slow to make a
subfloor look like a TCP connection over
the wire with no gaps okay and if you
have this the sequence number then we
can use this to to do the transmissions
and protect losses right but we still
have the problem that different paths
will have different delays and you get
reordering right so to deal with
reordering it in a separate sequence
space that's at the connection level
right and this will be used by the
receiver to put packets back in order we
also need a date acknowledgment for this
sequence base at the connection level
and so forth
alright so this is how the multipath TCP
packet header looks like so the port and
the sequence numbers they relate to the
soft flow of the multipath TCP
connection and this makes the the
subfloor look like a regular TCP
connection on the wire except there are
some options that belong to multipath
tcp that current middle box is done
and these options allow the receiver to
to reorder data and the connection
multipath TCP has a single receive
window per connection and this is coded
relative to this ACK that's carried as
an option here
I will not go deeper into flow control
as I said okay so here's how it works
now I again want to send segment one but
this will be the data sequence number
one right and when I map it on the red
path it will it will receive a sub flow
sequence number in this case 100 okay
now I send the second segment here it
will be it will receive a SAP flow
sequence number on the blue path and
finally I send the third segment there
as you see the sub Pro sequence numbers
are increasing continuously but the data
sequence numbers can be it doesn't
matter they can have hold okay now what
will happen if this dispatch fails and
this this packet never gets there well
what will happen is that on this stuff
flow will get a timeout and when there
is a time what we reject all the
segments that are outstanding on this
path on the other paths that are working
okay so what will happen is here as you
see we have a the same data sequence
number but it's mapped on the red SAP
flow and in this way Multi plasticity
can make Khmer progress
well the acts are so you have acts that
I mean the ACK the regular acts just act
the saw flow sequence number and then
you have a cumulative ACK for the data
that's all that yes yes yes okay so we
started out with what looked like an
incredibly open design space for the
protocol it turns out that in practice
because of a lot of constraints that
designs the decisions we took there was
not much much room for manoeuvre so it
turns out that a lot of the decisions
were more or less deterministic right
anyone could start from the same goals
in the same Internet you end up with
like the one possible solution there was
not much room for manoeuvre
yeah and put your extra stuff instead of
options just anticipated absolutely so
so I I did not cover that part about
encoding so it tells in the ITF we had
like a six month old a six month long
discussion about we're doing code
control information you can put them in
options or in data okay it turns out so
this is like a chain of logical
implications so first of all you need
the day pack if you don't have a date I
cannot do flow control properly then if
you put the data AK in the payload I was
just chatting the JIT earlier you get
deadlocks you can get deadlocks because
the payload is subject to flow control
okay and congestion control but flow
control is the is the is the problem so
what will happen is now if I should
probably not do this but I can show you
some slides that actually show the
deadlock okay okay so you can get a
deadlock basically that's okay
now this is this is it for the protocol
itself right
unlike switch to congestion control okay
and I'll start off with a very sort of
high-level slide now this is back in the
60s we used to have circuit switched
networks and what this means is whenever
you have a connection you have to set up
a circuit to the network and I'm showing
here a single link and two flows you
know the blue flow and red flow now the
problem with these pictures as you
probably are well aware is that this
flow is bursting here it could use all
the capacity but it's not allowed
by the very static reservation of
capacity on this link and the same here
so the result with circuit switched
Network is that you get great isolation
but very poor utilization right now
fast-forward 10 years in the 70s you
know packet switched networks you can do
this thing very nice so what what
they're really doing with what we're
doing with packet switching is really
pulling these circuits together to get
to get greater utilization now
fast-forward 40 years more today this is
what we have today so we have two
separate links in the network with flows
and this is look
strikingly similar to the circuit image
before right so the next step is
obviously this one where you can take
multiple separate links and pull them
together such that each flow can burst
and use underutilized capacity elsewhere
in the network okay and this is really
what multipath tries to do right the
problem is when you go from here to here
you've you've just lost isolation so you
need somehow to manage the sharing of
capacity and that's that's what what TCP
does TCP congestion control really
decides who gets what the question is in
the multipath context how do you split
the con how do you split the capacity
across the flows you know what is the
equivalent of TCP in the multipath
context and this is this is multipath
congestion control now as I said as we
started this work this was like the very
interesting research question that sort
of drove the whole project and it turns
out that the answer to this question
came when we defined the goal we wanted
to achieve once we had the goals that
with hindsight looked very very sort of
obvious it was not very difficult to
design a congestion control that achieve
those goals so here are the goals the
first goal is the most obvious goal if
you have a single multipath TCP
connection with many sub flows sharing
the bottleneck link with TCP then you
don't want multiple TCP to beat up TCP
you want it to get the same capacity as
TCP right and that's like I mean if you
tell people I will give you multiple TCP
it will just kill TCP throughput they'll
say okay we're not deploying this this
is obvious I mean don't go to the ATF
telling them that we're gonna beat up
TCP cuz they're not like you maybe if
you go to a specific company and say
your products will be beating up other
products then that's a different way of
thinking okay so the second goal is is
more subtle that's like
goal is we should use Pat's we had the
Pats we have efficiently and here's what
I mean so in this particular case I have
three links each with the same capacity
of 12 megabits and a single multipath
flow that has two sub flows one of them
has a single hop path and the other one
has two hapa in this particular case
it's obvious that this flow should get
24 megabits it should use both paths and
should get 24 megabits now to make this
more interesting I'll add another flow
here again with a one hop path and a
tuhoe path and finally I let another
flow here for for symmetry okay so you
have all of these flows that have a one
hop path and a two hop path and the
network is pretty pretty utilized okay
so the question is let's say these guys
here same thing they have a choice on
how much traffic to put on each path and
they can decide I can put X on this and
X on this or 2x on this and less on this
and so forth so how should they split
the traffic it turns out that the way
they split the traffic really affect the
total throughput of the network okay so
if they split it equally each of them
put equal weight on both paths you get 8
megabits and this is completely
counterintuitive why are they getting 8
megabits they should be getting 12
megabits no because that's the total
capacity is 36 megabit in the network if
you divide by affinity to be 12 well the
reason they're getting eight megabits is
because they're putting a lot of traffic
on these two hot pads that are less
efficient and basically use two
resources instead of one on the one who
path you is one resource on the top at
used to resources now if you put more
weight on the shorter paths for instance
two to one you get nine megabit four to
one you get 10 megabits infinite to one
you get 12 megabits okay so in this
particular case the optimal allocation
of bandwidth is you should push all of
your traffic's to the direct path and no
traffic to the other path okay now okay
does this really mean anything
well first of all the theory says there
is a way to get this to get to this
outcome just by doing congestion control
here right so the theory says this each
sender should look at the
Injection you get on each of these paths
and she's put triage it push traffic
away from the more congested paths
that's what theory says and I mean there
are there are proofs that this can be
done in a stable way it will not
oscillate so in this particular case
what we see that let's let's look at
this guy this guy will have a roster 8jp
on this path okay but on this path it
will see a loss rate of P plus P right
it will see a much higher loss rate and
that's why it's pushing all of the
traffic away from the higher loss rate
path right and the same goes for this
one
in the example I showed before where the
flow was alone there will be no higher
loss rate on the two hop path so in that
case you get the benefit okay so
basically the theory says you should do
congestion control you should put
traffic away from the congested pads and
that's that's all very nice the problem
with that is well here's the real
network you know we have a 3G path with
very low loss in higher TT again it gets
lost every every five minutes right and
it has an RTT of five seconds depending
on what carrier you use and here's the
Wi-Fi path it gets a lost every every 50
meter every every second or even even
earlier but this actually gives me ten
megabits compared to one megabit all
right so if I just take the goal I said
before always prefer your lower lower
loss networks that means when you have
3G and Wi-Fi always use 3G put no
traffic on Wi-Fi that's clearly a bad
way to do it because people will say
well yeah but what if I was giving me
ten megabits and you're giving me one
megabit and you're saying it's much
better for the network you know I don't
buy that so you really need a
counterbalance for the design principle
which basically says in any given
configuration if multipath TCP is giving
you less throughput than the best path
then the TCP on the best path then
you're doing something wrong so really
the goal here would be look in this case
you get you should get at least 10
megabits per second okay how you get the
throughput maybe you push more here I
don't care but I should get at least 10
megabits because otherwise nobody will
deploy this thing all right
so how do we achieve all of this well
this is TCP congestion control and we
all know there
so I'm just showing it to contrast it to
what multiplies TCP does okay so TCP
maintains the congestion window for each
connection and then let it get as it is
getting acts back for each check it gets
it increased the window eight degrees
the window by one oval w basically this
means in one RTT it increases the
congestion window by one packet okay and
then if it gets a drop then it just
holds the window and this is pretty
simple I mean everyone everyone knows
this now multipath TCP does this you
have a congestion you have a congestion
window for each path all right when you
get a loss on past are you just have the
congestion window of that particular
path all right so it's exactly the same
as TCP here the difference is the
increased part this is where all the
smart a multiple TCP are okay so what I
have here is the sum of Windows across
all of the pads and you can look at this
as a constant for now right so let's say
I have two paths I have a pass with
window one and another path of window
100 this will be 101 here all right now
the path with window one will increase
on every RTT by this much the past with
window 100 will increase by a hundred
times this much it will increase much
more okay so what this does is really
push the increase towards towards the
path that has the better loss rate the
higher congestion window alright so it
actually linearly does this if you have
two two flows that are have the same
condition window they will increase with
the same amount all right now if you if
you say this is 1 and if you consider
that the RT T's are the same for all the
flows you realize that on aggregate
multipath tcp increases with one packet
per R DT across all of its sub flows
right and this gives you the furnace to
TCP if if all of my stuff rows are going
through the same bottleneck then I will
be fair to TCP so ok to get go to that
is most traffic away from congestion
this is this is this what I'm doing this
is this helps me get go to to get goals
1 &amp;amp; 3 what we're doing is we're
dynamically adjusting this value of
alpha
to do the following things so multipath
TCP has lost rate and RTT estimates for
each of its paths once I have that I can
just plug them into an equation and say
what would TCP get on this path and I
get some throughput and then what I
basically do is I change this alpha such
that in aggregate multipath TCP gets the
same throughput that's the idea okay so
I mean this is the mechanism it's much
easier to see what the emergent behavior
is okay and this is the real formula but
I'm not going to discuss it all right so
let's see we have a web server with 200
megabit links and it happens that two
clients are using the top link and four
clients are using the bottom link right
so clearly that the bottom link is much
more congested now multipath TCP comes
uses using the using both links now
because this link is much more congested
it will push all of its traffic to the
top link right and pushing very little
traffic through here mostly to just
probe the capacity of this link alright
so and the the flow through puts our 33
megabit for the flows using the top link
and multi-pattern and 25 for the bottom
flows now if I add another multipath ACP
connection again I push it all over
traffic to the top link and I leave no
traffic on the bottom link and in this
case you see that all of the flows in
the setup phase you have exactly the
same throughput okay if I add one more
connection I start pushing in the bottom
path too right if I only push in the
ball in the top in the top path then I
would have more condition there so
basically I have to balance our
congestion so what what is really
happening is that multipath TCP is
trying to equalize congestion between
these two links okay and the net effect
is that these two links become start
behaving like a single higher capacity
link and the their capacity is shared
between all the flows okay so if I keep
adding flows then that's what happens so
this is the theory this is this is what
the theory says this is the practice
okay so this is a practical experiment
so I start with with I think five flows
and on the top link and 50
flaws on the bottom link and this is the
average throughput for TCP for a TCP
flows and then I start ten multipath TCP
flows which are shown in in this color
in orange so what you see is that
multipath TCP does something close to to
the theory not it's not exactly perfect
but so what is doing is it's mostly
pushing traffic to the top link as you
see the decrease of the of the top TCPS
the bottom TCP will also decrease a
little bit because of the probing it
does and also mod so multipath roughly
matches the rate of of the flow so the
the practice is not exactly the same as
the theory but it's pretty close okay so
the takeaway is that multipath TCP can
make a collection of links behave like a
single pool resource it says if you take
those links you put them together and
they just a higher capacity link that
everyone can draw traffic from and this
gives you better fairness and better
utilization the network that's that's
the intuition okay
the other application of multi pass TCP
is is mobile devices as I mentioned in
the beginning so again I have the same
scenario here now at this point with
multipath TCP there is absolutely no
problem to open a new stuff flow using
the Wi-Fi connection and just offload
the connection from 3G to Wi-Fi right so
I can do this make before break scenario
without any problems right now what we
the problem is of course in this case if
I move away immediately from the Wi-Fi
coverage then I lost my connection right
so I have to reconnect this region so a
better way to do this is to actually
open both connections at the same time
and do something that we call slow
handover right yeah it's a quickly
switching you know use all of your
connections and that's gonna give you
the best throughput in best performance
now you will rightfully argue that well
if you do that today your your phone
battery will die not in in one day but
in like half a day okay so that's that's
pretty that's pretty bad you know
completely acknowledge that argument but
from a performance and robustness point
of view this is the best thing you want
to do now if in the future the batteries
get better then you can do this if not
you can do this for limited amount of
time while the metals are flaky and so
forth so whether you you can do this in
practice is zero
but from from the networking point of
view this is the better solution
okay so here's an experiment with this
so this is our code running we have
we're using Wi-Fi and 3G REO 3G or a
real Wi-Fi and then we're comparing two
things we're comparing a modified W gate
application that monitors the interface
state status and if it notices that the
inter one of the interfaces is down the
interfaces those using is down then it
reopens a connection using the other
working interface and it resumes the
download with HTTP mediated HTTP range
header okay and what you see here is
basically the connection goes down it
takes some time to detect it and then
lets you start a new connection over 3G
it takes time for 3G to ramp up normally
it takes like two or three seconds to
rev up yeah okay so basically with
multiple TCP there's there's really no
disruption I mean the takeaway here is
not necessarily that the application
handover sucks I mean it's just two
seconds two seconds you can you can cope
with this the problem is that all
applications need to be able to do this
mobility inside the application which is
very tricky okay so I mean as an extreme
case what we did is we actually took
Skype and forced it to go over multiple
TCP by closing all the ports available
so we have an HTTP proxy that runs
multiple TCP on the client for our multi
pass TCP we started the regular sky
plant and we killed you know all the UDP
ports all the TCP traffic so Skype in
the end it's it's so good at detecting
you know an exit so the from the machine
that it actually goes over HTTP
so while Skype was going over HTTP we
actually killed Wi-Fi 3G and did
handover we Skype like playing playing
some encyclopedia some audio stuff so
it's funny to see what happens I mean
I'm not showing it here but basically
get a small period of silence of 1 or 2
seconds and then you see the audio
stream being played at the higher rate
because that gets all the packets ok so
I mean that's an extreme example you
really don't want to do VoIP over TCP
but
the handover multipath is if you provide
that work for unmodified applications
that's definitely the applications they
all want to jump on the CPU reconnect
and so you can have a sudden flood of
activity on the device where they're all
fighting for CPU and fighting for
network okay so the last thing I will
okay I'm a bit over so the last thing I
will discuss is how multipath HP can be
used in datacenters so I've mentioned
this thing that you take collection of
links and make the molecular single like
a single resource and this is the
intuition of why multipath TCP should
work in a dissenter so currently today
you have this a TCP connection it
randomly picks a path and it sticks to
that path with multi-party CPU do
exactly the same thing but instead of
having a single subfloor Pro can
actually have many subplots and for each
of those sub flows they get placed
randomly by equal cost multi path on
different paths and the software as I
said we have different 5-tuple so they
don't have different ports and that's
why they look like these TCP connections
right and if it happens to have Kali if
you happen to have collisions on any of
your sub flows then basically can just
move traffic away from the congested
link on T a known to the uncongested
links okay so visually this looks like
this so this is the case that I was
showing before where I was having a
collision like we're showing a collision
so let's say that this black flow is
multipath it will start another sub flow
that will most likely happen to hit of
an idle path now the congestion
controller will detect this and push
traffic away from the congested path
okay to the uncongested path it will get
one gigabit on this path and the fact is
that this red stuff flow is happy again
because it's getting one gigabit right
despite this collision so you know and
just to show you the example I showed
earlier this was the TCP throughput you
are getting in blue we have the
multipath TCP throughput
now clearly this is not perfect it's not
exactly 100% like you're getting in in
theory but it gets pretty close like the
average is close to 90 percent
utilization and even in the worst case
you get 600 megabit
so okay this was all simulation so what
we did is we actually went on Amazon you
see twins and to see if we can get some
of these benefits in practice so you
know infrastructure is a
service-oriented some virtual machines
and it turns out that Amazon the ec2 has
multi path topology so when we started
out in 2010 we were testing this I think
only one of their availability zones had
multipath retesting a few a few months
ago all of their available availability
zones have multipath so I think they
actually upgraded the networks or on the
other availability zones to have
multiple networks okay so we took 40
million instances running multipath TCP
or Carnot and the experiment what we did
it was very simple so we just I birthed
from every machine to every other
machine periodically in sequence by
doing either TCP multipath with two
flows to some flow sort of force uploads
and here are the numbers again I'm
showing the the flow ranks here and the
throughput on the y-axis so this is TCP
and multiple two or four samples I mean
you clearly see that you get a big
benefit in this case and these flows are
mostly in the same rack so of course the
ec2 network is a black box to us we have
no idea exactly why this benefit appear
right they could be because there is
indeed a factory network in there or
some multiplier or a multipath network
that and a lot of cross traffic and
collisions really help you or they could
be because they're doing perfil shaping
so we don't we don't really know okay so
that this is just qualifying these
results okay yeah
so you don't so you don't do anything
different in the stack you just open
many sub flows each of them will have a
different 5 tuple and then the you hope
that they'll get play plays on different
paths that basically yeah if you have
multiple interfaces then it's different
story but if you want to use sort of
network based multi path then you just
use five different five tuples I mean we
haven't really worked on too much so in
a datacenter the way we visit you do
this is you have a siscon troll that
tells the stack you know you should open
this many sub flows
maybe you know this much time after the
connection starts you know if the
connection is long is last more than
let's say 50 milliseconds or something
it's not just a quick transfer then it
makes sense to open it ok but I'm just
throwing 50 milliseconds as a number out
there I don't know if it's a good number
of do you need 100 or 200 yeah if
everybody gets synchronized at the same
okay I see congestion and stop sending
there and it all move at the same time
to the uncongested so this was like the
the biggest problem with low dependent
routing and that's why nobody does let's
say traffic engineering in real time
trying to balance congestion because
it's like a Holy Grail the theory of
multipath congestion control is shown
that this is stable so there are proofs
in theory showing it is stable and our
controller sort of basis is based on
that theory so I mean we haven't seen
any oscillations in practice the problem
is the controls we saw that the controls
in theory are shown stable but they have
a different different behavior I mean
they're basically exponential
controllers they're like scalable TCP
they'll increase
multiplicatively every time the problem
with TCP is that if it has small windows
it increases very aggressively so if you
increase from 1 to 2 that's a very
aggressive increase if you have like the
thousands of earth a thousand flows
because you double the load more or less
right but
stops you from oscillating in that
particular case is the time all right so
you'll be timing out a lot of the time
and you know statistically it evens out
so the answer is the theory says it
should be stable in practice we've seen
it's stable it could only be messy in
the like the cases where you have very
very small windows but in that case as I
said that you know the probabilistic
nature of time odds that does help you a
little bit so we think it's pretty
pretty safe it shouldn't be a big deal
if you do it in another because you
don't have the you don't have the you
don't how long the loop is basically of
the flow so if you do a change how long
should you wait until you change again
right here you're doing a change on the
natural path natural control loop of the
of the path which is basically the
round-trip time right so that's why it
intuitively should be easier to get
stability if you're doing endpoint
congestion control rather than in the
network okay so designing this you know
any multipath TCP isn't difficult I mean
it's pretty easy to do so to do
something that works but designing a
deployable one is much much more
difficult and actually it took the
biggest parts of this work just because
the internet architecture is evolving
all the time right and what this means
is that you need to put defensive
mechanisms to to detect when things go
wrong and you need to fall back to TCP
so let me give you another example of a
defensive mechanism there are middle
boxes out there that will modify your
payload your TCP payload for instance an
FTP meter box will rewrite in the
control channel will rewrite the IP
address if if it's a net if it's a net
doing FTP it will rewrite the IP address
written by the by the source to be that
the IP address of the net right and the
a period rest is written in ascii that
means the length changes so you can lose
or add a few bytes you don't know so now
that could really mess up a multipath
TCP connection because I've sent a few
segments here but all of them got shrunk
or got got bigger so then when I put
them in order
I'll send garbage to the application I
don't know how to put that in order so
what do you do in this case so what we
did is basically well you really have to
check some the data right
so basically the data comes with the
checks on that scared as an option and
when multipath TCP detects or checks on
failure basically you have two options
if that if you have other working sub
flows then you just reset that sub flow
that has a checks on failure and never
use it again if that's your only sub
flow then you have a we have a handshake
that allows you to fall back to TCP but
you never come back to multipath again
so basically as from now on we're doing
TCP we'll let the middle box do its
change but we're not doing a multipath
experiment just to TCP okay and this is
not not just multi-party if you like if
you want to do deployable changes to TCP
you need to take all of these into
account that that's basically the lesson
we learned the hard way and I'll finish
with sort of advertising slide which is
multipath topologies really need
multipath transport and multiply TCP can
use my unchanged application on today's
networks you can try it out and the
biggest sort of theoretical breakthrough
and the reason it's such a nice thing
it's this ability to move traffic away
from congestion and take multiple links
and make them look like a single shared
link and that's that's why I mean the
protocol itself is the engineering part
that was really difficult but the the
smart this is this is the smart part
right this is like his white gives you
such nice benefits in these centers and
with that I'm done Thanks so I mean I've
been talking to the Google guys to the
Facebook guys and so forth the Google
guys made it pretty clear that they will
they are reluctant to touch to touch it
until it's in the mainline kernel and
this is like the the code is maintained
by our colleagues from Belgium so they
are in the same project and they did
most of the protocol implementation so
the push in the next couple of years we
have funding for this so the push is to
just try to get it in the mainline so
currently we have one of the stack
emitters tutoring us on how to how to
restructure
the Big Dig patch we have so we have
like a 10 like 10,000 ways of course
patch which that touches all on the TCP
stack so it's a big change so that's my
guess is one city in the mainline people
will start playing with it before that
yeah they can play with Venus in a
simple you know they can just see are
there benefits but I'm not exactly sure
that they are willing to sign up to so
if you use like an experimental kind of
like the one we have the problem is that
the mainline kernel changes all the time
so you have to port the patches and
that's a huge effort I mean that's
a--that's a huge effort so realistically
speaking I think we'll see it in data
centers when we have it in the mainline
or no after we have it in Millennium
it's probably a bit optimistic to say
that to meet you have in the mainline
businesses but on mobiles I think that
the story is a bit different because and
the push he seems to be seems to be much
stronger on mobiles like for mobility
things they know there's a bunch of
companies interested trying it out doing
experiments and stuff so in that
particular case it might be yeah so I
mean you can use it so we have a paper
in Sikkim workshop this year and
basically this is what we look at you
know we look at what happens if use them
both of the same time if you just use
one and so forth so if you just use one
you'll have some glitches when you
switch from one to the other because for
instance if you're using Wi-Fi you
switch to 3G then you have a start up
time for the 3G because even 3G even 3G
is connected until you get the radio
location it takes like a few seconds so
it's no problem you know I mean the
implementation currently allows you to
say this interfaces in backup mode and
this is the primary interface so you can
just instruct the code to just use
inside the kernel to prefer one path
over the other so it's that's not a big
deal you can do it but yeah
so I mean yeah I think it's a tricky
path to go down to I mean that's the the
first if you look at how how the whole
internet architecture has been evolving
it's been a story of encapsulation right
and what encapsulating multipath tcp
over something like SSL is the ultimate
in encapsulation because if multiply TCP
becomes the sort of standard then
everything is encapsulated over SSL and
I'm I'm one of the skeptics of this
evolution which says a lot of the people
I talked to they say yeah but at the end
you know once you encrypt it they're
done and I don't think so I know I think
there's just a step that they say you
know the guy whatever the government
comes and says install disk in your
browser or else you don't get Internet
okay so once you install disk in your
browser what will happen is they'll
break the SSL connection they'll
terminate it they have a middle box that
looks very carefully if your traffic and
then they forward it and then nothing
stopping them from doing everything they
were doing it they're doing now from
doing it there right so I think it's
really a race to the bottom
all of this encapsulation I mean my my
good friend Lucien says that we should
use HTTP as the narrow waist I mean
that's even scarier but for short time
deployment it makes a lot of sense in
the long term I think we all lose I
don't know yeah
hearing you disappearing today suddenly
start behaving properly with him to be
here today start inappropriately turned
down connections that would have worked
so our experience with Skype I mean I
don't know I can't give you firsthand
information because I didn't run the
experiment our experience has been that
it was no problem like killing one
interface and just forcing captain moves
to the other I mean not forcing Skype
was getting so the thing is if your
interface dies then your kernel will
tell you your socket has died right yeah
you get on a board from the circuit so
that doesn't happen with multipath TCP
okay so basically the kernel just keeps
feeding you and you're happy right
I mean if an application out-of-band
actually just does if config every
whatever then it will it will you know
it could potentially get confused by
what's going on right but for Skype in
particular you just it just worked I
mean as I said we you know we had had
the flow work working over Wi-Fi you
killed Wi-Fi I moved to 3G nothing
happens I mean yeah I mean I I think in
that particular case I mean it should
probably work correctly like if they
kill the connection nothing happens
right it just they just is just they're
taking it in their hands right I mean
yeah
how much help later so um there's two
things there's um so I think multi-part
ICP mostly benefits you if you want if
you want to do if you want to do bulk
transfer right that's that's I think
what most of the benefits are because of
the mechanisms we have with the data
sequence numbers and so forth you can
imagine you could use this to get better
latency per packet latency I mean in
general per packet ladies you'll be
higher in multiply tcp because one path
can be it can be higher delay and then
the packet cannot get passed up to the
application until you know the higher
delay packet gets there because they
need to be passed up in order if you're
a data center I mean I was chatting with
some NetApp guys at some point and they
were saying well I think we we might use
this to for instance send the say
manifest transaction over multiple stop
flows redundantly okay and then make
sure that whatever you know the first
one gets there I mean yeah that's
completely fine I mean it is your use
case the protocol allows that you know
you can easily do that I just have no
idea how people don't use it but in
general if you really care about packet
level delay and so forth this is
probably I mean and short transactions
it is not for you because by the time
you set up a second sub flow you know
the connection is gone and this is
actually what happens in practice like
you start the connection the the stack
of course starts pushing packets on the
initial stop flow and then at some point
I think when you when you exit slow
start or something the second sub plug
gets created right so by the time in a
day Center for instance most connections
they will be gone anyway so</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>