<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Probabilistic Elastic Part Model: A Pose-Invariant Representation for Real-world Face Recognition | Coder Coacher - Coaching Coders</title><meta content="Probabilistic Elastic Part Model: A Pose-Invariant Representation for Real-world Face Recognition - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Probabilistic Elastic Part Model: A Pose-Invariant Representation for Real-world Face Recognition</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/X5p2RYU2Pwk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay so let's get started it's my
pleasure to introduce to the gang ha
gang is not scheduled to us he did the
internship with to send me a few quite a
few years ago and then he joined a live
lab after live level was dissolved he
moved on to a number of places including
no geology lab IBM research and now he's
a associate professor at the Stevens
Institute of Technology and today he
will talk about a probabilistic elastic
apart model for face recognition so
let's listen to it okay thanks Junior it
is a great pleasure to revisit the MSR
one of the best chemical science
research incident in the world so today
my talk is about a flexible part based
representation for real world face
recognition okay so you may wonder after
30 years of research why should we still
care about the face recognition research
I think a short answer for that it is
still not solved yet okay so before I
get into the technical part I want to
briefly introduce briefly introduce my
school so Stephen sees in a beautiful
campus on the New Jersey side of the
Hudson River so we oversee the skyline
of New York City basically the opposite
side is my hardened downtown so it's a
beautiful campus center most New Yorkers
when they come to you I mean perhaps in
their lifetime they'll ever come to the
total to our side and they deliver had a
chance to see the skyline of Manhattan
so next time if you happen to be here by
giving me an email and I can arrange a
wizard team to our campus okay so
current research in my group i
categorize them into three themes the
first is on human centered wish your
computing I tend to do my research
center around human-like understand
human from image and videos and also to
interactive type of recognition tagging
and things like that so the second theme
my research in my group is a bigger
issue data again part of their forties
originated from my experience here like
designing contact local immediate
descriptors all the way to a modeling
like a contextual information including
social networking contacts for for for
recognition essentially the third theme
of research I initiated at the school
after i joined the stephen sees on this
egocentric vision-based cyber-physical
and a colo color of the system the
reason i quite a cold / system because
we want bilder integrate the human and
the robotic system for example one of
our goal is trying to use that
egocentric camera this is a very cheap
camera the one on the right side is very
cheap spy camera i bought from china so
there's a pinhole camera in between of
the camera glasses and we want to enable
the users to use that camera to control
a wheelchair you may imagine that a for
a quadriplegic in the video they lose
hand functionality cannot really control
the wheelchair we want to build a
corrupt system where most often this
wheelchairs robots is moving
autonomously but whenever it is unsure
about the what's lexus step to make it
could ask the human for control then the
quadrilogy individual could use that the
camera to control it then it would
literally record a input like from the
sensors and output from the user
controls then we hope to build a linear
algorithm which can evolve the decision
engine of that wheelchair system so in
the future it could handle similar
situation ok so that's about the overall
description of the research in my group
so back to face recognition white we
really care about the post variation the
simple reason is that the posts would
actually mingo other visual variations
together so mixing is really complicated
we we all know that from the seminal
paper of vacant face and the
illumination con seeing that if if the
if the post isn't changing then
everything becomes linear and is easy to
handle right so but as you can see from
these examples once we have a lot of
hosts
since becomes really complicated so we
want to better handle posts with with a
better visual representation of the face
so there's two types of approach
approaches to handle post variation the
first aseem of research they focus on
fees alignment identify visual landmarks
I think there's a series of work for max
of research Asia they have really boost
some good facial I'm the algorithm for
real world photos ok just for math
probably the conversation though was
with Jen nigga he told me that at the
turn to face alignment there was a Miami
sorry I actually felt on those youtube
videos there is a benchmark for the
youtube video face faces datasets
released by the young wolf I think Jen's
algorithm didn't really fly on that
video database so we are going to
revisit that to see why our
representation is better so a lot of
theme of research trying to build a
robust the matching algorithm to handle
better handle post variations my
personal research is really focused on
this domain because I believe like low
fissile I'm and that wasn't me is going
to be perfect so you want to build a
robust matching I with them to to handle
any possible racial post variations you
can still have so so our approach is to
take apart based representation we want
to build a power base model ok previous
work on part based representation for
face images is mostly hand crafted for
example these parts could be defined
around like visual landmarks and and so
on and so forth what we want to do
though we want to learn the parts in an
uncivilized fashioned from a set of
training data ok then want to build a
generative model where once we have this
part base model we can and identify this
each specific parts in a specific input
image then we can use these part
specific apart in that image as the
representation ok we're going to talk
about that
the benefit of having such a
representation okay so there are a bunch
of work recently also on what general
face a more general object detection and
object recognition trying to build a
part based representation as an
intermediate level representation but
they haven't applied it on face and some
of the approach i do not see why they
could be used on the face domain okay so
so given this and here is the outline of
the rest of my talk so first I'm going
to introduce this probabilistic elastic
part model or it's very simple algorithm
but hopefully I can convince you that it
is very effective okay so then I'm going
to talk about two applications the first
is on face verification okay so one good
side of our representation is that it
provides a unified the representation
for post image and video based face
verification that that means we can we
have this representation where we can
enable a single phase imager to to be
matched directly with a video clip
without resorting to this frame by frame
cross-matching okay pairwise matching
okay well also we will also talk about
how we could use this representation for
enhancing any offline to in the phase
detector it is unsupervised the detector
adaptation algorithm nigga hopefully I
think I presented the briefly describe
some of the work we did before on how to
adapt a detector to a video here is just
we try to do an uncivilized detector
deviation to our photo connection to
make it better so this part of the work
we we have published in SEO APR 2013 and
this this part of work is going to be
presented in icc v2013 so and the some
of the experiments we we presented here
will be from our recent primary
submission because we do some more
experiments and the results are improved
okay so so first that what eats at the
publicity elastic power model so we have
three goes for this part based
representation first of course we want
it to be posting wearing okay the second
we want to unify the representation
image and video faces the reason we want
it to be like that because we want to
avoid this a frame to frame imagine and
also our ultimate goal is for fish
identification so when you are trying to
build a gallery database we want the
database really scaled to the lamp of
person instead of lumber of images in
that gallery database and ultimately we
also want this representation to be
additive meaning that if you have a new
face for one person editing we can
incremental update that the
representation without resorting to
other previous images okay so i will
show you how we achieve this so again
the general philosophy as I mentioned we
want to build a generative model where
for each specific the input image we
want to identify the specific parts for
that fits in in this image and we use
that as our representation so just sort
of give you a sense of from low-level
how we should enable to lend such a
power base model which starways a very
simple like a feature extraction process
where we build an image a pyramid for
each input face image and we densely
extract the overlapping patches okay
then for each patch we could build a we
could extract that descriptor either
saved or LBP histogram from that but we
do something in addition to that we
augment the x and y location of the that
descriptor to the over descriptor so we
quite a special appearance which
descriptor ok then up to this point we
have a set of features it is that it has
a spatial component and the location
component so so the face is represented
as a bag of features but don't be
confused by the words because we're not
going to build a dictionary to build a
bag of words representation we're going
to do something different here ok so
then how do we build this you'll ask if
our model is we we could gather a set of
20 images then we can fit a gaussian
mixture model ok in speech community
this is called a universal background
model ok but I will highlight something
we change the model a little bit i mean
it is more specific here because we can
find each gaussian component to be a
spherical Gaussian the reason I will
explain father because we want to to
have a better way to control the balance
between the sperians part and the
location part because they think about
that the appearance vector is about like
a safety is 128 that mentioned location
is only two dimension so we need a
better way to control the balance
between them if we use a diagonal
covariance matrix we won't be able to
achieve that as i will show you some
example we are going to show okay so of
course this is a very simple maximum
likelihood estimation problem with
missing data okay so we just gather or
Stella between Anita going through that
the feature extraction process to having
negative special location descriptors
then we're going to feed this coffee
mixture model okay in the end as you can
see this gaussian mixture model
naturally comes with a set of parts so
here at the visualization is really the
set of image patch is associated with
each coaching component okay up to this
point the mess that some to be really
simple to you okay so so how work how
are we going to build the representation
for each face image from this model okay
pay attention to this because this this
is a simple but really differentiate
them from the previous work okay so so
here if I have value input image here
suppose I have already lent this a
universal background model okay it's a
gaussian mixture model so the face the
improv is is firstly represented at the
back of spatial appearance descriptor
then in order to generate the fennel
representation for the face instead of
building a bag of words histogram what
we did here is that we do it to a
universe assignment okay sophie is
gaussian component we look for one of
the descriptors inside extracted from
this input face image which induces the
highest probability on this Gaussian
component okay so for each Gaussian
component we identify such a feature the
in the end we concatenate that set of
features we identified for each Gaussian
component together to form a single
descriptor vector for the face as you
can see this is for Gaussian components
three mega this is the probability map
for for their dodging component that
like a calculated with each specific
descriptor extracted from their face as
you can see that it is really revelant
in the chink of the face ok here is the
color of this i although they have a lot
of post variations okay so you could
view this this is more or less like a
alignment process there ok thanks we
have a implicate that so by doing this
maximum likelihood estimation like a
identification of the features we
actually have increased Adele i'm in the
process in this in this process ok so
wait descriptor actually pull this yeah
up to this point way discard the
location yeah we only have the
appearance part in this fan director but
is indexed by education component as you
can see the gaussian component the place
a row as a bridge to build a
correspondence between two faces ok so
so let's get into a little bit more
details here because as I said we
confine can find each Gaussian component
will be as febs farrago Gaussian the
reason for that is really this suppose
so here is it we show that if we use a
regular Gaussian for example with that
diagonal covariance matrix here is the
spatial spam of the Gaussian component
way length as you can see the span much
spatial regions in the face which is
rather the kind of behavior what we want
the main reason for this is that the
spatial part contribute more to the
probability we watching you if you put a
diagonal corns matrix you assume each
dimension is independent so if you try
to make the spatial component to
contribute more by simply scanning that
dimension is what going to be helpful
because your jaw
is going to like really enlarge the
variance of that dimension when you are
doing the yam estimation without the
affecting the other component weathers
if you I mean come find it to be a
spherical Gaussian than you Mingo other
words together so if you scale the scale
the location dimension you essentially
could have the location component to
have more influence so the the Gaussian
component becomes more localized so the
they are doing a local matching
essentially so any questions here okay
louder see white really dislocation
component the main reason is that like
okay so we did that this maximum
likelihood identification without the
spatial constraints as you can see you
could easily match I with with the mouth
part here the main reason because we use
as if that descriptor here safety is
very good in shift shifting illegal
errands like is shifting weren't so you
may match I ways with this on the in the
descriptor space versus if we put this
special constraint together we're really
matching the eye with the eye okay so
that's why we need to do this a spatial
component okay so let's let's say why
this representation is posting warrant
so we try to visualize that process okay
so what we essentially did is for an
input face image for each Gaussian
component where identify the local patch
okay the-the-the with the highest
probability then we put that patch back
into the location of dedication
component ok so we since that this fish
essentially that's the process okay as
you can see that this face is nearly
from though here although we average it
becomes blurred blurred because we
average the overlapping regions here
without doing a lot of fancy sort of
filter in there okay so this is with
suppose we just use they simply image so
something additionally we can do is to
really horizontally flip this face image
and the dying to the maximum-likelihood
identification with the joint set of
spatial appearance descriptors okay so
that as you can see the representation
becomes more near your friend oh okay i
can let you to see the difference there
so in the end what we did is we are
going to be a adopt this flip diversion
make a joint version of posts okay so
here is just the something more we can I
mean because of this universe assignment
based on the Gaussian component we don't
really care how many frames we have okay
so we can for one frame we can for
example this is George Bush's face like
will come out with with one
representation than with ten frames as
you can see that it is clearly it is
more Randall in a sense so it is more
wholesome wear it okay so 20 frames 50
frames they don't really make a huge
difference there so we also have the
version where we do the flipping for
each of the frame stir as you can see
they have a they have some difference
but a lot too much if you integrate
multiple frames together okay so so then
why this is a unified representation is
quite all obvious for for a single image
and for radio face image once we have
two white ones we have done the feature
extraction and then using this pad model
we quite pad model stands for
probabilistic elastic apart mode okay so
once we use this card model to to select
those features in the end they're going
to have the same dimension because the
feature dimension is with respect to the
number of gaussian component and the
dimension of the feature descriptor okay
so that's why up to this if once we have
the list representation we can come we
can match this single phase image with
with the video clip directly without
resorting to the frame to frame imagine
okay so why this incremental suppose you
have a gallery database you have a set a
set of a sip from the same person we
from this model we can generate a single
representation for this person right by
doing this maximum likelihood
identification so it is
mendel it could be incrementally updated
mainly because the incremental nature of
this max operation because once you have
this representation you giving a low
face we just need to compare if the
maximum likelihood identificate I
identify the feature it has higher
probability than the fish I already have
in this representation a lot if it is
then I just replaced the colonel
representation so it could be
essentially increment totally updated if
we have more faces added okay that's
that's the that's a larger benefit of
this although in this talk we are not
going to present any face identification
results but if we want to do face
identification with this representation
we can make the database essentially
skill with the lambo person instead of
number of images in the database ok so
you BMO is visible for one person no but
a whole everybody for everybody
population for the nominations
presidents given the operation yet post
variations yeah yeah yeahs for here we
talk about those rooms in one person so
we assume that we already have that the
upm mod ok so the from uvm do you love
your cell phone yeah we find also the
presentation to do present energy into a
single person yes yes so I'm going to
introduce a little bit the adaptation
process when you are trying to do
specific matching for apparel face
images we have that Beijing adaptation
process there that's more like like a
person specific adaptation okay so we're
going I'm going to talk about in the
face verification experiment okay so so
then I mean I hope you have get a sense
of what this symbol PAP model is ok then
I'm going to move forward to present to
applications one office verification and
I'll the other on face detection sure we
do the training face assume you wouldn't
need some kind of an argument right no I
yeah you could the user do alignment
always out on a alignment well I'm
assuming you
I may not be very good we do some
experiments we're still better than then
when this paper was published he's still
better than the best in this evaluation
in this pension updatable yeah yeah we
tried both like this I wasn't would
benefit from from some sort of alignment
exam but because this representation is
designed that he'll be robust at your
post operation says that's we have a
implicitly Minh processing imputing
muscle in the training you need you
wouldn't need it's good to have some of
the language i put it interesting you
are doing impressive your money ah
that's good you did you leave them to be
consistent if you have alignment in your
in your training phase and you have to
have the same alignment or testing phase
i will see my god yeah that's that's
what Kendra we are doing but it will be
interesting to try if we have alignment
always out the alignment on the testing
stage ok so sure so for face
verification we are going to talk about
the leg up results on to our very
popular benchmarks okay so so first we
are going to talk about uncontrolled
face verification like we're going to
introduce a very simple method first two
to use this proper representation for
for face verification then I'm going to
talk about how we can do a little bit
better suppose way we want to enhance
the matching of ass specifically spare
okay then i'm going to show that our our
top performance on both benchmark data
set okay so how could we do that imagine
when we have a parallel face we want to
verify if they are the same person a lot
so we're taking a very simple approach
here so once we have this representation
we quite a pap representation then we
just take the difference of these two
representation okay we take the absolute
the difference vector then give me a set
of training images training pairs
labeled with positive or negative
positive means they are from the same
person negative means they are a lot of
the same person then we can Trina som on
this difference vector to
to make a decision on if they are the
same person a lot so camera and a new
testing phase we can use this as we have
class refer to make a decision okay
that's a very simple method why haven't
the resort to more complicate the
magical ending algum yet ah but I think
I mean if we have a better magical any i
wouldnt it would enhance the results
indeed ok so so to make the
representation to be even better we have
proposed a page and adaptation scheme
where suppose this is the walkway called
the pep model which is universally
trained offline ok suppose we have a
pair of face images we want verify ok so
what we can do is we try to make this
model to be adapted to this pair of face
image to fit them better but what
deviated from this model too much so
it's a basin adaptation process ok then
we're going together a loo adapted a
gaussian mixture model ok then from that
we build this pebble representation ok
so if we look into the mess where it
really is it's very simple scheme where
we just put a conjugate prior on the
adapted parameters and this parent is
from the universal background model and
this this again this could be done in
Beijing yeah framework in an iterative
fashion really simple method ok so so to
see why we did this adaptation process
suppose this is the pair of face we
won't verify ok if we look into the set
of patches we we build a correspondence
with which the pep model ok here you can
see for some of those patches they are
still misaligned a little bit ok this as
we highlighted by the blue rectangle
there so this is the p4 adaptation after
we do the adaptation as you can see we
really make the alignment better if you
compare them ok so that's why this space
and adaptation scheme can help us to
build better correspondence there ok so
any questions on this part so we are not
trying to do a person specific
adaptation like in this
speaker verification domain we've here
we are really adapting the pad model to
a specific a pair of images we're trying
to match okay so so then we can also do
multi future fusion we have post a
fusion process where if you if we have
different type of features to do the pad
model and to do the elastic matching
then we can concatenate the decision
score together then Trina linear sqm
there to combine the school together
okay that's that's a very routine
process I just want to mention it
because our results benefit from fusing
multiple features okay so we're going to
present the results on two widely use
the benchmark data set one rfw the other
is YouTube faces data set okay can delay
we ranked at number two in this you r fw
database and the number one in the
youtube video face data sets so when we
are talking about results in era of w i
should be careful because the gen gen
steam has really pushed the recognition
accuracy to be super high but they
leveraged an enormous amount of external
data to trim their face alignment
algorithm and trim their face
verification algorithm so we're more
we're working on the most restricted
protocol without any outside the
training data the reason is that we my
philosophy is that you should really
come out with a representation which
could generalize across different data
sets that's why we are trying ourselves
just to are fw to see how it could
generalize so when we're comparing it
out where many compare results in this
category so we're all comparing with the
other algorithms which leverage the
enormous amount of external training
data okay so here Justin some details
how we did the feature extraction and
since like that ok so we specifically
way we use that like a yeah 1024
Gaussian components in our you'll be a
model okay so here is our results here
so this is the best results when we
published our paper in CTR 2013 okay and
the recently there is one paper
published from Oxford like I believes
I'm Judaism and screw up they they also
used a gaussian mixture model i'll use
the Fisher vector to do matching and
that they are currently the number one
and this was these results this PM
results is we if we use like a unlit lpp
feature okay if we use sift feature we
get more less similar results with the
LBP feature okay so if we do this fusion
we can we can drastically improve the
results okay so you've way to the
adaptation plus this fusion like we can
do even better okay under the ROC curve
line we we are not as good as them so in
terms of lumber we are we're about 1.5
below their accuracy so but still we're
currently ranked number two in this
benchmark okay so but their algorithm
needs to learn how to do have really
conduct like a metric learning on
different data sets which is the part I
I don't like but i respected their
performance a lot okay so on the YouTube
video faces ah normally I was really
published results in this this data set
mainly because of computational issues
all kinds of issues there so can delay
when we published our results this only
only the young wolf them self published
their results okay this the baseline
here okay so recently some more errors
and publish results they're like the
best one is this one published in the
biometric conference ok so the so our
results if we only use one type of
features we're about here look although
we are we are worst in the high
false-positive rate area we are we're
nearly as good as them with just a
single feature in the low false positive
area that's the error we really care
okay so if we use a different set of
features we we are actually slighted
already slightly better than the
algorithm if we fuse them together we
already get better on here if we do the
adaptation we do even better okay so
currently like a is a mix that we are
still lower than those algorithms under
this high false positive rate IRA but we
do significantly
other in this low false positive area so
I metric thing this one yeah ha yeah
that's probably I cannot remember the
easier is is the group lot so actively
in communication they are mainly
actively in the biometric can really day
okay so i can send you some information
okay yeah so currently if we do this we
in terms of recognition accuracy if we
we determining a single operating point
we are about 1.5 better than the best
algorithm published in the biometric
conference okay so so this shows like a
why this the lumber is lower than the
era of tableau data sets is because the
resolution of the faces in this video
face benchmark is as good as as the air
fw data set so we're currently lumber
wonder so and also i want to highlight
lega out here once we build the pepper
representation we don't need to do a
cross frame matching as this most of
these algorithm would do okay did they
lead you to this frame by frame like a
matching then identify the best matching
there okay so so just I mean our album
is always a lot perfect so which by
looking into these error results which
could tell us which direction we should
go so here are some areas made by our
verification algorithm as you can see
clearly like we're matching a white face
with asian face this shows that we don't
really have a comprehensive
understanding of the face so that's the
direction we're trying to to go we are
trying to build some like to do
segmentation and do semantic labeling
try to really understand the face like a
12 wide making such embarrassing errors
so that's that's the direction we're
going like trying to really drive the
face where vacation accuracy to the last
layer
me I can't do where you how many using
gray level image say some color yeah
we'll play an important role but so far
I I haven't seen I mean if there's any
work really that we do the color
information that's always interesting to
look at these errors it tells us we
still have a long way to go yeah but
when you report numbers like in the
previous page that are eight percent
right then it's a on eight percent of
the queries you got the right person out
of how many potential answers oh yeah
this is Laura identification disease
where if occasion husks so basically the
this benchmark data says they build some
standard lega basically the input is
face pairs so you just make this aging
if this pair is from the same person a
lot is a classification distributions
fifty percent match yeah fit fifty fifty
percent so the random guessing baseline
is fifty percent yes sir 80 so yeah sort
of taken what's that about three out of
five guesses you're doing better than
random yes yeah something like that
that's kinda stale of that I i think
this benchmark they designed in this way
to to balance the training really i I
don't I mean as you can see that the
distribution of match and long match
faces should not be fifty fifty percent
in real world right so is a skill to
distribution that sums embarrassed in
the future the the benchmark evaluation
could need to be redesigned somehow I
think yeah that's right oh it's a way of
measuring progress but is someone who
isn't a researcher in this field ask oh
you know if I give you a celebrity photo
on this what's the chance that your
algorithm will name the correct one and
let's say there are 200 celebrities in
here once what's the chance it's like
five percent of the time it will guess
the right person or what is it that's an
interesting question i think that the
lamp or i heard from google picasa is
that what they can achieve is like up on
the top 10 results they can make sure
that the land a percent of the cases it
could be correct oh and what your family
out because from from all celebrate face
images they have in the Incan community
serv to do celebrities there
saying that in top i see so you take a
celebrity photo you ask Google who is
this and it gives you a list of 20 names
and usually if you kind of look in the
top 10 it'll littell say you know ninety
percent of the time that the correct
lame is in the top ten faces will say
carmen diaz and laying a whole bunch of
peoples of which are opposite genders
you know kind of nonsensical but
somewhere those Ted the right person may
be there yeah that's what I heard from
but that I mean it could be they deliver
publish their results for something like
you know finding just verifying what the
labels are the images that can be useful
that if you basically said something
like here's my personal picasa photos
show me the ones with my daughter this
donor you know the question is will it
sort of you know well seventy percent of
it just be correct you're only twenty
percent you know i believe will in the
personal photo i but we can do much
better because the lambo fantasies much
less right just there is much lower
complexity but sometimes people look
more similar right Shelby you can't for
example take the badges of racial
differences and things like that yeah
yeah that's absolutely true i think
there's low really best the benchmark
for their this perhaps like some air
force least in that space really to
evaluate the progress in that space i
think i don't really see a lot of
benchmark stairs so Simon and when I was
still in Microsoft that Sam and I we
explored a little bit on this family
album scenario but I think we need more
serious benchmark in their space but
it's kind of difficult so yeah
okay Lex I'm going to talk about face
detection how many of you will hear
still seeing that face collections solve
the problem toys Lowell anger here so it
saved us we discussed this your hand if
you think it is resolved front faces
this is a pretty good look at some of
them 10 mistakes you would make with a
state-of-the-art face detector so your
your music I deduction here you will see
that I mean that's embarrassing right
false alarm why this is detected a face
that's very suspicious red we also lose
having some of the missing detection
there ok that's this is from viola
John's face detector for moments away it
is well as there is best one but I mean
we tested one of the reason the one mega
from Adobe like they have you Zampella
place the face detection I wasn't like
they are also making this kind of virus
I'm gonna show CDs its kind of the
baseline if you just downloaded free
software yes yes so was it better so we
want to do better than that without
there a lot of where foots ok so I'm
going to tell you a really similar
approach which you can do this so what
way do we did is very simple okay again
look at the philosophies were you single
but i mean the the implication is it
could be inspired a lot of scenes there
so that's that's the something i'm still
trying to explore so what we did is here
suppose we all have a photo connection
here okay so first i will set the
decision threshold for from the offline
between the detector to be really low
okay to ensure the recall okay so i'm
going to have the shadow fist candidate
here of course is going to have false
positive okay so then i'm going to
choose perhaps the twelve ten percent
the positives and the the bottom ten
percent top leg lives and treated them
as positive and negative examples then
i'm going to build the purple
representation ok suppose i have offline
chin pepper representation of half model
there i'm going to build a proper
representation on each image i connected
here okay i'm going to simply trigger as
we unclassified on top of the paper
representation there i'm going to rerun
call these face images then cut off the
threshold to TT to see if we can
together
1024 so it's a really high dimensional
vector you did so yeah so but that's
that's what we did at the symbol Aziz
after I describe this I don't need to go
through all these slides because that's
essentially what we did to see if we can
make it better okay so we tested our
August mounts three photo albums this
year berm energy eigen actually is
connected by am I and ashish like a back
like a several years ago we still have
some interaction there and so and the
the the other wines def TDP database ad
which is again released by Eric lending
Miller from UMass and it is I'm
financing I have a lot of discussion
with him recently so he said you know
what he did is he connected some web
photos then runs away all a John Steed
Hector and picked up audits was felled
there so he's specifically screwing up
we all are John's face detector I mean
so this set of photos are really
challenging okay the kinda passed the
algorithm like a detector there is a
phase detector called X Z jy published
by Adobe they have an example of its
debut de like a database or ten thousand
faces just doing this example a matching
to do physically action that shield the
best performance so far on this FTTP
database so we're going to show that by
using our adaptation scheme very simple
ways we can improve both the way all at
jons phase detector another XD gy
detector okay so so where's that I'm
going to play a video so but here just
some subjective results like this is on
the G our bomb techs dgy detector still
are making those embarrassing false
positives and we can get rid of those
and there are cases we can also yeah
here is the the results we show here its
many like a eliminating false positives
but we also have cases where we can
actually get the first leg lift back I'm
going to play a video later but in terms
of performance curves okay so first I
want to show that this paper
representation is really also good to
differentially face and long face ok so
here we did the same adaptation process
with just a concatenated sifted
descriptor
meaning that we are not doing the gut
you're using the gaussian mixture model
to select those part features instead we
just the densely extracted receive the
descriptors okay so here is the
performance of the viola John's detector
so if we simply use it as if the
representation where a lot less
necessary doing better okay but if we
use the pepper representation and used
and doing the adaptation we can do much
better okay on this gob okay which shows
that that I mean the reason is obvious
after we do this paper representation we
are reducing the the the with in class
variation of those face real face images
although the background like maybe stay
in the same because they are random
anyway so but we are making the face
class to be tight so that we can
together and here is some more
embarrassing on the album so here is the
performance of the viola John Steed
actor and this is the ex DG why detector
as you can see this detector is really
much better than we don't know Jones and
nearly perfect okay so ah let me see
this is our algorithm example based the
detector adaptation I was when we were
published in CBR 2011 it it improved the
we all at once detector but a lot making
the XD gy detector to be better okay if
we if we use our paper representation we
managed it to to improve both from the
elegance detector and even made some
improvement from the ex DG y conectar on
these datasets ok so we'll make meeting
much better so on the G album again this
is the results from our cpr 2011 work it
works meaningful with you like this use
amplify step approach so that's what
really make a lot of progress if we use
this paper representation and do this
representation as you can see after
adaptation even from the village on the
election results we let me see we yeah
so we the procurve is already better
than the XD gy detector so which shows
that this this is really helpful to do
this one cycle iterative reranking there
ok so this is on the benchmark like a
fgt be database like the disc way the
score means that if your pre predicted
has more than fifty percent overlap with
your grant us then you claim it to be a
crack detection okay so so this red
curve is the x DJ why detector results
and here are some bass lines published
before like a pay their use the
different local features like this one I
believe use the search feature and this
this is published by Oracle in your
mirrors group they are using a they are
also doing this type of deputation but
using a gaussian process classifier in
the middle okay so so if we do this
folder by folder deputation because they
have a temp folder cross validation
process if we only do that deputation
folder by folder we can enhance the
results we already enhance the result
significantly I'm not so sure I didn't
put the or folder deputation results
there I should add it back actually we
can do even better than this okay so
this should be the continuous score
candido score is your measuring really
the overlapping or between your
predicted rectangles and that so i
should change these slides a little bit
so ah as you can see this is the ex DG
white detector and after we adapted in
which the paper representation we made
it significantly better so here I I
would like to play the video perhaps
just give you a more sense that this
representation is also good in in
bringing some of the force phos- back
let me see okay yeah so as I said we are
going to represent this piece of working
I ccv soon nigga yeah this is the
village on student performance is valid
that like Al any % week or eight
here is the false positive that you get
rid of it yeah we have a false negative
here missing detection and we get it
back after this adaptation here is a
very similar we wonder why why this kind
of patches are detected its face if you
to history equalization on that face
page you will see it looks like a face
in then the day sir Graham is actually
published by shallow before ya get rid
of this we can get this back okay I will
simply stop the video because is it's
just gonna shove that is better indeed
and you see leave back
so just to some discussion on this type
of adaptation scheme I think it could
inspire a lot of interesting things
because you could think of like this
this is kind of a process where we are
trying to adapt our efficient algorithm
to to the statistic of the datasets
you're dealing with as it's just a light
way of doing that but I would see that
there there could be a lot of interest
in seeing induced from that I believe
chart did something for detector
deputation before right with with a
Taylor expansion type of would try to
modify the detector but here we're doing
a little bit differently like a by try
to leverage in the examples ok so in
unsupervised fashion so so just in
conclusion we have posting where and the
face representation induced from the the
pep model and the issue of the leading
performance on posts face verification
face detection task is on benchmarks so
our future work involves how we could
use this paper herbs and helium for
other visual recognition problems such
as scene recognition and we're currently
doing some work we're trying to see if
we can make a better object detector
based on this paper representation idea
ok so before I am a tall guy I want to
grill your face recognition capability
who is this guy without any hints ok let
me give you a little hint ok Carl he
plays chess
because partly cats morrow idol if it I
happen to solving just decades sure hey
playdough is deep blue so I walked from
IBM before so you remake this so we used
his faces or across our network so I
want to thank him indeed so I will stop
here in case you have any questions no I
don't blow lot I think I be I'm still
have a deep blue as a demo in their demo
room but I mean it is never played again
i guess like it's kind of interesting
now their focus is on what's it I think
the deep QA project is very interesting
so yeah okay thank you thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>