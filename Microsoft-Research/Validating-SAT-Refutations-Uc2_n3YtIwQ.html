<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Validating SAT Refutations | Coder Coacher - Coaching Coders</title><meta content="Validating SAT Refutations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Validating SAT Refutations</b></h2><h5 class="post__date">2016-08-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Uc2_n3YtIwQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so today I'll be talking a little bit
more about the correct version of that
the correct way of doing it but yeah
we'll talk about validating SAT
refutations and this is joint work with
ryan hill and warren hunt so today I'm
going to give a bit of a motivation for
while we're working on this and then
we'll introduce some set basics I'll
introduce what the property of
redundancy is in our context and then
how to how to construct a proof of
correctness or proof of unsatisfied
bility for sat problems and I'll present
a few different types of those and
explain kind of our final type our rat
proofs why we why we think they're nice
or have a nice property and then I'll
present our model for a rat proof
checker in a CL 2 and then a
specification for Anna proof of
correctness so there's some bad news in
the sack community and that SAT solvers
are buggy and not stop that just said
it's at an smt and qvf and there have
been documented these bugs have been
documented in some of the literature
there are a couple papers that use
buzzing techniques to find large number
of bugs and some of the most competitive
set stops at smt and q BF solvers and
what's funny is that even in these
competitions they have force a door for
model checking or anything like that the
competition winners may even contradict
themselves between successive years of
the competition so for example in the
hardware model checking competition from
2011-2012 the model checker that one
both of those years contradict dictates
off on the same problem between the two
years and another problem is that these
errors aren't always even implementation
based right so sometimes someone gets a
good idea and they have some concept
that they think is really good or and
they try it out and they have no way of
proving whether or not or maybe they try
to do a hand proof or something whether
it's correct or not but the bugs can be
on a conceptual level as well as an
implementation level
and furthermore one of the techniques
that was introduced several years ago
was claimed to be experimentally correct
in the sense that it had passed millions
and millions of millions of benchmarks
and still had it had a bug that could
that one of the co-authors of our work
Brian who found by hand by constructing
a very small hand example these are for
well no these are at first SAT solvers
now a bug in the SAT solver so the even
worse news is that some set techniques
that are out there right now can it even
be verified by existing proof structures
that exist so what we're trying to do
then is define a proof structure that
will allow us to validate all SAT
techniques so some of our solutions for
this problem is we can continue to just
trust set solvers and hope that the bugs
get ironed out and I don't think that
that's a very good answer to the problem
another answer we could have is we could
try to verify the SAT solvers themselves
and this verification process would
require us to have all of the major SAT
solving techniques to be verified at so
that we could get very good performance
with our verified solver right but this
is going to have a very delicate balance
between the efficiency and the ease of
the verification process so and even
more troubling is that whatever
verification effort we do on some kind
of verified solver is specific to that
solver right we're now tied to this
model we've written for a solver and we
can't swap out to different solvers what
if there's a new technique that comes
along that's discovered we have to go
off and implement that and verify it so
I don't think this is a very good
solution either instead what we're
focusing on is verifying the validating
the SAT solver output and so what does
this mean it means that the set solver
can even either give an answer of SAT
and provide a model or it can give an
answer of onset so in the SAT case if
we're given a model we can efficiently
check that that model satisfies the
formula that
was given to the solver but what happens
in the case of on satisfiability well we
can emit a proof of unsatisfied bility
from the SAT solver and we can do this
with very little overhead for the solver
and then a single proof checker can
validate the results from all state of
this state-of-the-art solvers and that
way the solver we choose doesn't matter
as long as it can emit a proof then our
proof checker can validate the proof and
the solver becomes kind of a modular
component in the system and finally the
proof checker doesn't need near as many
techniques or sat techniques as as the
SAT solver would need so here our
verification effort is reduced so what
what do we want from these proofs of n
satisfiability right well we've
identified five different properties
that we think are important for proof
Celyn satisfiability the first is that
they should be easy to admit from a
solver so the solver shouldn't have to
have significant changes to its code
base to admit one of these proofs and
down so in the next thing is we think
the proof should be compact so they
shouldn't take up hundreds and hundreds
of gigabytes or terabytes of space on
the disk and they should be able to fit
in memory so that we can efficiently
check them without having to go back and
forth to disk next we think that our
proof checker should be able to check
these proofs efficiently so ideally we'd
like the proof checker to be able to
check the proofs in a time similar to
the solving time so if the solver takes
100 seconds to solve a problem that's
unsatisfiable we think our proof checker
should be able to compete with the
solver next we want a simple checker and
this has kind of been the traditional
approach is having a simple checker that
can be kind of inspected by I and and
enough people agree that it's right but
I think we can go further than this I
think what we really want is we want to
mechanically verified checker proof
checker
and finally we want our proofs to be
expressive so if there's a technique out
there especially some of the ones that
are using pre-processing that go beyond
the current means go beyond resolution
and unit propagation then we should be
able to express that efficiently in our
proof so that the solver or the
preprocessor it doesn't have to write
large routines to output proof scripts
so some of the first work on this is
been done on resolutions I think
resolution proofs I think these are
probably the most popular form of proof
today right now and unfortunately
they're very difficult to admit these
proofs usually require significant
modifications to the solver and and they
incur a large overhead while the solver
is running to keep up to keep producing
these proofs the nice thing about
resolution proofs is that they can be
checked very efficiently but again
another problem with them is that they
take up large amounts of space on disk
for some of the larger benchmarks in the
sack competition these proofs can take
up terabytes of disk space and so
whenever you have proof spread across
terabytes of disk space you end up with
a large penalty going back and forth to
load certain sections of the proof from
disk and there's been a lot of really
nice work though for resolution proofs
on having a verified checker and so this
increases kind of the trustworthiness of
the of the proof checker but again it's
based on resolution proofs and suffers
the same problems so a different type of
proof that was proposed a while ago and
hasn't seen a lot of attention until
recently were clausal proofs or reverse
unit propagation proofs so these proofs
are extremely easy to admit you can
produce these proofs with just eight to
12 lines or so of some of the top ten
solvers eight to twelve lines of code
modification to produce these proofs so
they're extremely easy to admit they're
extremely compact in the sense that they
don't store all the information that the
resolution proofs store and they can be
but the problem is that there they can't
be checked efficiently they require some
amount of search on every step of the
proof in order to reconstruct whether or
not the the cause that was added is
sound so one of our first forms of work
is on deer up and so this is a extension
of clausal proofs where now we include
cause deletion information and just
adding this amount of information allows
us to check these proofs efficiently and
we have a few other modifications and
this is all documented a paper that will
be at formal methods for Peter aided
design later this year so another line
of work that we've done is on
establishing what we call rat proofs and
these proofs have a more expressive
proof format and so you're allowed to
capture a lot more techniques in this
proof format and if they're based on
causal proofs so they're easy to make
compact but they're still not very
efficient to check and finally we have
another work where we verified a rat
proof checker in a CL 2 and so that's a
little bit about what I'm going to be
talking that's what I'm going to be
talking about today is this final one
and in the future we'd like to have a
system where we can have all five
properties and so that's what we'll be
working on later so now let's move on to
some basics of satisfiability yeah
Yeah right so that's what we're working
on right now and I I think it can be
done I think you can write an efficient
validated or efficient mechanically
verified checker and we're going to try
to do that using a CL 2 so let me back
up for a minute and talk about the
satisfiability problem to be clear on
what we're talking about so
satisfiability says that given a boolean
formula is there an assignment of values
to boolean variables such that the
formula evaluates to true so on the
right I have a formula you can see
there's boolean variables represented by
the X 1 X 2 etc and we have this is in
conjunctive normal form meaning that we
have a conjunction of dis junctions so
given a a salt solution for this formula
so at the bottom I've got a solution X 1
naught X 2 X 3 or X naught X 4 given a
solution it's very easy to validate
whether or not this is a solution for
the formula so here's a now I've colored
all of the boolean variables green or
red depending on whether or not they
were satisfied by this solution and then
we just have to check that each clause
in this formula has one satisfying
literal but determining unsatisfied
bility is a bit more difficult now given
this formula which is unsatisfiable how
do i express to you that this formula is
unsatisfiable right I have to somehow
convince you that I've tried all
possible solutions or all possible
assignments and none of them were
solution for the formula so first we
need to model this problem in a CL 2 in
order to perform to mechanically verify
a proof checker so we do that first bite
establishing literals as positive and
negative integers and so here if I had X
1 before it's now been converted to the
integer 1 and if i had not x3 before
it's now been converted to the integer
not 3 or negative 3 next we can
construct clauses and we have them in
our model right now as unique
non-conflicting lists of literals so
this is an implied disjunction and when
I say non-conflicting I mean that you
can't have say one and negative one in
the same cause we can compose formulas
by having a list of clauses and we say a
tautology is a unique conflicting list
of literal so here in our model we have
two tall and causes defined separately
and so that requires a few extra checks
in our model and so this is ontology
because it contains 1 and minus 1 and
then what's up so that Clause would
evaluate to true always because either 1
or minus 1 would always be satisfied
yeah because they're implied disjunction
and then our assignments are unique
non-conflicting list of literals and
these are implied conjunctions it says
that one is true and negative two is
true and so on so once we've defined our
kind of data types we can define what
evaluation on those data types means so
we can negate a literal so given a
little one we can negate it to obtain
the literal negative one and so on next
we can evaluate a literal with respect
to an assignment so here if I'm given a
literal and an assignment I'll return a
ternary value so either true false or
undefined so in the first example the
literal one evaluates to true in with
respect to assignment because it's a
member of the assignment and the second
example the literal negative one
evaluates to false with respect to the
same assignment because its negation is
a member
the assignment and finally we have
undefined if it's not a member of the
assignment at all once we can evaluate
literals we can then evaluate clauses so
given a cause an assignment will return
a ternary value again in the first case
if any literal in the clause evaluates
to true then the whole cause will
evaluate to true and the second example
if all of the literals and the clause
evaluate to false then the clause
evaluates to false and finally we return
on to find otherwise next
so if you had a tautology would always
evaluate to true just because either
well yeah I could also evaluate to
undefined I think you're right yeah
because if it was not a member of these
if it hadn't been assigned yet no so now
we can evaluate clauses will evaluate
formulas by taking a formula an
assignment returning a ternary and a
formula evaluates to true if every
clause in the formula evaluates to true
and it a formula evaluates to false if
just one of the clauses in the formula
evaluates to false and it evaluates done
to find otherwise if it doesn't evaluate
to true and it doesn't evaluate to false
sense undefined it could be multiple
causes good to evaluate to undefined and
still be if one of them if just one of
them is faster it evaluates to false
right
so next I'm going to define what it
means for a cause to be redundant with
respect to a formula so we say two
formulas f1 and f2 are logically
equivalent if they have the same set of
satisfying assignments and we say two
formulas are satisfiability equivalent
if they're either both satisfiable or
both unsatisfiable so in the second case
for set of two foam is there
satisfiability equivalent they may be
satisfied by different sets of
assignments on the common variables but
still are equivalent with our respect
they it just can't be that one of them
is satisfiable one is unsatisfiable and
we say a clause is redundant with
respect to a formula if when you can
join the clause with the formula it's
satisfiability equivalent to the
original formula so in other words
adding the clause to the formula doesn't
change the satisfiability of the formula
and there are a bunch of different
definitions of redundant in a bunch of
different context and this is just the
one that we've chosen for this context
so now I'll have a little example about
redundancy so here I have a formula on
the left and it's one that consists of
the clause 1 to the clause 2 3 and the
clause negative 2 negative 3 and on the
right I've enumerated all the
assignments for the variables one two
and three and then on the right of the
dividing line you can see whether or not
there's a solution for the formula
whether or not each assignment is a
solution for the formula so an X
indicates that that assignment is not a
solution for the formula so here this
formula can be satisfied by three
different assignments so now given the
clause c 1 which is the cause one
negative 3 if i can join that with the
formula f then i see that i have the
same set of satisfying assignments so
these two formulas are logically
equivalent and c 1 is also redundant
with respect to f
the next given the clause c 2 which is
negative 13 we've eliminated if i can
join that with the formula f then we've
eliminated one of our solutions but it's
still satisfiability equivalent to the
formula f because it still satisfiable
formula and so this c2 is also redundant
with respect to F so now I want to talk
about a couple ways to establish the
redundancy property so one way to do
that is by using unit propagation which
is one of the basic SAT solving
inference techniques so given first we
need before we can establish unit
propagation we define what it means for
to have a unit clause so we say the
cause is unit with respect a clause in a
formula is unit with respect to an
assignment if all the literals in the
clause evaluate to false except for one
literal which evaluates to undefined
under that assignment so given the
formula on the right and the assignment
on the bottom which is 1 negative 2 then
in the red box you can see that this
clause is unit because all the literals
are false except for one which is
undefined and we in this case we can
extend our assignment with the unit
literal which is the literal for in this
case so unit propagation then repeatedly
extends an assignment based on
inferences from the formula and it does
that until there are no more unit
clauses so here we can extend the
assignment with 4 and we get another
unit cause which gives us the unit
literal 3 will extend the assignment
with a little unit liberal 3 and now we
falsified one of the clauses in the
formula and when this happens when you
know propagation falsifies a clause we
say that it generates a conflict
so now that we define unit propagation
will define our first redundancy
property so we say causes the reverse
unit propagation or rup redundancy
property with respect to a formula if
unit propagation on the negation of the
clause results in a conflict and that
statements a little strange so let me
say it another way we want to take the
assignment that falsifies the clause and
then show that that assignment will
generate a conflict for the formula so
in other words if there's a solution for
the formula it'll still be a solution
for the calls we're trying to add
establishes redundant so below that I've
got some ACL to code and I know not
everybody is used to reading things in
kind of a prefix format so I have some
notes off to the to the right side in
all these cases but this is essentially
a way of establishing a function called
R up p which given a formula in a clause
first gets a falsifying assignment by
calling the gate cause to get the
assignment a then performing unit
propagation on the assignment a to get a
new assignment yupi hyphen a we then
evaluate our formula f with respect to
this new assignment and to obtain a
ternary value and then check to see if
that ternary value is false or if it's
generated a conflict so given a formula
in a clause we can establish either t or
no whether or not this causes redundant
or has the rut property rep redundancy
property another way to establish
redundancy is by using resolution and
this is part of the resolution proofs I
was mentioning earlier so given two
clauses with a literal a positive
version of literal and a negative
version of the literal in the other
cause we can create either a new clause
or tautology by taking a union of all
removing the the literal that we're
resolving on and taking a union of all
the other literals so here given the
cause the two causes above we've
constructed a new clause 2 negative 3
negative 4 and this causes imply
by the two causes above so this is how
we represent in our model and notice I
take two clauses and a literal on which
we're going to resolve and so in some
definitions of resolution you just take
two clauses and you get a new cause back
or something like that but here we're a
little bit more explicit we give the
actual literal to our function that
we're going to perform resolution on and
again the result of this is called a
resolve a'n't and the resolving can
either be a cause or tautology in our
model and the resolving is logically
blood and it's redundant with respect to
two clauses that are inter formula so
now we can combine resolution and
reverse unit propagation to obtain the
property that I'll be spending the rest
of talk talking about so this is the
resolution asymmetric tautology
redundancy property a rat property so we
say a clause Hazrat property with
respect to a formula if the cause had
the Rupp property or there exists a
literal L in the clause such that all
the non tautological resolve ins with
all causes and F have the rough property
so that's another kind of a bit of a
mouthful so let me show you with
pictures how we establish whether Clause
has rat or not so given a formula on the
left and the blue boxes or causes in
that formula and a potential rat calls
on the right we first construct all the
resolve ins with that clause and causes
in the formula then for each of the
resolve ensuite they have the Rupp
property or whether there are two Tala G
and if each of the resolve instead the
rut property or their tautology then we
say that the cause has the rat property
and so you may ask why do we need this
rat property why can't we just continue
to use resolution or reverse unit
propagation to establish our proofs well
it's because the rat property is much
stronger than the rub property so on the
Left I have the
I have the rut property which can use
these to express techniques such as
resolution cdcl learning and SAT solvers
unit propagation subsumption but all
these techniques only preserve logical
equivalence but there are some
techniques out there that only preserve
the preserve satisfiability equivalents
but not logical equivalence and so on
the right block clause edition bounded
variable edition extended resolution
extended learning all these techniques
preserve satisfiability equivalence but
not logical equivalence and they all
have the rat property but not the rut
property so now I'm going to show you
and this is probably the most code I'll
show in the whole talk so now I'm going
to show you how we compute our rat
property in a CL 2 so first we end up
because all we have is recursion we end
up immediately dispatching to a helper
function but before we do that we copy
our formula f so that we have something
to recur over in the next function so
given a formula clause in a literal we
first copied the formula and then we
dispatched to the helper
right
right yeah the copy costs nothing and
the it just shares a pointer so now in
the helper function we're given a clause
list now that we're going to recur over
a formula a clause in the literal and if
we're at the end of this clause list so
the closest is our kind of working thing
that we're checking through we're
checking that everything in the clause
list has certain properties so if we're
at the end of the clause list then we'll
return t which signals success for us
then we look at the first element of the
clause list which is a clause and we ask
if there's even a literal on which we
can resolve and if there's no resolving
literal then we'll just continue going
through the clause list and will recur
else will compute the resolving and here
we label it are and then ask if that
resolve a'n't is a tautology and if it's
a tautology then will recur and continue
through the clause list if not we'll
check it to see if it has the property
the rut property and if it does we're
occur and else we fail and so this is
the exact same kind of procedure I
showed you a couple slides ago with
pictures
so now I'm going to talk about how
redundant clauses can be used to
construct proofs and I'll give a
overview of a few different types of
proofs so we say a proof trace is a
sequence of clauses that were redundant
with respect to a working formula and so
I kind of got working in quotes there
because we're going to build a new
formula at every step so on the right I
have a formula with the four clauses
represented by the blue boxes and on the
right eye and on the right I have a
proof which is three red circles so I
want to take the first clause in the
proof and check to see if it's redundant
with respect to the original formula and
so here I establish the satisfiability
equivalent with the original formula and
now for the next clause in the proof I
just established its redundant with the
previous formula that we constructed and
I continue to do this until I've reached
the end of the proof and so now through
transitivity I've established that the
formula on the right is satisfiability
equivalent to the formula on the left on
the far left and a refutation then is a
proof trace that contains an
unsatisfiable empty cause so here now
the formula on the right the last call's
in the proof is the empty clause which
can't be satisfied and since that
clauses unsatisfiable the formula is
unsatisfiable and it's satisfiability
equal to the original formula and we've
established the original formula was
unsatisfiable so this is just a
refresher of some of the proof
properties i'm now going to show you
resolution proofs clausal proofs and our
rap proofs kind of pictorially how to
check each of these proof types and so
you can kind of look for these
properties as we go along so first a
resolution proof has a lot of
information in it it's one of the
reasons they're so large so here we have
every clause represented by a blue box
every causing the original form to
represent by a blue box and all of the
proof clauses are represented by red
circles
and here each of them has a label
associated with it so that we can refer
back to a specific clause so in order to
check this proof we take the first calls
in the proof and established its
redundant and we do that through a
series of resolution steps and so here
the clause is three six and eight we're
all used to establish the redundancy of
the of the new clause 9 and then we
continue to do this for each cause in
the proof until we reach the empty
clause and so these can be these
disprove this proof style can be checked
very efficiently but the problem with it
is that as you see there's a lot of
information encoded in this proof here
every resolution step is encoded
everything has a unique identifier and
these proofs are very it's hard for a
solver to admit all of these different
steps when it's trying to actually solve
the satisfiability of the formula so the
other another proof type is the rub
proof type and so here I have the
formula on the left again and the proof
on the bottom left and notice now that
none of the arrows are there at the
beginning there's no information about
the arrows or which causes are used to
establish the redundancy of other
clauses and none of the clauses are
labeled anymore none of that information
is necessary because at every step we
take a clause from the proof and we use
a unit propagation to establish whether
or not it's redundant and so here
there's some amount of search that needs
to take place for every Clause we
establish as redundant but as soon as we
establish a causes redundant we forget
all the relationships that established
its redundancy so these can be very
compact but they also require some
amount of search and so they can be very
slow
and finally this is what our rat proof
format looks like so on the Left I have
the formula again and on bottom left I
have our proof and the green triangle
represents a clause that has the rat
property but not the rut property so to
check this proof we first check to see
if this cause has the rut property and
it doesn't so then we check it for the
rat property we construct all the nun
teleological resolve interrupt property
these are then what if each of them does
then the cause has the rat property and
it's redundant and we throw these kind
of temporary clauses away and then we go
on to establish the next two clauses
with our rut property and we complete
the proof
so now I'm going to show you how we
modeled our proof checker nacl too so
given that we've defined the rut
property already and we define the rat
property we can say what it means to
verify a clause in our proof so we say a
clause given a clause in a formula the
clauses then verified as being redundant
if it has the rut property or it has the
rat property next we verify a proof or a
proof trace by checking that each clause
in the proof has been verified and so we
do that by first checking if we're at
the end of the proof trace if we are we
return t which signals success else we
check we verify the first clause in the
proof trace and then we verify the rest
of the proof with an extended formula we
model refutations by saying that app
route any clause list that's been
verified is a proof trace and proof
traces that contain the empty claws are
refutation
so then we can specify what what it meet
what a proof checker should do in a CL 2
and we do that by first establishing a
quantification predicate so here at the
top I establish a this is the so a CL 2
doesn't have native support for
quantification and it's logic so we do
that through having Scola mised
functions in a different way so here I'm
establishing just you can read it almost
like you would if it were part of the
logic it says that there exists in a
such that a is an assignment and a
satisfies the formula so in other words
there exists a solution for this formula
for a given formula in our main theorem
then states that given a formula and a
refutation for that formula that's been
verified by our proof checker then there
does not exist a solution for the
formula so in other words the formula is
unsatisfiable and so this is the theorem
that we were able to prove in a CL 2
about the code that I've shown you up to
this point so now I'm going to give you
a little bit of a sketch of what that
proof is like and it's a pipe yeah yeah
if there exists a solution for the
formula then either we wouldn't be able
to verify the refutation so or the so if
they're just a solution for the formula
in the bottom part would become false
which would then sorry if there exists a
solution for the formula then we
shouldn't be able to verify the
refutation and the for the first part of
the implies would become false and so
the whole term would become true
Oh
so let me give a very brief sketch of
what the proof of our main theorem looks
like so the theorem stay that if we had
a formula no refutation then there does
not exist a solution for the formula so
instead of we can prove the
contrapositive we say if there exists a
solution for the formula then we should
not be able to verify our refutation we
next prove that if the empty clause
cannot be redundant if there is a
solution for the formula so given a
solution we shouldn't be able to
establish the empty clauses redundant
next we show that every clause in the
refutation is redundant and this gives
us a contradiction with the first two
points and we prove something like this
using kind of our only well not our only
but one of our main methods available to
us in a CL 2 which is structural
induction to prove 3 we end up showing
that clauses with the rut property or
redundant and clauses with the rat
property or redundant and this is proven
using a case split on the evaluation of
this hypothetical existing solution with
respect to the calls we're trying to
establish as being redundant so remember
from one we have this kind of
hypothetical solution so if the claws
were trying to establish is redundant if
that evaluates to true under the
existing solution then we say it's a
solution for the cause as well and we
can admit it as being redundant if the
calls we're trying to establish that
redundant is undefined with respect to
the existing solution we can modify the
existing solution by taking one of the
undefined literals and adding it on to
the solution and finally if the cause
we're trying to establish as redundant
evaluates to false under the existing
solution then we need to take some
literal we need to take some part of the
solution and flip one of the assignments
in that solution so that this clause now
evaluates to true
and the problem with that there's and so
that's probably one of the trickier
parts of the proof is knowing which
literal we need to flip so that we don't
falsify any of the causes of the
original formula so that's a bit of a
sketch the full proof is in our code
which is online or you can also read the
paper for a more kind of detailed
description of the proof that's right
right and so the reason that this proof
is a little bit more difficult than say
proofs of I all right so I've completed
proofs of a verified Rupp proof checker
as well but the reason this one's
different is that in the rut proof
checker all you have to do is show
logical equivalence you just take the
existing solution and say that it must
be as continue to be a solution because
they have the same set of solutions if
they're logically equivalent but the rat
property is much more difficult to show
redundancy for because now you have to
construct a new salute you have to just
say that there is a solution not
necessarily that the same solution holds
and so you can continue to modify the
solution throughout the entire proof so
what I've shown you today is our model
for an unsatisfied bility proof checker
based on this generalized rat redundancy
property our specification for what the
proof checker should accomplish and a
proof of correctness in a CL 2 that
shows that our model meets our
specification and so our goal in this
work and moving forward is that we want
to increase the confidence not in just a
solver but all satisfiability solvers by
efficiently checking proofs with a
mechanically verified proof checker and
so this is some of our recent work on
the subject we have a paper that's
accepted for the journal software
testing verification reliability to
published papers in the conference on
automated deduction and interactive
theorem proving and a paper that's
forthcoming in formal methods and
computer-aided design and so I will now
take any questions you have and if you
want to ask about one of these other
papers I can feel questions about
efficiently checking proof certainly
that kind of stuff thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>