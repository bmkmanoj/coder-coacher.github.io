<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Monitoring the Snowpack in Remote, Ungauged Mountains from Satellite and Computers | Coder Coacher - Coaching Coders</title><meta content="Monitoring the Snowpack in Remote, Ungauged Mountains from Satellite and Computers - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Monitoring the Snowpack in Remote, Ungauged Mountains from Satellite and Computers</b></h2><h5 class="post__date">2016-07-26</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/-rluukoxXMM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so for those of you here they were here
last year for Jeff's initial talk this
some fellow work from Jeff Dozier from
UCSB who's going who had done some work
on the snowpack but wanted to kind of
update us on the latest activities from
his visiting portion this year so thanks
Jeff okay yeah I've decided I'd like
this title being an intern this is right
so all right so so what we're we're
looking at is the idea of trying to
really do snow hydrology in areas where
it's the runoff from snow is really
important and yet there's not much of a
surface infrastructure to really make
any sort of measurements so so this is
the Hindu Kush range of Afghanistan
we're looking at an area that's eight
times the size of the state of
Washington so it's you know we're trying
to run these models / / pretty large
areas okay and and the problem that we
face or that the people there face is
illustrated by this this advisory that
came out for the from the UN's
information on our Institute for
regional information networks that sort
of monitors conditions all over the
world and tries to sort of alert the the
international community that if
something is troubling and you can see
this is you know a fairly sort of
desperate warning and the problem is if
you look at the date on it it's came in
September after the harvest had failed
and so the question and is could could
you have done a better job and even
looking at passive microwave data we see
that this year in this basin in terms of
just the total amount of snow
it was a pretty low number and so the
idea is that we could have given that
warning in April rather than in
September and and therefore could have
better organized a response to it and in
fact it was ironic that the following
winter in 2012 was a fairly big snow
year and what and this caused the
problem of not being able to get food
supplies into places where people were
starving so you know one year of not
enough snow and then the next year of
too much snow than the combination of
those led to to a lot of starvation okay
so the problem with this though is is
one of the questions is is do passive
microwaves in fact give you a reasonable
signal of the snowpack in in the
mountain environment and so we've done
some of this work in the Sierra where
we've got measurements at the surface to
compare with we oh so what the what a
passive microwave signal does is ed know
it's satellite that way yeah and it's
it's 25 millimeter pixels or so the
reason is that the emission from Earth's
surface at those long wavelengths is
very small so you're not getting many
photons to count so the only way to do
it is you got to open up the you can't
get a very good resolution the principle
on which it operates is in the in the
microwave part of the spectrum snow is
is not very ice is not very absorbed and
so what happens is but it does scatter
the radiation so you get radiations
being emitted from the soil and then
it's being scattered by the snowpack
above it and scattering of course causes
extinction
and that's why you know a cloudy day
there's less Sun sunlight under the
clouds and so what happens is that by by
looking at the emission from the longer
wavelengths where you're seeing through
the snowpack and then looking at the
shorter wavelengths you're actually
trying to estimate how much attenuation
is coming of from the snowpack and
therefore the snow water equivalent now
the problem is if you if you compare
this with a method called reconstruction
that we've worked a lot on you can see
that it's an order of magnitude less if
you look at the numbers on the y axis so
the the in the mountains at least the
passive microwave estimates are only
seeing about ten percent of the total
volume and there are some physical
reasons about fur why this and so and so
therefore we've tended to focus on this
idea of reconstruction but you can see
this problem this this is a time series
map of the passive microwaves it let's
see i'd like to just make it go a little
faster but okay this is a daily map and
we know snow doesn't really behave this
way right it's you know flickering on
and off and so one of the questions is
well you know are there ways that we can
still use it and in order to figure out
that we have to have ways of estimating
the spatial distribution of snow so the
way I do this is I've got the passive
microwave data over here the nice thing
about them is their timely you get the
estimate of the snowpack right away but
a lot of uncertainty and very coarse
resolution from modis or from other
satellites but promoters I can get
estimates
daily estimates of snow cover and the
reflectivity of that snow and then from
the global land data assimilation system
we can estimate snow we can estimate
solar radiation and long wave radiation
and so forth and therefore we can put
that all together and we can model the
snowmelt day by day and we can't tell
with this how much snow there is because
in this part of the spectrum we don't
see through the snowpack we just see see
the surface but on the other hand if you
can model the melt and if you can tell
when it disappears then you can back up
that calculation and figure out how much
there was on a previous day and so the
idea is to do that we can we want to get
them the an estimate of the snow water
equivalent trying to figure out if we
can you know correct for the passive
microwave data and then you know the way
that this is used will be used in an
operational sense is we can put that
here into the historical context
automatically we can Carter to say well
is there reason for concern or not and
if the answer is yes then the army takes
that information then you know looks at
what happened in previous years and then
issues warnings so now what I worked on
for this summer is a computationally
intensive part of the problem figuring
out how to try to use cloud computing to
to help with this and the issue is I
actually need a I need to have a daily
value of the of the snow covered area
and along with that I get an estimate of
the grain size and the albedo so how do
we do this well
we start with you know we kind of try to
go to basic physics so the this is a
graph of the optical properties of ice
and water and this is the index of
refraction the kind of thing you learned
about in high school about how light
bends when it goes through the substance
this is the absorption coefficient and
I've actually got a a slide that kind of
explains what these are this is what the
refractive index the definition of the
refractive index how the light bends as
it goes through a material this is the
definition of the absorption coefficient
that is you get a decay as you're
passing the light through a pure
substance and you you normalize it by
the wavelength so that the absorption
coefficient can be dimensionless and
then if you solve that differential
equation you get a hello Tony so we were
just defining the absorption coefficient
so we we get we get an exponential to
gay now in order to kind of explain what
a number of an absorption coefficient
might mean I simply can take this
exponent and solve for the distance at
which this number is going to be minus 1
and so we can call that an e folding
distance for light as its passing
through snow or excuse me through pure
ice so let me back up do that and so
what we see is if we look at the e
folding distance for ice that it varies
by you know seven orders of magnitude
over the distance of the solar spectrum
so in the visible part of the spectrum
that number is you know tens of meters
so you know when you when you go diving
in hawaii and you're under the water you
can see a long way
and similarly if you were frozen in
bubble tree ice you'd also be able to
see a long way whereas when you get out
to the longer wavelengths that number
you know gets down to less than a
millimeter right and the consequence of
that is we can then you know put those
kinds of numbers into a calculation of
the scattering properties of an image
individual snow grain this used to be
really interesting and difficult
computational problem that is Gustav me
published his equations in 1908 of the
the first really fast and useful
solution to those equations by computer
was published in nineteen eighty seventy
years after the equations themselves had
appeared but I don't have to worry about
that that's been done now and been done
really well but what you can do then is
take those properties for scattering
from a single grain and you can do a
multiple scattering solution for what's
going on in the snowpack and what you
end up with is something that is
intuitively pretty obvious and so what
this graph shows is the reflectivity of
snow of deep snow for the wavelengths of
the solar spectrum for a variety of
grain sizes going from very fine grains
to coarse grains m125 deep
part four no five point two point oh
five is pretty small yeah that's that's
about as small maybe point oh three is
about as small as snow gift and then on
me on the right hand y axis I've got
that absorption coefficient plotted and
what you see is where the absorption is
low the reflectivity of snow is really
high and and it's not very sensitive to
the grain size right okay you know and
snow is you know across the visible
spectrum snow is white right and it's
white but if you look at an individual
Snoke great it's it's not white right
it's transparent right and so but the
multiple scattering makes the reflection
why so you know if if a child asks you
you know where does the White go when
the snow melts well you you've got a way
to answer it actual question is there a
two-division by certain wavelengths
I am failing having those weird spikes
like that oh those are those are
rotational and vibrational moments in
the in the quantum mechanics of the
absorption of ice rotational states of
the water love you well or of the I
small but but it's pretty either pretty
ice and water only shifted a little bit
in this part of the spectrum where is
out microwave ice and water really
different right but so but what you see
here is a couple of things one is as you
get out to the region where the
absorption is moderate then then the
grain size makes a difference so what
happens as a result of that is your as
the snow ages and the grains grow it
becomes less reflective because remember
that about half of the sun's energy is
out beyond the wavelengths of the
visible and then out here snow is pretty
dark and and that helps us distinguish
snow from cloud because clouds have
little particles that's why they're
still up in the sky and that's really
the difference between an ice cloud in
the snowpack is a snowpack is a cloud
that got big enough where the particles
got big enough that they fell out of the
sky and landed on the ground right okay
so what this means is that if you
compare snow to the other things that
occur on Earth's surface here's
vegetation here's different kinds of
soil first of all there's a lot of
variability in snow if you go out beyond
the visible snow is one of the most
colorful substances in nature but you
also see that if you compare it to the
wavelength bands of motifs that are here
that it it really is distinctive it
allows us to distinguish snow from the
other elements and out here we can just
we should clouds and their words snow is
about the only thing that is really
bright in the visible part of the
spectrum and really dark in what we
would call the shortwave infrared and
sensitive to grain size in the middle
between those so so what that allows us
to do then is if we have satellites that
have these the sort of spectral
information we can distinguish snow from
other substances and this is with
Landsat and this is very nice this is a
30 meter resolution but it's got a
16-day repeat pass because the swath is
only 185 kilometers and so therefore you
miss opportunities so a lot can happen
in 16 days and if that day happens to be
cloud covered and now you're 32 days
between acquisitions so we'd like to do
something a little better but this this
use of the shortwave infrared part of
the spectrum allows us to distinguish
clouds so here's here's the visible
bands and you can see the clouds and the
snow ER are a little hard to tell apart
but there's the if you use the bands out
in the the further into the spectrum you
can see that the clouds are are pretty
distinctive now to the blue no the
closet
who's he who's not well this is at
Eastern Sears this yep that's all right
so now what modus has is it's got very
similar bands to what's on landsat but
it's got a swath of 23 hundred
kilometers and so this is a modus tile
that is 1200 x 1200 kilometers so that's
you know one point four four million
square kilometers state of Washington is
180,000 square kilometers so this is
eight times the size of the state of
Washington so and this one we get daily
coverage all right but the spatial
resolution is 500 meters and so what
we're able to do is buy this with this
spectrum we can get around this are we
going at least compensate for this
course or spatial resolution by
estimating a fractional cover of snow
within each pixel so what this does is
we we can calculate what are called n
members so in this case this is the
green is the concentration the
vegetation the red is the concentration
of soil and the blue is the
concentration of snow and so we can we
can solve for each that's also a pretty
computationally intensive problem but it
is it can be done as a parameter sweet
it's because it's the you know each
pixel's computation is separate from the
neighbors so it's a nice a nice
application for trying to put on to a
cloud right and it works pretty well
this this is comparing what we get with
that 500 meters with what we get from 30
meters and this is the scatter diagram
alright so there's some things i want to
do with this part of the process but
that's not really what i focused on this
summer the problem is i do want to get a
measurement every day and sometimes what
you see is you get clout and you so what
so what I'm thinking here of this is
this is now a data cube so this is the
the plane is the spatial dimension and
this it's in a projection so these are
kilometers north and south on the left
and east and west and then date on that
axis and the the the red color it shows
the absence of data so I you know I
picked it I'm not sure it was a great
choice but on the other hand there's
holes in my data so it's bleeding right
and and so we can look through the
through the year or in this case just a
thirty two day period and and then so my
my first step is in trying to get to the
daily data is to use a three dimensional
laplacian to to try to fill in those
holes right but but I don't mess with I
don't change any of the observations
themselves okay and you can see that you
know we we get something where the holes
are all filled in but but where it still
looks pretty messy alright so so we need
to have and this this is the thing that
makes it kind of a tough comer a harder
computational problem is that these
really are three dimensional data where
there's a lot there's lots of
neighborhood effects because sometimes
we want to slice the data this way
sometimes we want to drill down through
the
column and so in trying to to sort of
fix this to make it smoother we can we
want to be able to use some some
knowledge about what we have so there's
a couple of different kinds of glitches
in the data this is a pretty clear of
day so what we end up with those we have
both low frequency dropouts caused by
the clouds but we also have high
frequency because some of the sense some
one of the motifs bands is is starting
to go bad a little bit it's got some
periodic noise in it indicated by these
little red dots and if we look at it in
if we zoom in on some of these areas we
can see again both this low frequency
noise that we can identify but also some
high frequency noise so and and not only
that we we see this this break in this
image right in the middle of and and
what the reason for that is in this case
this image was stitched together from
two different orbits so so part of the
cause of this variability is the fact
that we're getting this wide swath you
know of two thousand kick more than
2,000 kilometres from only a seven
hundred kilometer orbit and so that
means you got to be looking at things
that are pretty high viewing angle right
so this is a map of that images and it's
what we would call the sensor viewing
angle so that's the angle up to the
satellite if you're standing on the
surface all right so it's if it were a
plane parallel system that would be the
same as the nadir angle from from the
sensor but because the earth is curved
those two numbers are different now the
problem is what happens as
you're so where it's blue it means that
that place was right underneath us at
this time of the orbit where it's red
you know we're up to 60 degrees or so
off nater off the zenith we're looking
at it and this this thing in the middle
is where the two orbits were stitched
together so what that means is that at
the edge of the swath so the pixel right
underneath the satellite is five is half
a kilometer square the pixel at the edge
of the swath is about five times one
kilometer so it's ten times as the area
at the edge of the Swan so that's so
that's part of the problem that is
introducing some of this noise into the
image is that on different days you're
actually looking at a different piece of
real estate on the ground that you're
and you want to try to put together a
you know how do you put a a picture
together so I think what this is it it's
a class of smoothing problems that where
I have more confidence in some of the
data than I do in other part
measurements and so I want to adapt a
smoothing method that in fact takes
advantage of the fact that I have a
physical reason for having more
confidence in some points than others
and so what I do is I actually use a
smoothing spline but I wait the
smoothing spline inversely to that
viewing angle were you raising your you
have to do with
you know the deeper their column and
then we'll moisture oh that we actually
start with an atmospherically corrected
value yeah but so that I guess the point
is is that if I have a bunch of clear
days then then the off Nader shots don't
contribute very much to the signal and
you know they pretty much get ignored in
the smoothing algorithm but on the other
hand if that's the only view i have in a
two-week period then i'll use it right
ok so this so that's what results ok so
hmm this is it this is each soap
that's first time T okay so what it is
is it's it's that same cube that we've
looked before and it's showing every day
from over a thirty two day period
smoothing that you as a result it was
moving but I think it's pretty good yeah
yeah it actually looks much better than
the other q yeah yeah that's the idea
yeah so it
definitely you can see that there's
where before they would flicker on and
on yeah not it okay so it works really
well I I'm really pleased to have done
this this the only problem is this is
this is just 800 pixels by 800 and it's
only a 32 day slice so this is a ninth
of a modus image and and a 12th of a
year and this took this took about two
hours yeah its own clock time Walt I'm
the azure well actually I ran this just
on one note by this is but I know now
how to break this up and that's an wen
Ming steering we're gonna do that I've
got I've got another week in other words
what what I'm going to do is is use so I
do the the laplacian smoothing over the
full tile you know of 2400 x 2400 and
then what i'm going to do is divide that
into nine parts and then take the whole
your column and do this moving on the
whole year and that's a way of getting
by the of actually taking advantage of
multiple things okay and then the way
that the reconstruction works is once i
have that then i can run a snowmelt
model and and the way I do that is is
this is illustrated with measurements
from a snow pillow that if you know if
you don't have a snow pillow but if you
if you know what day the snow goes away
and you can calculate the rate of melt
then you can back up and figure out how
much there would have been and so this
gives us give us a couple things it
gives us a spatially distributed
estimate of how much snow there was back
back to about the peak of the snow
right and so that allows us then to
compare with passive microwave data it
also allows us to compare with models
because one of the problems in in
especially in precipitation models is
you've got a grid you're modeling at
some spacing on the grid of 10
kilometers or 150 kilometers or
something like that and how do you how
do you compare that to a measurement you
know what is it you compare to well now
we've got something that we can use to
compare so so the way this works of this
we've compared this in the Sierra where
we've got surface measurements with
measurements at snow courses which are
the ones done monthly by people skiing
through the mountains and poking a tube
in the snow and weighing it and then
also with snow pillows which are an
automatic measurement and the good thing
is obviously there's some error in that
but but the error is centered around
zero so there doesn't appear to be a
bias right and part of the error is that
the snow pillow is only representing a
point within a half a kilometre pixel so
it so the snow pillow is not a perfect
measurement either right and then if we
if we compare the compared to the inputs
from we we have estimate the incoming
solar radiation pretty well air
temperature we do pretty well a a little
bit of a bias in the incoming long wave
radiation that could also be a
measurement problem that that's a
difficult thing to measure at the
surface and in the Sierra Nevada there
really only three long-term stations
that do it well the reason it's
difficult is that you're measuring the
same thing your instrument is emitting
the same thing you're trying to measure
and so the temperature compensation has
has proved to be hard with those okay
and so so is this reconstruction is
giving us a good answer because we have
other methods at least in well
instrumented place of places of getting
alternatives one is we if we have a lot
of surface measurements we can just do a
spatial interpolation or if we have a
lot of surface measurements we can do a
data assimilation model and the
reconstruction is in fact showing
greater amounts of snow than any of
those so are we right or are they right
right and here here's our estimate that
shows that the reconstruction is right
so what we've done is to use the
streamflow in these basins do a
calculation of evapotranspiration and
then how much change in storage it is in
other words taking the hydrologic
balance equation and then estimating the
precipitation from from that backing it
out and the both the interpolation
method and the assimilation are giving
you some negative numbers and a negative
precipitation can't happen right okay
actually fine does Q is discharge in the
river he is the evapotranspiration and
delta s is the change in storage from
ground water okay and usually over long
timescales that's going to be small
right so it's a way of backing out the
precipitation estimate and and you hope
that when you do that your precipitation
estimate ends up being positive right
and in in the case of the reconstruction
for 12 years 19 drainage basins our
number the numbers from the
reconstruction are all positive right
whereas for some of the others the
reconstruction is showing negative
values for some so and then we've got
others so the way that we part time is
running backwards
choking oh okay so the way we we do this
again this is another kind of
computationally intensive problem but
this is we can do day by day so it's
pretty easy thing to move on to Azure so
we take the shortwave radiation estimate
from from the either the national the
global land data assimilation system the
upper left shows the resolution at which
those day to come in which are in this
case are an eighth of a degree we smooth
those to the size of the modis pixel and
then we scale it based on the topography
so because the problem is in that eighth
degree pixel there's a lot of
topographic variation and so we we scale
it just doing a pressure scaling
relationship then we bring in the slope
and exposure and then we we calculate
for attenuation by vegetation we've got
then a map of the albedo we then
estimate how much radiation solar
radiation is being reflected back upward
and what we end up with is a net so that
goes in that's what energy that goes
into belt and then we do something
similar with the long-wave radiation but
all in the interest of time I'll skip
that detail but again that takes a lot
of computing but that's pretty easy to
parallel us because each day is
independent of the other days alright
and so if we do the same thing for the
hindu kush in this case this is just
showing the the data for a day we can
get you know over a mountain range
that's that's very large i mean some of
these drainage basins are the amo Daria
itself is slightly larger than the state
of Washington it's two hundred thousand
square kilometers
so we can get each of these inputs to
the model over over every pixel and then
we can calculate how much mouth is
coming from the radiation what's coming
for the lane sensible latent heat flux
which is a function of temperature and
humidity and then we can get all the
melt for a particular day and then we
could do it for every day for for every
year and so this is showing the the
variability that we've seen in in the
years 2008 is missing this is my my
colleague Carl Ricker was running this
on the on the Linux cluster at Santa
Barbara and he there's a difference in
lenox between the RM command and the MV
command and he typed RM instead of envy
for after he done all these calculations
for 2008 but on the other hand it made
it easier slide with only trying to put
four years instead of five um ok that's
they do good yeah yeah this is the
Wakhan corridor on the right this is a
sinusoidal projection that is so it's
okay so so I learned how to use a sure
sort of with when beings help and and I
and I think I learned I figured out how
to deal with the hardest parallel part
of the problem which is the fact that
we're dealing with something when yam
but it's a general problem of dealing
with three-dimensional data where you
want to sometimes slice this way and
sometimes you want to slice that way and
then the rest of it is is I think easier
to run in parallel because once we do
that then we can run day by day and you
can't well I mean now I'm wandering into
territory where most of you know more
than I do but but I guess the the issue
is that in the blobstore really the what
you can do is get input that that you
can't reach into the blobstore and read
part of a file okay so you actually have
to either well I don't know I I don't
want to say it it's too bad because the
I'm storing these results as hdf5 files
which supports block compression so that
you can read a piece of it even though
it's a compressed file but you got to
get it out of the store in order to read
it so I think the alternative is is to
take those those chunks that is to turn
every image into an into a nine by nine
are three by three so turn every image
into 8 images and then I can
parcel those out to individual machines
so this was all the calculations you
need to do sculpt it snow cover of this
particular region of four years and what
why then oh ok so what what you now have
is let me go back to this
sorry about that
it was right at the beginning her yeah
so I saw miss this okay so so what I've
got is is it I've got methods in which I
can estimate the snow cover while during
the year in real time because this
reconstruction you only get you get a
wreath you get the answer but you only
get it at the end on the other hand what
we show is it's a really good answer
okay and so and so what we now have is
something that we can use to compare
with say estimates from passive
microwave and end with Noah is
developing a central asian snow
accumulation model but you know they
have they have no way of validating it
and so this this gives us a method of
validation for for that kind of a model
and so there in fact I'm meeting with
them at toward the end of this month
because they're they're really you know
they keep asking us you know for the
reconstruction results for the past
decade
and then if we can figure out how to
help with the passive microwave data the
advantage you know as I showed before
you came in they did that only sees
about ten percent of the snow okay but
if we can figure out how to correct it
than that geophysical time series goes
back to nineteen seventy eight and so we
can then do a better job of sort of
putting any current condition into the
historical brat as part of the
historical narrative because a lot of
what we can and I mean in general
management of water works pretty well
when it's when you're kind of near the
median you know and so that's how part
of the idea with this is can you
identify the years that are at the two
tails of the distribution you know is is
this as you show the new clue look more
or less the same well they there was in
the cobble part of the watershed there
were there was flooding in in 2007
yeah so I know we're Cowboys on that
it's it would have been what's the part
that's draining to the south and that
and that does does show in 2007 so it
and and by and large one of the things
that really helps in insert of
management in the especially in in
places where simply giving a volume in
cubic kilometers or acre feet or any
sort of unit isn't going to mean much
anybody but if you can put things in
historical context you know if you can
say that this year is it's a comparable
to 2007 when there was flooding or
comparable to 2011 when there was
drought then even the villagers will
will remember what things were like in
those conditions and and therefore you
know knew what got flooded then or in
the case of drought how badly the crops
did then the less resources early on and
you can immobilize
well like again but what happened in
2011 is there was a big drought but they
find long so again
yeah it's probably easier to
look
so two thousand oh seven eight was a
flood 2007 in the southern part here was
was a
and the other I'll see much difference
yeah
um that's true we're that the
interesting thing about that year and
and about 2,000 in 2011 is the the snow
covered area was pretty similar even
though the depth of snow was different
so
the interesting partisan is this like
he's of layering that up with the basins
where they record goes out and then also
the populations
that you can use carefully
do it thanks very much good
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>