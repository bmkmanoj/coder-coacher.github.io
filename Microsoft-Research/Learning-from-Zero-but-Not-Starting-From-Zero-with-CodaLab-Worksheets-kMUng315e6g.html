<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning from Zero, but Not Starting From Zero with CodaLab Worksheets | Coder Coacher - Coaching Coders</title><meta content="Learning from Zero, but Not Starting From Zero with CodaLab Worksheets - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning from Zero, but Not Starting From Zero with CodaLab Worksheets</b></h2><h5 class="post__date">2016-07-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kMUng315e6g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning everyone it's a real
pleasure to have / Cillian here with us
for the day actually Percy is an
assistant professor and in the computer
science department at Stanford
University his research interests
include modern in natural language
semantics and also developing machine
learning methods that in for info rich
Layton structures from limited
supervision just this year he has lots
of awards I think very recently from
each kind he had an award the esky
computers and thought award also in 2016
and NSF Career Award 2015 last year
alone research fellowship I should also
mention that he was a max of research
faculty fellow in 2014 and I believe
versus has also been an intern the few
decades ago without matress of free one
decade ago not a few decades all right
just one today Percy actually has two
parts in the talk you will have today
one part is a research talk and the
other part address is one of his passion
which is about making research
reproducible fully reproducible and he
would be talking about kodala which is
actually an effort I've had the player
and pleasure and honor to to work with
Percy and interact with him on that
project so with that please let's
welcome Percy thanks everything for the
introduction and thanks to all of you
for coming so as you can tell from the
title there's really two parts to this
talk and so I think the time is
scheduled to go until 12 but I'm going
to no one wants to really sit through an
hour and a half of me talking so I'm
going to try to kind of breeze through
the first part but please ask questions
if you have any okay so to begin we live
in the era of big data there's so much
data that we don't know what possibly we
can do with it unfortunately you know
there we've been seeing a lot of success
using deeply
techniques to handle this data and it
has led to a lot of advances in speech
recognition vision language and so on so
what more could you possibly want well
so there's this a story of you know a
guy who's looking for his keys under the
lamppost and police officer comes to him
and says why are you looking under a
lamp post and he says well that's where
the light is and sometimes i feel like
the research community also is kind of
like this where we look under you know
we live work on these big data problems
because that's where the data is okay
but this is not what this talk is about
this talk is about the shadows about
places where there isn't data and we
want to still do some learning so what
could possibly be here of that sub
interest so I'll give you two anecdotes
from my own personal research so a few
years ago I was talking to shannon
peters and chris raid they had created a
database by extracting facts about
fossils and I said hey wouldn't it be
great to build a natural language
interface so that researchers and
students could go and ask questions
about this database and understand
basically fossils and how life of or a
rose better and I asked the first
question I said well you know what kind
of questions would you like the system
to support you have any examples maybe I
can train a model and of course the
answer is well you know the system
doesn't exist there's no users so then
there's no data here's another example
more recently I've been talking to mount
a clam who's at Stanford who have
developed this thing talk which is a
language for querying the Internet of
Things in a safe and secure way and
again the same script goes can we
wouldn't be cool if we build a natural
language interface so you can go talk to
your fridge or something and you know
again there's no users so we don't have
any data so both of these examples and
you can probably find more from your
personal lives is a problem where we
don't have a system so then we don't
have users sitting there and talking to
a non-existent system so there's no
users so
we really have nothing okay and so how
do we bootstrap from zero and i want to
emphasize this is not unsupervised
learning so unsupervised Lorraine's I
says okay I don't have outputs but i
still have inputs and i can go maybe go
annotate these outputs or i can do some
sort of supervised learning really we
have nothing ok so I think I've made the
point clear enough ok so let's formalize
this setting mathematically ok so here's
a set up so your boss comes to you and
says we just signed a contract that
we're going to build human level NLP and
we're going to ship tomorrow ok so so
what do you do well the first thing you
should probably do is just quit but the
if you don't want to quit then you can
come to my talk and I'll tell you what
you can do about this so I'm going to
talk about three avenues of dealing with
this this nasty boss ok so the begin
with this is a HCL paper from last year
with you she and Jana pen an idea is
just to set the stage we're doing
semantic parsing which has been a kind
of a research area of right for the last
five years and the idea is that in
executable semantic parsing we're taking
sentences we're mapping them onto some
logical form or program or database
query that can be executed on a database
to produce the answer so you don't have
i'm going to show you logical forms that
look like this you don't have to
understand the details but you can see
that this is the set of articles the
things that appeared in a CL intersect
and count them up so it's some sort of
little computation and so this logical
form connects the language to the actual
answer and there's a long history of
semantic parsing over the last two
decades you know Luke zettlemoyer a
mooney did a lot of seminal work and
recently there's been a lot of interest
with you know the rise of Syria and kind
of to return to kind of the interest in
deep language understanding what I
really like about executable semantic
parsing is that it kind of really
connects language to something that the
user would want in the real world so how
do we go about building somatic parts
also traditionally you
go and maybe get a bunch of sentences
somehow maybe you just write them down
maybe you asked people to write them
down for you and then you go annotate
them with logical forms or if you're a a
bit more clever you can annotate them
once sent answers and then you can infer
the logical form so we've been doing
this for the last five years but the
problem is sill dad this is pretty ad
hoc and it has in complete coverage just
to give you an anecdote three years ago
we released this data set web questions
which was you know one of the kind of
the first large-scale keyway data sets
but then we realized that there were no
numerical relations and thurs that it's
like oh shoot you know what a big
omission so instead of starting with a
language which is the ad hoc why don't
we start with what we have so what do we
have well we have a database or if
you're building a natural language
interface into a fridge you have a
fridge or your car or whatever and so
each of these databases gives you a set
of you know relations or primitives like
author publication date and so on and
what we're going to do is take these and
combine them in all sorts of different
ways compositionally to create the
logical forms and then we can go and ask
people how to target this logical form
using natural language and this gives us
examples of sentences logical form pairs
okay so there's two okay so I'm going to
skip the slide so there's kind of two
challenges one is that this number of
outputs is infinite this is the whole
point of semantic parsing is that you
can target an infinite space so you
can't just go through and ask people to
enumerate give you national language for
each of them and the second challenge is
that even if you could you go and ask ms
on mechanical work at erker hey give me
some natural language for this this is
just not going to happen okay so how are
we going to deal with the two challenges
first let's look at the problem of
infinite output space so clearly you
shouldn't need to gather all infinite
logical forms so because of
compositionality right so if I have
these two sentences after 2011 nacl that
I really kind of don't need this because
I've understood kind of um if I
understood anything about language then
I know I should be able to connect these
two and this is the kind of a good case
but even if you have you know after 2011
if you get these two sentences before
2016 then if you look at how what is a
natural way to realize this logical form
it's between between it's not after and
before right so then there's a case
where the alignment between the natural
language and launched perform isn't
perfect and you probably would want me
to see this to kind of capture of
language but the key idea is that on
this type of alarm call me kind of bound
lineman mismatch is bounded it's not the
case that you have arbitrary length 20
logical forms mapping to arbitrary
length 20 sentences you probably have a
little bit of non compositionality
locally so so we'll see how this comes
about later ok so challenge to we're not
be going to be able to show people
illogical forms so what happens if we
just show the natural language ok so
let's show the natural language but
actually generating natural language
from logical forms is basically just as
hard if we want to get most cited
articles NCS but the the I guess insight
is that there are many ways in natural
language to realize the same semantics
and indeed that's kind of the power of
natural language is that you can say any
of these and you'll canonicalize to the
semantic perform so by reversing this
process what we're doing is saying okay
why don't we just choose to generate
some utterance all we need is some
endurance that captures the semantics of
the logical form and is understandable
and we're going to weaken the assumption
a little bit we're going to generate
things like article with field CS at the
most article side so it's not very
fluent but you can read it understand it
ok so what we're going to do is we're
going to write down a small grammar that
defines a set of candidate
forms and what we call the canonical
audiences so these are uh Turin sasara
standable but not perfect English and
we're going to do them up to size three
so remember the bounded non-alignment
mismatch so we can do them up to size
three and then now we take these
sentences and then we go and ask our
Turk workers to write them into more
fluent English so one thing that I was
kind of a side effect of this project
which was kind of cool is that you know
that allows katzen that allows dogs
actually becomes pet friendly right so
there's a lot of kind of compression
that goes on and this is kind of
exposing the fact that you often have
these kind of almost macros in language
so individual words that actually expand
to a richer semantics ok all right so we
did some experiments we looked at eight
domains you know we basically went
through and generate logical forms
canonical audiences ask people to
paraphrase them and then we trained a
centered semantic parsing model and here
are the results so we compared kind of a
baseline model with some paraphrasing
features and then our full system and
using the lexicalized features is a
substantial improvement over the the
baseline and the point of this is that
if we try to train a kind of a generic
model that handles all domains that this
doesn't work very well and we kind of
really need this domain specific jargon
right so you might imagine oh why don't
we just build one somatic parser to rule
them all and not you know then we're not
really in this learning from zero
setting but but it turns out that in new
domains you actually because you're
doing nth and language understanding you
actually need data in that domain to
figure out what to deal with it okay so
the summary of this section is the
huddle will take away is that when you
have kind of no data you can actually
bootstrap it by if you have enough
structure on your output space you can
generate the outputs and then go
backwards to figure out what the inputs
are and I think we there might be other
ways of exploring these ideas and other
domains ok any questions before I move
on so you know peace I'm looking cool
then decide what up on all these movies
so this is an accuracy of the answer so
we trained a somatic parser and then we
had a test today huh what was of this so
we gather this data set we split it up
into train and test yeah yeah so when
you automatically generates these
logical forms for us your structured
data like knowledge base there will be
many other phones that are not sensible
yeah yeah not corresponding to
interesting question button how do you
deal with that yeah that's a good point
so there are a lot of logical forms
which are just kind of weird like before
3pm n allows cats and in those cases
it's not bad we're just going to get you
know kind of a strict compositionality
right and because we're only going up to
size 3 we're now wasting too much effort
and you know exploring kind of not
interesting in logical forms in the
future what we'd like to do is if we go
up to size 3 and then we realize that
maybe before and after when they come
are together that's interesting then we
can explore larger logical forms that
only have kind of interesting sub
components and kind of like a best first
search these bones in the first place so
we have a bunch of primitives and then
we just saw an them or the join the
military logical ops I think so sue not
impose on oh but not be better so
they're going to be valid because we
have their programs right so we can
execute them if they don't if they crash
them there
some person why you to say this is
something that's tough on batting you
have database to startle ya so starting
with zero language okay from the
language point of view yeah okay let me
move on since I have a lot to get
through okay so at this point you go
back to your boss you say okay great we
were able to deploy eight different
systems overnight and then your boss
says well you know you only got fifty
eight percent accuracy that's really not
good enough and i really want ninety
percent accuracy at least ok so now now
you should or maybe quit but let's so
let's stick it through and see what are
you LM college for the black but you can
perform whatever database knowledge you
buddy the base angel whatever don't make
water um it's not traditional transfer
learning where you have one
classification problem in another class
but he is using knowledge yeah okay so
this is a project with Keenan Aruna
Chris Manning from nips 2015 and the
situation is getting a little bit more
dire you have zero data and you still
want high accuracy okay so what are you
going to do well we have to change the
the spec a little bit so so we're built
on the seminal work from the 18th
century where you have the Turk which is
allegedly this machine that plays chess
but it really has a human inside ok so
what would but it would be kind of lame
if I conclude this part of the talk by
saying okay we're just going to have
humans do it and you know but so we're
going to go a little bit further and do
what we call on-the-job learning and the
idea is that this machine or this young
chap is you know on the job making
useful horseshoes or whatever and if he
doesn't know something he can ask the
the machine in case this old master and
over time he's going to become better
and better and asked the master less ok
so we're going to formalize this
intuition scaling back from the kind of
semantic parsing just to kind of
sequence labor line and so the
motivation app motivating application is
that you have a
natural disasters a stir and people are
tweeting left and right about kind of
where food and shelter is and you want
to be able to build a named entity
recognizer kind of on really quickly
okay so what we want to do is take
sentences and label them with either
resources or location or other so we use
a standard conditional random field
model where there's edge potentials and
node potentials and so here's a key
slide that demonstrates how we're going
to ask for help okay so we have a
sentence come in and initially we don't
know what the true labels are but we
have this CRF model that gives us some
sort of indication and so at this point
we can't we can predict but we're
probably going to be wrong so what
instead we're going to do is ask for
help we're going to request at y 1 and y
3 tell me the label okay so this is kind
of the state of the system and you wait
the current time goes and then at time 3
maybe this one comes back and says oh
this is a resource this one still hasn't
come back you wait a little bit more
this one comes back with person maybe
you don't trust this actually because
George is a person but in this context
is not a person suppose you suspected
something you can ask another turker and
wait some more and then this comes back
maybe at this point you say ok I think I
have enough information and now you can
on basically do inference under this
graphical model which is original CRF
with additional potentials and I'll you
predict the right answer ok so here the
idea is that because you have these edge
potentials you don't need to query
everything and so the question is which
position do query and when do you query
them because you're also in this kind of
temporal online setting so there's this
kind of trade-off between accuracy time
and money right you can spend more money
ask more people to get more you can
query more positions to get more
accuracy you can also reduce the latency
by asking a hundred people to prove
label every position and then just
whenever people come back
you know the take them in that's going
to be earlier than like the mean for
example but how do you actually kind of
um you know formalize this because this
is kind of get pretty confusing and
quickly so what we did was we formalized
in a kind of Beijing decision theoretic
framework the basic idea is we write
down what we want and now we just
optimize and do the vision thing of
course this is kind of tricky
computationally so I'm going to talk
about how we deal with this so the
clearest way to see what is going on is
via our game tree so the game is between
the system who's trying to make queries
and the environment who is the crowd
okay so in the beginning what are the
choices well we can ask for the label of
y1 or we can ask for a label y 2 or we
can just wait and see what happens so if
we ask for y1 and then maybe we're asked
for y2 and then maybe we wait so when we
wait the control passes to the
environment and we wait for some turker
to come back and there are many things
that can happen so some random amount of
time could elapsed and then we could
either get the query the response to y1
or Y 2 because both y1 and y2 are in
flight and they're kind of asynchronous
and each of these could come back with
either resource location or other so
there's kind of many possibilities here
and then once we pick one of them then
we continue the game okay so let's delve
into this one a little bit to talk about
what in dynamics of the system are so
the Dynomax specify a transition from
one state to another state where
something has been returned so we model
the time elapsed as a simple gamma
distribution and we have a CRF model
which conditions on the sentence but
also all the all the responses that we
gone so far that defines the possible
distribution of row correct labels Y and
then
because there's a human error we say
that with probability point three we get
a random label ok so this specifies the
distribution of our new states given
previous states which events is time and
gives us kind of responses to one
particular query ok so at the bottom of
the game tree we have this final state
where the final action is turned in and
to assess this here's where we just kind
of write down what we want so we have
remember we want accuracy we want to
minimize the amount of time that we
spent and then we also want to minimize
the number of queries because where
every query we have to pay some fixed
amount of money ok so in conclusion we
have this game tree with basically we're
trying to compute the max over all
actions and over here we're trying to
compute expectation with respect to the
environment and that the bottom we have
some kind of our betrays a cost function
so this is clearly going to be really
intractable so we use multicolored
research and I'm going to skip the
details we have one issue that we need
to do it with uncountable number of
transitions but I'm going to skip this
in interest of time yeah a quick silly
question so this formulation looks sort
of sequential in the sense they sort of
like request one thing at a time from
the crowd yeah and then so this doesn't
have to be because here I'm requesting
y1 and y2 and then waiting so when you
way to your return action so yeah this
would actually be equivalent to do
select and y 2 and y 1 god I oh yeah ok
so I'm going to skip these details you
can ask me later so the just as
summarized the final algorithm the
system is going to receive an input
sentence from the user and then while I
don't have enough confidence to turn in
the answer I'm going to run MCTS to
compute the best action which could be
great weight or turn in and then if I'm
waiting then I actually get a wait for
the human response and add it to my
state
and then at the end we're going to
return the ark max over the truth the
labels and then we're going to update
the parameters okay so i should point
out that we are this is kind of the big
using beijing decision theory but only
in the kind of inner loop of making
predictions so this aspect of updating
the parameters lies outside the beijing
decision theory so we're not choosing
actions to tell us how to learn the best
model where I'm choosing actions to make
the best predictions here inside the
tree is implying proud a good time was
it's done I the tree weld not
conceptually no because in the beginning
you have the entire game tree and as you
progress the game you walk down the game
tree and then you're only searching the
sub tree they're just kind of like in a
normal game okay so we don't did some
experiments on this named entity
recognition compared what happens if you
query every position five times using a
simple threshold baseline in our full
system and here the adaptive systems
outperform the that's basically having
five votes or the adaptive systems
outperforms you know only query in each
position once or three times if you look
at in terms of accuracy or f1 in terms
of latency you see that the adaptive
methods are which were getting equal
accuracy or a little bit better accuracy
than this are doing much better than
asking five queries for everyone and
then also we save a lot of money by
using kind of our vision decision theory
system what are the units for time time
is seconds or milliseconds rather here
so this is milliseconds per query
yeah suppose you have to hit the lump
our number one pound to to wait no three
terms money did you put that yeah we're
doing a hug yes I mean we just fixed it
to some people I don't remember what the
constants were but you can play around
if you value money or time lor yeah um
I'm going to actually skip this and just
actually conclude so here the basic idea
is you in this kind of complex
decision-making problem where you have a
synchrony and then you have to make
requests we saw that Beijing decision
theory gave you some guidance on how to
write things down and if you wanted to
you know adjust your time accuracy trade
off so you can kind of do that
declaratively and one thing that we like
to consider in the future is considering
other types of operations besides just
squaring an individual position which is
very low level in semantic parsing in
particular you can ask people to label
logical forms will get the answer maybe
paraphrase and this framework would
actually allow you to learn which one of
these questions that you ask the crowd
would be most effective okay so going
back to the boss you're saying okay we
got ninety percent accuracy actually we
got 88.5 accuracy but you round up okay
it's okay and the boss says well we are
bankrupt because you spend all the money
on you know mechanical turk so um okay
so now what do you do or you know if
you're probably quit you like you know
two months ago but there is a third part
of the talk and I'm going to try to
salvage this situation so here we really
have to change the setting okay and to
do that let's so this is actually coming
out at ACL this year so it's sooo des
and Chris and the situation is really
dard you have zero data you have 0 money
and you want still something good so
obviously you can't get one hundred
percent accuracy or anything
that but you want something good okay so
what is this good something well let's
take a step back right what are we doing
okay so we could be building natural
language parsers or we could be in the
business of you know making interfaces
that so that the users can get whatever
they want done they want to send their
email you want to find directions to the
airport or whatever and so from this
perspective if they were able to achieve
their goal then we should be happy so
let's change the the setup and to kind
of evoke kind of the spirit of what
we're going to do so VidCon Stein in
1953 and his philosophical
investigations famously said that
language derive its meaning from use
right so we often think of language
alice is in the language person you
think about the meaning of sentences and
the structure and the syntax and all of
this but really I think you know vision
Stein was pointing out that the I the
meaning of language is actually fully
contextual it depends on how it's
getting used and he introduces idea of
language game where people this kind of
almost thought experiment where people
can actually develop a primitive
language through the context of some
activity or goal ok so what we're going
to do is to operationalize this in a
simple setting which Creek all children
should learn in homage to sure Terry
Winograd sure Lou from the 70s and the
idea is that there's a user and a system
and the user sees the goal but the
system does not and only the system can
perform actions so in this case you want
to remove this red block but the user
obviously using human he knows language
but the system importantly has no
knowledge of language okay so this is
what happens we have zero data you have
no language so what the user is going to
do is is going to say something the
system doesn't really know it's going to
generate a bunch of hypotheses and then
the user is going to give feedback and
say this is the one I want and this
system can actually execute this action
avance the state and the game kind of
goes on okay so this is kind of what it
looks like
first oh ok so I'm going to say let's
see what am i doing remove let's say
remove orange ok so it doesn't
understand what I meant so I'm going to
scroll through I'm prudence pushing the
down arrow and scroll through to
something which I want and then I'm
going to click check and then I give
feedback to the Machine and now if I say
remove orange you know you can know what
I mean it doesn't understand colors so I
have to really teach all the colors
remove red but once I taught a color it
knows what it's talking about remove
brown ok so now I'm adding orange to
write most block and then I have to
scroll a little bit and then so on so
I'm not going to go through all this is
actually demos online you can go play
with it but over time you get into more
kind of interesting configurations and
also rich your language ok so the idea
is that through the process of the user
playing this game the game objective is
just to get the goal it's not to do
anything with language but you're forced
to in some sense through the
construction of the game to teach the
computer some language ok so there so
that's a setup I really want kind of
language to follow out from some goal
rather than oops then just kind of hand
specifying what deserve a lot of we want
ok so what are the logical form so very
briefly we have logical forms that so
here is all the blocks which are brown
oops leftmost brown block all but the
less most lap around back and remove the
all but the leftmost brown block so you
can kind of get an idea of the
composition of structure here we use a
simple log linear model with and
learning is just a single stochastic
gradient update we went to mechanical
turk we had a hundred different people
play this in their own parallel
universes and teaching the language
their own language to the computer right
we explicitly did not
right examples in English because we
didn't really want to bias people we
just kind of actually this is partly a
cog psych experiment we want to see how
people react to this setting and then so
here's what we got so here are the
players who were the best ranked 1
through 20 out of 100 which means these
were the people who required the fewest
number of Scrolls so 3 on average and
you can see that there's many ways to be
successful you can use basically
something like English or you can invent
your own shorthand and those computer
just learns whatever you talk time it ok
if you look at the average players
you'll see that either people were less
consistent with their language juice
which made it harder for the computer to
learn or sometimes people had a mismatch
between what they wanted and what the
computer was actually capable of doing
so we don't support absolute positions
so this was just kind of dropped on the
floor so it was harder for this player
to actually get what he wanted and if
you look at the worst players either
they're kind of spamming us or this
person forgot or I don't know then put
spaces in the sentences which means that
our model was not able to generalize
across any of these sentences so it was
really really slow to learn ok so you
get an idea of this is actually a really
fun project because you could actually
see how kind of the computer and human
were kind of adapting to each other over
time so so here's some interesting
examples so it doesn't have to be
English so one person decided to teach a
Polish and another person decided to use
polish notation I'm not making this up
people actually know did this so so that
was fine ok but when we were playing the
game ourselves we notice that something
was kind of um missing the system wasn't
learning fast enough and so if a system
saw this example and I say remove cyan
then the system will actually happily
suggest remove red as the top candidate
because under the prior it's only see
remove red so no it doesn't know si I
mean so it thinks ok Reeve basically
regrets to the prior but this is clearly
bad right because you know if I had as a
human if I wanted to say remove red I
probably wouldn't have said remove saya
I probably would have said remove red
right so as humans we have this
intuition of mutual exclusivity so
people who study a children language
acquisition how you know notice this
quite a bit with how kids learn language
and this makes the learning much faster
okay so we don't want to put this in as
a kind of a hack what we did was to we
want this to kind of a rise out of a
principal and the principal we adopted
goes back to your kind of paul grice
thinking about pragmatics of language
where language use is languages kind of
this game between two players of speaker
and listener and they're trying to
communicate okay so if you're trying to
develop a strategy so the system will
say okay I saw this utterance what does
it mean well how do I figure it out well
in my head there is a skew man out there
who tried is trying to tell me something
so how did the human generate the
sentence well he probably had in mind
some logical form and then he was
thinking if I said this sentence how
with a computer interpreted okay so this
is kind of a line of work which we did
in about six years ago and Noah Goodman
and Mike Frank if you heard of kind of
on our essay is is kind of they've
developed this framework further so the
idea is to model kind of communication
as this game theoretic in this game
direct manner okay so walking through a
simple example so if we were just using
our original semantic parsing model so
then I get a distribution over sentences
sorry logical forms condition on
sentence so you'll see that you know
remove scion with is going to get remove
red but if we recurse so what is the
speaker thinking the speaker is thinking
basically using Bayes rules with respect
to the underlying
the semantic parsing model and then if
you look at what the listener is doing
the listener is using Bayes rule with
respect to the speaker and in using
Bayes rule again and then you see what
the listener will do is actually assign
higher probability two things which are
not with real red right so it still
doesn't necessarily know what remove red
remember saya means but it knows it's
probably not with red ok so we
implemented this algorithm and initially
we didn't really see much of a
improvement and then we thought well you
know why isn't improving things well
it's not improving things because you
know why should it right so this is
we're making a modeling assumption where
the speaker is we're making certain
commitments about what the human is
actually doing and so if the human is
not doing that what we said the human
should be doing then we're not going to
see any gains and in particular there
are some players who are good who are
cooperative and then there's player
who's just type random stuff so we look
at the players who are in the top 10 who
are actually being cooperative and there
we saw a nice game right so this would
kind of is a kind of a modeling lesson
where you know we have the pragmatics
it's kind of a nice story but it really
only helps if the model is correct if
the if the humans are actually being
cooperative ok so what I really like
about this project is that the
downstream goal some language external
goal is driving the language learning
and you know it's it's communication is
a two sided street I mean both the human
and the computer are adapting over time
and we saw that prog mattox is I is
quite useful in cases where the motto is
correct ok ok so now final stand with
standoff with a boss so now all the
users are addicted to our game because
it's so fun
and this is actually well we didn't
actually we still had to we still had to
pay mechanical turk workers but in the
future I hope to actually create a game
where people would just play for fun and
then the boss says ok mission
accomplished we can go home now alright
so summarize we started by looking at
the bootstrapping problem we have no
users no system and we showed three
possible ways of tackling this problem
where you're becoming more and more I
guess aggressive about changing the
framework so initially we said let's
just gather some data offline to try to
cover the input space what happens if we
have workers that help us make
predictions and then in this case the
workers are and the users became kind of
one entity and that's the way we can
kind of a bootstrap I think most
successfully so few remarks um I think a
lot of success of machine learning is
due to just having the data on a
computer I mean the algorithms haven't
have changed a bit but I think that's a
second order effect and this talk I
think encourages us to think about data
collection and learning together so you
know the prep and the cooking are both
really important aspects of learning and
there's so much attention i think often
to the cooking part but the prep is
actually if you could you realize it
takes a lot of them your effort and the
second point is i want to think about
not necessary data sets in but think
about kind of environments and i think
the last part of the talk where the
language game is an excellent example
where you know the value of this the
setting is not that fact that we
collected 10,000 utterances but the
ability to experiment and the third
point is that i really believe that
system should get better with you so if
you say talk to your phone it doesn't
work I don't want to kind of give up and
never say that again I want to be able
to teach it and then have it fix it so
that I can teach it more advanced
concepts ok so any questions before I
move on to the second part of my talk
which I will promise to make sure yeah
how use you have any thoughts on how you
can scale up the language game two more
complicated settings cuz the one you
showed yes barely stand by the other end
when you have you know a lot of you have
a huge output space it's not it's not
really clear out right right so so
that's a good point so in the spirit of
wanting to have language that is
developed from kind of complexity of the
environment so I don't want to say okay
well please type more complicated
sentences because in this environment
there's no need to write but I think
once we have a more complicated
environment which we're actually working
on we're working on still kind of in the
block setting but more in between the
spectrum of Minecraft and where we are
right now and the idea is that now
people can build like chairs or
different kind of sculptures and things
and I think that language learning will
have to kind of proceed in kind of these
stages right so I hinted briefly at kind
of these high-level concepts like when
you say afternoon what is afternoon I
mean the difficulty I think is not an
understanding like the syntax and you
note of what afternoon is it's about
kind of actually ground yet to the world
right so you might initially say that
well I understand what before and after
are in time and then I want to say
before 6pm and after 12pm that's
afternoon so so I think I imagine that
we want a setting where language
learning happens where the users are
kind of teaching these concepts that get
more and more hila one complex yes so I
have applying the three principal we
talked about here maybe choose
Dallas it'll be example but the first
part will be equivalent in some image
easy they got a strap in apology not for
the sample means by the data and I think
the third part is as what once you get
something going wrong is easy to learn
the users but the second part would be
like uh I wasn't ever think about Oh
people oh so the second part is of for
example you have a speech recognizer and
then you have humans who are going to
listen to your transcript yeah yes
crowdsourcing and it should say that the
second third part is also I think nan
pretty non standard because typically
whenever you're putting out a system the
contract is that this system will be
pretty good it's going to be basically a
dolt right but Hiro I'm saying is that
the system is not going to be at all
it's going to be a child but it's gonna
be a child I can you know learn quickly
ok wait you see user to the users more
how slow that and I think in practice we
don't want to start from scratch i think
i'm making trying to make a point that
you can start from scratch but in
reality i think the interesting thing is
if you start at wherever we are and try
to increase the language so that they
think the folks first of all how does
the use of simulation fit into the
thinking or talking about but also you
don't have any anything to be you hear
miss Pachelbel um and then typically the
victim abilities that you use in a human
so pretend that you know you're
simulating the real application and
sometimes it's not very good right
because you know whatever here so we're
not using a laser model because not so
good at it I mean we're actually using
real users yeah I think that's the point
is that we're all right the first part
using a database oh so there are the
ideas that we would somehow covers a
space yes I think it's actually pretty
feasible I mean the more I mean
especially I think maybe in a like a
very wide open domain it would be
difficult but but like in any of these
kind of micro domains I really think
that you can just actively probe and ask
about how do you say this how do you say
this how do you say this and then you
just master kind of language at least as
an initial seed what's once you have the
initial model maybe you can do you know
step 2 or step 3 yeah so I think these
are all complimentary yeah to deal with
adversarial uses this process like this
going to start going to teach you things
are bad if your Microsoft griddles okay
especially right so how did he do that
commercial ways do it before not not
right so there's I guess to settings one
is that um their spam yet in a way that
doesn't actually help them and that can
be easily detected and also they you
know if they're actually trying to send
email or something they spam fine okay
you're not sending your email anytime
soon I think the hard part is if you
spam it in a way where you're
deliberately trying to you know let's
say I say define red is blue or
something then I think this is what kind
of personalization I'm kind of having
not a shared model can be important
where you know it's fine if you want to
call blue red go ahead I'm just going to
try to say okay you're you have your own
dialect over here and you know maybe I
share some parameters but keep it kind
of mostly separate and so there's kind
of many techniques and kind of multitask
learning that could allow you to do that
yeah suppose he basically on the first
part of when we were doing data
collection for the connect gesture
recognition system the mapping lap you
wanted to produce was a from movements
to gestures and people come up have very
different movements associated with the
particular gestures for example the
grief gesture people in the best would
reach definitely the people have a
history also say things right so even
though even the very well-formed gesture
like cake it would have very different
notions of what the cake means right or
rather people do it in them and so let
off this subject bias in the danger
which is which arises from people with
essentially doing it in different ways
but there were some framing buyers in
how you ask the question right if we say
but if you give an extra instruction to
a person they move your hand to the
right that's a lot of time because sort
of statement if you show that my image
that's it
that's like unless out because if you
show the video that's even more of even
less ambulance but then it restricts the
movement interest sixth the natural
entrance of the movement that the person
wants to do so there are all these
little questions or subject buyers and
flaming biases yeah and how do you
could've beaten about them in the car
with your reasoning for coverage yeah I
mean I think one way to address the
point where if you show them kind of a
direct stimulus then they'll not kind of
do what is the most natural for them but
on the other hand if you say move then
they might do something crazy I think
one actually strategy that we've been
thinking about is you know you do it in
multiple stages right where you say okay
you know why don't you just move your
right hand somehow do it do something
and then you collect some data and then
you in some sense in the concert man i'm
going to be paraphrasing so now let's
transform this into something else and
then I think trying to do in one step
might be too much to kind of get the
coverage but if you kind of do in a
coarse to fine where maybe you can get
them so we will be related to the third
part which is your of the target
representation that the system
understands yeah fixed yep so in this is
so it's fixed in this case and it's
fixed or something small but I think I
want to think about this as this is the
world or some let's say minecraft yeah
right so it's fixed but it's extremely
expressive and Lola whoa and rich right
and the idea is that you can build up
two concepts kind of in basically
unbounded a set of ways and I think
we're not there yet but I think I'm not
troubled by the fact that you know it i
think i want you to not think about i
have 10 predicates and I'm just building
a somatic parser for those 10 Predacons
um but actually want to move on to the
second part of my talk I'm happy to talk
to take questions all over later ok so
coda lab is this platform that I've been
working on over the last three years and
the goal is to make research more
efficient and reproducible and the idea
is that you know whenever I tell people
you know I want reproducible research
you know immediately there's two kind of
action there's this tension between the
kind of efficiency of how quickly you
can do research and reproducibility but
I want to say that you can actually have
both and a2 are actually you know really
two sides of the same coin ok so the way
core lab works is that there's a notion
of bundles bundles are any immutable
file or directory they can contain code
or data or results of experiments so
you're either uploaded by the user or
run on colab so for example you might
have worked avec that's a program that's
uploaded clue web is the data set that's
uploaded and then you can create this
new bundle which contains word vectors
this is run in the collab system and it
maintains provenance of how these were
directors came about what's knowledge
source it was useful and then you can
you know use the war vectors in various
experiments on the sku QA did I said and
then you can ensemble things and so on
and the idea is that every step in a
pipeline you're actually keeping track
of the full provenance of how this
result arose okay so let's dive into a
little bit about one of these edges okay
so here's an example so suppose you have
a confidence in Python and they have
this M this data set what does it mean
to kind of create a new bundle from it
well what we do is we take these two
bundles and then we basically put them
in a temporary directory inside a docker
container which is this lightweight vm
that has an idea of kind of what version
of you know operating system it's
running on and then i'm going to this
bundle specifies a command this can be
any arbitrary shell command which is run
when this command is run it outputs a
bunch of files which are then copied
back into the contents of this bundle
okay so that's the basic flow so make
sense okay so the idea now is that
instead of having the research process
work basically on at the level of papers
right so you see a paper on archive you
say oh let me go implement it or we
implement it maybe they've released some
code it's going to be at least one day
probably a week if they don't have any
Co
or something probably a month or Never
and instead we're going to have this
kind of building blocks depend on
bundles and idea is that because this
bundle is already existing in the system
and its kind of certified to run or be
and there's some format it just really
takes I mean a minute or you know
instantaneous to produce the new bundle
okay and I'll show some show some
examples so analogy I like to use is
that you know you know here we are kind
of in the know the days where we're kind
of moving around via horses and
carriages you know it's very flexible
you know you can go over the place but
you really it's really slow right
because they're also pot pot holes and
you can't get to certain places so I
think we're Cola vision is that we have
this high-speed rail system where you
have this whole province it could be
like a hundred deep but you can because
it's there you can just run it through
and that enables you to go kind of much
faster and much farther okay so that's
bundles right so basically people upload
bundles which are code data and then you
run them in the system their produce
results the other aspect of colab is
worksheets and idea is that we have this
bundle graph this is the pantograph but
we don't want to look at that we want to
show kind of more a well-presented
version and the worksheet is basically a
document that contains some text
descriptions and pointers into this
bundle graph so i'm going to say here's
the data set and we're going to compare
two methods and i'm going to reference
this okay so there's many it's so a
worksheet in the website looks like this
and there's kind of a markdown language
that allows you to type in kind of late
a core any sort of markdown you want you
can embed bundles you can form you show
the bundle contents you can define a
schema for displaying to table of
results you can graph things and you can
actually embed these directives that
allow you to show for example all your
running bundles or all of the largest
bundles or all the bundles in your
project
so it's a pretty flexible system with
this you can do many things using
worksheets so you can use it as kind of
research development environment this is
actually kind of the most I think common
use case at least in my group where
people are basically using running a
bunch of things and you can see kind of
the different statistics and the states
so you can fire off like 20 jobs and not
worry that they're clashing or and you
kind of all the results are maintained
here so six months later you see this
and you say oh how do I get this number
well you know exactly where you got it
from okay we've also using it to create
executable papers so here are two of the
several papers from our lab where you
have a description and then you have
graphs and these graphs are actually
generated inside code elapsed so if you
don't think this is sketchy you can go
and see the source code and see how it
was generated we've also used you to
benchmark results so the web questions
data set which we released three years
ago we have this leaderboard where we
have you know different accuracies for
the different systems we can also create
tutorial is about you know tends to flow
or whatever and all of this is you can
do on the web interface which I'll show
but there's also i think the most
productive way to use code lab is using
the CL command which allows you to
search for code and data upload files
just one in one command you can run
arbitrary commands you can look at the
output you can kill jobs remove things
and then you can actually do other stuff
too okay so a system architecture just
very briefly is that there's a website
and then there's a bundle service which
the command line talks to and then this
is powered by a bunch of workers running
on Microsoft Azure and basically
whenever you run a command this goes out
to the workers and it you know pumps the
outputs back
okay so let me give a quick demo to show
kind of what it looks like so if you go
to coda lab here you can look at the
public home it will show you kind of the
the papers that you can see that we have
in the system software data sets and so
on you can kind of just browse and say
hey let's click on this and you can see
one of the papers coming out of ACL this
year with descriptions here's a code and
data and all the experiments and so if
you wanted to run something new let's
say that you'll want to use your my home
which you can think about is your
homework sheet like a home directory you
can edit the mark down so you can say
hello ok so that's exciting but you can
also upload things so i can upload let's
say i have the sentiment data set let's
polarity train it has a UID so this is
kind of a unique global a unique ID
that's assigned once so whenever i want
to refer to this version of data said i
just use this ID so there's no confusion
about what version i'm talking about and
then you can see the contents here let's
upload the test data i can upload let's
see here's a classifier okay and there
which is some Python program ok so now i
can go ad run things so okay so what
happens when I run I first select the
dependencies so in this case I'm going
to depend on all three and what does it
mean to depend on three so you should
and then i'm going to type in the
command so what it means is that it's
like i'm in a directory temporary
directory somewhere where i have files
poll area train play testing text class
up too high and i'm going to run some
command okay so if i were in this
environment i could type text' class
octopi train clarity darin test Claire
t-test and let's there's some step size
parameter let's say point one okay so
then you say run so this will start this
run and it's running
and it's okay so while it's running one
thing we can do is we can customize the
results okay so here are the experiments
so here's I can display graph so this
run generates a tab separated file and I
can say we're use it to graph so now i
can use it to graph the error rates over
time and then okay so this one finished
I can actually rerun so if you go up
here this is the web terminal that gives
you kind of more fine grain access you
can say okay let's rerun this with
different hyper parameters so point two
point three point four and then you can
see kind of all these runs are kind of
happening okay on the graph okay so now
suppose you wanted to you know change
the program so you imagine okay you're
not happy with these results for some
reason so now I'm going to say ok let's
let's create a different version of the
program okay so pretend I edit it i'm
not going to edit it i'm just going to
upload the same version so i upload text
class again okay so now let's suppose i
want to rerun all these experiments with
a new version of my program so colab one
thing that's really nice is that because
it's maintained all the provenance of
how these results came about and what I
did with this text class there's just
one command so the command is mimicked
so i type mimic and then i select the
the old program and then i select a new
program and basically what it's going to
do is run everything that did on the old
programs on the new program okay and
including the formatting so it's going
to basically run all these four commands
but instead of using the old source code
it's going to use a new source code you
can see the results of hearing okay so
with this I think you know it's very
easy to kind of experiment and build on
top of
other people's work ok any questions
about what I did here just very quickly
but if I run a very resource-intensive
tossed on that so that's a good question
so currently these are powered by
Microsoft Azure and if you want it for
example or you have your own cluster you
can actually run a script that runs a
worker that connects the colab and it'll
basically run everything on your local
machine and then put the result in coop
so if you have your fancy cluster you
can also give other people access to
your cluster if you want to be generous
so it's an idea is that the computation
and the the presentation and management
of results archive decoupled yeah good
question hey wish I mistake yeah it's
any language agnostic so docker the way
it works is that you specify an image
like Ubuntu 14-4 and it has some various
things installed and you can run
whatever thing you want if you want some
other libraries install those libraries
and it can just pick it up so anything
you know C Python Ruby c-sharp Java
whatever and you can mix and match them
yeah ok let me quickly wrap up here so
um how many of you use Jupiter by the
way ok so this is a pretty popular so I
think one of the the most similar
projects is Jupiter so it's similar kind
of if you look at it your worksheets or
like notebooks right but there's some
kind of differences which I think are
actually important behind the hood right
so kolob offers these more stronger grip
reproducible guarantees right we have
this commitment of you run something
it's immutable and it's just sitting
there that people can point to so
Jupiter it has this you know Colonel
that it's running and you can basically
it's kind of a mutation so you can think
about procedural versus functional
programming I guess that's the way the
thing about it the second point of that
colab is more modular instead of having
these notebooks which are kind of self
contained colab has you know the bundle
graph which is this global bundle graph
right and worksheets are just pointers
into this so you can actually have let's
say you have a data set that someone
prepared right so this data set can
appear in different worksheets and you
can kind of share the data set or let's
say you process the data set so you sent
you know one week of hard time
processing this data set and now you
have some nice format now everyone can
just take that and use it and you know
that their results there are kind of
traced back to the original data set via
your processing and if you want to
change your processing then because you
have this trace now you can run
everything using the new processing
compared to github so this is kind of
the de facto way of sharing code and
mostly code right now so it's not meant
to be a replacement so everyone should
still use git and github because this
doesn't do fine grain line by line
version control emerges and whatever so
it's quite complementary and but I'll
point out that I think often when okay
releasing coded github is like a big big
step from where we used to be but it
still is far from I think of
reproducibility certificate right I mean
how many we have tried downloading some
code from github and it just doesn't
work okay how many of you have not
actually okay okay so and within
Microsoft there's a dremel which is this
kind of nice platform that allows people
to quickly use machine a large machine
learning two blocks cool lab compared to
that it's more flexible because you're
really just running arbitrary commands
so in some sense it's kind of for the
the power user right and i think as
researchers we know need to be kind of
on the cutting edge changing our
paradigms and we're not just doing
binary classification or no regression
also the second point is that there it's
more centered around these papers right
which are kind of the thing that is no
important in academia so you have these
papers they're executable you can have
the results
you can you know recruiters reproduce
some and build on top of them okay so
where do things stand so I think up
until maybe about this year I mean this
has been kind of a long process of just
building up the system because there's
actually quite a bit of things as you
can see that needs to happen so we have
a kind of a modest number of users
bundles worksheets extra papers and so
far you know various conferences have
been endorsing them I wouldn't say that
the usage has been this has not kind of
blown up in a way in that usage is still
kind of modest part of the reason I've
been kind of keeping a low key is that
you know when you're running people as
random code I don't want to I don't want
this actually to go on you know no
hacker news and have people like really
stress in the system but now I think
over the next few months I think things
are stabilizing quite a bit and now at
this point i think i would encourage all
of you to try and check it out okay so
and just to kind of emphasize i think
there's two ways in which colab I think
benefits people and I think it's worth
distinguishing the two the first is at
the individual level right so why should
anyone use colab well first it avoids do
pick up someone already did it for you
you can just immediately build on top of
it helps you manage experiments I found
this to be really crucial I mean to be
able to just launch a hundred jobs and
not get confused about what version of
what you're using so even if you don't
care about we should because the
reproducibility this is really useful
and furthermore you can you know put
things on kolob and it helps kind of
publicize your tools and data sets as a
result of kind of these benefits the
community benefits I think our are
greater in some sense because once you
have a large community of people with
these data sets and resources now I
think it really starts changing the way
that research operates remember that the
kind of the old horse and carriage
via the and the high-speed train now you
can kind of combine components and you
know ensemble them in different ways and
it should really just be easy like you
read a paper you want to try out
something you just go to Kolob and you
look at the command and you change a few
things and then you should be on your
way rather than having to go through
like a week of time trying to email back
and forth with a the user okay so i
would like to kind of think the
development team a bunch of people
contributed including people on
microsoft and also students are sanford
and with that i will conclude and take
any questions thanks because of the
executable paper yeah i got in this part
of it so somehow in the paper for
example icml paper or maybe I say locker
if you sent off today can you speculate
yeah so right now it's still a little
bit of a loose connection in a sense
that typically you have a paper and in
the PDF you say okay this just click the
link then it goes to Kota lab and then
you basically have this document right
so the idea is that if you have a table
okay Lydia yeah right click on this and
say where did this figure come from and
then you can play around with us you
said that I see a lot of semi all this
year has been featuring loop and sell
the paper thing um well I mean right now
it's just at the level of like okay
building awareness where oh I feel so
real so there's not like any okay oh
yeah it's up to the authors what they
might do at this party what is the
granularity of the African tools can be
basically she can users share different
types of modules or taken up they
increase one automatic you all the
dependencies will automatically be here
it is so for every bundle on worksheet
you can specify exactly who you want to
be
so it's more like a FS permissions it's
pretty fun great so by default
everything's public but you can always
they make things private if you want you
can also install your own version of
Kolob and try the local a everyone as
follows so how do you see this fitting
in with something like archive where are
you know archives like the place to sort
of just upload your papers is this sort
of like the place to upload your data in
this sort of prominence respecting wait
yeah I think that's the right analogy I
mean I think it's it will still be a
while before this kind of ridges in kind
of archive level just because the the
bar for uploading in PDF is way lower
than the bar for putting code and data
and in the right place so what a lot of
we've been trying to do is reduce the
barrier of entry trying to make this as
easy and flexible to use and i think
that the mental model will usually have
is like okay if you're doing research
you're running a bunch of commands and i
want you to be able to run those
commands as you would normally do but
we're going to just basically record
what you did and and so so i guess from
that perspective you know i think once
this kind of you know takes off a bit
more i think i think it will become kind
of a more of a standard place that you
know people can put code and data and
experiments
the question or plain as well let's
thank person for those two wonderful
talks porn that</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>