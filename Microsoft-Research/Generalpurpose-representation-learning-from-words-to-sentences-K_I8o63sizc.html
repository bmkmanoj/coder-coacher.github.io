<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>General-purpose representation learning from words to sentences | Coder Coacher - Coaching Coders</title><meta content="General-purpose representation learning from words to sentences - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>General-purpose representation learning from words to sentences</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/K_I8o63sizc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
good morning everyone is my great
pleasure to introduce Felix hill from
the Cambridge computer lab felix is
currently finishing up his PhD there and
he's done some fascinating work on using
deep neural nets to teach machines to
understand human language voice yours
thanks Katia for introducing me and
thanks for coming so yeah I think there
was there was possibly a torque
advertised with a different name and so
all of what was in that previous
abstract will be in this talk I just
changed the framing of the talk a little
bit so it's not and it's not the case
that I'm going to talk about something
completely different so yeah so I work
on automatic language understanding and
it's a really hard problem so you know
there are lots of things in artificial
intelligence that are hard but this is
one this is I guess Siri and you can see
that it's not perfect yet so there's
lots of things in the language there
that them system hasn't really
understood so um yeah there's a kind of
semantic thing which is internal to the
words alcohol poisoning is very
different from alcohol so just the
addition of the extra word radically
changes the meaning of that chunk which
seems to confused it it doesn't seem to
have a good sense of the intention of
the user or the severity of the
situation and these are all these are
all things which humans are kind of in a
glee aware of when they or maybe not
innately but they're intuitively aware
of when they when they interpret
language when they interact with people
so and then yeah I mean machine
translations another application where
you know you could think of it as an
application where we need to understand
the meaning of language it between
languages that are not very close or for
which there's not a lot of data it's
really still quite bad and even between
I mean it's not a well-defined problem
often there's not one single correct
translation but even between close
languages you can't use it for things
like translating a road sign or
something because there's a good chance
that what you get wouldn't be correct
so I think that one of the big factors
behind it's not a limiting factor
because it's quite hard to do something
about it but one of the factors behind
why these automatic systems lag behind
human level performance in interacting
with language is a kind of clear
difference between the way in which
these systems are trained in the way and
in the scenario in which a human
acquires and learns language so a lot of
my work so far as being sort of inspired
by the idea of bridging this gap making
these two things a bit closer but I
haven't done a lot yet so what we can
talk I'll talk about that but um you
know there's much more to do a much more
radical way in which we can make
language understanding systems like
human language learning which I think
will hopefully lead to systems which
give more human-like linguistic behavior
say typically at the moment most
language understanding systems are still
trained in the classical sort of machine
learning supervised learning way so the
idea is to function approximate a
function between the inputs and outputs
in some fixed set of training data which
is so usually defined before the
training starts and then yeah the the
kind of objective of these models is to
reduce the mathematical cost function
which is maybe not quite like single
cost function maybe not quite like what
humans aderman the learning and yeah as
I said the the training date is fixed
beforehand normally people play around
with how you order it and things like
that but it doesn't tend to depend on
what the model already knows and often
with language it's Union modal so often
it's text or linguistic resources if you
haven't seen any sort of examples of
this I'll talk about some in this talk
whereas human language learning is a bit
different so it's generally I mean you
know we do get some instruction as
children about language but it seems
like the vast majority of what we pick
up we pick up from interacting with
people in here in correct examples of
language without any sense of knowing
what's wrong necessarily yeah this clear
sort of straw
motivations and urges that seem to be
guiding human language learning so
usually we you know we want to learn how
to say something in order to do
something so that's not really well
reflected necessary in the current
training setting and as I said it's very
much the case that if a child said it
wants to know more about something then
you know by the time learnings
progressed a little bit he's able to
move the interactions the conversations
or whatever else he's doing in a
direction that will help him to learn
more about that so it's kind of guided
by what the model already knows in a way
um which is not the case with a lot of
the current supervised models and yes
it's also totally grounded and embodied
and you know what the child is so
learning the meaning of a word might be
something like learning what a concept
looks like and what it may be how it is
physically and then attaching a word
label to that something like that
whereas if you have these models trained
on text then learning the meaning of a
word is something quite it's not quite
like that so yeah so there are some
quite obvious discrepancies there and i
think that there's yeah good reasons to
try and bring them to reduce this
discrepancy you know it's obviously not
really true that if we do that
technology will improve but there is
quite a lot of evidence that that
happens at least to some degree so I
think it's a good thing to try see you
here is some sort of buzz words but I
quite liked it I like to think of it as
kind of two ways of understanding
psychology or so you know there was kind
of cognitive this who according to this
you were really focused on how the brain
works and then behaviorist who were kind
of a very much trying to model human
behavior from us you know inputs and
outputs and sort of much higher level
understanding of behavior and I think
what would be nice is if we can kind of
bring these two processes together when
thinking about language understanding
models and language technology and a lot
of the current work has been focused on
the top part which is nice but I feel
like especially for language which is
such a behavioral thing we're missing
out on on a sort of level of modeling
which could be really useful so
um having said that there is a small
amount of work which treats language
like this but then that work hasn't
necessarily embraced all the options and
possibilities that the latest work in
the sort of function approximation the
cognition pop and can offer so yeah I
think if we do that if we combine these
two paradigms and I think it's becoming
more and more tractable to to have you
know principal cognitive models
principle models but also trained in a
scenario where some weather where the
model learning and the setting there is
much more like um a much more realistic
setting of human language learning so I
think yeah if we do that we you know
there's a good this good at there's good
evidence that we can obviously we should
be able to get much richer scientific
insights just because it's much it's a
much more realistic model right so it's
a closer model so anything that we
learned from the model should be
slightly more valid but also you know
there's a bit of evidence in that what
I'm going to talk about and there's
other other pieces of evidence that by
making the training sexing a little bit
more like it is for humans we will also
improve the performance will get more
human-like output will get systems which
people can relate to more easily so and
i've said i've called it the idea is to
turn models of language understanding
into agents of language use yeah at the
moment they really are these kind of
very isolated models separate from the
overall human problem of language as a
sort of tool as a way of interacting and
it would be nice to bring them in these
models into that world having said that
it's a really ambitious program it's
also not particularly no but I'm sure
lots of people have thought about this
in the past I think that at the moment
there's a really good chance that now
you know now is now seems like a really
good time when this might be more
tractable because of the data that we
haven't also the computational resources
that are available now so so I felt a
bit about trying to do this but actually
most of my work has been in the first
part of this problem and just a little
bit extending towards trying to get
towards sort of
interactive or gold room learning as
well and but while including that
function function approximation pot so
that's what I've done to date and you
know it's nowhere near being what I'd
like to do and um so one way in which I
did this and one way which I thought
about and so I used a lot of Katya said
it's a deep learning and that's and
that's true but I think especially with
language understanding you know that the
particular nature of the model isn't so
important but what what does seem to be
quite important is the sort of the fact
that deep neural networks in code words
or other things which carry some meaning
in these sort of distributed
representations so a lot of other prior
to this language understanding systems
often would encode a word just as a sort
of as a symbol as a atomic unit and then
maybe features would be the presence or
absence of a word or um and you can get
along way with that so even now if you
want to know which documents have the
same content things like tf-idf is
incredibly powerful in it in it this is
just a thing where you should basically
count how many words are overlapping and
okay and their frequency but in the sort
of the neural language models which have
emerged more recently word concepts are
represented in in vector space and so a
lot of the work I was doing was trying
to understand these representations of
words or phrases or sentences and the
reason being that if you want to sort of
put any knowledge as well if you want to
sort of adapt these systems to put
knowledge into them then it can be a
good way you see it can be a good way of
transferring knowledge from one training
regime to another training regime often
these representations can be trained
with quite talking tossed agnostic
objectives it might be just trained on
some text or on some other naturally
occurring things and they can acquire
some principles of language which then
useful to inject or to add to some other
systems so um
that's why I was interested in these
sorts of representations and they sort
of play a part in all of the work that
I've done so lots of people heard them
lots of people who develop ways to learn
such representations for words and there
is a whole history going back 30 or 40
years of different ways to acquire
usually from just raw text these sort of
dense vector representations for words
which they exist in some space which
then itself corresponds to often
corresponds to human intuitions about
what words mean say words that have a
similar meaning cluster into one place
and things like that oh one thing that
people hadn't done is is thought about
or there hadn't been a lot of work on
extending this to two representations of
phrases or larger linguistic chunks and
as more and more neural language models
emerged which were able to be trained on
larger data sets it became obvious that
there was ways in which these models
represent phrases and sentences and so
one piece of work that I did wasn't
about understanding the internal
representations of these models and how
are they correspond to human
understanding and also the extent to
which they can be useful for for
application so this is a sequence to
sequence model it's an RN n which in
sometimes reads a reads a sentence in
the source language and then generates
word by word sentence in the target
language but there's a bottleneck in the
middle which is where the model stores
the information corresponding to what
it's read in the source language and
conditioned on which the model generates
or starts to generate the words in
language and then of course narrated one
word the next to the generation of the
next word is conditional upon the word
is previously generated as well as as
well as this prior information so when I
first saw this I thought and this is
Magic it must in that representation in
the middle the model must remember
everything that there is to know about
the the input sentence in order to be
able to sort of get a plausible
reconstruction of it and so I thought
that you know this sentence
representation must be like a real you
know a really kind of high fidelity a
clear representation of what this
sentence means but in actual so this is
when I started to become quite
interested in understanding these these
sentence representations in actual fact
it turns out that that's not the case
that the representation there is very
specific to the translation objective so
in particular it's actually strongly
biased towards the start of the meaning
at the start of the sentence I guess the
reason that I mean intuitively and I'm
not 100% sure but what feels like the
reason for that is that the task of
starting to generate the target sentence
is the most critical and once it's
generated a few words it's kind of got
its language model it's got its sense of
what might come next based on the words
it's already generated so at that point
at that point the knowledge in the
hitter in the knowledge in the weights
of the generating RNN can start to do
something you know they can start to in
there it can encode it's its language
model for French but what it really
needs to do is get the first words right
so it seems like that's the most
critical part and so what that means is
that these are you know if you start
this is a very short sentence but if you
look at these way these representations
are for much longer sentences they seem
to encode information about the first
chunk of the sentence and then the real
s and less influenced by the later works
and actually that's kind of confirmed by
the fact that I think people actually
got a performance improvement in these
models when they literally swapped the
they swap the order of the English
sentence and just retrain the model so
um yeah you can do that because this
model doesn't have any knowledge of
language before it starts training so
the fact that it's being trained on
backwards English is not a problem for
the model in that wouldn't be realistic
strategy in the long term I think
because what we'd like to do is have
these models learning from monolingual
text learning general principles of
language but also then doing the
translation objective and in that case
the model
would know that the English is backwards
and so it wouldn't have a good sense of
that um so then I started playing around
with these with similar models but just
trying to understand maybe can we get
richer sentence representation ritual
ways of encoding sentences in the inlet
in so one objective we worked with was
this it was kind of inspired by the idea
of denoising or two encoders which is a
sort of representation learning
technique which was usually used for
images so this was like you blow the
image a little bit and then you get the
the you train the model to reconstruct
the image without any blurring so
usually it's just a small amount of
random noise but in this case it was
even more crude than that it was
literally just a small mistake in the
sentence and we train the model to
reconstruct the sentence without that
error and we had a couple of them ways
to do that so one would be just sort of
random swapping of pairs of words and
then another thing would be just random
deletion of a word and as I'll show in
the results you know these sorts of
representations have other properties
which eat which useful so this is
particularly useful for a paraphrase
sort of using its prior information in a
panda paraphrasing system it seems to be
quite good at that so paraphrasing is
the idea of detecting when two sentences
have roughly the same meaning but they
might be written in a different way and
so yeah no I mean we did an experiment
for weeks and weeks with the
possibilities with such a model but of
course you can play with this noise
function you can increase or decrease
the number and actually what what did
make seem to make quite a little
different to the optimization was the
curriculum so if you slowly increase the
amount of noise here then the model the
cost of the model you know behaves
nicely echoes lower overall closing the
encoding in the little thing that's
warlike
copy of the text if you are people
you're penalizing if it means you're
trying to get it to construct the exact
right right yeah sue so you mean it
would be what would be ideal is if you
could have I mean the obvious thing to
do in a kind of not particularly am
creative when would be if you had a huge
bank of sentences which had a credit of
meanings but were written differently
then you could you could train such a
model and I would obviously I think me a
good paraphrasing model what and in fact
when I use this system in a supervisor
so when I use this system in them it to
use its prior knowledge for a
paraphrasing system then that's that's
exactly what happened so we put a
classifier on top which is trained on
some paraphrasing data exactly like that
but the reason that we can't do we aim
the reason that I didn't try a model
like that from scratch is that there is
only a small amount of such data so it's
actually not trivial to get sentences
whose meaning is equivalent but so there
are data sets available but of course
yeah there are many possibilities for a
crow sentences of equivalent meaning and
things like that it's actually not
trivial to get really nice day too so in
in all of these experiments I focused on
what I sort of roughly called unlabeled
data which is well I defined it
something which wasn't data which wasn't
created for the purpose of training
models so instead it you know it's
naturally occurring things that it's not
a raw text but it's naturally occurring
things that so um in this study we
didn't look at things like paraphrasing
data because generally that has to be
kind of curated and there might be nice
ways of getting it but um I didn't know
um is there a way for you to quantify
how high fidelity that that in
representation is that it has learned or
is it mostly end-to-end trust
performance well the exactly so I'll
come to that basically yeah so I'm just
going to do it sort of introduce a few
different models that we compared in
this so another one was this dictionary
representation to in this work so there
was all these these existing methods for
training word representations which are
quite well established so the first
thing in this model is to just train and
get good high quality representations
for a full vocabulary of words so 200
thousand words something like that and
then the intuition behind this model was
so it with all these models if you'd
like to get a good representation of a
sentence what we need is a kind of
signal which says we know well what does
that sentence mean or the very least
some objective function which we can
sort of require a model to know about a
sentence in order to do something in
this case the idea is that the meaning
of the the meaning of a dictionary
definition or buts or maybe a very small
description in an encyclopedia or
something should correspond to the words
that definition defines so if we've got
a good quality space of word
representations you can use that as a
sort of training signal to train a model
to read definitions that arrive at the
point where that word is and this
actually gave some really nice results
as I'll show later so this turned into a
really interesting model and of course
to it so dictionaries are labeled data
in the sense that a human was required
to create them but they're nice in the
sense that they are freely available in
you know in many languages so this sort
of data does exist and a nice thing here
was that it became a really nice testbed
for different models and understanding
about what the important information is
when we encode so this is a this is a
sort of classical RNN we also tried one
with the long short term memory and say
this has some sense of word order
because the the updating function
between one hidden state and the next is
not necessarily symmetric so the order
in which the input is put in will affect
where the model ends up in the word
space at the end and but we also just
replaced
with addition so this is much faster to
train and it's also faster faster to
encode at the end I guess a test time
and we did that because reviewers asked
us to do that as a baseline but actually
it worked really well and then finally
we had another variant which was that
the input to the model is the pre
trained embeddings which are exactly the
same that say the words represented here
in yellow are in the exact same space as
the word there's the target on which the
model is trained and then there there's
a there's a mapping here a non linear
mapping that's parameterize by some
matrix is the same matrix in each
position and then they just added
together we also tried this model the r
NN model with the pre-trained word
embeddings as well as input and so it
became a nice way of saying there are a
number of ways of evaluating this model
I mean just by playing around with it
and so just by inputting arbitrary a
test I'm inputting arbitrary sentences
and then retrieving from the space we
found that it really did seem to have
quite a quite a good sense of what these
in what these sentences means so and it
generalizes quite nicely away from the
training data so with something like
this a habit that would annoy your boss
that's clearly not in the training data
there's no dictionary that would define
a word like that but as I'll show you
the model comes up with plausible
plausible candidates for that and
equally we found that slightly strangely
we found that if you train the model on
quite a lot of dictionaries and then it
it kind of knows enough to be good at
and doing general knowledge crossword
questions so and it was actually getting
a really high proportion of things from
like the Guardian quick crossword
correct especially if you if you limit
the search at the end two words of the
length that the clue specify so you use
the information in the clip so
this I could show you that this got lots
of attention because I mean it's
actually not really the justification
behind tool it was just that we needed
to we were looking for a sort of a way
to evaluate it other than just on the
held out on the other than held out
training data but evaluation on the held
out training data was useful in terms of
you know comparing different models so
without that was a useful thing but yeah
as you can see the the candidates here
are really quite implausible and this is
true for lots of queries like that I
mean there are many things that it's not
good at and they're also quite
insightful so negation there are lots of
hard problems in sentence processing
words like negation massively change the
meaning but they're kind of small so
it's obviously very nonlinear the thing
between form and meaning and here it
yeah you can see it's got this quite
good factual knowledge as well so this
is I mean getting question answering
factual knowledge in into a continuous
embedding model is quite difficult
because often the factual answers are
not very high frequency and you know it
you maybe need what seems like more
structured knowledge and of course there
are many questions that this can't
answer there has to be a certain degree
of overlap in the form between here and
a dictionary definition otherwise it
wouldn't be possible so if you asked it
and you know who is uh what's the name
of Barack Obama's eldest daughter yeah I
you know it wouldn't know that it
couldn't generalize that far from the
training day sir but things that are
about the fun ruff Lee about dividing
properties is pretty good at so I think
the message here is that this can be
used as a smooth interface maybe but you
would also need a way of combining it
with a larger knowledge base of this
other ways of getting sentence
representations so the data that does
exist is and that we do have a lot of is
this caption image caption generation
data so i mean this qualified in my
definition of being unlabeled because i
guess it was the you know these images
were originally captioned there for
making you a nice website or something
so in that sense it wasn't for the
purpose of training a model and these
this data set or data sets like this is
a flickr data set they've been used for
lots of things so actually the going the
other way around is the more
justing bit which people have done this
is a you know sequential generation of
captions conditioned on the image
representation that's very interesting
we just reversed it so that the pre
train so you train a convolutional net
work on classifying images and then the
idea is that and the final layer of that
classifier forms a bedded representation
which encodes the content or at least
encodes some some view of the content of
the image so when you if you take such a
network pre-trained you can use it to
get out relatively interesting and
possibly sort of from the visual
modality representations of an image and
then if you consider that to be that to
be a fixed representation which isn't
updated as this model trains the rest of
the model then the task is just to read
the caption and arrive at a place in the
space which corresponds to the meaning
of the image so this is you can think of
this is a sort of visual signal for
getting sentenced representation so more
visually it might prioritize things
which are obviously concrete which is
clear and clearly exist in the physical
world things like um okay and then as a
baseline surprisingly effective is or in
a lot of evaluation surprisingly
effective way of getting a
representation for a phrase or sentence
and this is what a lot of people have
done previously it's just a sort of
crude additional averaging of the words
um it's it's it's it's a bit of a weird
phenomenon why this works at all people
have discussed it there's some intuition
and especially in this case so this is
one way of getting the word
representation so and you store a set of
embeddings for you can think of them as
input words and then a set of embeddings
a different set of an independent well a
different set of embeddings for the same
vocabulary as output words and then this
model the Sebo model essentially takes
the input embeddings so in a training
case it it requires these training cases
from text in this case five consecutive
words the two outer words of the five
both directions are added or the input
representation for those words
added to get a single single room for
representation and then that's used to
make a prediction or and the model is
optimized so that the highest score the
highest scoring word in that case would
be would correspond to a is the output
word so in the objective function here
there is some incentivization for these
things to be additive in some way so you
would want the words to add up and have
some sort of coherent meaning from which
we could make a prediction about the
word in the middle so it's just a small
intuition as to why you can add these
and still get something plausible so we
changed this model in order to kind of
make it better really getting it or
design designed it to hopefully be
better at getting a type of sentence
representation so it's a very simple
change to this SIBO model in fact all it
does is and the input representations in
this model are taken from one sentence
and then the output representations are
taken from sentences which are either
side of it in in a book so the signal
that the models trying to exploit is
something to do with the narrative that
connects one sentence to the next
sentence in a book as you can imagine
thinking like well what sort of
knowledge would they need what sort of
representation would I need in order to
make a strong prediction about the word
about what's in about what came before
and what came after but um this model is
also designed to be kind of super simple
in the sense that we had lots of
evidence that just adding things and
things that weren't aware of word are
actually quite effective in
representation so this model we yeah we
thought about doing it with RN ends and
those sorts of things but we found that
you know we could get this model working
really quickly with this quite simple
strategy so all we do is we we
initialize random word embeddings
corresponding to input words which is
the words in the middle of
then they are simply added to create
what we think of as a sort of core
sentence representation for the middle
sentence and then based on that in
exactly the same way as in the Sebo
model so using a soft maps we make
predictions and we just try and optimize
the model to give high scores to all of
the words in the sentence before and the
sentence after these words have no
status relative to each other so they
are all equal it's just predicting it's
all bag of words it's just predicting
words in nearby sentences so the
embeddings that are in yellow are not
the same as embeddings that are in grey
so that so that that's that's an
interesting design decision which was
also made in these models and it bitch
it it was shown that with
experimentation that this was actually
necessary so it's quite interesting to
think about why you would want that why
you would I think it's you would always
see always have a high score predicting
yourself but you don't necessarily want
that in language so you don't want the
target embedding of a word to
necessarily be the same as the input
embedding of a word because these will
put these are sort of the yellow words
sort of need to be good at making a
prediction for what words come near to
those words and often that is not the
same word so that's a little bit of
intuition but I'm not a hundred percent
sure I haven't tried to demonstrate it
for me so in this case you can think of
these representations as being slightly
different these ones because they're
optimized to be added so you need to add
them up and still get something which
makes sense it in the sense that the
representation in the middle needs to be
good and useful for predicting the
content of nearby sentences so how how
is this how is this different to other
models well I've got a little demo which
it turns out that this is actually quite
nice what you end up with is
representation which can be added and
slightly more plot you get slightly more
plausible representation at the end of
it than what you would have done if you
just trained them
using the Skip gram or the sea boat
model so in this demo all they did was I
I trained such a model and I trained a
CEO model and then I encoded something
like 2 million sentences from bad
literature so the literature was freely
available because it wasn't published
and I think yeah it wasn't published
because it doesn't seem to be very good
um but so what you can do is just enter
any sentence and then retrieve from the
space the nearest sentence in the book
and you can see that in this and quite
nice contrast between doing this with
the old sero model and doing this with
this new model which is optimized to be
slightly better at sentence
representations so um it's a little slow
because it has to do try that ok yeah so
I mean neither of these is it's flawless
the model can't do anything particularly
clever it just has to retrieve from a
set of synthesis which already exists
but you can see that on the right it
seems like what it's producing there is
more similar to the query than what it's
producing on the left and it's possible
to try this with with any sentences and
get a sense of you know the principles
that the representations encoding and
one thing that struck me here you know
it's not it's certainly not there at the
moment but these representation I in
order to make this sort of fit on my
server I had to make these quite small
so they're both 100 dimensional there's
the 0 and the fasten and it struck me
that you can encode quite a lot in 100
dimensions in these representations and
um I thought you know if we can get a
little bit better at this then it opens
up the potential for a sort of top-down
generation because what's nice about
what's nice about the sentences on the
right is that they are grammatically
correct they're perfect English and the
reason being that they've they've
written by someone what's not now
that they might be known to have exactly
the right semantics but equally with
current language generation you know you
get you probably get quite you may well
be able to train a model to get really
good semantics but then it might also
make some linguistic mistakes which I'm
very natural so there could be
advantages or ways of incorporating this
into a generation system such that we
you know you produce and something which
is which is which has already been
produced before and is therefore
guaranteed to be correct English and and
because it's in this embedded in spaces
it's it's already sort of readily
available for use in a neuro language
model which is not the case with maybe
other approaches to information
retrieval which which existed before so
um that's another potential use and yeah
we can try one more sentence just to try
and give the sea another nice thing
about this model is that there is no
model in the sense that it's just all in
the word representation so there is no
the encoder is just to add them up they
just optimize word representations which
are slightly better at adding
so yeah I mean it's not clear exactly
what what this demonstrates but I think
well to me it demonstrates that yeah
there's a more plausible sentence
meaning space on the right-hand side and
there is on the left hand side but these
sentences on the right are undoubtedly
slightly closer than what's on the left
okay so yeah so I compared lots of
models to try and understand the
representations and there is some
interesting differences between them so
some of these models are aware of word
or do they have that within their
capacity they will encode something
different depending on the order in
which you input the words others are
completely blind to word order and then
they obviously require different levels
of training so the nice thing about the
trying to get these representations is
it's kind of a sort of a rudimentary
unsupervised learning you use them to
hopefully acquire knowledge which then
you can add to some other system with a
specific task and so you know the degree
to which they are unsupervised is not
it's not equal so some of them are
really can be trained on just an
unordered list of phrases and sentences
others the ones that rely on them the
narrative structure of one sentence to
the next then leave sentences must be
ordered so the last model that we
discussed then there needs to be there
needs to be trained on a book in which
the sentences have order otherwise of
course the objective of predicting words
in nearby sentences doesn't make sense
and finally some of them rely on a more
structured resource such as image
captions or dictionaries but these are
all things which which exist in the
world without necessarily needing to be
created curated so this is cat ears
question how do we evaluate this so the
people are sort of there's lots of lots
of work in language processing on them
on representation learning and it's
quite fun and cool but you know it I
mean there's still only just starting to
understand what the possible
applications of this are
so one way that people typically
evaluated word representations was just
to see how closely the space of word
representations correspondent to some
measure of What's in people's minds so
by doing that their last people what
words or they'll get some sense of what
words a similar maybe they'll even use
brain imaging data to understand how
similar representations are in the human
mind and then they'll compare a simple
metric like dot product or Euclidean
distance or something like that so no
training data they'll just query the
representation space and see how close
they are so that tells you well this
isn't maybe a nice model of cognition
but it doesn't necessarily guarantee
that the representation is useful for
anything on the other hand there's these
what I called supervisors evaluations so
that's not to be confused with soup the
supervisor the models being supervised
the model is in general a kind of
unsupervised the ones that acquire these
representations but when we evaluate
them one thing you can do is take some
extra training data use them as features
in a classifier and the idea being that
the classifiers kind of neutral in the
sense that it's not particularly so this
was logistic regression and then if one
representation allows this
classification problem to be resolved
better than another representation
feeling is that there's more useful
information in that representation so
it's it's I mean neither of these is
perfect as a way of evaluating for
various reasons but I try to use both
just less that was look so compromised
so what we found is that yeah be one
interesting thing was that when you use
the representations in the supervised
setting and you get readily different
results of what's better than when you
use the representations in the
unsupervised setting so generally
speaking they're simpler models the
shallower models the models that don't
encode word order they perform better on
these unsupervised evaluations whereas
in the supervisor evaluations it's the
more complex models with a recurrent
recurrent neural network or some word
order encoding um
now yeah just like k-nearest neighbors
or somethin that's nothin here is still
simple so how would you how would you
evaluate using ten years so embed your
if you're trying to do some soup rice
task I guess the movie recommendations
is like how many stars do you give it a
second so find the nearest sentence in
your data set based on some sort of
distance in the embedding space and then
give sort of 15 years natives
classification yeah that's true so that
would be kind of along the lines of wife
called the unsupervised evaluations be
using but it but it bit using the other
you know using a slightly different data
set which isn't this a psychological
measure but rather some other measure of
like what's correct I kept their listing
how we've got the supervised evaluation
just when something that's not a linear
classifier okay okay so you're actually
using the training data for the
classifieds not linear yeah I say the
reason that I I used the exact formalism
that I did was that other work had
already used it so we could just do a
direct comparison but yeah you're right
i think that ultimately the test of any
of these representations should be you
know how many different systems can i
put them into in order to gain some
improvement the problem is that it
becomes a bit untrackable at least for a
piece of world like this with where
we're comparing many many different
models it became a bit intractable you
know ideally we would sort of trade
apply the representations to many
different downstream applications and
then evaluate how well they perform so
if we allow nonlinear classifiers here
then it kind of just would open up a
huge sort of scope for comparison in
many different models but yeah that
would be the most realistic thing to do
because presumably that's you it would
be a sort of state-of-the-art model in
which it was used it wouldn't
necessarily be and of course there is a
sort of there's a nonlinear element to
the decoding process for a lot of these
representations so in the you know the
cost is computed based on the words that
are generated conditioned on these
representations in an RN in the case of
the these models
and so it maybe isn't surprising that
they're not as you as you kind of
suggested it maybe isn't surprising that
they're not very good at the
unsupervised evaluation and you could
argue that maybe even in this case um
it's not surprising it might be that you
need a nonlinear classifier in order to
get out the full potential of these
representations but it's a trade-off
because if you allow the classifier to
be too powerful then you may be not
isolating the effect of the
representation so it could be that the
classifier would work with um you know
it would it's just exploited the
training data the little bit of training
data you I'd on top maybe or something
like that so I think that was the
thinking behind defining a framework in
which use a very simple classify to
evaluate these things and and so by
following the framework of other authors
I was able to at least compared my
representations with theirs and sort of
build on their work rather than we doing
it so and so there were some I mean this
is a kind of ugly table of results but
there was some interesting and insights
so on the supervisors evaluations it's
actually the case that the dictionary
the dictionary training really does work
quite well um and and the the model with
pre-trained embeddings and in most cases
so these are these are here these are
different examples of the classifier
thing right so they correspond to
different task movie recommendation
subjectivity analysis and and things
like that so on the larger number of
those the best-performing model is that
is the bag of words dictionary
representation model the one with the
pre train without inviting so this is
quite interesting because it's it's it's
an example of a little bit of transfer
learning so this model is learning about
word meanings first from raw text and
then kind of applying that knowledge
leveraging the dictionary definition
data to learn how to combine those
meanings and then based on that you get
quite a rich phrase or sentence
representation and
and that the the denoising auto encoder
model seems to learn features which he
useful for paraphrasing so this is quite
a high score on the Microsoft Research
paraphrasing data so that yeah there is
I mean there is this is a reasonably
sized data set so would there are some
people who have just trained a model
that the similar sort of model directly
on that data but I wanted to in this
work to sort of understand what could be
learned from this unsupervised pre pre
training acquisition of features and it
turns out that the features are the
features are pretty good they're quite
good the ones you learn with the
denoising auto encoded this is the one
where you corrupt the input and then try
and recreate the correct sentence these
things I feel silly on MSRP now is about
81 in the first number so it is just
trade all the other yeah yeah exactly
that's a model which was trained using
the training data but it was obviously a
model it was tailored specifically to
that task and so we're getting pretty
close just by using this background
knowledge having said that of course
yeah something like sibo is also it's
the worst model here but it's what it's
also doing okay so you get quite a lot
just from from the training data in the
super versatile innovation um and then
in the unsupervised evaluations we see
quite it quite a difference so the best
performing one here well one thing
that's interesting is that still adding
up word representations actually
performs really quite well so am one of
the messages from one of the takeaways
from all of this is if we're going to
persist with representation learning we
probably need better ways to evaluate I
don't think that these unsupervised
evaluations really necessarily the
essence of what we want from the
center's representation if you're able
to just add up the meanings of words in
a model like that and get such high
scores I think it suggests that the
examples are not so these typically
unfortunately these year the this SCS
and the sick it's two separate
evaluations but they both consist of
pairs of sentences which are rated by
humans for how similar they are but
actually the inter annotator agreement
on that is very low it's a hugely
ill-defined things so you can do that
for words and generally you get quite
high agreement so that suggests that
there is a thing there that it's
relatively covered from person to person
but when you do it with said it is it
just totally depends on how the person
Jesus to perceive each sentence and so
this is a very noisy analysis and it's
the best we can do with the current
evaluations but it's important not
refute into it one thing that was
interesting was that on the tray on the
test set which correspond to images the
model train run captions was actually
the best so there's a slight effective
modality there this model is actually
better than other models at knowing how
similar caption descriptions are ones
that it wasn't trained on so that shows
you that they're actually a little bit
specialized to the particular type of
language and then the first sentence
model which is the one where we looked
at the demo this is actually this is
actually pretty robust but again it
doesn't mean look looking at the demo it
was clear that this is stronger than
sibo or skip grand but in these
evaluations the difference doesn't show
up too much so it for me it says that
the evaluations and a bit suboptimal and
but what one thing that's interesting is
that the dictionary representation model
which was the one with the pre-training
weddings and then trained on dictionary
definitions this actually performs
reasonably well in both who provides
them unsupervised evaluation so to the
extent to which this this sort of
analysis is useful and the conclusion is
probably that these are the best
representations of course in a perfect
world I think what we would have is a is
a predefined set of downstream
applications where we can plug these
representations in and and measure the
improvement or lack thereof and then
plug all different representations that
would be the perfect evaluation
framework but it hasn't been defined so
we have at the moment researcher stuff
to focus on what they can easily compare
with other work so one thing that I was
more I've done recently and I was trying
to and I thought was a maybe a more
satisfactory way of understanding
representations this
a memory network so this is a slightly
deeper network in which you can encode
as a representations of what are
considered to be memories have a
slightly different status in this model
so we actually set this up on what what
we called the children's book task which
is the idea of it's a language modeling
toss the language modeling is just
predicting missing words in a sentence
but this model in the training data you
get access to the previous 20 sentences
and then in the twenty first sentence of
word is missing and you have to predict
that word so it's different from
previous language modeling data sets
because normally you just get a sentence
and you have to believe the word and
because this is taken from berks there's
quite a lot of narrative which means
that things react are and so the model
is kind of tested in its ability to to
look back further than the current
sentence and do something sensible and
the baseline for this would be something
like an RNN language model so you
literally train the model to it just
ignore sentence boundaries and train the
model to be optimal at predicting the
next word and then at test time in this
case burn it in with all of that get to
here and then make a prediction and you
can condition it on the remaining words
that the earth you know you can make
your selection based on the highest
probability right to the end of the
sentence so that would be a better base
slider we compared with that the memory
network has a slightly different
architecture so it does that basically
at this level but then at the same time
it computes a representation of the
context and a mechanism which waits
where to look at in that representation
and then it recruits that information
then uses it to make a prediction so
it's kind of deeper there's a lot is a
bit more to optimize because it has to
optimize this RNN which reads the
question but it also has to optimize a a
network which represents this and it has
to optimize a mechanism which looks at
that or so it's kind of three things to
optimize um but in the context of
representation learning it's quite nice
because you can actually make quite
structure choices about how to represent
this information keep the same softmax
attention mechanism which is literally
just a weighted average of which thing
in the memory should I look at more than
other things and the representation you
cheat a representation form you choose
here can make quite a big difference to
the performance of the model so this is
quite nice in terms of understanding
representations for cures it's a more
downstream application you know it's not
this is not a tool I mean most people
don't need a a an application which
predicts the next word but it's closer
to a natural language application so
it's you can imagine this big this sort
of language model is very useful to put
on top of a machine translation system
to score the outputs it's useful for any
to the dialogue system to make sure that
what's coming out is plausible language
so language models are undeniably useful
and this is a this is a more extrinsic
task it's easier to to explain this task
rather than getting people to rate
sentences or something like that and we
actually got humans to do this test as
well and that's quite interesting
because you so there is that by the way
I forgot to mention that there's a list
of there's a list of possible answers
here so humans we've got humans to do it
when they only had the sentence the
final sentence and then we got humans to
do it when they had the 20 sentences
before it's actually incredibly boring
to do this because that's all it's quite
a lot to read it each case but it's
interesting you know they score
something like sixty five percent
correct when they just get the sentence
and that goes up to about 80 when they
get the whole the whole thing and then
models are they also show that our
models also show that effect but they're
obviously not at human performance yeah
yeah there's candidates here they're
actually from they're actually always
from here yeah Amanda's that is well
yeah there's a number of things we just
sort of effect what models work on this
so we didn't actually use the candidates
for training when we trained this model
we just used the knowledge of what the
correct answer is that you could imagine
is that of ranking based
training which penalizes are the
candidates and increases the correct
candidate or something like that maybe
but in this case it was just maximum
likelihood training where we just
increased the probability of getting the
correct answer so say we only used these
candidates at test time to to select
between um yeah I mean it would
obviously this take this data set can be
used without candidates that is true
yeah I mean yeah I think I'm not quite
sure exactly what the decision was to
provide candidates I mean 10 okay so
yeah it may it might be that you know
that just the average score might be
something like twenty percent if you
didn't provide candidate so a very low
number in this case I guess it just
keeps it open to a wider range of models
which can somehow score these and rank
them versus a model which really needs
to make a choice from his whole
vocabulary that that can often be really
expensive and maybe not the sort of type
of model that we we wanted it was think
in a way yeah yeah I agree that if we
could have done it without the
candidates you're describing is if this
someone else's data set that you made
this data set right yeah yeah well I
made it real aberration yea though it
was my di suppose it was we just I can't
remember the moment where we sort of
agreed to fit the candidates in but
you're absolutely right yeah well it was
it was put together with me and
collaborators and yeah I mean it could
be used without candidates but but I
mean one thing that we wanted to avoid
was that you could only evaluate models
based on perplexity so we wanted to have
models where they could get a sort of
numeric score um if you require models
to give a probability to the right
answer or something like that then that
obviously restricts the class of models
that that could potentially attempt the
task so that's that's one thing
and anyway the interesting thing was
that we found in this we didn't try many
difference it's quite hard to optimize
this network and we I you know I was
only doing this work for a short amount
of time so I didn't try many different
representational forms but one
interesting thing and the final thing I
guess was that in this model we found
that um you know sort of small sub
sentential chunks with a by far the most
informative we're representing the
content in the memory so if we tried to
incorporate all the whole sentence in in
a in a single representation and then
just have 20 memories of sentences the
model would sort of lose information in
some way we get blurred but when we had
chunks of length 5 just windows moving
across the memory and then the model was
allowed to select by looking at those
then it performed a lot better and so
yeah that's that's the end of the talk
say yeah just to recap um you know the
long-term goal would be to to try and
make models of language understanding
closer to the scenario in which humans
learn language and I've done a bit of
work which is sort of a little bit of
the way there in terms of improving the
supervised learning part of the function
approximation part and making it a
little bit more realistic but um I think
in going forward what I'm interested in
doing is combining such models with
different frameworks for training which
allow the models to take different
training examples and explore areas of
training data and things like that in
order to and see different effects and
hopefully improve technology see thank
you please we'll be here for the rest of
the days
there's anything you were talking for
that one he's going to touch with you
hey</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>