<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Charles River Crypto Day: Delegating RAM Computations | Coder Coacher - Coaching Coders</title><meta content="Charles River Crypto Day: Delegating RAM Computations - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Charles River Crypto Day: Delegating RAM Computations</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/rqBVl_D9Rt0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
alright so it gives me great pleasure to
introduce Amir paneth and he's going to
tell us about a work with the hell
Tameka lie on delegating Graham
computations okay thanks Daniel a again
I'm one where I'm going to talk about
delegating Ram computations this is a
joint work with with the al al I and
please feel free to stop in with
questions anytime ok so let's start with
an example that will help us understand
what is delegation and why do we need it
so let's say that someone gives you a
pair of graphs and your job is to decide
whether these graphs are isomorphic or
not so in this example the graphs are
pretty small so it might take you just a
few second that there to realize these
graphs are really isomorphic but what if
the graphs Terremark are much bigger so
I'm going to live this up so you can
verify it may take you a few seconds to
verify so just in case you haven't heard
the exciting news there's a Bubba has a
brand new algorithm for deciding graph
isomorphism that runs in quasi
polynomial time so great we can use
Bobby's algorithm but there's it's quasi
polynomial when the graphs are pretty
large then running baba is algorithm
will still require a very very long time
now add to it the time that it takes you
to read by base paper implement the
algorithm then we're in very bad shape
so here is where a outsourcing
computation and delegation come to our
rescue so cloud computing platforms like
Microsoft Azure for example they allow
us to access computational resources
that are far beyond what we have on our
laptops so what we can do now is take
take our two graphs agh send them to
Microsoft Azure as they will run the
computation for us and it will just give
us the answer which is in this case no
the graphs are not as a north so if
you're a cryptographer this is exactly
the point where we start getting very
suspicious so don't get me wrong we
completely trust Microsoft Microsoft is
be nothing too good
there's a lot of cameras all around but
who knows maybe we're not really talking
to a sewer maybe we're talking to an
imposter okay and maybe for some reason
they want us to get the wrong answer
maybe they're just lazy they want to
save on computation in any case you know
what they say it's not paranoia if they
really out are out to get you so now
what we want to do is use cripta to do
this security and the way this works is
that together with a computation we send
some cryptographic challenge and now
using this challenge the cloud can also
computer proof that it actually perform
the computation correctly so for us is
clients verifying this proof should be
very easy much much easier than running
the computation ourselves and for the
cloud computing this proof should not
incur too much overhead beyond the
original computation because remember
that we are the ones that are actually
paying for the CPU cycles so just
because we're following one stock let's
just contrast it from the setting that
one was mentioning so here we're talking
about the computational setting where we
use cryptography and we assume that even
a cheating cloud runs in polynomial time
but we do insist on preserving this to
round communication complexity that we
had in the insecure a delegation okay so
this is what we call a delegation
protocol researchers have been thinking
about it for quite some time and today
we have this really amazing result of
calories and rod Blum that allows us to
delegate any polynomial time computation
based on the hardness of learning with
errors good okay so now we have this
really fantastic tool we can delegate
massive computations a securely so this
will definitely be useful maybe you'll
be useful for scientists I'm sure you
can come up with other examples but we
want to think big we want to help as
many people as possible maybe we want to
get delegation into any every computer
so we should really focus on
computations that regular people do
every day so maybe we can think about
email so we all use email some of you
will probably use it even before the end
of this talk and most of us have tons of
emails in our inbox
so even a routine operation like
searching for our emails can be pretty
challenging so maybe you can use the
legation to help us securely search
securely outsource the task of searching
for our emails so the way this will work
is something like this first you take
your entire inbox you upload it to the
cloud together with the keyword so this
defines your computation and then the
cloud sends back the search result
together with the proof so you don't
need to be an expert on delegation to
realize that this solution is really all
wrong right so first of all by the time
that it takes you to upload your entire
inbox you can already do the search
yourself also most of us we store our
inbox directly on the cloud we don't
save our emails locally so if we don't
trust the cloud then how can we hope to
verify the output of a computation where
we don't even know what the computation
is so the problem here is that we're no
longer thinking of very long
computations over a short input now we
want to delegate simple computations but
over a very large input or large memory
so the computations that we want to
delegate are often of this form you can
think about searching through emails
delegating database queries computing
statistics over big data and I think
this type of computations is where the
utility of delegation it really comes
from even though graph isomorphism is
also a very interesting problem okay so
if you so we wanna if we want to deal
with this type of computations we need
to do things a little bit different so
back to our email example mmm so you can
think about the space but yeah from this
pic from the picture it looks like the
space is the issue but the issue is
really the input like is they put
shorter okay but now it will be more
clear so we'll see what we actually want
to do so back to our email example a we
can do something like this initially
when we first a outsource our inbox to
the cloud will also compute a short hash
or a digest of this inbox and we're
going to save it locally now
ever we want to delegate a complete air
to search for our inbox will just send a
keyword and we'll get back the results
together with the proof and now we can
verify this proof against the digest
that we saved also whenever we get a new
email we upload it to the cloud maybe it
goes directly to the cloud it doesn't
matter the cloud now sends us back and
updated digest this digest prime that
already includes the new email and it
proof that this new digest is really
correct and again we can verify this
proof against the old digest so of
course these interactions can happen
over and over again and we want all the
changes we make to our inbox to persist
between interactions see it's like a
cryptographic challenge that you send
together with the computation and you
just need it for the club needs it to
compute the proof we just write so
ideally what we want is that both digest
the new and the old are always small
specifically we're going to repeat this
with the new digest so we don't want our
parameters to slowly grow yeah when I do
this again from from now on once I
verified the proof I now digest prime is
my new digest and that's how I repeat
good so this is called a memory
delegation protocol because we first
outsource a large chunk of memory and
then we and then we delegate
computations over this memory so this
was defined by chung at all they gave a
protocol for simple computations and
again using the protocol of kor kalai
rosenrot bloom we can delegate any
polynomial time computation okay so
memory delegation already comes a much
closer to what we need in this in this
email example but actually we're not
quite there yet so let me draw your
attention to a major problem that we
have with memory delegation that has to
do with the efficiency of the cloud so
if we don't care about security if we
don't want the server to compute any
proofs it can actually search and update
our in our inbox extremely fast much
faster than the size of the inbox the
way this works is that the car
can compute an index of our emails it
allows it to search an update in sub
linear time so think about something
along the lines of binary search but now
we want security you want a computer
proof and even though our computation
doesn't actually touch the entire inbox
in memory delegation computing a proof
is always proportional the time to
computer proof is always proportional to
the size of the entire memory so really
computing the proof could be
exponentially slower than running the
computation and this means that our
protocol it doesn't result in tremendous
overhead for the cloud so let's stop and
think about what's yeah memory is the
input or yeah the size of the inbox it's
in memory in this example the computing
the proof will be proportional to the
size of the entire inbox so in this
example the memories just inbox this is
a claim about existing solutions not
about the concept yeah it's a claim
about both existing solutions and just
the definition of memory delegation so
I'll go into the detail in a bit so so
so what's the problem here I mean
originally i told you that in delegation
protocols the of the efficient the
approver must be efficient the cloud
must be efficient has to have small
overhead now i'm telling you that in
memory delegation the overhead of the
cloud is actually huge so there must
have been some misunderstanding here so
the issue is that the efficiency of the
cloud really depends on the model of
computation that you're thinking about
so in memory delegation we always model
our computations an existing memory
delegation the way it was defined and
constructed we always think about
computations as during machines and in
the turing machine model any meaningful
computation has to read through its
input at least once so we anyway pay for
the size of the entire memory but in
real life computations run and not
answering machines they run on the run
run around there are no computers
I wanted people to stay around so thanks
there are non computers and they have
random access to their memory so if we
really want to capture the efficiency of
these type of sub linear computations
that only touch a part of their memory
then we need to work with a more
expressive models like random access
machines or ramps so Rams are definitely
a superior the Turing machines when we
think about sub linear computations but
even when you think about computations
that do touch their entire memory then
ramps can still give us a quadratic
speed up compared to Turing machines now
remember that the computations that we
want to delegate are already very large
so a quadratic speed up here could be a
very meaningful in practice ok so what
we're after is a delegation protocol for
a run computations and before I tell you
the result let me define just a bit more
precisely what is run delegation so the
definition have free parts the syntax
the efficiency requirement and it is
security or soundness so the syntax of a
ram delegation protocol is as follows we
have a server in a client at the first
phase the client wants to delegate a
memory capital D and it also computes a
digest of this memory now in general in
this face we should also allow the
server to do some one-time
pre-processing of the memory before it
stores it this will be important for the
server to later compute proofs and stuff
like that but just to simplify the
notations on the slide let's assume that
the server saves the memory is in the
second phase the client wants to
delegate a computation so first of all
it samples a public challenge and a
secret verification key then it sends
the server the challenge together with
the computation described as the RAM
program in now it's the surfers turn the
server is going to use a prostitute that
we call prove it basically execute the
computation and compute the proof of
correctness at the same time so the this
procedure takes the challenge in the
computation it also has access to the
memory so here if we want the server to
be officially it's crucial that we also
model the server is a ram program so the
procedure proof has kind of random
access into the memory and what it
outputs is the output
of the computations e a d prime which is
the new digest of the computation after
it was executed so if the computation is
read only if it doesn't modify the
memory d prime is just equal to B and
also a roof p for the correctness of ZN
d prime so the server sends this to the
client and using the verification key in
the digestive the client verifies the
proof and if everything is ok we accept
the new digest and we can repeat the
second phase yeah yeah specifically
every time we will repeat we sampling
you know there's no reason that's just
what we're gonna do to get I'm gonna
mention i'm going to talk about this
more when I mean when I stake there is
yeah what's the difference between PD in
G prime V prime I understand that's the
new digest what's p + Z so Z is the
output of the computation what I claim
the computation actually output so I'm
saying I'm running this computation I
got this result the memory has this new
digest in case you want to run another
computation this is what you actually
care about these for the future and P is
just a proof to diesel correct so Z is
the result of the computation on the old
d yeah no yeah the competition's perform
correctly right for the Google example
makes no sense but in general
competition yeah yeah so for the email
example it makes it right sees like all
the words you found it have the word
Popeye in there okay and you can the
capital D can change you can write to
memory yet right yeah you can write to
memory so in particular d prime can be
different indeed there's no capital T
Prime yeah it's implicit right i mean
this moment still doesn't capture the
email example as it is now as the emails
are already on the server right i mean i
mean you can figure out the computation
that writes the email you can always but
the the way it captures it is that the
second said if an empty you can start
with m we have two options either you
open your in your inbox empty ok and
then you can every time you get an email
you run this ram computer you are on the
second phase that just writes the email
today
box or you start with the full inbox and
then that case you have to computer
digest one time by yourself these are
kind of equivalent in terms of
efficiency famu I don't have that they
have a beginning either you get them one
by one or you have them all to begin
yeah questions so if I don't give you
enough rebound with the size of a memory
oh that yeah so I can start off with
like a tiny digest question tiny memory
and write read without loss of
generality you can always replace the
preprocessor this first phase by it
actually delegation around that
initializes the memory and you'll get
the same efficiency okay so this is
syntax more questions about syntax okay
so now the efficiency of the scheme so
when we think about the efficiency of
the legation protocols it's kind of
useful to compare it to the insecure
delegation where we don't compute any
proofs so ideally what we want is that
the efficiency of every operation is
exactly comparable exactly the same as
in the insecure case up to some
polynomial factor in the security firm
so delegating the memory in computing
the digest will be linear in the memory
size time a factor polynomial in the
security parameter K running the running
time of the server will also be
proportional to the running time of the
computation and of course running time
is in the RAM model and what about
verification so in the insecure case we
don't really have verification here we
require that the verification time is
linear in the description size of the
computation and the output so we have to
at least read those and again we pay a
polychaete factor on top of that so this
type of efficient verification implies
that the length of the digest the length
of the proof and the verification key
they're all short their polynomial in
the security parameter and they're
independent of the length of the
computation so the dive see smaller that
she's just point o me link a poly
independent of the computation yes it's
just how in our construction is just the
output of a collision resistant Hamish
okay so as you can see this efficiency
requirements are very tight you can
think about the more liberal requirement
where if we delegate a time T
computation then the server runs in time
polynomially related t squared or t
cubed and so this is also reasonable
requirement and in fact in the protocol
of Kor the overhead of the server is
quadratic but today we will be able to
improve this and we'll get this tight
notion of efficient exactly okay so we
talked about syntax and efficiency now
let's talk a bit about a soundness and
security so we're going to consider a
game between an adversary taking the
role of the cloud and a challenger at
first we had the adversary choose
whatever computation and whatever memory
it once then the Challenger computes the
digest of this memory and also sample
the challenge and now the adversary it
chooses an output a new digest and proof
and we say the adversary wins this game
if the proof verifies but the output or
the new digest either the output or the
new writers digest are incorrect so this
is one way to define security we can
also consider a stronger notion of
security where we like to adversary
directly choose the digest so now the
digest doesn't have to be computed
honestly it may not even corresponds to
any actual memory so if we want to talk
about this stronger security then we
need to change the rest of the security
game a bit now this game doesn't really
make sense so can someone tell me what's
the problem with the game isn't written
now
right so now d capital T is not defined
the real memory is not defined so the
correct computation is not defined so
that what does it mean for the
computation to be correct so in this
setting we just require that a the
adversary can't prove that the same
computation with the same digest lead to
two different outcomes and this is
strictly strong so this type of strong
security with adverse early chosen
digest is actually a pretty useful so
think about settings where there is one
party that delegates the memory and then
there are other parties that want to
delegate computation over this memory so
even if you don't trust the first party
the delegated the memory even if they're
colluding with the cloud still you're
getting a very meaningful notion of
soundness you cloud can just prove any
statement that it wants and the strong
security also have a bit more surprising
applications in the theory of your
knowledge if you're curious about that
then ask me in the end of the talk and
I'll say a bit more about that right so
can't even cheat on the science yeah
okay so we do get this stronger security
with adversarial digest I'll say more
about this in one slide but for the rest
of the talk of mainly going to work with
the simple definition where the digest
is computed honest good so this is the
definition a questions about that
fantastic so we can move on and talk
about results so our result is that we
constructed the legation protocol for
our computations assuming sab
exponentially secure a fhe booya morphic
encryption or even simpler a
computational private information
retrieval scheme so this is just the
same assumption used in the Kor protocol
for Turing machines so we get a
delegation four realms essentially based
on the same assumptions I'll just
mention the dinner construction we do
use collision resistant hash function
but this assumption already follows from
fhe or peer
so there is a small new ones here so
really what we need is a quasi
polynomial fhe but sub explination
collision resistant hash function so if
you want to just not right question
resistant hash function this would be
okay so it's not completely the same by
these vehicles okay so let me mention
some important properties of our
construction so first of all as I
mentioned we get tight efficiency the
running time of the cloud is exactly
proportional to the running time of the
computation not the running time of the
computation squared like in previous
works and again running time is measured
in the RAM model so here we get another
quadratic improvement over Turing
machines and of course for sub linear
computations this improvement could be
much much more dramatic we get security
with adversary chosen digests there's a
small caveat here so in our construction
as i said the digest is just a collision
assistant hash of the memory and we
don't want to let the adversary choose
the hash function we need to trust that
it's collision resistant so in practice
it's not really a problem because we do
have trusted hash functions like shot
two or three but in theory what we do is
we add the public parameters to our
scheme that they just describe the hash
function and their chosen honest good
the next property when I mention is
adaptive sound is so that the soundness
means that we let the adversary choose
its computation not in the beginning
like in the previous slide but also
adaptively after seeing the challenge so
our construction is based on the Kor
protocol which is not adaptive but let
me just mention a new unpublished work
of Justin Yale and vika and they get an
adaptive version of the care our
protocol and also of our scheme and
another wonderful thing they do is they
improve the assumption from a sub
exponential of 82 just standard
polynomial fhe so look forward to that
if they want to get round they also need
to sync resistant but again it follows
in here because we get rid of
exponential assumptions then it really
follows there is no cap okay so
a our protocol also have some
limitations so first of all we only get
a privately verifiable protocol not
everybody can verify proof just someone
that knows the secret verification key
also we don't get any secrecy so on
mentioned this property it means that
the memory in the computation their
public they're known to the cloud so let
me stress here an important distinction
between our work and previous works so
usually getting secrecy for delegation
is not really a problem you just run
your delegation under fully homomorphic
encryption but in the context of RAM
delegation this transformation is not
really applicable so can someone tell me
what's the problem you can still run the
update yeah why okay exactly the quit
this transformation loses all the
efficiency of RAM delegation and now the
cloud will have to take the entire
memory and use it under the fhe so we
completely lose the efficiency
requirement that we want so it seems
that getting public verification and
secrecy really requires very different
techniques than what I'm going to show
you today and really there's a parallel
line of works that achieve these
properties based on program of host
occasion so I just want to do a short
comparison between these results and
office keishon based results so lately
there's been a lot of progress in office
getting ram programs and this also gives
you the legation forearms and as i
mentioned this delegation protocols have
public verification in secrecy the
drawback here is well first of all the
assumptions of exponential IO instead of
just lwe and also a they need to assume
that the digest is honestly computed in
fact in these schemes the digest is not
even publicly computable it contains
secrets so the cloud they can work with
the cloud can work with its digest they
can update the digest but they can't
just compute it from scratch so when we
think about this secret digest this also
makes the question of adaptive sound
it's a bit more complicated because
now we would like to let the adversary
choose its computation adaptively not
only on the challenge but also on the
digest that's even more important
because this is something that's persist
through throughout the life of the
system so in our scheme this is for free
the digest is publicly computable here
they have to do some work and the bottom
line what we know how to get today is
adaptivity with respect to the digest
but we don't know how to get a ductility
with respect to the challenge this is
just the state of beginning and that
after I don't need to worry about it or
like every step in just in the beginning
okay so this is all I wanted to say
about the results any questions so far
yeah so one example that I gave is that
may be different parties there's one
party delegates the memory and then
other parties want to actually compute
on it so this means that if the party
the delegates the memory cailloodles the
cloud there is a total break the cloud
can compute anything and just to check
there's also you could also do this like
in random or Clamato right like with its
snarks and stuff like that right that's
if you just want verification yeah I'm
gonna get to that oh yeah sorry it's not
like I'm just comparing to the office
kitchen but I'm going to explain how
this relates to knowledge assumption
random Oracle's roughly halfway for the
technical part the ways for that okay
hey okay so now we can comparing
confiscation because that was the best
thing that was known before no no this
is kind of a parallel line of works and
I think that it achieves these really
interesting properties of public
verification and secrecy yeah I just
want to also but still think I'm parable
so I just wanted yeah the random Oracle
stuff achieves everything everything is
green not super so how do I know we
don't you secrecy right you can't you
succeed okay good good point but they're
on the morrocoy achieves public
verification it adaptive soundness and
the digest is public and I don't know
what you should write here
good so let's move on to talk about
techniques okay okay so so the so maybe
and we want to construct around
delegation protocol and a very natural
place to start would be in memory
delegation so remember that Ram
delegation is just memory delegation
where the approver is much more
efficient so this is the first thing we
tried it really didn't work we ended up
doing something else but I do want to
tell you in just a couple of slide why
this doesn't work so if you lose me off
if you want to take a little break then
the next two slides about memory
delegation they're kind of a tangent so
you can check your emails in securely
okay so so how do we construct memory
delegation so to see that we need to go
even third further back to Turing
machine delegation simple Turing machine
so now the client delegates an input in
a computation and what it gets back is
the output and a proof and because the
client knows the input and the
computation that it can verify this so
if we want to get memory delegation out
of this what we do is we look at
specific instructions of delegation for
Turing machines and we look at how the
verification procedure actually works
and what we see is that the verification
doesn't actually need to read the entire
input it only needs Oracle access to a
few locations of the low degree of the
input when it's encoded using an error
correcting code called low degree
extension so if we want to get memory
delegation all we need to do is to have
the server implement this Oracle for the
client in a secure way so the work of
each angle on memory delegation suggests
two different methods of doing this the
first method is have the client computer
hash tree over the low degree extension
now the digest is just the root of the
hash string and the proof also contains
an authentication path which is
basically a proof that the Oracle answer
is consistent with the root
second method is for the client to save
one symbol of the low degree extension
in a secret random location so now using
properties of whatever extension the
prover can actually prove consistency of
any other location with the one location
to the client knows but if we want to
keep the location secret then we need to
use fhe or secure function evaluation
for this ok so this is two ways to get
memory delegation now we want to get Ram
delegation and we're going to start by
just thinking about two very very simple
Ram computations the one that just reads
one bit for memory in the computation is
just writes one bit so if we're using
the hash tree method reading is actually
pretty straightforward but if we want to
write even a single bit to the memory
then now the cloud now all the locations
of the logical extension needs to change
and the clown needs to recompute the
entire hash tree and obviously this is
too slow so if we're using the second
method of saving one location in the low
degree extension we can actually write
really fast we can in fact update the
digest without even communicating with
the cloud it's pretty amazing but if we
want to read even a single bit then
again because of because we're using fhe
the cloud needs to take the entire
memory and use it under the fhe and
again this is too slow so we didn't
solve the problem but at least we got
this nice symmetric table out of this so
this is nicely now so this is just like
a toy example right so we just read one
bit it's not really clear how to extend
it to any read-only computations I mean
maybe you can but that's a problem with
memory delegation this is kind of a
problem with the approach right yeah so
we're going to really do some things ok
so we're done talking about things that
don't work let's talk about what does
work it will be a good time for
everybody to tune back in if you weren't
listening so now I'm going to give you a
one slide summary of our approach this
light doesn't really mean anything but
it's really easy to remember
and you can use it to convince other
people that you attended the talks or
pay attention so any round computation
we can think about it as having two
components the actual computation
running on the CPU and the external
memory so we know how to delegate
computation this is the Eclair our
protocol we also know how to delegate
memory I'll remind you how to do that in
the next slide now all we need to do is
to make these two solution play well
together okay doesn't mean anything
right yeah okay this is just like to
help you remember what's going on I'm
going to combine a so our high-level
approach is to combine a known solutions
for delegating memory and for delegating
computation I'll explain it exactly what
delegating memory means in the next
slide so let's review this really
classic scheme of gold oh hello Scott we
remember something about Jerry but what
went wrong what went wrong with memory
delegation in terms of solving what you
want to do right now so in memory
delegation the magic of getting rid of
the input of delegating the input to
someone else and still having all the
delegation vertical works is that you
can't really get rid of the input you
need to remember something about it but
not directly on the input about the law
degree extension of the input and
another use all methods yeah together we
do not use all to be extension because
this is the property that you change one
you need to work so hard to change
everything else but is really old so
does it mean that in particular you will
give us a different approach for memory
dedication yeah yeah yeah well this
approach will contain care are inside
but so if you just want the shortest
path from KO out to memory delegation
you should use the old approach but this
gives you a new put a completely
different no this will use the care are
mostly as a black box you don't need to
know though the great this is your goal
but i recommend it's green
okay good so let's start by reviewing
this really classic scheme of well dunno
Slav ski for outsourcing memory so
what's the setting here so here we have
a trusted CPU that is interacting with
untrusted memory so everything we read
and write can be modified adverse early
and now we want we want to add
authentication to this so that the CPU
can trust that it's really that the
memory is really acting consistent okay
so we all know that we can do this based
on collision resistant hash function
this idea of hash trees now originally
gonna stop ski also wanted to achieve
secrecy so they developed this mechanism
of oblivious Rams here we don't care
about secrecy we just care about the
authenticity of the memory so let me
read ascribe this hash tree solution in
a way that is a bit more abstract so now
the CPU will save a short digest of the
memory this is just the root of the hash
tree whenever we read something we can
also obtain a short proof of correctness
this is just an authentication path in
the tree and also whenever we write
something we can obtain an updated
digest for the memory and again a short
proof that this digest is correct so now
using this terminology we can take any
ram computation and describe it using
this long table and we call this the
transcript of the computation so what do
we have here so the computation proceeds
from top to bottom not from left to
right in the in every row we have the
state of the CPU the memory operation
which is either read or write their
memory address for this operation the
bit that is read or written the new
digest after the operation and of course
a proof of consistency so if we're
reading something the proof attenti
kate's the bit with respect to the
digest if we're writing something that
proof authenticates the new digest with
respect to the old i jest from the
previous line okay so we say that such a
transcript is valid if for every pair of
adjacent row in this table everything
kind of checks out so
example here we would check that
starting from state s5 if we read the
beat b5 you will really transition into
s6 and in state s 6 we write b6 to the
first address of memory and also p6 is a
good proof authenticating ad for with
respect to be three but this is a long
to say but it's very intuitive right
good so again the intuition is that your
transcript is valid this means that
either this computation described here
is really consistent every time we write
something when we later read the same
location we get the same thing or one of
the proofs in this transcript has to be
bogus and this means that we can
actually take this trunk stripped and
use it to find a collision in the hash
phone ok so why am I troubling you with
these annoying transcript and all this
complicated bookkeeping so we're going
to use this notion of transcript to
reduce the task of designing a ROM
delegation scheme to designing a
different type of proof system so in a
ram delegation scheme we're trying to
prove a statement of this form a machine
in a machine m given access to memory d
output Z but alternatively I can also
prove an equivalent statement that says
that given a hash function I know how to
find a valid transcript for this
computation so assuming collision
resistant hash function these two
statements are really equivalent but
still they're very different statement
they if you want to prove these
statements you need to use different
type of delegation protocols so
concretely the statement above is
deterministic while the statement below
is non-deterministic it has a witness
which is just the transcript also to
prove the statement above you just need
a sound argument but below you really
need an argument of knowledge because
this statement is computational even if
the statement above is false still there
exists a valid transcript but the
cheating prefer may not be able to find
this transcript efficiently so so far it
seems like we're much better off working
with the statement above but here's the
punch the segment above is about Ram
computations and the segment will always
just about Turing machines so even if
this computation above has a huge memory
verifying the transcript can be done in
small space now of course we can take
any ram computation
and simulate it on a Turing machine but
this will blow up the running time the
point here is that verifying a
transcript the time to verify a
transcript is exactly proportional to
the RAM running time with the
computation yeah because just you need
to verify the number of lines which is
just the number of steps in the around
computation good so it seems like we
might have made some progress now we
just need to construct an argument of
knowledge for non-deterministic turing
machines that has the same efficiency
properties that we mentioned before the
problem is that this turns out to be
kind of a notoriously difficult task so
do I mean by that so so today we only
know how to construct these things I
during around am Oracle model or based
on strong non falsifiable and knowledge
assumptions so this is already a good to
know if you are willing to work in the
random Oracle modem acknowledge
assumptions then you already have rom
delegation this is what Daniel mentioned
before so I don't think there is
actually I don't think that this theorem
is ever explicitly stated anywhere but
interestingly in practical works of
delegation they do sometimes follow this
approach I think that this is simply
because round computations are much more
efficient but but today we really want
to get something in the standard model
based on standard assumptions like lwe
and here we have some bad news so
there's this lower bound of genuine
weeks that tells us that you can't
construct such a thing based on
falsifiable assumptions using a black
box reduction so today crossing this
Gentry wix barrier is considered to be a
very difficult task and really we're not
going to cross it today we're just going
to go around so the point is that we
don't really need computer delegation
for any non deterministic Turing machine
we just care about one very specific
computation that verifies a transcript
and this computation has this very nice
structure that we can exploit
specifically we say that this is a
computation with a locally verifiable
witness so roughly what I mean by that
is that you can take your witness break
it into small pieces
and now you can verify these pieces one
by one and every piece it can be
verified without a lot of work so if
you're thinking about verifying a
transcript every piece is just two
adjacent rows ya know so we're looking
for a non-interactive solution yeah just
to miss it okay so for this type of a
nondeterministic statements it is lower
bound no longer applies and really we do
get a protocol based on lwe so our
protocol is just basically the same
protocol as a KRR but with a different
analysis so we definitely need to open
up the analysis of Kor so here is a one
page of the proof specifically you can
see it's page 103 it's pretty technical
stuff now the under the other 102 pages
are also very technical so the point
here is that working with the changing
the proof of care can be may be
unpleasant luckily for us we don't
really need to do it we don't even need
to talk about law degree extensions we
can work with an abstraction of the care
our proof here we can we kind of use the
main part of the proof is a black box
and we just build on top of that so this
abstraction of the KR proof is pretty
useful he was already used in several
other works I think it's something that
is really worth knowing so let me tell
you a bit more about this abstraction so
if you look at the heart of the Kor
proof what it gives you in very clean
terms is something called arguments of
local satisfiability for
non-deterministic turing machines so
this will be the main object that we're
going to work with from now i'm going to
define exactly what this means in the
next slide for now just think about it
as arguments that have some weak notion
of soundness so from arguments of local
satisfiability k i'll go all the way to
full-fledged arguments for deterministic
turing machines the first they did it
with bounded space and the later they
remove that and today we're going to do
those arguments of locals
I ability to get what we need arguments
of knowledge for non-deterministic
Turing machines with locally verifiable
witness okay and again using collision
resistant hash functions in this notion
of transcripts we can get arguments for
deterministic lamps so I think neo
mentioned this before we also get an
alternative construction of the
arguments for Turing machines that have
a better efficiency than the arguments
of kr good so this type of modular view
of our construction allows us to
dramatically simplify the proof but it
also allows us to get stronger results
so wrap everything yet well just this so
it also allows us to get stronger is
also if we improve these arguments in
the bottom these kind of these
improvements kind of propagate up
concretely in a work with dialog bloom
we get arguments of local satisfiability
that are a publicly verifiable based on
a graded encodings and this new work
that I mention of Justinian zvika they
get adaptive arguments and based on just
polynomial time assumptions so now by
doing virtually no extra work we can get
full fledged arguments for Turing
machines and RAM that have all these
nice properties good so this is the
power of abstraction yeah yeah oh here
you use fhe and here you use nothing and
here you use collisions ok and here you
also use nothing so in that sense these
two arrows they don't subsume this arrow
because I mean you can actually
interpret all this result in the MIP
settings where this would be
unconditional and this more efficient
proof will still be assuming collision
resistant hash yeah everything purple
yeah oh ok great so today we're going to
talk about this arrow and I'll start by
defining what our arguments of local
satisfiability for non deterministic
Turing machines are we doing on time
only this time 35
okay so as you probably know we can
describe any non deterministic
computation as a tableau but again it
goes from bottom to top now and this
device just a big table of boolean
variables VI and now the computation is
described by a boolean formula fee that
takes all these VI variables and it
basically checks that in the bottom row
were consistent with the correct input
in the top row we're really describing
an accepting state and everywhere in the
middle all the local constraints of the
computation are satisfied so if the
formula feed satisfiable if it has a
satisfying assignment then it means that
this this happens if and only if this
non-deterministic computation is
accepting so this is just standard stuff
so now I'm going to define what it means
for the formula fee to be locally
satisfiable and this is just a
relaxation of a full-fledged
satisfiability so we state that fee is
locally satisfiable with a locality
parameter kappa if there exists an
algorithm that we called a we call a que
local assignment generator that
basically samples partial assignments
for this tableau so the way this works
is that you first need to specify a set
of it most capa variables from your
tableau and then you think of this
algorithm is this big red button that
you can press and you get an assignment
for this for the variables in your set
the problem is that this button is
probabilistic every time you press it
you may get something completely
different so basically the assignment
generator defines for every set of at
most cup of variables a distribution
over assignments so for this to be a
good valid local assignment generator
the assignments that samples they need
to satisfy a couple of properties the
first property is called everywhere
consistency and it just means that for
every set of variables and for every
assignment that you sample for them this
assignment should be consistent with the
computation so it should satisfy every
clause in fee that is over the variables
in your set
every right but we're using the fact
that this feels kind of local every
close is just working or maybe free
variables so if these three variables
are in your set they disclose better be
satisfied intuitively if you look at
this assignment it will look like
something that is actually consistent
with the computation the second property
is called no signaling it's a bit
trickier so let's spend some time here
so the non signaling property tells you
what's supposed to happen when you
sample two assignments assignments for
two sets of variables that have an
intersection specifically tells you what
is supposed to happen in this intersects
so I'm going to tell you exactly what's
supposed to happen but before we do that
let's try and kind of guess what we can
require here so one thing we can require
we require is that these two assignments
always agree on the intersection so this
turns out to be very strong it basically
implies that the local assignment
generator is kind of deterministic it
always agrees with one global assignment
so now there's really no difference
between local satisfiability and global
satisfiability too strong for us so
let's try something else these two
assignments they don't have to agree
maybe we put no requirement okay these
two assignments can they're not required
to be consistent in any way so this
turns out to be too weak so if Kappa is
pretty small I'll tell you what it is
later then any set of Kappa variables
will be kind of trivially satisfiable
intuitively we don't capture these the
global structure of the computation that
connects the input to the output like
this ok so let's try it one more time
this time it's going to be just right so
the no signaling property says that the
two assignments they don't have to be
the same on the intersection but they
have to have the same distribution so
for example if I sample an assignment
for the first set and one of these gray
variables here always gets the value 0
with probability 1 so this means that
when I sample an assignment for the
second set then the same variable should
also get the value zero is probability 1
this is kind of what we're going to use
out of this property now I'm just know
during this version just sample an
assignment for these and restrict it to
the gray area samples
police and restricted these two
distributions are identical the marginal
district at work with the definition
where they're statistically close and
there's a new work now that i mentioned
that actually work with a computational
distinguish ability no so here there is
no MIP there's nothing this is just like
it's a blow and something that reads out
of this tableau there's no pcps or
anything like this just you read out of
the tableau and what you read has these
very natural statistical properties of
you know when you read something that
intersects you need to require something
so this is like maybe the only thing
that I can come up with that users
require it actually helps us okay good
so this is the no signaling property
questions about that okay so so we're
going to think about copper as being
polynomial in the security parameter and
we say that a formula fee if it helped
is locally satisfiable if there exists a
couple local assignment generator that
satisfies these two properties so i
defined the main thing okay so back to
our outline we have arguments of vaca
satisfiability this is what we get out
of the KRR so this is kind of a clean
thing that you can know about the care
are forfeit gives you this not all the
Greek side a and again we're going to
use it to get arguments of nice for non
deterministic turing machines actually
just to keep things simple today we're
going to again focus on the one
computation that we care about the
computation that verifies a transcript
so this is what we're going to see today
and in fact I was cheating a little bit
this is also what we do in the paper we
never actually define this more general
notion the reason I tell you about it is
because I think it gives the right
intuition all we're going to use in the
proof is the fact that this transcript
is locally verified so if you want you
can define this thing and make the proof
go through i'm sure okay great so now i
think we're ready to describe the
protocol so we want to prove a statement
of this form am yeah
that's pretty good well they don't go
here but they go somewhere that's what
they do previous slide yeah the wrong
there so KRR give you can think about
the proof is consisting of two parts
this part and this part in the context
of soup ubers you could think about a
tableau and about these right right so
if you actually read their paper they
don't do that ok this is the intuition
of what they do they don't actually
define this notion achieve this notion
use it as a black box they actually kind
of modify the construction of this to
get this directly but you could do this
in the work with the guy we actually do
this formally and you can also get it
from this work on run but this this was
their intuition all along this is how
they describe their approach the right
direction okay so this is what we're
going to do today and let's describe the
protocol so we want to prove a statement
of this form a ramp program outputs em
output Z given access to memory with
digest d right so the way we're going to
prove this is we want to use the care
our protocol to prove that there exists
a local assignment generator for this
specific computation that verifies the
transcript and it has this very nice
structure so this computation in the
cast computation the witness is just the
transcript and we read the witness line
by line and between every line we have
this block that verifies consistency of
the two lines and also the first block
verification block also explicitly
verifies that the digest is the correct
digest that we care about in the last
verification block explicitly checks
that the last output is equal to Z
things are so this is the state the
memory of our thoughts so important but
the state the memory operation the index
the bit that you read in the digest okay
you don't really need to remember good
so and now we want to prove soundness we
want to prove that if the statement
above is false
then give me any local assignment
generator for this computation I can use
this local assignment generator to break
the security of a hash function let's do
that so the proof goes like this the
first thing we need to do is take our
Ram computation and execute it in our
head and obtain the real transcript of
this computation now what happens when
we try to verify this real transcript so
every intermediate verification block is
going to succeed because this camp
transcript was computed correctly but
the last verification block is going to
fail because the statement is false the
computation doesn't reality so we call
this computation on the left the correct
computation and also every partial
assignment just a blow we say that it's
correct if it agrees with the correct
computation so now someone gives us a
local assignment generator and it's
adversarial it may not sample
assignments that are correct but what
we're going to prove the is that either
all the assignments that we sample
heroes are correct or we can use this to
find collisions in a hash so how do we
do it so we first look at the
assignments to the first verification
block so now i'm using the every or
consistency property we know that all
this verification succeeds and in
particular this means that the
assignment to the first row of the
transcript has to be correct we
explicitly check that the digest is the
correct so also we know that the second
line of the transcript is verified
against the first one and since the
first one is correct if the second line
is incorrect that means that we found
the false proof and we find the hash
collision assuming that this doesn't
happen then the second line of a
transcript here has to be correct as
well okay so now we move on in sample an
assignment for the second verification
block and now because the second row of
the transcript is in the intersection of
the first in the second blocks we can
use the no signaling property to argue
that if it was correct before then it's
also correct now so now we're going to
use the everywhere consistency again to
argue that the third line of the
transcript has to be correct or we break
a collision resistant hash and we keep
alternating between the everywhere
currency
extensive property in the no signaling
property until we get the final row of
the transcript needs to be correct and
this means that the final verification
block has to fail but remember that
everywhere consistency means that this
has to be consistent with the formula
feed has to describe an accepting
computation so this is where the
contradiction comes okay so this is all
I wanted to say about the proof i think
this if you know the KR our proof it's
basically so hey you're no signaling is
strong right you cannot these
distributions have to be
indistinguishable from each other right
oh you seem to be saying right here
isn't that it's good that it is a
consistent right i'm using a very
specific corollary of no signaling that
says that if some point something in an
assignment is equal to a specific value
in one assignment and it will be equals
0 in the other m that's all i don't
think i need more than that that's a
much weaker non signaling you have some
reverse implications right for the no
signaling is necessary for this kind of
stuff to work I mean I don't know
correct no no I'm using it for soundness
this is the soundest right I mean ok so
this but so what you need it to it but I
need like a very specific thing I needed
that if you sample an assignment for one
variable and it equal to 1 with
probability 1 then we will also be equal
to 1 if I sample something else it ask a
related question the marginal
distribution is a point not to be sorry
why do you need such a strong finger is
using local Simon generator that's gonna
use the football yeah sorry right
trouble to look for the argument you
just made yeah that's a good point right
and you really do use the full power of
know something you don't just use it for
Freddie cuts that compare okay so i'm
missing ohio or the bill so cool sensor
transcriptase already linear that's
already very long right so you never
sent a transfer no so this real correct
transcript is something that only exists
in the proof yeah the verifier
never compute this but when you try to
when we touch proof sounds this is what
we usually do we take like the proofer
even though it sends short proofs we
kind of try to recover from it a huge
transcript so this is what we do in the
are you finding the key out of the code
key claims are you ready ok are put the
call on a fantastic so the carrier
protocol I I said it the official good
great question the efficiency of the kr
protocol I said it's quadratic you can
actually say something more refined it's
proportional to the time times the space
of the computation so if you're thinking
about computation in general
computations the space can be as large
as the time if you think about low space
computations you actually do get
something that is tight and one of the
benefits of proving something about the
transcript is that you're always working
with small space basically you're
outsourcing the space using this
collision resistant hash font for this
type of computation with with this sort
of local checks the local Simon
generator actually implies that there is
a complete assignment link to the full
thing right you can use it to recover
how is that different maybe for my
intuition like why does that not hold
for just complete any non deterministic
competition I cook a little bit like
where does that go wrong where does that
go wrong great so we kind of induct use
induction we started from this being
correct right so even if you think about
nondeterministic computation that only
has one witness and in kind of you know
the only way to write this whole thing
non-deterministic Lee is this one
particular way the problem is that when
we look at things locally we don't know
that it could be when we read the first
thing every time you read we could get
something completely that the very first
row right there's no notion of correct
right right so all we need is this
notion of local correctness which is
exactly what this more general type of
NP computations is a good so more
questions about the proof so we're
basically done i just want to mention
some interesting future directions about
the legation so the first future
direction is together delegation scheme
that is both adaptive and publicly
verifiable this is something that we
currently don't know how to do without
knowledge assumptions
not even based on a four station and I
think this type of proof systems are
really cool because they allow us to
reuse the challenge so in particular
this means that someone trusted can
sample and challenge once and for all
and publish it as a crs now everybody
can use the crs to approve anything they
want to everyone else so this is maybe
the closest we'll get to NP style proofs
in the succeeds deterministic settings
okay and the second future direction I
want to mention is kind of an obvious
one yeah it should be it doesn't have to
be small but you should at least like
don't read the entire challenge in order
to verify you maybe you want to read a
few bits of it yeah that will also be a
very useful
it's hidden in the local satisfiability
so this thing on the bottom here that
says arguments 40 satisfy break it's
hidden in the kr poof it's the
assumption that we in here a great so
the second direction is really an
obvious direction implement a delegation
protocol that is efficient enough to be
used in practice so I think that a so
far in the field of delegation there was
this really productive cooperation
between theory and practice so every
time we get this improvement in our
theory then this also inspires a lot of
implementation projects and I'll take
I'll take on Alessandro for helping me
out with references here so one thing
that we can learn by looking at these
examples is that thinking about a ram
computations tights efficiency getting
rid of quadratic overheads it can be
very can be really crucial for getting a
practical protocol so all of these
results they're in different settings
than ours some of them use interaction
many rounds of interaction some of them
have a large pre-processing so they only
get a amortized efficiency some of these
are based on knowledge assumptions so it
will be great to get a practical
protocol that doesn't rely on any of
these so now we know how to do it in
theory and you know the time for
implementations is right ok that's all I
wanted to say thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>