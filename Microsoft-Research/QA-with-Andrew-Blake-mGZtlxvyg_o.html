<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Q&amp;A with Andrew Blake | Coder Coacher - Coaching Coders</title><meta content="Q&amp;A with Andrew Blake - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Q&amp;A with Andrew Blake</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/mGZtlxvyg_o" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
and in fact i see that Professor Andrew
Blake has now joined us from Paris we
already heard his keynote Andrew welcome
thanks for taking the time to feel some
questions from our online audience today
hi there very glad to be here so before
we begin with the audience Q&amp;amp;A taking
questions from the folks watching online
I'd like to briefly recap some of the
points you made during your keynote a
few moments ago we saw that will start
with the complexity of teaching
computers to see why is this such a
daunting task well I think there are
quite a few layers to it the first thing
that is deceptive is that we humans are
carrying these massive processes around
in our heads lots and lots of hardware
packed into our skulls and so we forget
how effortless it is how effortlessly we
see so we go around the world with all
of this computing power directed at
analyzing the visual world and that you
know that makes the tasks deceptively
simple but the next layer of the
complexity is that when you look at an
image and analyze it scientifically we
have image processing tools that have
been developed over the years and we
look at into actually what is what is in
the image and what comes out of a
standard analysis it's actually very
very confusing and so it makes you
realize that the world is actually a
very complex place full of visual
textures full of details which actually
obscure the the main features that we
want to extract from the world so is
this kind of um the deceptive power of
the brain and the obscuring effect of
all of the detail and texture there is
in the world it's a very complex setting
indeed while an Andrew you talk about
combining the two competing paradigms
the generative approach versus the black
box detector can you comment on the
prevailing view point in each computer
vision research community is there a
consensus on the best way forward
actually I don't think there is a lot of
consensus and there are also waves of
fashion so the the generative approach
what
called analysis by synthesis in the talk
is is something that's been going on for
a long time but then the the black box
approach has become very popular
envision since about two thousand and
that now is holding sway and my guess is
that we haven't seen the last swing of
the pendulum yet so as I said in the
talk I think the really exciting
prospect is putting these two ways of
doing things together in a in a seamless
and as efficient as possible kind of a
passion and r we got some of your
questions people watching online now
they're submitting their questions
online we've got one here for you it
says how much you've read what we see do
we interpret correctly because we know
what we expect to see the hand for
example we see the hand because we
expect to see the hand from the context
of the scene where as the computer
starts from scratch every time yeah but
it turns out that actually that's that
context idea that that sense of
anticipation is something that you can
also build into a computer program so
we're not completely stuck with our
computer programs now in the commercial
world these folks obviously are we
talking machine learning about priors
prior probabilities yeah and one can
sort of mobilize the prior of a hand for
example as part of the analysis software
that is going to interpret the data now
since we're talking about the hand and
waving of the handsome and I apologize
for jumping on you there we are 5,000
miles apart after all but since we're
talking about the hand a lot of folks
are familiar with this motion now with
Kinect of course it's been a great
success commercially folks at home to
what that is so it helps give some
context and it shows the commercial
potential of computer vision I know my
daughter loves it she loves watching the
Avatar version of herself go around
disneyland can you talk about the other
real practical applications of computer
vision things that are available today
well I mean even just beginning with
Kinect there's a tremendous amount of
potential I mean we've begun with kinect
for computer gaming and the
application of committee of gaming as
waters has forced the development of
connect and enable that development but
now what we're seeing is many other
different kinds of ways of using that
capability so one of the things we've
seen is work in the operating theatre
where the the surgeon would like to be
able to manipulate images that appear on
the on the screen above the patient but
it's very hard to do that perhaps one
way of day it will be to walk over to
the keyboard that's controlling the
computer and types of stuff on the
keyboard but first of all that loses eye
contact with the the patient the pay the
work that's being done on the patient
and also it's impossible anyway because
the surgeon is scrubbed up and can't
actually touch your keyboard so what you
do instead well one possibility is you
talk to somebody at the sign of the
operating theatre who is not scrubbed up
and you tried to give directions left a
bit left a bit right a bit right a bit
and of course that's also very
unsatisfactory and very impress eyes so
what we're able to provide instead is a
gestural interface which uses both
speech and hand gestures and the surgeon
can stay absolutely in place next next
to the work that is being done and
control really rather precisely and
delicately the the images that appear on
the screen above this is obviously
amazing stuff the kind of technology
that we use to see in movies and thought
that'll never happen and now it's
starting to come about here I got a
number of questions I could ask but I do
want to bring our online audience in and
let them pose their questions they've
got a lot of them coming in so we want
to open it up to the viewers here it got
one from a student says I'm studying
computer vision while image new and
other databases become larger and larger
the classification algorithm become more
complex and time-consuming do you have
any advice for students who only have a
PC to do the research in this area well
actually you know PC these days is
pretty powerful and I you can do a lot
with that so I don't think necessarily
the restriction to one pc is the
bottleneck I think well well I'd say
what I advise any student is do lots of
reading and see what other people are
doing have a look at the the latest
conferences like the one that we're
and here but the the big conference is
in computer vision and just see what
ideas are coming up and what are people
what people are playing with and I think
you know you'd find that to be quite
inspiring you've mentioned using
computer vision in cars and everyone
knows that one of Microsoft's
competitors a big company known for its
search engine are there developing a
driverless car what kinds of problems
have to be solved before we actually
have cars that drive themselves and when
realistically you expect to see
something like that on the road well as
I mentioned in the talk Mercedes have
already announced a fairly profound
piece of driver assistance this doesn't
actually drive the car for you by itself
but it's doing some very high level
monitoring of the environment of the car
looking out for pedestrians and reacting
to the pedestrians on a time scale that
actually human drivers can't manage so
actually increasing the safety of the
car driving even more safely than a
human driver can manage at the moment
but I think one of the interesting
questions is which will happen first are
we going to get completely driverless
cars or are we going to get increasing
levels of of assistance and a little bit
like you know cruise control gives
assistance at a fairly low level are we
going to see effectively more and more
sophisticated and comprehensive cruise
controls my guess is probably the latter
because that provides a continuous path
for the car manufacturers to introduce
innovations I I think that that's where
i put in putting my bed Andrew you know
how it is no matter how exciting the
technology or the breakthrough as soon
as it comes out people say what else
what next I got another viewer question
here from somebody saying one of the
most exciting new ideas or breakthrough
is coming up in computer vision well you
know that's um that's always difficult
to say what the new things are going to
be what we seem to be seeing at the
moment as as Chris mentioned in when he
was talking earlier chris bishop um
we're seeing people using data on a
bigger and bigger scale but one of the
interesting challenges is that the world
is full of data which is not labeled
that is to say you know as you are I go
around the world experiencing it we see
many chairs and many cars and many
familiar objects but these
don't have labels on them and so somehow
it would be great if when we are
teaching computers about seeing if we
could make use of this so-called
unlabeled data just the data that arises
naturally as you move around the world
so I think that's one of the very
interesting challenges that people are
dressing at the moment can they make
learning algorithms which will really
benefit from the vast majority of the
data out there which is some unlabeled
it's like you know when you're growing
up you have have some parents around and
the parents can tell you about certain
things they can pick up a car for a
young kid and point to it and say that
that's a car but you know that's a
relatively expensive exercise you know
parent has to go out to work there's a
limit to how much of that pointing to
things they can do what the young kid
experienced a lot more of is just a
world full of objects with no parent
pointing at them so that's like the
unlabeled data that the computer vision
people have to deal with it seems to me
that this kind of work teaching machine
to interpret an image in the same way
that we do using our brains something it
opens up a whole new area and the
exploration of the nature of
intelligence and he thoughts about that
absolutely because I think understanding
intelligence is a huge enterprise it's
one of the one of the really big grand
challenges for for scientists to
understand what intelligence is about
and there are many kind of skews on this
many ways of approaching it so a
physiologist would approach it by
looking inside the brain looking at the
structure of the brain trying to record
signals a psychologist would approach it
because the psychologist can't open up
the brain they have to work by
presenting you with stimulii like visual
illusions or a great favorite and
measuring what your reaction is to the
visual illusions but in computer science
we have a completely different
opportunity which is we actually have
total access to the inside design as it
were of the computer that is
understanding the world so we can tailor
that computer and experiment with it in
a an exquisitely detailed way which life
scientists can't possibly equal so it's
a particular opportunity i think that
people
all who deal with computer models have
to probe the nature of intelligence very
exciting times I think and dragon
another question from you from our
online audience watching live right now
read write off for the surface here
since deep learning is very hot these
days what are the pros and cons when
applying it in the era of computer
vision in other areas well deep learning
is very hot and very new and i think we
probably only just seen the the
beginning of what it can do i think
actually this is one of the areas where
computer models are arising which should
be of particular interest to life
scientists because one of the mysteries
of the of the brain is that fibers
inside the brain that carry information
are traveling in both directions so they
travel from let's say the eyes or other
sensors into the brain but they also
travel out again and it sort of a bit of
a mystery has been a bit of a mystery
why one would need tracker fibers
traveling both ways it's obviously they
need to go in from the eyes into the
brain but why would they need to come
back out again and so what we have here
with the leaf deep belief networks is a
theory of learning which really makes
use of both of those kinds of structures
and I think that's something which life
scientists might really want to wake up
and take notice of just at the time when
some very exciting new initiatives in
mapping the brain are coming out both in
the US and in Europe in another question
form for you hear from our online
audience they're coming in Fast and
Furious here right from the surface what
are the future areas in which computer
vision and machine learning can help
people in real life using smartphone
platforms smartphones yes I mean there
are so many things I think a machine
vision is going to do with them
smartphones I guess there's the prospect
that we may have software on the phone
probably partly on the phone partly in
the cloud that allows you to hold the
phone up to the world and be told an
awful lot about what's happening there
so for example you might be in a famous
tourist site like Herculaneum shall we
say and you
hold the smartphone up to the to the
ancient buildings and ruins that you're
looking at and as you move the
smartphone around you'll see on the
screen an overlay maybe even here as
well information about what it is you're
looking at and so we could have a very
comprehensive smart interpreter of the
world there Wow got another just sort of
a question / comment from a viewer a bit
skeptical perhaps they say you know I've
heard it said that even a three year old
toddler is better recognizing everyday
objects than today's most powerful
supercomputer so they're saying so we
must be there for a long way off from
machines really being able to see right
well it's interesting isn't it I mean
that that's absolutely true you know we
we taught computers long ago to play
chess at a very high level and now you
know the best chess computers can beat
world champions and we think of chess as
being something very difficult I mean
for for most of us certainly for me
chess is pretty difficult but walking
around without bumping into things I do
that you know really without thinking
and as you say by the time you're you're
free you've got to that so that is a
very strange state of affairs but we
should remember also that the toddler
already has this massive processor in
there in their skulls and they've had
three years of intensive training trying
to pick up food and getting into their
mouth you think of the amount of
training that's gone gone on there I
guess what we have to do is replicate to
at least to some extent that train
ability but I do agree with the
questioner we're still a long long way
off I don't know that we yet have the
smarts even another of a dog or a mouse
I mean we might be you know getting
close sometime soon to the mouse but
it's a long long way to go before we can
have the kind of human level of
capability in dealing with the world and
linking perception and action I myself
have two daughters of five year old and
a three year old so I've been
programming for about five years now and
I I know how intensive it can indeed be
I have another viewer question for you
someone says basically when it comes to
broad societal impact not just
commercial impact for Microsoft what are
some of the key things that this higher
level of computer intelligence could
enable well I think one there
number of things that have broad impact
I think one of the exciting areas is is
medicine I mentioned earlier the
operating theatre and the user interface
but but also there's a great volume of
data coming out now from diagnostic
imaging in medicine so diagnostic
imaging is getting more and more
powerful it's getting cheaper and often
the quantity of of imaging coming in is
such that the clinician doesn't really
have time to look at it all and analyze
it all in detail so I think what we're
going to be able to do is to build
software which gives a very considerable
power assist to the clinician in for
example alerting their attention two
parts of a volume scan of your body
which have interesting information or
else helping the clinician to be very
precise about delineating some part of
the body or even a foreign part of the
body like a tumor that they want to get
rid of it's very important to be able to
delineate the tumor very accurately so
as to remove the effect of the tumor
without damaging the surrounding tissue
which has vital front function for
example in the brain I think those are
very exciting prospects now obviously a
human takes into account you know other
senses that we've learned you to learn
behaviors when we're determining what it
is that we see how important is it when
it comes to training machines to see
obviously they can't smell like we see I
think that's flames I smell burning
that's a flame all right yeah well Ian
of course we we do have multiple senses
and we can sound and vision would be an
obvious example we can see a crowd and
we can hear the noise of a crowd and we
can work out that that is a crowd and I
think that's where the probabilistic
framework for dealing with data which is
one of the big subject of this
conference is very exciting because that
provides a kind of theoretical insight
into how you can take information from
very different kinds of sensors and
combine them on the face of it the
information you get from something a
sense of receiving sound and something
seeing images they're very different
kinds of currency how do you somehow
exchange those different currencies of
information into a common
rnc so that they can that they can have
a combined effect on the inference that
you make and the theory of probabilistic
inference has some very powerful things
to say about that and I think that's one
of the big causes for hope and
excitement andhra I got one more a
viewer question for you and I think is a
great one because I think this will
represent a lot of the general public
and how they would look at this it says
I'm pretty skeptical about some of this
computer vision stuff I mean it says my
cell phone takes pictures but half the
time you no they're blurry or badly
exposed so how can I rely on computers
to see the road while we drive for
example when their cameras are obviously
so myopic yeah well I mean of course um
you know there are very good cameras
around you have to remember your cell
phone is a commodity instrument that has
to be engineered to a price and you know
the cheaper your cell phone is I guess
the the more constrained the camera is I
guess I'm seeing on some of the the
cameras some of the cell phones nowadays
we're getting much better cameras and
the pictures are much better and
certainly when it comes to the
technology on the car we can put quite
high quality cameras on the car and
there's the the money available in the
retail price of the car if you like to
put some quite good equipment on there
so I'm not so much worried about the
optics and the hardware I think those
problems can be addressed and and have
been an are being addressed I think
really the challenge is much more to do
with processing the images what happens
to the image when they get into the
computer and how effectively can we
extract the information about the world
out of those images I think that's where
the real challenges well the future is
fast approaching it's a really
fascinating stuff Thank You professor
Blake a fascinating look at the teaching
machines to see we're going to have more
info on this hot topic later in our
broadcast well I'll be interviewing
leading computer vision researchers at
Fei Fei Lee of Stanford vision lab and
Sebastian new ozan of microsoft research
and i'll also chat with Professor Zubin
Germani</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>