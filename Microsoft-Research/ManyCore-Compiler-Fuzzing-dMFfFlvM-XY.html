<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Many-Core Compiler Fuzzing | Coder Coacher - Coaching Coders</title><meta content="Many-Core Compiler Fuzzing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Many-Core Compiler Fuzzing</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dMFfFlvM-XY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
okay let's get started it's my pleasure
to welcome Alastair Donaldson to MSR
today he's here just for this afternoon
Alastair has collaborated with many of
us over a large number of years he's a
professor at Imperial College London and
he has expertise in compilers and
program verification and GPUs and he has
recently added compila fuzzing to his
repertoire today he's going to tell us
about some of his recent work in that
direction ok ok thank you Shaz so the
work I'm going to present today is a
collaboration with Christopher lib'ry
and and rail ask you who are PhD
students in my group at Imperial and
also with Nathan Chong who used to be a
PhD student in our group and is now a
postdoctoral research at UCL and what
we've been doing here is looking at the
reliability of compilers for the many
core programming language opencl and
more generally we are interested in the
reliability of compilers for GPUs opencl
is a programming language that is the
targets multi-core are many core devices
of which GPUs as a major fraction of the
target device audience okay so I have a
personal motivation for this which is
that for the last few years I've been
working quite intensively on a tool
called GPU verify which is a static
verification tool for GPU kernels this
is something I started which has as a
visiting researcher in 2011 and GP
verify is these days pretty effective at
finding bugs in GPU kernels and
sometimes is capable of verifying
particular correctness properties of
those kernels under a number of a number
of assumptions and caveats and this has
been a main focus of my group and I for
a few years and this begs an obvious
question so GP verify operates on source
code actually operates on llvm bit code
that's been obtained from source code
from an open CL or CUDA kernel so the
question is can we trust the tools that
are going to compile that source code to
get you something the runs on a GPU so
if you can't trust those compilers if
there's compilers have bugs in them then
you could use GPU verify or a similar
tool maybe one of the tools from Ganesh
capella Christians group in Utah to
check correctness properties of your GP
Colonel only to have the colonel do
something completely wrong on the
hardware so this is the personal
motivation for me for getting interested
in this work so what we wanted to do in
the project was look at to existing
compiler testing techniques that have
been successful in finding bugs in C
compilers and apply them in the domain
of opencl so those techniques are random
differential testing which was
popularized in C by the ce smith tool
from the university of utah from pldi
2011 and a more recent technique called
equivalence modular inputs testing which
was at last year's pldi from researchers
at UC davis so we wanted to try and
validate those in a new domain and in
the process devised novel opencl
targeted extensions to these techniques
and assess them use them to assess the
quality of industrial opencl compilers
so we tested 21 different device
compiler configurations in this work and
we discovered a number of bugs from
various vendors including altera AMD
Nvidia in Intel as well as in
open-source opencl compilers ok and a
key thing here is that many of these
bugs and I fixed so some of these
vendors have been pretty active and
fixing the bugs we've been reporting
which I think suggests that their bugs
that people do take notice of and we
never did further testing on these
implementations and already noticing the
bug rates to be going down partly as a
result of these fixes so what I'm going
to do is talk about random differential
testing give you some background on that
and in the process take a quick detour
into the problems of undefined behaviour
in compilers and then I'll tell you how
we lifted random differential testing to
open CL and then I'll tell you
background equivalence modular inputs
testing the other technique we validated
and show you how we lifted this to open
CL and then I'll discuss some of our
experimental findings and show you a few
examples of compiler bugs we found and
please do feel free to interrupt me if
you've got any questions as we go along
ok so random difference you're testing
is conceptually a very simple idea like
I said it was popularized by this tool
see Smith from the University of Utah so
the idea in the context of C is let's
imagine we have got a tool to generate
random see programs and c smith is such
a tool so you run c smith and it
produces a random c program by which I
mean the program was randomly generated
the program itself is deterministic and
does not employ any randomization
but its contents are random we will then
give this random C program to a number
of compilers for example you may give it
to Microsoft and Intel's compilers as
well as a couple of open-source
compilers compile the program and let's
assume that the program has been
designed so that it should print a
number that's all the program does if we
get different numbers from these
compilers then that indicates that at
least one of the compilers has a bug and
in this case I've singled out crying as
being the compiler that gives a minority
result and it would be likely that clang
will be the compiler with the bug here
although of course theoretically it
could be the only compiler that compiled
the program correctly or they might all
be wrong but in practice typically the
minority compiler is the compiler with a
bug okay so question for the audience
then why might this actually not signify
compile a bug because of undefined
behavior Yeah right so if the program
random don't see exhibits undefined
behavior then it would be no surprise
that you would get different results
from different compilers so mismatches
in results indicate bugs if the compile
is agree on implementation divine
behavior but this depends upon the input
program being free from undefined
behavior right so if the input program
is free from undefined behavior but does
exercise implementation define behavior
the compilers must agree on that
implementation define behavior but the
undefined behavior one is the real key
so I think it's instructive to take a
quick detour into the problems of
undefined behavior in the C programming
language so if you take a look at this
little program main so there what i'm
doing here is reading x from the command
line and squaring x and then if x
squared is less than zero printing x
squared is negative and then printing
the value we computed for x squared
otherwise printing x squared is
non-negative and printing the value
computed for x squared okay so if i take
this program and i compile it with GCC
and i would run it for example on the
number 10 then we see x squared is
non-negative 100 alright so what if
instead we run this on a large number
like 1 billion what do you think is
going to happen
is not a London is that right that's
pretty stable here 123456 because what
I'm doing here one American building on
American with a mug in here hahaha so
what you think will happen that we Frank
square 1 million all fluorescently over
thought something right so you might not
be surprised to see x squared is
negative and then a very negative number
right so now let me compile the program
again but this time with optimizations
ok so that's not a bug because the comp
C doesn't live you self is not supposed
to guard against over for right so that
might be what you expect to see there
was an over thermos unlike the right
result in a sense so you might think
that this is not an acceptable result x
squared is non-negative and then a
negative number so that's the sort of
thing you can imagine very much
confusing a programmer in a program um I
think oh dear you know there's a bug in
the compiler what's the compiler done
wrong this did something also long- yeah
so it said so that without optimizations
we got x squared is negative and a
negative number with optimizations we
get x squared is non negative and a
negative number right but this can I to
be quite easily explained so when you
write x times X in a sea program where X
is signed you are actually telling the
compiler that it is allowed to assume at
this program point the x times X does
not overflow because if x times X does
overflow then not just the result of
that operation is undefined but actually
the whole behavior of the program on
that execution is undefined so as a
programmer when you do an arithmetic
operation on signed you are telling the
compiler that this is not going to
overflow because if it would over for
the compiler can generate any code it
likes right so because the compiler
knows this did not overflow it's able to
do a good optimization right it can
optimize away that guide and it can
actually transform the program into this
program which is a more efficient
program and that's the compilers job and
this more efficient program prints the
result we get it says x squared is
non-negative and then it computes
whatever you got by squaring X and on in
some register and an x86
machine doing multiplication you are
going to get overflow you're going to
get wraparound you're going to get this
negative number so it's quite a nice
example of know the x squared is
positive yes interesting okay so the
compiler is smart dinner then well I
think the components market after know
that the semantics of this program is
identifying so came to why do it well
the compiler smarten up to the
somebody's is only defined if this does
not overflow and furthermore the
compiler knows that if it does not
overflow the result will be non negative
and therefore it can apply this
optimization right so it's applying dead
code elimination on the assumption the
program as well defined okay so so for
this random differential testing
approach to work we need the program to
be free from undefined behaviour so the
way this works in a program generates
like C Smith is you can use a
conservative effect analysis to for
instance make sure that you don't use
some pointer unless you're guaranteed
you've initialize the pointer for
instance as you generate the program you
can be conservative there and the
challenge in making a program generator
is it's easy to write something that
generates programs that are free from
undefined behavior if you don't want
this program to be interesting but
writing something that generates
interesting programs in the sense that
they really explore the language and
really give the compiler a hard time and
yet are free from undefined behavior
that's the challenge so Smith see Smith
has this effect analysis and also uses
safe map operation so for instance
instead of generating a divide where you
want to need to a random expressions see
Smith would generate a call to a macro
called safe div that we take e 1 and E 2
and the macro uses the ternary operator
to say that if e 2 is 0 then evaluate
the result of evaluation would just be e
1 the numerator otherwise it would be
the actual division and there's nothing
special about a 1 here the point is that
we need to give some defined result
anyone is probably more interesting than
just 0 or 3 or something because e 1 is
itself potentially large and interesting
randomly generated expression ok so I'll
briefly tell you how we lifted random
differential test into opencl so the ce
smith tool generates random C programs
that explore the richness of see and
avoid undefined behaviors so what we did
is built an extension called CL smith
that except the aims to generate opens
the L kernels that explore the further
richness of opencl because open sales
based on C so we could get a lot of the
richness of see the richness of open
sale already from C Smith but examples
of additional richness our vector types
and operations in open CL and into
thread communication so you have all
these threads running a GPU kernel and
communication between those threads is
something we were keen to explore we
need to avoid additional undefined
behaviors so for instance data races and
barrier divergence are two kinds of
undefined behaviors you have in this
data parallel world and also there are
some vector operations that come with
undefined behavior constraints and
furthermore we need to guarantee
determinism so in the world of
concurrency you can have programs that
are free from data races and yet behave
non deterministically so those programs
do have well-defined behavior but you
get a set of possible results from such
programs and for random differential
testing it were pretty difficult to well
it would be pretty difficult to apply
random differential testing if your
program can compute some result of an
unknown set because then you've no idea
whether two programs the same program
running on two different implementations
is giving different results because
they're both acceptable members of the
set or because one of them is wrong for
a compiler book recently knowledge of
Elizabeth because of the presence of
Atomics that's right I see very good not
because of just regular operations
because we were gonna get non
determinism from data races yeah it is
wait with Atomics good okay so a very
basic thing then is to instead of making
a random c program make a random opencl
colonel by having a colonel yep I'd be
able to guest programs or generate
programs and use Atomics well we'll come
to that okay but in general yeah we got
to be careful with users on MIT's in
carefully crafted ways okay so simple
thing to do that is have a program where
every thread runs a function and writes
the result of that function to an output
array it's threadid and this function we
can generate using C Smith because C
Smith can generate see functions opencl
is very similar to see in its core
language so if we've got this funk which
is a c function we can make every thread
run the same function and write the
result into an array and then we can
print the result print the contents of
that array as our program result so all
threads would run the same function
there's no communication between the
threads
and the only engineering challenge here
was to work around the fact that we
don't have globally scoped variables and
opencl so C Smith we generate a lot of
global variables we've got to find a way
random and what we do is you pack them
into a struct we have a struct that's
got all the would-be global variables
and we pass that around by reference so
really funk would take reference to
structure and if func calls another
function it would pass in a reference to
that struct so the reason we did this is
that I think in research is very
important to start with simple solutions
first before you go for more complicated
solutions and I hypothesis would was
that we wouldn't really find any bugs
with this technique because it'd be so
straightforward in fact almost all the
bugs we found were with this technique
so we found lots and lots we still
managed to you happy healthy happy but
yet cream isn't oh well I mean we did a
big evaluation and we scientifically
showed you know bah-bah-bah right
awesome science so well it's an
empirical say right the questioning so
to make an empirical study
scientifically just need to be
rigorously yeah yep so we found a lot of
basic compiler bugs in these compilers
so problems compiling the sequential
code that the threads execute rather
than difficult optimizations to do with
concurrency which is I suppose perhaps
not that surprising in a language like
opencl with hindsight it's a date
apparel our language so the programmer
is actually controlling the parallel
execution it's not that the compiler is
controlled in the parallel execution so
to some extent the compiler is not going
to be doing sophisticated optimizations
related to currency although i know that
some compilers do do some optimizations
to merge threads together for example
okay so i'll show you what one of these
random encounters looks like and if
you've ever seen a random program from c
smith you'll realize this is looks quite
similar so i'm going to deliberately
flick through this quite quickly just to
show you just to give you a flavor for
what one of these things look like so
got loads of variable declarations
inside these functions you have all
kinds of crazy code like four loops with
you know break statements in the middle
of them here's some opencl specific
stuff i'll come to you later a barrier
there ok so you can see this is not the
kind of program you would like to be
understanding as a human but these
programs are good at inducing bugs and
compilers so the next thing we wanted to
do was to support vectors and our
hypothesis here was that because opencl
has a very rich set of vector types and
operations these may be under tested by
highlighters so we extended CL Smith to
exercise this rich vector language and
this required some engineering effort
because C Smith the original tool would
slightly abuse the fact that C is pretty
liberal with the types and you can you
can implicitly coerce between most
integer types so in generating
expressions see Smith wasn't taking care
deliberately wasn't taking care to
attract the type of the expression being
generated to make this work for vectors
in open sale which have stricter typing
rules we had to really do some quite
serious engineering work but
conceptually this was straightforward
and we had to take care of some
undefined behaviors so for example I
thought I find a bug in Intel's compiler
because they ended up with a very small
program but my small program will try to
clamp a variable X into the range
minimum one maximum zero and then I
stare that the small program I thought
what does that mean to clamp something
in the range 10 and then I look to the
spec and it said that the vapor of pump
is undefined if min is large in the max
so you know in fact this small program
was just an undefined program so there
are a few cases where we had to treat
these vector operations to make sure
that they had well-defined behavior
under all inputs okay so just to give
you an example of vectors so if I search
here for cl ZD so can't leading zeroes
this is an example of an open CL vector
intrinsic this book this gives you the
number of leading zeroes in binary
representation of a number another one
is rotate so if you apply rotate you
give it two vectors and what it does is
it takes the first vector and the second
vector and for each component of the
first vector it takes the component of
the second vector and rotates this thing
the number of bits specified by this
thing and that's well defined even for
sign because open-celled demands two's
complement so you can do these bit level
rotations ok yep do you are down to use
these or is that already like some sort
of a medieval stage no no so these are
the original programs and what we do is
if we find a mismatch between
implementations what we've been doing is
reducing the large programs by hand
until we get small test cases and I'll
show you later some examples of the
reduced programs something we're working
on at the moment is trying to extend
existing work on reducing C programs to
open CL which has some practical
challenges
so in the car next racista than see
husband yeah and was it necessary to
gender in such large programs in the
first place so he's bounced in the ce
smith work they did a study where they
assess the extent to which they would
find bugs if they restricted to small
programs medium programs large programs
and that work they did find indeed that
you had to have large programs if you
want to have a good chance of finding
miss compilations and compiler crashes
now we did not do an equivalent valid
evaluation in the opencl context we but
we actually do have all the data at our
fingertips to to do that retrospectively
so there's something yeah so what was
there any sign of a reason oh well or
was it just I think it's a balance of
probabilities I mean you know you if
there's enough code if there's more more
and more code there's a higher chance
that compatible have an opportunity to
miss compil I think it's as simple as
that this guy said that efficiency of
Germany cities it's in case that for
every bug ya phenix is a spot of
programming in cases the same father
then the random number generator is not
efficient did you know generating us the
spawn of programs that find the same
book I think it's definitely true but so
in the ce smith work my room my memory
of that of what they said was that to
find bugs they needed large programs but
they could i think they could always
reduce them to small programs at still
exposed the bugs it wasn't as if they
had to be large it's just that through
large programs they find more bugs but
sure if they were doing you know if they
find the right small programs they would
find the bugs i mean i think the
fundamental question here is not so much
the size of it sound like you cannot
start on this goeth notice it's really
the debug ability of it if it's really
huge and our ability to deboard then the
chances of getting preg Sturridge's
right but i think if you find that
you've got program that causes to
compilers to give different results once
you find that you can then apply this
automated reduction technique which they
have it yeah and then you can get the
small program right you can get a small
example that can be fixed so i think the
strategy in c smith and see reduces use
big programs to find mismatches but then
you've got a reducer to give you small
programs and we didn't evaluate whether
we needed big programs here some of the
implement
tations be testable quite weak in which
case it or than we needed big programs
but some of them were pretty strong as
well in it and but we don't have the
reduction yet the automatic reduction so
reducing the big program by hand does
take longer although it doesn't take
proportionally longer because up when
you can prune away huge parts of the
program immediately you can just cut out
some function call this calling list of
the functions and you know right right
just the Delta debugging if you're like
yes if your ass exactly okay so the next
thing was into thread communication so
in open CL you can use barriers to allow
threads to communicate with one other
synchronization barriers and I
hypothesis based on having seen some
llvm bug reports related to open CL
barriers was that compiler sometimes
have a hard time optimizing around
barriers so we figured if we could find
a way to use barriers and have threads
communicate in a race free manner this
might give us a more opportunity to find
compiler bugs so what we implemented was
roughly the following imagine we've got
a bunch of threads executing a kernel
and we've got a shared array s imagine
we can give every thread a randomly
generated but unique index into this
array at the beginning of time so every
thread owns an element of this array the
threads can read and write that element
freely as they execute the konuan so as
the threads xq they've got unique access
to their element and then when they
reach a barrier synchronization we can
do an ownership redistribution so we can
change which thread owns which element
and then the Third's can carry on
executing this allows the threads to
communicate data values to each other
but in a way that guarantees freedom
from data races because between barriers
the threads have unique access and at a
barrier they then do a permutation of
who owns what so this is a fairly simple
way to ensure that we avoid data races
we have to be careful about where we
place the barriers though because in GPU
kernels you can't have barriers and
thread sensitive regions of code so the
way we dealt with this was we restricted
the use of thread ID in our random
programs so that we could place barriers
wherever we wanted ok so to give you a
little flavor of this in the random code
so here's an example of a barrier and
then immediately after the barrier this
T ID variable gets updated
to be this which is a random permutation
okay then shaz us about atomic
operations so indeed we wanted to try to
investigate the use of Atomics in these
random programs but Atomics are the one
way in opencl you can have race free non
determinism so atomic operations are not
deemed to race with one other and you
can use the Tomic's to for example see
who's the first to get to a certain
point in the code right so our
hypothesis was that the compilation
might be sensitive to these subatomic so
they'd be worth exploring so we wanted
to find a way to use Atomics in a
deterministic manner so we had a couple
of ideas and very much our approach it
was we were brainstorm ideas until we
came up with something that we were sure
was gonna lead to determinism and well
define us and we would implement it and
see what what would happen okay so the
first idea we have is atomic sections
the idea is we've give every work group
a shared counter call it C and an
associated result variable could see
result both initialized to 0 and then we
would inject in the code anatomic
section so this would involve doing an
atomic increment on the counter and
testing whether you get the constant
value D which is some constant chosen at
generation time if you do that means you
were the d+ first thread to execute this
atomic increment so if T was to for
instance then you get the old value of
the increment right so you'll be the
third thread to increment it if you find
it was equal to 2 and in particular
unless so many threads increment this
that the counter wraps around only one
thread can get into this conditional
agreed right so now that thread can call
a function which is a randomly generated
function and then it can add the result
of that function to the atomic counter
variable now the reason we made this be
an atomic add is precisely to capture
that wraparound case where you may
actually have an atomic in a loop and
you may have the possibility to the
counter wrapping around and then in
theory two threads could get in here and
if we atomically add then we're still
race free so how do we make sure that
this gives us determinism well we've got
to be careful this function doesn't leak
which thread executed it if this
function would somehow leaked the
threads ID then we would actually get
different results depending on which
thread got into that function because
that thread would then start to behave
differently and in particular that
thread may now not reach
areas that it would have reached
otherwise so this was actually the most
challenging thing to implement by a long
way almost all the bugs in our tool were
related to this mode it was pretty
difficult thing to get right we kept
thinking we'd found in fact we didn't
find any compiler bugs related to
Atomics but we kept thinking we had so
we kept thinking we found one we would
investigate investigate investigate and
we would find it was a problem with our
implementation so and you know we
eventually didn't find a single bug that
needed an atomic we found plenty of
mismatches in programs that contained
Atomics but we were always eventually
able to reduce them down to not need the
atomic in the end okay so yeah the key
thing here is that the effects of the
function should not be visible outside
the section there's pretty difficult
because this funk is going to be
computing with all kinds of pointers and
we had to restrict what could be done
with those pointers in in particular
which you shouldn't go to modify things
outside you should be able to modify
data outside this section okay so the
other idea is a simpler so some
operations in opencl deter atomic are
suitable for doing reductions in
particular add min ands or as three
examples you can do a reduction
operation on them right you can apply
these operations to a bunch of data to
get a result and because these
operations are associative and
commutative it doesn't matter in which
order you apply them you'll get the same
result in the end so the simple idea
here is that we randomly emit an atomic
operation so this is one of these
associative commutative operations and
we have every thread evaluate an
expression e anatomically apply the
result of e to a shared rebel s and then
we can do a barrier synchronization and
then we can at the end of the kernel
have the master thread from a thread
group add the final result of this s to
its final result okay so this is another
way of using some atomic operations in
practice all right so to show you these
Atomics in one of our random kernels so
here's an atomic reduction using max so
the threads are doing an atomic max
operation and this is the this
expression here which is fairly hefty
expression is that expression they are
reducing
okay and you might notice that we do use
a threads ID in the reduction operation
sorry having trouble with my cursor here
we use a threads linear global ID in the
upper on to the reduction and that's
actually safe because even though the
feds have got different IDs since
they're all contributing to this
commutative operation that's fine so
then afterwards we have a barrier and if
i look for atomic ink here's an example
one of these atomic sections so if we
atomically increment this counter
variable if its value 1 we must be the
second thread to have done this then
we've got some code which has got to be
thread sensitive threat insensitive okay
so the second technique we investigated
was equivalents modular inputs testing
which was proposed at last year's pldi
and this is a pretty cool technique that
the technique these people proposed so
it works as follows let's imagine you've
got a program in some programming
language and so let's suppose that this
program is well defined and it's
deterministic so we can compile this
program and let's imagine we only have
one compiler we don't have the liberty
of multiple compilers to check against
each other we only got one compiler
there could be a few reasons for this
this could be a new language another
reason could be that in some domains and
in particular the GPU domain some of the
vendors we've talked to have told us
that they're not allowed to benchmark
against other GPU implementations now I
don't quite understand the reasons for
that but I think it may be to do with
the possibility be includes a reverse
engineering labs but some of the vendors
have said that they're they're not
allowed to just get the latest tools
from some of their competitors and
compared with them so if you are under
those constraints or if indeed it's a
new language you have one compiler then
you can't do random differential testing
you can do it with multiple optimization
levels but you can't do multiple tools
so the idea of this is let's say you've
got to program p we can compile it and
stick it through a profiler with respect
to some input I and because the program
is assumed to be well-defined and
deterministic what this profiling will
do is partition the statements of the
program p into two disjoint subsets
we've got those statements that are
covered by the input I and statements
that are not covered by the input I and
I hope you'd agree with it if we run the
program again and again on I we would
get exactly the same partitioning
because the program is deterministic no
wonder find behavior no non determinism
get exactly the same partitioning so
what we can do then is
we call d the statements that were not
touched by I we can take the program P
and we can manufacture from it as many
programs as we like by messing with D so
we could delete some statements from d
or we could change some operators used
in the statements in d or we could add
some fuzzed code into D or we could take
some statements from the program and put
them again in 2d we could do anything
like to this this I dead code to make
lots of variants of P and these programs
globally speaking are completely
different programs that for the global
space of inputs might give totally
different results but they have the
property by construction that for I they
will give the same result so we could
then compile all of those programs with
our one compiler remember we own a one
compile inner and we could run them and
if they give different results let's
assume that again that they print an
integer if they give different results
we know something must be wrong with the
compiler right so this is a i think a
very smart idea from these guys at last
has peeled yet and we wanted to try to
validate whether this would be effective
at finding bugs in opencl however there
was a problem so first of all this
equivalence modular input requires the
existence of this input dependent code
if you've got a program that doesn't
have any code that's only reachable for
certain inputs then you won't be able to
do this manufacturing with multiple
programs secondly all this create a
program which has a substantial amount
right but oh so a selling point of this
technique is that you can apply it to
existing code all right so you might
have some test cases that were
handwritten they're already interesting
test cases and you can apply this
technique to those existing programs you
don't have to be using random programs
yeah so we were looking at trying to
apply this to existing opencl programs
but our experience from working with
these programs is that they don't
typically contain that much code that's
conditional on certain input values
having properties and the second thing
is you would need a profiler to
implement this technique and there isn't
a readily available opencl profiler so
the problems found on that tip about
opencl kronos just don't contain that
much input dependent code and second
there's not a readily available profiler
for opencl and of course we could build
a profiler so this was the fundamental
problem we didn't want to build this
profiler only to find that there was no
no I dead code to be found so our idea
was your ready source suggested this in
your
question was what we can make up this
input dependent code right we can make
what we could make programs that have
input of any code but if we've already
got a program we could give that program
extra code that's input dependent in the
following way so this is a very simple
idea but it was pretty effective in our
work and there's no reason why this idea
couldn't be applied to other languages
there's nothing opencl specific about
this idea so let's imagine that we have
got some piece of code yep sure yes
technique so I I was just imagining that
if i sat down and tap hard for say two
hours yep I can come up with five
different ways of compiler buzzing okay
this is one particular technique so what
is it that is ultimately going to
distinguish one technique from another
you may be sure that even in companies
that have the job of producing
commercial confider yeah there's a lot
of compiler fuzzing going on already
yeah what is what are we chasing here so
i think the bulb i think the goal of
compiler fighting is to find bugs right
and the way you find bugs with fuzzing
is by producing interesting inputs well
so I think there are two things if you
can fuzz in a way that allows you to get
high bandwidth then it doesn't matter if
your inputs are interesting on average
if you can get through loads of inputs
if there are some interesting ones then
you will find bugs with them eventually
so the challenge is to have a method
that allows you to very quickly try lots
of inputs and to make sure that there
are going to be a decent number of
interesting inputs in that set so in C
Smith what they were trying to do was to
try to explore as much of the C
programming language as they could and
try to not be restricted for example in
C Smith they didn't restrict to programs
that guaranteed termination because if
they did they could easily generate
terminating programs but they would have
to place a bunch of restrictions to
ensure termination and they were they
feared that those restrictions would
reduce the effectiveness of finding
compiler bugs so instead they had
programs that may not terminate and they
just use the timeout right so the idea
with fuzzing really would be I mean of
course there's no there's not really any
science in coming up with ideas for
making random programs right you can
evaluate the things scientifically but
the evaluation would have to be guided
by how effective your up finding bugs in
comparison to other fuzz's or as the as
you fix these bugs do you then find
anymore or do you basically have a bunch
of bugs that a given fuzzer can find you
fix those bugs and that fuzz and I just
can't find any more bugs
even though they're plenty of bugs hey
um maybe I'll disagree with the with the
kind of overall go back you your clothes
because to my mind it's the ghost hunt
to find bugs before it goes to find bugs
that matter nothing bill is a big
difference between the two which is why
we see so much regression testing can
just write every compiler that frankly
gets anywhere right because the PT
player that is in the number of programs
website so we have you are open waters
and they never eatinsane our customers
develop or whatever and Asajj they
really don't want to break those where
is three I think just about every
component developer who acknowledge that
there are dark and troubling corner
cases and yes maybe sometimes they would
like to know about these things but I
think at the same time to acknowledge
that the variety problems there just
that you know you have to prioritize
your time as well yeah so anything I
would say that anyone involved in the
real world of software would agree with
you that in any large software project
you have a priority list and you usually
have more bugs than you can fix right
you want to be equal results approach
for the private zone yeah but I would
say that if you're finding bugs that
people are fixing then that's a sign
that you are doing something that people
think is at least partly useful if you
don't fix it yeah I suppose yeah but I
mean if you email something privately
with the bug report and they say thanks
a lot and they say is we can I fixed it
then well you've certainly not done any
harm well of course they could introduce
more but of course they do issues more
about this I fixing the bug yeah he
knows right but i think that are you
away i would say that fuzzes are useful
is in trying to get some idea about
whether your system is satisfying a
modicum of robustness so if you run the
fuzzer and every 100,000 programs you
find a mismatch think you can maybe be
quite happy and you may not even bother
investigating those mismatches if you're
finding a really large number of
mismatches then you know I think that
might suggest it's just a basic quality
problem and you need to improve that
quality I think is sort of difficult to
give these questions definitive answers
right I mean
it's definitely true that what Matt what
counts is finding bugs the matter but
what but defining what it means for a
bug to matter is another question this
is a longest yes you can okay so the
idea here is suppose you've got an
existing piece of code this is a little
opencl colonel actually not a little
open tail condoms is a fragment of a
real open Co Colonel that does
breadth-first search let's say we've got
this piece of code then what we can do
is we can add a new parameter to it this
is a parameter which is an array called
dead okay and this is something we've
added and then given that we've added
this new parameter we can inject code
into the kernel that is dead by
construction so we can add a condition
here saying if dead at element 43 is
less than Delta element 21 then execute
this arbitrary code right and if we make
sure this condition is going to be false
at runtime then this code is dead by
construction so in particular if we fill
the array up with increasing values this
condition is guaranteed to be false this
code will not be executable and it
should therefore not change the
semantics of the program and the key
thing is that the compiler cannot know
what we're going to invoke this function
with that run time so the compiler must
compile this function to be to work for
whatever inputs would give it well
defined behavior and the compiler
furthermore is going to try and optimize
all of the code including this code and
if the compiler will get this
optimization wrong it may cause some
code that is actually reachable to be
Miss compiled so this is a very simple
idea injecting dead by construction code
this was a pretty effective and like I
say there's no reason why this could not
be applied to other languages okay so
what we did experimentally was we took
twenty one of these device in compiler
configurations so a bunch of GPUs from
Nvidia AMD and Intel some cpu
implementations from intel AMD and do
the previous thing that you were
inspired by and maybe we'll start
finding more words right you can so oh
and we did do that as well okay and an
FPGA implementation alterra and also to
the ocl grind open source emulator and
what we did was we applied random
differential testing by generating
60,000 kernels so we have six modes that
we come on CL smith in the basic mode
the mobile vectors the mobile barriers
the mode with atomic reductions atomic
sections and the mode with everything on
at once so we did 10k kernels each of
those modes we had to discard some of
them due to some bugs we find in C
l smith quite late on in the study so
this is very large study with a lot of
implementations in several times during
the start we had to restart because we
found problems in our tools and i should
say right now that I don't believe that
these 60,000 kernels are all going to be
good kernels there will certainly be
some bugs that we have not discovered in
our tools so I think any macroscopic
results we give should be given as an
indication of the quality of the tools
we're testing of course there will be
there will be some cases where when
you've messed up and have generated and
not a nonsense Colonel we applied Eni
testing to 10 real-world applications so
we took applications from the road inia
and powerball benchmark suites and we
injected dead by construction code into
those kernels and then we also did what
you were alluding to shares which as we
did random emi so we took a bunch of
kernels generated by CL smith and we
equipped those kernels with dead by
construction code as well is that where
you were what you were thinking of okay
so what we did here is we made 180 based
programs and then we tried 40 variants
for each of those based programs to give
us 7200 the reason for these slightly
funny numbers is actually we had 250 of
these programs but I told you where to
discard some of these programs and we
end up having to discard 70 of our based
program similarly and all the
corresponding programs so we have this
slightly smaller numbers than we would
have liked here so the first thing to
say experimentally was that we
discovered quite a lot of machine
crashes so some of the configurations we
tested we have to give up testing
because we found that the programs we
were generating were causing not just
the program to crash but the whole
machine to crash yeah so i'm going to
show you an example of this but i'm
going to save at the end of my talk
because the GPU driver is buggy it's
just operating some really or so that's
our hypothesis but we don't know but
it's it's pretty well it makes testing
very difficult if you want to run ten
thousand tests run them overnight what
we were known as we would set this thing
off go for lunch come back machine would
be dead so then we would try and log
where we got to because you know if the
machine would have rebooted that will be
okay because we could petition have a
script that would say well where did you
get to okay carry on but sometimes it
would just be that the machine was
frozen so this is pretty difficult so it
seems that a Miss compiled GPU kernel
can wreak more havoc than a Miss
compiled C program in our experience and
then it's quite interesting is
particular
action because you have these things
WebGL and web CL where you can visit a
website and it can make things happen on
your GPU so I was thinking of trying to
come up with website of death that says
if you've got an xxx EFT card don't go
to this page because if you do your
machine will just look up right so so
this was something that made the testing
very difficult for us in certain
configurations and we basically stopped
testing those configurations also cause
the machine to crash it's just that that
particular C program has to be run in
Colonel Warren as a driver right so but
what interests me is that the memory so
I think it's terribly buffer overflows
but I don't quite understand it I mean
if you imagine something running on a
GPU that's an off-chip I mean it's a
accelerator card then the global memory
as i understand it on that GPU is not in
the same memory space as your operating
system so i don't understand how
something like a buffer overflow could
be the issue and there and then the GPU
driver is going to be it says go execute
the program right but it doesn't
interact with the program as the program
executes so i fail to see how the
program doing weird things caused the
driver to do weird things so you know I
I don't really know enough about
operating systems to to know but it was
I found it very shocking ok so I'm going
to show you some data about the
effectiveness of the GPU bender yeah
we're in recessions and the other bugs
deterministic unfortunately no so there
so um we found that it was not
deterministic and actually would one of
the vendors in question their latest
drivers are much more reliable actually
than the ones we were testing is telling
us buffer will be deterministic would it
be deterministic whether the Buffalo who
would lead to that crash that's less
clear to me mutation are all Microsoft
was that these graphics drivers and one
of the most fun drives really yes okay
so what I'm going to show you here is
some data so I'm gonna look at is for a
given configuration and a given mode of
our tool i'm going to show you the
percentage of kernels that did produce a
result that was not in agreement with
the majority result for that particular
colonel so this ignore is time ax
ignores
no crashes ignores cases where the
colonel crashed at runtime is cases
where the program gracefully terminated
and gave an answer and that answer did
not agree with the majority does that
make sense so I think this is a
reasonable way of assessing to what
extent you're getting wrong code bugs
from these programs there are some
caveats though some of our programs are
likely not well defined despite our
efforts we don't know of cases where
that's the case but it's certain there
will be some the second caveat is that
of course it may be that sometimes
there's been a compiler that's been the
only one who got the answer right and
we're assuming that doesn't happen in
these results okay by think that's the
second one is more of a theoretical
concern I think the first one I'm sure
there will be some examples where the
problem is with us okay so we did 10,000
tests / mode except not as many of that
in atomic sections and all due to a bug
I mentioned that we found and see it in
C Smith CL Smith ok so the i'm showing
you four examples nvidia gtx titan GPU
and intel cpu a GPU from an anonymous
vendor and OCR grain which is an
emulator and i'm looking at
optimizations either off or on although
in this emulator the optimization
setting doesn't do anything so there's
just one column here and what I'm saying
here is that this there are these six
modes basic vector barrier atomic
sections and Tomic reductions at all
meaning everything at once okay so what
I'm saying here is for instance that in
basic mode and the nvidia gtx titan with
no optimizations point one percent of
programs appear that gave a result
appeared to give the wrong result right
so a couple of things we can see from
here are well first of all invidious
implementation seems to be doing pretty
well but you can observe that in all
cases by this one these two brothers art
I well obviously whether zettai actually
but in these three cases you can see
that there appeared to be more bugs with
optimizations on a numbered off which is
perhaps not surprising you might expect
that a compiler would would miss penny
more with optimizations on than off
although some of the vendors we talked
to said that they don't really test the
compiler with optimizations off because
it's on by default in opencl and if you
look at the entire results you can see
this plays out they didn't tell us that
actually but this appears to be the case
here so with optimization is off you can
see that there is quite some problems
and interestingly you can see that would
barrier mode in Intel they get a massive
increase in the in the Ronco
buggery and I think this is an issue
with fuzzing so the thing about fuzzing
is that a relatively easy to trigger bug
shows up a lot and we found a particular
bug to do with barriers on this version
of Intel's compiler and it just appears
that that bug we trigger all the time so
I don't think this means that you know
there's something terribly wrong with
their compiler and how that it's just
that in this barrier mode the kinds of
programs are you generating are very
likely showing the same bug over and
over again of course we didn't reduce
that many of these 10k test because we
were doing the reduction by hand you can
see in this anonymized configuration you
can see again that they do know
optimizations appears to be giving a
higher bug rate in general than the
optimization is enabled although that
that's not true in the basic mode and
one thing to say about this ocl grind
emulator so this is actually really
excellent piece of software from the
University of Bristol but it had a
couple of very simple bugs to give you
one example add a bug in the way the
comma operator in C was interpreted now
our fussing tool based on C Smith
generates the comma operator all over
the place really all over the place so
you can see that this appears to have
you know well this does have a very high
wrong code rate and you might think of
all I wouldn't use ocio grind but I
would actually be grossly unfair because
it's a very useful tool we found it very
useful in debugging our own tool it just
had a bug with the comet operator which
they fixed now and now you know if we
would rerun these things again with us
your grind you would see that rate would
drop way down so some some basic
problems can lead to a very high bar
great and in fact we were using ocl
grind actively at the moment because
we're generating we're building a
reduction tool to automate this
reduction process and we're using OCR
grind as our undefined behavior tester
because it does lots of checks for
undefined behaviour and it's a dynamic
tool so it scales well on the examples
that were using ok so a couple of
characteristics of the bug we found so
we found so we investigated thoroughly
just over 50 problems and we focus
mainly on investigating wrong code
problems so this is not representative
of the kind of problems you see this is
our focus was bias towards finding ronco
problem but these are the other things
we found on the way so we found a few
front-end bugs so a couple of cases
where the certain operators and language
which is not supported but we did find a
couple of spec ambiguities so there are
some weird interaction between vector
initializers and casts and it's not
clear to me what the right rules are
from the open seal specification and
invidious implementation differs from
Intel's implementation for example so I
thought that was pretty interesting we
actually found those because we were
generating some code that where the code
we were generating with sort of
ambiguous and we knew what we wanted
when we investigated it but we could
understand why there was disagreement
from the implementations we found load
of compilot internal errors a couple of
compiler timeouts cases where the hilar
actually get stuck compiling the program
a couple of runtime crashes although I
suspect there are many more of these
cases where the compiled program crashes
and then a number of ronco bugs and we
investigated a bunch of further bugs
arising from dead code injection and I
wanted to talk a little bit about the
nature of the wrong code books so a lot
of the bugs we found related to
incorrect handling of structs and this
might go back to ben's point about
whether a bug matters or not so in
opencl one does not tend to make
excessive use of structs in particular
you would not typically have a struct
with a struct inside it with a struct
inside it with a struct inside it with a
union inside it with an array of length
I thighs dome tent for inside it you
know the things you just would not do in
opencl of course the compiler should
still compile them correctly but you
might you know you might be sympathetic
to a compiler developer purse that quite
low in their priority list well we found
a lot of very basic bugs related to
struct handling and the reason we found
those is that I mentioned earlier on
that there are no global variables in
opencl and we mimicked boba verbs by
putting them all in a struct and our men
that any bug with struct compilation was
very very likely to show up in our
fuzzing because structs were fundamental
to our infrastructure so you know if but
we find some very simple bugs to do with
structs like destruct initializers not
matching up with the way structure
indexed um we find these problems in
most of the implementations we tested
but and those are the ones that the
vendors freaking to fix we didn't find
some bugs related to barriers but these
were a little bit disappointing in that
although they were bugs that did require
barriers to be present they actually
didn't require the barriers to be doing
something related to inter thread
communication in particularly we could
have cases where the threads would not
be communicating at all they'd be using
strictly private memory but the presence
or absence of some barriers would be the
difference between successful or
unsuccessful compilation so that was
quite interesting we don't know why
because these are closed source
compilers and we've had a couple of bugs
related to vectors and
sadly no bugs related to atomic
operations despite the fact that that
was the hardest thing to implement okay
so I'm going to finish the presentation
by showing you a few examples of bugs so
the first one I want to show you is
pretty simple this is a bug with the
rotate vector instruction so this rotate
takes a vector of size 2 and a vector of
size 2 and what it should do is take the
first component of this one and rotate
it by the number of bits specified in
the second component okay and the same
for the second components so what you
think the result should be them for you
take 11 x 0 0 and take the x component
or result the bits yeah should be one
okay and we're running this with one
thread X's component 0 here okay so so
let's run this um so we run our launcher
tool which launches the colonel and I'm
going to say rotate so platform 0 device
0 this is an old cpu compiler on my
laptop so you can see that we get the
wrong resulting we get ffff ffff and if
we would try this with Intel's more
recent compiler they they've
independently fix this problem so this
is not something we reported to them
they'd already fix this and if we look
at the assembly for this we see that
there's just some it appears to be some
constant propagation gone wrong in the
assembly code fffff is just soared to
memory there's no rotation going on okay
so that's an example of a small bug but
you know I would say that this seems
like a bug that could could wreak havoc
in an application that needs rotate not
quite sure what people do with this
rotate by the way we're taking bits but
I mean open still has a whole load of
intrinsic so I think come from the group
you created the standard lots and lots
of competing demands there you do we
soon enough protable sign bit
manipulations very author ok an ego so
this is an example with barriers so i
have a colonel it declares an int x
passes the address of X 2 h and then it
eventually right side the value of x so
H
what H does is it calls k okay and what
k does is it does a barrier no reason to
do a barrier no share memory going on
here and then it calls F and stores the
result of F in the pointer P which is
our X and what F does is it does another
barrier and returns one okay so we can
find here that you know this should end
up printing the value one because X
should end up in one and this is
executed by two threads and it needs to
be executed by two threads for the book
to show up although the fridge don't
communicate so if I would run this then
with optimizations enabled that we see
the correct result 11 and if i disable
optimizations then we get wrong result
10 right and we did look at the assembly
code produced for this but we didn't
manage to work out what was going wrong
here because it was extremely long
assembly code you know we didn't spend
the time to dig into that okay so that's
just a couple of the sorts of ronco bugs
we found so you can see then they're not
terribly obscure bugs I mean they're
relatively small programs that you feel
should work correctly okay so some
ongoing and future work so some of the
vendors we've talked to about this work
have been pretty interested in a fixed
bugs in their open sale compilers and
some of the vendors we've talked to have
been interested enough but have
basically said to us though for them
opengl is a much bigger priority to the
opencl so opengl is actual graphics as
opposed to this so-called
general-purpose graphics processing
right and I guess maybe not surprising I
guess because I'm very much in the world
of cuda and opencl I sort of forget that
there are people who actually do
graphics right thank you so some company
said you know great view at a OpenGL
version of this and to me that seems
very challenging in a way they're really
interested me because it opens yell
everything is floating point but it's
floating point with a distinct lack of
precise rules for what is acceptable
from a given operator and what's
acceptable ultimately is what would a
pass the conformance test suite and be
what would be acceptable to gamers or
two people who are interested in using
the GPUs that so if you want to be
labeled as an OpenGL compliant
implementation you've got to pass a set
of conformance tests so those
conformance tests do provide some
implicit specification of what would be
so that
specification of opengl as far as i
understand it replaces almost no
obligation in informal text on what your
floating point operators have got to do
so if you're a pedantic form a
verification person you could say okay
well i'm going to make them all return 0
all right but then you fail the
performance tests so there clearly is
some notion of what's acceptable right
there's the conformist s and there's
what would stop people buying your GPU
but there is no exact image a particular
OpenGL shader should produce the cycle
and said why all they just let the
market decide I suppose because they
don't worry i don't know but my guess
would be that they don't want OpenGL to
get a bad name huh yeah yeah demarcus
should you say that good yeah I mean
pretty much anyway so there you know
that is the point I'm making though is
that there's no precise specification so
you couldn't even do some kind of
abstract interpretation / approximative
analysis okay that even if there was a
precise specification so okay so that's
something that we were quite interested
in working on related to that is finding
floating-point compiler bugs so in see
there is some notion of what
floating-point cannon cannot produce if
the compiler obeys the standard but
compilers also have optimizations that
you can turn on like fast math where
they do more interesting things with
your floating point if you want speed
and then there's this interesting
distinction between result difference
due to an aggressive load the point
optimization that's correctly
implemented and the user asked for it
and a compiler bug and how'd you tell
the difference I find that quite a
challenging problem also compiler
fuzzing on non deterministic programs
that use the rich set of opencl Atomics
that are related to c plus plus 11
Atomics that seems like an interesting
challenge and they're more pragmatically
being able to automatically reduce these
bugs and rank them would help us make
more progress in this work and try more
interesting strategies and be able to
evaluate more than we have done which
things are working well and which things
are not working well so I want to
conclude by showing you this little
opencl kernel and this is doing a
reduction and this loop here is is a
reduction loop and it has a misplaced
barrier all right this barrier is
supposed to be there okay but it's
inside this conditional
and it still do that is free but this
program has got no semantics because the
barrier is in a divergent location right
so if you think that you know bugs and
GPUs don't matter then you know just
gonna melt his laptop here really step
away from the podium okay are you going
to show that you cause I froze my phone
yet but I asked me know is your cursor
frozen is it frozen yeah it's frozen I
don't even know her you see try typing
come up here never go if you want dad
apple just begun I gravitational okay so
on that note thank you very much I'm
really gonna stay but this happens all
of that um so what happens all the time
is that thing's freeze now so there I
discovered this unfortunately when I was
teaching at the upmarket summer school
two days ago and I was trying to show
that you get weird result with barriers
and I crashed my machine and had to
start using the blackboard you know for
my for the rest of the lecture because
this machine does this I find that this
machine has to reboot very well yeah
also so then after I gave the electron
the blackboard and you know I did manage
to reboot it but then it wouldn't
project probably oh ok but then actually
look so I did find that in this case it
paid the display had crashed and then
appears windows got the display back now
so that's why I thought the problem was
but then actually this morning I was
trying to just prepare this crash to
show you and I waited for about 10
minutes and the play didn't come back so
I don't know whether the machine had
crash or whether display would have
eventually come back so I saw him so I
may be an exaggerated when I said that
this craft my laptop I'm not exactly
where I said across these other machines
i mean they definitely did crash but
yeah I mean I suppose if this would lead
to something a long-running computation
on the GPU if there's barriers in the
wrong place and this may be leading to
the thing getting stuck in an infinite
loop you could imagine that could hog up
all the resources that are rendering
this is the same GPU this rendering
things to my screen right so you could
imagine that could be the reason
yep okay so anyway that was not that was
our badly defined program but imagine
your compiler miss optimized and gave
you that program yeah yeah yeah all
right very cool thank you look</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>