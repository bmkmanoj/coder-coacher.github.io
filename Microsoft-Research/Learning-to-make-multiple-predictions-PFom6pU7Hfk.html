<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Learning to make multiple predictions | Coder Coacher - Coaching Coders</title><meta content="Learning to make multiple predictions - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Learning to make multiple predictions</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PFom6pU7Hfk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
ok so I'm push Miccoli I'm researching
the machine learning and perception
group so and i'm talking about learning
to make multiple predictions so the
first question is why do you want to
make multiple predictions why not just
stick with the old sort of thing just
make one prediction right or maybe sort
of give a distribution right the problem
is that most users when they come to
Bangor when they basically interact with
our photographs they need solutions they
need results right one result or two
result or three results at the moment
the machinery is only to provide them
one result right and this is about
making predicting multiple sort of
outputs available to the user so let me
give you an example suppose here is an
image and you wanted to segment this
image in PowerPoint so what you want to
do is essentially to cut out this bird
from the photograph and paste it in some
different context or in some other image
so what you could do is basically you
can mark these sort of pixels saying red
pixels belong to foreground and blue
pixels belong to background and what
PowerPoint would do in that case would
give you this sort of a mask they sort
of a result and now you have segmented
your sort of bird and you can place it
in any sort of other image so what is
the problem the problem is that this
method fails so why does it fail it
fails because of two reasons the first
reason is that the model might be
misspecified so what do I mean the model
that I was using for the previous image
segmentation task is just a pairwise
markov random field it just sort of
encourages smooth segmentations it
doesn't know about objects it does not
know that the the head it should be
connected with the feet there is no
connectivity higher-order constraint in
the model why is it that these factors
are not
included in the model because they are
very hard to sort of do influences or
hard to do learning in right so we used
a very simple model which actually does
not describe the state of the world just
because we could do influence in it
easily and therefore you will get these
results and therefore one single result
of this model might not be good enough
so you might need multiple sort of short
set it the second sort of reason why one
single prediction might not be
appropriate is the problem might be just
ambiguous so the the user sort of comes
in marks these blue pixels as background
mozzies green pixels as foreground but
now the system has to sort of reason
about did the user want to segment both
trained coaches or a single train coach
so if the result was a single train
coach then this should be the result if
it was to train coaches then these two
segments should be the result okay so
wouldn't it be nice if we can somehow
create a pipeline or machinery which
could basically give out both these
results or a set of these results okay
now this is not limited to segmentation
it is sort of everywhere so if you are
thinking about any structure output
prediction problem related to images
Sadie blurring or denoising you could
now give the user not just one D
blurring or not one de-noising result
but give them say in 10 results and the
user can choose right so if you are sort
of uploading your photograph on
Instagram now the app could just provide
you nine filters and in a three by three
format and then you can choose which
enhancement you should you want for this
particular image there's no reason for
just one enhancement you could think
about what are the the best nine
enhancements as could be assigned that
could be sort of put for this particular
image ok so let's sort of recap how we
actually make predictions
how we do structured output protection
when only a single prediction is
required so most of these models like
the image segmentation model are just
linear models right so you have a bunch
of you have a vector of weights and you
have some linear sort of features and
then what you do is basically you train
this model by empirical risk
minimization okay so you have your loss
function you submit over your training
instances here's your ground truth is
your model prediction and now you are
going to just minimize over the the
parameters W you are doing empirical
risk minimization that's it simple stuff
we in fact we cannot do this because
this is a very difficult optimization
problems for people sort of use upper
bound right sort of a structured hinge
loss right the minimize this sort of
surrogate risk rather than the empirical
risk okay and this will give you a
single sort of results you have learned
your score function and then you will be
able to sort of find out the Y which has
the maximum score and that is the
segmentation or the late image labeling
result that you wanted okay so so
suppose here is a score defined over
this multi-dimensional this hugely
dimensional sort of Y vector this Y
vector corresponding to sort of in the
case of segmentation a binary vector
which is with the length of the number
of pixels right so there you have this
huge sort of space of wise and this core
function is defined over that and the
best sort of solution is the best
segmentation now if you wanted to get n
best you will see that most of these
segmentations are very close together
you will you might basically get a
segmentation which sort of sort of
differ by from one another by just a
single pixel so you don't need that
right in the case of the Train example
so if we go back in the case of the
trade example you want these solutions
which are very very different in terms
of having Hamming distance right from
one another if you just think about the
end based solution what it will do it
will give you one result which is it and
others
which is just 1 pixel away in terms of
having distance you do not want that
okay so what you might want is basically
instead of this where all the three best
solutions are tightly sort of nearby you
might want to basically get these best
modes of the scoring function but the
point is the scoring function itself is
was trained by minimizing the empirical
risk which and thus it only meant that
the best why under the scoring function
makes sense the others the scores for
the otherwise don't make sense if you
don't think about the margin arguments
for an up for that for time being okay
so what are other ways to actually
generate multiple predictions what one
could do is basically take the scoring
function and just add noise to the
weights the parameters just perturb the
parameters and then find the best sort
of wise based on the the new scoring
function right the perturbed scoring
function and you will get these samples
okay so that's one way to do it but then
you lose any guarantees now I mean if
the scoring function was trained in a
particular way then you don't you lose a
sort of all guarantees here but there
are works in literature which actually
take this into account very nicely ok so
what perturbation should one use in this
case the approach that has been taken in
the division literature is why not
generate a sort of solutions which are
different from one another so how do you
specify different so you will first find
the solution which is which has the best
score so here is the first segmentation
for example now you will add in an
explicit diversity term which into your
score function which says the next
solution has to be different now people
who sort of are familiar with DPP's
would know that there is the sequential
sort of diversity term which basically
says that the next sample has to be
different so you would sort of think of
it in that sort of way where you have an
explicit term which says the next
solution has to be different what it
does it makes the optimization problem
very very hard
still people have sort of used have
taken this approach so so first you add
this term you now you will get this
solution now you will get this solution
and so on again why are we doing this
because sy the scoring function was
trained by empirical risk minimization
and the only guarantees are for the the
best solution under the loss and under
the scoring function there's nothing
else that the training was doing so we
take a different approach and we say
instead of making multiple predictions
from one single model so instead of sort
of trying to reuse the scoring function
in some way to basically generate
multiple predictions why don't you just
learn multiple scoring functions and
just choose the best from each scoring
function independently right so this has
the benefit that if you learn now
multiple models you could sort of just
put them into a parallel architecture
and all these models will be generating
solutions simultaneously so you don't
have to wait for the sequential sort of
sampling approach yep this is different
from the perturb the parameters approach
because you're not so randomly procuring
the pieces but rather you're done
training exactly separate models
absolutely else that's sort of different
about the way they've been trained
exactly exactly so so how do we train
them so this is a good point so what we
do is we define a set loss instead of
our normal loss we will now say let's
have a portfolio of models and our loss
is the best loss under the portfolio
okay so we have these multiple models
and these multiple models are generating
multiple predictions and you will say
that the loss that this portfolio sort
of encouragingly the minimum of the
individual instances in the portfolio
okay so in this case suppose there were
three models and this was the ground
truth so the first segmentation model
produced this the second segmentation
model produce this crazy segmentation
and the
model produce this so in this case the
loss would be the minimum of these three
losses and it would be 3.44 am i clear
ok ok so now the question is how do you
minimize this set loss so recall that
even minimizing the structure output
protection problem in the earlier case
was in one wasn't it sells very
difficult now we are sort of thinking
about a portfolio of this these
structured output predictors right so
how do you do empirical risk
minimization within this so what we did
was essentially sort of came up with
this truck this set hinge sort of loss
and basically decomposed it and then had
a coordinate we wrote it in this sort of
way and then had a coordinate descent
method in which you optimize these
indicator parameters and then these
model parameters so let me give you a
sort of intuition about how this is
working essentially what the model is
trying to do it has specified some
models in the portfolio say five or six
right it has said five there are five
models which which are in the portfolio
what it will do it will say that each
training example can only contribute to
one of the portfolio's to 11 instance in
the portfolio right so so so if you take
if you think about a greedy approach you
train the first predictor on the whole
sort of with the whole training set C
which instances incur the highest loss
and now basically use those instances
for the second predictor right and then
do the same thing for the third fourth
fifth and so on of course that would be
just one iteration now you can do
basically you can go back in reiterate
okay so I say essentially you are
partitioning your training data by sort
of sort of assigning training examples
to different parts of your portfolio
okay so yeah so you just repeat this
process and so just to show that this
upper bound makes sense and this
algorithm makes sense you can see that
the objective function the objective
that we will minimize a it sort of goes
down and the training error goes down
now training error here is the set loss
and also the test error goes down okay
so all sort of well till now now this is
essentially the test error and here are
different baselines so mcl is basically
what we will sort of refer to to our
algorithm will refer to it as MCL CSV
CSS VN CSS we have this this red curve
corresponds to sort of manual clustering
so i told you that essentially what the
algorithm is doing is essentially
partitioning the training data into
different partitions and then using the
partitions into train parts of the
portfolio okay and the CSS p.m. CSS vm
is essentially saying let's cluster the
data first and then train individual
distances and you can see it's it's
quite bad the green one is basically the
best use method earlier where it was
using just one model and then generating
multiple solutions by putting in these
explicit diversity terms okay how much
time do i okay so should I take five
more minutes I have a question well yeah
so essentially it seems like what you're
doing is the risk minimization analog of
fitting a mixture model exactly because
you have the coordinate descent
algorithm exactly basically doing
assignment to each of these experts and
set loss is basically saying well you
know it's the loss of the expert that
you've been assigned to which which
sounds great but my worry is is it's not
it doesn't seem necessarily the case
that once you've done this kind of
harvest
that the other experts are going to do
anything sensible right there they're
sort of off the hook one year once an
image has been assigned tabs are expert
they can produce rubbish yeah and so it
seems like the needs to be something
else to get a diverse set of good
answers in there rather than yeah so
exactly exactly so so what your
interpretation about mixtures of models
is absolutely correct what the technical
contribution in fact is essentially how
do you train right was essentially the
training part we were not claiming in
terms of that we were the first to do
mixtures learning of mixtures so it's
exactly sort of model vixter learning
and your point is absolutely valid that
once you assign if any example then the
predictor is of the hook it can do
anything right so you can think about
this as you add in more and more
predictors at the in the model at one
point all the instances have been sort
of taken care of and then and the new
predictors can now just roam free they
can do whatever they want right because
they're of the hook because all the
instances have already been taken care
of the problem lies in the empirical
risk minimization if you were doing
Beijing risk minimization then this
would not have happened right because
they would always be some mass which
unexplained but now we have sort of
because you are using empirical risk
minimization we are in trouble so in
order to sort of so I should be doing
bezera specialization but I am sort of
doing it in a sort of crazy way by
having an explicit diversity sort of
regularizer so now this explicit
diversity or equal to either what it
says it not only do you want to sort of
minimize the loss but you want you have
to be different from each other so now
all the sort of predictors are coupled
right so you could in fact even put a
DPP prior here saying that you have to
be different from other people in terms
of what predictions you make for each
instance so so the results are good I
don't have time for it but we can be
getting sort of sort of explains in I
really wanted to go into one more I just
wanted to make one more point
so the example that I gave till now was
in user interfaces where the user can
choose if the Oracle and can choose
between sort of K examples you sort of
provide to the user the second a very
nice approach that we have just used
this for is inverting generative
procedure so suppose you have a 3d model
of the scene and you are given an RGB a
bitch and our depth image and you ask
the question where is the camera right
where is the camera when it is looking
at this image where is the camera in the
scene so it this is a very very simple
model a very very simple problem
mathematically you are just trying to
find the camera pose which which when
rendered gives an image which looks like
the observation right so this is general
sort of inverse problem the problem is
that this minimization is very hard to
do so what Jamie and others have done is
basically used a discriminative Lee
trained predictor to actually just
directly make the prediction now the
problem is that just making one
prediction does not always work so what
do we do we just learn a portfolio of
these these predictors so instead of
just trading one forest one
discriminative pipeline we will train
multiple discriminated pipelines which
try to do the same sort of thing which
try to minimize the set loss okay so I
of course this improves again the
results and i think i am out of time
right okay so essentially what this
graph shows is that the on the x-axis
are the number of predictors right and
each predictor is basically giving it
gets to where the camera is and then we
will start from that pose and then
minimize our inverse we do the
optimization that we just mentioned and
you can see if you choose the Oracle
after you sort of minimize that this
error once you minimize this error and
you minimize this error with multiple
starting points corresponding to the
different predictors in the portfolio
and then if you choose the best one
then you get this performance if you
choose basically these are essentially
generative models right and they cause
they give you different levels of
accuracy but you can see that as you
increase the number of predictors it all
sort of increases and all these sort of
multiple proposals are done in parallel
there is no sequential thing about this
so thanks for listening and these are
the conclusions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>