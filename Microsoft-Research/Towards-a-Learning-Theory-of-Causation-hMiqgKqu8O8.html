<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Towards a Learning Theory of Causation | Coder Coacher - Coaching Coders</title><meta content="Towards a Learning Theory of Causation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Towards a Learning Theory of Causation</b></h2><h5 class="post__date">2016-06-27</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/hMiqgKqu8O8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so thank you um this this talk is to
review our submission to icml the the
most recent word I've been doing which
is to try to solve the problem of causal
inference from the machine learning
point of view so to start with well this
is doing work with Creek mo Bernard and
Ilya from the Max Planck Institute for
intelligent systems in Germany and the
problem with causality is that it is a
concept that is even difficult to define
to start with so maybe I can use the
audience and do a check if if you can
tell me from these two random variables
whether X causes Y or Y casa sex and by
causing I mean that if I intervene in
the cost the effect will change but if I
intervene in the effect the cost will
remain the same right so you have to run
the variables you have the dependence
pattern of their joint distribution in
this scatterplot can you tell me hands
up if you think X casas y 1 ok half of
the room so hands up y cosas sex ok so
it seems like the inference of the room
is X causes Y and this is indeed the
case X is the elevation of some German
cities and why is the temperature
recorded at some point in this series so
if you intervene in the elevation the
temperature will drop right but if you
intervene in the temperature of your
room for example turning the heating on
what your room will not elevate in in
this space right at least in most cases
so second one that's X cos Y hands up y
cosas sex ok so y cosas sex is more
popular choice maybe because you thought
I should put one in each direction but
here the answer is none here x is the
number of ice cream sold in the US and
why is the number of murders committed
ok but still in the scatterplot you can
see some some some dependence butter so
what is the difference with respect to
the previous example right here if you
if you play God and you
make humanity to consume more ice cream
you do not expect people to kill each
other more or less and if you intervene
on the number of people getting killed
you don't expect people to start
consuming more ice cream so the
dependence here is being generated by
some common cause and this is the the
weather it seems like when weather is
nicer people tend to eat more ice creams
get together more in the streets things
get complicated than they kill each
other more and and in the first case
what we have here is a direct cause
effect relationship okay so elevation is
directly influencing temperature in the
interventional sense that if I interview
if I intervene in the in the altitude of
the measurement the temperature will be
affected but in the second case this
common cause is responsible for creating
this dependency and the question here is
now can we just from observational data
from this scatter plots in fair if we're
dealing with this kind of situation or
the other one and the answer is no in
the most general sense this this task is
impossible but as humans we keep doing
it so why not try and why not try to do
it from the machining machine learning
point of view right so just to give you
another example of when correlation the
symmetric concept of dependence is not
really capturing the essence of the
asymmetric concept of causation here you
have another screenshot from amazon so
here you are buying this back and well
amazon will tell you better together or
works well with it you know since you're
buying the bag why shouldn't you buy
this laptop it goes well with it and you
know this feels wrong but it makes sense
that if you're buying the laptop you
should be recommended the back maybe
that's more sensible so amazon has
improved ever since and nowadays if you
are to buy this glass room to shine
Schneider which is a circular glass
cutter your recommended some other items
like like a balaclava or a backpack with
self-deploying wings of Batman so
there is a massive metric semantics
underlying every correlation and my
message here is that every machine
learning algorithm is based on
correlations or dependencies so if we
make an effort to go in the in the
direction of using Gauss effect
relationships instead of dependencies
maybe we can fundamentally and
transversally improve machine learning
algorithms okay so in a nutshell we are
given some sample from the Joint
Distribution of some variables in this
case ABCDEF and we're interested in
going from this to this which is the
causal structure underlying the random
variables the cause-effect relationships
okay and yes a historical remark there's
very true there's very important players
in this story the first one is David
Hume and Scottish philosopher from the
18th century he was the first one of
saying you know you cannot observe
causation you can just observe
dependence buttons and as humans by this
repeated observation of dependence
patterns you can infer causation but it
is not possible to do directly and then
maybe maybe David Hume was the first
philosopher to take causation as a
philosophical issue and I studied in
depth and then at the other spectrum one
of the most contemporary persons to
study causality in a statistics as you
de Appel who was awarded the tuning a
war in 2011 he was the main proposer of
graphical models and and base nets which
is the this graph that I showed you here
and which will be the main mathematical
tool that we will use ok so what is the
state of the art to recover coastal
structures from observational data so
one of the most widely used algorithms
is the PC algorithm it was proposed by
Speights and colleagues back in two
thousand and it works more or less as
follows you have a set of these random
variables and if you are interested in
determining whether there's a
cause-effect relationship between a
variable I and J xin XJ then do we look
for every possible subset of the other
run of the other random variables in the
set and if you cannot find any set
such that when you condition on this set
these random variables become
independent then there must be something
else responsible for this dependence and
we conclude that this is a cause-effect
relationship right so if you condition
on every possible subset of this set of
random variables and still these two
variables are dependent then you
concluded their circus effect
relationship and this looks like a very
good thing to do but there's a lot of
assumptions kicking in like you have to
make very strict assumptions between the
D separation properties of the graph and
the joint probability distribution you
have to assume that everything that is
to be observed is observed so there's no
latent variables playing any role and
then even though you consider all these
assumptions in in some cases like this
one for example and you cannot recover
the truth the true graph you can only
recover the Markov equivalence class of
the cause-effect structure underlying
these random variables and since you are
exploiting conditional dependencies then
this algorithm cannot work in the two
variable case right if you only have two
variables you have no third variable to
condition on to make your causal
inference in this way so this these
methods do not work for the two variable
case so for the two variable case we
have another set of algorithms for
example this is called information
geometrical causal inference method and
it will look to extract cause-effect
relationships between random variables
connected by a deterministic and
invertible relationships and the way
that it works is to assume that the cost
is generated independently from the
mechanism mapping it to the effect right
so if the cost in this case has a
uniform distribution and the effect
which is this function is generated
independently it is unlikely to find the
correlations between the slope of this
function and the density of the input so
if you look at the effect here which is
why then regions of lower slope get
translated into regions of high density
because a lot of mass from the cost has
been mapped to the same
point ok so this asymmetry is one of the
many footprints that you can use to
perform causal inference a second one is
the additive noise model here do you
allow your data to be noisy and what
you're going to do is two things first
you're going to fit a function to your
model to your data and then you're going
to look for the direction under which
your noise becomes independent from the
input ok let's say the variance of the
noise so here X is causing why again and
you can see that the values of the noise
from X to Y is more or less constant
across every possible X but if you turn
your head 90 degrees you can see that
the values of the noise in the opposite
direction Valley is a lot ok so under
some technical assumptions you can
conclude that the correct cross or
direct direction is the one that allows
you to have this independence between
cost and the residuals of your non
linear fit ok so this is more or less
the flavor of the state of the art so as
you can see the problem with this method
is that each of them has a very
particular set of assumptions on your
data and these assumptions are really
often difficult to check in practice so
it seems to me that there's a lock for
the general cause-effect inference
procedure that will add up to the data
that you have to analyze without making
these strong assumptions or being so
tailored to to the assumptions that you
need so I first step towards the
resolution of this problem was given by
a Calgary competition and here the the
setup of the problem changed here you
are given a lot of data which is this
set and each of the elements in your
data is going to be a sample from two
random variables cause-effect and label
analeigh and the label will tell you
whether X causes Y or Y cosas sex so
this is a fundamental change on the
problem definition jur you're going your
phrasing cause-effect influences a
classification problem right because you
are given many many many scatter plots
so each of this SI is a scatter plot as
i showed you before and then li is just
a label saying X causes Y or Y cosas
so now the pipeline would be first to
extract the set of features from each
scatter plot and then build a classifier
on top of these features to classify the
direction of newest scatter plots ok so
the participants usually crafted a set
of features by hand let's say the
entropy of X so each si is defined on
xinyi two random variables so for
example crafting the entropy of X the
entropy of Y conditional entropy is
mutual information higher order moments
and so on and then once you have this
handcrafted back to the real features
then you can just build a classifier
that predicts the label of new scatter
plots and this completely beat the state
of the art and worked very well but the
thing is that if you want to analyze
this pipeline is very difficult because
you are crafting the the features by
hand and then how can you tell what this
converges to write this as you get more
and more data so this project that I'm
presenting here is just an adaptation of
this scheme in such a way that we can
analyze it we can derive convergence
rates and consistency and then do some
experiments to to prove these results so
this is the general picture here we will
assume the existence of some
distribution here that we call the
matter distribution and this is a
distribution of distributions ok this
distribution will give you pairs of
scatter plots and labels and these
scatter plots are defined on two random
variables which are related by the
causal relationship that the label L is
is indicated ok so the matter
distribution will sample densities on
two random variables connected by the
causal relationship defined by the label
and then from these densities we will
sample some finit samples ok so there's
a two-sample stage here first your
sample measures and from these measures
you sample samples ok and this is the
data that you get to observe and now the
question is how can I feature eyes this
scatter plots in such a way that I can
derive my consistency and learn learning
rates right so we're going to use this
meuk which I'm going to define in the
next slide on the empirical distribution
defined by by there by the samples SI 2
okay so in the end of the day this set
is going to be the data that I'm going
to fit to my classifier which is pairs
of features from the scatter plots and
the binary labels okay what are these
features that I'm talking about this
these features will be Colonel min
embeddings so kernels are used
throughout machine learning to map
points into a high dimensional space and
in in this high dimensional space you
assume that you can use linear models
because all the nonlinear dependencies
have have been unknown in this high
dimensional space so this is kind of the
same thing but instead of mapping points
to a Hilbert space I will map
distributions to a Hilbert space how do
you do that how do you map a
distribution P to a Hilbert space well
you just take the average of your
feature map of the of the current that
you choose let's say for example the
Gaussian kernel it's the one that we
will use anyway and then you just
integrate the feature map of the
Gaussian kernel over the measure okay as
I said it is not realistic to assume
that we can observe measures it is more
realistic to assume that we can observe
the scatter plots that I showed you
before so then this integral becomes
just a sum of the empirical measure of
this category okay so I just take my
point i compute the feature map of each
of the point in the scatter plot with
the colonel i take the average and then
that's my feature map okay so for the
Gaussian kernel this is actually an
infinite dimensional feature map okay so
this is a the administration of what's
going on you have two probability
distributions here in your original
space these are to scatter plots let's
say and you map them uniquely to a
Hilbert the space associated with some
kernel k okay and this is the the
feature map for the distribution one and
the feature map for the distribution to
and if your kernel is characteristic
this mapping is injective so you don't
lose any information okay this is the
ideal case on which we get to observe
the measures but in reality will serve a
scatter plot a scatter plots that it's
finished samples so the picture looks a
bit more like this you get the sample
from the the random variables x1 y1 and
you get another scatter plot from x2
I too and you can map this again
uniquely to a Hilbert space right and
now the mini embedding will have some
variance and this variance is going to
be intrinsic to the to the sampling of
your method if you get one sample from
one distribution and you get the second
sample from the same distribution well
due to the finit sample size you you
will have some variance and we want to
take account for this variance in inner
inner inner theory I'm going to skip
this but in the end of the day we want
to measure how quickly you approach the
best classified in your class as you
have served more measures and as you
have served more samples from these
measures okay there's this two-level
again so n is the number of measures
that you have serve so this is a quite a
standard result from learning theory and
then this ni is the novel part of the
bound which tells you after you get to
observe more and more points for each of
the scatter plots then your bomb gets
tighter and you approach the best
classifier in your class okay so if you
observe infinitely many measures and for
each of the measured you have served
infinitely many points then you get your
your consistency in the learning problem
okay a bit of experiments this
experiment is linear models so each of
them of the scatter plots will be a
linear relationship between two
variables and this linear relationship
will be polluted with a Gaussian noise
so you can prove that this is an
impossible problem to solve you can fit
the the same model in one castle
direction or the another so in this
sense we get forty nine percent accuracy
and I put a smiley face because this is
actually what you are supposed to get
okay if you make it non linear so now
the coastal relationship is as the one
as i showed you before then the accuracy
goes up to ninety seven percent the
model becomes identifiable in this sense
okay so this is all synthetic data for
training and testing what about if i use
a generative model for a synthetic
generative model for training and some
real data what do we get so we have this
tubing and cost effect bears this is
82's cattle
of real data I collected by hand with
known causal relationship and and you
you get the state of the art in the
indeed in this data set and much faster
in in practice we're using a random
forest to classify them weddings so you
don't have to do any independence
testing you don't have to fit any any
any complicated model you just push the
embedding through the forest and you get
your your label or coastal direction
okay another problem is to distinguish
the ice cream and the elevation
temperature case and we get good results
as well another case would be to to test
independence which is to test these guys
versus the situation where there is no
link between the variables this would be
a dependence test trained on data for
data and you also get a significant
result of chance okay this is a rather
philosophical problem I give you a time
series but I don't tell you if the time
series is on the correct time direction
or I give it to you reverse time so here
you want to classify whether xt causes
xt plus one right in the time series or
whether XT plus one costs 60 and this is
impairing the direction of time in the
time series so if I give you this to
time series I don't know about you but
it is pretty difficult to me which one
is the contact point but the method can
achieve eighty-two percent
classification accuracy and real google
time series and i'm going to skip how I
do this for ducks because some I'm
running out of time but up to now I just
I just did Costco's effect inference
between pairs of random variables you
can extend this to do it on many
variables and we did this in two data
sets this is the data set on on cars and
for example the variables that that are
in the data center horsepower the weight
of the car the acceleration that year in
which the car was released the number of
cylinders and the engine displacement
and then the target variable usually in
this data set this is the consumption
the miles per gallon of the car and what
you need a human component to interpret
the result but it kind of
sense that the horsepower is crossing
the consumption to go up as the number
of cylinders the H is also negative
influence on the consumption because
cars get more efficient and so on the
car gets more acceleration as it gets
new where the weight is also a cost of
the horsepower and so on so well it's a
bit hard wavy but this is another data
set Avalon's are some creatures living
on the sea is also from the UCI data set
and then you have the mid weight they
got weight on the shell wait and you can
see that these two these three weights
contribute to the total weight of the
thing the h of the thing will cost the
weight the left the diameter and the
height to to evolve and so on so it
seems like the method at least this
preliminary results and X is able to
attract the relevant cause effect
relationships okay I will conclude here
my conclusion is that causality is
somewhat learnable from experience as
David Hume proposed a couple of
centuries ago but there's still a lot to
do right the DAC experiments that I
showed your very preliminary and we
still need better routines to learn the
matter distribution and the kernel
functions used to distract these
features and maybe as as related feature
work you can use this kind of
distribution or classification learning
theory to learn maybe the number of
components in a mixture maybe the
dependency statistic maybe some kernel
hyperparameters regularizer think that
you can learn directly from data but do
not necessarily have a closed form
solution okay that's it thanks we have
time for one quick question maybe
and you didn't challenge yeah so the
competition yeah the competition had a
dataset right and this data set was
built by someone and we believe that
they there might be some biases on this
data set so if your hand crafting the
features during weeks to push up your
validation score it makes sense that you
will have captured these biases on the
data set and we are using a completely
automatic model just a colonel in
embedding with a Gaussian kernel and and
drop it there so probably that's the
reason I don't know</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>