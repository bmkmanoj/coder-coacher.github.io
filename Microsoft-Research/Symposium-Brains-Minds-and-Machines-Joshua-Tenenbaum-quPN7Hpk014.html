<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Brains, Minds and Machines - Joshua Tenenbaum | Coder Coacher - Coaching Coders</title><meta content="Symposium: Brains, Minds and Machines - Joshua Tenenbaum - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Brains, Minds and Machines - Joshua Tenenbaum</b></h2><h5 class="post__date">2016-06-13</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/quPN7Hpk014" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">materials supplied by Microsoft
Corporation may be used for internal
review analysis or research only any
editing reproduction publication
reproduction internet or public display
is forbidden and may violate copyright
law
so let me introduce now Josh Tenenbaum
he also does not need an introduction I
will only say that he represents
cognitive science in the center and
today and I think that's a big important
part of understanding human intelligence
the brain and the mind and I would like
to add that josh has been instrumental
in getting our centers a table without
him the center would not exist Josh okay
great thanks to all the organizers that
Tommy let me return that a number of
times over we owe so much in the center
to you and thanks for putting together
along with Max and Gabriel a great
workshop that tries to show this vision
to the rest of the community and I think
I hope all of you I mean you're all here
so I am very pleased to see people
interested in the connections between
the study of intelligence in brains
minds and machines I have here the names
of all the people whose work I'm good
actually talking about and but they'll
be highlighted on the particular slides
and I should thank them in advance I
tend to go a little bit over it and so I
want to make sure that I say that very
clearly I'm gonna be talking about the
work of a number of really brilliant
people who have been lucky to work with
and I'm very happy to share it with you
guys here um like many of the other
speakers I I felt like I had to start
off with some history and I won't um
I'll just flash this history by you know
it's exactly the same history you just
heard about but the thing I want to
point to here is that there's a success
story for the study of intelligence
across brains minds machines it's just
the one that the speaker in question or
we're just debating about before and
it's really about one aspect of
intelligence though which we could call
pattern recognition
it's striking going back more than 50
years right that the very same circuit
elements that seem to be there in early
visual cortex in the work of Hubel and
Wiesel what we now call
linear classifier seem to be useful for
solving the classic problems of pattern
recognition like say taking a letter X
and being able to recognize it
regardless of where it appears in the
image or what other things might be
cluttering it up and then over a couple
of decades write that idea was was
scaled out into multi-layer layer
hierarchies the Neo cognate Ron again
motivated by the same kind of basic
pattern recognition problems but mostly
on very simple theoretical examples and
then keep going another decade or two
the work of Yann Laocoon and and many
colleagues at AT&amp;amp;T just won one place
where you take the right really really
smart and hardworking engineering
dedicated engineering trying to make
this real-world combine it with good
real-world data sets like the MMS data
set and then you have something that's
actually useful technology that now it
can recognize letters and numbers on
handwritten checks and envelopes and so
on okay
again keep going forward make the data
set a lot bigger and maybe a lot more
interesting for real-world pattern
recognition problems like many classes
of objects many many examples and then
you know the rest is history you have
image and that you have Alex net and and
we've all seen that okay and then again
from the standpoint of brains minds and
machines it's quite striking that these
same kinds of ideas have have actually
provided great qualitative and
quantitative insight into the behavior
and the brains of object recognition in
in humans and other primates okay so
what else is needed what why are we not
done well here's the basic thesis of my
talk and I think you can see this in
common with many of other speakers which
is that intelligence is more than just
pattern recognition okay in particular
what I want to talk about is the aspects
of intelligence that we could call
modeling the world so this means
explaining and understanding what we see
imagining things that we don't see but
could write problem solving and planning
actions to make those things actually
exist in the world and then building new
models as we learn more about the world
these are the problems that I think are
particularly interesting about human
intelligence and that I want to
understand
now it's important that this is not the
same distinction this distinction
between pattern recognition and modeling
the world is not the same as the
distinction between say perception and
more general flexible thinking you can
see all these more interesting kinds of
thinking like processes in perception
and I'm going to talk about work we've
been doing which is basically in within
the domain of higher level more
cognitive perception partly because
that's where I think the connection
between brains minds machines is most
readily made in particular I'm going to
talk about two kinds of sophisticated
perception as understanding and modeling
the world one having to do with how we
go beyond just recognizing patterns and
images to really grasp the whole
physical world I mean look around you
just look around the scene where you are
right here and for all of you who are
familiar with the state of the art in
pattern recognition in computer vision
just think about how little of what you
can see and how much of the texture of
the objects where they are all the
things you could do if you were going to
plan actions move around move things
around move people around how little of
that is really being tackled currently
another thing I want to talk about is
learning and in particular something of
this really distinctively interesting
kind of learning that we see in humans
and and maybe rats but it's really
mostly about humans kind of one-shot
learning the ability to learn some kind
of a model of the world from very little
experience maybe even just one example
and the approach that's in common to all
of these is really sort of an old
approach I mean all the good ideas are
old it you could you could put call it
something like this it's it's basically
about a causal perception namely that
what we're doing is is we're trying to
invert the causal processes that that
generate scenes and then the generate
images from scenes it's an idea that is
in many ways attributed first to
Helmholtz although I'm sure you can find
versions of it going back to Aristotle
at least in the Western tradition geoff
hinton was was and continues to be one
of the best proponents of this idea for
people who are familiar with the
Helmholtz machine an earlier version of
deep learning or one version of deep
learning a lot of what I'm going to be
talking about can be seen as a version
of this idea only instead of
representing the causal models with
neural networks we're going to be
representing them with a kind of
representation called a probabilistic
program this is just a figure from a
very nice recent paper by Zubin gar
money in nature
surveying a number of developments in
probabilistic AI machine learning
including probabilistic programs and for
those of you who I mean I'm sure pretty
much everybody here knows about
graphical models you can think of a
probabilistic program as a
generalization of a graphical model
where you use programs to represent the
causal process and not just graphs so
just to sum up the approach very clearly
here right we're trying to we have the
idea that we're going to be doing
reasoning with these richer causal
models as a kind of Bayesian inference
on generative models defined by programs
as opposed to say graphical models in
bayesian networks and we're gonna talk
about then vision a richer kind of
vision that really graphs more of the
physical structure of the world as
inverting these graphics programs the
kind of programs that you might use
actually like in the video games that
Dennis was talking about you know we're
like a game engine graphics renders and
then concept learning as inverting a
generative process that that produces
objects as a kind of program induction
or program synthesis okay and for those
of you who are interested in deep
networks I would it's important to say
this is not meant to be mutually
exclusive with a neural network approach
in fact I think it's quite complimentary
and one of the things I'll briefly talk
about is ways they can come together but
maybe that's something we can talk about
in the panel so first starting with the
problem of perceiving the physical world
maybe to motivate this more concretely
think about some hard problems of a
person detection things that go beyond
the current pattern recognition approach
to say identifying localizing parsing
out bodies and images I think it's I
think it's fair to say that conventional
say for example detectors for people
which are quite good in a lot of
settings would have trouble with most of
these images here they might be able to
tell you for say the image in the upper
left they might be able to find the
people who are on the front row of that
bicycle group of bicyclists but they're
not going to be able to tell you that
there's maybe something like 30 or 40
bicyclists in that scene or to tell you
that in this scene over here in the
upper right that there's a couple of
hundred people or here maybe about 50 60
people and here zero people right so
think about how is your brain able to do
that or to take a problem take this
problem here this is an airplane full of
computer vision researchers from the
last computer vision CPR conference
again conventional systems for detecting
people or parsing out body pose are not
going to be able to find most of the
people in the scene because most of the
people are mostly invisible yet you have
no trouble combining all the you know
all your knowledge about the physical
world about bodies about airplanes and
not only can you detect the people but
you can sort of parse out where their
bodies are so let's just take if you if
you can see here I mean it's it's hard
with the big room I don't know let's
let's take this guy here okay do you see
his head in his shoulder yeah this is an
interactive demo okay now um think about
so you see his head here his shoulder
here
think about where his right hand is and
I just want you I'm gonna move the arrow
over here over over the image I just
want you to hum when I get to where his
right hand is is it over here
you're supposed to hum not laugh okay
think of how about his um left big toe
okay
hum when I get to where his left big toe
is okay very good yeah so how are you
able to do that nobody can see his left
big toe but you have a model of bodies
along with the rest of your model of
images that allows you to solve that
problem
or let art to take a problem in face
recognition again where there's been a
lot of success in what I'd call the easy
problems of face recognition here's a
harder problem which at least until
recently I mean I'm sure there's some
experts on face recognition here and I'm
I'm actually excited that in the last
couple of months some of the best
machine face recognition systems are
starting to be able to solve this kind
of problem but say going back even a
year certainly more than that the best
say deep face type systems you know
basically would just say this problems
too hard we're not even gonna try to
solve this so here's a picture of my
collaborator and postdoc ill Creole
Durham this guy on the Left does anybody
know who the guy is on the right it's
also lker okay how many people can see
that they're the same person raise your
hand if you can see they're the same
person that's at least plausible okay so
um then the rest of you should just be
more daring okay
so as we as we've shown in experiments
you can vary you could I can show you
someone you've never seen before and
vary the viewpoint and the lighting
conditions quite severely and you can't
perfectly identify the person you know
you're not gonna be 99% correct but
you're gonna be well above chance I'd
say a hard same different task like this
and we'd like to understand how you can
do it
okay so here's an example of doing this
with one of these kind of probabilistic
programs a probabilistic graphics
program this is work the first part of
this work is was led by Tejas Kulkarni
one of our graduate students and
presented at the last cvpr and the idea
here is to write down with a simple kind
of graphics program there's a face
there's what part of it is actually
modeling the 3d structure of the face
and the texture this is based on work
from Thomas Vetter and colleagues and
their basal face model and then there's
a simple kind of graphics rendering
thing that you put on top of that to
model the way the lighting works and the
camera angle and then as you can see
here on the on the right on the right
hand of the slide those are samples from
the generative model like samples from
the prior you run this random face
graphics program forward and you get
random images of faces from
viewing conditions alright and then
perception is like running that
backwards so for example conditioning on
this image of a face you haven't seen
before and then asking your graphics
program to generate a likely posterior
sample which means to say what what way
of setting the latent variables the
inputs of the graphics program and most
likely have made an image that looks
like that kind one of many places where
we've been interested in integrating
deep networks here for example is taking
advantage of the fact that they are
really good at pattern recognition they
learn really good features for pattern
recognition which in this case might
provide a good similarity metric for
matching the outputs of the graphics
engine with the image namely you don't
necessarily try to match the pixels but
maybe just say some continent features
that's that's that's one such approach
now just to show this thing in action
illustrating what I hope will be some
somewhat at least a little bit
impressive and also something that
should trouble to you here I'm showing a
face on the left that's an input image
and on the right I'm showing you the
models kind of hypothesis as it tries to
search around using a kind of MCMC
algorithm an elliptical slice sampler in
its latent space trying to match that
image trying to come up with a good
posterior sample and so you can see it
kind of an action it starts off with
basically a random guess and reasonably
quickly narrows into something pretty
good as well as I'll come to in a minute
it's it's it's reasonably quickly but
it's not that quick in fact it's way too
slow your brain is able to perceive this
face you know in well under a second
whereas this system takes much longer it
takes a number of iterations of MCMC but
what you have is not just a match at the
image you have a 3d model that you can
then do some nice things with like you
can re render that face imagining what
it would look like from very different
viewpoint or lighting conditions and
that serves as the basis for a pretty
powerful invariant face recognizer more
powerful than you would get as I'll show
you in a bit then just use just trying
to find traditional feature invariance
you can do the same kind of thing for
bodies where now you have a graphics
model of a body here on the lower left
you're just seeing some random samples
of body poses and then for example if
you now take an input image of this
Usain Bolt up here sprinting here's an
example of trying to match that with
again doing MCMC in the space of
possible inputs to the graphics program
and again we're not trying to match here
and
trying to match pixels we're trying to
match a kind of enhanced edge map so
what you see in the middle between the
the movie and the and the image is the
sort of intermediate representation but
again something like confident features
might might be good I mean this is not
implausible sort of thing for a
mid-level content representation and
again you see if you wait a little bit
you know this this thing pretty quickly
figures out this interesting non-trivial
pose and on some pretty hard pose
recognition problems it actually beats
some standard specially engineered just
and discriminative ly train to formal
aparts models so we see these as
successes but again I want I want to I'm
interested more in where their
limitations are so in particular while
they can do pretty rich scene
interpretation by inverting a graphics
model they're way too slow so here's one
place where we've thought about going
back to the helmoltz machine idea from
Hinton and so on which is to say well
maybe we could try to learn a
recognition model this is basically
exactly the Helmholtz machine it's in
the same way we have a top-down
generative model we're learning a
bottom-up recognition model in this case
the bottom-up recognition model can be
defined in a pretty effective way by
using a confident and I think that's
that's not unrelated to what those
contents were effectively engineered to
do basically to invert this kind of
graphics pipeline the key thing about
what we're doing here is that the
continent can be trained just as in the
helmoltz machine idea from a purely self
supervised data so you don't need any
label data you're just your drawing
samples or fantasies from the generative
model and training the convent to invert
that to be able to guess what from the
images to be able to guess the latent
variables to the graphics program if you
then use this basically to initialize
MCMC what you can see in this curve over
there and the lower-right is just that's
just basically the log-likelihood as a
function of time and it solves the
problem almost perfectly from the
beginning blue is what I showed you
before red is the conv net enhanced
initialized MCMC it's it's not perfect
this is sort of a log likelihood on the
log scale so even though so that red
curve there is is it's still there's
still actually a number of log points
and if you look closely you can see that
the the guess is that the continent
recognition model makes rightaway kind
of look almost right but you can if you
look at them for you know even just a
second you can tell they're not quite
right what we've been doing this is now
work of ill Kerr yield
and colleagues we've been using this
kind of combination top-down bottom-up
model to provide what what to us are the
best fits so far for a range of
interesting hard behavioral tasks in
face recognition
we have harder and easier problems of
varying pose and lighting and we also
vary the timing so this is just a
preview of some unpublished work to be
submitted pretty soon showing that this
model is able to fit pretty well a range
of behavioral tasks and then in
collaboration with the vendrick free
wold who's another one of these brains
mind machine Center partners Tommy
mentioned the work that he and Doris
sounded this model is also helping to
extend the kind of successes that that
Tommy and Joe libo and others had in
modeling their mid-level face patches
now to the most high-level face patches
okay so I want to just briefly before
leaving perception just talk about where
where you can go with this idea what
I've talked about is by inverting these
graphics models we can get something
about the 3d structure of the world but
then of course when I talk about having
a causal model it's not just about
finding what's out there but about
imagining and reasoning with it so I
just want to point briefly to some work
that Pete pettalia and just Hamrick did
with us a couple of years ago Pete
continues doing this kind of work in
deep mind and I think it's really
exciting that Dennis that the vision
that Dennis has includes this sort of
idea to say well um if you look at these
scenes for example you can recognize
that there's blocks stacked up but you
also get a sense of what we call the
intuitive physics there right that the
ones say in the upper left are those are
those are stable whereas under gravity
they're just gonna stay where they are
whereas the ones in the lower right look
like they should be falling over and we
can take this idea of say running a
probabilistic graphics program backwards
to get a 3d scene of the of the blocks
and then combine that with probabilistic
programs for simulating physics again
basic kind of game physics engines run
that forward a few time steps to imagine
what would happen and as you can see
here this system and then imagines that
the blocks are going to fall over so
that's how it can make a judgement that
these this is a unstable Tower of locks
here's another sample from the same
probabilistic program pipeline again an
inverse graphic sample to figure out the
3d position of the blocks and then a
forward sample through the physics
engine and you can see they're sort of
different but the same basic thing
happens after a couple of times
most of the blocks fall over so our
model here does a kind of very sort of
poor man's Montecarlo gets an estimate
from a few samples like this of what's
likely to happen and we've been able to
show that that provides a very nice
quantitative model of people's intuitive
physics judgments in a range of natural
scenes so here I'm just showing three
examples of Tower stimuli that people
judge in a graded way how likely this is
to fall under gravity and that
scatterplot just shows that our model
predictions versus human judgments in a
range of these stimuli the same kind of
thing though and this is really
important when we're talking about the
more sort of interesting kinds of
intelligence going beyond pattern
recognition and and very much
dovetailing with some of what dennis was
talking about having this generative
model doesn't just let you solve this
task the very same model lets you say
answer many other questions like how far
is that are that are the blocks gonna
fall or which direction they're gonna
fall in or suppose I tell you that these
notice here that you have some of the
blocks or one color some of the other
colors suppose I tell you that the gray
blocks are ten times heavier than the
green blocks or vice versa how will that
change which way you think this is going
to fall or if you see that the blocks
fall in an unexpected direction can you
figure out that one color is ten times
heavier than the other it's not
restricted to blocks of all the same
shape and size the blocks can be
different shapes and sizes we it's not
restricted to just forces that are the
standard ones like gravity and friction
but for example we suppose I tell you
that the table is bumped from one angle
or another the very same model provides
pretty much the same level of
quantitative prediction in all these
cases you can also as something this is
something that Pete continues to do at
deep mind use it to actually plan your
actions in simple physics based video
games and if you saw maybe some of you
saw the poster that a couple of current
people in our lab judge and woo an ill
Creole Durham and others have been doing
is basically another way of trying to
integrate a physics engine approach that
here they're analyzing simply simple
sort of blocks rolling down inclined
plane examples a physics engine approach
with a deep learning system for trying
to make good guesses about the physical
properties of objects and then use that
to initialize again in a probabilistic
physics program for trying to parse out
and reason about and predict the motions
of objects now taking into account
things like friction and and density
okay so we know in the last few minutes
I want to turn to the second topic of
one-shot learning and just again let me
just ground this in some concrete
examples and I know it's late but these
demos are more fun if you join with me
okay um
raise your hand if you know what this is
okay
raise your hand if you've never seen
this before okay good so most of you
haven't seen this before that I could
have asked the question raise your hand
if you were a rock climber and I would
have gotten the same thing because this
is a very standard piece of rock
climbing equipment called a cam alright
now the next question is mostly as well
is really only for the people who
haven't seen it before the non climbers
okay so here's a complicated scene of a
climber laying out their equipment can
you find the other cams I'll just move
my mouse around and just hum if I'm
pointing over one of those things again
here here's the object now here these
are okay very good you found them notice
they're different they're different
colors they're slightly different shapes
slightly different versions they're in
very different positions you know in 3d
but you still did okay okay here's
another thing raise your hand if you
know what this is okay very good
everybody's nose with this segue but
remember the first time you saw one
right you didn't think you didn't think
it was a bicycle you didn't think it was
a unicycle or a motorcycle or a car it
was like something kind of like those
but you were able to recognize oh this
is a new kind of vehicle or personal
vehicle um and you could see other
things and you could tell it apart from
the familiar ones as well as recognize
the new examples right how many segways
are in this seam just to get us all on
the same page - right okay now this
ability to learn a new object concept
from one example is not just about
recognizing things right it's not just
being able to pick out new instances you
have the ability to parse things into
you know to parse it into parts and
that's probably partly how you're able
to do it right by knowing something
about wheels and handlebars and so on
that's your ability to parse this thing
into its parts it's probably part of how
you recognize it you can generate new
instances you can draw depending on how
good a sketchy or I can draw new
examples that you haven't seen before
imagine what they'd be like you can
imagine combinations of these and other
objects to produce yet still more
fanciful objects
this kind of motor unicycle that you
know maybe you haven't seen but you can
imagine so we've been trying to study
these kinds of one-shot learning
abilities where again the interesting
thing is kind of the combination of how
how much we can learn so quickly the
ability to learn basically a generative
model of these object concepts from just
one example something that then supports
one-shot categorization but also these
other more creative tasks we've been
studying this particularly in the
context of a data set of handwritten
characters that we created originally
under Russ salakhutdinov when he was a
postdoc in the lab and the recent paper
that we're very excited it just came out
today in science it's the this is work
of Russ but primarily Brendon Lake who
finished his PhD leading this effort and
is now at NYU and I'm particularly
excited to tell you about this because I
hope that this will inspire a number of
people to try to work on these problems
of interesting one-shot learning and and
I think the data set that we collected
here will be of value to many people
regardless of whether you like our kind
of approach or other sorts of approaches
so I really just want to emphasize that
that all the data and code for these
kind of one-shot learning if Hadron
characters are available from Brendan's
web page as well as his github site and
we you know please have fun
okay so here's that here's let me tell
you it will show you this if you haven't
seen these data before it's we were very
inspired by the stuff I started out the
talk with in particular yawns work on
trying to study in you know he was he
was trying to really make pattern
recognition with deep nets work and he
had what I think was the right idea of
go deep into the into this domain of
hanwen characters where there's really a
lot to be done develop the basic ideas
and then once they got to a point of
maturity those same principles people
showed could apply to a much wider range
of interesting real-world pattern
recognition problems we when we first
came up with this data set we thought of
it as kind of like the transpose of m
nist where m 'no Sten categories with
thousands of examples of each we wanted
to generate a data set of thousands of
categories with only a few examples each
and we we did this by going to a
wonderful website called Omniglot so
we've named our data set the Omniglot
data set after the website that's
collected examples of basically all the
world's writing systems so you can see
some of the examples of these simple
visual concepts again they're basically
no more complex than M NIST as
individual items but there's a lot of
them so for example we have many
alphabets that probably you've never
seen before we have some alphabets that
nobody's seen before because they are
made up like from the television show
Futurama it's again a remarkable thing
about alphabets that people can make up
new characters and whole new alphabets
and you can do one-shot learning here so
just again one more interactive demo
actually there will be one more
interactive demo so here's this here's
this example in does anyone know this
alphabet yeah what was it what is that
it so there's there's a range of Indian
alphabet is that yeah okay so I don't
even know the alphabet but let's let's
play this game so okay so I want you to
hum again or well let's do clapping clap
so here's it here's a here's one
character of these twenty characters
down here one of them is the same one so
I want you to clap when I get to it okay
here we go
oh sorry okay
ok very good yeah
so people are basically perfect at this
and it's quite amazing um how can you do
this well here's an idea we I mean we
think you do this by basically thinking
about how you would draw the characters
in some form and there's a lot of
neuroscience as well as previous
psychology suggesting that this is in
fact something about the way people
represent characters as well as many
other related concepts like spoken words
and speech okay
so look at this character and in the it
just imagine and just in the air draw
how you would draw this character so
just everybody do it draw the character
okay you um you probably did something
like this right okay it turns out that
people's drawings are quite consistent
again even for characters they don't
know
so for fairly simple characters like
these ones with just two strokes or even
for more complex characters like these
ones here which have a number of
different parts basically people draw
them in very consistent ways even when
you you don't know the alphabet so we
try to formalize this idea of a
generative model like a kind of
probabilistic drawing program this isn't
this is an example of it we call it a
Bayesian program learning because
basically we're doing a hierarchical
Bayesian inference on a multi-stage
probabilistic program in particular
there's one stage of publicity program
which captures the motor program the
thing that you guys were just doing
right there it's like the commands to
your arm that generates instances and
it's probabilistic because you don't
draw it the same way twice and different
people might draw it a little bit
differently you need to capture that
variance to be able to do all the tasks
we're talking about but those programs
themselves are generated by a
higher-level program that's the prior
it's a program generating program that
captures your knowledge about this
domain your knowledge about how to read
and write basically okay and then
perception inference and learning is
basically trying to invert this causal
process I won't go into the details but
again you can read them in the paper in
order to make this work there's a kind
of a learning to learn process so we
have a sort of held out background set
in the paper we mostly consider a very
big background set that we hope
everybody would be pleased with like a
thirty alphabets we also have smaller
alphabets smaller background sets which
are more like the experience of humans
so you can try that out if you like like
try just trying to try to learn your
inductive bias or your representation of
how characters work from only
alphabets that's more challenging and
then you can use these generative models
to do all the tasks we showed you like
classification so for example here if I
if I show you one instance of these
again these two patterns up there it's
two characters and then I have the one
on the bottom and I want to say which
one is it well I think we can all see
it's much more likely to be able on the
left than the one on the right and we
can do that because basically the
inferred stroke motor program for the
one on the Left provides a much better
fit to just the pattern of ink there
right I mean we can measure this in
terms of log likelihood and it's about a
thousand log points better okay so now
this we we did a bunch of different
tasks here we did a these challenging
one-shot learning tasks where there's a
20 way classification task you can again
see one is just like the one we did
before and and we quantified how good
people are is at this as well as a
number of different models people again
are basically getting this error rates
down under 5% where chances 95% error E
or success rate of 95 percent and
chances 5% and that's all our Bayesian
program learning model is also able to
do that whereas a range of other models
including sort of lesion versions of our
model that leave out this the the key
aspects some of the key aspects of the
probabilistic program and it's and the
learning to learn don't do as well but
also we compared a range of you know
various kinds of deep networks
confidence and so on and again with a
lot of hard work you can get them sort
of close to human level performance but
there's there's there's still a quite
significant gap the more interesting
thing though that you do with these
generative models that are you know
again just really go beyond the pattern
recognition paradigm that we've
inherited from deep networks are these
more creative tasks so so here's a task
where for example we asked people we
give people a character and we say draw
another example of the character don't
copy it just make another instance of
one we asked nine people to do that and
then we asked our model to do that nine
times and then we can do a kind of
little Turing test where we show other
people
the humans versus machines and we ask
can you tell the humans for the machine
so this will be our last interactive
demo for each of these cells up here
nine of these characters were drawn by
the human and nine were drawn by the
machine so just say which of these left
or right were drawn by the human or the
machine so in particular machine so we
haven't raised your hand if you think
this one this
once here we're drawn by the Machine
okay raise your hands if you think this
one is drama the machine okay
I don't remember who's right we'll find
it okay um well what about raise your
hand if you think this was drawn by the
machine raise your hand raise your hand
if you think this was drawn by the
machine
okay how about here raise your hand if
you think this was drawn by the machine
raise your hand if you think this was
drawn by the machine okay raise your
hand if you think this was drawn by the
machine okay machine okay here's right
answer didn't anybody get them all right
a couple people all right how about here
baby I mean basically you can't tell
we've quantified this and people a few
people about ten percent of people are
above chance statistically on this task
but most people can't tell and and we
did it these simple little visual Turing
tests for a number of other creative
tasks like for example a more
interesting one even asking people
giving people characters in a new
alphabet and say now draw a whole new
character in the alphabet these are just
examples of our computer program doing
that okay um I'm I think I'm basically
out of time so I'll just say we think
that this kind of approach is of course
just just as we saw with you know Kahn
nets and other classic approaches in
pattern recognition we think the
principles here of you know are much
more general than just recognizing
characters there's a number of other
kinds of kinds of concept learning tasks
that people are able to learn from very
few examples and generalize in
interesting ways and we're excited to
try to apply these approaches there but
that's very much future work so just to
wrap up then I started off calling the
slide conclusions but it's really it's
not conclusions it's looking forward and
I think if we want to see what is the
future study of intelligence integrating
across brains minds and machines well we
want to say looking back we had 50 or 60
years of studying pattern recognition
and we made a lot of progress
it may not be solved but I from my
perspective it's getting pretty close
and I think it's it's it's time and it's
very exciting that we're now able to
move on to these more well more
interesting aspects of more human-like
intelligence beyond pattern recognition
to building causal models of the world
that support explaining imagining
planning and things that are more like
thinking I think that we're gonna need
powerful tools more powerful tools than
say the neural network toolbox has given
us to capture these kinds of generative
model
and here I've shown you a little bit
about how we're trying to do that with
probabilistic programs and program
induction and shown you how these tools
are already letting us capture
interesting aspects of perception and
learning and build more human-like
perception and learning systems in
machines but there are many open
questions and I hope some of you will be
interested in working on these like for
example for probabilistic programs how
can we scale up inference to be much
faster and much more general if you're
interested in that check out the black
box inference of workshop on Saturday um
how can we scale up learning to more
complex kinds of problems tick programs
than just the very simple programs that
we did for these hundred characters how
can we integrate these ideas with neural
networks on the engineering side and
maybe most interestingly how do these
kinds of richer causal models and causal
model building abilities work in the
brain these are things that we hope
we'll be able to address in the coming
years and again I hope many of you will
be interested in working on them too
thank you
you
each year Microsoft Research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>