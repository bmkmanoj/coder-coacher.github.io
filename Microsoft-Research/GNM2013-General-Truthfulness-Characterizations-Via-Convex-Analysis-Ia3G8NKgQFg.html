<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>GNM2013: General Truthfulness Characterizations Via Convex Analysis | Coder Coacher - Coaching Coders</title><meta content="GNM2013: General Truthfulness Characterizations Via Convex Analysis - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>GNM2013: General Truthfulness Characterizations Via Convex Analysis</b></h2><h5 class="post__date">2016-08-09</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ia3G8NKgQFg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
and it's about to start of the postdoc
at MSR New York so it contains convex
analysis in the title and so I don't
want that scare you it turns out you
actually only need to know to fax from
Tom backs analysis and so I'm gonna give
them to you in the first two slides and
you know that'll be more than enough to
understand for the talk so the first
thing you need to know is basically the
idea so if you have a convex function
write a function whose whose epigraph
the set of set of points above it's the
compact set then if you take a
derivative of it and plot a line out
along that derivative it's always going
to be below the functions or like like
this X here and more generally even a
points where the function may not be
differentiable that just means you have
a whole family of these tangent lines
you can choose from and each of them
will still remain below the function we
call you know each of these a sub
gradient there would be the gradient if
it exists at a given point if the
function is differentiable there so
that's that's one fact about convex from
convex analysis the second is a way of
constructing convex functions and so the
important thing to know here is here I
have in the dashed lines three different
convex functions and I've created I've
created a new function by taking the
point-wise supremo by just taking
whatever them had the highest value at
that point and in doing so I created a
new function that's guaranteed to be a
convex function so that's it that's all
the that's all the convex analysis that
you're going to need are there any
questions so far ok good so we've had
we've had a number of talks over the
past day and a half or so that have
touched on mechanism design so I'm going
to treat it very generally so there's
going to be some set of outcomes in the
world
uh you know say for example we have to
pick whether we should spend a bunch of
money to build a new bridge or to make a
nice Park and then lots of people may
have different opinions about how much
they like this so you might find someone
who's who values the bridge at five
dollars maybe they you know have to
cross the river quite a bit and then
they might value the park at only three
dollars you know how much they would
personally be willing to pay to have it
so in general you can think of the
private information that a person might
have or their type as a function that
for each outcome associate it's a real
number with it which is how much that
outcome would be worth to them and so I
use functions here because that turns
out to be the correct mathematical thing
you want to use for the convex analysis
you can also just think of this as a
vector that reports the value for each
outcome and you know since if and that's
going to be entirely equivalent did
everything it's finite so okay so we've
assumed that we have some some agent in
the world who has private information
and now we're actually going to have to
make some sort of decision so we're
gonna have to have some function it's
going to go it's going to take the type
of B&amp;amp;B agent and it's going to pick one
of the outcomes for our set for example
a very natural thing you could do is you
could just go through and pick the
outcome is going to make the agent the
happiest among all those possibilities
right that's you know perfectly natural
thing you could do so that's one
function that shows up in mechanism
design the other function that shows up
in mechanism design is a payment rule
that says okay now also based on that
information I'm going to decide how much
you have to pay and you could for
example do what would be a first price
auction and that is charged them
whatever they said the thing that you
chose was worth and then once you've
chosen these two things then they have
some utility and their utility depends
on both their true type because they
care about the outcome to get selected
and it also depends on a type that they
reported to you so their utility if they
make some bid be and their true type is
t well it's the value that they receive
for the outcome that's chosen so if this
rule he said that it was that British
worth 2 and the park is worth 1 so the
bridge will be chosen so his value from
the outcome chosen was going to be 5 and
then his payment says he pays whatever
he said it was worth so he said it's
worth 2 and so his overall utility is
going to be 3 now 11 note about this
utility function that will turn out to
be important later is that this this
utility function is an affine function
of his true type you see a term here
that's a function application if you
like linking up types of the vector this
is just a dot product so this term is
going to be linear in the true type and
then there's this payment where the
truetype doesn't appear at all so just a
constant from that perspective so in
terms of your to type this is an affine
function and then if you want to talk
about well is this magnum mechanism
truth for a lot truthfulness is just a
property that says your utility for
making any bid is less than or equal to
the utility you get if your bid was your
true type and so in this in this setting
we see actually this this mechanism is
not truthful because if instead of if
instead of bidding to and one he had bit
is true type well the same thing would
be chosen but now he's going to pay 5
and so as you told you would 0 so this
design turned out not to be truthful so
are there any questions so far about
kind of what mechanism design is or how
I've represented it for the people that
no mechanism design okay good
and so then there there is a you know
quite a bit of theory trying to answer
the question of well okay we saw that
one mechanism we came up with isn't a
truthful mechanism what are all of the
truthful mechanisms that we could use
and so Myerson and a paper that did
quite a few major things in it but one
of them was he answered this question
for what are known as single parameter
domain you can think of these as domains
where the private information is just a
single number like how much do i if
there's only one item being sold how
much do I value that one item and he
showed them that setting a pair of an
allocation rule on a payment rule is
truthful if and only if the allocation
rule is monotone that is if your type is
higher if you have a higher value for
whatever it is you'll get more of it or
be more likely to get it so monotone in
that sense and then there's then there's
a particular way of constructing what
the payment rule has to be from the
allocation rule we can we give this nice
if and only if characterization so
that's for single perimeter demands it
turns out to be exactly equivalent to
say that the consumer surplus function
that is basically how happy you are the
utility function before how happy you
are given both the outcome and the
amount that you had to pay if that is a
convex function and at any given point
the allocation is given your type is a
sub gradient of the convex function at
that point this turns out to be an
entirely equivalent thing to say and if
you want to know why it turns out that
basically going on here you have an
integral of this function a we assumed a
is monotone and the integral of a
monotone function is a convex functions
if you want to know why they're
equivalent that's why the main thing
that's important for the talk is that
they are equivalent and this is actually
true more generally so meyerson's proof
about a modern allocation rule is only
true
in kind of limited settings but this
this characterization that involving a
convex function as a sub gradient is
true in general ok so now I'm going to
switch to an entirely different domain
but also a domain where people care
about truth so again there's going to be
some set of outcomes and you know the
outcomes here might be whether it's
going to be rainy tomorrow or whether
it's going to be sunny tomorrow and now
instead of having a person who has
preferences over which of those outcomes
happens although you know these are
probably things that we have preferences
over there's someone who has some
information about how likely these are
are going to be for example it might be
weathermen and you has some probability
distribution over how likely these two
things are and this this being England
maybe there's a probability point one a
son and a probability point nine of rain
and now we would like to have the expert
who knows this information reveal it to
us so we'd like to come up with some
rule that based on a report that we're
going to ask for from this expert and an
observation of what weather actually
arrived on tomorrow or whenever we're
interested about we want to give the
expert a score and so you know the score
could be for example as typo there
should be qo not p 0 but the score could
be for example the payment you get is
the logarithm of the probability with
which you said the outcome the outcome
that actually occurred would have
occurred so it could be you know any
rule and this is the payment this is the
rule by which we're actually going to
pay you to give you an incentive to
truthfully reveal the information that
you have and so well what do you is the
expert care about then well you're going
to get you know your pain
is well some outcome is going to be
realized according to a true
distribution that you know and then
you're going to get scored based on this
rule you've been told so that's your
expected score and and note that because
expectations are kind of a linear
operator this is in fact Fi and in fact
linear in your true information so maybe
you know this this is what the world
looks like from the perspective of the
expert that's going to 11 potential
scoring role and so again we care about
truthfulness we want to ask well does
this rule we wrote down have the
property that the best thing the expert
can do is to reveal his true true
probability distribution and it turns
out it does and it's it you can show
that in fact the score Fred the other
thing is going to be less than or equal
to the score be four the expected score
from reporting truthfully so this you
know this is this is an area where care
about truthfulness looks you know in
many ways quite different from mechanism
design you know so another place that
has almost up to a minus sign the same
definition is machine learning where you
might care about proper loss functions
which is a loss function that guarantees
that if you if you knew the true
prediction you should be making it the
loss function would actually be
minimized by that it's the exact the
exact same question questions so far ok
so you know has been quite a bit of work
on this scoring rules literature and in
fact there's a very nice
characterization theorem that actually
goes back to the 60s in its original
form but stayed kind of in a nice
general modern version by lighting
raftery and they showed that a scoring
rules proper if it's derived in this
particular way from a convex function
and the sub gradients of that convex
function
alright so we have a different so you
know so far we've seen kind of 22
different sort of domains where we care
about some notion of truthfulness we've
seen kind of two different
characterization theorems that were kind
of proved entirely separately but they
have you know quite a bit in common
they're sort of some sort of outcomes
about in the world there's some sort of
affine function being computed this will
care about and those kind of a notion of
truthfulness looks and tactically
similar so what's what's going on wire
wire convex functions their sub
gradients showing up and both of these
and the answer is that second fact that
I told you before right truthfulness is
a property that says the supremum over
all reports I could make is equal to the
value that I realize given my true
report right that has two weekly
dominate everything else I could do well
we know that then if we view this value
of what do I get with my to report is
just a single a function of much report
because of this construction we saw
where we're taking a point why supremum
over affine functions which you know
which are convex the resulting G we get
from doing that is going to be a convex
function so that's why really in general
in these different domains where we care
about truthfulness what's popping out of
it is a convex function so the main
thing we do in our paper which is
available on archive it has the same
title of this talk if people are
interested in seeing more of the details
that i'm going to give as we write down
kind of a general model that that
encompasses both mechanism design and
scoring rules as well as any of these
other settings that kind of have this
property where you're trying to get
something truthful and so basically
although we care about is there's some
set of types it's going to be a subset
of a vector space a reward face this
space is going to be based off of affine
functions and then a subway of selecting
based on the type of the agent one of
these a fine
and then truthfulness the notion of
truthfulness that I've kind of written
in a curried notation here you can think
of as a parameterised family of
functions if you prefer because remember
that you know the types here are
functions themselves and kind of the
main result we have from the paper is is
a characterization of basically what
what all of the things you can do that
are truthful are in any of these
settings and certainly this is this is
this is for the most part known in both
mechanism items scoring rules already so
I intended this this idea isn't isn't
wholly new in and of itself there's
certainly bits and pieces we get that
are that are new from the unification
we're going to present so it in fact so
if you look at this here and then we go
back a few slides and look at the dining
Raftery characterization theorem right
the two equations are are very similar
and and it's not not going to be an
accident the major thing you know to say
is that well basically we say the truth
most consists of picking some convex
function and then a selection of its sub
gradients and it's an if and only if
characterization so why why is this the
way we get truthfulness than us so i
have a picture that has quite a bit
going on but hopefully i can walk you
through it and give you a sense of what
why these things are showing up when we
care about truthfulness this picture may
be somewhat familiar to people who know
who knowed about about scoring rules so
here we have the convex function G which
you can think of as if I am of some type
T what is my utility going to be and in
mechanism design this is a consumer
surplus function but this is you know in
general the expected utility I'm going
to have if I report truthfully right and
now ok so now consider some me being
this particular type T well I could make
any other report I could report anything
in here
and i would get maybe this blue function
for that report which because this
mechanism mechanism I've chosen is
truthful you know has to coincide with g
@ t and has to be below it otherwise and
so the question is well where do these
other points on it come from well
suppose i have instead chosen to report
some t prime well what is what is this
scoring say that i get for reporting t
prime well i'm going to start at g of t
prime so i'm going to start at this
point and then i'm going to walk out
along a sub gradient essentially from t
prime to t so i'm gonna do is i'm going
to walk down to there and so you'll
notice that that is exactly the value of
the blue function at a report of T prime
so that's where that point is coming
from and so why is why is why is you
know this giving us the truthfulness
property that we want since we paid the
convex function well the definition of
being a sub gradient is a linear
function tangent at the point and always
below because we have a convex function
so that property sort of definitionally
being a sub gradient is exactly that
property we want of being always below
and is why truthfulness is coming out
and is giving us our if and only if
characterization so it's late I won't go
through the details of the proof I will
say that the proof is very familiar to
people who know scoring rules the first
two slides are are exactly lifted from
mining and raf trees proof so it's
literally nothing new and the first in
the first two thirds of the proof
there's a little bit here that involved
letting us handle handle settings where
the set of types may not be convex but
even that actually borrows heavily from
some work and the mechanism design
literature by archer and Kleinberg but
you know the three slides i clicked
through fairly quickly are literally the
entire proof
add a little more time and it was
earlier in the day I would actually go
through them so it's not actually a hard
result to prove by any means it's
actually really simple but it's nice
because in pulling together kind of
these this characterization you know
that looks a lot like the one using the
scoring rules literature but also brings
in mechanism design we can then
immediately start taking results that
are known in one literature and applying
them in the other so for example a
mechanism design you know I had
considered and figure it out what what
mechanisms could look like with non
convex type spaces because maybe it
might be perfectly reasonable to believe
that I might not have all possible
combinations of values might not be
sensible in some setting and so that
this maps directly over into the scoring
rules and we now have a characterization
that didn't exist before what scoring
rules look like in non convex settings
and why is this interesting well you
might you might be thinking okay I'm
going to ask weather forecaster to
report me some probability but you know
in reality people don't have you know
don't have arbitrarily fine real valued
beliefs about probabilities and events
and their heads and you know if you're
going to want to have a nice simple all
the station thing you might want to
discretize it in some way for example if
you want to apply these in a more
general setting of may be evaluating
reports we are going to make in a
crowdsourcing system you may well want
to discretize the reports are going to
allow people to make and so the question
okay if I go through and do this
discretization are they going to have
any is this couldn't have any effect on
the incentive properties or am I going
to get more or fewer things I can do and
one of the things that comes out of our
characterization is actually this
discretization is entirely irrelevant it
doesn't change as well as long as you
don't change the convex hull of the set
of types you aren't going to change the
things that are truthful at all you know
perhaps perhaps less general interest it
allows us to relax
a an assumption that was needed in the
mechanism design literature in one of
the characterization theorems um so you
know that so those are things that are
immediate from just the characterization
theorem another thing that we can do
from this view of the world is actually
go through a large literature and
mechanism design and greatly simplify it
and give you know both conceptually
clearer proofs and you know a better
understanding of how these things fit
together in several ways so one thing
that people have been interested in in
mechanism design quite a bit is the
following question so I have write a
mechanism consists of two parts to
consist of an allocation rule and a
payment rule and so there are some
settings where I care about that payment
rule maybe as I want to be collecting
money but in other settings I just want
to be using this mechanism to optimize
some desirable outcome in the face of
rational people i don't really
particularly care about the money other
than that it's helping me get a good
outcome so then the question is what are
all of the different allocation rules
all the way of choosing outcomes that i
can implement truthfully of the via some
payment scheme i don't care what payment
scheme it is but some payment scheme and
get something truthful out there's you
know there's a large literature that
have looked at various aspects of this
so that the meyerson argument I I
mentioned earlier shows that essentially
the probability the property of being an
implementable allocation rule is
equivalent to being with sub gradient of
a convex function and so there's a paper
from the 70s by roche that identified a
different equivalents to condition a
techno condition known as cyclic month
Nyssa t that actually comes out of
convex analysis and is very heavily
connected with the property of being a
sub gradient of a convex function and
then there's been a bunch of other work
I think this was from much of it sort of
since two thousand seven or so finding
weaker or more local conditions that are
useful for providing this
characterization but all of them sort of
go back and work with this cyclic
monotonicity condition which is a really
nasty thing I you know other than movies
I only know of a single example where
anyone has ever successfully
successfully derived a mechanism and
proved it truthful using cyclic
monotonicity pretty much it pretty much
every other setting it's a very
unnatural thing to work with so instead
actually we argue that you should
rethink this whole literature and think
of all of these arguments is instead of
looking at cyclic monotonicity arguing
directly that some set of properties is
equivalent to the property of being with
sub gradient of a convex function and
this allows us to give dramatically
simpler proofs as a number of these so
for example you know this is this is one
condition i picked out from the
literature because it's particularly
nice they they they identified two
properties that lead that lead an
allocation rule to be truthful or you
know in our sense a selection of sub
gradients to be a selection of a fine of
linear functions to be some great into
the convex function and that is they
satisfy a technical condition called
week month Nyssa T that you don't really
need to understand that I'm not not
going to go into other than that it's
sort of the right generalization of the
monotonicity we saw in that
one-dimensional setting before it's the
right generalization of that to multiple
dimensions and a path independence
property that basically says if you
start going it's beta says this is a
conservative vector field if you know
that is but basically if you start doing
integrals along through this space of
linear functions that we've chosen it
means you get path independence to
basically if you take the integral from
point A to point B and the path integral
from point B to Point C then that's the
same as having taken
the integral from A to C and as they
they establish as the main result of you
know takes them about 12 pages and it's
the main result of a gb paper so it's a
fairly strong paper and they put really
a lot of work into proving this fact if
you if you view the world through out
through through the approach that we're
using it actually turns out to be a
single slide and about the level of
difficult that you could give to an
undergraduate as a homework assignment
to do the proof because it essentially
just proceeds from first principles the
only slightly tricky thing is we need to
find the right definition of a convex
function G but once we define that
convex function G it's a matter of
proving this function we've constructed
as convex from kind of the standard
first principles you know you take an X
and a Y and you take some some linear
combination of them and then you just
argue exactly that that linear
combination is greater than equal to the
value of the function at that point you
know the standard textbook way of
proving a function is convex and you
apply you apply week mon ethnicity and
you apply path independence at the
obvious places in the algebra and the
answer pops right out so sort of as an
analytic tool this approach gives a
dramatically simpler way to approach
these sort of problems and actually one
of one of the nice things is that you
know it's not just simple to prove these
but it's also more constructive is in
that proof I said the first thing we did
was went and started out by constructing
explicitly a convex function G and
through explicitly constructing that
convex function we explicitly construct
the payment rule so as a result we know
not just that there exists some set of
payments that make this allocation rule
truthful but we have very natural way of
characterizing exactly what those
payments are in a lot of settings and
actually we think that so basically this
literature have been going on by people
focused on mechanism design but you know
what we show is they effectively even
proving new new
necessary and sufficient conditions for
being the sub grading of a convex
function so we actually think that you
know sort of using our cream to pull the
results the other way we actually think
I don't want his you know I'm not a
convex analysis person myself let alone
say a too strongly but I have talked to
a couple and as far as I know actually
several of these characterizations are
not generally known in convex analysis
in terms of necessary and sufficient
conditions for being the subgrade Ava
convex function in one set or another so
I think actually this creates some new
results in convex analysis and for
example for people care about certain
rules that lets us say that for example
it turns out to be a sufficient to
consider local miss reports in the
scoring world space so this was kind of
known and mechanism design but you don't
actually have to check if a squirrel is
proper for arbitrary miss reports it
suffices to check for sufficiently
nearby reports and so you know in
everything I've talked about so far you
we've wanted to take kind of the full
private information that an agent has
and elicit that but in a lot of settings
that's not really natural so you know
for example suppose I wanted to ask you
know a person please tell me your entire
entire probability distribution over the
quantity of rain we're going to get in
the next month right expressing that
probability distribution is you know
it's an you can give me a fine an
arbitrary PDF for an arbitrary CDF or
something like that but there's this
whole space of mass key functions and I
mean if I'm going to you know do this on
a computer I have to give them an
interface lots and construct arbitrary
PDFs whereas kind of an unnatural thing
and I may not care about actually the
whole richness of this distribution even
if they could you know bring their
beliefs down in such a complex thing you
know I might actually only care about
something like the mean of this
distribution or some other statistic
right or
um you know feel for more mechanism
design background there are lots of
settings where maybe I actually
particularly in settings where I don't
want to use actual money maybe I only
care about people's preference order
over the outcomes and this shows up in
mechanisms that are used for example in
matching problems like matching medical
residents to hospital residency slots
our matching students to schools and
those sorts of problems it turns out the
mechanism don't ask for the utility for
each outcome they just asked for some
sort of preference ordering over the
outcomes right so sort of these settings
on both sides where you care about this
kind of indirect elicitation of the
private information of some kind of
intuitively simpler representation
rather than eliciting the actual thing
it turns out you can formalize this a
notion of a property of type you're
interested in and there's a little more
complexity but you can generalize our
main theorem to be able to handle all
these cases so actually not just do we
carry these kind of would be direct
revelation mechanisms in in the in the
main room design sense but we also
actually characterize all of these other
more indirect things that are you know
useful for settings where you don't want
to deal with the complexity of the full
type space and you get you can observe
you know sort of a number of interesting
and useful things from this
characterization so one thing that
follows immediately for example is that
because convex functions are
differentiable almost everywhere and it
turns out that our characterization says
that canonically asking people for a
property means you're asking them too
tough to pick a sub gradient for you so
it turns out that if a property is
Alyssa tible it has a unique value
almost everywhere because you know for
some stumps istics there may be multiple
values that are equally reasonable as
the true value so actually this fact
lets you rule out some some things as as
not being elicited Bowl without doing
any further work so it kind of gives you
a tool to show the thing they're not
elicit a bowl it it also has you know so
far those things that I that I think I
won't go into they're a bunch of other
applications of this that we do in the
paper you know for those no revenue
equivalent some mechanism design and it
turns out that you know it's sort of you
can prove revenue two equivalents
theorems for various settings using this
approach I went through kind of two main
areas where we care about truthfulness
but there's been a literature of kind of
other variants of scoring rules for
example where you want to get
counterfactual predictions so you want
to ask somebody predict what would
happen if I did something that you may
or may not do that so you may not be
able to evaluate that prediction well
what what do sort of score and roll like
things look like in that setting all of
these things kind of have the f I'm
property so instead of people having to
go and prove a new characterization
theorem each time you want to ask and
these varying questions we have this one
characterization theorem covers all of
them and one I want to talk a little bit
about is Robert's theorem so in
particular I've cheated a little bit so
far on the mechanism design side and in
everything I did I only had a single
agent in the world and that wasn't an
accident in one sense that's all all
that matters because if you look at any
notion you care about like Beijing
incentive compatibility or dominant
strategy and scent of compatibility they
all essentially look like something
where you can project down onto a single
agent so for example general
truthfulness and dominant strategy says
for all strategies for all types of
other agents I want this traditionalist
to hold so you can check if something as
truthful by just looking at each of
those projections individually and
verifying each of them
and you know sometimes sometimes this
sort of characterization is enough to do
something really useful so for example
this was exactly the characterization
Myerson used for single parameter
domains let's plead to a lot of very
practical mechanism designs because it's
been it's turns out to be you know good
enough to you know there are many
practical cases where you can show the
thing you care about is monotone for
once you've fixed other people and so
that works great but there are also a
lot of cases where you really want to be
able to say something stronger about
what happens with multiple agents and
you know those sorts of
characterizations have been harder to
come by so 11 really well-known example
is Roberts theorem which says that if
you have if you have a setting like the
example with the bridge in the park but
there are these three outcomes and there
are unrestricted valuations that is
every agent can have any possible value
for each outcome you're not going to put
any sort of other constraints on how the
values have to be related then there's
only one mechanism sort of one family of
mechanisms you can do that's going to be
truthful for all of the agents
simultaneously and that's what's known
as an affine Maximizer and basically
what that is is you choose you're going
to compute a value for each possible
outcome that consists of an arbitrary
constant you associate with that outcome
and then a weight you associate with
each agent and so you sort of score the
outcome by summing over all agents there
they're weeded value for that outcome
and then add the concent for that
outcome and call that the value for that
outcome and then you take the outcome
that maximizes that and so the those
turn out to be the only allocation rules
that are truthfully implementable and
there's been there's been a lot of hard
work trying to relax this unrestricted
valuations thing because this rules out
things like combinatorial auctions for
example where there are natural
restrictions such as the idea that
well if you give me an extra thing that
can only increase my value because I
still have all of the things I had
before so they've been there been some
work that's that that's managed to
stretch it a little bit in this
direction but one thing we're kind of
working on is future work is we think
there's a way to use our
characterization to give a a both a
simpler proof of Roberts theorem which I
guess the proof is is short and not too
hard to verify but a lot of people find
extremely hard to understand why on
earth it works and so we think we can
kind of give a bit of a simpler more
intuitive proof and also a proof that we
think we see how to generalize towards
this that's kind of future work and what
we're working on at the moment so to
wrap up now we have our main main result
is a kind of a new characterization of
truthfulness that generalizes both
scoring rules and mechanism design and
it gives us simpler kind of constructive
proofs about what allocation rules are
implementable and all I didn't talk
about it much in this talk we can
generalize it to to these sorts of
indirect elicitation settings where we
only care about say some property of
distribution so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>