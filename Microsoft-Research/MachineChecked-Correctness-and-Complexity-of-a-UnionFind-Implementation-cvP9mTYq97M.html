<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine-Checked Correctness and Complexity of a Union-Find Implementation | Coder Coacher - Coaching Coders</title><meta content="Machine-Checked Correctness and Complexity of a Union-Find Implementation - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Machine-Checked Correctness and Complexity of a Union-Find Implementation</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/cvP9mTYq97M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
hi everyone we have the pleasure of
having phosphoprotein visitors today
from ania phosphors interests include ml
type inference among other things and
also program proof and this is the topic
of the taco day is going to tell us
about a verified implantation of a union
find algorithm books in terms of
functional correctness and rhythm
complexity thank you and thanks for
inviting me to to visit rise very happy
to be here so this is joint work with a
shockable who's also researcher at inria
and as jonathan just said this is a kind
of case study in proving a small piece
of camel code both in terms of carrick
nests and in terms of time complexity so
we picked union-find as an example
that's interesting to us because it's
very useful in it has many applications
in compilers and theorem provers because
it's at the heart of first order
unification in particular and it's also
interesting because it has a very tricky
complexity analysis which you can which
has been simplified over the years
beginning with taärgons analysis and 75
and so we wanted to see if we could port
this analysis to a machine checked make
a machine check version of it so i'll
begin by recalling briefly what
union-find is how it works it's a data
structure for maintaining equivalence
classes under unions so I'm guessing
most of you have seen it before it's
also called a disjoint set forest where
every element either is a root like this
or has a pointer to some other element
so it's got a link this one for instance
has got a link to a root and each of
these trees forms an equivalence class
whose representative element is
the root and the the ochem lapi which
you can offer for this algorithm is this
where there is a type of elements and
three basic operations to create a new
element find the representative element
of an arbitrary element so fine we'll
just follow the links all the way down
to the root and union which takes
typically two roots as argument or two
arbitrary elements as argument and if
you give it two roots for instance it
will install a link from one to the
other and there is also an operation not
shown here for non checking testing
whether two elements are in the same
equivalence class so the code for this
thing is very simple and that's one of
the reasons why we chose this example it
fits on a slide and I'm not getting
going to read everything but the few
things which are worth noticing are that
every element is mutable it's a
reference to some content and the
content is either a link to some other
element so a pointer to some other
element or if we have a root then we
carry an integer rank which is used to
do balancing when we unif when we Union
two roots the rank helps us decide which
way the pointer should be installed so
the balancing is visible here where we
compare the ranks and another thing
that's worth noticing is the find
operation so it's written as a recursive
function which just follows the pointers
all the way to the root and the
interesting line is this thing here
which installs shortcuts so its path
compression where we we modify the
forest as we walk it so as to make the
next find operation more efficient so
it's the combination of balancing and
and path compression which gives the
very good efficiency where find and link
and union have almost constant time
complexity at least if your reason in
terms of advertised complexity
and in the worst case it's logarithmic
so the complexity analysis was first
done by Targon in 75 and at the time the
paper published by tartan was quite
complicated but it's been simplified
over the years by charging himself and
by others including chosen and you can
find a very simple proof today either in
the textbook I have cited here or in
some course notes which are available
online bite arjun and so the paper proof
is about three pages and it's very easy
to follow at least if you are happy with
checking that it's correct because it's
it's quite difficult to understand why
it makes any sense on how they came up
with it but at least if you just follow
the steps you can confirm that
everything is correct fairly easily and
so the the main result is that the
complexity of Union and find is 0 of
alpha of n which means almost constant
in practice because alpha is the inverse
of this function a which grows very very
quickly so the things I want to talk
about today are some some details of the
specification of Union find and how we
how the specification talks about what
it does and how much time it needs at
the same time we'll see and also one
point I want to emphasize is that we're
not just making a proof of the algorithm
based on some pseudocode but we are
actually looking at the o camel coat
which I just showed and we prove that
this particular implementation is
correct and this is modular in the sense
that we establish a rather simple
specification which a client could use
if we had a for instance our unification
algorithm could be proved correct based
on this specification
I should say that if you want to ask any
questions during the talk you shouldn't
hesitate so the way we do this is we use
C FML which is a tool developed by r2
it's embedded inside and it can be
used to reason about o camel code so at
the same time it's a library and a tool
the tool takes the o camel code and
turns it into a formula
description of the behavior of the o
camel code and then there is a bunch of
lamp levers and tactics which
you can use to actually reason
step-by-step about the code so
essentially it's a whole logic or a
separation logic where you have
preconditions and postconditions and and
you proved that the co satisfies them i
should say briefly that there is a lot
of related work on improving programs
correct and of course i'm not going to
mention all of it here but much of it is
mostly concerned with functional
correctness and does not look at
complexity at all and if you look at the
the previous work that does include
complexity concerns then often there
they are concerned only with the
mathematical level and not not with the
code itself and also often they are
concerned with entering the complexity
completely automatically whereas here
we're not trying to infer anything at
all we're just trying to do a manual
proof and in this little corner of the
literature where we fit has been
relatively little explored I think most
people have tried to fit in one of the
other niches but we are the almost the
only people I believed to have looked at
manual proofs of complexity and one of
course so it's manual so it's a bit
painful but you it can be very
expressive for instance to express
improving this alpha of n complexity is
something which no automated tool could
hope to do because there is a very
and there is a proof which requires a
lot of human ingenuity and there is no
way you could do it automatically at
least with today's tools the original
program is is translated into back into
the springville yes the do camel coat
which I showed here is translated by the
sea FML tool into what are two of course
a characteristic formula and that's a
kind of description of the behavior of
this code sorry yes from his thesis yeah
so then we establish a whole triple
about this coat of a pre post condition
pair thank you trust yes you have to
trust that the tool is correct yeah so
this has been proven on paper but of
course there could be a bug in the paper
proof or a bug in the implementation of
the tool so you have to trust this part
there was another question verifying
competition basically it was also
needles and Rose Danielson doing yes in
anger doing horrified lazy instructors
yes there was this paper it's a popular
way yeah I misunderstand Yeltsin and
indeed indeed a he would fit in in the
same niche as us I think he didn't try
to automate but he had quite a lot of
expressiveness because he could use
actor as a as a theorem prover to do
interesting proofs of complexity and
indeed he focused on the use of thunks
and lazy evaluation and so first I'll
show the specification which we proved
so that's what we show to clients of the
Union fine module and then I'll say some
words about the framework which we use
separation logic extended with time
credits and if there is time out i'll
say a bit more about the proof itself
and the invariants which it uses
internally
so the specification since what we use
is essentially a whole logic a
separation logic we equip every
operation with a precondition at a post
condition and that's what we show to the
clients so the way we write these things
is maybe a tiny bit unusual but that's
because we have to fit in in cox syntax
but this is the way we write the
specification for find for instance the
this line here is the precondition and
the last line is the post condition
where r stands for the result returned
by find so what this has roughly well
the precondition says you have to have a
well-formed union-find data structure
before you can call find and so this UF
here is an abstract predicate which
means there exists a well-formed
union-find data structure and i am the
unique owner of it since this is a
separation logic we follow this usual
discipline of separation logic which
which says that when you want to mutate
a data structure you have to be the
unique owner of it so that's what you f
ND our means and the parameters ndr are
explained down here on the slides DS the
set of all elements so the set of their
memory dresses if you will so that's the
domain of the union-find data structure
and is a bound on the number of elements
I'll speak about it a little bit later
you have to fix it at the beginning it's
used only in the complexity analysis it
doesn't really exist at runtime or play
any role at runtime and our is a logical
level function which maps every element
to its representative element it doesn't
really exist at runtime either in your
definition of the of the unified
structure you miss it usually one has
contents of alpha alpha oh yes that's a
good remark
indeed we we were a bit out of time when
we when we rush to publish a paper about
this so we had to leave out the alphas
but you're right that usually you would
attach a datum of some type alpha to
every root and then the type LM would
become a type alpha LM and find would
return may be an elf our maybe we have
another operation besides find which
would give you the datum attached with
an equivalence class so it wouldn't be
much more difficult I guess maybe one
more day of work to adapt this and we
plan to do it so here indeed because we
don't have these data these these data
elements what fine does is just return
the representative element and that's
what the specification says here it says
this thing will return an elements are
such that our is the representative of X
and the union-find data structure will
still be well-formed after that you will
still be the unique owner of it and then
the interesting aspect here is this
dollar alpha of n plus 2 so dollar is
our notation for time credits so it's a
permission to spend one unit of time
basically and and here what we are
telling the client is you need to to
give us Alvin plus two credits when you
call fine and that's the advertised God
so to speak so it's the amortized cost
and as we'll see maybe the real cost
will be less than that or maybe more
than that but that's our business we
take care of that internally the client
doesn't have to know all they have to
know is they have to give us this amount
of credits saving credits one
yes yeah I'd say a bit more about that
later on these are the things of the on
the right the star are your relatives
right so this one is not really pure
because these credits are a fine and so
we when you when you say dollar end
credits it means I own these credits i
am the unique owner of them and maybe
I'll consume them and then they'll be
lost forever so the first star is really
start of to impure assertions and indeed
this one between brackets so those
square brackets are the syntax for pure
assertions so this equation is something
that does not represent the ownership of
anything it's just just an equation just
a normal conjunction is now yes here we
could we could use a normal conjunction
but I don't think we have it we never
use it I think we just used star
everywhere and the other operations have
analogous specification so I don't think
we need to read them in detail but again
we'll see a precondition in a post
condition and again we see the number of
credits that must be passed in so this
one happens to require three eleven plus
six credits and that's a bit more
concrete than we would like of course
we'd like to say it's Oh Big O of alpha
of n and we have begun working to work
with big O's but it's not quite ready
yet so at the moment i'm just showing
these concrete specifications and maybe
one would also like to to publish a spec
which says something about amortized
complexity and worst-case complexity so
here the worst case complexity is over
log in and the spec doesn't say it if we
wanted to say it we would need to have
maybe another kind of time credits which
cannot be stored from one invocation to
the next so then we could say we require
a login non storable credits and that
would be a wave
saying that the worst-case cost is over
log in this is the function make which
creates a new point so this one just has
constant time complexity and yeah there
is this precondition here this condition
which says the Cardinal the cardinality
if the domain should never exceed n this
is kind of unpleasant but it's imposed
to us by the the way the proof is
written the textbook proof which we
follow it has this parameter n which
needs to be fixed at the very beginning
because it plays a role in the
definition of the potential function and
this is where we see this is where n is
fixed and this is also where the UF
predicate is created out of nothing when
you want to begin using the algorithm
initially you have nothing you can but
you can say I'd like to begin working
with an empty Union Union find data
structure and this does nothing at
runtime actually because you don't need
to do anything to initialize the
structure so it's just a theorem that we
prove then that says if you have nothing
then you can turn that into an empty
Union find data structure with an empty
domain and at this point you have to
choose n and it's going to be fixed for
the remainder of the use of this data
structure so this is not very having to
fix end like this is not very convenient
and there is actually a recent paper
which was published last year where they
are they're able to avoid this thing and
we hope to adapt their proof in the
future large with no bad consequences
yes there are you really coming here
here or yeah yeah here you you can
choose any end you like and it's only
used in in the complexity analysis it
doesn't have any use at runtime so you
could you could choose no no and n is
abuse that run time at all yeah it's
using the complexity analysis so indeed
it is used it appears in these
preconditions but it doesn't influence
the actual runtime it's it's only used
in the analysis yes you could use I
don't know but something like the age of
the universe for N and it would give you
alpha of n equals 5 and basically in
practice you would be happy how about
say it saying n is a ghost that yes it
well it is ghost if you will just like
DNR these are these things appear only
as parameters to the abstract predicates
but they don't appear in the code itself
so that that's the way we we manipulate
ghost state
someone else kid without the end could
you could you have Justine incremented n
if it it's hard now you he exceeded and
we just well in the proof we follow it's
hard to change n in the mid somewhere in
the middle because you have you have
defined a potential function which
depends on n you have carefully arranged
just the right number of time credits
everywhere on every element in your data
structure and if suddenly you change n
then you may have to request new time
credits and and then put them in your
data structure so it's not easy to see
how to do this but but actually the
paper i mentioned does this it requires
some subtle changes to the proof so we
again it doesn't look very hard and once
these guys give you the right approach
but finding it is very difficult i think
so i'll say a few more now about the
logic that we use this slides is
supposed to recall basically were some
definitions of separation logic the the
the assertions that we use are
implicitly parameterised over the heap
so heap to prop means there are
propositions which refer to a heap or he
bled it's typically a partial heap only
the part of the heap that you own and
you don't need to we need to read this
these are the the definitions of the
usual connectives and in particular
separating conjunction says the heap
should be exploitable into two
compatible sub heaps and h1 should hold
of one of them and h2 should hold of the
other so these are basically the
definitions which you find in every
paper on separation logic everywhere and
and the basic see FML framework uses
these definitions what we want to do now
is extend it with time credits and
somehow we have to explain what dollar n
means
so to do that well first yeah let me see
what we would like to have we would like
to have dollar n as a new connective and
your newest kind of assertion in
separation logic so we would also like
it to have type heap to prop and the
properties that we needed to satisfy our
very few only these two basically so
zero credit should be the same as true
as nothing and we would like to have
this equation here which says that if
you have n plus n prime credits then you
can split them and and use the two parts
for different purposes maybe pass end
credits to a function which you're
calling and use the rest for yourself
later on or maybe store store some of
them in the heap for later use and keep
the rest to use now or something like
that so that's basically the only
properties that we need and we also need
somehow to tie the meaning of these time
credits to the actual computation
mechanism we need to say that whenever
you perform one step of computation you
need to consume one credit and so first
I'll say how we define dollar n how this
predicate it just says that well there
is a kind of you can think of the heap
as containing a special memory location
where there is a certain number of
credits that is stored and so we were to
say that we're changing the type of heap
it's not just going to be a map of
location to values but we will add to it
this special memory location which
contains an integer and it's the number
of credits that are still in existence
and in that case dollar n just means
that this memory location this ghost
memory location contains the value n at
the moment and again this can be a
partial count in the same way that a
heat can be a partial heat
which represents only the part you own
this n here can typically represents
only a number of credits that I own and
maybe some other people oh and more and
this is reflected in the in the
definition of separating conjunction
where you see we have a plus here so
this yeah this basically means different
threads can hold different numbers of
credits yes siree algorithms were useful
have it be a rational number that's all
for patients um maybe it could be a
rational number yeah or even a real
number at the moment we've been working
with integers and this doesn't prevent
you in some proofs from using rationals
or reals to reason about how many
credits you have but we thought it would
be simpler to make it an integer in this
model it could be real too for the
moments we don't have many with we
haven't done many case studies yet only
two or three besides this one and for
the moments working with integers has
always been insufficient okay so to
connect these time credits with actual
computation steps what we say is very
simple it's just every function call
consumes one credit and if there are any
loops in the program we just view them
as recursive functions so the we only
need this this role every functional
call costs one and also we provide no
way of creating new credits so you have
to think that at the beginning of the
program of the program's execution a
certain number of credits are given
given by God so to speak and you can
only consume them you can never create
new ones so intuitively it should be
easy to to see that the total number of
function calls that are ever performed
by your program is bounded by the
initial number of credits that you
provide which intuitively means that
this initial number of credits is a is a
good measure of the complexity so this
particular inequality we proven paper so
we have a precise statement which I'll
just skip but we can prove it on paper
in the same way that we prove the
correctness of the logic the sea FML
logic yes what you're counting is the
number of calls to your API functions
such as link every function basically
every session yeah including any
auxiliary functions that you may define
inside your module this time it's the
same with a function uh you can consider
it as a primitive operation and say it
costs 0 or you could consider it as a
function and say it costs one in the end
it doesn't make any difference of course
well it makes a difference in the
concrete count of credits but as
emphatically it doesn't make any
difference and intuitively one might
think that it would be sufficient to say
every recursive function call costs one
credit but since we are in a high order
language we don't really know ahead of
time which functions are going to be
recursive which functions are going to
call each other so it's simpler to just
say every function call costs one and
the way this is done in C FML is that
conceptually see FML with time credits
well it will just insert a call to pay
at the beginning of every function for
instance and then everything will
proceed as in the old see FML without
time credits you only have to consider
that this pseudo function pay has dollar
one as its precondition and that will
force you when reasoning to pay one
credit every time you come across this
call to pay so that's how its
implemented I think
it looks like you're not let's go into
debt you can't say well if I have
infinite sequences of these operations I
will eventually advertise it you have to
save in advance to pay yes the if you
want to advertise you have to save in
advance so I guess this means we we can
we do potential based proofs of
amortized complexity and some paper
proof don't fit in that framework
because they want to consider the whole
sequence of operations at once and for
instance I know if a a paper that
reasons about Union find in a divide and
conquer manner and so it reasons about
whole sequences of operations and and
this kind of proof we would not be able
to port directly another thing which you
may have been wondering about is is it
okay to just count the function calls
and in what sense is that meaningful
measure there are two two assumptions
which we're making here and one of them
is that if you have a no camel function
which doesn't contain any loops then the
the compiler which will translate it to
some assembly or machine code that
doesn't contain any loops either which
means that the cost of invoking this
function is basically a constant it can
itself of course do some other function
calls but those will be counted so there
is basically here a constant factor
which is the size of the largest
function body in your assembly code or
something like that and the other
assumption is that every machine
instruction executes in constant time
for for some constant so some people may
throw their arms in the air and say this
is crazy but I of course some machine
instructions take much longer than
others but at our level of abstraction
we'll we'll just say it's a constant so
if you accept these hypotheses which we
cannot really prove because
that would require a detained model of
the compiler and of the machine if you
accept them then you get that the the
number of credits which are spent is
really up to a constant factor a good
measure of the time that's required to
execute the program on this we are I
mentioned already in passing but these
time credits their ordinary separation
logic assertions so you can this means
you can pass the ownership of a certain
number of credits from a color to a
collie or even back and also you can
store them in the heap and we'll see
that in the union-find example where
when we look at the definition of the UF
predicate will see that it says several
things and among others it says I own a
certain number of time credits that's
not the credits that i have saved ahead
of time to be able to justify the that
the amortized cost of every operation is
is correct okay so this leads me to the
the last part of the talk where I'm
going to say a few more words about how
we define UF internally in particular
what it looks like so you f is a
conjunction of 44 things well the
definition looks like this and i'll
explain in turn what these four things
are i don't think i have to go too deep
into the details i just want to to say
roughly what this is about so the first
part of the invariant is what you would
find in a mathematical proof if you were
reasoning about the pseudocode and not
the actual code then you would need to
say some things like the disjoint set
forest is balanced in some way and the
ranks which are stored on the nodes
satisfy certain properties so that's so
the kind of thing you have to to right
here and if I read just one yeah
this f this capital F which hasn't
appeared yet is is the graph it's a it's
a relation between nodes and it tells
you when there is an edge from one node
to another so this particular line here
for instance says if there is an edge
from X to Y then the rank of x is
strictly less than the rank of Y so that
this says the rank grows as you follow
grow strictly as you follow paths in the
graph so that's one example of a
property which you need to track off it
needs to be part of the invariant and
and so k is this function which maps
every element to its rank and it's also
ghost state in a way if you recall the o
camel code in the actual executable code
we only keep track of the rank of every
root for the internal nodes we don't
need to keep track of the rank whereas
in the proof we need to keep track of
the rank of every node and that's not a
problem in so it's permitted by by this
approach the second part of the
invariant is the ownership of the the
parts of memory where the nodes exist
since this is a separation logic we want
to say we are the unique owner of this
part of memory see FML gives us a
predicate called group ref which
represents a region or a group of
references in the heap and it's
parameterize by a finite map m which
maps every memory location to its
content so in the invariant we are going
to have an assertion of this forum group
ref m and then we need to connect the
the first two things that we just saw on
the one side we had the mathematical
reasoning and on the other hand we had
this group ref assertion and we need to
to say what's the connection between
them so that's what this third part is
about we have to say that the domain of
the map M which exists in memory is in
fact exactly d either the D that appears
in the mathematical
their end and we have we also have to
connect the content so we say that for
every X in there mfx is a link if there
is a link in the graph and MF x is root
if X is a root in the graph and we also
say that if it's a road than the rank
that exists at runtime is the rank that
we keep track in the matter babe
mathematical part of the proof so this
is the usual way of connecting what
happens at runtime with what happens in
your reasoning it's the representation
predicate and the last part of the
environment is the potential so here we
follow the textbook proof about the
advertised time complexity we we it's
the potential based proof so there is
this potential function Phi which tells
us how many time credits we should have
at hand at every point in time so it's a
function because it depends on many
things d FK + and so on and so in
we will have to define this function Phi
and as part of the invariant we will
have to say we we hold fight I'm credits
so that's to sum up that's how you f is
defined it contains the mathematical
invariance the ownership of the
references the predicate that connects
the first two aspects and the
appropriate number of time credits and
once we have given this definition then
we have only have to check that every
operation satisfies its specification so
it takes typically every operation has
UF as a precondition and UF as opposed
conditions so we will have to prove that
this invariant is maintained
the definition of Phi is a very tricky
I'm not going to read this in detail
that's the question here is how did they
find this thing and I think it's quite
hard to understand the historical
process by which they came to this but
some intuition is given by this paper
here where they have an approach which
is not based on the potential function
it's based on looking at the whole
sequence of operations and then using a
divide-and-conquer argument to find a
recurrence equation that describes the
overall cost so this paper is I think
illuminating to some extent but it's not
directly amenable to our style of
reasoning so we have to follow the paper
proof based on on the potential function
and this one unfortunately doesn't seem
to carry any interesting intuition at
least for us maybe for Targon it does
but for someone who would have found it
by now converting a proof that about a
sequence of operations into a potential
base um there you keep your light get a
constant number of credits in beginning
the problem is we we have we are in this
whole logic approach where we have to
give a pre and opposed to each operation
and if you do this this forces you into
a very local view where your reason
about one operation at a time so i don't
i don't know if it's possible to remain
in this framework and at the same time
be able to reason about a sequence of
operations maybe it's possible i'm not
sure
that said if you want to reason at the
level of the pseudocode and so the
actual executable code then I guess you
have more flexibility and you can reason
about the sequence of operations there
was a paper this year by Tobias nibco at
ITP where he did some proofs of
advertised complexity at the level of
the pseudo code and I think he allowed
himself to reason about sequences of
operations so coming back to these
things basically we translate them
directly in to it isn't very
readable but it says the same thing
essentially we use for convenience we
use we don't limit ourselves to the
constructive subset of so we allow
ourselves to use episode and operator
for instance it's used here because here
sergeant says let's P of X be the parent
of X if X has a parent and this seems
innocuous but we're really you cannot
translate it into without using the
epsilon epsilon operator or maybe yota
operator the unique choice operator
because if if X doesn't have a parent
and then this thing doesn't make sense
so you must allow yourself to say let P
of X be this expression if it is defined
and if it's not defined then P of X is
anything it could be any node yes you
need that if you just said p of x has
the time to be the parent of x or my ex
ourselves yeah maybe you could give it a
default value yes yes but then you would
need this if ya you would need this if
which is another thing which we use and
which is also non-constructive in
usually you cannot say if on a
proposition you can say if on a boolean
which is not the same thing so if you
want to say if X as a parent then this
else that you need if which takes a prop
as an argument and
and this requires it's essentially the
excluded middle or something like that
all right so it's another feature which
we use here it's this capital if which
takes a prop and that's also not part of
the constructive subset okay and the
last thing I'll say is well you know you
don't want to look at the proof in
detail it's a bit hairy but what's
interesting is it's just the way that
what you have to prove which is this
anyway inequality arises naturally just
because you have to prove that the UF
invariant is preserved so initially as
part of UF you get a certain amount of
credits by you also get the credits
which are brought to you by the client
for instance if we are verifying find
the precondition says the client should
bring alpha of n plus 2 credits so you
get these credits here and using all of
that you're supposed to well you will
have to consume some of them because you
are making some function calls so that's
the actual cost and then you will have
to prove that you're able to
re-establish Phi the invariant in the
new state in the modified state so
that's the the Phi prime term which is
here so that's what that that's the
inequality which is proven in the
textbooks and here it just arises out of
the methodology which we follow and
that's about as much detail as I wanted
to show about the proof but I can show
more details offline if someone's
interested so in conclusion where we're
happy with the result because the the
proofs the textbook proofs were
relatively easy to port and we think
it's nice to be able to write a whole
triple which says something about
correctness and complexity at the same
time and we think it's good to be able
to reason about the actual code rather
than
some kind of abstract pseudocode and the
whole thing is relatively short it's
about 3,000 non comment lines of proofs
for the mathematical arguments and then
about four hundred lines of code for the
specs and the the equivalent of the VC
gin process so very producing the proof
obligations which f star for instance
would do automatically or Daphne in this
case you have to do it step by step by
using tactics but it's it's quite
concise usually so it doesn't take a lot
of space you can find the proofs online
and in the future some things we'd like
to do so this song I mentioned it's
established a more precise bound which
doesn't force you to fix the capital and
ahead of time so in practice of course
alpha of little n alpha of begin there
are both constants for any reasonable
human use but it's convenient not to
have to fix capital n for the client
also we'd like to introduce this big o
notation Neil Nikhil mentioned this and
this could be while it's one case study
which will be part of a larger project
that's just now beginning and just about
to begin we have got some funding to try
and develop a verified o camel library
containing some basic data structures
and algorithms typically collections of
various kinds and graph algorithms and
the typical kinds of algorithms which
are useful when you implement compilers
or their improvers or things like that
so see FML would be one tool which we
can use to develop these this library
and other possible tools would be y 3 or
or itself or maybe if star so
that's something which we're about to
begin and that's it
thank you was it worse time how long did
it take I took me about two weeks to do
just the mathematical proof of
complexity without any regard with to
the actual o camel coat and then after
your came and did the connection between
the mathematical proof and the code and
it took him maybe one week not when you
meet maybe even less I'm not sure
exactly pretty well Arthur is no normal
yeah a frost of course after is is the
author of cfl and his also a very smart
guy so someone who doesn't know see if
ml would need more time to get
acquainted with it and this and at the
moment CFL is not very well documented
but as part of this project which I
mentioned we we intend to produce more
documentation on how to use the tool yes
um and the version where you have the
particular constants like three alpha
and so on and so they go notation if you
refactor the code a little bit in a way
that introduces more function calls
that's going to change the cost yes
that's the trouble with the concrete
costs it's not modular because some
internal change in the code becomes
visible to the outside because the the
concrete number of credits changes so
that's that's the main motivation for
introducing the big o notation that
allow you to hide yeah internal once you
say it's 00 f alphabet then you're free
to do as many function calls as you like
internally as long as you preserve the
asymptotic complexity just a
higher-order function it's gonna get
called by the higher functions yeah so
when you when you do when you write down
a specification for a fold function for
instance which does a loop you could
equip it with several different
specifications
which will be useful to in different
scenarios for instance you the most
precise specification would say the cost
of fold f is the sum of the costs of all
individual and vacations of F that would
be the most precise specification but
not very easy to use and you could also
derive from that another specification
which says if F is constant time for
instance then the cost of fold F is just
0 of n where n is the number of elements
and you could have other specifications
in between like whatever the cost of F
if you have a bound on it then the cost
of the loop is n times this bound so you
can prove several specs for the same
function and the client is then free to
choose whichever one is most convenient
so that's the way we plan to approach
working with high order functions yes I
can see after seem to talk why you're
attempting to go to the 0 of 0 notation
but at when you first introduce the
three alpha plus it Oh success photo
that's that's going to be very useful
it's useful to see the to see because if
they were meaningful if it was actually
talking about x86 instructions or
something or something or yes maybe its
resilience or something it would it
would be useful to lift that expose them
if the guess if it was an actual
estimate of the worst-case execution
time then maybe it would be useful yeah
say you may not want to just throw away
everything in make it make it over
because ultimately maybe you want to
have a model machine and then if you
wanted to do that I guess we would need
to try and have more automation in in
the process of gathering these little
constants because at the moment it's
tolerable to do it by hand because we
seldom pay we only pay at function calls
but if we had to pay for every single
instruction then we would have to
compute the sums of all these costs and
we would have to automate it otherwise
it would be intolerable
a distribution of Labor where you spend
a couple of weeks during the
mathematical proof I'm wondering how
that division of labor worked out
because it seems like you need to reason
about the structure of the code with the
specific function calls that are made
and so on to come up with these
constants so are you able to do it just
independently of the code initially huh
well it was fairly easy because
abstractly you have you have an idea of
what union-find is so if let me go back
to the slide where i show this invariant
this is you can describe the algorithm
abstractly in terms of these things the
graph f which describes the edges in
memory it's just a relation it has type
element to element to prop and and
similarly you have this function K which
is just a function of every element to
its rank and so on so you can you can
prove many properties of these things
abstractly i can define union and find
at this level i can say what's the
effect of union and find on FK and are
abstractly and then I can prove many
levers about what these operations do
and how how many how much time so to
speak they take so that's what I did
without even looking at the code so you
can do all of this math independently
and then it's fairly easy to connect
that with the actual o camel code using
see FML basically see FML extracts proof
obligations and every obligation is is
proven by one of the levers which you
have done at the mathematical level
ahead of time even the amount of time
takes over so you can you can use and
yes you have to artificially produce
something that allows you to reason
about the time for instance in
to reason about the cost of find I
haven't I have defined an inductive
predicate which means I we are doing n
steps of path compression and once I
have this predicate I can give a bound
an end for instance I can prove that at
most this many steps of path compression
are needed so that's where the hard part
of the proof goes in and then it's very
easy to connect that to what the actual
code does
alright alright yeah thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>