<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Symposium: Deep Learning - Leon Gatys | Coder Coacher - Coaching Coders</title><meta content="Symposium: Deep Learning - Leon Gatys - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Symposium: Deep Learning - Leon Gatys</b></h2><h5 class="post__date">2016-06-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/26_OPg2mHBI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright it is my pleasure to introduce
the Unga teeth Leon is a PhD student in
Machias pathak back as lab and into
bingen and he is each d is about using
CNN's and linking them to biology and
today he's going to talk about how to
use CNN's to transfer style and thank
you yeah thank you very much for the
kind introduction so I'm Leon I'm very
happy to be here today and talk to you
about a neural algorithm of artistic
style which is joint work together with
Alexander eka and my supervisor machias
betta get at the University of tubing so
in our work we use a pre train
convolution in your network for image
processing so there's actually no
learning involved and in particular we
use the convolutional part of the 19
biggg network so we all know that when
we show an image to to a convolution to
a cornet the the information about that
image is represented in the different
layers of the network in terms of the
feature maps and actually each feature
map is just a filtered version of the
input image so for the purpose of this
talk you can think of a CNN just as of a
multiscale nonlinear filter bank now and
we can visualize the information that is
preserved in the in the future maps in a
particular layer of the network by
finding a new input image that produces
the same feature responses in that layer
and if we do that in the in the lower
layers of the network we sort of get
back to the original image whereas when
we go up to the higher layer we find
that much of the information about the
detail pixel values is lost but the
information about the content of the
scenery and the objects in the scene is
still preserved and there's actually a
cvpr paper from this year about that by
andrea but all this group that goes more
into detail now we have a paper at this
conference where
show that if we not constrain the extra
feature activations but the correlations
between feature maps and a number of
layers we get a pretty good model of
natural textures so if capital F is a
matrix that is a matrix of feature maps
in a particular layer so each column is
a vectorized feature map then we just
take a matrix of inner product the
matrix of inner product so correlation
matrix where each entry is just a dot
product between two vectors feature map
to transform the feature method to
transform the feature presentation into
a textural representation that has lost
all the information about special about
the spatial content of the image and if
we do that in a number of layers of the
network and we then find new image that
matches this texture representations we
can tell we can basically get a
texturized version of any input image
now to perform artistic styles ver what
we will do is we will extract the
texture information from painting and
the information represented in a higher
layer of the convolutional neural
network of the photograph which
basically preserves the content of the
image and we will combine both of these
both representations into a new image
that actually combines the style of the
painting with the content of the
photograph so how is that done in
practice well we first show the painting
to the convolutional neural network
compute the future map activations in
response to the painting and get the
correlation matrix on a number of layers
of the network then we show the
photograph to the to the neural network
and we compute the future activations in
response to the photograph and then we
show a white noise image to the network
and basically compute the correlation
matrices in response to the white noise
and compare those with the correlation
matrices in response to the painting and
we do that on a number of layers of the
network and get a loss function that is
just a linear combination of
of the the loss functions in the
individual layers that basically
measures how far away are is the style
or the the texture of our image that we
generate from the texture of the
painting and then we basically at and
then at the same time we compare the
actual feature map activation and
response to the white noise with those
in response to the photograph and then
we get a total loss function there is
just a linear combination of this loss
function that that measures how far we
away from the style of the painting and
that the and the loss that measures how
far we away from the content of the of
the photograph and we can we can then
just use the usual optimization
procedure of convolutional neural
networks and compute the gradient of
this loss function with response to the
feature map activations in the conf net
and use a standard back propagation
procedure to obtain a gradient with
respect to the pixel values now we can
use this gradient just as the input so
this just gives gives us a function
value and a gradient with respect to the
pixels and we can use that as input to
any optimizer and perform gradient
descent on the on the input image and we
can do that until we converge to a very
small loss and basically obtain an image
that simultaneously minimizes the
distance from the style of the painting
and the content of the photograph and I
prepared a movie to have a look how this
image generation works in practice so we
start from the white noise and we will
now see the gradient descent on the
input image to then generate the new
image
and so we can see that basically the
network start with matching sort of the
the low leather features and the color
map of the of the painting and then they
gradually get the content right of the
of the photograph and now we see the the
gradient descent is almost converged and
we can sort of give through a few steps
and you see the the painting basically
doesn't really change very much anymore
but yeah so I will basically we we end
up with a yeah with a with a new image
that combines the style of the van Gogh
painting in this case and the content of
the nips poster now I just want to make
the point that this is not only
constrained to artistic styles fur but
we can actually also apply this
technique for for general style transfer
so here I have a picture of New York by
night and London by day and so we can
use the sty transfer a technique to turn
the image of london by day and to an
image basically by london by night and
with that i think i wanna leave you with
a few impressions of my university town
tubing basically in the style of several
painters and i guess some of you already
seen these images but i think it's nice
to show them anyway so this is a
photograph of tubing so this is staring
I'd this is Picasso and so so many or
not many people actually know that all
the great artists have come to tubing
and faint this so this is smudge the
scream so this is a bit older this is
Turner so
and I went to achieving on a very stormy
day apparently and to have something
more abstract this is Kandinsky yeah and
with that I want to end and I want to
thank you very much for your attention
and if you're
and if you're interested in trying this
out yourself you should check out d
parte oh and you can upload pictures
there and if you want to see more
examples of textures you can check our
website thank you thank you I'm you're
sure so why not initialize from one of
the two images oh you can do that as
well it doesn't change very much I like
the initialization from white noise
because there you can basically sample
many different versions of the of the
same image right if you initialize where
the deterministic seed then you always
get the same image but it's true that if
you initialize from photograph I feel
that usually the pictures look maybe a
little bit nicer but the pictures I
showed you here I think they were
initialized from white noise yeah yes
hey have you explored an analogy for
text such that it's possible to let's
say take a nap here take a style and put
some other content on there so we
haven't done that I have seen something
online where some people tried it didn't
look very impressive so far but I I
guess like if you have the right network
architecture it could work I you have
never worked with all your data so I'm
not really sure yeah any other way yes
have you tried building a generative
model of the covariance matrices of the
features in order to try to generate new
styles so I looked into that or I'm
looking into that it's not it's not
completely straightforward because
you're not really so you can't be sure
that any curve that they actually exists
images for any covariance matrix you can
sample right so it might be that
actually in this texture of presentation
space it's only a point cloud of the
examples that you that you get when you
get when you input images right and
there's no that there's no smooth
manifold that you could model with the
with the density model so but it's a
very good questions and we're looking
into that yeah last question hi how do
you explain that taking the covariance
matrix captures to style so I think you
should so so you you have to think about
as texture modeling so it's really like
a texture transfer algorithm and so the
fact that spacious summary statistics on
feature responses captures texture very
well that's sort of it's it's it's not
super surprising that it works so well
with deep networks that are trained on
object recognition is very interesting
but it's just a spacious summary
statistics so you can also the simplest
way case would be just taking the mean
feature map and that already works sort
of well and that's just the second order
thing and that's that works really well
yeah I mean it reminds me were all the
work by simoncelli he got to do it using
wavelet teaspoons and this is a new
number
exactly yeah yeah very last question I
really like her work and actually
launched your algorithm on WeChat but
due to lack of money we didn't continue
with that but we attract a lot of users
a lot of them are boys using the using
algorithm to depict for their
girlfriends so one of the problem we
found is that for four phases is kind of
distortion a lot but minor suggestion is
that if you don't pick a specific later
for content but you only pick the higher
of the lower level first for a couple of
iterations and then change to a higher
level it actually will make the the
faces and the textures even more clear
and with a better shape yeah yeah I
you've done some experiment as well I
saw you just use a single layer of the
content activation so I've tried using
different layers for the content and i
found a cruiser to take higher layers
for that i think with faces in
particular it would be super interesting
to use network that i actually trained
on face recognition because this network
is trained on objects right and and i
think an image net they are not that
many faces in on a large scale so yeah
but thank you very much yep thank you
let's thank Leon again thank
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>