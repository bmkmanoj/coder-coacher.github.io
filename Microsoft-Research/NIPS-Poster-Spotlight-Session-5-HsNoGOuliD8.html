<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>NIPS Poster Spotlight Session 5 | Coder Coacher - Coaching Coders</title><meta content="NIPS Poster Spotlight Session 5 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>NIPS Poster Spotlight Session 5</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HsNoGOuliD8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
we have eight spotlight speakers they
have three minutes each please visit
their posters once they're done hi my
name is Dylan foster this is a joint
work with Alexander rockland and Karthik
Streeter on so we study adaptive online
learning algorithms and these are online
learning algorithms that are interesting
because they can adapt to data that's
nice or easy in some sense to achieve
improved performance but still maintain
strong worst-case performance guarantees
and this includes algorithms that can
encode a user's prior belief so that
when data matches their belief they get
improved performance formally we
distinguish these algorithms from sort
of typical online learning algorithms in
terms of their regret bounds which is
our measure of performance so you're
sort of typical online learning
algorithm gives us a uniform regret
bound where even though the bound is a
function of data the or even though
regret as a function of data our upper
bound is simply a function of the length
T of the game that we play adaptive
online learning algorithms on the other
hand give us a regret bound that does
depend on data and so can capture the
nice properties I described before so
there's been a lot of work on adaptive
online learning algorithms in recent
years but most of this is focused on
specific algorithms in our work we sort
of proposed a VC or pack style framework
for studying adaptive online learning in
particular we give a sort of for a
particular adaptive bound be we look at
whether or not there exists some
algorithm achieving this bound in an
information-theoretic sense so I work is
a minimax tile analysis of achievability
we give sufficient and in many cases
necessary conditions under which
adaptive bounds can be achieved so using
our framework someone can push a given
adaptive balance through and either say
yes this bound is achievable or no this
band is not achievable but if we add
some constant to it will get a new bound
that
is achievable beyond looking at
achievability we look at going from
bounds to algorithms so given a bound we
can go to algorithms that achieve this
bound using this framework that we call
adaptive relaxations we also drive new
regret bounds for online learning this
includes sort of a new online pack based
style theorem and new bounds for online
model selection in the work in pretty
generic settings and we also give
balance for online supervised learning
with predictable sequences which allow
us to sort of encode prior belief in
behavior of our hypothesis in class and
finally we recover a pretty wide array
of known adaptive regret bounds from
literature this includes small loss
bounds bounds for unconstrained linear
optimization in Hilbert spaces sort of
regret to best first regret to average
style bounds bounds for online learning
with predictable sequences and second
order and quantile style bounds for
experts so if this sounds interesting to
everyone come have a look at our poster
which is number 100
hi everyone my name is Waleed Christian
and I'll give a brief overview of our
paper on actuated mirror descent and
continues in discrete time and this is
joint work with Alex Honnold aya and
Peter Bartlett from UC Berkeley and QUT
so we consider the problem of minimizing
the convex function with Lipschitz
gradient on convex constraint set and
what we show is how you can design
accelerated dynamics in continuous time
then discretize them to obtain an
accelerated first order method for
discrete optimization and so in
continuous time what we do is
essentially combine two ingredients the
first one is the OD interpretation of
nesterov method and that's due to sue
Boyden contest from last year and the
second ingredient is the mirror descent
the continuous-time version of mirror
descent which is due to nemirovsky in
udine which essentially lets you handle
constraints by defining the dynamics on
the dual space and then introducing this
mirror map that map's the dual space to
the constraint set ok so by combining
these two these two ideas we define an
energy function which is this v function
here it depends on a primal variable a
dual variable end time and then we
design dynamics to make it decreasing
over time ok so as a consequence we
immediately obtain the one over T
squared desired conversion straight and
in fact the dynamics have this nice
interpretation so it's this figure on
the right so it tells you that there's a
dual variable that follows gradient
dynamics but the gradient is multiplied
by T and then you have this mirror map
that map's you to the primal space and
in the primal space you do averaging ok
so it's a combination of dual dynamics
and then averaging in the prime of space
alright and so in discrete time now we
show that by carefully discretizing this
OGE you can obtain a family of x rated
narrow descent algorithms that also
achieve the same one over k squared rate
and what the discrete algorithm does is
essentially at each iteration take two
steps one of them is the thread
this update colored in red which is a
mirror descent update with increasing
step size and the second one is the
green update which can be anything from
a gradient step or a product step or a
mirror step but with constant step size
and then to a convex combination of
those ok and the way to show that this
achieves the same one over k squared
rate is to use the exact same weapon or
function that we introduced in
continuous time so we make this
connection between continuous and
discrete time which gives a lot of
intuition of why acceleration works and
then we test this on a number of
examples to show things like restarting
heuristics the effect of the different
parameters in the algorithms and so on
and so if this sounds interesting to you
I'd love to discuss the details so come
to our poster tonight thank you hi
everyone title of a poster is a empacar
localization of homogeneous divergence
on discrete samples face and I'm a
raucous technology from huge innovation
quality and this is a joint work with
trabajan con amore and the purpose of
this poster is to estimate parameter by
solving this kind of optimization
program el interés function and p
children is an empirical distribution of
the data set and cubed theta is a
discrete probability model such as
sports machine or asleep restricted
porno machine and difficulty of this
kind of problem is caused by the
calculation of the normalization
constant for example Boltzmann machine
has a normalization constant rate
written like this and this tongue is
very difficult to calculate when the
dimensionality of the input X is very
large so our motivation of our pasta is
are we never want to calculate a normal
constant and we employ sweet idea to
about the calculation of the
normalization constant first ah here is
a unnormalized model with a
normalization constant region like this
and second idea is homogenous divergence
homogeneous divergence is invariant
against change of the magnitude of the
function so we can estimate the
parameter with the unnormalized model
and final idea is an in-vehicle
operation and this idea make it possible
to ignore also observe the domain on
sample space so finally when we propose
an estimate about the discrete model
which is derived from the convex Ross
function and our proposed s matter can
be constructed without calculation the
normalization constant and our estimator
is a asymptotically consistent on the
efficient I mean that our estimator has
the same efficiency which there with the
mle so please be disposed I'll are 58
thank you very much hello everyone I'm
jayadev Acharya I will talk about
optimal testing for properties of
discrete distributions this is joint
work with konstantinos daskalakis and
Gotham cometh so we consider one of the
most basic questions in statistics
suppose you obtain samples from an
unknown source or distribution P and you
want to know whether so the data is
coming from a particular source or
family or model of interest for example
is that is the data coming from a
monotone source from a unimodal source
or if it's a multivariate distribution
then are the marginals independent of
each other for example suppose you
obtain suppose you observe a few
examples from a cat from a three
dimensional categorical random variable
denoting the gender wealth and voting
preferences of individuals anyone may
want to know whether these features are
independent of
other so as composite hypothesis testing
this problem has been extremely well
studied in statistics for many decades
now and in the classical set up the
domain of the problem is fixed the
number of samples goes to infinity and
we study the error rates for many modern
applications the data set may be over an
extremely large domain it could be
multivariate and the number of samples
is finite and in these cases 11 may want
to study the optimal sample complexity
the computational efficiency for a for a
small fixed error probability and the
question is can we do it with number of
samples that's only sub linear in the
domain size so we propose a unified
framework that achieves the optimal
sample complexity for a number of
families of distributions such as
independence monotonicity law concavity
and so on this unified framework is
based on a modification to the
well-known chi-square statistic that
reduces the variance and we also design
efficient learning algorithms for all
the classes that we want to test against
and one of the main results is that we
can test many families of distributions
with sample complexity that grows as
only square root of the domain size so
if we have a domain of 1 million
elements then we need only a thousand
elements to be able to a thousand
samples to be able to say something so
if you go back to the problem of testing
independence of categorical random
variables where each feature has K
possibilities then the domain size is KQ
but we need only care to the three over
two samples to test independence for
example so please come to our poster
number 94 94 thank
hi so I'm your own singer from Harvard
and this is joint work with saiyaan von
Drake from IBM Research so in this paper
we asked whether convex optimization is
robust to mild errors so suppose that
instead of optimizing convex function
you had access to a slightly erroneous
version of the function the question is
whether you can optimize it
approximately well so in this example we
have a convex function that's depicted
in blue and an erroneous version of it
depicted in red and now I suppose that
you start with a gradient descent
algorithm on the erroneous version of it
the gradient descent algorithm starts
somewhere and then immediately gets
stuck in one of its the local Optima of
the the erroneous function so you know
and then returns the solution which is
arbitrarily bad so the moral is the
gradient descent are fails already for
very very small errors right which is
small somewhat alarming right so now the
question you know the fact that gradient
descent fails doesn't mean that any
algorithm fails so the question is
whether we can design algorithms are
somehow robust to these small errors
unfortunately the answer is no we showed
the very very small errors lead to stark
inapproximability basically we show this
for both the additive and the multiplet
of error models when the air is as small
as essentially one over square root of n
sorry 10 verse crowed yeah 1 over square
root of n and basically what we show is
we show that for a series of very
natural optimization problems in these
various models it would require
exponentially many queries to get our
approximately good solutions I can't go
into the details of the proof but I'll
just give you some intuition so
basically what we do is for all these
constructions we do we construct two
functions F and G so that almost all the
queries these functions are very very
close but an exponentially a few crazy
these functions are far we then
basically express the the erroneous
Oracle through these functions and show
that if we have access to this erroneous
Oracle distinguishing between these two
functions is somewhat hard and this is
this leads to the inapproximability
results so finally just before I go I
want to just want to mention two results
so this this result in comics
optimization actually followed
from a previous result that we have with
a Venus on pussy deem on showing this
module optimization you know is not
robust to these sort of errors but
fortunately for some optimization we can
show that we can get optimal
approximation results with noisy
Oracle's another result that I want to
mention appeared in cold this year
showing that if the air is on the order
of a 1 over n then you can design
algorithms that achieve good results so
in contrast to you know in our model we
show that if you have air of 1 over
square root of n you have an inner
proxima bility but if the error is 1
over n then you can design good
algorithms so that's it Thanks hello
everyone I'm Mithun Chakraborty from
Washington University in st. Louis and
i'm here today to present joint work
with my advisors and meadows so the
question we address here is one that has
been explored for some time across
disciplines ranging from machine
learning to computational economics to
more traditional economics and finance
for that matter which is that if a
sequence of traders were to interact
with the price setting mechanism of a
financial markets such as a prediction
market how would its price properties
relate to the private beliefs held by
these traders about the uncertain event
on which the market is based and most of
the work in this vein that you will find
involves some kind of equilibrium
analysis of market model with Bayesian
learning agents in this paper however we
have adopted a different approach we
assume a myopic one-shot trader setting
and the only other assumption we made
about make about trader behavior is that
they follow a generic smooth risk-averse
utility function and we are agnostic to
how the private beliefs of these traders
are generated we show that if such
traders were to interact sequentially
with a market scoring rule which is a
popular family of methods for
implementing prediction markets then the
resulting price process is equivalent to
an opinion poll which is itself a
standard belief aggregation procedure
that has been studied for a long time in
various fields such as political science
and this is the most general result we
have we also highlight a couple of
special cases thereof which are
important in their own right so the
logarithmic market scoring rule which is
by far the most studied in the most used
member of the market scoring rules
family in conjunction with the constant
absolute risk aversion utility function
class which has no budget constraints
induces a logarithmic opinion poll or in
other words re normalized weighted
geometric mean of the agents personal
probabilities and the same market
scoring rule in the presence of a new
budget constraint utility function with
decreasing absolute risk aversion is
equivalent to a linear opinion poll or
in other words awaited arithmetic mean
of the agents personal probabilities and
in these two special cases we show that
the market mechanism is equivalent to a
Bayesian learner even when the traders
beliefs are static in the former case
the updated market price is equal to the
posterior point probability of the
forecast event with the agents believe
serving as an observation with a
well-defined likelihood structure and in
the latter case the market's updated
price is equal to the posterior
expectation of a beta binomial inference
where the agents belief acts as her
private maximum likelihood estimate of
the same probability so that was an
overview if you're interested in the
details please stop by our poster that's
number 71 thank you so much
hello everyone this is eg a one from
University of Michigan I'm presenting a
multi-layer feature adduction for tree
structure google also where higher
hierarchical projection this is urgent
work with jpn year tree structure blah
so is a powerful technique for feature
selection when there's a hierarchical
tree structure amount of amount of
features however 22 is highly
complicated irregular rider sawing the
tree structure colossal problem remains
challenging especially for larger
applications to deal with lives we
propose a model year feature adduction
method to pre identify the set of being
active nodes which are groups of
irrelevant of features our method can be
summarized in four steps for the first
step we apply our method to test each
node from the top level to the bottom
level to detect the inactive note for
the second step we remove the detected
in active nodes and all its descendants
from the tree for the third step we
remove all the features that are
contained in the inactive notes from the
data and finally we solve the tree
structure Google problem on the reduce
the data one appealing feature of our
misery that the model learned on the
reduce the data is the same as the one
learned on the four data our method is
based on the geometric properties of the
dual problem specifically we have to
tcom hold a given vector with respect to
the two feet ball set that is induced by
the tree structure in other words given
the sum we have to find other summons
even we only have the Sri verbals we can
see that the induced do fit well set is
very complex one of our major
contribution is that will show this
thick
Malaysian problem the means are closed
form solution by a hierarchical
projection era a pillar to our method to
our adult he that will shew the
projection onto the sum of two convex
sets can be decomposed into the sum of
the projections onto these two convex s
respectively if one of them in the bowl
experiments show that our method is able
to identify almost all of the inactive
notes which leads to a speed of about 40
fills our data with about help meaning
variables without our methods the solar
takes about six hours which can be
reduces to only nine minutes is combined
with our method if you are interested
please stop by my otha number 63 tonight
thank you okay last one so I'm tamil
Cohen and this is a joint work with also
decade from Microsoft Research and on a
nail done from the vitamin Institute and
it talks about a bandit convex
optimization which is an online version
of zero order or a derivative free
optimization and similarly to
derivatives optimization we can only
query function values but the function
also changes changes arbitrarily between
queries so it goes as follows first we
have a convex function f 1 we can query
it at the point X 1 and get and get to
see the number f1 of X 1 and we think
about this value as the loss we suffer
on the first round then on the second
round there is a new function f2 which
might have nothing to do with the
previous function f1 week were equally
at the point x 2 and get to see and
suffer the loss f2 of X 2 and get to see
this number in this number only so this
goes on 40 rounds and a our goal here is
to do will so do well compared to the
best fixed point X tau head we played it
constantly throughout the T rounds this
is what we call regret so this nice
problem was first studied in 2004 by
flux mark Alan Rickman
and was extensively studied since then
and despite of this effort it is still
open for more than a decade decade even
in the one-dimensional case and when i
say it's open i mean there is a huge gap
between the known algorithms and
information theoretic lower bounds for
this problem okay so a in this paper our
goal is to narrow this gap and bring
algorithms a closer to the lower bounds
and we do that by introducing a new
bias-variance trade-off of the gradient
estimators used in a by previous
algorithms for this problem so previous
algorithms use the queried function
values to estimate gradients these
estimators are quite accurate they have
a low bias but they're heated at the
variance is huge we show a new trade off
that allows to substantially reduce this
variance at the cost of a somewhat
larger bias and this trade-off turns out
to work in our favor for smooth and
convex loss functions where the best
regret was t to the two-thirds and where
is in a our new algorithm gets regret of
T to the five over eight and you would
have to trust me that 508 is really less
than two thirds okay so for the new
algorithm new bounds of everything else
please come see us at the poster thanks
you
each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>