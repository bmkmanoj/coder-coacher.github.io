<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Botness 2016: Speech Integration with Bots: the Good, the Odd, the Ugly, Lesley Carmichael | Coder Coacher - Coaching Coders</title><meta content="Botness 2016: Speech Integration with Bots: the Good, the Odd, the Ugly, Lesley Carmichael - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Botness 2016: Speech Integration with Bots: the Good, the Odd, the Ugly, Lesley Carmichael</b></h2><h5 class="post__date">2016-07-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/1t0WVRPM-aI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">please welcome dr. Leslie Carmichael
thank you you know when you have a
million windows open forever and ever
and you haven't rebooted in about six
months and it's kind of slow so just
hold on a second oh yeah okay so I've
called this a speech integration with
bots the good the odd and the ugly so
I'm going to give some a flavor of each
of those in a moment here okay so I'll
just start talking so all right I think
it's coming
ok
sorry for the delay and I shouldn't kick
any cords okay so in general terms when
you just think about speech versus text
you know speech is generally great for
things like hand free situations so you
know you need to be in your car or you
know your otherwise busy you know you're
in the kitchen cooking and you know
you're in the middle of a recipe it's
also very good for synchronous and
multi-turn conversation so when there's
a circumstance where the entire
conversation can unfold and there's time
and opportunity for that to unfold
that's a great opportunity to be using
speech but that's not very helpful for
asynchronous thing so you know when
you're thinking about productivity you
want to be able to get things done in
lots of different circumstances you're
waiting in line for something you know
you're on the subway whatever and so in
cases like that having an interaction
that starts with speech but cannot
gracefully be continued using text ends
up being a problem and also speech can
be very helpful for the speed of task
completion so sometimes you know texting
writing out texts can take an awful lot
of time text however is better for other
things like for privacy so you know it
can be a little awkward to be at the
airport and you have some kind of task
that is optimally done in speech because
it's faster but you feel awkward because
you're in a situation where that's not
really so comfortable text also has an
audit trail so if you're interacting you
know with a bot for example and you've
typed something or if you're just in
facebook Messenger and you type
something and some BOTS proactively pops
up to offer you something you can then
just scroll right back up and go look at
what you wrote and say okay I can see
how that popped up right now whereas
with speech you don't have the benefit
of an audit trail sometimes depending on
the type of device or interface that
you're working with also text is better
when you're going to be in a noisy
environment so the the environment you
know room like this that's kind of
cavernous depending on the microphone
array and
vice and so on you can have different
levels of quality and accuracy with
speech and so text is more reliable and
I already mentioned a synchronous task
completion so but what we really want to
talk about is okay that's the general
case but what about speech versus text
for your bot and so I'm going to talk
about these different areas behavioral
trends speech Fe morality and the creep
factor the type of bot that you have
will lend itself better to speech versus
text in some cases what happens when you
have a speech only you I for example
Alexa and also I'm going to talk about
the elephant and the room and when I get
there you'll know exactly what it is so
for behavioral trends I already
mentioned how speech can be awkward in
public another thing is there's there's
this assumption that younger people are
more accustomed to touch and speech
based types of interactions with devices
so of course they're just going to adopt
everything and as they grow up they're
going to be using speech all the time
whether it's at the airport or anything
else but that's actually quite a general
assumption I was talking with Mimi last
night and she raised this great point
that while younger people are generally
more comfortable with those types of
modes and interactions that they're also
quite private so teenagers you know are
in a situation where they're trying to
they're establishing their own identity
and are going to be less likely to sit
in their parents home and start talking
out loud to a bot about something
personal they're going to be more likely
to type and kind of protect their
privacy and also behavioral trends
really vary across regions and across
you know language groups and things like
that so there isn't really a
one-size-fits-all and all of these are
considerations when thinking about
whether you should have speech powering
your bot or not so speech to fee
morality and the creep factor so imagine
that you are you know today you have to
act you activate the echo by saying
Alexa you know Alexa but you know
imagine a day when you're talking with
Alexa and it's a speech only you I and
now bots have an
opportunity to also have trigger words
and jump in you know inappropriate
moments I mean can you imagine you say
remind me in a conversation in your
living room or the word uber comes up or
reschedule or takeout or something like
that and then something you know jumps
in so you're chilling out with a friend
and you're talking about plans to go out
later and one of you says when we go out
later let's take goober instead of drive
so what if suddenly in that moment Alexa
speaks up and says would you like me to
call an uber for you that has creep
factor for so many reasons for starters
it seems like it feels like you've been
eavesdropped on and that's just
extremely uncomfortable and if you're in
the flow of a conversation and a bot
jumps in based on something you said
that it may not have enough context so
it's if it's trigger word because the
device really can't at least there are
laws you know we can't really just have
something constantly listening to
everything that you're doing without
your oh you know you being aware that
that's happening so speech is a fee
Merle and people also don't remember
precisely what they said all the time so
you get this wait I didn't say anything
that made that happen and when sorry
about that so you can't easily go back
and see what you might have said that
triggered the bot to do what it did
text-based communication has an audit
trail like I mentioned before so if the
bot is just tuning in for a trigger word
the other thing is that it may not have
enough context so if you were talking
with your friend about plans for taking
an uber later tonight for something but
it's only noon and the thing jumps in
and says oh hey you want me to call an
uber for you then it's also just creepy
and awkward because it doesn't have the
right context to do that so you have
these compounding problems of you know
the eavesdropping effect and the
ephemerality of speech and having a
harder time being able to kind of trace
back what you said that might have
caused some kind of interaction and then
also this context effect
if if the bot did actually go back and
process the fact that 10 sentences ago
you said let's go out at seven o'clock
and then later you said hey we should
have an uber instead of drive and then
the bot popped up and said would you
like me to call an uber for you at seven
o'clock that would also really really
creep people out so different types of
bots this these last few days a whole
lot of really interesting
categorizations and distinctions have
been mentioned by a lot of different
people so this notion of bots that chat
vs bots that do is a way that I heard
this characterized yesterday also
broadcast vs catalog and then you have
task completion bots customer service
BOTS conversational chat so there's
really no one-size-fits-all for using
speech in conversational chat this is
the type of context that I mentioned at
the beginning when when there's a a
genuine multi-turn experience to be had
and it can be done in a synchronous
fashion like all at the same time then
that can be quite effective for a task
completion but it may or may not be
awkward or appropriate to to do
something depending on the type of task
you know the type of task might be
something that you actually want to get
done on the side when you're just in
line for something and so on and the
type of task that you may invoke when
you're likely to be in a public place so
that would not really be an optimal time
for using speech and also the bot type
interacts with the the device type so a
speech only you I like Alexa depending
on the type of task you're trying to get
done and whether you have other modes
that can have an impact so you would not
want to for example ask a speech only
you I to you wouldn't ask a general
query and then want to review a whole
set of results because I speech only you
I can't show you those results there's
no screen you know you can't quickly
move through those things and so
therefore having like speeches your
modality in that case doesn't help you
get anything done quickly at all because
it would actually take it would be quite
cumbersome to get through those
those results and there's also this
concept of bots versus personal
assistants so a bot takes action on your
behalf for a specific thing that's a
theme that's really come up here about
the you know having like a narrow and
well-defined task being a really
effective way for robots to work but
then there's the notion of personal
assistant so we have things like Cortana
out there we all have Siri out there and
these types of things they know you they
have access to your calendar they
probably have a credit card number and
things like that and they're able to
take action on your behalf for many
things including spending your money and
sometimes they can do this without
confirming with you because you've given
some kind of blanket general permission
and so on but another theme that's come
up here in the last couple days is this
notion of trust and that you have to
build that trust with your BOTS between
the bots and the users well I what we're
going to see happening is BOTS being
able to get utilized through personal
assistants and so now these lines get
blurred you already have trust with your
personal assistant but you may not have
trust or know the bots that's actually
completing a task behind the scenes
there so this is I think going to be an
interesting space for sorting out what's
going on there and and then also the
data management around that if you are
talking with your personal assistant
because you're comfortable doing that
and you're comfortable knowing how that
data is treated as third-party BOTS come
in behind the scene behind that do you
have a good understanding of the data
management and what's happening there so
speech only you I there's no screen to
show or confirm speech recognition
results before a bot takes any action
text to speech read out of the
recognition time of the recognition ads
time to the task you only get one result
presented to you so this gives providers
a lot of power one of the examples you
know that's heard talking with some
people yesterday is how you know unless
you specify to Alexa play booka shade on
Spotify
then Alexa will just go look for booka
shade in amazon's music and if it's not
there will simply tell you that it
doesn't exist so there's a there's quite
a power play there when the the device
situation is such that it's only a
speech you I it means that you don't
have a lot of opportunity of variety and
results and then providers end up making
choices for you also these things are
possibly good for good practical jokes I
recall Jesse Robbins offering an idea
for a good practical joke in these early
and somewhat opera times of bot tech
where he was suggesting that you walk
into a friend's home and immediately
shout alexa order 3,000 live crickets to
be shipped overnight immediately it by
default yep and so even if you go and
you delete the order now there's some
metadata somewhere that you've got this
deep affinity for you know thinking that
you want to buy live crickets and then
canceling that order and who knows what
will pop up on your recommended items in
the future huh more crickets so here's
the elephant in the room I think privacy
is a pretty important topic for this and
in in particular for speech so you know
speech is a special datatype under
various laws globally and in particular
when it comes to kids and Coppa is the
child online private protection act and
this applies to operators of online
services and apps who specifically are
directing their services at children but
it's it also has language in capo that
says if they are aware that they are
collecting personal information from
kids and so speech is considered a
personally-identifying signal as a
biometric signal in this particular law
and this is just one law of many around
the world so what it means is that a
someone who is providing one of these
types of services cannot store voice
recordings without consent and must be
able to provide parental access and
deletion upon request
so what's interesting here is you look
across the landscape of all of these all
of our companies and technologies Siri
ads feature the Cookie Monster Alexa ads
frequently show kids scenarios engaging
in the home the Google home promo video
which recently came out shows school
kids talking to it and you know do they
say that they're directly targeting to
kids I don't know but you know these are
the kinds of things where we have to be
mindful in how we're designing this and
speech adds an extra layer of complexity
there and also it does raise the
question of what about third-party users
of available services so you know
Microsoft we have great ap is where
people can utilize speech and language
understanding technologies and if third
parties are directing what they're using
that to toward kids then there would be
an issue because the terms of use you
know for some of these api is you know
specify the age at which you can target
things and and that sort of thing so
this is a it's an area that i think
should not be overlooked in bot
development and understanding the data
management that's going along with it so
integrating speech into bots how how
would you do it right and i would say
enable speech instead of typing as long
as these conditions are true so if the
user can read edit or confirm the speech
recognition before a bot takes action
especially if it might be spending your
money improve the speech recognition
accuracy by training the engine on the
most probable language for the bot so
the type of task or the type of
situation that's going to be used and
also utilizing understanding and intent
models and not just a domain language
model but also looking at the broader
intent context to get a richer and
better recognition and also not allowing
bot messages to be read out loud using
text to speech synthesis to the user
without consent because the user might
be in a public place sometimes and not
other times and if you have something
like that that's just a
default thing that you're setting up and
that can be problematic so that's all I
had to say thank you sure I can take a
few questions
yeah I don't want speech to be like the
spinning gifts of the old days you know
when people first came up with the
spinning gifts everybody was excited
about plastering their websites with
them and I know I've just dated myself
by saying that but anyway any other
questions yes I'll do a demo for you
next time yes
well actually just in traditional speech
recognition engines the way they work
today we actually can accommodate for a
lot of disfluencies already so a little
tidbit that might be interesting to you
is that the most common trigram in the
English language is III because a lot of
people will start a sentence to say I I
think that we should something something
so when we put the recognition results
into your document if you're dictating
your email or something we just say I
think so and so and we don't you know
actually literally capture your
disfluencies in the display form that we
produced to you so some of that is
already taken care of in the way that we
designed the systems but in the case
that you're talking about that that's
where examples like that would be
valuable training data and there would
be machine learning to benefit from that
and improve improve those models over
time yes your first
experience what huh
okay yeah the question sorry it did not
repeat the other ones the question was
what do you think we will get to a point
of bot fatigue we're just like there's
kind of a nap fatigue you know there's
an app for everything and it's hard to
keep track of it all etc will we get to
a point of bots fatigue and I think the
answer is probably most certainly and
that is you know the the reason why I
had mentioned the integration of
personal assistants and BOTS I can see
how as personal assistants become more
integrated into people's lives that's
where a trust factor gets built up and
then BOTS can be the task specific
excellent tools at getting things done
that can improve the quality of the
experience for your personal assistant I
think that's one direction that all of
this could go the other thing that comes
to mind with your question is I think it
was about six thousand times over the
last 36 hours I've heard the topic of
discoverability raised and so that's
probably something that would factor in
as well if you know apps over time ended
up having marketplaces that help
facilitate finding the apps that you
want and so on and so you know maybe
bots will have some solution like that
as well but yeah if they don't and
they're not very discoverable then
accessing the power of bots through
interfaces that you're more familiar
with may well be key just like Facebook
messengers you know one of the places
where it's a familiar place and then
bots are accessible through that okay
I'm sure one more yeah
so the question was about the speaking
style adapting to voice agents over time
so how is that changing and yes we can
definitely use comparisons with the way
that people when we first when the
industry first could speech enable even
things like web search people would
still just speak a string of keywords
and you know it takes it took showing
examples to people and things like that
to start to get a natural language
approach to show up more we see people
talk to Cortana in a very natural way so
that's a direction that it moves in and
I think you know yesterday there was a
talk from pull-string talking about the
the most important thing is you know
hire great writers and make sure that
you have you know these arcs and the the
way that the conversation should flow
and the bot can guide the conversation
and all that kind of stuff so the very
nature of like how these interactions
will go in these themes that I'm seeing
over the last few days I imagine that
the language that people use with bots
will adapt very quickly and even looking
in the the samples that Lily was showing
from shall eyes you could see a very
conversational natural style that wasn't
you know so terse of you know just
finding out information getting an
answer okay I think that's it thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>