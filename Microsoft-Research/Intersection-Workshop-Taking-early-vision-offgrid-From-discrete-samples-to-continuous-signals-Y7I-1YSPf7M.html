<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Intersection Workshop - Taking early vision off-grid: From discrete samples to continuous signals | Coder Coacher - Coaching Coders</title><meta content="Intersection Workshop - Taking early vision off-grid: From discrete samples to continuous signals - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Intersection Workshop - Taking early vision off-grid: From discrete samples to continuous signals</b></h2><h5 class="post__date">2016-08-11</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Y7I-1YSPf7M" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay so this is work okay it's
complicated okay get over it fabiola a
viola is a PhD student at Cambridge
supplied by a river to Tripoli and by me
and we decided to solve a problem that
i'll show you at the very end which
turned out to meet requirements to do a
lot of work what class of problems am I
looking out i'm looking at their
division problems as Peter enumerated to
begin with so i might want to take a
noisy image and return a clean image or
i might want to take a low-resolution
image like the one on the left and
returned a high resolution image like
the one on the right this is an output
from the thing I shall describe and in
general I may want to take some bag of
pixels that I've brought out here some
bag of measurements of the world and
return some representation of the world
and I'm giving you a hint here that
there is going to be a triangle mesh and
that this is going to be sensible to
have tried to extract a triangle mesh
from an image that is going to be deeply
sensible and but before I tell you that
let me tell you what our options are
today effectively you may consider two
schools of approach to this problem you
may consider the so-called discrete mrf
school where I've given a little bag of
pixels yes and I measure I have some
representation you I for example a gray
level image I'm going to find the gray
level denoise value at every pixel I so
I want to find you is that match the
image and maybe I want there to be not
too much difference between adjacent you
eyes that might be the very simplest
thing I think about I use these sort of
silly norms to mean some distance don't
worry about it so that's what that's one
side of what I might want to do on the
other side I might want to write down
this thing with integrals which says I
want to continuous function you to match
my image and I went again to minimize
some continuous regularizer like the
normal to gradient don't worry about
discontinuities for a moment they're
very important but I'll bring them in
later
ok and I'm going to say well that's a
very simple I'm not just going to look
at pairs I could have some general
regularizer or prior on my use maybe my
latent representation of use is not the
same size as the image so I have some
filter banks operating on the use that
give me my image maybe I go down here
and I have a sort of fields of experts
model where I have a general
transformation from my new space to the
image and then some general
representation of my prior as as some
filters applied to the use or if you go
over here to functional land and have
some generalized regularizer over here
on the function you ok so there those
are all my options so let me say why how
you might want to try and choose between
two and there's a sort of a classic
picture here from plaza del which it to
give it purely as an illustration the
idea is something like when your priors
live on the pixels they end up a little
bit access aligned so you might end up
with some solutions which look a bit
blocky that's the kind of the very
coarse level reason you might not want
to use a discrete functional whereas
over here in continuous land this prior
is rotationally invariant right if I
rotate my ex space this prior doesn't
change its value so this looks good and
you might want to get a picture out
which then says oh look I got a sort of
a smoother solution but there's a little
problem with this side which is you
don't have access to this that is not
what you were given you were given these
guys hey sorry we're oh yes I yes this
example is just a picture that
rotationally invariant would be nice
yeah but it's an impacting course about
filling it there is some data at the
boundaries yeah ok so again so I want to
use this one because you know
rotationally invariant is very nice but
this is the one that we know to work
right so I've said this is a picture of
fields of experts it's not a picture of
what what Lebanon Adler did but the idea
is that when you make your prior by
learning patches from the world if you
take you know eight by eight patches or
10 x
patches then you can get fantastic
denoising results for examples of patch
priors really work they're really great
I love them for a long time and yet the
best you can do with total variation is
a kind of a cartoony piecewise constant
solution so that seems a bit sad the
patch priors we feel capture texture
they capture important stuff about the
world that the dead leaves model under
total variation can't really capture so
patch priors are great but surely we
can't be happy with patch priors and
especially think f five by five when I
took a five by five block and I want to
use this somehow to represent something
intrinsic about the way images are
formed right am I really going to take
the five by five blocks from all the
images in the universe including all the
noisy crack the iphone images which are
noisier than the examples we want to
denoise in the first place that's fine
that's respond question think about your
patch prior it's going to be
rotationally invariant if you show it
all the images ever it's going to be
translationally invariant the kind of
textures you're going to see in five by
five are going to be on off on off okay
there's just that not much complicated
stuff happening under a price prior
surely we don't need to use packed part
and to solve our early vision problems
notice I'm restricting to the sort of
five by five level i'm not talking about
256 x 256 if you have access to all the
beautiful 256 x 256 patches in the world
of course you'll do better but but we
don't can we walked right okay so
discreet MRFs the kind of things that
i'm going to say underlie or live near
patch priors they're fine but you know
you might have a sort of a gut feeling
that there's a continuous world that you
prefer to look at but we definitely
don't want to look at variational
methods as they're represented today
because we don't even have access to the
input data which was that continuous
image I of X and having drawn this
distinction and I have yet to find a
case where the variational method once
you read the sentence that says and then
we discretize and then you do lots of
hard work turns out to be exactly the
same as the as the continuous method all
right so for all the variational methods
that we know of we have some
constructions under our framework that
yield exactly the continuous methods
slightly weird constructions but they're
that they're the same
okay so what is this framework that I'm
trying to tell you about and so again
here's my input my input is a set of
samples at these pixels i have three
samples at these pixels i have zero
samples and at these locations i have
one sample so the input is a set of
samples and they're scalars even for a
color image because there are just three
at the same spatial location so sample
spatial location and in this image I
have I'm telling you 7,000 numbers
that's what I'm that's what I'm giving
in and what I want to get out is
something more beautiful than what I've
been given okay these samples there's a
bunch of other stuff that I might not
know about the image at the blur kernel
or point spread function maybe I don't
know the spectral filters that gave rise
to to the color samples maybe I don't
know the the camera response function or
the gamma curve you know yeah for the
moment let's just say I'm going to
simplify to a gray level image so i have
a list of samples and i have a point
spread function which i may or may not
know okay how did this sample get here
well i'm going to say that sample got
here by looking at a continuous world u
of x so u as a function mapping from r2
to the reals continuous world out here
viewed through a point spread function
which is a kernel kappa i and i'm
representing it with this this cone here
the world was integrated dotted with the
point spread function i added a little
bit of noise and that gave me the sample
at that point right that's what happened
so now it's very easy and obvious how
you write down the functional that you
want to minimize right each of my end
discrete samples was explained by taking
my continuous domain function
multiplying it by some point spread
function it doesn't matter if it's the
same translator that every pixel or if
it's different one at every pixel and
then and then I want to minimize the
difference between my sample on the
prediction under the model and I've done
some prior here this is still a
rotationally invariant prior funny nor
means I may be using one norm to norm
point seven norm I'll be doing something
at boundaries to make it all kosher but
effectively I minimizing over a
continuous function you the difference
between its dots with the point spread
function to give the discrete image
samples
right so that's all all unclaimed all
I'm doing and I'm claiming that we have
never actually in computer vision
written down this paper with this to me
self-evidently correct formulation
before lots of special cases of it which
I you know I'll give you a hint as to
why we haven't done it before obviously
this regularizer could be changed for
anything you know we'll talk about that
so what are the components here that I'm
claiming we haven't properly written
down before I'm claiming we haven't
properly put a discrete sum then a norm
with the integral inside the norm okay
and I'm claiming that to do so would be
correct and there are lots of people who
use special cases like a delta point
spread function that's really no good
because the pixels do have a physical
size given by their point spread
function etc etc so claim 2 i'm going to
try and claim that having written it
down it is correct and the argument i'm
going to try to first of all make is
that we do indeed have a continuous
world that it is sensible to talk about
a continuous world and that's a sensible
thing to seek so here is a i'm going to
look at a single edge from a well-known
image i've left this down here so you
can continue to study it because i hate
it when the equation goes past and you
don't want to see you but the top half
of the slides is what we're going to
look at so i have this single age from a
well-known image and here in red are the
samples from that edge okay so even at
this is the sharpest edge in the image
and even those learners hat probably has
some like furry base around the edge my
point is that the image of lenarz hat
that sharp edge subtends maybe two and a
half pixels so if i try to reconstruct
that using a some piecewise constant
model i can't find a good place to
position my piecewise constant model
because it's not a good model of what
happened however if the black curve is
now considered to be the curve out in
the world and it's convulsed with the
green point spread function then what we
end up with is this sloping
reconstruction so what I'm claiming is a
good fit to lend us hat is a piecewise
constant continuous world convolved with
a point 0 function and that will fit
yeah yes very good point yeah yeah yeah
absolutely very good I'm making I am
making an assumption which is that I
have a continuous world just outside the
camera and that then the blurring is
done on that and of course that's that's
assuming infinite depth of field and I
may have an example at the end we
probably are certainly as an example in
his thesis where he actually solves for
different point spread functions as a
function of depth and yeah yeah there's
some horrible potentially horrible
differences okay good no absolutely and
I don't we've never we've looked at
making them live in a piecewise you know
constant world yeah so that's a full 3d
reconstruction that's great but maybe
where we have to go
which is you making us pretty up stinky
away the what you have to do is take
your little blue and two instances well
actually here is this infinite series
regular isolation
Oh
so the regularizer in sometimes just
sits there it's fine but it's a total
variation style yes hey so the most
important thing okay how to word it so
we do get ringing sometimes as you will
with any deep lowering if you have the
wrong point spread function so if we
have a roughly right point spread
function we don't get ringing this is
one where I think can you ask that again
at the end because I think when you've
seen the mechanics
because my representation has infinite
frequencies in it from the beginning
because it's piecewise smooth so the
representation as you will see yeah yeah
it contains in frequencies it's not
bothered right ok so now I'm going to
make a claim this simple total variation
prior applied to continuous world is as
good as a complicated patch part and
it's going to be sort of obviously true
but let's look at this one the example
so the blue curve is some draw from a
dead leaves model okay so it's on a
piecewise smooth it looks these ways
constant but of the new Tania drift here
so some draw from a piecewise smooth
world that world was convulsed with a
point spread function giving these ideal
samples this is the the ground truth for
denoising the image which I've got which
is the third row here so this is the
image i've gotten i would like to
denoise the image strategy 1 i'm i try
is a total variation denoise on my input
samples and as you can see i get this
sort of stepping effect right i can't
the the prior is trying to say piecewise
step age and of course it is in psy step
age so I over get a stepping effect or I
turn it up so much that I'm just going
to get total cartooning okay so I think
okay the world is more complicated than
I thought I learn the fields of experts
prior on this model and then appeals of
expert fire of size five yes it's
beginning to understand it fields of
experts prior of size nine can suddenly
see that no the world isn't just a
simple dead leaves piecewise constant
model it's dead leaves viewed through a
point spread function so the fields of
expert fire can learn that and can give
me a good answer okay but hey that's
like a nine wide fields of experts prior
on this really simple domain right we
might need a nine by nine fields of
experts on images and we know it's going
to be difficult and anyway what if i
change the scale of everything so and
just to show you the obvious thing when
we run the correct model in this case
it's trivially going to work because it
really is the correct model you know i
get the same the PSN are as i did with
fields of expert
you know it's sort of obvious that the
simpler prior view through a psf can do
the same job as a patch prior on this at
this stage okay what's my time ten
minutes ok so how am I going to solve
this I'm specifically telling you that
I'm going to solve for the function you
and it's going to be over a sort of
infinite resolution ok it's not infinite
resolution it's a 64 thousandth of a
pixel but I think that will do so what
are the options well ok I claim this
hasn't been written down but we've been
doing this forever in computer vision so
what do people do a very simple thing to
do is to write down the function you in
terms of some basis functions Phi so i'm
going to say the definition of you as a
point x depends on parameters bold you
and those parameters are linear
combinations of basis functions Phi ok I
popped that definition of you into my
integral down here I move some things
around with some other things around
move some other things around that was
easy and now I've got the unknown
parameters out here and in here I've
just got an integral which is point
spread function x basis function ok so
for fixed pixels fixed basis functions
fix everything I can evaluate this
integral in here and I'm just going to
go end up with something exactly like
the discrete mrf model that I had before
ok so that's that's fine all I've done
is made myself feel a little bit better
about using a discrete mrf ok so that
was that sequence of stuff happening
there again you know basis functions
equals easy the problem is that the
fixed basis functions are not going to
allow me to move boundaries in the way
that will make the prior work so that's
going to that won't do just to remind us
of things that this could mean one of
the basis functions that people very
commonly use is what I call piecewise
boxes so every pixel has a little box
the basis for the ice basis function is
simply a hot one by one pixel box around
the center of each pixel and now a
linear combination of these exactly
gives you the old mrf some people can do
much more interesting things so the
problem with peace why
boxes is that the only discontinuity
boundaries you ever see are aligned with
the pixel grid absolutely not
rotationally invariant so you can do
better you can use boxes which have a
few more angles in them and this gives
you some increased rotation invariant
but as had it has only been done before
with fixed layout of the boxes so you
improve the normal wrangles you
represent you certainly don't have a
continuous domain representation and you
know if I want to get from you know if I
want to get an age that isn't in here
then I you know it's difficult I could
do some by linear interpolation one sees
that allows in image vectorization so
there's a in computer graphics sometimes
you have an image I of X and you'd like
to find some simpler form of it so you
can find a representation in terms of
these five boxes I'm going to generally
call this loss as sort of a wave littia
expansion so I have some linear
combination of some basis functions
which might look like this all of these
are unsuitable for my task because they
don't allow sharp edges and the sharp
edges of the key to the prior okay so
there's my wavelets again so what do i
do I take the wavelets and then top them
with some triangles so the triangles
have hard boundaries right the triangles
are arranged here so that they're a
measure of the image and then i can
create functions which are like triangle
signs let'slet's they have hard
boundaries and they're smooth in the
middle so its up for a second right so
you is some of our triangles a sum over
basis of some parameter times the cutout
mask for the triangle kaity times the
basis function what's good about this
well obviously I can represent any
function because I can just let my
triangles refine to infinity I can move
the vertices around right and you know
provide you guys suitable basis
functions and I'll tell you about the
choice of those later obviously I don't
want to refine to infinity I want the
thing to just give me a solution so
let's see how we do okay so once more
let me take you through what's going to
happen this is a 3 by 3 pixel image I
have a fixed triangulation underneath
represented by the blue curves what I
want to show you is
that is how we work out those integrals
the point spread function for pixel one
is in this is one inside this polygon
and zero outside now you might say
that's a terrible point to a function I
want a Gaussian i encourage you to
actually look at the point spread
functions of real cameras and you will
notice that they are as non-gaussian as
there are a non polygon I said one of
the things that you see in point spread
functions is the image of the iris of
the camera so in fact a polygon may in
some cases be a better model for the
point a pato polygon with one inside and
the zero outside may be a better model
for the point spread function then some
gaussian that you made up so so i'm
going to assert that i'm perfectly fine
to use a point spread function which is
one inside the polygon 0 outside so my
integral over the whole you is going to
be the intersection of this polygon with
the various triangles underneath so
polygon clipping routine is one of the
pieces of code I need to solve this
problem once I've done that it's easy I
can solve for you trivially except that
it's really really important that i'm
going to move the vertices so now what I
need to work out so here's one of these
integrals right it's the integral of a
basis function over a triangle
intersected with a point spread
functions support window ok so that's an
integral of some function over the
intersection of these two polygons and
what I want to know is what's going to
happen when I move this vertex that way
ok it's a bit painful to work out but
it's no more complicated than the
polygon intersection and we've written
the code for you and it exists online so
the question is what is the derivative
of this intersection with respect to the
movement of this vertex you just do some
greens theorem along the boundaries the
vertex move these intersection points
move a little bit you add them up it's
fine ok right so I've told you that we
can optimize the triangle mesh and we
can move the polygons let me tell you
for a second what the prior looks like I
wrote down the prior like this which was
just some norm of the gradient
integrated over the domain obviously
that does you can't do that where
there's a discontinuity so you separate
the domain into the smooth bits and the
non-smooth bits in a Mumford char
lifeway and then you have a different
regularizer along the boundaries which
says match up along the boundaries and
the normal recognizer inside here the
polygons and you should think of them as
much smaller than a pixel you need an
extra little variable which is a the
okay so to answer this question about
depth of field the answer is you should
really be fitting a full 3d model as a
full 3d model of the world which you may
represent us piecewise are chunks at
different depths okay so to do that I've
got a chunk here at the front and jump
in the back they will definitely need to
live I'll need this back one to live
behind the front one it doesn't matter
how many polygons I use to represent the
back piece if I use very fine polygons
are very large polygons it won't matter
because and now gonna have to skip to to
a picture here which says because of the
way we've written down the energy the
energy of the function represented as
constant inside this triangle or
constant set of parameters inside this
triangle is the same as the energy where
the triangle is split ok so the
triangles never appear in the energy the
energy never gets to look at the
triangles it only looks at the function
they define so this is why I'm saying
the size of the polygon can't matter yes
yes absolutely that must change yes
sorry yes I think you said polygons
anyway yes the point spread function
must change but these are two ways to
change it the one we've done which is
happy as we've actually just changed it
but that doesn't cope with the fact that
the point
function changes shape near the
occlusions the correct way to do it
would be just to build a proper 3d model
of the world read the letter for that we
have we have and I won't show you any
pictures yeah yeah we haven't I won't
show you any pictures we can't recover
it very stable yet it seems that you
absolutely so the question is because of
something okay so first of all if you
fix the triangulation the solution for
you under some norms as convex under
other norms is you know close enough
that it doesn't matter right so you can
fix the mesh vertices it's all fine no
dhokla minima okay but the whole point
is to move the next rose disease and do
slightly better than you were doing with
the fixed point the fixed ones is what
we're doing right and you have to do
lots of hacks to get rotational variants
with the fixed mesh so what I'm saying
is it's a bit like I hope Stefan agrees
that early fields of experts is simply
if you vary the experts we're not saying
we got the global optimum we're not
saying you learn the best act both
filters but they were better than
anything else because everything else
had fixed filters so what I'm saying is
start off with your mesh where you like
it as well as you like start off Umesh
where you like it now move it a bit and
things will go better things will go
back by things will go better I mean
Pearson R will go up or you know super
essence super resolved image will look
less ugly so the fact that there are
local minima does not mean the fact that
there are many minima around me does
nothing I should stand high on the body
side I'm still going to do better by
going down
yeah yeah that's a real question um it
turns out to be quite a difficult
question to pose to leave it right so
what does it mean to rotate the linkage
and rotated by 90 degrees that's not
very interesting ha you know how can I
rotate it by 45 degrees well I can
trivially do it I can apply a rotation
matrix to the exes to the Tuuli
locations but that's not an image you've
ever seen that's that's like a rotated
image if I rotate the image doing the
appropriate resampling well you would
first of all recover this representation
then appropriately r example then you
know ok ok thank you thank you moving
element in around since the late yes
even Miller guys come in physiol doesn't
claim
which is it's a resolution not infinite
dimensional row and I did say 164
thousands of a pixel not infinite ok so
we're help to little by the image in the
image only exists at a certain
resolution so once you refine below what
the image can tell you your prior is
completely in control and you know
doesn't need to cause yeah exactly so
the questions does this prior
intrinsically like or dislike ringing
okay well no the news is that lots and
lots of people know about the moving
element method they're frightened by it
because it looks like a hell of a lot of
moving parts to put together to make it
work and the news here is that it's
really important to move the vertices or
they a finite element to have your
finite elements adapt and I don't simply
mean refined right lots and lots of
people refine so I've got my triangles
and I make everyone smaller about the
same amount refining doesn't get you
anywhere because it doesn't change the
range of angles that you can represent
all right so for my prior to be
rotationally invariant I need to be able
to represent all angles are all 64,000
squared possible angles that I can't
represent so so yeah
China desperation
yes but but I'm not claiming that this
image recovers the underlying the true
underlying model right so yes I could
have a perfect okay here's an example
that will probably answer that question
so we've taken our rendered disk
computer graphics disc and slide it
slowly right so the pixels just happen
to be aligned different plate with the
disc and recover it and you don't get
the same death quick if you add a little
bit of wobbling and jiggling around at
the boundary because you know the prior
doesn't really know what's going on it's
not recovering perfect this so yes so if
you did that profits rotation it depends
where the pixels land which answer you
did
that's a real that's the question right
so it's true exactly okay okay so when
was the where did you put that up okay
so let's make this the question session
so how results do want results I'll do
this one and this is good because okay
let me be clear we've been working on
this a long time it turned out to be
quite hard we told what's going to be
quite hard and it turned out to be quite
hard and and we are not even halfway
done right what we want to do is solve a
up tick flow problem where yellow pixels
map to purple pencils right because we
hate yellow pixels Mac pink to purple
pixels here's an intermediate result
where I have some input some denoising
problems and we have techniques like BM
3d and a gnat's technique which you know
give us reasonably nice looking images
and PSN arse of these numbers and we
have our result which gives us a Pearson
R which is not as good as these ones but
much higher than total variation right I
do not think this result is properly
converged right I don't think this
result I don't think the prior reusing I
think we should have a current or based
prior something more elastica like prior
but yes I hope that are even so we're
clearly without texture it should be
okay now think about texture do I have
some examples um texture texture texture
so we've looked a lot at pixels with two
or three pieces of hair in okay so those
individual strands of hair run into a
pixel certainly one strand of hair
running through a pixel at the infinite
resolution most of the lot of the
textures one might think of should
perhaps be correctly modeled as
themselves not as texture all right so
what I mean is you know if you go close
enough to my jeans you should start
modeling it as white blue white
wait blue if you go far enough away you
should just buy believers you know
whatever a piecewise smooth variation
from white to blue so I do sometimes
wonder especially if you can / 5 by 5
weather texture is just sort of a
accident that says looks too complicated
to resolve or will resolve it to
something they could write yeah yeah
you've read the caption to our figure
these matter guess we should we want to
really well some hair pictures of Fabio
seasons are pretty good for a bit fact I
think we made them too thin you got a
little bit of ringing we don't know how
to fix it at yeah but they're a little
bit fact maybe twenty percent 25 but
they really hair done the little pixel
but Sir I don't know yeah I guess I
guess we've spent at the time so will
you be home from the coffee way and I
guess we can be</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>