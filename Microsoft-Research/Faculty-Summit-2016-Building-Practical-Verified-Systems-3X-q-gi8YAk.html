<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Faculty Summit 2016 - Building Practical Verified Systems | Coder Coacher - Coaching Coders</title><meta content="Faculty Summit 2016 - Building Practical Verified Systems - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Faculty Summit 2016 - Building Practical Verified Systems</b></h2><h5 class="post__date">2016-07-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3X-q-gi8YAk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">this is the session on building
practical verified systems and I think
this is a very exciting time for
verification just in the last like five
or ten years we've really started to see
the first substantial verified useful
systems system software including things
like verified operating system micro
kernels verified file systems
distributed systems compilers security
critical applications and we're
fortunate today to have a group of four
speakers I believe giving three talks
and all of these speakers are people who
have really been driving this
verification of system software agenda
for and building some of the first
practical verified systems so we'll
start it off with Nikolai Zeldovich was
on the faculty at MIT and he'll be
telling us about building a file system
that's so verified that it will work
even when your underlying computer is
not working all right yeah thanks very
much Chris so this is a joint work with
a number of undergrad and grad students
at MIT and two of my colleagues Adam and
France so problem we're working on as
Chris alluded to is that file systems
are actually quite complicated and I
have a number of bugs so this graph
shows the number of bugs found and fixed
by Linux kernel developers in the widely
used ext3 file system it's a pretty big
piece of code 60,000 lines and bugs keep
being found and I'm sure we'll keep
being found years for years to come
what's worse is there's actually many
file systems there every year someone
comes up with a new file system and adds
a Linux kernel with its own requisites
set of bugs ah and the thing that really
worries us is that a number of these
bugs are quite serious they lead to
security exploits they lead to losing
data and so on so the this problem
hasn't of course escaped the research
community there's a lot of research on
trying to find and fix bugs in file
systems but much of it so far has fallen
into the category of trying to find bugs
by symbolic execution crash injections
and so on which reduces the number of
bugs but doesn't eliminate them
altogether we can't say that okay now
we're done I can
really trust my file system to keep my
data safe and there's been also some
work on eliminating bugs by proving
their absence which is the direction
we're taking but the prior work to this
point hasn't been able to capture a full
file system and reason about crashes and
crashes are really important for a file
system because crashes can occur at any
time due to maybe my bat my laptop here
running out of battery or my hardware
failing or some software bug in an
unrelated part of my system occurring
and reasoning about all these crashes is
difficult because they can expose all
kind of intermediate states that existed
for a small amount of time while your
program was running that maybe the
program it didn't consider so on the
right hand side of the slide is a patch
from the Linux ext4 filesystem that says
well this one corner case it doesn't
really happen very often and doesn't
really matter that much but if we crash
this one line then the journal is going
to get corrupted and you might lose all
your data so we got to fix this so it's
really important to reason about crashes
at every point and it's not just for
data loss it also matters for security
so it turns out that for about six years
the Linux ext4 filesystem had two
optimizations not going to describe them
in detail but they involve sort of
writing data directly to disk instead of
through a journal and using checksums to
write journal entries consistently to
disk and it turns out that these two
optimizations interacted in a really
subtle way so that if you had both them
enabled and you crash at just the right
time then one newly created file can
contain the data of some other user
seems like a bad security problem and
the legs developers actually couldn't
really figure out how to fix this
problem so they just disabled both these
optimizations together in the mount
command you can only pick one or the
other so our goal here is to avoid this
mess and we want to certify a complete
file system so we want a machine
checkable proof using in our case
that our code actually meets a
specification both while it's normally
executing and under any sequence of
crashes including what turns out to be
particularly tricky is crashes during
recovery itself
so my laptop runs out of battery i power
it up i start recovering a trip over the
power cord and it crashes again better
be the case that it still has my data
despite these two crashes so the
contributions that i'm going to talk
about in this presentation are twofold
one is a framework that we developed
called CHL for reasoning about crashes
formally for persistent storage systems
like a file system built in that
automates a lot of this proof effort and
allows us to reason about crashes and
the second is f SC q which is the first
certified crash save file system that
are built on top of this that provides a
basic unix like environment and took us
about a one to two years of work
including actually learning for all
but one of the authors so just to give
you a sense of what this all means um we
have two artifacts that we've built the
CHL I told you about on the left and FSC
q the file system on the right and we do
two things first we feed both of them
into the proof checker and that
checks if our proof actually convinces
 that our implementation meets the
spec if says okay we're good to go
in theory then we take the F seq code on
the right and we generate some haskell
code which is how you get executable
code out of or at least one plan
then we compile it with a Haskell
compiler to produce a user-level file
server using the fuels interface on
Linux and linking together with a fuse
driver we can actually run it on top of
the Linux kernel so that applications
like MV or whatever else you want to run
will send their system calls to the
kernel which will for them back up to
our user space file server and that in
turn will read and write the disk using
regular read/write system calls on a
block device driver so just give you a
little bit more intuitive sense of what
this is I actually have it running on my
laptop here so I'll switch over I have a
terminal I can go into a file system are
mounted on a USB drive here using f SC q
I have a little repo storing some C code
I can run may to compile it you know
compilation is maybe not the most
exciting file system or cloud and I'm
not sure what you know how much it
matters if I crash but maybe if I have a
mail server that's actually much more
exciting
maybe I don't really want my mail server
to lose my mail in case of a crash so
here I'll run a simulation of a male so
we're delivering messages onto my USB
Drive using FSC q and in the middle of
this operation I'll crash it by pulling
out the USB Drive so here it is and this
or similar it exactly what we want to
prove that regardless of when I pulled
out this USB Drive and crash the file
system all of my data should still be
there according to the theorem and the
spec and I can try to you know check
this all I have to do is unmount the
file system and remount it in the bottom
terminal here and we'll wait a while for
it for linux to believe that i've
plugged it back in which should happen
and then I should be able to go back and
see that you know not repo that I built
all the dot all files that are compiled
are still there and if I look in the
mail directory there are some mail
messages here for the user there are
some new ones there's a spool directory
with some in progress messages and you
know something seems to be there this is
intact and I can mount it and look at
the files but are these the right files
did I lose a mail message or is this
actually all the mail messages I should
have expected so for that we need some
kind of a specification to tell us what
should we be expecting from a file
system and in at least the unix
environment we have a POSIX standard
that purports to tell us what our file
system should aspire to so I read it and
it has one paragraph that tells us what
we should do in case of crashes or what
the file system should do and I'll
paraphrase this that says that when a
power failure happens you might lose
data and this data might be associated
with a file that you had opened or maybe
with one that you already closed it
might be also socially with the
directory or with some other part of the
file system and you might lose a part of
it or the whole thing and the thing you
should do after a crash is carefully
examined it by hand to figure out if
it's what you want it or not so this is
not from a formal specification
perspective very encouraging in POSIX is
defense the reason they have such a
vague specification is because their
Charter was too
they find a common denominator for all
the UNIX file systems in existence at
the time and they've succeeded but
nonetheless these different
interpretations of the specification
have led to lots of confusion for
applications as to what to do on
different versions of Unix so for at
least the beginning part of my talk our
starting point for a spec is going to be
transactional meaning that every file
system operation has to run in a
transaction so that we start a
transaction do all the steps and then
commit and either the whole thing
appears on disk or nothing appears on
disk and you can implement these with
this fairly simple right ahead log but
the questions for our Tsar how do we
really formally specify this it both in
the normal case and when a crash occurs
and how do we reason about recovery code
running after a crash and then crashing
itself from running again the recovery
code and what happens after recovery
finally finishes so to do this with
start with a fairly standard system
called whore logic where your reason
about programs with pre and post
conditions where you say that if i'm
going to write value v to address a on
the disk and originally address a
pointer to v 0 then after i'm done it'll
have v no big surprise but reason about
crashes what we're going to do here is
add a notion of a crash condition which
describes all the possible states in
which you might find yourself if this
program crashes so for writing to a disk
not surprisingly our model says either
its old value or the new value and I
said not surprisingly but really there's
something here we're encoding our
failure model of a disk here and we're
saying that sector rights are atomic you
can either have the old value or the new
value in particular you can't have a
corrupted sector even if you crash
during writing it and this matches the
common model that many file system
developers have so this spec for disk
right along with our specs for disk read
and disk sync form our sort of set of
axioms about what our failure model or
disk model is and on top of it we can
try to prove more interesting things
about bigger programs so just to give
you a sense of what it means to write
proofs about bigger programs here's a
function for looking up a block number
in an inode
and the reason this function is slightly
interesting is because it actually has
to see if the block number is big in
which case it has to go through a layer
of indirection otherwise it can read
directly from a linear array so what we
do to prove a pre post and crash
specification about a function like this
is to transform the function into a
control flow graph very much like
standard for logic reasoning and then
try to prove that the precondition of
each previous step implies sorry the
post condition of each step implies the
precondition of the next step after it
and the interesting thing for crash
conditions is that we have to prove that
the crash condition of every step in
this function implies the crash
condition of the entire function which
models what you would expect the crash
condition of the whole function is how
you might crash in any one of the pieces
the all the steps I've described so far
actually pretty automatic and can be
largely automated by our CHL
infrastructure the thing that we find
that actually takes a non-trivial amount
of time is reasoning about different
representation and variants on entry and
exit from a function where your
reasoning about the same state of a file
system at different layers of
abstraction so to give you a little bit
more sense of what I mean by that when
you give you an example so we talked
before about the specification for
writing to a raw disk location and here
i have a specification for writing to
transaction so I've started a
transaction and while I'm in a
transaction I want to do a logged right
I could of course write a specification
that says well yeah i just added one
more element to this list of elements in
a transaction but there would be a
difficult specification to use from a
higher level instead the specification
we write is that in the precondition you
can think of the disk as satisfying a
log invariant that says it kind of looks
like active transaction with some
starting state and an old state and this
old state has address a point a to v 0
and the old state isn't the real
contents of the disk it's the virtual
state inside of this transaction layer
and afterwards you still have a disk
that contains some kind of a log
representation but the representation of
the log is that there is a new state
with address point here than you value
and the slog wrap you can think of it as
a big representation invariant
implemented as a macro of these little
points too fat
it's about all the different addresses
that the log is using to store its data
structures so this is how we reason
about the sort of higher level functions
now we're actually in a position to try
to argue about a specification for an
entire system call this is a simplified
version of the create system call that
creates a file name in a directory and
the precondition for this is that we are
starting in a state where we have some
sort of a tree representation of what's
actually on disk and we for the
simplified spec we say well there must
be some path where we are right now
we're trying to create a file and the
file doesn't currently exist in that
location in the tree and the
postcondition is going to say well yeah
the new state is we also have a tree but
it's a different one it's the one that
you get if you take the old tree and you
plug an empty file into the file name
we're trying to create this is a
reasonable spec I'll sort of pause it
for the create system Colin POSIX the
difficult thing here is the crash
condition so what are all the possible
ways you might crash while creating a
file well you might crash before you
even start creating a file or you might
crash after you've already created the
file or maybe you crash in the middle of
creating the file while you're writing
some parts of the unjust data structures
or be you crash in the middle of
committing the transaction for this
operation there's many other states in
which you might crash and what we'd
really like to say is that after
recovery we are either back to the old
state or onto the new state and to do
this we need to understand what the
recovery procedure is doing so in our
case the recovery procedure is actually
fairly simple it starts with any
precondition that satisfies this log
intact macro which is just a shorthand
for that long list of crash conditions I
showed on the previous slide and in this
post condition it promises that the disk
will either be in the last log state or
it'll roll forward to the new committed
state and the really interesting thing
about this log recover specification is
that it's aight important its crash
condition is exactly the same as its
precondition which means that we can
crash as many times as we want and
restart log recovery so by putting that
create system call in a slog recovery
together we can finally write down and
Adam a city spec for that create system
call
we start with the same precondition I
showed you earlier get the same post
condition but now this recovery
condition says that after we finally
finish recovering will be either in the
starting state or in the news data now
this actually looks like the kind of
atomicity you might actually want from a
file system so to summarize the CHL
framework I've presented to you the key
idea here is this notion of crash
conditions to describe the ways in which
your program can crash and these
recovery semantics that allow you to
reason about what happens after you
repeatedly jump to recovery on a crash
and the benefit here is that we're able
to precisely specify the way a system
can fail and automate quite a bit of the
proof burden so on top of this we've
built a little file system called fseek
you that I showed you a demo of earlier
the file system design itself is not
super exciting it's close to version 6
units from the 70s the only difference
is write ahead logging which gives us
crash consistency but we're also missing
some features like symbolic links that
allow us to write a simpler
specification and the only sort of
interesting thing here is that our
implementation is carefully structured
to reduce proof effort as opposed to
perhaps have less code or some other
goals so in terms of the evaluation I've
already shown you it kind of works on or
at least in one case it handle the crash
okay ah the bigger question is really
what kind of bugs have we eliminated by
writing and proving these theorems about
FSC q and how much development effort
was required for us to write all of this
code and proved it correct and what is
the performance characteristics of a
physic you like so in terms of the bugs
that we eliminate one data point is that
we very rarely actually had to run our
file system we mostly worked in proving
its correctness and when we finally
executed it it pretty much just worked
we rarely if any if ever ran into
implementation bugs because we had a
proof and when we ran it it did what we
wanted the one exception of course is
when we got the spec wrong so one
example is we forgot to specify that
when we extend the file we should zero
fill those new parts of a file
in our case we filled it with whatever
was on disk already and complications
fail to work we noticed this fixed the
spec and then we were able to move on
maybe there's a more systematic
evaluation we looked at a bunch of bugs
that Linux file systems have suffered
over the years loosely categorized in
this table on the slide and what you can
see is that for many categories f seq
eliminates all the possible bugs in that
space perhaps more interesting are the
categories where f SC q does not
completely eliminate the possibility of
bugs one such category is returning
incorrect error codes our specifications
are imprecisely in the sense that they
say that if an error occurs you will get
an error back and nothing will happen
but we don't prescribe a particular
error number value which POSIX in some
cases really cares about do you get
eeper more Ian Val or email access or e
too big we don't care and as a result we
might miss some errors on the other hand
if we're turning air we're guaranteed
that nothing happened we roll back the
system call a similar category is
resource allocation bugs so f seq is
guaranteed to never lose track of
resources but our specification does not
require the file system to create a file
even if space exists it's always allowed
to say I can do this you get an error
back and finally we don't do anything
about concurrency bugs right now partly
because or in large part because we
simply don't model concurrency in our
file system every system call is
executed sequentially and we're
currently working and have some ideas
about how you might do concurrency but
that's actually quite a tricky topic in
formal verification so far now in terms
of proof effort and what it took to
develop this this whole project is about
thirty thousand lines of verified code
and specs and proofs to put together now
the number is kind of big you know
remember that buggy ext3 file system
most sixty thousand lines of code the
cool thing here is that we have formal
proofs helping us so in some sense it
doesn't really matter if we have a lot
of code or a lot of proofs because
they're checked the other cool thing is
that about half of this is the CHL
infrastructure I told you about that
should be common for any file system any
storage application and f seq proper is
a little bit under fourteen thousand
lines of code now perhaps the more
interesting question is not how many
lines of code it took us to do this once
but what does it take to evolve it to
add a new feature once we've built FSC q
and that actually seems more promising
so we looked back and try to figure out
what did it take us to implement various
features once we had a basic protocol of
seq up and running and they're largely
contained to the particular module
affected by the change so for example we
had to reorder disk rights for
performance and we changed about a
thousand lines in the logging layer but
nowhere else and a similar story held
for a bunch of other changes where they
were pretty localized and it's partly
helped by having very precise strict
specs between layers that if we can
reprove with the change module the
change does not propagate further in the
system now in terms of performance we
are evaluated running time of
development like benchmark running gait
make and this mail server I showed you
in the demo and we compared fseek you
with two file systems one that has
pretty much the same design but it was
written in C called ex v6 and the other
is the ext4 filesystem that I showed you
earlier from Linux and we run ext4 in
two different modes one in the
synchronous mode which mirrors our very
strict transactional crash consistency
guarantees and the other in a more
asynchronous mode so the performance
results are that we're actually pretty
close in terms of runtime to the ex v6
file system the overhead is mostly
because we're running Haskell instead of
C compared to ext4 we are maybe within 2
X in terms of performance because ext4
has a more sophisticated right ahead log
design that writes about half as much
data than our simple prototype I'm
describing but the huge winds are from
changing a spec in EXT for a sink the
file system does not promise to write
your data to disk right away
how pretty much every file system runs
in practice and then everything runs so
much faster so the one thing we've
worked on actually since we've written
published this result is trying to
achieve close this gap of trying to
implement differ durability we have some
preliminary results that actually show
that you can do it and now we have a
version of FSC q that is not fully sort
of published and documented but actually
matches ext4 async in terms of its disk
i/o efficiency so it seems hopeful that
we can get pretty close to that really
low runtime number and surprisingly the
hard thing wasn't so much in writing the
proofs but more in coming up with a
succinct and reasonable specification
for what does it mean to defer the
durability of a change to a file system
what does it mean to call F sync and so
on there's a bunch of other open
problems as well that we are looking at
how to certify a parallel file system
how to certify applications like a mail
server or key value store and how to
shrink the tcd size and actually
generate efficient executable code
instead of haskell but maybe the broader
message is that we'd really like to
prove end-to-end application security
with this approach and from our
experience formal verification really
does seem to have turned a corner and
seems to be getting towards being
practical for really engineering secure
systems and we'd like to prove
end-to-end security of applications like
messaging where I'd like a proof that if
I type a message on my phone and I say
this should be sent to Chris let's say
then only chris's phone should show this
message and no one else's and I think
formal methods is one part of a solution
to a challenge like this and I think
there is a big opportunity here to have
really significant impact on how we
build secure systems so to close I told
you about the CHL framework that we've
built for formalizing and proving
specifications about systems that might
crash and we used it to build a fescue
file system that has pretty usable
performance and took us somewhere around
maybe two years of effort including
learning in the process and all of
our source code is available online and
if Chris permits i'll take some
questions yes
speaker and we have time for a few
questions so what does sump shins that
you need to make about the underlying
hardware and how do you express them in
your assertions yeah so the assumptions
are actually these kinds of
specifications so this is perhaps our
most interesting assumption that when
you call disk right then on a crash
either you still have the old value on
that sector or you have the new value on
that sector we have the discrete
function which basically says if the
value is there you'll get it back and we
have the disk sync function which says
you'll sort of flush pending rights but
we basically have these three axioms
written in this crash for logic that
describe the three functions that are
this provides and that's pretty much it
and how realistic are these assumptions
which is who you talk to our mini file
system developers especially academic
ones sort of swear by these assumptions
in practice if you buy an
enterprise-grade disk it matches these
assumptions if you buy a reasonably
inexpensive consumer SSD let's say or a
USB flash drive it will often not meet
these assumptions so the failures you
might have is that you crash and the
data there is nothing like you've ever
written there at all and if you sink it
tells you yep I flushed all your changes
to disk it might not have actually
flushed them yet so I think you could
argue about what these assumptions are
you could formalize a different set of
assumptions and prove a file system on
top of them but I think many of the same
ideas will still be useful Thanks other
questions so you showed that the crash
condition wasn't particularly difficult
to write because it was like really big
right so I didn't really understand
whether you somehow whether your method
actually you still have to write that or
or did you or can you say something like
well if you execute the recovery code
after after this procedure this is the
final state that you get and and this
eradicate the
the need to actually write the yeah so
for the top level specifications we've
actually come up with a notation that
captures this notion that basically
you're either in the precondition or the
post condition and after recovery you're
in one of these two states because it
seems like like the model logic along
the lines what's used in kiv would just
allow you to say inside the formula well
after executing this program this is the
condition that has to hold which seems
like something that would be useful here
yes I think you can build for for
interfaces where you really expect this
nice closed sort of atomicity you can
write notation we have one a notation
that does this it turns out that inside
the file system you often have various
subtleties about how you're going to fix
things up because you're in the middle
of the final system your recovery
routine is maybe going to do something
specialized in that case it helps to
write a slightly different crash
condition which is why we kept the
notation for our you see em alright
let's go ahead and thank Nikolai again
our next talk will be by brand partner
is a researcher here at Microsoft
Research in Redmond and he will be
telling us about verified systems with
with an eye toward security I think
thanks Chris yeah I'd like to tell you a
little bit about the ironclad project
that we've been working on at microsoft
research for the last three and half
years or so so this is gonna become a
broad overview so I thought I'd start at
the very beginning when most of us
involve this project we're coming from a
security or a systems background and so
we mostly thought that verification was
something you only use for really small
programs or for critical but maybe niche
applications so things like NASA or say
publishing papers at poeple can all
agree very important but not something
we all do but then thanks to this the
series of successful verification
efforts around larger more interesting
systems as well as some really slick
demos that we saw some modern
verification tools we got really excited
and said maybe this is the time
verification is going to take off so we
can said you know we came up with this
hypothesis is a these tools are ready
we're going to build big complicated
systems with them
and unfortunately having worked on this
for about three years I would say this
hypothesis is not actually true yet what
I do think we have proven is a somewhat
weaker version of that hypothesis I
think that if you have a group of
researchers who are not faced with say
eminent product deadlines they can build
somewhat practical systems at a modest
scale that get moderately complex I
think that's already a major
accomplishment in a long way from where
we've been say a few decades ago but
part of the goal of the ironclad project
is to try and bridge this gap to take us
to the point where this is a regular
tool real developers do turn to so the
ironclad project we've had a couple
phases we start off with what we called
ironclad apps we're trying to prove the
security of an entire stack of software
we then brought in our horizon doing
compass distributed systems where you
have multiple systems running verified
code and they're all talking to each
other and finally most recently we've
turned to the average HTTPS project
where we're trying to verify one of the
cornerstones of internet security so
this talk will give you a brief overview
of all three with a focus on the
security aspects so with an collide
items we were trying to provide this
end-to-end security guarantee that
Nikolai alluded to and so this is
motivated by the observation that today
when you submit your information online
really the only guarantee you get back
is something that looks like this right
they if you look carefully all they
promise is that they're going to use SSL
and they're going to try hard to protect
your data and you know maybe that's not
the most reassuring statement but even
if you believe that they really are
trying as hard as they can all it takes
is one little bug anywhere in their
software stack and that guarantee is
going to be undermined so in contrast
with iron cloud apps we want to provide
a strong guarantee that every single
instruction in this remote service
adheres to some simple high level
specification so more precisely we'd
like the service to provide some
statement and a public key that
convinces Alice that every single
assembly instruction is going to adhere
to some simple policy that she has in
mind like her password will never leak
or her data will not be misused by this
remote service so we're able to provide
these strong guarantees by combining
three technologies one is a facility
called late launch it's a predecessor to
the sgx technology that's become more
popular what this allows this is do is
to run software and a completely
isolated environment so we don't have to
worry about other hardware or software
on the platform
we also you take advantage of secure
hardware to bind that cut that software
to a public key and then we use software
verification to prove that that code
that's actually executing matches some
simple high-level specification all
together we put this together into a
property we call secure remote
equivalence and what that means that a
high level is that Alice can establish a
secure channel meaning that her messages
will remain secret and will not be
tampered with and she can use that
channel to communicate essentially
directly to that abstract version of the
application she no longer cares how its
implemented because she knows how it
will behave of course the main challenge
here is the software verification angle
because for top to bottom end and
security we want to verify the entire
software stack and yet we want to be
able to do so with a reasonable amount
of effort because the effort to do
verification is one of the main barriers
to using it in practice so of course
there's been prior work people have done
verification for security purposes
before but a lot of it was focused on
small components so looking at say the
security of the RSA oap protocol but not
the code that actually implements it let
alone the code that surrounds it in a
real system other efforts some of the
ones I mentioned before looked at larger
pieces of code but typically only add a
single layer so when you're only at a
single layer you can't give it a good
into end guarantee about how the entire
system is going to behave in contrast
with iron cloud apps were able to
provide a strong end and secure
communication with remote service all
the way down to the level of assembly
code this means that we can rule out a
host of the standard security problems
buffer overflows code injection kind of
things that you see in the headlines or
security conferences but it's actually
more than just a list of negatives is
actually a strong positive property
because we know exactly how the
application will behave at all times
give you a flavor of how we do go about
providing these guarantees like to go
through a little bit more detail what
our methodology looks like so typically
we start by writing down some trusted
high level specification for how we
expect the system as a whole to behave
we do that using a high level
declarative language that allows us to
write things like for all's we can
quantify over all possible inputs to the
system we then write an implementation
again in a high-level language in this
case daphnia language developed at
Microsoft Research and this looks a lot
like a standard programming language
that you're probably familiar with
except that we can annotate it with pre
and post conditions so precondition says
that
must be true before you can call it the
postcondition says that it will be
checked that this procedure actually
does provide this property when you
return and of course there may be hints
that you add to helpfully verifier see
this that's how we get past the
undecidability of this problem
ultimately after this verification signs
off we compile the specification down to
something that talks about the real hard
where you're going to run on and then we
compile the high-level deafening code
into a verifiable assembly language so
this looks like assembly language that
you're probably familiar with except
that we've translated the high level
invariants to now talk about the machine
details like ax and EDX and the compiler
is also smart enough to insert
additional annotations that help the
overall proof go through ultimately this
is what we feed to our verifier and so
if it signs off we're getting a
guarantee about that low-level assembly
code that we're about to run so assuming
that it does we go back and we strip out
all the annotations so we just have
regular assembly code and we run that
through a trusted assembler and linker
and that's what produces an executable
so this approach has a number of
benefits it means that we can write our
specifications in a simple declarative
fashion which makes it easier for a
human to come along and look at this
spec and decide yes that's how I want
the system to behave we also spend maybe
ninety five percent of our time writing
code at this high level which means that
we can write proofs and code at a fairly
rapid pace and iterate quickly and to
give you a sense of what that looks like
I'd like to give you a small demo of
what what it looks like to use the
language in particular so here's an
example of a method that you might write
in Daphne so this is a little bit of a
toy example but it'll give you a feel of
what the workflow looks like so here I
want to take I'm taking in an array and
a length and I want to make a copy of
that array something you might do in any
imperative language and so as you might
expect I'll start off by allocating a
new array and Daphne's actually running
in the background and it's already
detected that I've made a mistake here
and it's telling me that may have just
allocated a negative length array so
that's bad but rather than adding a
dynamic check to check whether the
length is greater than zero I'm instead
going to add a precondition that says
anybody who calls me has to prove that
length is greater than equal to 0 and
again running the background Daphne can
see that that's enough to make that
error go away so I can then proceed to
write the loop that's going to do the
copy so
not too surprising here we're going to
loop over all the indices add an
invariant that's keeping track of the
fact that this loop index is going to
stay within bounds and inside the loop
we're going to do the copy that you
would expect so copy from the input I
over to output I and again here Daphne's
picked up a number of problems that I
made along the way one is that if we
hover over here it can't actually prove
that i'm going to terminate and that's
because I as I often do have forgotten
to increment my counter here so once we
add that Daphne can now infer that this
entire thing is going to terminate but
it's noticed that I might have a null
pointer here another common programming
mistake and again rather than adding a
dynamic check i'm simply going to ask
Utley person who's calling me not give
me an OL array and finally we have one
more slightly more subtle problem this
is saying that the index may have gone
out of range and that seems odd because
I've already proven that I'm got or that
I'm looping from zero all up to length
if you think about for a moment just
because i called it Len doesn't mean
that the length that was passed in has
anything to do with the array that was
passed in so to rule out that problem I
can add a requires this length really is
the length of the input array that I was
provided so once i had that I'm now
proven that I don't have any bugs in my
code but I haven't actually proven
anything useful about this method or
what it's about to do so for that I
might like to write an insurer's it says
array equal of the input and the output
array to say that I've actually done
this copy the way you'd expect and here
unfortunately we can't this proof isn't
going through this is a a post condition
that's not holding that's because as
we're going through this while loop
we're losing track of all the progress
that we've made so far so here's another
place where I have to give it a little
bit of a hint and say that for all the
indices that are between 0 and the one
that we're currently working on then
I've current I've correctly done the
copy for those embassies and so we're
going to verify that this is maintained
by the while loop and then automatically
infer that that implies the post
condition that we were trying to get so
now I've actually proven something
interesting about this method is a
question
sure so you have two questions why do I
have to write the insurer's and why do I
have to write the invariant ok sure so
you could certainly imagine a system
that automatically infer some of these
invariants and people have done some
work on that and you there's also other
ways in which you could write this this
program that you would not need the
invariant in this particular case I
think it's this is just a useful toy
example to show that what the workflow
looks like in more complicated code it's
less likely that you're all correctly in
for a loop invariant and and what we
found in practice is it the easy ones
like this are or sorry the ones that are
easy to infer are often not painful to
write so like that first invariant and I
just type it in I don't really think
about it the ones that are hard to infer
are also the ones that require the human
to sit there and put some thought into
it and so there's some gains to be had
but not not a lot of present so
hopefully that gives you some evidence
for why I think rapid development is
possible when working in this language
and of course that's a tour example it
doesn't always work out that nicely but
many times it does ultimately though we
get this nice low-level guarantee about
the actual assembly code that we're
going to be executing and that means
that we can put arbitrary complexity
into our compiler and as long as the
proof still goes through it on the
assembly code we don't have to worry
about having introduced some flaw in the
code that we did at the top level and in
fact this means that we can do
performance optimization down at the
assembly code in fact we have done this
to get better performance and you can do
that with the sort of safety net of
verification behind you so give you a
flavor of what the actual implementation
looks like we write down specifications
for the hardware and for the application
the libraries it depends on and then we
write verified code so we have a
microkernel based on the verb up
previous work on the verve microkernel
on top of that we wrote a number of
drivers for both the TPM the secure
hardware element i mentioned earlier for
the network drivers network stack a lot
of cryptographic algorithms including
sha h mac RSA and
some algorithms built on top of them and
ultimately applications that we care
about give you a flavor of those
applications we start with a very simple
password protector that makes offline
dictionary attacks impossible we then
moved on to a logical notary that
assigns time stamps to documents that's
presented with by hashing and signing
them along with the monotonic counter we
had a generalization of that to a
trusted incrementer and then our sort of
showpiece application is a different
tree private database very simple
database but one that gives you the
strong guarantee that when you encrypt
your private data and send it off to
this this database even though we allow
analysts to run queries against that
database the results are only ever
released in a differentially private
manner that means that at some level the
probability that your privacy is harmed
by contributing to this database can be
considered negligible however it's not
actually obvious how you specify
security for applications like this when
you want to encompass the entire stack
of software so there's the problem that
you first have to write down what does
it mean to have something that's
difference your private but even once
you do that if you want a low level
guarantee you I should also have to
write down a specification for the
underlying hardware and even with those
two you still need to come up with some
way to systematically connect those two
and hits give a specification for the
entire system so let me give you some
examples of how we do that in the
context of the differential private
database so as we do for all of our
applications we do this as by writing
down a state machine for how we expect
the application to behave that means
that we first have to define the states
the application maintains so for example
the database has a set of keys a privacy
budget and of course the database data
itself then we have to specify how the
state machine can transition from an old
state to a new state upon receiving what
requests from the outside and what
responses it might be permitted to send
in response so here's an example of a an
analyst sending in a query and we're
going to say that you're allowed to
respond to that query if the amount of
privacy that you're proposing this end
is less than the budget that we have
remaining that in the new state you've
updated the budget appropriately to
account for that query and the response
that you're about to send is the result
of doing the computation correctly and
then adding an appropriate amount of
differentially private noise so that
gives us an application spec but then we
still need a hardware spec so we do that
by writing down a detailed model of x86
hardware that means that we write down
and say that each CPU has some number of
cores
a linear amount of memory some io state
and then each one of those course has
the standard registers like EAX EBX as
well as all the sort of hairy details of
segmentation and paging on top of that
model we then write down a specification
for each assembly instruction that we
plan to use so for example we say that
the add instruction takes into registers
it does the appropriate modular addition
and stores a result back in one of the
original registers so this is a little
bit tedious but we were able to write
down about 60 assembly instructions and
that proved to be enough for the kind of
software writing this still leaves us
with the question of how do you connect
these two layers right the differential
privacy specification is talking about
real numbers and high level abstract
concepts this is talking about 32-bit
integers so to connect these two
specifications and create something for
the entire system we have to look at how
information enters and leaves the system
particularly at the assembly level so
they simply levels typically through
instructions like NB and out be the
right directly to devices as well as
more subtly instructions like move that
might write data to a region of memory
that can be accessible by a memory map
device like a network card so our
verification tools allow us to put
preconditions on these output
instructions so you might think that we
can simply write down the application
policy and say that you must prove that
you're satisfying the application policy
before you're allowed to call this out B
instruction and technically that's true
but in practice that would mean you'd
have to write down a mathematical
function mapping all possible 32-bit
inputs to the system to all possible
allowed 32-bit outputs from the system
that means we're gonna have this nice
clean specification of differential
privacy and then we're going to add all
these gory details of how to create an
IP packet computer check sum over it all
these details that really don't belong
in the specification that are going to
make it hard to right and even harder to
look at and decide yes that's how I want
my system to behave so in contrast we
came up with a technique that we call
state machine based relational
verification and a high level what that
means is that we annotate instructions
that read data from the outside world
and say that they're going to be
considered public then we're going to
say that the requirement for writing
data to the outside world is it that
those values are also provably public
does that seem safe it should be safe to
take a value you got from the outside
world and write it back out but that
doesn't let you do anything interesting
with secrets so to allow that we
introduce a trusted d classifier that's
tied to that application state machine
that means that the implementation can
statically invoke this d classifier and
say here's a request i received
the outside world and a reply that I
would like to send back the D classifier
is going to keep track of what state the
abstracts that the abstract application
is in its going to say is it allowed in
the state upon receiving this request to
send this reply if it is then it's going
to advance the state of the abstract
application and provide a Declassified
output that the implementation can then
say segment into packets and compute
check sums over without having to put
all those details into our spec
ultimately this means that we can have a
nice clean simple specification and yet
still prove that the system's output is
indistinguishable from what you would
see if you're talking to the abstract
application so I don't have time to go
into all the details of our results but
the high-level message is that we wrote
down our specification for the hardware
and software and about 1800 lines of
daphnia code respectively for the
software in the hardware the
implementation the actual executable
code is about seven thousand lines of
code and that compiles to about forty
one thousand lines of verifiable
assembly code yes so so this is just
showing executable code so it's it's not
counting any of the pre and post
conditions or any of the hensel we have
to add I'll get to that in just a moment
so at the assembly level this means that
we have a ratio of about twenty three
two one so we're we have an
implementation that is substantially
more complex more detailed than these
specifications or we're gaining
something at that level from
verification in terms of the proof
effort there's a couple ways you can
measure it one is the ratio of how many
additional hints how many preconditions
post conditions and variance assertions
that you have to add and here the ratio
was about four point eight to one so
that's higher than I would like but
still not terrible considering that
oftentimes you'll write maybe two or
three lines of test code for every line
of implementation code in a production
system it also compares favorably to
previous work where the ratio was closer
to thirty to one there's also translated
into the amount of time we spent where
we spent almost an order of magnitude
less time in terms of person effort
developing all this proof from verified
code and finally in terms of performance
this wasn't a main focus of our work but
the high-level message is that we in
many cases got within the right ballpark
and in some cases like with our Shah
code we're within thirty percent of
openssl zor the state-of-the-art
unverified and software and
fundamentally there's no reason that our
verified software should be any slower
than our unverified software because
we're not adding in
a dynamic checks everything's happening
statically the only barrier to
performance is how much effort you're
willing to put in to proving that you're
optimizations are in fact correct so
there's also a qualitative aspect to it
which is does verification actually
produce something useful and so if we
look back to our original diagram here
we actually worked on this over the
course about six months across four or
five developers and didn't run it until
about 24 hours before the SOS p deadline
and i cannot recommend strike
structuring your life this way it's very
stressful but we were very lucky and
that almost all this code worked the
very first time we ran it and that's
what unable to actually submit the paper
and I don't know about you maybe you
write better code than I do but that's
never been my experience with any other
code project little own for something
that's doing complicated cryptographic
algorithms or low-level operating system
code you may notice that there's one box
it wasn't checked off which is the
network driver that's because from a
security standpoint there's a very weak
specification for the network driver it
just should not leak application secrets
so we didn't bother to specify things
like how to correctly initialize the
network card and in fact in our original
implementation we did not do that so we
had a system it was very secure we
weren't sending any network packets but
it wasn't very useful and so we did sort
of traditional debugging until we had a
system that could actually send Network
packets and was provably secure so
that's ironclad apps in a nutshell like
to briefly talk about how we expanded
that to cover distributed systems and
here I'm thinking about the large-scale
distribute systems that big companies
like Microsoft Amazon and Google run
where they hire very bright PhD people
pay them lots of money and yet still
have these rather embarrassing headline
outages and why is this is because these
are very complicated systems that are
very hard for humans to reason about
with iron fleet in contrast we developed
a methodology where can actually develop
provably correct implementations so
implementations not just provably
correct distributed protocols and prove
that they are safe mean it will not
output anything incorrect and live me
they will eventually make good progress
so you'll never get stuck in live lock
or deadlock and to our knowledge this is
the first work that actually proved
liveness properties about a non-trivial
protocol little own and implementation
at least from a mechanically verified
standpoint so to give you a flavor of
what we built we had a system called
iron RSL which is a replicated state
library that runs a paxos algorithm
around a cluster of nodes and proves it
even though we have the system running
on multiple different nodes to the
outside world it looks like it's running
on a single
and we can preserve that illusion even
when one of those machines happens to go
down part of what makes iron a cell
interesting is that includes lots of the
complicated features you often find in
real world protocols and implementations
but that often left out of models that
are have been verified in the past so we
include things like state transfer log
truncation things that you need for good
performance or run on a realistic system
we also built a charted key value store
we call iron Cavey this uses
distribution not for redundancy or
reliability but for good performance so
an administrator can take popular keys
and put them on dedicated machines yet
we guarantee that the entire collection
still maintains the outward illusion of
a single unified hashmap moving forward
we're working on the the Everest
expedition which you may have heard me
discuss a little bit yesterday at the
Hot Topic session here we're looking at
the https ecosystem which is critical
infrastructure underlies the security of
the internet and yet it's a very
complicated infrastructure includes lots
of different sub protocols as well as
cryptographic algorithms and as a result
of all that complexity is very hard to
get right we've seen years and years of
attacks on the entire ecosystem ranging
from low-level buffer overflows to
high-level design flaws and we've seen
this at all the different
implementations so this is a case where
we actually have inversion programming
going on in practice and it's still not
working so with Everest we're hoping to
eliminate this by developing fully
verified replacements for all these
pieces and verifying that the
composition thereof is itself secure we
also have a vision that this verify code
is actually gonna be deployable and
usable by people in the real world which
means that it should be a easy one line
switch to go from whatever unverified
code you're running today to running our
new verified software and we want to do
that for large swath of the ecosystem so
popular clients as and servers out there
and finally we want to work on making
our tools even more usable and more
trustworthy so we're looking at
certification in particular so that we
can have a small trusted computing base
is of course raises lots of interesting
open research questions about how do we
decide that multiple protocols that are
being used in conjunction are secure or
how do you upgrade to a new version
securely without undermining old or new
security how do you handle advanced
threats like side channels and how do we
decide should we trust verification
tools or teach others how to use them we
have a large and growing team so it's
not just ironclad anymore it's also
working with me TLS folks as well some
new members of the team spanning both
microsoft research as well as academic
partner
and there's lots of open verification
challenges in general that we hoping to
attack along the way things like how to
maintain staple proofs as you're
developing across many developers had a
reason more efficiently about mutable
state concurrent programs like Nikolai
alluded to or probabilistic reasoning
for crypto proofs overall I think I
hopefully communicated the ironclad apps
is this system that allows us to provide
strong into end security guarantees all
the way down to the level of assembly
iron fleet is able to extend that to
distribute systems improve both safety
and reliability and with everest we're
hoping to demonstrate that we can use
verification on real world software
they'll actually be deployed and provide
strong security for the broader internet
community and a high level I just like
to echo to the general theme of this
session which is that verification of
complex systems code is becoming more
and more feasible and we're working to
make it grow to larger and larger
systems so all of our code is available
on github and with that thank you are
there any questions you have any hints
on how to write secure security specs so
then we used a couple of techniques one
was to focus pretty heavily on trying to
keep them as small as simple as possible
just do less code means less bugs
hopefully the other part was that we
actually employed formal spec reviews so
we'd have one person independently write
the specification somebody else come
along and review and make sure that it
said what we wanted it to and that
process actually caught several bugs
along the way and also motivated the
person writing respect to try and keep
it simple so the person reviewing it
would actually have a possible chance of
understanding it I think the other thing
you can do is once you have a
specification you know the
implementation matches that spec you can
then write additional lemmas about the
specification just check whether it has
the properties are you expect it to have
so I think those are two steps in the
right direction I'm not I think as we
move forward there'll be more more work
to be done in that space any other
questions
so obviously in theory the finite state
limitation of the abstract model when
you're doing the state-based stuff is
the limitation I is it also a limitation
in practice I could certainly imagine
specifications where I want to say I
return the same number of packets I was
given and that sort of thing which is
clearly not finite state oh so this is
finite state in the sense that we have a
potentially infinite number of states
with infinite alphabet zoo possible
transitions so this is definitely turn
complete so I know that in the in the
background you use XIII right definite
reason alone so I'm curious how often
did you hit incompleteness of XIII where
you had to provide kind of additional
hints for the proof to go through and
things like that like quantifier
Association stuff and so on good
question and frequently and then you
would provide patterns for quantum or
association was that the common fix or
yeah well so we certainly learned
there's a big difference between
automated and automatic this is not
automatic it was automated a lot of it
was around triggers for quantifiers and
as over the course of the project
definitely got better about choosing
quantifiers and about exposing
information to allow us to to understand
what was going on with the qualifiers
the other place where we ran into
trouble was with nonlinear arithmetic
that was another obviously heavily
incomplete area and there we actually
wind up turning off a lot of automation
and doing more more manual work there
thank you here ok let's go ahead and
think Brian again
alright and our last talk is going to be
by Zach cat luck and she won and leaves
are going to tell us about distributed
system right no no no no no yeah we'll
talk about about some other things so
yeah so thank you everyone for staying
to the last talk on the second day she
and I are super stoked to be here and we
sort of wanted to take a big perspective
on verification and progress which it
turns out our other speakers of session
have done as well but back in the 60s
right Dykstra made this comment that
whenever exhaustive testing is
impossible we can really only trust
proof and a few years later developed an
approach with this paper which said
you're living in a dream that's never
going to work and so you know he's been
roughly four decades since this debate
started and it's been raging the whole
time and if you've been paying attention
today and like watching the talks here
it looks like you're sort of living in
this wonderland right there's a huge
number of large complex formally
verified systems across a diverse array
of domains operating systems compilers
you know networks models all kinds of
stuff and there's a huge ecosystem of
verification tools to support this and
they're getting better every single day
so should we just declare victory like
is that it you know does does Dykstra
win is it over well maybe not so fast
right if we actually go look at a lot of
the systems that are used to motivate
research right when we give the sky is
falling slide in our talks we don't
necessarily always see verification
being applied in these systems and
there's a couple of big reasons why it
remains challenging to apply existing
verification techniques to existing
systems and also there's a real sort of
limit eight there's a real lack of
expertise out in the field of
verification so today I wanted to talk
about some stuff we've been doing at
u-dub to try to push forward on both
these fronts we have a ton of different
verification projects going on but we're
just going to focus on one involving
radiotherapy we have a bunch of classes
that also involve verification we're
going to give some insights from class
that Brian Chien I just taught last
quarter so to start off with we're going
to go into some details about the
radiotherapy system but first kind of to
take a big picture if we look at all
love these results these sort of you
know big landmark successes and
verification they're providing really
strong really formal guarantees but
typically it's for a single major
component of a system right or one
service that AB larger system I rely on
if we look at the the sorts of systems
where we often really want these
guarantees because lives are on the line
we really care about into end guarantees
we don't care about a single component
being right with absolute certainty we
care about the system working you know
from the sensors to the actuators right
from physical to physical properties and
in practice people who build these
things what they use to to try to build
confidence that those properties hold
are called safety cases now if you're
like me and you had not previously heard
about a safety case essentially these
are large natural language documents
that construct an informal argument for
weather system should be reliable and in
principle they always go from sort of
some physical property or action to
another physical property or action and
what's nice about this format is you can
integrate all sorts of different kinds
of evidence right now everything has to
be a proof not everything has to be
model check some things are testing some
things are expert review and because
it's a natural language you can sort of
tie together all these different diverse
sources of evidence into some sort of
overall argument for the reliability of
the system as a whole of course you know
it's not a panacea these things are a
natural language and they tend to get
really really big and that means that
they're hard to develop it's hard to
make sure that what you've developed
it's correct that this large national
news document actually presents a
coherent argument it's also difficult to
change because as you continue to evolve
and extend and improve your system the
safety case needs to sort of stay in
line with what the actual implementation
does and unlike in the formal
verification space there is no ecosystem
to support the development of these
safety cases so what we've been looking
at doing is trying to make safety cases
more formal and still preserve a lot of
that flexibility that makes them great
that ability to integrate all sorts of
different kinds of evidence so a
particular i just wanted to really
briefly talk about our main test case as
we're developing these tools which is
the clinical neutron therapy system at
the university of washington so this is
a radio therapy device which is used for
treating cancer radiotherapy isn't come
tonight musical stress relief or
anything and it's one of only two or
three in the world that uses neutrons to
treat salivary gland cancers primarily
it's a large complex system involving
several different hardware and software
components that are all linked together
over an Ethernet network and across all
these thousand lines of code in
different systems we want to ensure that
the radiation beam will always turn off
if anything goes wrong right so the beam
will not turn on if the settings are out
of the prescribed tolerances if
something happens during treatment and
settings go out of the prescribed
tolerances the vm will turn off so the
engineers in this group had previously
developed a safety case and at a high
level look at sort of one piece of it
for the gantry rotation so the gantries
were that's the business end of the
accelerator right it's where the beam
comes out and there's the patient and it
can rotate 360 degrees around the
patient and so they want to make sure
that that gantry is set to the right
angle so when it enters the patient it's
not destroying some tissue that that
wasn't intended to be destroyed and so
you start off with some sort of
high-level property that you want to
hold it is part of prescription safety
and you break it down into simpler
properties you sort of continue this
process again in natural language and
how you get down to some basic claims
about the actual implementation of the
system right so from these sort of
atomic claims about you know this part
of the system always has this property
does this you build up Richard Neutra
arguments until you get that high level
property you want now as we mentioned
earlier this is great because it can
help increase your confidence but
there's no way to check this document to
make sure that the argument is sound and
there's no way to make sure that the
basic claims that are made about the
components actually hold on the
implementations so what we've done is
about this technique where we decompose
this into sort of two big pieces one is
we have a model of this system that we
can apply automated checking techniques
to and then into that we can plug in
tools that collect evidence about the
sort of atomic properties we need from
the implementation in order to know the
system is safe and this has several
benefits so our models are specified in
alloy which means we can automatically
check them the alloy model comprises
both specification of the state space
the system can be in as well as the
argument for the overall safety of the
system and it's based on these sort of
atomic predicates but all of the
is are guarded by these evidence
relations that have to be satisfied by
checkers right and so in this way we can
sort of plug in all sorts of different
kinds of evidence and by applying the
technique we actually were able to
uncover a few issues in the radiotherapy
device that's been used for about 30
years now at the University of
Washington there's sort of three
different classes of these in particular
on to talk about a bug we found in the
gantry rotation angle handling that
could have potentially been fatal I
should mention it I don't know if I'm
required to no one's ever died in the
u-dub radiotherapy CNTs device so you
shouldn't be scared these engineers are
super good but we are running our
checker for the control software that
controls the gantry angle it reported
this counter example which we thought
was really weird so that's basically
saying that the prescribed angle that
the gander should be at for the beam
shin heard the patient is 315 degrees
but in actuality it would be 45 and then
Bing would be on and so we started
looking at the code and it turns out
that the gantry can actually turn more
than 360 degrees and so they can put
more patients through the near they can
provide therapy two more patients they
want to be able to treat angles that are
the same modulo 360 as the same angle
and it turned out that in order to
compute this in the you know systems
control language they're using and CNTs
is called epics it's actually a sort of
non-trivial computation because there's
no mod so we're trying to do all these
weird tricks to get it and instead of
you know correctly computing that you
were the same mod 360 angles were
considered the same if they were sort of
mirrored / the / 0 degrees so this is a
bug we found and fixed and you know more
broadly what we're trying to do is this
is you know sort of one first project
for this kind of system we're looking at
other systems that use epics for control
in particle acceleration and radio
astronomy and their it's really
important because there's billions of
dollars of scientific equipment that's
controlled by these systems we want to
make sure it's reliable too so it's sort
of one side of Indian you know physical
to physical things the other side of
trying to prove verification is making
sure you have more boots on the ground
of people who are verification experts
and for that
I'll turn it over to my mostly esteemed
colleague I'll take this one frontier
I'll talk about class we taught that you
definitely are lost Carter so this is a
grad class we created on system
education because we want to create a
bigger army of people doing verification
we love building systems with no tools
we have tried we have dumb papers in
cocking Daphne smt so it should one to
me no breathing ever ever tease to do
more of their stuff so this is we ease
of Brian and Zach and I we cooked our
discuss and why don't you talk about a
bunch of reflection on the feedback from
the students after the pub discuss so
mostly on the two chains they choose and
the end to end the correct need some
concerns the students have and serve
something they would like to see like
automated or automatic proofs so this
cleaner this only done this once we had
17 students plus three of us so it's a
very small sample the results shouldn't
be generalized the cost structure is
very simple so in the first three weeks
we did a crash course on three types of
tools smt basically a three hour so some
of the students nerd rosette also 20
based on day 3 and also we did one week
daphne and one week on so all the
students who took this class also had
taken a grad p 0 class in coffee for
either at UW or before the a cami so
that's a background of the students and
in the rest of the civics we did big
paper discussions on the following in
the classic papers as a way you know
three of us lead our discussion on to
the students let the rest and also have
one guest lecture from garnet then the
students basically returning a class
project basically most students
continually on their own and research
projects some critics start a new
research so I'll talk two of them in the
end
and here's some background of the
students so you can see we have a 17
turtle many of them are from the pl
background we have five from system
networking background to from security
and we have one from marcia knurling
what two undergrads and webmasters so
that's the other students we have so we
have in total of eleven class projects
and so we basically look at what kind of
tools they choose in the end so you know
top one choice is then next is SMP
that includes three active use a three
or tools based on day three and then one
used koa and other three do surveys so
they didn't really write code so that's
the last part so we also let's take a
look here for look at like how people
are doing based on their background like
what would they would choose so it's an
interesting pattern you can see here
based on the results show you know for
like PL students they are more likely to
choose and then smt for system
students mostly scared away and choose
this MTN PLA and for secure students are
scared by all of them for some reason
and the other for actually undergrad and
masters and machinery stones are very
you can see like they enjoy taking out
challenges and use so to sum up so
nine programming language students and
also the other undergrads and masters
and mercenary students chose and
they are all sitting in the post lab and
soon other in the people from other
girls didn't choose and the
advantage here is one we have new house
we have a grad class in pio in
which zach has been teaching for a few
years we have very good books like Adams
Palace book and the Benjamin Pierce book
using and also there's a good
community support instead of UW outside
eww so that's why most people like the
students said and the second one is you
know also have bunch me for using the
three and smt and rosette
and it's one peer student 3 system
networking students and the reason they
gave is because also there's another
appeal students taught by amina turlock
and also they love automation and some
are doing program synthesis so that's
pretty much you can do if you have to do
some sales / we also send out this
question of a later on why you don't
like because we were surprised like not
many people choose Daphne we were
expecting know sometime would at that
point and so why not use Easter bail
because it's also very public tool that
many people use for research when I you
sling also quite like there's a user
group in UW are quite a few people there
are interesting leaning and have to try
that so the bunch of results again it's
unclean incomplete so don't generalize
the results but one top one reason is
mostly because most servers we have more
expertise in kaka SMP in UW and Brian's
not joining us so secondly is also some
people take out there and continue on
their research projects so they are the
Incan city so that's why they can change
and another reason is certainly the
complexity of the tools like for example
definitely requires you to understand
also like boogie and the three and also
how to tune triggers I don't know what
happened I was class so that's one
reason some student gave and the last
one sort of lino the complexity of
setting up all the tools and platform
dependencies but anyway in the end you
can see the majority are the conclusion
not very general conclusion from here is
it's mostly social factors not really
like a technical side from the paper the
discussion so we ask you about some
students about the feedback on the
papers which shows and there's a bunch
of interesting questions they had why is
what's the like we say are we all love
verification but what is the empirical
evidence that those systems are better
and towards the end we have more
security papers and some students have
some doubt on okay it's secure there are
some nice theorems you've made of some
shins
they really secure but it's unclear from
that point and also some students many
comments like okay security is more like
a spectrum it's not like a binary valued
secure a non-secure so how does
verification fit into that big picture
so that's one side another side is more
about amazing so pretty much every paper
in nowadays we say we have a lot of
proof automation but also if you look at
the lines of proof compare two lines of
code it's do a huge proof burden and how
to improve on that so in the rest of the
talk I will just quickly describe two
ongoing projects also as the class
projects and the current training
results so the first one is okay let's
just do it in perko study and see if
verify systems are better and the one
notable example was in from compiler
testing a literature on this nice paper
from Utah they build this to assist me
then compared with concert and llvm GCC
and showed actually verify the compilers
better in terms of correctness so we
took on issue systems and they are known
to be very hard to build correctly and
in the recent a few years we have made
tremendous progress on building complex
systems so we have artfully that we have
Verde you have choppa those are like
replicated key value stores or Charlotte
cubic stores so basically in students
they wrote fuzzing testing tools in
themselves they did extensive code
reviews the Union try to inject bugs
into the code and see if verification
steel goes through and hopefully not and
so and also other side is you should
choose some control groups which are on
verified systems and you want to say oh
if like those are basis for popular
consistent production system people use
which are unverified but you want to see
if those bugs which can be prevented by
our current practice of verification and
of course this also you know not very
general
it's limited it's biased and that's the
current results we have so far the first
question want to answer is our value
systems better and the answer is yes so
we haven't found any bugs in the
verified parts if the specs are correct
and also giving a concrete example so
there's no protocol bugs we found in the
audio systems and it's not because of
lack of trying so they're all actually
just just proved and correct and the
other result which is also interesting
on the neck societies so what can go
wrong because in the verifier systems
still complex systems have a lot of
different parts and human beings
involved so what are those results where
can go wrong so actually they've
students have found 16 bugs in different
part of the system verification tools
the specs and even the implementation
that are not covered by specs and they
have reported all those bugs to
developers and for a fixed right now so
one example can tell you is for example
in disputing infrastructure for
verification they show the building
scrub script would invoke Daphne and
parse the result out and there's a bug
in the mix script so we will print the
verified no matter what Daphne says like
even if it's broken or its own verified
you can imagine this kind of last mile
bug right it's very unfortunate but also
because human beings are evolved and we
haven't verified that and a second
example is this is a bug in the oh come
on round time in the Martian library and
often happens you verify in cargo
extractor code into a comma and of
course you know that part is assumed to
be correct and in that part unfortunatly
you can have corrupted UDP packets
sending out so that would invalidate oil
proofs the last question we don't really
have a good answer for it's like
actually now our replication prevent
bugs in production systems through the
colonel sir we will say yes and no the
yes side is
article bugs are prevented so we look at
the past why year or the year bugs so
they should be able to be prevented by
our current to save practice in
verification the three projects knows
that is most of those systems so far we
haven't touched like say machinery
configuration crash recovery those parts
of something could be interesting a
future directions a second part of this
project is so what if we take extreme
stand on verification what if we just
don't want to write crew so we want to
make sure everything is automatic or
automatic but we change our system to to
make sure that education would go
through what kind of system abstractions
we can build so we take one specific
area which is a file system we try not
read proofs should basically make magic
well these people with the right spec
with writing impatient no proof you have
to provide some environments on the disk
so in the environment would be on the
on-disk layout so it has nothing to do
with the code so there's no environments
or annotations on the code but only on
the on-disk layout of this file system
and also the good thing is also it can
provide we want to sort of counter
examples if you have in your tricky bugs
you want to understand what can go wrong
or how can you what kind of things can
lead to that bugs so the hollywood idea
is to take advantage of fully automated
smt reasoning that sort of a very good
tool we have right now for automatic
reasoning that now the problem so the
highlight here you can think about this
is you can apply symbolic model checking
two systems but the challenges are why
is how do you terminate how to actually
finish exhaust the search space and one
way to do it is to achieve scalability
by very careful design the system you
know with that you're earning twice
about excusing over two layers instead
of the entire stack of layers and the
last one is you should have to have
loops so you have the careful design
system you wait I don't have loops so
for example you want to find a free bit
for a block and the idea is you can
verify the loop or you don't you just
check
just validate so invoke unverified
allocator and just check the result and
save actually is a very bit so in that
case you don't have to verify it the
trade-off of course is there's no
guarantee if there is enough space then
it's possible that this alligator
wouldn't return to you but in any way
it's still like a safe approximation the
current results you have is a journey
fastest Makawa xv6 is similar to the
design of physics and f CQ impacted
scribe we wrote it in Python and you
invoked a three four-hour verification
for runtime we just actually compiled to
see for better performance so the
current correctness guarantee you can
imagine here is one is written in Python
so it shouldn't have low level a buffer
overflows or those bugs and because we
actually tried we exhausted or every
single arm code path so there should
cover all the code a possible case and
it has functional correctness so if the
spec imitation shouldn't meet the spec
and also even if there's crash we
actually prove that it's either one of
the imitation will result in one of the
cases covered by the spec so that means
I'll crash safety so this should idea we
are exploring like this try to know the
idea because we push a button and you
get a verification results seem to work
for this one particular case we don't
know how general it can be but for this
particular case we have some spec the
live code is 3000 which is roughly the
same as SE implementation of the X
basics file system and the proof perdon
basically is 5 environments on the
on-disk layouts so I believe that's an
easy way for programmers to do and to
change so basically the students the new
chain implement new organizations and
just rerun day 3 and it's done so
there's not much you need to do for
verification and it basically soup the
students a three-month then to have a
pretty mature file system that is able
to self host its own development
the git repo is on the file system
itself for several month so that's
pretty much we have today so that tells
you about the radiation therapy machine
we have seen how to apply reputation
into other domains and also see how we
can train next generations for doing
more education work Thanks any questions
for Zach and she or more broadly does
anybody have any questions for any of
our speakers
okay thank you a very nice for giving
them big fan of verification but one
question that the motivation seems to be
more like the sky is falling type of
motivation for affiliation and if we
think of Bill Gates morning this is you
know programming I've been the same
anything is here in sometimes we are
going backward because not only on top
of the code we are asking for the proof
so what should be the right way forward
and is our way of putting verification
not like you know the next step in
programming and how things should be
done rather than something that you do
because you have your back against the
wall so oh I wonder you could take like
very extreme is that verification is a
janitorial task that you do it when
there's no more research to be done in
the space and file systems almost fall
in a space like it's been around for 50
years we figured out what a file system
should give us now it's time to finally
verify this thing and we'll be done so
that's one view the other thing is that
for bigger applications they are
evolving so fast that it's not clear
they have a spec that can be stable that
you can prove against my favorite
thought exercises facebook which has no
notion of a spec and tomorrow it'll be
different even if you do manage to come
up with it so I'm not sure the
verification has a place in every layer
of our software stack and certainly
right now I think the only target is
very low level widely used
infrastructure with very stable specs
that don't change our time is it just a
bit a slightly more optimistic note oh I
think I think as systems grow complex so
as you start trying to build these giant
distributed systems and essentially a
warehouse that's acting as a computer
people are trying to realize that
existing techniques don't work for that
and exhaustive testing doesn't work so
they are looking for other tools both
for correctness and for agility it's
very hard to make changes once you have
this big system set up and you have a
reasonably stable you don't want to
touch it because you want to be the last
guy that changed the code right before
everything breaks so I think to the
extent the verification can start giving
you more flexibility let you experiment
or innovate faster then we might see it
being used more yeah just to touch on
that I mean I think that there are
increasingly many examples where
we can't write the code without
verification it's like the windows 8 USB
stack right was written using support
from P and it was code that humans could
not right they tried they were just too
scared they could never get it right but
with support they were able to get it
right so I think that's like the most
you know I think in my heart right now I
sort of agree with Nikolai but like the
the party line is that there are
programs that that right now we would
like to write but we can't because we're
just not smart enough and you know the
increasingly verification is going to
enable us to write those programs I
think the other thing is that there's
places where we're not programming and
we should be so like the safety case
like making those basically expressing
those programs like we're that is you
know a new application of it where it's
not being used so I do think that things
are changing but I totally agree with
Nicola that it's not going to be for
every programmer for every program every
time I want to know my one way to think
about it could be like considered as the
economy issues if the cost of testing
over ways the cost of reification why
not like so you want to send something
to Mars you don't want to test it okay
my understanding is that there's some
sort of party going on in the McKinley
room now so I think this would be a good
discussion to continue over beer let's
thank the speaker is one more time</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>