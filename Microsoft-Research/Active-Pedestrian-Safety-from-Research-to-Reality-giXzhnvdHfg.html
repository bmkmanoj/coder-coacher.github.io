<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Active Pedestrian Safety: from Research to Reality | Coder Coacher - Coaching Coders</title><meta content="Active Pedestrian Safety: from Research to Reality - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Active Pedestrian Safety: from Research to Reality</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/giXzhnvdHfg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
the last time I gave a talk at Microsoft
Research was in Seattle it was during
the final stages of my PhD so I consider
this somewhat of a comeback 15 years
later and this time in Cambridge and I'd
like to cover some of the work I did at
Daimler R&amp;amp;D on the topic of active
pedestrian safety it's a very worthwhile
theme a theme that has seen considerable
progress over the time period and I'd
like to go over the factors that have
contributed to this success and also
touch upon some of the ongoing research
issues okay so when people originally
thought about machine intelligence it
probably had a picture like this in mind
so here's Robbie the robot a rather
clunky creature that would help us with
all kinds of tedious kors in the
household like fetching the phone
washing the dishes or cleaning up now
that thinking gradually evolved from
Robbie to something which is more
human-like both in terms of appearance
and also in terms of behavior so we
arrived to a picture like this we still
have machine intelligence embodied as a
butler for humankind but this Butler has
some personality and it's conscious and
so forth although some people had a more
menacing view of how future machine
intelligence would look like but why
wait for the future because the first
large-scale deployment of machine
intelligence is already with us and it
comes into an embodiment that you are
very familiar with it's our modern car
modern cars have sensors to survey the
surroundings the interior of the car
they perform reasoning based on the data
extracted from sensors based on store
data and they act to make driving safer
and more convenient so perception
reasoning in action these are the
classical elements of an embedded AR
system and this is what a modern car
nowadays provides now you see here a
picture of the flagship mercedes-benz
model the s-class which was the latest
version was introduced a few months ago
and one of the things that we are very
excited about is the new sensor on board
here just below the windshield and it's
a stereo camera it's the first car sold
worldwide that has a stereo camera on
board and the stereo camera opens rich
range of new functions that we can do
and we believe it will transform or
should I say here connecta size the
field the intelligent vehicles field in
our case and it's not the only sensor on
board we have actually a very large set
of sensors and I brought this slide
because I wanted to give you an
impression of how many sensors now are
in a modern car the top line s class but
also in the e-class of this year so we
have the ultrasonic sensors which are
here and here and there are meant for
low-speed maneuvering for parking for
backing out that typical have a range up
to one meter but there are one ones
which have which are here laterally
which go up to four and half meters
because they are measuring the free
parking space for the automated parking
then we have a whole set of radars so
with the long-range radar up to 200
meters in front mid range radar up to 60
meters and the short-range radar with
goes up to 35 meters
mately and their various viewing angles
and they're also radars to the back okay
to do detective somebody's nearing
really fast it detects overtaking cars
and it detects if one is cutting in on a
car over here so the brownish areas are
the radars and then we have video we
have two cameras for night view we have
a near infrared camera and a far
infrared camera working together and
they have an opening angle of 20 degrees
up 260 meter range we have the stereo
camera which I mentioned which is 45
degrees opening angle and we also have
four different cameras which are located
over here and here and here so they
cover basically 360 degrees around the
car it's it's it's also meant for
low-speed maneuvering for visibility for
the driver so this is really a very kind
of extensive coverage I think and with
this we can do a lot of nice functions
and an overview of what's available is
here some of these functions are new and
some of these are upgrades of previous
versions now I won't go into all of them
because then I'm running out of time I
do want to share with you some of my
personal favorites and one really cool
new feature in the new s-class is active
body control with preview so the s-class
is the only car that can sense bumps
ahead of time on the road using stereo
camera and it has the ability to vary
the suspension of the wheels
individually in this car so that means
it can compute best strategy
for oncoming bumps so that's active body
control with preview then adaptive
cruise control with steering assist well
adaptive cruise control is an old hat it
is based on radar and it allows you to
set up desired speed and if a slower
vehicle comes in front it will slow you
down so it keeps a safe distance to the
preceding legal that's adaptive cruise
control but now with the stereo camera
we're able to quite precisely detect all
the vehicles in front and we're also
detecting the lanes that means that this
function will also do the steering for
you automatically right and its really
autonomous driving on the highways what
is does but due to legal requirements
autonomous driving is not yet legally
established this system checks every 10
seconds if your hand is on the wheel
right but other than that it really
drives by itself it's a really cool
feature it's not research it's not
science fiction it's not Arnold it's
right here you can just buy it ok it's
really cool and well then there are a
couple of assistants functions for
safety which are important for pre-crash
breaking the thing is that typical
drivers do not break strongly enough in
emergency situations because they are
not familiar with the situation so the
system if it sends is an impending
collision and it sends is that the
driver is tipping the pedals it will
boost the brake pressure to full
emergency braking right away that's what
the pre-crash braking is and we used to
have that for longitudinal traffic and
now in the new ens class we have it for
lateral traffic so that's really nice
but what's missing right obviously just
imagine that you're driving in in London
or Cambridge and we are driving your
kind of entering into the navigation
unit your destination or your kind of
the kids in the back of making a fuss so
you're kind of looking back when
suddenly a child appears in front of
your car okay and this is a very
critical situation when drivers are not
paying attention or maybe when
visibility conditions are poor and so
the plight of the vulnerable road users
that's the official term meaning
bicyclists and pedestrians it's very
clear if you look at such emotional
picture like this but it's not just
emotions it's also the hard fact if you
take a look at the accident statistics
you can see that for example in Europe a
quarter of all traffic fatalities
involve pedestrians and bicyclists so
dark blue are killed pedestrians and
medium blue killed bicyclist and you can
see here a quarter of them involve
pedestrians and bicyclists in some other
regions like the u.s. okay it's much
smaller portion I take it that nobody is
walking in the u.s. I mean most people
take the car so I think that's the
reason why this proportion is less but
taking a look at some asian countries
you can see here that this proportion is
in fact in excess of forty percent so
it's quite significant and if you want
to know where the big numbers are coming
from of course you have to look at
countries like China and India and so
that's where the numbers are coming from
the big numbers so the numbers of
traffic fatalities of course have
propelled a lot of initiatives also from
the legislation point of view and the EU
has been very active in this domain and
apart from the legislation efforts
consumer rating agencies will quite some
influence because they can award or
withheld a car's maximum rating
the number of stars based on whether
they pass certain tests like pedestrian
safety tests and up to now the tests
only involved passive safety meaning
what happens during the collision and
after what's the maximum impact of the
head of the leg on the motor hood but
starting in 2015 euro end cap will also
consider active pedestrian safety
meaning what happens before a crash
using sensors and so this is what we
have been working on we have been
working on devising sensor systems that
detect dangerous situations with
pedestrians ahead of time in order to
either what warn the driver or to apply
some vehicle control emergency measures
and the primary sensor that we're using
is evidently video because we have a
large resolution in depth we use stereo
so we have quite good resolution as well
and that's important resolution because
we can then distinguish objects and we
can discriminate them from the
background and the topic is very tough
it's very challenging because evidently
the pedestrians have a quite large
variation in appearance due to the pose
due to the clothes and various
viewpoints and also the backgrounds are
logically a dynamic and an ever-changing
and cluttered and pedestrians can change
their direction at the whim so it makes
it hard for prediction and two for
collision risk estimation and well we
need real time processing and we have
quite high performance requirements
especially for those applications that
start doing emergency braking so
meanwhile the field is quite active with
a lot of universities and vehicle
suppliers and vehicle manufacturers and
I think you can distinguish three main
nah Rios for the pedestrian application
first you have the scenario at the far
range and this is typically on secondary
roads in bad visibility conditions or
bad unlit roads rather you have the
scenario at the medium range this is the
classical pre-crash scenario and this is
typically in urban environment because
that's where the most pedestrians are
and you have a scenario here at the low
speeds and it's about parking and it's
about backing out and it's about
informing the driver of what's happening
around the car and you can imagine that
these three scenarios have quite
different requirements in terms of the
sensor coverage in terms of the vehicle
speed range in terms of the performance
that are necessary for for those
scenarios so certainly an application
which just does information or warning
is somewhat more forgiving than one
which will deal emergency braking right
here I'm going to focus on this part
although the techniques that we use for
pedestrian sensing apply nearly one to
one to the other scenarios okay and this
is my favorite slide for Daimler
management in the past decade because it
shows the progress that we have obtained
measured on the same large data set and
so we started the first large scale
tests were in 2003 in the city of Aachen
in Germany and so there so first of all
I should mention that we're dealing here
with the correct recognized pedestrian
let's say the detection rate versus the
number of false recognized pedestrian
trajectories per hour so when we did
this first time in 2003 the cars behind
were honking
because we were just driving 30 km/h in
the city and we had a terrible
performance okay really really terrible
because we were only detecting forty
percent of the pedestrians out there
while having an amazing 600 false
trajectories per hour meaning about ten
per minute so this system was actually
hallucinating pedestrians all over the
place and while managing to miss more
than half of the real world so that was
really bad but then again two years
later nobody was honking anymore because
we're there at least we were driving 40
but fortunately we also improved our
performance quite significantly so this
is not linear scale so we had an order
of magnitude less a false positive at
the same time we went up in the
detection rate significantly then again
three years later order of magnitude
again and another twenty percent and the
last iteration we've shown here is yet
another order of magnitude and up to
ninety percent detection rate I should
highlight that this is not the this what
I'm showing here it's not the false
breakings actually in the car because
this would be really terrible but this
is just the output of the vision module
after the vision module there is another
module from radar which will confirm
we'll need to confirm if there are
targets on collision course and also not
not all these false trajectories involve
collision course so you get a
significant filter actually after these
results but this is just the vision
module performance so I think an
interesting question is to ask is you
know what made this progress possible I
think it's kind of a lucrative for the
general progress that has been made in
computer vision on object detection in
the past decade right so to the to our
credit being a division community the
vision community came up with better
algorithms
and looking at the system architecture
what we have is a modular setup where we
start out with a module which does the
region of interest generation and well
this could be based on if you're using
monocular vision this could be based on
motion it could be based on scene
geometry we're using stereo meaning that
we're detecting obstacles and then we
move to the next module which does the
classification for pedestrian yes or no
we integrate the detections over time to
obtain tracks to figure out whether they
are in collision course yes or no at
this point we could also integrate
information coming from the other
sensors we're doing path prediction risk
assessment and then comes warning and
the actual we control now in terms of
the algorithms for the classification
module I believe that the first
milestone was around two thousand five
when papers like vom Jones appeared
adaboost with high wavelets that really
brought us forward and also of course
the law intrigues hog linear support
vector machines so around 2005 who had
pretty good base features and base
classifiers that we could use for this
problem but I think the second milestone
was kind important and that was the
realization that you could get much
better performance if you can combine
various features and combine various
classifiers and so you see here some of
the work that we did two years ago and
here we combining gradient features like
hog with texture features like locally
local binary patterns and we're not just
using intensity images but also then
stereo images and and and dense optical
flow images for classification we're
doing that for various poses of the
pedestrians and we're doing an approach
where we have for each combination of
these items
expert classifiers so the overall
classification result is going to be a
weighted sum of what these experts are
saying and the technical term is of
course mixture of experts and it's quite
amazing it was for me at least to see
that if we're taking again detection
rate versus false positive rate we want
to be here if you take the baseline to
be the hog linear support vector machine
here in red that you can reduce the
false positive rate by a factor 42
against this one and it's not a strawman
comparison because the hog and the
linear support vector machine has been
quite a good contender in many of the
benchmarks so far so fact 242 we'll take
it thank you right now another thing I
want to argue for and to motivate is the
use of dense stereo the benefits that we
have from using den stereo for this
application of course then stereos also
use from any other driver assistance
function but it helps a lot for the
pedestrian application it helps for
generating quite precise regions of
interest of where to search for
pedestrians that's one it also helps for
the classification of pedestrians we
found out that you get a factor of four
improvement if you just adds their den
stereo to the classification module in
addition to intensity and what I want to
show in this clip is how accurate the 3d
map is and how good of a localization
you can get with then stereo and this is
the sgm algorithm which runs real time
and which is integrated in the car so
you see here the detected pedestrians
that's the output of the system that I
draw your attention to this part this is
my former student
Marcus Ann's father and he's a former
because he is forward because he
graduated yeah but so yeah we have a
color-coded depth map but what you will
see is once we kind of fly through three
space how accurate I believe the 3d data
is it's not as good as the velodyne
scanner but it's not that bad either
okay another aspect that brought us
forward was better hardware well that's
not really to our credit but we'll we'll
we'll take it anyway and so we are
profiting of the big gains in processing
speed as as formalized or as simplified
by the Moore's law a very important
issue for the automotive application is
low power consumption so we are very
much interested in embedded hardware
like FPGAs and DSPs which have a much
lower power consumption like than
generic processors you can see here in
FPGA forex eiling's which has an order
of magnitude less power consumption and
it helps that many of our algorithms are
data parallel and so what we're doing is
we're once we have prototype things on a
PC we're moving things to the FPGA DSP
area and you can see here some of the
work we did previously on this area in
2002 we did some work on template
matching shape matching then 2009 we
implemented the sgm algorithm on fpga
and more recently the pedestrian
classification was placed on fpga
important issues of course to have the
right sensor and our suppliers develop
the stereo camera and the right
packaging it has to be automotive grade
it means it has to withstand high
temperatures because it's in the
windshield so if the sun is shining
it can get really hot and also the nice
thing is that the FPGA board is actually
placed right there so the whole unit the
sensor and the processing unit is
together you don't have any cables and
so forth okay we cannot underestimate
the beneficial effect of having more
data and that's kind of obvious I think
in this at this audience early on we did
some experiments with the number of
pedestrians in data set and so we were
just doubling the number of positive
samples in a data set going from 1600 to
12,000 that's very low data but just
kind of to give you the idea and each
time that we're doubling we're doubling
the training set we got better
performance in this case it was even
linear so every time we're doubling the
false positive rate went down and well
now we have much larger data sets so
this kind of linearity does not hold any
more but of course we're spending a lot
of time to device and tools and to deal
with large data and to be able to enrich
this data samia semi-automatically and
meanwhile we have arrived to yeah it
doesn't matter i think it was just this
was just that data set basically it was
not a bird time unit this was just
classification data set but i just
wanted to illustrate the linearity in
the beginning of course it doesn't hold
we're closer to saturation but we're not
there yet meanwhile well we have a
pretty good coverage of all that's where
we were based so I guess that Oh big
portion of the population is in the
training set of timer then we'll expand
it geographically to stuttgart a hand
and so forth and it's of course
important not just to have a
representative data set so we don't want
to have something which maybe
like two European fashion or something
like that so that's why you also if
you're serious about it you also go to
many other cities outside the Europe and
and so forth and as a result we have
about an order of 10 to the 7th images
and in the order of 10 to the 6
pedestrian labels right and we were
thinking wouldn't be nice from how to be
able to generate new pedestrians without
doing all the work and and labeling them
this was especially a request from our
students and let's see yep and so we did
some work on generating to do to devise
a generative model to move to for
pedestrian appearance and this model
contains a free components shape of the
pedestrian the foreground texture and
the texture in the immediate
neighborhood and so we have the image
representation we're going to a
low-dimensional latent representation on
this case it was just bc a Wii Fit
probabilistic model mixture of gaussians
parson windows which we then sample and
then we put these components back
together and we have our virtual
pedestrian and yeah this is a
visualization of varying the components
the eigenvectors individually so this
guy is getting fatter or is getting
slimmer within a second and so that's
the main major modes of variation you
can also take account of the gate here
we're just keeping the we're fixing
everything else and and varying the
texture so you can get the main modes
it's just overall brightness of the coat
of the pedestrian one of my favorites is
this one over here we have separate
generative models for various viewpoints
and in the frontal view point you can
see
cific patterns like the coat shirt
pattern up here so the thing is now we
can take these virtual samples and add
them to the training set of our favorite
discriminative classifier and we use
some notion of active learning we're
only adding those examples for which the
discriminative classifiers has problems
with which are close to the decision
border and then we do the ROC and in
fact it shows that we get about thirty
percent less false positives if we add
these virtual samples okay and the last
point I wanted to highlight was the
evaluation aspect of a pedestrian
detection so meanwhile there are a
couple of benchmarks and evaluation
methods that have been introduced and I
list some of them here we have been also
very active in this field and this has
been important because it has allowed to
quantify performance of the community
and also kind of to direct research and
in some promising directions and so our
first data set that we made available
was in 2006 on pedestrian classification
so these basically are involved image
cutouts more recently we also added
multimodal data meaning stereo dense
stereo and thence flow in addition to
intensity so this was the data set we
used for our mixture of experts study
then we have our data set on on
pedestrian detection meaning that we
have whole sequences and this was a data
set which was in a city of Auckland it's
about half an hour driving you get all
the vigal data the speed the jaw angle
and the nice thing about this is labeled
extremely well every frame is labeled by
hand it's very precise and most
importantly it also contains stereo
images because I believe we should move
away from the monocular
data sets to the stereo data sets
because that's where actually i think
the high-end pedestrian detection is
going and well you can find these data
sets that are publicly available and you
can find them by searching on the web
and so then you can try out your
favorite or you can try out your object
detection classification tracking
approach on the pedestrian application
if you wish now this was the part where
we're driving through city now we would
like to have also some data where which
is a bit more yeah interesting in terms
of the pre-crash range right so the
question is how to perform then this
realistic pre crash tests now of course
we can use a dummy we do that but the
problem with the dummy is that it
doesn't have the right signature the
sensor signature right I mean it could
be look like a human but maybe it
doesn't have the right temperature so we
would have to heat them up for if we
want to use far infrared sensors and
then if we want to use radar sensors
then again you have to put some metal on
it so how to do that how to we would
like to do actually test with real
humans real students right so how can we
do that safely of course any ideas for
those that have not seen my next slide
pardon a trapdoor you can just okay
that's an option and other hi dear okay
I'll just provide the solution rather
than using a dummy pedestrian that real
car we switched the roles we use a real
pedestrian and a dummy car and the dummy
car looks like this one this is actually
was performed where we met last time in
at noon eaten and this this was a new
project and the testing was performed by
a UK company Myra and they built this
test rig and we put all our favorite
sensors on the test rig so we have here
the radar sensors we have stereo camera
for infrared camera over here and the
clue is are the safety cables here and a
redundant fashion and so the thing is
you will see that here is this test rig
is as is moving towards the pedestrian
and at the very last moment with a
deceleration of much higher than you can
get with a real car it's being held back
so let's see there is a volunteer and
there is a let's try that again let's
see if you can play that again
so how does it look like from the center
point of view well it looks quite
intense this is by the way the crane
that was used for the overhead camera to
film and to get ground truth so here we
go and this guy here appears to be
praying this is this is an old video in
terms of the processing so it's not
don't don't worry about this part what
we did is several scenarios easy ones
where there is no occlusion but also a
bit more involved sit ups where there
are parked cars and occlusions but you
can imagine that you get some really
specific data which you can actually get
normally like with a car or you
shouldn't do this ok say where are we
now well we're very pleased that after a
decade of research active pedestrian
safety is now part of the mercedes-benz
en s-class 2013 and now the question is
well actually i'm going to show you
first a video clip which illustrates the
function preset this is a comprehensive
retention system from space fans the
sentimental brake assist us and the
priests hey bro how to prevent it we use
the severity
am i protecting other leaders with
pedestrian recognition the preset break
man takes on a new dimension the stereo
camera and a system of long medium and
short range clear monitor the area in
front of you the informations line and
processed in the control unit to provide
early recognition of road users in the
leg analyzed at the same time these day
lines to calculate whether there is a
risk aversion if such a risk is
identified the citizen can provide a
visual and it honorable wardens the
first if the driver Braves brake assist
first ensures that the optimal brake
pressure is applied even if the pedal is
depressed to murthy in critical
situations if the driver does not take
action autonomous Freddie may take ESS
necessary but a recent break the desk
recognition and conclusions with people
at speeds of over 50 km/h moreover the
severity of an accident in reduced
significantly and at the 72 km/h okay so
the question is what's next and you can
ask you can answer that question quite
or you can ask that question rather
literally and this is some of the work
we're doing more recently we're trying
to find out what what's the pedestrian
going to do in the next second or so so
we're looking at the scenes like this
where a pedestrian is moving towards the
curb side and I'd like to ask you who
thinks that pedestrian is going to cross
ok and who thinks that pedestrian is
going to stop ok this is a minority and
who doesn't care
actually this is just 200 million 230
milliseconds before the actual event is
very late and I see there was still some
confusion going on let's see what the
system is saying in fact I will direct
your attention to this part of the image
well an icon will appear which tells you
what system thinks yes the system things
is going to continue and that's correct
and so let's see I'm just going to stop
it here so I don't have too much time to
go into the details but basically this
is an approach where we have learned a
lot of trajectories of stopping and
walking and we're matching a test
trajectory to this data set for the
similarity we're not just using the
positions of the pedestrians which would
be obvious but also taking into account
the dense optical field meaning because
we want to get some more precise in the
some early indicators of subtle movement
so it's not just the position but
additional motion features okay um and
so right just want to run it maybe after
all here and so we're you're seeing some
of the particles for walking and for
stopping you're seeing the ground truth
location within the future of course we
also do this for moving vehicles because
that's what we're really interested in
it's not that easy actually and we
wanted to know how well does the system
do are we better than humans with the
system or not well unfortunately the
humans are still better so the humans
are paying attention they're watching
videos and they're being asked the same
question that I asked you and so if you
take a look at the performance and this
is the classification accuracy of you
know choosing the right class versus
time and t0 meaning at this point
there's the actual event so either he
stopped or he's crossing the street and
you notice that the scien line of the
humans reaches eighty percent accurate
see about 570 milliseconds before the
event whereas our best systems that we
proposed does so only 230 milliseconds
before the event and the baseline which
is a fancy common filter with multiple
motion models thus so only 90 milli
seconds before so you might think okay
what's the big deal about 200
milliseconds well you can show that it
can really reduce your chances for
hospital stay by fifteen percent and
there's some reasonable assumptions an
important issue is perhaps those who
include some features regarding pose in
this path prediction aspect and that's
why we did some work at this year's be
MVC on pedestrian segmentation where
we're combining data driven segmentation
methods based on CRFs with model
knowledge with global shape models the
statistical shape model inspired by
coots and so we're iterating and you can
see here when you start out with a
initial shape you know then you can get
much more precise by combining this
top-down and bottom-up cues okay so i
also want to show you some work that
we're doing my colleagues are doing at
the actuators maybe i'll ask the answer
the questions at the end i want to show
you some work that the colleagues are
doing on the actuator level so you see
here some video on the test track and
then you'll thing and in stuttgart here
are the light barriers and here comes
hans and hans is fearless always in
front of the car so this is the video on
automatic braking well that's nothing
new anymore right this is part of the
2013 ens class it's not trivial because
you have to break not too early and
especially not
too late so that's kind of tricky to
time it precise but in this work we also
looked at other maneuvers like automatic
evasion and so this maneuver is executed
completely automatically in fact the
system had to choose between evasion and
braking depending whether it could still
break on time or evade and it had only
300 milliseconds to make that decision
all right it's it's very tough and it's
an instance where the system is actually
better than a driver and you will see
here one fragment where the wheel is
actually turning during the maneuver so
you can see how that kind of looks like
right now obviously if you're clenching
your fists on to the wheel you can
overrule the system that's what always
will be the case in the driver
assistance functions the human driver
can overrule the system right so now let
me summarize it has been a great decade
for computer vision as you certainly
will agree and it has been also a great
decade for intelligent vehicles and no
better example than perhaps this
pedestrian application which has seen
very strong progress in which has
culminated now in market introduction my
personal lessons learned from this time
was not to get sidetracked if you
believe in something so because there
are always people that tell you we won't
need this or and the others are telling
you this cannot be done so I think it's
it's important to stick to your beliefs
on the technical side there's still work
to be done on this area we're not done
yet we can improve the sensing
capabilities still further and we should
have
additional focus on a better
understanding of the traffic situation
and collision risk estimation as I
pointed out and certainly new activation
concepts like this maneuver i showed you
will be important on the road towards
fully autonomous driving and towards the
beginning of my presentation i refer to
the accident numbers for pedestrians and
I'm very gratified that my colleagues
that the accident research department
have taken a look at the current system
on the market and they have computed or
they have estimated that this system can
avoid six percent of pedestrian
accidents and reduce the severity of a
further forty-one percent which brings
me to my last slide
using a service stock accounts
stop
the technology may be hard to imagine
why you would want it's not so this
leads me to my final and only formula
here better algorithms market-ready
hardware more data and extensive testing
means more life saved thank you very
much and I also would like to credit the
people who contributed in particular
some of my former and current PhD
students thank you very impressive
specific question the question Breaking
and avoidance does that take down two
vehicles immediately behind the vehicle
itself to some degree it will not make a
decision to break or not based on the
vehicle in the back but it does have the
radar to the back and it will flash the
brake lights strongly denoting the
emergency braking procedure rain rain
yeah it's not that bad he surface stereo
camera facing in head yes so rain at
night is a challenging with if there are
some some it will challenge the stereo
algorithm so yeah it will degrade some
of the performance but during day time
it's not a big problem i would say
service at night specifically yeah so it
will degrade a little bit actually i
should mention that the system is also
operational at night so it's day and
night right there is some degradation
involved but yes it's we're not having
hundred percent performance so that's
the degradation part that's right also
when they are blinded by by other cars
yeah
you may be classified using stereo but
right which is a pedestrian action
trying benchmarking with mobileiron
which uses just monocular right what
sort of performance difference that
we're looking at your system and this is
no but I system well I don't have a
direct benchmark that I could offer you
but we did make this study where we
compared our algorithms or mono and on
stereo which are just which I referenced
you and we saw in terms of the
classification performance only a
benefit of up to factor of four now that
does not include the benefits that you
have for a better region of interest and
a better localization localization is
very important because you really need
to know if you have monocular vision and
you want to do the correspondence with
radar you have to watch out that you're
not having cases like you have a coke
can in the front and and some some some
pedestrian in the back and suddenly you
get some strange configuration so it's
very possible it's you can do some you
can you can solve that problem and
they're doing a good job invision / line
but I think stereo is really the way to
go so I hope it at least partially
answers your question think so man are
we talking about these detective excuse
me in terms of the image size yes I mean
we are we're looking at pedestrians that
are about up down to 30 pixels and go up
to you know as half-human tation but he
didn't quite say why pixel wide
segmentation is imposing right i mean
this was just we're thinking of that as
a front end to post recovery and some
other extraction of some significant
features that would help us for the
prediction aspect
now now that's very recent yeah
absolutely curious what you did with
your the false alarms and the down to
one hour is a huge improvement like you
say you feel as a magnitude over eight
years but it's still far too many false
alarms for operational purposes and so
then I guess you're taking the radar on
the other signals yes I mean it helps a
lot week since this is what gets you
down yes and the more data we have much
larger data as as I mentioned we have
you know New York millions of and so
that also helped reduce a lot and it's
also this aspect of bootstrapping so
it's not you just mean it's not that
just you have a big data set but you're
kind of getting new data all the time
with the mistakes that the classifier is
making and collecting new data and so
you can really focus on the important
samples in in database in combination
with yeah it's better than one power at
the moment and it very much benefits
from the other things that come later as
well yeah we would like to say what the
final false alarm rate is it's a you you
it's very hard to measure it because it
just doesn't appear basically and at the
same time you do have a positive impact
otherwise you would just switch the
system off right but it's very important
that you have yeah close to very close
to zero mistakes and this is more
important even than because that's what
what you have to compare with the
baseline and the baseline is that
there's no system so you don't want to
have the case that with the system you
suddenly have an emergency braking
that's really the worst case scenario
but you know if we have like ninety
percent or something 90 ish percent
detection that that's ok because it's
better than zero so that's kind of the
rationale
what's a full autonomous driving I mean
a couple of challenges in terms of
customer acceptance legal and technical
challenges can you say a little bit
about the the wider space of Baltimore's
driving and power companies maybe you
have a different strategy yeah so I
guess google has been very much and use
the past 23 years on this team and
they're very strong on on map building
and a use of map for localization and
they've really showed you know the
strength of this information and we are
very much also concerned so that's
important at the same time we're very
concerned about using sensors that are
market ready or close to market ready
and so we have my colleagues have
demonstrated just a couple of weeks ago
autonomous driving from the city of
Mannheim support time which is goes
through the city of Heidelberg and
through very smaller cities fully
autonomously with sensors which are very
close to what's in on the market meaning
stereo vision sensors and cameras no
velodyne sensor so that's I think for us
the challenge due to use sensors that
yeah are kind of realistic for the
foreseeable future and to look in some
gradual approach of increased automation
as I showed you with the ACC with
steering assist towards fully autonomous
driving we should go to this point but
it's kind of fascinating thank you very
much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>