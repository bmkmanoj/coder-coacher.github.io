<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Python+Machine Learning tutorial - Data munging for predictive modeling with pandas and scikit-learn | Coder Coacher - Coaching Coders</title><meta content="Python+Machine Learning tutorial - Data munging for predictive modeling with pandas and scikit-learn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Python+Machine Learning tutorial - Data munging for predictive modeling with pandas and scikit-learn</b></h2><h5 class="post__date">2016-06-22</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/HMc8wfoeWzw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
um so now we'll focus on machine
learning itself so machine learning is a
way to write programs that accept to
analyze data and Auto Tunes there are
internal parameters to make good
predictions automatically based on
historical data so typically you you try
to have a program that finds the
structure of the data to find a
relationship between input variable and
output variable so that when you have
new data you pass it as an input to that
program and will predict the most likely
output for that specific piece of data
so for instance you can do time series
forecasting for the price of an asset or
the temperature if you are doing weather
forecasting are spam or not spam in
emails and so on so it's gonna be more
intuitive if we do some plots let's
execute matplotlib and plot this
function which is already it's written
as a as a external Python file that you
can find so this function basically
shows a data set in two dimensions so
the first dimension is on x-axis and the
second dimension is on the y-axis and
those are the two input variables for
our model and the goal of this model is
to separate
blue dots or yeah gray gray blueish dots
from orange dots and you can see that
there is a natural organization in that
two-dimensional space and so we can find
build a model that will draw a line a
boundary between those two areas and
we'll try to maximize the margin between
those two areas so in that case it's
using a stochastic gradient descent a
linear model so it's trained with the
stochastic gradient descent
optimization routine to fit a linear
model and the linear model is just
something that finds an
hyperplane in into that space of two
dimensions so it's a straight line in 2d
I won't detail the the mathematics any
more than that so we just give you some
names like this and if you can have a
look at the reference documentation
scikit-learn website if you want to have
more details on the mathematics of the
models and in the documentation we also
include references to the the main
papers in the literature to get more
details so that does it make sense so
for instance here the two variables
could be the age and size of people and
and half of the people could be man and
half of the other people could be women
and you could try to find a boundary
based on the age and size information
it's completely stupid because in your
life men and women will have almost the
same size and matching edges so the two
groups will overlap a lot in this case
there is a clean separation this is
really very rarely the case in real life
otherwise we don't need to do machine
you know so that if you are interested
in the in the source code for for this
you can execute this statement and you
see figure here is a is a folder that is
also a Python package because there is a
unit file in it and and we import this
function for from there and this is
actually this function is defined in in
that module so it's just not very
complicated to do that plot you can see
that there there is the function itself
the scikit-learn
classifier here that is fitted on the
data and then we do a bunch of
matplotlib magic to the figure itself we
will see in detail how to train models
there is a second kind of machine
learning algorithm that we will tackle
during this session is called regression
the first one was a classification
problem because we are two categories of
samples and we wanted to find a boundary
between those two categories so it's
classifying
or orange in that case we will do a
regression problem where we have one
input variable on the x side and one
output variable on the y axis and in
this case we we try to find a linear
relationship between the output and the
input so you can see that the the output
is a continuous very variable because
there are many different possible values
of Y there is not just two or a finite
number it's it's a floating point values
so basically regression is when you do
machine learning and the target variable
that you're trying to predict is a
floating point number it's a continuous
variable classification is the same but
you are trying to assign finite number
of classes to the output so discrete
variables so integers or our label
string labels all right so to do machine
learning in Python you can use the
cyclotron project so it's an open source
project you can download it and it works
on most platforms so if you go on
scikit-learn org you have the full
documentation and if you import
scikit-learn you can play with examples
datasets that are shipped into the
library directly which is very nice to
quickly explore the behavior of models
on sampled data so this is mostly toy
data because it's small so that you can
download it quickly but it's already
useful to get some intuitions so in the
data set package of a crm there is a
function called load digits and that
returns an object that has several
attributes data target and images many
more so data so let me execute that so
data is a number array and you can see
that it's a two dimensional number right
if I do shape here I
I see the shape of the array so it has
more than almost 2 mm rows and 64
columns so we call the rows the samples
and the columns the features I'll give
more details on what it means but the
input data of most scikit-learn models
will be expected to have a
two-dimensional shape with samples and
features and we also have a target
variable that is stored in a separate
array which is a one dimensional array
and you can see in that case those are
not floating point values but those are
integers I can check the G type and
integers so those integer are basically
the labels for each of the rows in my in
my data set so why why do you think
there are 64 values yeah 64 is 8 by 8
and those are actually pictures
represented as rows in an empire array
and they are just pixel values gray
level pixel values of 8 by 8 so we can
check that by accessing the the images
attribute which is which has the same
data but shaped in a different manner so
if I check the shape you can see that I
have the same number of rows but then I
have two dimensions and I have 8 by 8 so
if I take the first row of that 3
dimensional matrix I get an a by 8 array
and on this two-dimensional array I can
do in Show
we see map
it was VLT that cm that gray and I can
see I can visualize my matrix we also do
interpolation equals nearest because
otherwise slightly misleading so you can
see the actual data those arrays are
actual images and there are gray level
images with pixel values so you can see
that I've just 8 by 8 pixels so 64 in
total and those are gray gray level
values between 0 and 1 I think one is
white and 0 it's black okay so the the
digits that data attribute is the same
but reshape so the first the first world
will be concatenated with the second row
and so on on a single 64 bit a vector
the 64 value items vector ok so now we
have the data we can train a model so to
train a model in scikit-learn you you
import you read the documentation and
you see the list of modules and you find
the modules that you are interested in
and so in that case we are looking at
the SVC class from the SVM package so
the SVC class stands for support vector
classifier so it's a support vector
machine for classification and
regression so this creates target
variable and it takes two input
parameters which we call hyper
parameters those are mathematical
constraints that will affect the way the
machine learning algorithm will learn
from the data so those values here I'm
fixing them arbitrarily but in practice
it's very important to try on the data
which value works best and we need to
automate this using what we call the
parameter sweep or grits
when we want to do that in real life for
now and to start we will just fix those
two values so I created those the CLF
object which is classifier so by default
it's untrained and if you print it you
see all the default parameter values for
that model so some of them are like
mathematical attributes that constrain
the machine learning algorithm like row
F and degree and gamma and others are
more like technical attributes like
whether we print stuff on the output the
cache size the memory cache size of the
object so you you have to read the
documentation on the website to
understand what they mean so once we
have our instance object we can call the
fit method under data so in this case I
will just take all the element of the of
the data set except the last one columns
- - one yeah column the - one means all
the element except the last one and I do
that both for the input so the last row
and the output all that last the last
variable and this will train internally
the model so it's it's exactly the same
object but it has been mutated
internally to fit its internal parameter
to compress the data and find the
structure the structure of the data once
we I have this I can call predict on the
last row of my data set and it outputs a
single integer which is the integer
matching the class of this data set so
if we can have a look at the last image
of the data set and use in show again
and you can see that the the last data
point that we used for the prediction is
this and it predicted eight so it looks
like an eight so apparently it did a
good job in that case so we can check by
I'm printing that the target value
target the value of the target variable
for the last element it's actually
innate so it's a good projection all
right so you have questions on this
let's move on so you can close this
notebook and go to the next one well we
will reclaim in a bit more detail how
the data works in psychical so as you as
you've seen we've we've dealt with an
umpire race for the input variable that
has two dimension the first dimension is
called the sample the second dimension
is the features so the samples are the
observations are the instances in your
dataset the features are the attributes
of each instance so you can also
visualize this as a database table the
sequel database table are an Excel
spreadsheet for instance you have
columns and rows in general the
convention is to put on the columns
attributes of observations and
individual records as roles or samples
so this is the the traditional way and
this is the representation that
psychically on expects for all the
algorithm so we can learn another data
set which is a data set that was built
by adding like biologists moving around
in the nature and looking for flowers
like this one so the species of this
flower is an average set also
but there are like very close species
versicolor
and an virginica and so the biologists
want to classify those flowers and to do
the to do so they will observe numerical
attributes of those flowers to be able
to build a classifier so in your opinion
what kind of attribute can we collect on
those
pictures to try and classify them the
color yeah yeah and if you are a
statistician you know that it's
interesting to measure the petal length
the petal width the settlements and the
cipa which so I'm not a biologist myself
so I don't know which one is the CIPA
and which one is the petal but if you
have diverged this you would do and so
in and so it's it's available as a CSV
file that we can load from scikit-learn
and it has four attributes or four
columns sepal length in centimeters and
we have three target variables which are
the identifiers for the species
so again we can import this data set
from the data set folder and
scikit-learn and see this object here
iris it's a weird kind of object that
looks like a Python dictionary so it has
different keys or attributes so we have
the data array the names of the features
the target variable and the names of the
targets so let's have a look at the data
array we can load the shape and print
the first element so we have 150 flowers
we have the four attributes for each
individual flower and so in the first
flower in my dataset I have a little
lens I think no Sybil Sybil length sepal
width petal length petal width so
apparently the Sybil are bigger than the
flowers so this is the input data and we
also have a target variable and you can
it's a good sanity check when you are
dealing with data like this and machine
learning you check that the target
variable you have as many observations
in the target variable as you have in
the input data because otherwise you
have a mismatch and it meets
it's not actually the right labels and
we can have a look at the target
variable arrays and you can see that I
have 150 elements and they have three
possible values zero one of two and to
understand the meaning of those three
values you can have a look at this
target names attributes and zero stands
for setosa one stands for versicolor and
two for virginica so in scikit-learn for
classification we also will often use
integer encoding for the different
possible classes it's because it's more
efficient from a memory memory point of
view than repeating the string values
over and over again so we use numerical
encoding like integers so let's plot two
dimensions of this data set so here I'm
selecting the first two dimensions of
settlements and sepal width on those two
axes and I'm using matplotlib with to do
our scatter plot with different colors
for the three possible species and you
can see already that some some the
setters are species for instance just by
having a look at the sepals
it's quite easy to separate them from
the other two so let's try to play with
this cell by changing the values of the
indexes so you can see that those are
the indexes of the of the columns of the
data frame the data array so let's try
to use other attributes and look for a
better separation between the two the
three classes and do that on your
computer and see if you can find better
ways
actually oh the
hopefully the video is still fine okay
thanks all right so do you have any
suggestion one two - actually this is
the one that I've and it's actually a
good suggestion because you can see that
would be easy to draw a line here to
separate cities very similar drawing
another line here would work quite well
so it means that if we select a subset
of the features the right subset we can
actually have a good model so we what we
did there is just manual feature
selection in real life we will not do
that
we will give all the features to the
algorithm and most of the time the
algorithm should be able to pick up and
wage the feature relatively to one
another to find the good ones so the
question is can we you plot a third
dimension it's possible with matplotlib
to do 3d plots but it's a different
syntax but most of the time anyway 3d
plots I there you have like matching
that everywhere not really visible so
but you could if you if you want and
anyway in that case it's for dimension
data so it's limited and in real life
problems we would have hundreds or
thousands of dimensions anyway so so
another question
okay so the question is can you explain
this function for matter so basically
this is a trick yeah no I cannot explain
this yeah I wouldn't have done it myself
this way so I think if you want to you
can call several times
PLT scatter with different subsets of
the data and assign explicit color to
each of them and put a label and call
the legend it would have been easier to
understand but a lot and slightly not be
able to type okay but you can if you if
you want to know how to do my pro tips
visualization the best way to do it is
to go to the MATLAB website there is a
gallery you look at the plots that looks
like the one that you're interested in
and you adapt the the source code to fit
your data
all right so in scikit-learn there are
many other available datasets so if you
import the datasets package you have
functions that starts with underscore
fetch or make so load underscore is for
loading data that is shipped within the
source code of psychic down so those are
very small data sets other more
realistic data set can be downloaded
from public URLs on on the web so you
can use fetch data and it will download
the original data and convert it into an
empire array for you and save it a local
copy in a temporary folder and psychic
lon and finally do you have also make
which is useful for generating synthetic
they are with statistical assumptions
that you make a Videla to you just try
to break your machine learning algorithm
using a statistical statistical is
generated there so let's try to have a
look at the kind of data sets that you
unload I forgot to import a thing
I forgot to execute this okay so if I do
a load underscore and I eat the tab key
ipython will will autocomplete so you
can see a bunch of standard data sets
like Boston for regression of housing
prices in Boston in the 70s there you
have the digit digits data set diabetes
and so on if if you want to know where
those data come from I just want to do
that get rid of this so if you want to
know where those data come from and
actually when you fetch data it will
store them in a local folder and to know
where this folder is you can call get
data home from the data set package and
you will see the past local folder on
your machine so you need type completion
so you do data sets you can tabs
incomplete and type the beginning of
something and you
so this will work and you a deer or LS
and you should see the temporary files
that are downloaded by psychic lamb when
you fetch the asset so don't fetch any
data set now because you can have it but
in the future if you use the fetch
comments it will download them all here
okay okay so let's play again with the
digital asset actually actually we can
we can move on a bit and keep the end of
this and move on to the next so actually
we can break now and year Microsoft
Research helps hundreds of influential
speakers from around the world including
leading scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>