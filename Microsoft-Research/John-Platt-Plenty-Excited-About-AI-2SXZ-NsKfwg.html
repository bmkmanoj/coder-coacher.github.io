<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>John Platt Plenty Excited About AI | Coder Coacher - Coaching Coders</title><meta content="John Platt Plenty Excited About AI - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>John Platt Plenty Excited About AI</b></h2><h5 class="post__date">2014-08-04</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/2SXZ-NsKfwg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right I'm very excited to be here at
John Platt John tell us a little bit
about you and your background at
Microsoft Research well I'm a
distinguished scientist here at MSR and
I had been in Microsoft for 17 years and
I've worked on both machine learning and
other things like computer vision and in
computer graphics and signal processing
and audio so I've I like a lot of
different fields of computer science and
so I've been working both doing pushing
state of the art in terms of the
research and also getting this research
into our products and how did you get
started in the field of AI oh gosh I've
been working in AI machine learning for
about 32 years now I I got into it in
1982 because at Cal Tech at the time I
was living in Southern California and
john hopfield and Carver Mead were there
and they were starting to build they
wanted to build chips that sort of acted
like the human brain and that was so
exciting to me I decided to go to Cal
Tech and I always ask people what was
your first computer oh let's see
I that my first programmed a computer in
1973 and that was with a language called
pl-1 and I think it was a cyber computer
it was at the University of Chicago nice
and so how do you define artificial
intelligence and machine learning as
well are they two sides of the same coin
or how are they different oh okay it
they are very intertwined so I would
define artificial intelligence software
that's trying to emulate the human mind
so that's often specific to a domain
like computers that can see that's
computer vision and their computers that
can listen which like speech recognition
or computers that can read text which
would be natural language processing or
or text binding so that's AI and
relating to human mind and then there's
a set of specific techniques which are
machine learning in machine learning you
it's that it's a set of techniques that
turns a data set into a set of software
so it's sort of an alternative way of
programming so instead of writing a
specification and then trying to sort of
hand build a piece of software that
matches
the specification instead you have a
data set and perhaps some desired output
or behaviors that you would like when
you see elements of that data set and
machine learning will generate a piece
of software that will match your goals
on that data set before we got started
we had an interesting discussion about
AI tell us a little bit about how AI has
changed over the decades and I was
surprised to hear how far back it goes
oh sure AI is really intertwined with
the history of computer science some of
the original computer scientists I think
we're interested in computers because
they wanted to build artificial
intelligence artificial minds that going
back to Alan Turing who proposed the
Turing test yeah I mean AI dates back to
the for example to the 50s one of the
things I told you about before was
people might not realize but there's a
little adaptive one layer neural network
in pretty much every phone it's it what
it does is it performs what they call a
coup stick echo cancellation so that
when you when you speak into the
microphone it doesn't cycle or when you
speak out when you get the sound out of
the the speaker it doesn't go back into
the microphone and echo and make screech
you sometimes ya hear that when it fails
but the fact that it doesn't that you
don't hear that a lot that's actually a
little algorithm that was built in 1960
that was one of the original AI
algorithms by Bernie Woodrow so it just
shows you that sort of AI a machine
learning has been around for many
decades and it's ubiquitous around us
you might not even realize it and what
is deep learning compared to traditional
machine learning okay deep learning is a
particular kind of machine learning and
it addresses a famous problem in machine
learning called the problem of
representation you see many of these
problems become relatively easy for
example let's say computer vision if you
just had the right representation one
pixel in an image tells you very very
very little about what's in an image if
I just took one pixel of a picture of
your face it would be very difficult to
tell what that was but if you transform
the data and transform it enough times
then you can get a very high level
representation for example it might be
this is a face this is
face of someone with brown hair or with
blue eyes and then I could recognize who
that was given the high level features
now previously before deep learning
people would hand design or hand
engineer the mapping from raw inputs
like pixels to features they could use
and then those features would be fed to
a standard machine learning algorithm
the recent success that the learning
shows that you don't have to hand
engineer then in fact computers are
actually better at engineering those
features then people are so what you do
is you take very large data sets and you
learn how to transform the raw data like
pixels into high-level representations
another nice thing about that is that
with the reason what's called deep
learning is that it does it through
successive layers of transformation so
it goes for a low level or petition like
pixels to edges to textures and whatnot
and that sort of emulates the way the
brain is architected that your brain
itself like in your visual system is is
structured in layers and and as far as
neurophysiologist know that each layer
is computing a more complex function
given the inputs from the previous layer
deep learning does the same thing that's
why it's called deep and how much of
this is defined by the programmer
compared to what the machine picks up
over time I mean does the programmer go
to the specificity of like these are the
edges these are the features to look for
or does the the device discern that over
time from looking at a bunch of
different pictures it's the device
discerns that over time that the nice
thing is like the programmer might say
you know I want six steps of
transformation I want six layers and you
might specify well how many features do
I want to I want a thousand or a hundred
maybe depending on how much compute
budget you have and then you turn it
loose with a data set and it will
actually figure out oh I want to do
edges and I want to do this kind of
filter that kind of filter so it figures
it out in fact you often can't tell is
it really computing and editors are
doing they'll something more clever and
why would a developer use one approach
as opposed to another what are the
differences in application between deep
learning and machine
learning so deep learning you would use
when you really it's you don't know how
to hand transform the raw data into a
data set that you like so for example
one is that one example I give is let's
say doing movie recommendations you know
mostly you know what the representation
of a movie is who is the director who
starred in it which users liked it or
maybe you want the demographics of the
users it's a you know fairly clear how
to encode that into software but for
images or for sounds or for text in
general it's very difficult for an
engineer to know oh how am I gonna
represent these pixels in fact that's
been the major problem in computer
vision for many decades so now you would
use deep learning to essentially develop
representations for you that you could
reuse on multiple tasks so vision is one
one input method it's one sense for
humans but we have many senses that we
depend on is it the same for machines
well just starting to be I mean many of
these fields of AI each sense so to
speak was an individual so field like
the really computer vision people who
just studied pixels and there's the
speech recognition people who just
studied speech but when you think about
how human brains learn like when little
kids learn they use all the senses they
have available to them they read they
hear they see if they can and that's in
fact there there isn't a supervision
signal it's not like people tell them
usually oh this is a coke can it's that
they learn from experience so we're
starting to see more and more of that
there's a lot of multimodal multimodal
learning that people are strategy to do
with deep learning like trying to
correlate images with text or text with
sound and that's terribly exciting
because you might be able to learn very
sophisticated things from the
intersection between two modes can you
share some examples of where Microsoft's
work in these areas have made its way
into projects or products sure um we in
terms of products we're very proud of
the fact that
we were the first company to develop a
large vocabulary speech recognition
based on deep learning and the fact that
has gone into our speech recognition
products in for example our search
engine you know also in our search
engine we use deep learning to kind of
analyze images and so that's that's also
part of the search engines so that's
that's very exciting we're doing a lot
of research currently into different
ways of applying deep learning to
various interesting tasks so that's
still an area of active research
especially around the the three I
mention of artificial intelligence
images audio and text they're all very
interesting for deep learning and how is
something like Cortana different from a
search engine Oh
oh that's very interesting Curtin is
just great I think it's one of the most
fun things to work on Cortana is what
they call a dialogue system which is
actually tough it actually responds to
you and in a search engine you you just
give a short query maybe a couple of
words but in Cortana you actually speak
to Cortana and you expect that Cortana
will actually say the right thing back
to you and if Cortana is confused she'll
ask you for clarifications even though
it seems very simple and obvious it
actually turns out to be an incredibly
tricky problem how to make that work
well and robustly about anything so
that's still we've got enough to ship to
our customers and make them happy but
it's still an open research problem that
we're all super excited about it's
interesting it makes me wonder should
search engines ask for more
clarification if they don't understand
something sure I mean to some extent
Cortana has a search engine inside of it
so it would be really neat if if there
was ambiguity or if Cortana won if you
were unhappy with your search results
maybe you could ask Cortana for more so
yes I think that's actually the futures
is to have a dialogue system sort of
handling a lot of your information needs
and how should developers think about
deep learning what are the the
applications and at what point should
they start considering it for their
projects well as we're saying you they
can you decide to use deep learning and
and try to train up something but it
takes a very large amount of data
compute certainly you could do that in
the cloud on Azure but it could be that
if they think oh I have a scenario where
I would love to have a computer that can
you know I'll point a camera at
something and I want you to recognize or
I can listen to some sound and have it
make a decision or I want it to process
some text and do something intelligent
if that's one of the scenarios then what
I would recommend is using if you could
find a pre-defined deep learned feature
to the extractor and then build
something on top of that so for example
that in the cloud ml sorry Azure ml
product the you could be able to use a
module that that has already been pre
trained with deep learning and then use
as your ml to build a specific
classifier on top of it how does a
developer become an expert in this space
well the way to become an expert in
neural networks or machine learning is
to try and just to keep experimenting
for perhaps thousands of hours uh a lot
of people at Microsoft because we have
so much data and we have so many
different scenarios around the company
many of us have just spent months or
years applying machine learning to do
various tasks and that's how you learn
as but now that we have the tools that
are in Azure ml other people can start
to accumulate this experience too and so
they should go ahead and and try it on
their own data that's how we did it
yeah what was an example of some of the
most advanced AI that Microsoft has well
I would say that the Bing search engine
is probably the most advanced a
collection of AI or machine learnings
that we have and when you think about a
search engine itself is sort of
artificially intelligent it really has
to know what you mean by the short
queries that you give and has to sort of
understand all the documents on the web
so the way we built Bing was out of many
many pieces each of which was trained
with machine learning so I would say
that's probably the the most
sophisticated one that we have at
Microsoft in the past with search
engines it was
effective to just search for the
keywords you thought would show up on a
page or we're at the point now do you
believe that you can just use a natural
search term there are examples in our
products which prompt you with natural
search term if you look for example at
the power bi product you can actually
use natural language to sort of navigate
through your system and get good
visualizations that you want so yeah
getting getting natural queries against
data sets is definitely happening now
can you talk a little bit about project
Adam and what makes it unique
oh yeah project Adam was very fun to
work on I helped trishal Chilam be a
little bit project Adam is a distributed
system that allows you to Train very
very large scale neural networks it it's
unique because it a lot of people have
been getting away from or getting away
from the use of sort of standard CPUs to
do deep learning and training of deep
learning models and but but of course
you get a lot of elasticity you get if
you can use the cloud to to Train deep
learning you can then get fast resources
available applied to it unfortunately
the reason why people have have been
moving towards GPUs is because per node
there's so much more effective but what
trishal did was very clever in that he
figured out a way of sort of effectively
marshalling many many cpus all to work
on the the same neural network and
that's actually pretty tricky I mean one
of the hardest things about a
distributed systems is figuring out how
to actually effectively use a
large-scale computational infrastructure
it's very easy to build something with
thousands of nodes but waste most of the
capacity of them and trishal doesn't do
that so that's very exciting and now
that really opens up
I mean trishul and I are speculating
about what kind of amazing things we can
build with a project Adam I mean what
kind of large-scale systems can we can
be build and how much more
amazing sort of AI stuff can be do so
I'm very excited so talk about some of
the capabilities a project Adam well one
of the most exciting capabilities our
project Adam is in computer vision or
recognizing objects in the image
trishul training it up to recognize
22,000 different categories of images
and these are very fine distinctions
like I was very excited to see could
tell the difference between a emperor
penguin and a king penguin I don't think
I could tell the difference and it's
really it's not perfect but it's really
remarkably good it's substantially
better than existing systems they've
been published and it's just incredibly
fun to play with you you could feed it
images one of our directors have fitted
an image of a small of us of a rabbit
running in its backyard and it said
rabbits so that was terribly exciting
anyway so it can it does very very good
whole image vision recognition I've
often wanted to get to Windows Phones
and try to get Cortana to have a
discussion with itself all right are
there any examples you've seen where 2a
eyes have a discussion what does that
look like well I don't know if I'd call
them AI but inside of the editor called
Emacs there were two there are two chat
BOTS one of them which is Eliza which is
the classic psychoanalysis one and one
of which which emulates what zippy the
pinhead the comic book character says so
there's a command for to have them talk
to each other and it's it's quite
surreal poor Eliza tries to a
psychoanalyze zippy which is just who is
just saying random things since quite
amusing
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>