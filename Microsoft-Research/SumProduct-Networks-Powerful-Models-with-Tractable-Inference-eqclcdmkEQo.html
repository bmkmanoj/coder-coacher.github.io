<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Sum-Product Networks: Powerful Models with Tractable Inference | Coder Coacher - Coaching Coders</title><meta content="Sum-Product Networks: Powerful Models with Tractable Inference - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Sum-Product Networks: Powerful Models with Tractable Inference</b></h2><h5 class="post__date">2016-08-08</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/eqclcdmkEQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year Microsoft Research hosts
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
okay it's a pleasure to have pedra with
us Pedro's at the University of
Washington has done a lot of excellent
work on relational learning and
knowledge based representations for
learning Lisa can you talk to us today
about some new work on influence
injectable networks all right thanks
everybody for coming please feel free to
ask questions at any point if you have
them okay
so I'm going to talk about some private
networks a new class of models that are
quite powerful and yet still a lot for
tractable entrance this is work that
I've done at u-dub with my students
Tribune's on - boom - is actually at MSR
Redmond right now so some of you might
even have met him I will start with some
motivation and then I will define some
Prada networks and look at how we can
learn them both learning weights and
structure and learning weights
descriptively injera tively and then as
time allows I will have some discussion
and you know again several these things
can be abbreviated you know we can have
you know more questions or fewer so
that's this is all flexible so here's
the motivation we live in the age of big
data and the point of big data is that
we can learn very rich models of
whatever we're interested in however
rich models means you have complex
interactions between the variables in
the model and complex interactions lead
to intractable inference meaning it
becomes very computationally expensive
to answer questions like what is the
probability of this given that in that
and this is bad enough but it gets even
worse for the following reason is that
in most in most learning algorithms that
learn which models inference is a
subroutine so as you're learning you
have to repeatedly do inference
so if inference is intractable and it's
then many times inside learning then
learning becomes very tough in
particular you have to use approximate
inference and the approximate difference
and the learning interact badly and life
becomes very very difficult and so what
really happens today is that you know
despite all the big data in excitement
for the most part or almost entirely
people do not actually learn
what you you know genuinely call which
models what they learn is very large
simple models like for example you can
do a linear regression over a hundred
thousand variables with a hundred
thousand predictors instead of a hundred
you know that's big data but it's still
only linear regression okay and what we
would actually like to do is learn truly
rich models from big data because after
all you know the data is there and
probably allows us to do that if we can
only figure out how here's just one
motivating example a very popular
example is there's social networks right
so this is a graph of a social network
of people each link is you know
friendship or family ties and this is
how many packs of cigarettes they smoked
today and what happened between you know
1970 and 2000 is that many fewer people
are smoking and traditionally use model
things like what is your probability of
smoking given your properties right your
propensity to smoke but the thing that
really drives people smoking habits is
whether their friends and acquaintances
smoke if you're a teenager and most of
your friends smoke you're gonna start
smoking as well and that is actually
what's hard to tomorrow because now
instead of each of these guys being an
independent point a person with their
properties it's all one big network and
now whether this person smokes is gonna
ultimately influence whether that person
smokes as well and so life now has
become very very tough so on the one
hand we really want to model these
things and that's what potential we have
the data to do these days on the other
hand modeling them is going to be very
very difficult so what can we do well
the most powerful or sort like the
standard powerful type of model that we
can build is this is what is called a
graphical model how many people here are
familiar with graphical models like
Bayesian networks and Mrs that's most of
you which is good so I will I will go
over this background briefly but again
if if at some point you're missing
something we can go back to it so
there's things like Bayesian networks
which you know there's a note for each
variable and there's arrows pointing
from some notes to others which roughly
mean you know speaking represent some
sort of direct dependence between them
Markov random fields are similar except
the the except that you know the the
edges don't have arrows and lately
there's a very new powerful very popular
and you know type of model which can be
viewed there's a still a type of
graphical model which is deep
architectures and deep architecture
is what they have is like they have a
lot of layers of hidden variables which
is potentially very nice for modeling
the real complexity of the world all
these hidden variables but then you have
to get at them and the advantage of that
that these representations have is that
they're compact you can model phenomenon
with the Bayesian number that is not
very large and yet you know is actually
quite rich because it can have errors
going anywhere and you get even more
compactness if you go too deep
architecture however compactness of the
representation is just one aspect of the
problem that right then you also want to
be able to do the inference efficiently
and by doing inference I mean things
like answering questions of the form for
example you know here's a famous example
you know the alarm in your house will go
off if there's a burglar right that's
what it's for
but it may also go off if there's an
earthquake right this example comes from
who the Pearl who lives in LA and this
makes a lot of sense all right so you
might want to compute for example the
probability of burglar given alarm the
problem is that in order to do that you
have to sum up earthquake okay and if
instead of very quickly Heather hell you
had a thousand boolean variables you
would need to sum out over you know two
to the thousand states and that's what
the problem is right and and in general
there's no efficient way to do that so
in the you know the the conventional
wisdom is that the inference cost is
exponential in the tree width of the
graph what is the truth of the graph
without going into the ORS if you think
for example of an image where each pixel
is a variable and and each rebel depends
on the variables above belong to the
left and right the truth of that graph
if if the image is a thousand by
thousand is actually a thousand because
you have to you have to define one
entire column of the variables to make
the two remaining halves of the image
independent and this is extremely bad
news right because if the inference cost
is exponential in two to the thousand
it's not going to happen in this
universe so what can we do about that
what we do is approximate inference okay
but now what happened right we can't do
it exactly so we use approximate methods
like Markov chain Monte Carlo a belief
propagation variation approximations and
so forth and that in itself is already a
problem because that inference tends to
not be reliable it takes a PhD to know
how to make it work they may give bad
results it may still take a long time at
set etc
but it gets worse when you actually try
to learn these models so how do we learn
these models the the high-level idea is
really this is that we want to learn the
parameters of the model such that the
empirical statistics for example how
many people smoke and you know have
cancer or how many alarms go off and
there's a Burghley and so on and so
forth you want the empirical statistics
to match the predicted statistics the
model predicts that you know 80 percent
of people who smoke will get cancer but
if in practice ninety percent of them do
then something is wrong with the model
that needs to be adjusted
so if I can match the empirical in the
predictor statistics then I'm good that
I've learned a good model the promise
that the compute the predicted
statistics requires doing exactly the
kind of inference that's intractable I
need to know what the model tells me in
order to compare it with what the data
tells me and adjust accordingly and this
is where all hell breaks loose when you
combine this with the fact that you have
to do approximate inference all right so
first of all the inference is
approximate so this is actually going to
be in reliable right you're naturally
you're not actually going to get
accurate values here a lot of the time
moreover typically there is no
closed-form solution for this problem so
you have to do some sort of optimization
gradient descent or quasi newton or
something like that and moreover as long
as there are hidden variables in the
problem and you know in enriched real
models that are almost always important
hidden variables where you can you can't
get rid of them then there is no global
optimum right there is you know it's not
a convex optimization problem and there
isn't a single global optimum when you
come when you combine this with the fact
the inferences approximate learning
becomes very hard indeed even you know
even for those of us with phd's in the
subject it's often too hard right let
alone for people who don't know are not
experts so let's treat pardon II know
what I mean isn't I think think for
example of the likelihood right as a
function of the parameters right no no
no global Optima means like you know
here's my huge you know I make all my
parameter W it means something like this
no yeah sorry yes it's it's yes there
may be exactly there are look there
isn't
single optimum right yes that yes yes
yes that would be a yes sorry that was
that was a dead language was Lucia what
I mean is that there are local lot in
there okay so there isn't a single
optimum
yeah and so you can get trapped in here
when in fact you wanted to go over there
and then that's the problem right so
what can we do about this well people
have looked on many different ways to
try to combat this but the one that I'm
gonna try to propose here in a way I
think is taking the bull by the horns
which is let us actually define a new
representation where we can solve this
problem but yet let's make very
representation as as efficient as
possible for inference so think of the
space of compactly representable
probability distributions some
probability distributions can be
represented compactly as a Bayesian
network and and some can't so let's say
this is the space of problem two
distributions that can be compactly
represented as you know bayesian
networks for Markov random fields or
deep models or whatever most of them are
intractable right so their trouble there
is a small subset here of models that
are tractable and these these innocents
are good because now the inference is no
longer a problem these are things like
mixture models hidden Markov models you
know things that are very very limited
in what they can express well what what
I'm going to describe here today is a
new class of models called some part of
networks that first of all compared to
graphical models it has an intersection
the sense that some things are compactly
representable as both graphical models
and some product networks there are
unfortunately some things that you can
represent compactly as graphical models
but not as some prada networks because
you know there's there's no free lunch
on the other hand there are also many
things that we can represent compactly
as some part of networks that you cannot
represent compactly as graphical models
in particular graphical models depend on
conditional independence if there's no
conditional independence then your data
so your graph is wrong one bit click and
all hell breaks loose in some problem
now a typical some part never actually
is all one big clique so if you looked
at as in
look at the corresponding graphic model
you think it was completely intractable
and yet it's still compact but of course
the more you search the thing is that
this here is is intractable inference in
the case of some prior networks this
entire space is all tractable inference
you no longer have to worry about the
tractability reference it's linear in
the size of the network in the case of
graphical models the the inference could
be exponential in the size in the number
of variables in the network right or in
the number of nodes in the network here
the inference is always linear in the
number of nodes in the network okay so
doing inference is basically just
evaluating the network it's never harder
than that you can do it on a very very
large scale so how do we do that can I
define what sorry yes think exactly
think of it as the number of edges
that's actually the better thing is not
the number of nodes is the number of
edges right so a graphical model has
nodes and edges right and inference is
not tractable because it can be
exponential in the number of edges in
the network okay in the case of some
part numbers inferences linear in the
number of edges in the network our
inference is orbital for the number of
edges in the network and that's what
doesn't happen all of the above every
one of those can be done efficiently no
some pro network the example that I have
here was computing marginal conditional
probabilities but the singing so here
are things that are efficient for you
we'll see this in a little bit but like
computing the partition function is
tractable computing arbitrary margins
and conditionals is tractable generating
samples is tractable and computing you
know MEP States is also trackable so all
the things that we usually want to do
with probablistic models are tractable
in the case of some prime networks all
in linear time Eunice's of the network
exactly
so that's good right well you're
probably wondering well you must be
sacrificing a lot to obtain that and the
whole idea in some pro narrow is is to
answer the question how little can I
sacrifice while still guaranteeing this
I wanna guarantee that inference is
tractable but do I really have to be
this restrict and the answer is no
there's a whole universe of things out
there that we can do while keeping
inference tractable yeah this space yeah
oh this what is an example of this this
oh yes I see yes notice there are not
existing tractable models but I don't
know right that's why I left that open
right I would guess that probably right
there this is probably non-empty but you
know we I don't have a ready example for
you okay and again you're like why worry
about I mean it's an interesting
theoretical question right but the good
is that over here all right so what is
the some part of network a some part of
network is defined recursively a
univariate distribution is a some prior
network so for example if my variable is
boolean and my rebel X is boolean you
know like a Bernoulli distribution would
be an example or you know a multinomial
for discrete variables or a Gaussian if
it's continuous or Poisson or it you
know like whatever univariate
distribution you have is fine in fact in
fact what we really require is not that
the distribution be univariate but that
but that the mode and the under and the
partition function of that distribution
be efficiently computable it can
actually have many variables what has to
happen is that the individual
distributions that you're combining
themselves should be tractable when in
fact as long as the treta but they could
be anything that you want what we're
going to do here is combine tractable
distributions into much rich or much
more complex distributions that are
still tractable okay so how do I do that
in by combining two things a product of
sum product networks over disjoint
variables is still a sum partner
okay so what this means is that if I
have a distribution over my variable X
here and I have a distribution of our
memorable Y I can just take the product
of the two and call that an SP n okay
and what that means is that basically I
said that this variable has its own
distribution that's independent of this
distribution over here right so this is
just the independent model it's not very
exciting so far right but remember that
where we're going with this is that this
could actually be a wholesome product
Network and there could be more stuff on
top of it so if we actually want to
represent dependencies then then what do
we do actually we just do the mixture
model so the other thing that as some
part network can be is a weighted sum of
some product I works over the same
variables so for the product they have
to be over disjoint sets of variables
for the sum they have to be over the
same variables and we will see shortly
why this has to be the case but the
meaning of it should be fairly straight
for is that like you know here I have an
independent model of x and y and I hate
and here I have another independent
model of x and y but now I can combine
them with it with a weighted sum and now
they are no longer independent and
remember this X doesn't have to be in
the various distribution it could be a
big sum partner where that's over that's
already over a very large number of
things so this is just a mixture model
with a mixture components being sub SP
ends okay in fact for a lot of things a
good way to look at it and some part
network is everywhere you see is some
node think of it as the result of
summing out a hidden variable okay so
for every some know then in the in a
some part network there's a
corresponding hidden variable that
you've effectively summed up okay any
questions so far right so this this
definition is very simple right it's
powerful because now you can recur
sarbat early I can do sums of products
of sums of products you know up the
wazoo I can build up networks with
millions or billions of nodes very
easily it just by combining these things
and what we really have you can't just
take any two things and put a sum no but
I can check whether these general
variables
you're all variables no sorry for
someone yes they have to be over the
same variables so what I need to know is
for an SP n is what variables it's over
which you know presumably I know
and then when I'm trying to decide
whether I can combine two SP ends with
the some node right I have to check
whether they're over the same where the
variables are the same if they're not
the same for example I can pair it out
with you know independent models for the
variables that weren't covered in fact
in some extensions of Espeon suis do
that if they're disjoint I can do a
product if they're the same I can do a
sum if they're neither I need to somehow
turn it into this and in fact this is
what the junction tree algorithm is do
it oh this is just for display purposes
yeah this could just be one X but but
then you know the graph would be black
it would be what Mark Newman calls a
ridiculous yeah so this you know if you
want to just think of this as one you
know yeah so in press equals some
partner where doesn't have to be a treat
can be a dag right this is one of the
things that gives it power is that
nothing says that I can't reuse the same
SP n 500 times if I want you know if
that's what I want to do okay so so far
the definition is simple right it's
potentially powerful in the sense that
yeah you can build very complex models
in this way but but not but now there's
two questions right the first questions
like okay but my my promise here was
that the inference is going to remain
tractable right why does the inference
remain tractable actually the reason you
know like the theorem where we show that
inference I mean strategies like you
know it's it's less than a one column
proof all right and here's why it
remains stratum and hopefully I can give
you the basic idea right here so claim
one all marginals can be computed in
your type right for example what's the
point what suppose that I have a
distribution over x and y and i want you
know each of them has 3 values 0 1 and 2
and i want to compute the probability
that x is equal to 0 right i need to sum
out why i need to marginalize over y
right how do i do that and in particular
if i wanted to compute the partition
function i would just be summing out all
the variables right so competing the
partition function is is a special case
of computing modules it's a special case
where you marginalize over all the
variables
okay so how do we do this and why is it
going to be tractable well let's let's
play this through the recursion let's
suppose that X just had a univariate
distribution right then by hyperino X
was just a little multinomial over these
three values right then in that case you
know I I know how to compute the
probability that X is zero so I just
read it from you know from the
distribution okay and now let's suppose
that X you know then what I actually
have is a distribution over x and y but
they're independent okay well again life
is easy because I can just you know
these two things factorize right the
factor isn't into two different
distributions of a different variables
so I can just take my value over here
and multiply it by the sum of hours over
there which if the distributions
normalize is just one okay so you know
this is what the the product node buys
me and this is why I want it to be over
this joint variables because that's how
I can factorize it into two independent
components okay so I can do things up to
here and things remain tractable right
now what about the some notes well what
happens in the some node is I remember
like I'm doing a sum over values of Y of
this sum of our mixture components right
that's all that's going on at a some
node right what I want to do is be able
to interchange the sum of our values of
Y with the some of our major components
and I can do that precisely because the
initial components are overall the same
variables right so just a matter of up
here what I did was apply the
distributive law and here what I do is I
apply the commutative law
there's nothing fancier than that going
on okay notice that if we if they were
not over the same variable then I
couldn't do this right I couldn't just
need to change the sum over the mixture
components under some of the variables
because there would be different things
in different you know substance okay and
now well if this is valid at the leaves
and it's valued at product nodes and
it's really at some nodes then it must
be valid all the way up to the root so
bottom line I can compute any marginal
and but you know like here I was like
you know X was evidence and I was
summing out why but you know I can have
anything be evidence n be something out
anything right and it always and it
still works out right notice that what
happened over here was that like I had
one distribution for XE but I have
another distribution for X over there
and you know watch some problem
I could have a whole bazillion of these
distributions of X and they're all going
to get combined you know with summing ro
over whatever the relevant variables are
but a very simple algorithm actually
gives you you know very fast inference
on something that could actually be a
very very powerful model okay so this is
we're computing marginals but a lot of
the time in real applications for
example in language and vision and you
know speech and whatnot what you
actually want is to compute the ma p
state is I given this evidence what is
the most probable for example given my
noisy image what is the most probable
set of segments that the image is
composed of so how do we do that turns
out we can also do this efficiently we
in linear time by the same principle in
fact this is going to be quite quite
important for learning as we will see
later and the way this works is actually
very very simple it's the following to
do an EP inference what we have to do is
to passes through the network the first
path pass is just going to complete
compute the value of the mode right what
is the maximum probability and the way I
do that is simply by replacing the sums
by maxes everywhere I was taking a sum
of the children I now take the max of
the children and here at the leaves
instead of doing the marginal right I
just take the mode and and then the
upward pass is exactly the same as
before right I take the mode here I take
the evidence value here the product is
the product the max is the Max and
finally what I get here is the value of
the mode okay but what I want is not
that so this was exactly parallel to the
computation of marginals except with
Max's instead of Sam so it's tractable
because it's the exactly the same
algorithm with only some replaced by max
right but this gave me the value of M of
the mode what actually no I'm not done
yet no okay let me finish this and then
I'll ask your question right but what
actually winner is I want I want to know
what is the M AP State all right what is
them what is the most likely value of Y
right given my X now you see this error
going up this was the upward pass that
computes the maximum that computes the
mode now there's a downward path
which is really called the traceback
phase writing things like this like you
know you know the Viterbi algorithm the
Viterbi algorithm is actually special
cases doing this
what I do in the Nara past is like I
start from the root and then each some
node I pick the highest valued child and
remember I know the value of each child
because I computed them all on my way up
right on my way up I didn't just compute
the value of this guy computed the value
of everybody all right so what happens
that at each node I picked the most
likely child at each some in each
maximal I picked the most likely child
right the the the highest value child
nor is it's not the child with the
highest weight it's the child who the
highest value comes from evaluating the
entire network under it okay so this guy
has a weight of 0.4 in this guy has a
weight of 0.6 but I'm going this way
because if you leave all it is for
network this value point 3 and this is
another point of 4 so this is again if
you think of this is the hidden variable
right what I'm doing is I'm picking out
that the most probable value of the
hidden variable okay and at each product
node I go to all the children so what
the MIP inference does is it selects out
a subtree it selects out a tree that has
two properties it's the tree is a sub
graph of the whole SPN graph and it
accounts for all the variables and it's
a tree okay and then you know when I get
to the leaves of that tree you know in
each of those leaves I pick them out you
know of the distribution that's there
right as a result of which for example
here I pick I pick this value of y
because it was the most likely one it
wasn't necessarily the most likely one
over some of the other leaves that I
could have reached okay and notice that
you know this phrase of course is also
tractable because this face is actually
even faster because all it involves is
like you know is is order of the depth
of the tree times the number of children
at each node okay yeah there is a way to
do that which I did not describe here
yes but you can there's actually a
variation on this algorithm that will
compute all the marginals of all the
variables at once all the single
variable modules yes in your time yeah
it's just I mean it's a slightly
offensive thing but not that much yeah I
mean for purpose of this talk just
imagine that you do one of these
computations for each variable you know
you you can count the order of the
number of variables but that's actually
it would be stupid to do it that way no
no in the remember what I do in the
upper paths again if you know Viterbi
this is just like Viterbi right or if
you know Junction tree you know MAPI
junction tree right in the upward path
what I'm trying to compute is that is
the mode of the probability what is the
highest value that my probability
function reaches right you know think if
instead of you know think think of all
of the graph of probability right this
is X and this is P of X right well let's
say this is a distribution in the upward
path what I'm going to compute is this
value in the downward path what I'm
going to compute is the value of x that
gave rise to that value right so the
upward path is just by computing a
marginal except that instead of sums you
do maxes and instead of marginalizing
here you pick them out actually I mean
like exactly ignore if you try me yeah
ignore Viterbi right think about this
way if Y was alone if I was alone right
then its mode will be this value good
right if Y was just being multiplied by
X it would still be this value because
it's just being multiplied by the
constant right but now what happens when
I have a sum node right is that the
winner is going to be the largest value
of this multiplied by this or this
multiplied by this and that's what I did
right this is gonna be like you know 0.6
multiplied by 0.5 and over here it's
going to be point from x
point one it's not just the winner among
these two because each one of them is
now waived by the probability of X we
call this down there P 1 P 2 P 3 P 4 but
so then the probability of an event
upstairs would let's say is a way to
spawn half between the two it would be
one-half v1 times P 2 plus 1/2
P 2 times P 3 exactly the point is that
I can think of it as introducing another
variable which is sort of one which
decides whether I choose 1/2 the other
half yeah that's the hidden variable
over here
I remember we are now maximizing over it
not something because if I want to
maximize this distribution I couldn't
think of having a distribution they have
another variable which you decide like
alright yeah and remember I could be
talking about if these are different
states right here's y equals 1 and
here's y equals 0 right so I'm this way
I'm trying to pick up the knife so I'm
gonna decide if the winners gonna be 0 1
or 2 if I was marginalizing good points
so if I was if I really want to think of
the hidden variables as of these nodes
as representing hidden variables then
I'm actually not summing over them
you're right you're right no yeah
because that's not what I'm but if I
wanted to do that I could notice by the
way that I in I can have any mix of
maxes and sums here that I want right
yeah what I'm computing here is not the
maximum for Y summing over all the
vowels of the hidden variables good
point but right but I could do that if
that's what I wanted but again that's
not what we want to do you know you know
in typical you know for example in
Viterbi
just say that type of words for just a
second okay so that's so in summary all
margins can be computed in linear time
in the size of the network and all MEP
states can be computed in linear time in
the size of the network so the problems
that we want to solve actually now are
trivially easy this thing that we spent
banging our time banging our heads
against now is you know not a worry at
all yeah and you have sums of sums so
you end up with a tree at the end then
what do you do with all the individuals
know they remember the tree remember the
tree is one value for each variable so
here there's only one variable in its Y
so I pick one but in general right you
know I want to find the M AP value over
100 variables that tree is going to have
the property that it has one leaf for
each variable it tells us the value of y
one leaf tells us the value of y1 one
leaf tells us the value of y2 there are
never two leaves telling you the value
of y1 that cannot happen it's easy to
show yeah of course yes the reason the
reason I'm I want to do this so think of
this in terms of Junction do you know
Junction trees okay although this is is
a compact representation of the junction
tree right you don't think of a junction
tree as having hidden variables
representing each state of each
potential right you maximize over them
well I'm doing exactly the same thing
over here okay so the reason I want to
do this is that I want to generalize the
junction tree algorithm and Viterbi and
all that good stuff if you really care
about those hidden variables and you
want to sum over them then please do
that is still going to be tractable but
you know for our present purposes that's
actually I think not that important
because the standard things that you
want to do an in particular the way
we're going to use this in learning is
this way
well so but so remember the inferences
is linear in the size of the network
right but the network when do things get
intractable what happens if I try to
represent you know an Ising model with
this is that I have an exponential
number of notes exactly or if you will
an exponential number of hidden
variables remember if you have a
distribution over an boolean variables
you cannot represent it as a mixture
model with two to the N components and
that's what's going on here except with
a very important thing that what I have
is like I have ten components being
multiplied by ten being multiplied by
ten and so I get you know a million
components at a cost of three thousand
that's not like that's the thing that
I'm getting is that at the end of the
day you can think of this as well being
Google into a very big mixture model
except that the mixture model is being
very compactly represented by using you
know these factorizations more questions
okay so let's okay so so now a couple of
important questions what does an Espeon
actually represent right so one of the
nice things about graphical models is
that if I want to set up a graphical
model I have any tuition about what the
arts represent you know III put down
nodes represent in the variables and I
draw arrows between things that are I'd
like to dependent I can have a handle on
how to design them alright what is an
Espeon this is just the kind of strange
computational device well that's okay
because the inference is efficient but
then I don't know how to you know deal
with espn's in real life
well actually it turns out that SP ins
actually have a very natural intuitive
meaning which gives you a very natural
way to set them up and this is what the
intuitive meaning is it's more than
intuitive but let's let's give the
intuition is that a some note this will
not surprise you is really representing
a clustering each side of a some node
represents a cluster okay except that
I'm doing it in a subspace all right I
have classes over for example only XY
but not Z or only over X 1 2 X 10 but
not over X you know 11 12 100 right so
wherever there's a some node what's
happening is a clustering of a subspace
okay whenever there's a product what I'm
saying is that I'm combining independent
features of the objects in this
subspace okay the commitment that a
product no introduces that in that
context in the context of all the some
choices that you've made so far things
are now going to be independent so for
example in this is the type of
application that we've actually looked
at as you'll see in a little bit
provided there's time let's suppose that
I want to have a property distribution
over images okay then here's a fragment
of that represented as an Espeon right
represent a property over the other
images distribution of her images with
with a Bayesian network our Markov
random field is hell right in fact
people don't get it for don't get very
far in trying to do it they they maybe
represent some intermediate level of the
objects or you know or you know super
segments or things like that but nothing
cool doing this with a simple network
you might start for example with a sum
at the top that says this is going to be
an indoor scene or an outdoor scene and
if in your training data 80% of the
scenes were outdoor then that's gonna be
0.8 right then for outdoor scenes I
could have something well this is a city
scene versus the country scene again a
some node right and now here we are in a
city scene you know this is a very
simplified example just to give you
intuition but I can say well here's what
happens is that this scene is composed
of three you know are four or five
roughly independent pieces there's the
road itself there's the people there's
the cars there's the buildings and there
the sky didn't put this guy here alright
so what happens up now conditioned on
that class right if he wasn't indoor
senior said well I'm gonna decompose in
the ceiling furniture walls and floor
here because it's a city I'm gonna
decompose it into people cars he knows
you know roadway you know buildings and
sky and maybe trees okay and now for
each of these guys I mean to recursively
model it as a mixture of the things that
it could be like for example this could
be a person riding a bike taxi or a
person walking on the street or a person
doing whatever okay so now I'm gonna
have again a mixture distribution over
what the contents of this support of the
image could be right and now if it's a
person writing at a bike taxi as it is
in this image now obviously I can
decompose that into the person and the
bike taxi right and now we're now look
at the person in isolation well maybe
this is a person but maybe it's a lamp
right if you actually look at this thing
you know that this is the kind of crap
that real vision algorithms do right
they look at a person and think it's a
lamp because the person you know this
could be a lamp right with some noise
and some piece of tree that came over
from somewhere right so now I'm gonna
have a probability distribution of
whether it's a person or lamp but then
if it's a person that in turn can be
decomposed into the head and the torso
the legs and so on and so forth right so
I can I can build a very rich model of
images this way and again the inference
in these models is always tractable to
compute any probability of any of these
things all you have to do is basically
an evaluation or a couple of evaluations
of the network okay so this I think is
very important because it tells you how
to set up an SDN for some problem that
you're interested in dealing with and
also how to interpret what you get when
you learn an SP and you can then go and
inspect the some doesn't go like oh this
is here is a you know is a distribution
over the kinds of people that I see on
the street
or this over here is decomposing you
know a person into head torso and legs
lamp but now my person I'm now if I know
it's a person then the person has arms
and legs exactly when the lamp has
exactly the lamp could become precisely
so the rule is whenever I'm uncertain my
stick and makes a distribution on it
which are clusters over the
possibilities and your products are now
I know what I'm doing
and now here's have yes and the products
are like in this component now because
it's a person these yeah yeah exactly
following very important thing that I
think you alluded then I have further
yeah and notice you notice another
important thing that happens to you is
that like this split on this the split
on this side could be different from the
split on that side and this is where you
know you wind up with the model that you
know as a graphical model could be one
bit clique because these guys are all
dependent on each other unless you know
that they are decomposing this way all
right the right there's things that are
dependent on this side there and
dependent on this
and vice-versa so if you ignore this
decomposition and just try to build a
straight for graphical model it all
looks like one big clique in fact the
graphical model for this for the whole
image is going to be one big click over
all the pixels right with two to a
million States yeah yes so I mean I
could have right here where I have
person writing about X I could have
another option that is person on a
wheelchair and then there would in turn
decompose into a person in the
wheelchair and the wheelchair would have
the wheels etc etc it could be a robot
on a wheelchair in which case right so
all of these things are tractable right
but there are but the thing is like some
some things cannot be cannot be
represented as a compact SPN these
things are you know there's no miracle
here right so by full Bayesian you mean
in the inference sense or the learning
sense of vision right so inference is
what I'm explaining here right
learning is means that you not have one
more distribution which is over the
models themselves right and you in fact
we actually haven't looked at that right
but but you know an attractive thing
that this has from the Bayesian point of
view is that the Bayesian model average
itself can become tractable although I'm
not ready to claim that because we
haven't done that but I would suspect
that that's the case maybe with some
additional conditions but yeah that's a
very interesting question all children
should be over the same variables very
good question what that means is that I
lie then you caught me right the thing
that I glossed over here but now no
longer can is that well but you know if
you if you think of this as carving out
a little region of the image right the
region of
that gets cards for a person on a bike
versus a person in a car different which
means they if that's the case then I
can't really just have a sum over them
because it would violate this consent
that if it be over the same right so
what are we going to do what what we
actually do in some of the examples we
have later is that like we what we do is
like we have a bounding box and we say
this bounding box inside it is a person
and and I can only have thumbs over the
same bounding box I cannot have a sum
over this bounding box here and that
bounding box over there yeah these fine
exactly finally down here the leaves are
basically you know univariate gaussians
over the over the you know the
individual pixels number of colors the
number of pixels precisely yeah I mean
we should never lose sight of the light
side of the fact that the vast majority
of models are still not compactly
representable here but the thing is that
yeah well even an abstract painting is
still not that random right but the
thing is that it is random at some level
yeah but the food is that these
distributions that they're not of what
occurs in the real world anyway their
projection towards mine more questions
so you have a question that I never got
it okay yes if you have a deck then how
do you I mean the car might have no so
how would this be a diagram I could have
a person write in a car or on a bike
right but the model of the person can
you know doesn't have to be different in
that actually it is different because
they might be sitting versus whatever
right but in general right you know I I
could have parts of the model that I
shared right I could say well personally
in a you know I'm I have a model of a
person in a car and I have model of a
person in a bike and in stand then that
decompose into a model of the car
the person we met you had to model for
person and an angle of the leg and the
angle of the leg which so it would be
still the same model but in one case the
angle is 90 degree centi as I sort of
standing up no but exactly so if the if
and that's the real cases that people in
a car might look different from people
in a you know in a bike in which case
they have to be different models because
they have different parameters like you
said like if say people let's say it's
people standing up sitting down but for
example no but right so but I can
there's so what you what I hear you
saying is that like these models have
the same structure but different
parameters but that means that you know
the SPN fragment is still going to be
different and finally remember these
things all cash out to pixels and those
are just at the end of the day I'm
accounting for the same pixels no you're
trying to do it you're trying to do a
different decomposition no no this is a
good exemplar so I can have an anode
over here whose children are angles the
hidden I can this the kind of you know I
I can actually set it up that way or I
can this find out that this is what I
discovered right
I had a some note right whose children
were you know like this position this
position this position this position
with some resolution if there's ten
different positions that your arm could
be in I could have a some node where
those are the ten children and then I
would have a mixture model of how things
look when I'm sitting like this when and
they're like this and when they like my
etcetera said
okay so let me just say this without
going into it into too much detail
probably not too hard to believe at this
point the standard tractable models that
people use are all special cases of SPNs
things like hierarchical mixture models
thing Junction trees including hidden
Markov models non-recursive probably
context-free grammars and so on these
you know thing you know I all these
things can be straightforwardly
expressed as some partner works it is
also the case for each of these that
there's something some pro networks do
that they don't for example in the case
of fire actual mixture model right every
model in my hierarchy is over the entire
space there isn't this notion of models
over subspaces and composing them so for
example a product of two hierarchical
mixture models is an S P n but it's not
a hierarchical mixture model anymore
even less of one than when I put now a
node over these guys and so on for
example you know I probably still
context-free grammars right there models
on a string so they only split things
into contiguous pieces and in the nest
en they of course don't have to be
continuous and so on and so forth then
Junction trees right again they very
easily translated to some prior networks
about what some partner goes by is that
if there's context specific independence
if there's determinism at set etcetera
this all leads to simplifications or the
some part of network but not the
junction tree which is how you could
wind up with a junction tree that is not
thin and yet the inference is still
tractable okay and you know like ESPN's
build on a whole bunch of previous
related work which I'm cavalierly
omitting here but you know I'd like to
mention that that it does exist
they have relations to the interesting
things like Endor trees arithmetic
circuits multi linear functions which is
something that people in theory have
studied substantially right so this SP I
naturally have you know interesting
relations to a bunch of these other
things actually depends grammars and so
on you can do infants in some of these
and it's sort of big issue of what kind
of structures they captured
you know what kind of ins if you looked
at this in the linguistic context and
how they compare to yes oh yes so you in
the in in parsing right dependency
grammars are subsets of PCF G's yeah an
SP ends are a superset of PCF G's so
there's things that you can represent
with an SDN that you cannot represent
with the pcfg
you can represent op PCF G's and
therefore all dependency grammars
extractables polynomial right so this is
a good example right so how do I convert
the pcfg to an SP n right the espys in
is actually going to look like the chart
so I do suffer a polynomial blow-up
right so the SP n is polynomial a larger
than in you know it's going to be cubic
in the sentence length and you know or
it's or like in the number of right but
you know that but that's okay because
you're gonna incur that cost more
naturally the parsing anyway when you
build the chart okay so how do we learn
these right so this is all very nice but
how do we learn these networks okay so
we're a little bit short of time so I
will probably skip over the genitive
learning and just try to give you the
main ideas of discriminative learning
and just an inkling of how we do
structure learning right so for now
let's assume that the structure is known
and I'm just trying to learn the weights
so how do I do that well the ideal
discriminative learning which is what
people use you know most of the time in
practice is I have some set of variables
that are my query variables and some set
of rebels that are my evidence variables
and what happens is that I'm always
going to know these these ones and what
I'm trying to do is infer those which
means that I don't need to waste any
effort modeling dependencies among the
X's because they're all going to be
known at Korea time I just want to know
for example given the image what is its
most probable parts or given the
sentence was its most probable parts or
you know given you know like this is it
a penguin or is it you know is it some
other kind of bird okay so if you know
conditional random fields SPNs you know
the math and the learning crispian's is
very similar to the math for conditional
random fields with hidden variables with
the big difference of course that
everything is going to be tractable or
the inference is going to be tractable
and
and you know and in conditional random
fields it's not okay so what happens I
have my image right the the beauty of
discriminative learning is that now I
can compute any features of my image
that I want I have you know total
freedom to do that it's convenient to
keep them non-negative but but you know
not at the end of the world if you don't
right and then I have my evidence right
which is for example the particular
pixels that I saw and then I have
whatever I want in for like say the
class of that image in addition as I
mentioned you can think of the some
nodes as representing hidden variables
okay and now learning consists of
finding the parameters of the SPN and
the parameters are just the weights on
the some nodes right that's where
everything you know is captured right
because now I've already fixed the
structure right so I want to find the
parameters that maximize P of Y given X
for all the training examples so maximum
likelihood learning and you could do
regular eyes and you can do you know
Bayesian posterior ISM let's just look
at you know none of that changes between
s PN's and other things so how do we
learn this well yes you have to remember
though that so there's nothing to
learner in the product notes but if
you're uncertain about the decomposition
right which it could be that
uncertainties captured that the some
node above I say it could be decomposed
this way or that way not tell me you
know what the probability of each one is
okay so it would be redundant yeah I
could say there's X Y which are
independent of Z or there's Y Z which
are independent of X and now I learned a
mixture model over that okay so the
uncertainty over the over the parts
structure if you will is represented in
the some nodes yeah yeah yeah so these
these boxes right what I'm saying is
like I'm computing and
distribution for each of the product
notes would be something and yeah
different in different one then and
there could be a very large number of
different distribution absolutely yeah
well so in this case I'm assuming the
structure is given when I saw people
doing proximal time again you know
provided there's time now I will give an
example for actually learning this
structure right which is the more
interesting prom at end of the day but
actually you know like doing with
learning is already not not trivial yeah
and yes yeah and if them and if the
model is rich enough right just learning
the weights can actually be very
powerful so but let's look briefly at
how you learn the weights and then look
briefly at how you learn the structure
okay so I want to maximize the log
likelihood which is the log of this over
all the examples and I do that by
following the gradient right I'm gonna
do gradient descent standard thing right
so what is that what is the gradient of
the log likelihood right well it's the
gradient of the log of P of y and x over
P of X right that's just people i given
X right and so this winds up being you
know a very natural thing which is here
I have to sum right over all states of
the hidden variables given their I know
the correct label so I'm only summing
over the hidden variables and here on
this side I'm also summing over the
possible labels okay and the difference
between the two is my training signal
again once they match up you know I know
that I've in that I reach my maximum
likelihood the problem is they're in the
CRF you know computing this is
intractable in general right and here no
it's always tractable as we already saw
right so we can do it all tractable and
this is my my gradient that I need to
compute and then right what do i do i do
back propagation all right SP ends are
just like made for back propagation and
then the reverse right back propagation
is where you compute the gradient of
this root first and then of the next
level given the root and net of the next
and so on and so forth so the recursive
structure of SP ends so like goes
hand-in-hand in their propagation
let's say like this is the gradient of
my you know whole network with respect
to this root this you know let's say
this some node is the root right so the
gradient of the log-likelihood
respected that is obviously one right
because it's the same thing right and
now what happens is there at every some
node you know here's the rule right this
is it's just
propagation except with the particularly
simple set of functions at the nodes
instead of sigmoids orgasms you just
have sums and products right so was the
derivative of a sum well it's just the
sum of the derivatives right so that's
what I do
right at each at each node for each some
site some child right I add to the
derivative the child the weight right
because it's being multiplied by the
weight times the derivative with respect
to the to the parent right and likewise
for a product node right what happens
that I have to multiply by the values of
the children so first I didn't output
past the computed values and now for
example that the gradient right the the
the partial derivative of the function
of the log-likelihood respected this guy
right is going to be this which was the
gradient at the parent times the product
of the gradients at source a times the
parts of the values of the siblings
right that's just you know the product
rule of differentiation and like and I
do this from the root all the way to the
leaves and then finally I'll end the
parameters for the univariate
distributions you know the univariate
way okay and this is how it'll migrate
this sense so very easy and very
efficient I just use it the SPN
structure there is however I can write
so you know this is machine learning
right with hidden variables and so we
don't guarantee that we find the global
optimum it's just like yeah right
there's all the usual things that you
can do with multiple restarts and you
know and smart initialization whatnot
but you know but that's life however
there's a little bit of good news that
I'll give you in just a second but first
here's a big problem is what's known in
the neural net world to trace the great
diffusion problem is that I have a
strong gradient signal at the Athena at
the output layer or the root in our case
but then that signal gets more and more
get smaller and smaller as I progress
which means that by the time um I'm two
or three layers down there's almost no
training signal and this is why even
though in principle with back prop you
can learn very deep layers in practice
people only learn you know networks with
one hidden layer and all of this deep
learning literature that is coming out
these days and you know and getting a
lot of press what they do is they learn
models with two or three hidden layers
and very rarely they might learn
something with six layers because it was
probably hand engineered to be for
character recognition or something and
the basic thing that's killing you is
this current diffusion problem and we
face the same problem here because again
we're doing that propagation through
potentially a lot of layers so how do we
solve this problem in a very simple way
it's that we're going to do hard
inference instead of soft inference
we're going to instead of using sums
here we're going to use maxes the
advantage of using maxes instead of so
it's an approximation right you can
think of as we're approximating the sum
with the max which is often a pretty
good approximation all right but then
given the result of your map of your map
inference now the problem is convex and
there's a single global optimum because
I filled in the hidden variables right
so now there's there's no more room for
a local optimum right so what happens
with our difference is that I don't get
this great in diffusion because I always
have a signal of constant strength going
down no matter how many levels I have
there's a result of which we can learn
some Prada networks with we don't know
how many we've learned them with like
tens of levels but that's because what
was needed for the application it's
interesting for example that you know
consider the question of envision how
many layers do you need and as far as we
know there is no limit to how many
layers you could learn this way right we
in practice have learned things with on
the order of you know 50 60 70 layers
but you know we could probably go
farther okay
well in a standard back prop right it's
not probably stick models so there isn't
this notion of doing MEP entrance right
there is any inference because within
the probabilistic model right but there
are similar tricks so the analog you
know is that like I want to make sure
that I have you know like that that my
signal stays strong right and there's
there's certain tricks that you can use
to do which people have studied but you
know in that context that didn't get
very far even in deep learning today
people don't really have a solution for
that but in this context is a very
natural solution yeah actually like
replacing the standard sigmoid
activation functions by just you know
Max's in which case you do get the
gradient propagating down all the way
and some of these things that do happen
some of these deep networks that have
lots of layers no you you don't get any
sort of yeah and in fact you know some
the more scalable of these net was these
things like max pooling and some pooling
and max pooling in some cooling actually
the analog of our maximum par notes and
people have tried to put probablistic
semantics on them but then the inference
blows up here you have probably stick
semantics and know infants blow up okay
yes no because exactly be precisely
because what actually sir my your
question will hopefully be have should
be answered by the next slide so here's
what happens I do my MEP inference right
with the real data right this is my
green tree right is what the inference
with the real data did here's my so with
my known why write something only were
the hidden variables here is with my
unknown why right this gives me a wraith
tree and now my training signals
actually just going to be at the
difference between this trees so if this
here there's no signal because the right
answer is the right choice is being made
right but but then you know here in one
case you know let's see like this guy
went this way this guy went that way so
what's gonna happen is that I need an
increment and it's a fixed size
increment of this guy plus one because
of this plus plus one on this weight and
minus one on that
I noticed that it was going to be plus
or minus one no matter how far down you
go
you're always choosing one child you're
not choosing fractions of a childhood
get over small it's always right so the
learning rule actually winds up being
very intuitive is that you know it's
again it's similar to conditional random
fields this my my gradient is just going
to be the number of examples for each
some child right it's gonna be the
number of examples that had a credit
label minus the number of examples with
the model yes and if they're the same
I'm good if with model guests I have
higher value I you know the weight needs
to go down if this was lower than though
it needs to go up and that's what I get
because it's gonna be a positive
quantity really you're you're supposed
to be calculating but the sum not with
the max we're sorry doing soft gradient
not the hard gradient and a a prairie if
all the sums were dominated by their
maximum terms then this would work is
this better than that is it that because
you're taking a difference you could be
doing better in certain cases and say
yeah or or is or is it really only
working when the sum is dominated by the
matter not always in fact so this is a
lot like and in fact in the genitive
case it's gonna be exactly hard versus
soft TM so in soft here my the
fractional assignment of things to
cluster sort of LT and variables in here
I'm doing hard assignment and this is
gonna have exactly the same advantages
and disadvantages what people typically
do and the problem with soft TM is that
you know it's very it's very slow to
learn so people often start out doing
Hardy M to get the fast convergence and
then soft TM to really make sure you get
to an optimum and we actually we
actually thought oh yeah that's what
we're gonna do we're gonna do max
followed by yeah but actually as it
turns out you don't actually get you
know you don't get any mileage out of
that you don't get a better optimum that
way now this could depend on the problem
I can certainly make up pathological
cases where this will give you bad
results transition yeah so in this whole
thing this is the place where you made a
compromise if this is good then the
learning is convex the inference is
tractable you know life is wonderful but
you know there was this one thing
that we did you know overcome they look
a lot more the gradient diffusion
however you want to look at yeah okay
alright so we apply this to
state-of-the-art you know image
classification problems on standard
benchmarks and we beat everybody you
know so our bm's SVM's etc set on the
various conditions we you know like this
is stuff that people have put you know
hundreds of person RZ of work into on
Drina verse of these problems generative
word learning it's basically the same
thing except that now instead of being
descent we can just use the M I would
just you know generative learning is
we're learning a joint model of the
variables we can do that using M but
other than that the algorithm is very
simple and we apply this to the problem
of completing images like you know I
give you half the image in you to give
me the other half and in this case their
faces so you can compare but we did this
with arbitrary this is some that most
people didn't even attempt before
because it was too hard and we do
intelligent things like you know like
like you know filling out the beard here
nevertheless you can see that this got
this has these artifacts right the
artifacts are because we're using a
decomposition into rectangular you know
sections when we learn structure that
that decomposition itself is going to be
learned that you won't have these
artifacts anymore you know I can here's
the architecture that we used I won't go
into details of what it was women just
and you know here's a summary of you
know how you do learning so there's you
know soft inference or hard inference
there's general TV I'm Janet Aventis and
this committee were innocent and on this
side you using derivatives and on that
side you just using counts alright and
that's why this is more robust or not
are not so faster to learn but again it
doesn't give you the optimum guarantee
that that you have on the other side so
one quick word about structure learning
right or actually I mean if there's no
time I can just skip over this yeah okay
yeah so now let me just say that we have
a paper about structure learning coming
out in ICML and you're welcome to take a
look at it yet again
beats everybody by a mile actually not
let me build a frame in terms of
likelihood we are comparable to things
like Bayesian network learners but then
a difference time the ESPN takes a
fraction of a second whereas with the
Bayesian network you're doing its
sampling or BP and you know I having a
lot of trouble and then the accuracy of
the query answer is much much higher in
our case
so even in cases where the vision I will
have higher likelihood when it comes
time to answer questions the Bayesian
networks loses a lot of that because of
the inference and we don't okay so to
summarize in machine learning as in
computer science in general there's
always this trade-off between
tractability and expressiveness and what
we're doing researches explore different
places on this trade-off and this is the
case with graphical models right there's
like you know there's there's Junction
trees over here where it's like you know
thin Junction trees or mr. models which
are not very expressive but very
tractable or you can learn you know
models are more expressive but less
tractable right so this is what you know
life is usually like but every now and
then we can do something better then you
know explore a certain you know trot
ability expressiveness trade-off curve
which is jump to a better one and this
is what some part networks do in some
partner works there's still a trade-off
between expressiveness intractability
but now we have points on that trade-off
there are better than the points that
you had over here now with some products
for the same expressiveness I can have
more tractability or for the same
tractability I can have more expresses
and so this is what they bias is that
you know it's we're still doing the
trade-off but now we're in a better
trade-off crap okay and there'll be code
data and so on you know we have
implementations of this that will you
know that we'll be putting online within
the next couple of weeks so you can go
to this URL and download thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>