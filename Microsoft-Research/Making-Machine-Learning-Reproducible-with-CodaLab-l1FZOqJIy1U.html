<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Making Machine Learning Reproducible with CodaLab | Coder Coacher - Coaching Coders</title><meta content="Making Machine Learning Reproducible with CodaLab - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/Microsoft-Research/">Microsoft Research</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Making Machine Learning Reproducible with CodaLab</b></h2><h5 class="post__date">2016-06-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/l1FZOqJIy1U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">each year microsoft research helps
hundreds of influential speakers from
around the world including leading
scientists renowned experts in
technology book authors and leading
academics and makes videos of these
lectures freely available
you
so it's a great pleasure to introduce a
via dube here this is an end of
internship talk and so let me give a
little bit of background of what IV has
been up to before coming to Microsoft
and what he's doing a tree when he's not
here so IV the PhD students in the
machine learning department at Carnegie
Mellon working with professor Eric
caching be his interests include
statistical machine learning information
retrieval clustering and before that he
worked as a researcher for two years at
IBM Research India and before that it is
masters in CS at the iit bombay working
with professor su man Chakrabarti and so
with which we thought that you know with
and and his published already papers he
also has a patent so with all that with
rich we thought well clearly i was going
to do great research everything says
that in his resume so let's give him
even a harder challenge and so we said
you not only you're going to do reserve
but actually you are going to make it
fully reproducible on a platform that is
being developed and so that some of the
challenges that have you had to do and i
must say that he was up to attend and we
hear more about in now the research and
the reproducibility thank you yes that
was a great introduction so i'm working
on a reproducible research on coda lab
and so before i go into it let's talk a
like let's bend a slide on what coda lab
is cuda lab is an open source platform
and this is my perspective by the way
and you can download it from github you
can even go to coda ab dot org and see
all about it which has to face it's one
of them is to host challenges and
currently there are machine learning and
medical imaging tasks challenges that
have been host that are already there
and that visit is called competitions
and the other visitors own replicating
and reproducible research and if you go
on the site you have a banner saying
coming soon so that is what is the
worksheet and this I've taken directly
from the side and it says that
worksheets are is used to can be used to
publish executable papers or as a
personal research log and you can do
this because worksheets are we are a way
of integrating both text and experiments
and in experiments I mean you can upload
your data your program run them have the
result and talk about it and my
internship was as to prove this concept
that it can be used to replicate results
and it cannot just be used to replicate
results from papers you can because the
principal scary you can also have
tutorials on it on some on topics and
all of course you can use it as a
personal personal research law so with
these three in things in perspective I
go to next slide which by the way acts
as two things a this will be a road map
of what will be what I will be talking
up and be this will also act as a
summary of the research work that I have
done so what is it the first caller bad
set of tasks which and the crosses just
represent which of the three things that
we are talking about replicability
tutorial and research the will I be
doing in it so let's go into one of them
machine comprehension and the name
implies machine comprehension is how
well a machine is able to understand
text and it uses multiple disc
techniques from multiple disciplines
like information extraction information
retrieval relation extraction semantic
parsing and so on you can the list goes
on before this paper in 2013 most of the
research work on machine comprehension
was focused on a particular small task
of info whether it will be in
information retrieval or in parsing
because there was lack of openly
available data where which can be used
for doing machine comprehension
and the way that the authors defied
machine comprehension was if you are
given a passage if a machine is given a
passage can the machine then answer
question based on those passage and that
is what this paper by Matthew and
Matthew and Christopher was awarded so
going a bit more into the data because
the main main aim of this paper was to
delete the data set for for that
challenge this is an example of on the
right there's an is the example of a
story it's a story about a turtle who is
always creating trouble and then you are
asked to a set of questions the
questions can be very simple as what was
the name of the turtle and the answer is
right in the first line itself but
finding that answer you might have to
use some kind of information retrieval
just plain similarity based measures or
you might even do some kind of crazy NLP
tools the second question is also what
did hit pull up in the grocery store and
I've just highlighted the idea that in
the passage that is needed to answer
that question so again so the main focus
of the paper was to release the data but
they also gave two very simple baseline
it's simple in the sense it looks simple
but if you try to beat it it's it's a
bit difficult and some people are
laughing because in the Hat so one of
them is a sliding is this is where you
take a sliding window across the passage
and this just fine for each answer what
is the maximum similarity of the sliding
window for the question with that
particular answer so one of the ways of
doing it is you can given the question
and one of the answer you can using
rules predict what the answer sentence
would look like and then find whether
that sentence occurs in the passage or
not another they give another base line
where from the from the output of the
first algorithm
just subtract what is the dis- mum
distance between a query word and an
answer word so and this would help if
your are it would help if you're if
you're quick if the answer word is
concentrated where the query is and so
we deep reduce the algorithm and the
results and we have nearly the same
numbers as they had in the paper with a
small difference next I would like to
show how how we do this on coda lab so
to do this on coda lab first and
foremost if you are to starting from
scratch you will have to download it
from github and then install virtual
environment if it is already not there
on pip and then if the steps are very
simple these are exactly the set of
steps that you need to do nothing more
after that and I have already done this
so to see whether everything is working
or not you can just type CL and it will
show you a bunch of commands that you
can use with CL and C L stands for Kota
lab it's a short form if you want to see
what are the worksheet which are already
there you can just say wls and it shows
me that I have so worksheets
corresponding to the things that we our
star I was showing you in the tasks ok
so let's create a new worksheet CL new
say MC test presentation particularly
for the presentation if you do CL LS so
let me explain some a bit more about
coral am here go to lab you can put in
text and the remaining things like data
like your code and the commands to
execute those code comes in as bundles
you can think of bundles as just folders
and for and where your data or your code
or or the run command is saved so
currently if you do CL LS as it showed
it is empty because you have not
uploaded any kind of data program or
anything
so let's add I've written down already a
set of steps that I would like to add so
let's let me show you how the worksheet
would actually look like so this is is
assessed in remote desktop into as your
linux and it's not very well calibrated
so have to be okay so this is the
worksheet that I just created MC test
underscore presentation and as you can
see there's nothing in it currently now
I add message so the command is CL ad
minus M I just add this message and of
course it will reappear here okay now
you can add now you can add on the text
and they're very soon it will support
latex so you can even add latex to
explain and we will do the same so we
will add messages that will explain what
I just said
and if you refresh this you will have
all the other things in so now we can
add now we are free to add in the data
and if you do an LS here we will see
that the data is already there I am
sorry for the front it's MC test in the
score data and the command to to upload
the data set is just CL upload data set
so as I told you that there are three
different types of bundles CL upload
will upload a bundle then you'll have to
give the type of bundle whether its data
set whether it's a program or whether it
is a a run executable quad if you do see
LLS it will show you that this is a data
set type bundle which has been added you
can similarly add and by the way all all
this that i'm adding you can I didn't
wanted to do refresh again and again but
if
so if you add it and I added it with the
description of what the data set
contains who this will also contain the
description of that of the data set you
can add you can now upload the program
so this is the metadata associated with
the program you can sell give the name
you can also give it tags license so
Cyril and other another bunch of star
stuff I'm happy with whatever it is so I
will just continue so again if you do
see LLS you'll see that you have the
data set now and you have the program
now so that your program has been
inputted is in but you have not given it
commander to how to run it and that is
the next bundle which which is just CL
run the program name so we do CL LS you
will see that well it's hard to see here
hold on so if you see the last line till
now we had ready ready and now it is
created the DS has come here I'm sorry
about that so it's the run command you
have given the run command but it has
not run yet it is just that this command
is created that is what that status says
and the reason is in kota lab there is a
background server worker that keeps on
running and when it is running it would
have directly executed this but since i
have not run anything in the background
i will have to do CL worker and this
will run this particular than command so
now you can see it says it is ready and
after this I have to interrupt it
because it goes into and sleep mode
until a new and new run commands are
added ok now if you are wondering what
happened to what we are looking at well
so we have now the empty test program as
well as the emcee test run okay if you
if you thought that oh I forgot to add
something we have some text previously
so you can do w edit W stands for again
were editing the worksheet and here you
will see all the text associated that
you have added and here you can directly
add whatever you want to have like I
might want to give the instruction to
add
i would i would like to give the
instructions to add to run the program
before before running the actual program
so that people who can who see this file
are actually able to run it so you can
add whatever you want and it will be
reflected here one thing that I am NOT
able to show you right now because the
bundle services there is some problem
with the bundle service is I can show
you in the command line if you look at
forgiveness so if you look at
inside a bundle which has already run
and give the minus V option for verbose
you can actually see what the standard
error was was the standard out was and
as it as I told you it's it stores it as
a folder there is a folder corresponding
to the data hash which you can find and
you can see all the run output there
itself ok that's a quick short demo of
how to do it on coder lab so this is
what I couldn't cannot show you that a
very soon you will have this probably in
a day that you can click you can look at
the bundles and what is there within the
bundle in the website itself and then
you can look at standard error or you
can look at images that your that your
file might create and so on ok ok so
remember if you remember we also had
machine the research aspect to the
machine comprehension test and this is
something that I'm doing with min bear
who is another intern here and he's the
lead on this and along with the battery
Richardson at the central idea is so and
this is known that you can for question
answering system you can always improve
the accuracy by using information
retrieval techniques but can we do
something better or something smarter
than info just using plain simple
information retrieval like we looked at
how to we can incorporate rhetorical
structure theory which basically a
one-line X simple explanation would be a
probably and I one is that if you have
two sentences rst parser would give you
a links such as explains that are causes
such as sentence one is caused by
sentence too and if the question itself
is what causes something which is in
sentence too then you can follow it
backward and answer the question so that
was the roughly the idea we are using
the rhetorical structure theory
and the third one which is multitask
learning this is something that we
started thinking about like two weeks
ago and there the idea is that we can
think of different types of questions as
a different task like if you're trying
to answer when it's a time related
question so this is a different task as
opposed to when you're trying to answer
a question about what or why and we are
making some progress and we're and wind
may we'll probably talk about it more
when he presents okay so we have talked
about replicability and i will show you
how to use gorilla worksheet now what I
didn't talk about both fact it's a fast
lmm is factored spectrally transformed
linear mixed model and the reason it's a
the principle is the same that we we
explain what it is and in the in the
worksheet and then upload the code the
data and run it see as we mentioned
previously we can all we also want to
put in tutorial in coder lab and that is
where I will try to explain calibration
again so people familiar with machine
learning would notice that most
classifiers tries to optimize for
prediction error by optimized I mean
minimized prediction error so in trying
to do so it becomes very good in getting
the ordering right by getting the
ordering right i mean if it is trying to
predict if you are using it to try to
predict the probability or in a binary
class classification for example then it
will if I example belongs to positive
class all if you try to do is make the
probability that the example belongs to
a positive class more than the
probability that it belongs to the
negative class as long as that happens
prediction accuracy wise golden calculor
but sometimes you might not just need
classification as for example if the
classifier is being used in a pipeline
and later down the line you want to know
what is the prob what is the actual
probability of this data belonging to
in your particular class and that is
where calibration comes in so
calibration is the producer is a
procedure to produce posterior
probability of classes after
classification and from from co delas
worksheet perspective we want to make an
introductory tutorial for calibration on
on the worksheet there are a lot of
papers on calibration starting from
blatts paper in 1999 and now he's listed
a few here it's not it's not a complete
list let me say that out right because
there are a lot of other papers that I
have not cited here okay so let's let's
look at it in a bit more detail so for
cap for calibration perspective are all
the slides on calibration on the x-axis
will have scores provided by the
classifier so we are assuming it can be
probabilities also but we are just
assuming that it's Jesus course provided
by classifiers and if you now plot in
this case you are just binning the for a
two class classification problem the the
negative class and the positive class
and you're just showing the bin output
okay there are multiple things that we
you can see right here e as you go along
this as you have increasing score you
pref your preference for one class
increases above the other right and B
this is not a perfect Gaussian so you
cannot just fit a Gaussian here and
solve the problem okay by these to
prepare both of these two images are
from John Platts paper so what what you
can do is you can be in it so by billing
I met think about score from minus two
to say minus 1.5 and look at all the
examples that have that particular score
and see the fraction of say the positive
class in it okay and that is the plus
marks on the on the right hand figure so
as you can see clearly that this looks
like a sec
and hence John Platt suggested that we
will fit a sigmoid on top of on top of
the scores to get to the probability and
this is something called platt scaling
and here on the right again we have we
have reproduced the same result on the
left you will see some more information
by more information I mean that the
green ones are actual examples so
instead of minus one and plus one I have
made them 0 and 1 to fit in the same
picture and what you cannot see is the
generating probability so how did we
generate the data well we sample
something uniformly between minus 5 + +
5 that acted as a as your score okay and
then from a generating probability which
is we cannot see you get the probability
of it belonging to the positive class
and then that probability is used to
sample whether you get a particular
class 0 or 1 so it's not that important
for this case because you can you see
the platter scaling directly fits it but
what if you have some function which is
like like a ramp or a staircase so again
the blue one is the generating
probability and the red one red is how
good a fit it is so for the ramp you can
see that splat scaling is doing what it
can best do of course there will be some
gaps but it's pretty much capturing it
but if it is a circus it's a
pathological case but if it's a circus
then it fades an important point to note
here is we have not deviated from this
picture where as you increase along up
along the x axis which is your score the
probability of being belonging to +1
class is more than than belonging to the
minus one class and this is the idea
behind isotonic regression so basically
you fit a bullet on a clean on
decreasing function and this is what
happens so of course there are jumps
because because of a number of other
reasons but these jumps will become
smaller and smaller as you have more
data and it is much closer to the actual
line for the staircase case than fitting
a sigmoid now there are various points
to mention here hey this is a
nonparametric method hence requires more
data than flat scaling here you are just
fitting a sigmoid and fitting a sigmoid
is a two variable you have to just find
two variables and they are finding two
variables you don't you don't need much
data as opposed to soy as opposed to a
certain aggression and B if you're
thinking that hold on I can solve this
using a function to function regression
sorry using a single one dimensional
regression problem you have a score and
you want to predict probability you can
do it and you can use nonparametric
methods to do it but the only thing that
we that is isotonic regression is doing
more than their Arjun just using a
regression is that it is suggesting that
we use monotonically non-decreasing
function because that is the property of
some classifiers all right any questions
ok
good so we talked about calibration and
we have put it in as a tutorial and the
reason I am not showing you the demo
here is the principle is the same I
describe an algorithm and then update
the date upload the data upload the code
and run it and show you the output the
outputs these are exactly the same
outputs I have taken it from there that
you will see there the second point I
would like to mention is that
generalized additive models we have also
have a tutorial for generalized additive
models but again so for the point of
view of pushing code a lab worksheet I
just want to mention it because this is
the work that I've done here but on the
point of view of understanding coded I
 it will not help for this
presentation next I will like to 12 into
the research work that I'm doing with
rich and its mother called multi-level
sparse intelligible model for multi task
aggression and I'm sorry the title is a
big big and we'll talk about I'll try to
break it in two parts and explain you
what is part means so but from kodaline
worksheet bones perspective this is to
use coder lab worksheet as a personal
diary for researcher and this is the
work in progress we have some primal
results that i will show you and and
we'll see okay so what is multitasking
location first and foremost i hope
people here know regression it's just a
way of pain which you are given an input
X suppose the simplest way of
understanding it and you have an output
or a regresar or a predictor that you
want to predict say why and you want a
transformation or a function that will
take in this input X and give you this
output Y but often it might happen that
data for a particular task that you have
gathered is limited an example might be
that suppose you are looking at you are
trying to predict say the height of some
particular
variant of dinosaurs and you have
collected data say in Argentina and some
other researcher was trying to predict
the weight of the dinosaurs in some
other part say Brazil for example and
and they have taken data on for weight
individually they might have very few
dinosaurs data available to them but
they might want to pull the data
together so as to help or so as to help
both the two task of predicting the
height as well as a weight and and this
is multi class regression which can tell
you all about it if you want to go to
him he started it in nine case so ah the
next part of the title that I want to
explain is intelligible models now among
regression the simplest model that you
can think of is linear regression
because you are taking their F is just a
linear way it is or you're just applying
linear weights to the features and
summing them up and if you plot the
accuracy of that it sits somewhere here
but somewhere here related to what
suppose you have a very complicated
model that takes in that such as you
take a very complicated kernel as we
apply it as SVM that might give you an
accuracy which I am denoting by the last
one here RF radial basis function
absolutely level now as the accuracy
increases there is one problem though
that might you if you try to explain the
colonel to someone who is not familiar
with machine learning or who is not a
statistician it might be a problem so
intelligible models are models where
where you try to increase the accuracy
as much as possible while still staying
in the domain where you can explain it
to any particular individual easily and
when you think about what are things
that can be explained easily
if you have functions on a single on a
single dimension you can easily explain
it to any any individual right you can
just show the function in 2d and explain
it if you have functioned in 2d of on
two dimensions so the function is
actually in 3d you can still show it in
two individuals and people will still be
able to organize beyond that physicists
and machine mathematicians will I
recognize it but not every individual so
those are the functions those are the
function domains in which intelligible
models stay so you are so for example
jam which is generalized additive model
which we had a tutorial on in Kerala
actually is just where you take
individual features reshape it and some
them that's your predictor and camped GA
2m which is basically capturing the
pairwise interaction also as opposed to
just a single feature interaction and
what if this was this was work which
started with rich and his intent yen
2012 11 and so and it it it went into
his 36 completely in his thesis and they
found that by just using a single
dimension functions which is very easy
to understand they can get to about
fifty percent of the difference in the
accuracy between linear regression and
RF and by using this pairwise
interaction they could go to ninety
percent and that's quite good because
you're still staying in a domain where
you can look at it and understand while
you have reached good accuracy number my
work is to use intelligible models in
solving multitask learning so that were
one task helps another okay
so that brings me to the summary that
could a lab worksheet and again so all
this all the things that I've done is on
the worksheet so again so watch it can
be used while you are doing research you
can run experiment and see which failed
why it failed and you can even write it
down to that will help you also in
future so go to lab worksheet can be
used to upload code data for
publications it can be used for
tutorials it can be used for each other
such as bookkeeping other interesting
thing that it can be used for is and
this PhD students will agree that when
you are submitting homeworks you get the
same print principal you submit answer
you have a program you upload the
program you have to run it on the data
until the results okay thank you yep yep
curious why I just walk by the district
decision was made not to go to the fully
GUI interface you've got this command
line okay good all these all these
commands and their options the supposed
to wonder like kind of thing so so
nervous I think that's more for good
that I could have questioned the things
I really so we did some surveying just
to see what people are in your area
light and what came back like both so
like that there are some points in the
disciple of doing the research
development of the research for comment
lines much better than you know what
happens interface because to support
everything and make it really smooth and
has all the way the researchers what if
you have a come online as part of the
relevant
one you can actually add texas directly
observing potential and come on right
and by the way so this is still in
development and then you know ultimately
it will be also possible to actually
work there Mikey and insert text you
know the website but we are not there
yet so kind of between the two
absolutely
ok
is it a social aspect like if I have a
problem and data initiated with you yes
yes so the thing that I didn't mention
because I was not working on it how is
that so one of the aspects of worksheet
is after you have published a paper and
someone asks you for the code you can
just share the code bundle and also the
run bundle because that will give them
the environment in which you ran it and
what the result you get it is going on
Ranma o lightnin final response curve is
downloadable libraries they need or use
to us so yes so there are if you want to
rerun yes you need but if someone makes
shows that in the environment like of
course some of the packages you might
have to install it and they can mention
it but some of the other variables can
be set in the environment within the
bundle itself so you can set some of the
variables while running it
they want to emphasize that you know
like gordo rock is that my first week
when we started the internship said you
know this boot one two three and three
was kind of stretch goal three
worksheets and actually managed to five
but we're good at is to be new and
questioned about the cuddle up stuff so
suppose you make your worksheet
available to me you've done a full set
of experiments well code test data and
all that sort of thing and then let's
say I want to change just you know some
piece of code in the middle I want to
run some other piece of code you know a
new way of doing calibration or
something like that but I still want to
do everything you did to check the
calibration beforehand and then to
measure the quality of the calibration
after members and maybe compare on this
new data set to the other two methods
can I sort of easily insert my new piece
of code yes so still run your stuff and
then compare all of them somehow is so
uh or was it fork to a different thread
is it hard for me to get back onto your
path that you originally had so it
started off at as the bundle being
static lack after the run has results us
out like it cannot change it but now
current there are certain functions that
have just been added like two weeks ago
week ago which is like mimic which
basically does what you're saying so it
will mimic that on a new data or on a
new set up it will just make without
doing any change so yes
ok
okay thank you very much they just thank
are you there</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>