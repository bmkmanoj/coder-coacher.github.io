<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Cloud Devops - Paul Stack and Lynn Langit | Coder Coacher - Coaching Coders</title><meta content="Cloud Devops - Paul Stack and Lynn Langit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Cloud Devops - Paul Stack and Lynn Langit</b></h2><h5 class="post__date">2016-10-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lYgZZuwfRR8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">you got Michael hi Paul hello so and
this
the joint session I'm Paul stack this is
Lin Lang it I'm very very privileged to
actually be doing a cool present in
session with someone whose stuff i
follow really well so this is awesome
that's well thanks for doing this and
this is like a cloud DevOps talk we are
going to be building some cloud systems
it's mostly demos yeah yeah and so as we
go through it will hopefully just fire
lots of questions honest we may run
slightly over night because we're a
little bit late but just keep
interrupting me some questions as you go
and I don't work for anybody I work for
myself and I have an MVP from Google
Microsoft and Amazon and so I'd love to
give my opinion about things so feel
free to ask okay feel free to ask so I'm
gonna let you get started ya know we'll
switch in the middle cool and I do work
for someone but I'm still quite
opinionated okay and so the first of the
demos I'm going to do is just based on
his ear and he is your users in here
yeah so I'm just going to build some
basic compute examples in his ear I'm
going to use a tool called terraform
anyone know terraform some people some
people so I work for the company hash
Corp this code is written pre me working
for Hoshi Corp so this is not a best
practices way of doing it this is that
getting stuff done waived in it so there
we go so when you're writing some
terraform code tariffs on code has its
own DSL ok so because of the dsl that it
creates it's very simple to read and
it's not using large jason files so
those who use cloud formation you have
the json the content for the cloud
template and those again here using as
your resource manager also have the
Jason templates okay hash court decided
that maybe Jason wasn't the correct way
or the easiest way for developers to
have to write this type of code so
created small composable resources on
segment pieces of information called
resources and then that way they could
pass information between them and under
the hood it was taking care of it
terraform actually is based on graph
theory so terraform will actually
understand the graph and the order and
the operations
that the cloud providers need in order
to actually build the application so for
example I declare an azure resource
group so this is using the observed RM
the resource manager is not using on the
classic system so it's using the new
portal and the new features so
everything goes inside a resource group
we have some variable interpolation in
here so we pass in a location location
being like Southeast Asia Australia West
Australia east central us etc okay we
can then declare a virtual network pass
in a name address spaces again we're
passing in the location so that we can
understand and we can actually make it
unified through it but then on line 12
we're actually referencing the resource
group so this is helping terraform
understand how to build the graph we're
actually saying at this point this
virtual network is dependent on the
resource group declared above so this
variable interpolation syntax allows us
to be able to use the computed values
that are created as part of the resource
group and that come back from the API to
be used in other locations and i'll show
you when we go into AWS how that works
even more fine-tuned because there are a
lot of values that come back from the
API that you don't have to set but that
are very useful to be stored elsewhere
then we declare some subnets we declare
a storage account change the name of
that storage account because the other
one exists at the minute and
we have containers inside the storage
account and then lastly where we're
going to create some scale satin sheets
okay so scale sets in isere are the
equivalent of AWS auto scaling groups
for those who don't use them this allows
us to specify a number of machines and a
zero will keep the health at that level
of machines so if you drop one of the
machines or one of the machines days as
ural spin up a machine in its place so
now we start to get into some interest
and stuff we can have nested resources
or nested information as part of our
resources okay so we can have an sku so
the size of the machines we can have the
OS profile so like the admin username
admin password this is unfortunately one
of the areas of terraform suffers in
this is a plaintext password this is not
great there are current implementations
and current work on their way in order
to stop that high score does make a
secret store it's called vault and it's
fantastic terraform has currently no
integration resolved yes it currently
has no integration with it it is it is
in the works I know I know and there are
a number of tools that people have
actually written in order to solve this
problem so I'm a company called open
credo who are based in the UK have
written an encryption engine for
terraform so that as soon as you
actually run your terraform scripts and
it creates that the state file it will
encrypt your state file for you so it is
being worked on I'm we know that it's a
grave concern and it's something that a
lot of people even internally are
thinking hey we need to do something
about this pretty fast we have a network
profile then we actually going to store
some discs we're going in a zero when
you spin up a machine it's not like EBS
and AWS okay it actually will store the
disk as blobs in your storage account so
that you have to specify where you want
the machines to still in the blobs and
if you obviously need to delete the
blobs then the machines will disappear
or if you do delete the blobs and
machines will disappear which is not
fantastic and lastly we're going to use
1604 for this Ubuntu 1604 and see this
is obviously Z Neil this is the new
ubuntu that we can spin up I have
commented out for those when you go to
the website when you go and download the
source code for this there is windows
work in here as well spin up a scale set
of windows takes 30 minutes I don't have
time for that in this demo but you can
go and you can download the code and you
can try this out in your own storage
account and it should work ok it does
work ok should I say so inside terraform
we can run the command terraform plan
excuse me
tariffs on ply terraform plan will take
a snapshot of the state locally so it
will work out and draw the graph locally
and it will compare that graph against
what is in the cloud provider that it's
trying to manage and it will give you an
output eventually and it will tell you
what it's going to do and how many
pieces of information is going to change
it will give you the full output okay
you can go and have a look at it and see
whatever you want the nice thing about
this is because we have a graph we can
actually map the graph the graph allows
us to start to picture our
infrastructure so we can see how you do
it so I'm going to run the command
terraform graph which will give us a
load of garbage out this is of no use
whatsoever we can pipe that through a
package called thought on OS X or
there's other ones available in Windows
and we can save it as a PDF or a graph
or whatever so where I use this is every
time I make a change to my
infrastructure I save a snapshot of the
image so that I can see how it's changed
which is this is my living documentation
and as I make changes or adverse changes
I can quickly reference and say hey
what's different between these two
systems because it's very easy to look
at an image and say something's missing
or the dependency tree has disappeared
so therefore we can't talk and though we
can't talk to our story defend no is the
answer because the PDF I have not been
able to manage together excuse me and
I'll come back and I'll show you how to
create a delta output okay one second so
let's open the grass and we can see a
tiny little image okay this is a very
simple infrastructure and as we go into
the AWS one will be load a much more
complex infrastructure so the virtual
machine scale sets depend on both the
storage container on the subnet there is
no dependency between the subnet and the
storage container so they can be created
at the same time the storage container
depends on the storage account and the
subnet depends on the virtual network
again there's no dependency between them
so they're in different trees of the
graph and can be created at the same
time
everything is dependent on the resource
group so what this is telling you is
that the first thing to be created in
this entire infrastructure is the
resource group then we can create the
virtual machine in the storage account
then we can create the storage container
in the subnets and then lastly when all
of that is in place we can create the
skill set any questions on that awesome
so let's run it so I showed you the
tariff on plan okay terraform plan can
actually be saved as an output and
that's where you do your Delta's okay
because you're saving the plan of the
output and then you can actually compare
the plan against what the current state
is and that will actually show you what
the delt is so tariffs on a plane it's a
little slow on Azure because it's making
a lot of network requests under the hood
and like a lot somebody actually
benchmark this using charge proxy on an
airplane Wi-Fi and it made in the region
of about 2,000 requests in order to
build a skill set because they have to
register providers and there's a lot of
negotiate content negotiation going
backwards and forwards and AWS their
model is different so it's not i'm not
saying that this is worse but it's
different than how other clothes are
working but what you can see is its
created the storage account creation
complete then we can see it's creating a
virtual network at the same time it's
creating the storage account so they're
happening a parallel and you can see all
the computed values this is all
information that is available to us that
come back from the API once the creation
the virtual network is complete we can
start to create the sub math or yet the
subnet and lastly once the storage
account is complete we can start to
build and the containers and then
everything will kick in analyze they
build a virtual machine scale set so if
I go to the portal they're very awesome
as your portal does anybody use the
portal it's really tough it's really
hard and i love the scrolling right
you should read Lin's blog on this it's
fantastic so right now we can see that
there's a virtual network and we can see
that there's a storage account and if i
refresh you'll see their scale status
now you actually being built and we can
start to see that it's making its way
down through the system I'm really
hopeful this will work this work there
dear if it doesn't work now you can take
my word that it works so that's going to
take a little bit of time so we're going
to swap across the AWS okay just because
this will happen in the background for a
few minutes and then we'll mess around
by removing some things and we'll we'll
be able to see the deaths and what
terraform does it right there I think it
takes in the region of about three
minutes for that specific demo so
here we go so containers anyone use
containers few people containers are
ridiculously hot right now and everyone
wants to learn how to build container
architectures this is not serverless
okay I'm not building microservices I
have a really simple container there is
a HelloWorld container and your nextel
container and what we're going to do is
we're going to actually build an ecs
cluster we're going to create the ecs
service the task definition I'm going to
put it behind an ALB internally and
lastly we're going to actually have like
a discovery endpoint which ties the
whole thing together with a dynamic in
genetics conflict as proxy passed
through the system so there's a huge
amount of code in here right and we're
going to take it a little bit of a tight
at a time so that I can actually talk
you through this code is available so
don't worry about like digesting it all
night
here we go in order to use a double yes
you just got to change the provider
terraform ships with many providers on
the lid ok Google AWS and is your dance
simple VMware vCloud digitalocean joint
there's lots of cloud providers in there
ok you can go and you can experiment
with whatever you work in in your
day-to-day environment in fact if the
tool doesn't support with your provider
there's a video of mine online and honey
right a provider it's a shameless plug
and we are going to declare a data set
this is new 207 which was released
Wednesday morning and what this doesn't
says hey go off to my AWS account tell
me the availability zones that are
available to use within a specific
region the reason that this was created
was that in u.s. East one and AWS
different people with different kinds
we're getting different availability
zones okay because there are so many
availability zones I'm to use you can
actually only use three and Amazon will
randomly give you access to three of
them so we thought why don't we write a
tool that will allow you to go to the
cloud provider and tell you what
availabilities are available within your
account we have a really simple keeper
and then we have a VPC so we're going to
create a VPC that has a root cider block
10 0 0 0 0 / 16 the biggest cider block
that we can give okay it's got 65,000 IP
addresses in it we're not creating
65,000 services we're going to have to
private subnets and to public subnet
because it's in Sydney and the sibley
data center it only has to reach to
availability zone so we're going to just
use that now we are going to take the
lookup of the availability zones
available inside our account and we're
going to create our VPC across all of
those availability zones the data
sources lookup is new
but passing lists around within
terraform is 9 you so before we would
have had to take that we would have had
to actually convert it to a string
comment the limited string pass it is a
string and then in the and the other
side we would have to split it again by
comma in order to create our list so
that was kind of sucky so we thought
let's change it and let's I actually
pass I have support for passing around
lists all of this is wrapped up in a
module a module is a reusable piece of
code within terraform for those hair
developers think of it as like a third
party aap I like a library that you
download and you write code against and
we can go and have a look at one of the
modules so the VPC is probably there the
most complex that I have we have an
interface so it takes a name a cider
blocks and public subnets and private
subnets some availability zones it has
some outputs which we'll come back to in
a little bit we have a right we have
elastic ip's we have not gateways this
code looks a little bit more complex
because we're using a lot more
interpolation of the system we're
passing variables in so we have to
access the variables using things like
element and length and constant indexes
but because this is hidden away in the
module as a developer you may not care
in my last role as an infrastructure
engineer I used to write these modules
put them on our github at the company
and allow the developers to download
them as part of the module source and
they would just write them so the
developers only care about a VPC that
worked they didn't have to care too much
about the internals of the VPC and that
was very key it was really useful
because as an infrastructure engineer we
had a lot more power and a lot more
control about what they were building
yes it's completely abstract in a way
that the information and somebody asked
me before they were like wool a module
allowing me to be able to switch cloud
providers the answer is pretty much yes
okay if you can come up with a naming
scheme a proper name and convention
between the in the module that is
generic enough among cloud providers you
can have a VPC and the equivalent in the
azure being a resource or a resource
group sorry if you can create some
generically named parameters as an
infrastructure engineer you can change
it onto the hood and as you know if your
company has decided to go all amazon or
all zero or change from one to the other
the developers again don't need to care
they just need something that works and
someone that they can test their systems
so back to the rest of it we're going to
have a am i okay that's Amazon's machine
image so we're going to use a pre-baked
Amazon machine image in order to spend
up for it I'm our ecs cluster ok this is
the cluster of machines in which we're
going to deploy our docker images or doc
reserves ok we use the am I we give it a
cluster name we give it some specific
size and an instance type and then we
can actually say hey look I want to
create this ecs cluster in the VPC that
I have declared above so the data that
is coming back the ID so if you go to
Amazon you'll get an ID like VPC dash 1
2 3 4 5 6 7 you can get that information
back and you can supply it to the next
module down the tree in order to build
that tree and say hey take it and build
it in that system we're going to create
a bastion know just because in case
anything goes wrong we can ssh in and we
can have a look around and then we're
going to create a service this is where
we get into the real meat of building
our application itself for those who
have looked at ecs services you got to
do all sorts like build Jason templates
and task definitions I thought it would
be really good to be able to abstract
than away okay I don't want people to
have to create Jason I will create a
template that will but they can plug
values into and the Jason will be
created for them so the first thing is a
service we want one instance of our
service it's going to go in the cluster
we created above and it's going to have
the I amaral so the access and identity
from the cluster that we created above
know the access and identities I'm not
going to go into because that could be a
whole talk in itself what it allows us
to do is to say hey this user or this
service has access to launch and
instance within the cluster in a
nutshell we're going to create a service
a task definition called demo service
and it's going to use the engine X
docker container which is just freely
available on the docker hub we're going
to give it a little bit of memory and
support and then lastly we're going to
give it a knee lb
if you have one or more darker services
or ecs services in the system because
they're dynamic you want to be able to
hit those and you want them to be able
to to take care of the health checks for
you so we're going to put them behind
small elb and everything will be able to
be tunneled through the lv we're going
to take the output of that address just
so everyone can see it on the screen
we're going to build a dynamic and your
next config this is like I'm going to
say this is quite hockey but this works
perfectly okay so if you have like 20
services and you want to build a frump
entry point into your entire application
because everything is hidden away in
private subnets you don't want to expose
all those addresses you want a single
entry point into your system so we build
a really simple engine X config where we
can say listen on port whatever the
server name is whatever we want and then
the location of this URL when we hit the
endpoint / will call it Sidney we're
going to go to the Sydney elb address
when we go to foo will go to the fruit
lb address and so on and so forth but
because this is all using interpolation
we can take the outputs of all the lbs
that are created I'm dynamically build
our engine X conflict and inject it into
our services there's a question I knew
there was gonna be a question here they
do they do um this is not me trying to
sell how she caught up tools at all okay
and as I say this code was all written
premium hockey for the point of this
demo right now is to show you that with
a little bit of code and a little bit of
simplicity you can start to take
advantage of using container services if
you want to go and install like a three
node cluster of a service discovery tool
then that's great because there's a lot
of code out there and do it but a lot of
people will look at it and think if
that's a real big overhead and they may
not want to do that and then the last
part of it is we have a discovery module
discovery modules spins up some machines
and elb injects they end your next
conflict into so there's a lot of
different pieces of code here
let's have a look at what it does Tara
phone plan you'll see this should be
quicker it is much
yes your one worked I'm actually quite
surprised I'm not really surprised we're
going to let that plan in the background
for a few minutes i'm going to show the
easier stuff quickly then if i refresh i
can go and have a look at what's in the
scale set and we can actually see that
there are some themes running way ok so
likes a really simple declarative code
like really simple code we are actually
able to start building a very simplified
infrastructure you can make this as
complex as you want you really can and
what i can do is i can actually start
going and go hey let's remove this
virtual network oh I don't want to
delete the resource group that would not
be fun
this is one of the problems of the
portal you can delete some things but
you can't delete others settings we're
going to pretend that that works the
portal is quite complicated for some of
these what I wanted to do is I actually
delete one of these machines but you
can't delete one of the machines from
the console this is a new feature by the
way this rigid released six weeks ago
when you created a virtual machine scale
set if you wanted to see the machines
that was in it it lias your
documentation actually told you to go to
the CLI and want to see a like a month
there was no way of being able to see
them in the console so let's leave a
zero behind and you can see that there's
a lot of provider support in there for
all different things here's our plan for
our service discovery and our our our
ecs cluster okay we can see that it's
going to add 40 pieces of information so
tariffs on apply and while that's
running
i'm going to show you the graph of this
the graph starts to become a lot more
complicated okay there's a lot of
information and a lot of pieces of the
puzzle right now okay because we're
using things like I am and we're using
subnets and we're using subnet
associations and we're using right
tables and we've got all of this
information but effectively its drawing
us a complete picture of the order in
which of operations okay anything along
the same level can all be created at the
same time the lower done the more
dependency it has so it starts at the
bottom it works at way up and all the
pieces of the system at the top level
are all the pieces of the information
that we require this is not the most
complex graph I have seen some of these
graphs are ridiculous like the more
network infrastructure that you manage
I'm the more pieces of the clothes that
you manage the more information that you
can get ok I'm going to include the
graph in the github repo just so that
people can see them just because they're
quite useful to see and I'll drop in and
the readme some the commands in which to
do it and what packages are available
but this is really quick this is like
creating ridiculously fast wow it's
going faster than I can hold up so as
part of the as part of the install when
it spins up the bastion node ok so the
node in which we can ssh into and then
go all around inside our VPC we want it
to run some remote exact okay it's in an
Amazon Linux image okay amazon Linux is
usually very good at keeping up with the
latest packages and the security updates
so what I want to do is just threw out
the equivalent of like a young update
okay just to make sure everything is
work and it'll excuse me all the package
sources are all available so it will
terraform as when it spins it up we'll
wait for the machine to spin up it will
use the credentials that you have told
it to and it will connect to that
machine via SSH and run any remote exec
commands that you want so this is where
you can do like your chef Ron's or your
puppet runs or your ansible runs
whatever you feel and it will take care
of helping to provision your machine for
you
let me go and clean that up quickly this
is because I just tested this stupid
thing
this is just a showy that errors can't
happen let's delete those quickly there
we go so terraform has saved partial
state here okay it doesn't have to go
back to the start and redo everything
because it remembers that it has already
created the VPC it has already created
the bastion box it has already created
the ecs cluster know what it's doing is
it's going to refresh the state of
everything and it's going to say okay
where have I got to make the changes to
bring the environment up to the same
configuration and it'll continue just
turn in its way through any questions so
far oh good question where does it save
the state so right now it saves the
state locally okay because I haven't
done anything else with it there are
many options in which you can save your
state to for example s3 buckets is your
blobs Google compute engine atlas I'm
hoping I've heard rumors that someone is
opening a PR that you can store your
state in fault just because it's
actually sensitive information it would
be really great so I stored in there but
artifactory is another one so people
create their own endpoints it's just
basically put and get in order to store
the state on when it's finished or when
it's just about to make a plan but the
nice thing about it is is that by
storing the state remotely more than one
person can share that state because
right now if Flynn run the same commands
that I was going to run and didn't have
the state it would try and recreate
everything again and it would basically
fall apart because you would create two
V pcs with the same name in the same
site or blog so if you're going to use
it in a team for definite you must store
it remotely and Esther if you're an AWS
an s3 bucket that's version and
encrypted is probably the best thing to
do and it's very simple configuration to
do that it's on the website and you can
have a look right it's working its way
through right now
that's going to have a look at what it's
doing so we have a demo cluster and
they're currently some instances being
spun up in that demo cluster it takes a
little minute just for them to spin up
and actually register themselves so we
have a bastion node we have a discovery
instance we have an ecs cluster instance
and you can see that the ecs cluster
instance is still initializing so that's
why it's not part of the cluster right
now hopefully it'll kick in very shortly
come on
it's thinking about it I promise you
on ecs an instance for an ecs cluster is
effectively a machine at just a tiny
instant and it has a darker agent
running on it and you inject the name of
the cluster and it goes off in searches
inside the system each of the nodes in
order to form a cluster okay so this is
Amazon's way of doing it and it would
seems they work quite well there we go
we have a registered container which is
awesome so now we're actually going to
start getting the service don't worry
about that that's my fault I'm
refreshing to quickly so it's trying
actually um it thinks that it's
available because it's making an HTTP
request an orderly work out where it's
at
I have like four minutes of this left I
promise you and then you can get
somebody's going to show you something
else
you can have a look at the state
actually why this is happening just so
you can see what it's doing so it holds
the version of terraform it holds all
the information that you want you can
mark variables is sensitive if they're
marked is sensitive it won't store the
the actual value in the state file this
is very new usually get hard coded
passwords stored in your state file and
when people were checking their state
files in the github and public repos you
could search them the minds of people
who check stuff in the public repos and
github is amazing it really is so please
take care of this type of stuff we have
a demo lb address we have a discovery
address and then it starts to register
all the all the resources that we have
all the availability zones etc
everything is there ok so we should
actually have a service right hi
hopefully come on service
it's really thinking hard about this
service
this is very strange
please don't fail
I'm currently getting two and a half
kilobytes a second
any questions where this is running
anyone just want me to get on with it
hi this is bizarre this is actually not
creating the service for some strange
reason but you can see that it's
actually trying to create the task
definition the service I don't know why
it's not but it seems to be stuck in a
lip trying to create it right now oh
there we go home excellent so we have a
service I actually surprised me that one
and if you go inside the service you can
see that it's we want one instance of
the service so it's currently trying to
spin up an instance of that service it's
some this is like autoscaler but for
your darker containers so you tell it
how many instances it needs and it keeps
them running you don't need to care
about this which is awesome and we
actually have a finished product so the
last thing is we have a discovery
endpoint terraformers by the way
terraform has outputs that you can
actually put some very cool information
into ok so for example I'm actually
telling the user if they need to buy SSH
into the bastion it's it's SSH ec two
dashes are at so you can use variable
interpolation and formatting and strings
in order to give really good information
and helpful information for the users
but so this is like the top level page
ok but if we go to slash Sydney we're
actually going to go through and proxy
to another engine next page which you'll
say the same thing damn it yeah so what
attack suppose it's a simple proxy past
let me show you what they stupid let me
show you what the launch conflict does
right here and we can I'll debug it
before i give you the repo name that's
so funny
so the user data that we're injected or
just in an install of engine X and we're
just echo night some configuration and
that's what it is right there it's
because I have an equal sign in there
rather than anything else so my engineer
configuration is incorrect and therefore
the proxy the proxy pass won't work but
we'll just inject the knot in and saving
it as like an engine X conflict so every
time you add a new service terraform
will regenerate that engine X conflict
and inject that in for your user data so
that when you boot it allow you to
create as many services as you want I
have one on my machine that I can show
you at the end I can't chill on camera
but there's currently 15 services on it
and you can see how it builds the full
tree for the engine X conflict and with
that i'm just going to pass it over to
limp any questions before i go on ecs
excellent these guys are going to switch
right but can you physically put it oh
yeah yeah so as he's doing that one of
things I always do when I come to a new
location is I test the speed of the
cloud and so I did some research before
I came over and what I found is that
your co-working space fish burners he
has her fish burners was supposedly had
the fastest cloud in Sydney so what I
did is I went over to fish burners last
Friday and I tested the cloud and for
this particular scenario just have to
mention that the fast strangely appear
to be in Sydney it was using the google
implementation with the data center in
singapore so google is the inventor of
the container technology and what I find
when I travel to different locations is
if there's not a data center in the
country the cloud provider kind of tends
to be ignored and in some cases that's
valid but i would tell you based on my
own testing if i were setting up a
cloud-based environment here i would
certainly look at google in terms of the
scenario that Paul showed I think it was
kind of proved out terms of straight up
speed a sure was by far the slowest
amazon was in the middle and google was
on top speed isn't always the only
concern but that was kind of the case
with
now for mine my my talks are very much
of a contrast to Paul's my scenario
comes out of my work as an architect and
I do a lot of bake-offs and the
uncracked that's the name of our talk
and the Bake off's are often enterprise
I work with both startups and enterprise
and I'm gonna take a very old-school
scenario which is data warehouse and I'm
going to show using the vendor tools in
this case amazon so none of the fancy
you know third-party tools which are all
good and great and very useful but I
think it provides like a contrast to
show what can you get with the vendor
tools so the scenario that i'm going to
show is a data warehouse and this comes
out of my own work just setting up data
warehouses in reality and i did this as
a workshop at reinvent last year setting
up a data warehouse in two hours just as
an aside if you you might not be aware
of this but the redshift product which
is the it's a MPP massively parallel
postgres implementation is the fastest
growing product in the history of amazon
so I'm not the only person that likes
the product it's a thousand bucks a
terabyte yeah which is just stunning so
it not so much this last year this last
shows doing Lana IOT but in the 23 years
previous nearly a hundred percent I set
up redshift data warehouses at customers
because almost everybody could have a
good use for it it's just really really
simple so the things that are different
in my demo is number one I recorded it
because I didn't want to rely on the
Wi-Fi for loading an actual data
warehouse that just seemed kind of crazy
and number 2 i'm showing using pre-baked
am is that allow you to rant vendor
services that load the data warehouse
and visualize the data warehouse so ETL
tools and visualization tools so in the
one that i did in vegas i use tableau
for the visualization but i got to know
the guys from yellowfin who are actually
local here in Australia so I did this
this implementation with yellowfin for
the visualization tool and the load tool
i worked with mattila an ETL which is a
small company in the UK that was a
consulting firm doing redshift and they
didn't find like an ssis type thing for
red shift so they built one it's an ec2
instance and i actually discovered them
i did some work with amazon on the
different
vendors in the marketplace and brought
them to the show and they won best of
show last year so it's kind of cool
right i mean feel kind of good about it
so matil Ian's really solid product
there's other ones out there so what I'm
going to do is I'm going to play my
recording and kind of talk through it a
little bit and then I'm going to talk
about the process for building up
scripts using the CLI scripts and some
of the tools that I use I wrote all this
in scripts it's in github so you can see
it and then I'm going to show using
cloud formation which is the Amazon tool
that generates the entire solution
formation in JSON file and you can check
it in and check it out does it make
sense so that's what I'm going to try to
work on here and I have all my resources
published everything is on my blog which
is Lin Lang get calm so if you're hungry
you can just leave now and go watch out
everything there so ah okay and you know
one of the things probably does anybody
in here use the amazon marketplace yeah
i did some work with them it was really
interesting and azure and google are
coming along there but amazon has really
got a lead on them in that they are
understanding working with the partner
so obviously that's the console and
there's the marketplace and what this is
is just a marketplace of am is and how
this is useful in cod DevOps is if
you're trying out versions of products
so let's say you're on tableau or
something and you want to go to the next
tableau go here grab this particular am
I as when Paul was showing his am I for
his engine X this is an am I as well but
it is an ami that is optimized by the
vendor so this is just it's like a huge
tip basically when you're using this
stuff and then you can go in and you can
see on a manual launch you go to your
particular region and then this is the
like for Sydney this is the particular
am I that we're launching and this just
launches an ec2 instance so and there
are literally two thousand products in
the amazon marketplace and this is a
really active area of development around
some of their newer technologies like
serverless and IOT so there's going to
be other you know solutions inside of
here so it's not really a sort of
additional dev ops ii scripty kind of
thing but it really does help because
they have configuration information they
have pricing you're basically renting
this and you can get up and going really
really quickly so let me just start the
video here I can get that going see
that's the scenario basically and all
right so I'll just start talking through
it so i'm going to show you what this
looks like in the console everything
that I'm doing can be done in Sydney I
think it's really important to show
people in a geography things that you
can actually do on the cloud in that
geography it must be really frustrating
to see services that you can't use I
know I was in one demo and I was trying
to localize it and the products weren't
available so we're going to use red
shift and we're going to use s3 we're
going to first set up our im's so I am
is the most particularly incorrectly
done area that I see on a consistent
basis and as Paul said if you're going
to go on the Amazon Cloud you really
really need to properly understand your
IM security I am NOT a security expert I
have yet to find in three years of
customer who has it set up correctly
it's quite scary actually like he was
talking about people checking in their
keys and everything so this is a policy
a document and these are users and roles
again I see people doing policies with
stars in them all the time so all
resources just real obvious things so in
the best possible world you're going to
want to have security training and the
security audit so once you do that then
you need your key pairs those need to be
properly secured like Paul was saying
very very important I see these you know
copied all the developers all the time
you're going to want to associate some
elastic IP addresses those are your
public IPS you pay for those in Amazon
if they're allocated but not associated
and then you want to set up your VP sees
this is very similar again just setting
up your infrastructure to set up the
data warehousing scenario and properly
restricting the last production and
situation i'm in which is an IOT we
actually had five days of security
training and then we're going to come
and have security audit I would tell you
particularly around data scenarios and
most particularly around IOT they're
actually becoming
targets somebody put up a redshift
instance in that environment and didn't
properly protect it through the security
groups and it was hacked within two
hours yeah bitcoins so really really
important so this is just showing your
security groups which is basically a
firewall your inbound or outbound rules
so my take on this assuming most of you
are developers although might be some
develops people in here sorry developers
is not a part-time job this is a
full-time job and I should not be able
to hack all these amazon sites you know
I'm a suburban mom who started computing
in middle age Jenna mean people who are
really serious are going to are going to
do bad things so you know these are all
the all the things that you're going to
be setting up all your security groups
so this is the infrastructure before you
start you need your v pcs now I'm going
over to the marketplace I'm grabbing the
material image for Australia reading the
security setup which is just a single
ec2 image but you can scale it just like
you know SS is on sequel where you can
have partition the distribution into
your data warehouse and you can use a
this gives you a recommendations around
the proper size instance to in the
proper type which is also something i
see done wrong in a lot of data
scenarios people we use the wrong type
of ec2 image and have really crappy
performance this is all recommended by
the vendor so it can save you a lot of
time so this is showing the setup ec2
and then you have a public IP which you
associate once you're properly secured
so you don't end up having somebody
Bitcoin mine and your proper security
notice its associated to security groups
then this is what metalia looks like so
it's a GUI based interface again it's
been a real time-saver the first
redshift that I worked with I wrote all
the scripts to load everything and that
generates a JSON output which can be
checked in this configuration as well so
now I'm going over to set up my redshift
instance which again if you're not
familiar it's a equivalent of similar to
sequel Azure data warehouse sequel Azure
data warehouse went GA two weeks ago I
did take a look at it in preparation for
this talk it looks like a good product
the reason I didn't include it is
because redshift has been a market for
three years and I would need to do more
testing before I can feel comfortable it
looks looks good though for Microsoft I
mean looks good good just an from a
google standpoint while this is coming
up I will use a product called bigquery
sometimes which is literally sequel
query as a service they abstract away
the server implementation a lot of
people kind of get freaked out by it
because you have no control over the
server of those servers underneath at
all you literally just put in a sequel
query that you have to upload your data
to Google but I do use that as well and
it's a very good product so this is just
showing where I'm going to put my
templates in my bucket for cloud former
and inside of here I know where am I
going I'm going going back to metalia so
I'm going to show a bit about mattila in
here so you just get to the public IP
address properly secured to your you
know so only you can connect matil ians
very sophisticated its redshift native
it will automatically detect your
redshift instances which is really cool
once you have the proper security setup
very easy to use it's really a beautiful
product it was really cool it's really
cool to discover a great product and
help people become successful do you
know I mean it was really kind of a neat
thing so they have the the configuration
components and then they have the
transformation components and their
smart components they're also extensible
so they're going to create a developer
marketplace so if you guys are really
into this and you wanted to like cell
components because they're real
doing quite well very usable nice
interface very much like a atl tool i'm
assuming most you know SS is so very
similar to ssis and the guys have a
sequel server background so they kind of
built it in mind but it is a redshift
aware which again helps you like red
shift has the way that you loaded as
important around sort and distribution
keys because it sets up the proper
Fanning of the data and this product is
aware of that so it's just showing you
some of the transformations and you can
change jobs its transactional it's
pretty pretty cool product and again i'm
not i don't work for Mattel Ian it's
just I happen to use this one I'd use
talent on here one of the cool things
about this type of scenario is you can
spin up and spin down using the
marketplace and you can do bake off's
you know I mean I do that really really
frequently with customers and to be
inclusive Azure and Google Cloud have
marketplaces and they are growing them
they're just not as you know don't have
2,000 people in there so this is just
going on a bit it's showing now they're
integrating with not only amazon
services but i think you can do twitter
and facebook and everything else in here
so let me just skip this up a little bit
because it's kind of a lot of material
all right they're showing you the
credentials and again you can version
this is a JSON so its configuration you
can bring it in bring it out let me skip
up a little bit more skip up you can
sample your data there's the admin thing
okay so now this is yellowfin so
probably most of you guys use a tableau
in here that's the most common thing or
power bi this is similar to a power bi
it happen to be based in Melbourne so I
thought I would try to help the local
company they're good solid guys same
thing you just do an am i and bring it
on up really quick follow their
instructions connect and so I'm going to
skip up just a little bit here ec2
blahdy blahdy blah and then you have
this beautiful dashboard that's
drillable embeddable so on and so forth
and I mean you will impress your boss if
you set up an end
data warehouse in two hours you will you
will I worked with one company in the
middle of the United States they had
been trying to write scripts and do all
the stuff manually and we literally did
it in two days and the guy got promoted
like I'm not making it up it was great
so it's all good and this just shows how
it connects natively because of the
popularity of redshift there are a
number of visualization partners that
just collect connect natively and will
be cognizant of the aggregates and all
the things the redshift does and just
can allow you to produce beautiful
dashboards really quick like so that's
kind of the snare so I know we want to
do some of the dev ops ii stuff here so
let's kind of go up through that so now
that goes all the way up to you thurs
your there's your end to end okay that's
how it looks this is cloud formation so
I'm assuming most people in here have
not seen this anybody seen this before
well of course right okay of course so
this is a tool that's included with
Amazon and this is the cloud formation
designer which although looks like it
might be kind of great i'm going to say
on the video is very hard to use okay
it's very hard to use so i hope the team
continues to take the usability feedback
what it allows you to do is it drag you
drag items on and you can model what i
realistically do is I build and i do
what i did in here I hand build my
environment and then i use a
CloudFormation template that spins up a
tool that captures your current
environment and creates a JSON template
that you can then use that is how I
actually do it what I wish I could do I
wish I could comfortably just drag on
here in model like an architect but I
just the usability is a little bit
clunky I don't know if you find it that
way too yeah so so anyway so this is the
output of what it looks like so the tool
is actually a CloudFormation template
it's an ec2 instance it's a website so
you go to cloud formation the first time
and you don't have anything spun up you
say I want to spin up this wizard
basically and that's what it looks like
and it's a stack so the Amazon stack if
you will and then you go here and it
goes to a website
and you just click through and you say
what do you want to capture from the
current infrastructure and that's how
you generate the template so it's not
super sophisticated because you know
it's included it's free but it is usable
right and it's a basis for working with
Amazon configuration as code and I don't
know do you ever use this as a basis for
your stuff or you don't use it anymore
yeah you move kind of beyond it yeah
yeah but when you're just getting
started yeah it's a good way to start
right because you can check in your JSON
code and you can dip it like some of you
guys were talking about to dip your
environments now I actually don't know
in Azure how this works I assume there'd
be something with powershell and with
Google they are still coming along with
this so you know my experience is more
in the amazon world but it's just my
lack of working with azure at a as an
automated level something I need to kind
of probably take a look at so you can
see just click through and you just say
what do you want what do you want what
you want and then when you get to the
end it gives you a JSON template and
that is something that is executable and
difficult does it make sense okay so
that being said I'm just going to skip
up there is your template and you know
there they've got the sample templates
inside of it and there if you want to
open your template so I made a template
of the existing environment and then I'm
just going to open the template and
that's how I loaded that picture up does
it make sense I'm not as fancy with my
scripting is this fine gentleman but you
know mine is more I don't know replicate
able well it ok mr. it does have a
template behind it yeah yeah yeah so in
addition to that I made a bunch of and I
think I'll just skip over to here I made
a bunch of scripts and because you know
kind of in the old fashion world we
script so I checked all the sin and you
know this is kind of the world that I'm
in with the enterprise where I'm
teaching them cloud former and
evaluating tools so we are doing a lot
of scripting for DevOps automation so I
wanted to show you a tool that
I just really love for Amazon that is
amazon has a labs a github site so it's
on amazon labs so you have the regular
CLI but if you go AWS shell it's just
one of those little things that makes
your life so nice because it has
autocomplete and you can just say you
know whatever it is you want to do like
allocate hosts and it you know it helps
you write and because like you're
spending a lot of time writing these
scripts and this this is my like tool of
the day it's a very simple thing but it
really helps me to more quickly write
CLI scripts and so when I was developing
my scripts i use this pretty extensively
I don't know how great it works on a
Windows machine because I don't have a
windows machine and somebody at work had
a problem with it but you know it works
pretty seamlessly seamlessly on here so
in any case honestly that's really the
majority of what I had to present i'm
trying to think if there's anything else
I want to talk about I really wanted to
leave a little bit of time for questions
because like I said I do have this
unique perspective of I work with all
three cloud vendors realistically and
you know you can get my opinion on that
good do you see anyone that's jewel or
try hosting would like so do you see
anyone that's hosting in as you are same
thing you know okay aimers customers you
don't have to say names when I'm just
interested yeah yeah and the experience
it yes I do yes so what I see and this
is in the outs of the hot startups in
what's called silicon beach because I
live in LA and so there's a there's a
start-up sort of area north of the
airport there that Google has moved to a
lot of people are moving from Silicon
Valley because the rents are too
expensive so Google Facebook Microsoft
whole bunch more so I see people will be
on amazon and then they will add Google
services for big data Google bigquery is
a really powerful service it literally
is query as a service it almost scares
people because it's a query window you
type in a sequel query and bam you can
just process you know
dream amounts of data so that's the
biggest one that I'm seeing now Google
has added they hired Nikhil who built
some of the SSI as stuff in Microsoft
and they built a dataflow pipeline but
it's all there's no visual aspect to it
you have to write code and so you have
to be a pretty hardcore programmer to
write all your components yeah I know
present company right but I'm seeing
people do that because the Google Data
Services are really really cheap google
cloud in general is super cheap to use
but difficult to use you have to have
two high level programmer jobs and their
documentation is utter crap and they
don't maintain it and it makes it very
very difficult and they're aware but
they don't seem to fix it right but
personally I use the Google cloud for
all of my projects because it's the
fastest they pre-warm their VMs I did
some perf testing for aerospike which is
a Redis competitor and I just like I got
it's like when you fly first class I
can't tolerate latency on VMS anymore
because Google's VMs or GC EVMs and
their containers are pre-warmed so they
come up in milliseconds milliseconds the
fastest VMs for windows are on google
cloud engine Google compute engine
probably they don't they don't release
the implementation so so the other thing
that's really interesting is I think the
data Wars and cloud are not about
storage i think storage and now even
compute with serverless are becoming
lost leaders and I think the wars are
around that value added data services
data warehousing and really the hottest
house places machine learning and what's
really interesting to me is how the
three vendors have had three different
approaches to machine learning so Amazon
is kind of the the everyman like I'm a
developer and I just want regression or
classification because clustering is too
much for me you know what I mean and I'm
that person so I've used Amazon machine
learning it's very like just let's get
it done okay Microsoft has the well you
have to hire a team of data scientists
because you're the
enterprise and that's how you do things
right which that has applicability to
because they're ml for data scientists
is really really powerful but I think
you have to be a working data scientist
to actually get value out of it what has
been super interesting is how google has
slowly started releasing their ml as a
service that's that's pushed by vertical
this is very quiet their speech API
their vision API their sentiment API
they kick butt they kick butt I was
talking to a guy last night he's doing a
translation app for local people or
something like that and I said Google
would probably want to work with you in
the translation API because they're very
they know they're very interested in
this particular space and of course
they're very good at it they've been
doing it for years so to me it's it's
the really super exciting time to work
in the cloud and my take on DevOps is
utilizing what the vendors have to be
able to spin up and spin down proofs of
concept very quickly which is a very
architectural focus but there's so many
new services that if you can quickly
compare and try them out you can really
be providing value to your customers in
your company so it's a little bit
different and that's why Paul and I
decided to team up because you know to
me he's the day in day out the better
work don't call me at 2am kind of guy
right and I'm the witch new fancy shiny
things should you buy right and there's
DevOps and both parts so I think that's
what we were trying to convey pretty
much so that's that's really all I have
we gone over time a little bit do you
guys have any questions yep okay let's
say you haven't startup and I the most
important things for you is the speed
and the cost yeah and simplicity so
which one of three that you say do you
have a Python developers know what kind
of developers you have I just thought
the developers are do the dotnet
developers want to work in c-sharp or
are they open to node and so many other
things they're open to know that's all
okay so what is the volume of the the
business is it going to be at you know
terabytes of data or me
bytes of data uh it's gonna be a
terabytes but it's not that much i think
the e-commerce so yes just i don't i
probably gonna sure i probably long as
ur because tooling integration language
integration you're going to get up
faster i would do the startup program
really push your vendors on their
startup programs i don't know how they
work in australia but in u.s. google's
coming out really aggressively you can
get three hundred thousand US dollars
credit amazon i think is a hundred
thousand but i could be wrong that's
they keep upping it do you know to mean
so really push your vendors so that you
get the services free for at least the
first year and maybe beyond that the
advantage to google would be a lower
cost ultimately microsoft i think is
still ultimately the highest cost
although they're they're addressing that
for the services but there's also a cost
of course for the developers right and
so microsoft if you're a dot net
developer that's the lowest cost because
you have tooling integration and
language integration and those things
matter right so so i probably start on
azure and maybe do a bake off with
google just to kind of kind of see
because google is the total opposite
side do you know cool thanks yeah
anything else alright we guys thanks for
hanging in hopefully it was worthwhile
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>