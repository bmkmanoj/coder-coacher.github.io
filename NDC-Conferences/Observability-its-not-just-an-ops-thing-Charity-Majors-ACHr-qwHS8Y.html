<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Observability: it's not just an ops thing - Charity Majors | Coder Coacher - Coaching Coders</title><meta content="Observability: it's not just an ops thing - Charity Majors - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Observability: it's not just an ops thing - Charity Majors</b></h2><h5 class="post__date">2018-02-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ACHr-qwHS8Y" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">I swear to God the hardest problem in
computer science is audio-visual
technology hi it's very bright up here
I can't believe it there are people here
it's like Friday and you guys should be
drinking what the hell are you doing
well welcome to my session on
observability and it's not just an ops
thing how many of you self-identify as
software engineering humans sweet how
many of you identify as operations not
me oh good perfect
well I come from operations I've been a
software engineer I've been a DBA I have
an engineering manager currently the
co-founder and CEO of a company but my
heart always belongs to operations
because I feel like that's where
computer science meets reality and
that's where I like to sit this is this
informs how I feel about software code
is fine but code and my experience
causes problems and I don't like
problems
I like the way my friend PVH puts it is
the best code is no code at all
second best code is code someone else
writes and supports but you get to use
and read and the third best is literally
anything else so and I have a new book
out database reliability engineering and
if any of you happen to have it I have
so you notice there's a horse you're not
allowed to have mythical creatures as
you're a Riley book cover and we wanted
to unicorn so we made a horse and I have
stickers that will make it into a
unicorn for you so see me after class
highly recommend you can also put it on
your laptop it's very cute so I've been
doing ops I've been on call since I was
17
half my life Jesus Christ but I've never
really liked monitoring it always felt
to me like you know after the fact clean
up I don't think visually I don't really
think I don't I don't know I'd rather
just said no Hawking like anything with
with pipes I don't I have a hard time
going from here's the problem here's the
solution now draw a pretty picture of it
that's probably why my design aesthetic
is so subtle I hate matter I love
debugging like I love any day that I get
to justify launching s trace it's like a
good day to be alive I also love
firefighting but I will usually denial
while I'm sober and honeycomb is not a
monitoring company people people talk
like we are all the time but it's um
it's really not how we see ourselves
this is not a monitoring talk a couple
years ago at monodrama crepper he said
monitoring is dead and I love hyperbolic
statement so I'm gonna make a bunch put
a little asterisk there and your mind is
like she doesn't really completely
believe this it's contextual blah blah
but that's not as fun it's just like
planting your flag right monitoring is
dead
you heard it here monitoring is dead
it's whatever
modern systems has not changed
significantly in 20 years and is falling
behind the way that we build software
our software of now large attributed
systems made up of many non-uniform
interacting components or the core
functionality of monitoring systems has
stagnated this is super true how many
different architectural paradigms have
come and gone in the last 20 years boo
boo bunch like I can think of three or
four or five depending on how you're
gonna define them and yet we still have
this model of I'm going to look at this
system predict how it will fail write
some checks and done right
and that's that's been okay like we've
gotten pretty far with it and I don't I
genuinely don't mean to on all of
the wonderful companies and tools out
there that are doing this like they have
matured they have improved they have
gotten better but they fundamentally
answer known unknowns right if you have
a question they will answer it like real
fast for the past couple of years I feel
like my experience has not been that the
problem that mine
my issue is with known unknowns it's
with things were like well I've got a
few problem reports some of them might
be reliable some of them definitely
aren't that one is reliable but hmm I'm
suspicious that we they're describing
actually could it be a problem because
of this thing that I'm aware of over
here you know they could be correlated
they could all be part of a master plan
or they could have nothing once if I
knew what the question was I
could answer it
you know the entire problem is what is
the question these are clearly unknown
unknowns these are not ones where you're
picking for fun going oh that again you
know that again it's more like what and
for one last time that was not what
dominated field God know I'm cursing my
out of order nice because it's a
beautiful diagram whatever we'll get to
it later just mentally bookmark this
anyway if let's take monitoring to mean
this for the purposes of this talk it's
the action of observing and checking the
behaviors and outputs of the system and
its components over time how many of you
are on call ever been an on-call
rotation okay cool
as you know it has basically no longer
practically possible to curate and tend
to the vast volume of paging alerts that
we have started generating for ourselves
and this is why nobody wants to be on
call and I don't blame you it's
terrible
it burns out your systems it doesn't
make your it doesn't it burns out your
humans and it doesn't make your systems
better generating lots of alerts is an
outdated pattern as an outdated model so
now let's talk about observability and
if you look at Wikipedia it will tell
you that you know it comes from your
control theory if you ask Twitter it's a
marketing term that I made up to sell
software well I didn't make it up it is
I do use it for technical marketing
thank you very much
observability is very much about the
unknown unknowns it's about giving
yourself all all of the components all
the low-level primitives that you need
to answer any question that comes up not
just the ones that you could predict or
the ones that you've experienced before
and you're able to write a check for
right it's about being able to reason
about the insides of your very complex
system and and understand anything
that's happening without having to go
and run s trace or attach gdb and and
like when people complain about having a
new term I think it's important to
realize that it's it's because we have
20 years of best practices built up for
monitoring that are really robust and
they work really well and they're often
diametrically opposed from the best
practices you have for observability you
want two words because there are two
different practices now obviously both
practices can coexist in the same people
the same team the same companies even
the same tools can be used from both
purposes but it's very distinct for
example best practice and monitoring is
you should not have to stare at graphs
all day the system should inform you
when there's a problem legit super legit
but monitoring is highly biased towards
alerts and actionable words every time
you get paged another best practice it
should be actionable so that's cool but
like a lot of the times I'm if I want to
understand something I don't want you to
work for it it's not necessarily bad you
know I just want to understand it I want
to make a decision about what software I
wanted a right or
or you know validate a hypothesis so oh
yes many of the fun tweets that people
have been yammering about I invented it
no I invented it I saw it first and you
saw my talk whatever uh anyway this
brings me to my own personal definition
this is my spirit animal i I think that
observability is very much the software
engineers and this is why this room
should care right that we monitor his to
operations and I say this like kicking
myself a little because we have spent
the last decade telling people
monitoring is not just for off you know
okay it is kind of like monitoring is
how you operate services which is not to
say that developers can't do you know
our great services and all that
whatever but it's about understanding
what's happening on the inside by asking
questions on the outside and really
observability a observable building an
observable system the system is
observable to the extent that anything
can happen and you can poke around and
figure out what's going on so it's not
new and also and this is more
controversial there are conventions
there are things that I would strongly
argue are associated with observability
in observable systems they're not part
of the definition and you can definitely
create observability with other tools
but I think that it has to be it should
be it is often most effective when it
when it's a vet Verdun metrics are a
crazy ride we've been on for the last
twenty years because people happen to
publish their white papers about metrics
and thus like a thousand flowers bloomed
time-series databases and metrics and
dashboards and everything and we've been
using that hammer for every
 problem for like two decades
sorry
don't curse it's hard to remember
so we've been doing that for but like
these same companies also had have tech
on Avenger and stuff but they didn't
write they didn't open source of papers
because they figured they considered it
to core to their business
competitiveness they're better they're
event-driven tools are better much
better I I think that it's an arguable
that the health of the system shouldn't
actually matter anymore
metrics dashboards are great for
describing the health of the system they
don't tell you anything about the health
of the request which is why we are
dancing around between dashboards and
logs and there are other tools and just
like it's pretty I you can't do
high cardinality with metrics and high
cardinality
for context cardinality so you have a
collection of a hundred million users
the highest cardinality will be you know
unique user ID or social security number
so lower will be first name or last name
very low cardinality will be gender and
the lowest of all presumably would be
like species so what's going to be
valuable is the low cardinality
information it's the high cardinality
information entirely and the reason that
metrics can't really do it is because
it's the right amplification you know an
extra metric is a single number and then
you append tags to help you whoop and
this is the backbone of everything that
has been in the market for the past 20
years for helping you understand your
systems and it is a powerful but limited
tool it was literally what we were left
with when we were like gosh we have big
websites hardware is so freakin
expensive I can't store all this on disk
and forget about it my 16 Meg's of RAM
are taken how much can we throw away and
still understand anything like and thus
the metric was born anyway
this is highly controversial but I
believe that this forms the core of any
really powerful observability tool not
coincidentally it also very much
describes honeycomb I would argue that
the causation goes in the opposite
direction but you could find many people
to argue with you
you know I'm a vendor don't trust me
software development process back to the
main plot this this is someone's
beautiful idealized version of how
software gets built decide to verify and
toss over a wall profit I guess I don't
know and the thesis of my talk here is
going to be how observability can and
should be wrapped into every single part
oh not enough unicorns I'm sorry there's
more people are walking out already
that's fine the development process like
the first step is usually what needs to
be built what needs to be fixed the PM
sympathizers in the audience would
recognize this as a gathering
requirement stage and how we do it and
then verify my laptop but like federally
want to make sure that this works right
usually with tests and benchmarks QA and
their importance like I'm not trying to
downplay the importance of tests at all
but they're isolated and they're very
dependent on again the known unknowns
the things we can imagine will break the
constraints that we can conceive of you
know and then we have exceptions our
reliable are a reliable signal that
something exceptional has happened in
production except it doesn't always mean
that and it's also very limited
sometimes bad behavior doesn't actually
cause exceptions it just causes your
memory to grow forever until it crashes
or it just increases the latency or it
just you know consumes more and these
gonna be just as exceptional if you let
it go on long enough or it might never
even crash but just provide a really bad
experience for someone maybe your
request ends in three seconds but your
timeout was one second and then of
course ops will tend it forever and ever
well you move on to shiny new problems
just another day in the life of a baller
software engineer
see I'm not so insane about my hope code
causes problems saying right like you
are responsible for this piece of
until you decommission it from the day
that you think of it all the way through
developing it and testing it and
hardening it it's your it's your child I
actually kind of like to think of
production systems like the fourth
trimester you know how I'm like
evolutionary biology they're like you
know human babies they're born so weak
they can't even walk their fourth
trimester because their big-ass brains
actually takes place outside the womb
I feel like code was it shipped to
production B she's nice
do you not assume that this child can
walk yet I love you software engineers I
really really really do but you spent a
lot of time looking at fake things I
don't get it sometimes there are
compliance regulations and things that
you you're helpless I get it and and
then there's just the fact that you've
had really shitty tools for I'm gonna
stop not trying to curse it's just
impossible I hereby apologize
you've just had really shitty tools for
a long-ass time let me tell you a little
story about why why I actually started
this company are you guys familiar with
parse the mobile backend is a service
yep our stands so I was the first
infrastructure engineer at parse I built
the systems and I built the teams I was
there through the Facebook acquisition
almost four years in total and we were
serving over a million users by the time
I left over a million apps hosted on our
platform love that love that product so
much oh and then Facebook killed it I'm
definitely not bitter ever no grudges
are ever held Facebook killed it but
before that when Facebook acquired us
around the time they acquired us I think
we're hosting about 60,000 mobile apps
and that was around the time that I
realized was dawning horror that we had
built a system that was effectively
under debuggable by some of the best
engineers in the world doing all the
right things we had built a thing all
right so to be fair
I'll sit I think I would diagram that
coming up you see it's like spaghetti
right it's like it's it's and we were
doing microservices before they were
micro-services and you know we were
running you know hun hundred mongodb
replica sets where we let developers all
over the world upload their own queries
and we'd just make it work
suite of JavaScript containers where
people just upload their JavaScript we
just make it work you know you could
launch a query from inside cloud code
that would loop back in multiple times
and generate queries every time the
fan-out was great
we just make it work I never do this
it's a terrible idea
but magic for for the developer using it
so it was it was pretty complicated and
I was running two teams at that time
back in the software engineers and and
production engineers and every day you
know I'd get a complaint or a report
like parses down I feel like person not
down where the look at my wall
full of dashboards they're all great
there's hardly any errors like we're
clearly not down these people aren't
crack which is always an effective
strategy when dealing with your support
teams I'm just losing credibility of the
longer are you with them and I know it
but it's frustrating because like every
time I would go and investigate or i
dispatched an engineer like please go
and look at this you know it would take
them a very long time hours minimum
sometimes days and they just be trying
to anytime you're a platform and you're
spending attention and time on one user
you've failed like you should examine
your life choices because you did
something very wrong you have to be
solving the problems naively you have to
be solving like it was a category and we
were spending I you not like 70 or
80 percent of our collective time
tracking down these one-offs and we were
losing ground and I fried all right we
were also using Ruby on Rails among baby
which did not help matters but both set
that aside for now I tried everything
and finally the thing that dug us out of
the hole was when we got some of our
datasets into a tool at face book called
scuba any Facebook people here or X
Facebook if you'll ever talk to a
facebook engineer and you mentor X
Facebook and you mention scuba
look out for the misty look that they
get in their eyes it's like oh yeah man
that was amazing and to be fair it's off
it's a completely ugly and it's a
hostile tool like it does not want you
to use it it's it's it's doing its best
to be absolutely unusable and yet all it
does is it supports high cardinality
grouping slicing and dicing by fields
and memories you can just you know sort
click quickly you know sorting in memory
and we reduced the amount of time that
it took us to track down these
incredibly arcane edge cases from hours
or days to seconds or minutes like
reliably
I was amazing we got it handled on her
 we got better and like and I just
moved to LA like they said I don't like
monitoring like she's finally you know
on to the next thing but when I left
Facebook I started realizing I no longer
knew how to engineer without a tool like
this like literally I'm like well I've
been out of the world for four years
surely it's come must have come a long
way since then there must be something
like this out there cuz I don't know how
to do my job anymore without it spoiler
alert there wasn't and that's why like
my grand plan was honestly just well oh
you wanted to be money okay I'll go
build scuba and we'll fail all up and
source it and then I'll have it my seals
like please stop telling that story
please it makes you sound like we're not
ambitious but that was a grand plan was
borne out of me then over the last two
years we've been around for two years in
a two or three weeks and over the last
two years I have become extremely
convinced it all y'all are like running
into the same cliff you're about to go
over it because micro services are
really what I see as our entire industry
doubling down on complexity we're just
like
 it any farther we're just gonna
like hold our breath and jump and like
you have to make every single decision
over again you have to reexamine your
entire tooling like everything about how
you ship software and understand it has
to change in order to deal with this
increasing complexity where was I oh
yeah your development process the
development process is so much more than
these first three steps we have to care
about what happens in the wild when our
code beats built user workloads and
there is no substitute you can accept no
substitute for real production data real
users talking across the network with
real packet loss to other real services
I wanted to make this observability
driven development
Christine Nix did but as a software is
being built like you should not be
decisions and evaluations that you make
at the end when you're shipping it like
these should be think you should you
should be informing these hypotheses as
you're going right at every step of the
process just as much as testing or
documentation like you want that
feedback loop of you know just like you
know the way that we were all told to
ship changes to get you know you want it
to be a small coherent change that you
can then go look at and see did what I
expected to happen it actually happened
did anything else seem to happen around
it is anything just obviously stabbing
me in the eye you know and this is where
like monitoring can't do this monitoring
the patterns of monitoring are not these
patterns a better way to put it because
if you try to create alerts for the
combinatorial explosion of thresholds
that you may make go up or down your
entire team will quit and they should
you can't predict that you shouldn't try
you do need to get in the habit of going
to look at it right you need it this to
be muscle
memory you ship something or your
internship something then you go look at
it and if you're not looking at it when
it's normal you will not know what
normal looks like when things actually
break so absolutely it's kind of about
helping people to find this vocabulary
that ops and devs need to share normal
can mean something different to everyone
like you might freak out at the number
of errors being thrown or you might be
like no that's that's okay and here's
why
now I I would definitely argue that
there is a threshold of sanity you know
it should not look the opposite of how
it is you know if I'm thinking that like
the Supreme Court reasonable person's
test right what a reasonable person
think this is pornography I mean a
system that is outside the bounds of
normal you know it should look broken if
it's broken it should look not broken if
it's not broken but those are very broad
categories sometimes normal means
including outliers sometimes normal
means excluding outliers because you
know that these users are doing
something broken that you are not
supporting yeah I kinda want to just
like the ten commandments so
observability isn't just for ops just
like the dev cycle doesn't end it to
play time part of owning our code to be
iteratively using data to improve it the
current landscape of tooling is very
much designed for and written for ops
people I'm sure you've noticed this you
know anything that starts out thinking
the load average or CPU time is a useful
metric as some party their roots are
showing right and I mean that shouldn't
ops people shouldn't even think of
 whatever just whatever people
think that ops people will think that
load average is useful or something I
don't know but like memory utilization
and disk use these things are useful but
they don't actually help you figure out
things like which bill introduced this
issue
what special case in the code was
triggered as developers like we should
start demanding that our graphs and
underlying data have enough richness in
detail that we can track a problem back
to the code that caused it and and like
I'm I don't know personal notes like
this matters to me a lot because well a
lot of reasons honestly it matters to me
because I am tired of seeing teams
abused themselves I'm tired of trying to
talk software engineers into
understanding their own I am tired
of it being so miserable for them to do
it there should be fun you should this
should be more fun than not knowing it
right you should get a dopamine hit
every time you find something that would
have been a user facing problem they
would have woken you up in the middle
that you should be able to find them go
ah this is so cool you know there are so
many just like morsels of delight that
you should be stumbling over on any
given day and it angers me that our
tooling is so bad and we've been leaning
hard into this mindset for a while and
it has been wonderful it has been
wonderful to get to practice what we
preach and to build this culture of
asking questions frequently of each
other and at every stage of development
so I have some some examples of like how
we're doing things I'll just talk
through we in just lots of structured
data that's another of my religious
beliefs that all data should be
structured I mean come on the difference
between a structured log and a string is
like the difference between grep and all
of computer science I should not have to
tell you why this matters if you don't
have a religious zealot about structured
data structured logs in your
organization find one or make one they
should be super annoying
um besides that we in just a lot of
structured data we wrote our own storage
engine because there was nothing out
there that could do the kind of high
cardinality analysis that we need and
highly performant query engine on top of
it we believe that in order for people
to be expected to keep an eye on these
things it should be really fast like
like sub-second latency for a 95th
percentile we don't want to break
someone's flow when they're trying to
explore trying to understand what's
happening
you know we want to feel like oh this
this you can just iterate as quickly as
your brain can go it's really important
to us so we spend a lot of time thinking
about query performance
we also are selling the businesses worth
SAS so we're selling businesses who rely
on us to understand their systems so we
dog food everything we only use our own
systems to understand our own systems
separated on completely different stacks
of course we're not idiots and and the
nouns the things that we need to drill
down on are often customers right this
is one of those things where high
cardinality if you can't group by one of
each of your 10 million customers that's
a problem and that really at its root is
the thing that fixed everything for us
apart is just the ability to break down
by that one in a million app IDs and
then any combination of anything else
right so you basically it's like you're
pretty generating all of the dashboards
a graph for every single user because
the only thing that matters to them is
how they're experiencing the world not
how your 95th percentile user is
experienced in the world right so super
obvious are nouns or customers you know
so like being able to tie these sorts of
concerns has been pretty game-changing
for us you know not be different if you
care about shopping carts or maybe you
care about you know expensive Rock
queries or transactions but the premise
is the same the most painful problems
that debug the most annoying things to
realize the most important edge cases
understand often originate from that one
outlier doing something expect
unexpected
and that usually the case is that when
things are normal you don't care about
the details what you care about is the
shape in the direction the curve the
grouping of what's happening but as soon
as something is not going right then you
care about all of the details and this
is why sampling is still powerful for
this case latency increase which
customers are impacted who will benefit
from batching yeah let's see oh it's
somebody made me after my strange work
talk they made this mug and I
love it so we actually hold ourselves to
a much higher understanding of the code
that we ship then I think a lot of
people do we try really hard to practice
what we preach and and we all right we
had our first outage last August you can
look up the post-mortem that I wrote I
had been having this like mounting sense
of dread for like Theresa was like I'm
like it's been a year and a half and we
haven't had an outage yet what the
is wrong when his cousin gonna be so bad
of course it was Kafka related but it
did come but you can read about it but
like we don't have outages we don't
really have that urges and I credit that
a lot a lot with the fact that we're
just always looking at our like we
have a lot of customers there very high
traffic and we don't really go down we
can fail for a user who's doing
something in an edge case you know but
I've totally just fixed our lesson I
apologize so let's go through some
examples of what we've done honeycomb
and why I think this is better let's see
great performance yeah so we're
constantly in individual leaves and our
career tree to understand things like
hmm this one data set seems to pop up
consistently in the set of recent slow
queries why like which queries are
slowest what do they look like breakdown
by query shape look at the raw you know
look at the absolute max this is another
thing you cannot do with all those raw
records look at the performance
characteristics
and and and this feels a lot like a
business intelligence mindset you know
it's not one where you're you're looking
at your dashboards and you're just like
answer ANSWER Answer no you don't you're
not paging through the answers you're
you're starting with a small question
and then you're following the data where
it's actually leading you right
Christine likes to compare it to like
looking for your keys do you start out
with a list of the places your keys
might be no you're just like you start
looking and and when you remember oh you
know sometimes I leave it over there you
go look over there
Sam was like debugging you just start at
the edge and work your way down to the
lowest point at which there is a problem
was being shared this is not new
computer science it's just new for
systems let's see yeah so decide this is
the least decide was the least
interesting thing because everybody has
a opinion about how you watching
what you should do right build so for
example we had some folks asked whether
we could unroll their JSON for them they
wanted to send nested Jason and they
were hoping we would flatten it for them
inflight well Brett our own storage
engine which means that we can't rely on
anyone else in the world having done
some things for us just unfortunate
believe me it was the last resort and we
did not read your database I'd like to
make that perfectly clear it's not a
database it's a storage engine there are
no transactions there's no replication
we shall out to our think it's a storage
engine never ready database never write
a database unless your database company
so it seemed like a pretty
straightforward win but we were worried
about the performance of impact because
um anytime that you're taking something
small in-flight and expanding it you
should be so instead of just diving in
and making the change we first like went
and saw how many current customers were
doing something that would be impacted
by this that took about 30 seconds and
then we wanted to see how many of those
people would actually see a performance
like a decrease instead of you know an
increase so we added some fields to the
payloads to approximate that and let it
run for a while to give us information
on is their nest of JSON how deep does
it go how much
how many columns are there how how much
space would there be if we if we
multiply it how does it turned out we
had a fairly small number of customers
using nested JSON but they made up a
disproportionately large percentage of
our traffic and on top of that a few of
those customers would have ended up with
really messy schemas like hundreds of
extra columns like in a in a low part of
the tree if we just blindly turned on
this obvious improvement in the end we
made it we made the unfurling opt-in to
limit the blast radius observability
could also help you write less code
which is a winner always won at one day
engineer was digging into our web apps
data set and pulled up you know p10
225-250 3590 on the round-trip query
time from the clients perspective
compared it to from the service
perspective we realized that the median
query time was over 50% the JavaScript
active pull interval so instead of
writing a bunch of code we just dropped
that on the client and immediately
everyone perceived an immense honeycomb
speed-up I love I love what we get to
write less code and I love these stores
because they're kind of like debug
statements in your data right it's kind
of like getting to attach s trace to
your running system or run gdb live like
oh what a luxury by having a flow where
it's lightweight and natural to add
these things to production code in the
wild we can make more informed decisions
testing your correct code for
correctness is great running on your
laptop is definitely a thing that it
should do we love feature flags for
letting you ship things to production as
a first step and making sure that we're
still happy with it it's great because
you could ship the code without using it
or using it you know just for some users
for example the customer who wanted the
unfilled JSON we shipped it with a
feature flag and turn it on just for
them because they had already stated
they weren't willing to accept the risk
terrific
we also add the name of the feature flag
just as another dimension for all of our
data sets so we can slice and dice by
any combination of anything plus any
combination of future Flags you know
maybe a change that we're making
intersects and it intersects with one
feature flag and not another in
unpredictable ways let's see Wow is it
really that good already I've been
talking about haven't I
okay I'm gonna skip through all this
because this is all pretty obvious I
think so what's the biggest source of
chaos in systems well humans obviously
software engineers you guys definitely
the source of chaos state of the art for
deploys now adays seems to be just
drawing a line and what's happening
which is great but like I said metrics
dashboards high cardinality they can't
support the ability is actually an
infinitely increasing monotonic
monotonic increasing integer which is
also high cardinality and everybody has
multiple versions running in production
in any given time whether you want to or
not so here is our visualization of just
like what happens when we're doing a
rolling deploy you know nothing fancy no
Canaries or anything you can see how
there's three different versions running
there we have a trigger that we set up
that anytime that there's more than two
versions running in production for more
than you know 10 minutes it'll let us
know we have not set up automated
Canaries that graduate as they gain
confidence just because we're not large
enough but I highly recommend that it's
probably the number one thing even do to
harden your deploys and deploys not only
are humans are the thing that is the
source of chaos but your deploys it are
responsible for at least half of your
outages like they are the things that
are the most fragile every single deploy
is a very unique combination of that
artifact those servers that environment
you can only test that to some extent so
you should work you should focus on
hardening it and adding guardrails
instead of actually being too paranoid
or focusing on staging I hate stating
environments
skip all this best practices though you
want context you want so much
context you want all the context that
you can possibly get the way honeycomb
dudes that does this is anytime your
request enters a service we initialize a
honeycomb event and then throughout the
life of all that request is in that
service you just toss in there
anything you think of it might be used
for it or interesting the the business
downs you know the app ID shopping cart
idea there like anything that is
interesting or identifiable the system
stuff like The Rock query the normalized
query family any latencies you get from
calling out to any other services or
storage layers and your software
engineering neurons to the lady um you
know that the Hat whatever toss it all
in there hundreds is fine up to the
limit of the open file handles and Linux
thousands and then when you're the
request is exiting the service or errors
out we ship the blob off to Honeycomb
so it's a very low write rate but the
events can be arbitrarily wide so that's
a lot of context and it's so nice to
just be able to go
oh here's how the system looked when
this request happened instead of trying
to go dashboard timestamp oh NTP is
off by a minute and a half adjusting for
the timestamp you know just like dance
of the eyeballs that we do when we're
debugging mmm context is everything
finding different ways to group your if
you're not if you're if you're not
including attribute or the dimension
that is actually the thing that all the
things that are broken have in common it
will be as though it does not exist it
will be invisible to you you will tear
your hair out you will go mad so just
capture everything that you can think of
mmm you know common source of comments
of nouns consistent namings dashes
underscores whatever you're doing make
it consistent so the people can move
fluidly from you know system to system
and understand what the hell's going on
and this is another kind of honeycomb
ISM um so it is a fact of life that when
you're building systems to understand
other systems you have to discard some
data because the amplification like if
you have people who are instrumenting
well for every event the enter is your
production system you may generate tens
or hundreds of events describing that
right this is the best practice well I
assume you are not going to pay for it
observability stack that is tens or
hundreds the size of your production
stack it's so facto you are going to
discard some data then you really have
two choices you can either discard this
way or this way metrics dashboards time
series they have all chosen to discard
this way the older your data get the
less fine-grained it is the more they've
taken everything that happens in an
interval and just squished it right and
once squished you cannot unsee wish the
way that we do it in event worlds is we
discard data this way by sampling which
is how scientists do data you know I
people get all my data you've thrown it
away every day it's just like saying you
know what's the temperature in San
Francisco 73 degrees well it's not 73
degrees everywhere it is 73 degrees in
the places that we have agreed or a
representative of San Francisco sampling
is everywhere so for sampling but what
you don't want to do is is use it as a
blunt instrument right you don't want it
not every piece of data is equally
valuable the things that are rare you
want to save all of the things that are
common you don't so like for example a
parse we would sample reads heavily and
in our database traffic and we would
keep every delete because they were very
rare for like web traffic 200 throw a
lot away 500 keep them all at Facebook I
think that the
bling ratio that parts the sampling
ratio for 222 one and a Facebook it was
like there's thousands to one the
representative sample is all you need
when times are good because all you
really care about is that shape we also
haven't come we do the math to you know
draw the correct numbers in your graphs
just based on the sample rate which is
an attribute in every event an example
schema evolution so like this is us
these are the things that we could
predict that we would we would want
these were some of the fields that we
added and then you know we start start
iterating at it some more and on and on
so there are going to be a few different
kinds of things here there are the
things that you can predict you're going
to want like the HTTP attributes
anything about database queries any
latency is there's gonna be temporary
things that you're adding while you're
developing to understand and debug your
systems and then there's the things that
you add mid outage that become permanent
our mission is really this stop trying
to guess what software to write like do
as much of it scientifically as possible
this is the other this is the other one
you can tell the difference when
Christine slides in behind your a
distributed systems engineer now you're
welcome you should ask for a raise the
other list of attributed systems they're
never actually up they're never all up
if you have a wall full of green
dashboards tell you how awesome you are
you should not feel good about yourself
because it's lying to you
I mean you should feel good about
yourself but not because of your
dashboards okay and basically done but
there's a couple of complexity so the
reason that I think that we are we are
at this tipping point where
observability has become important is
because the complexity is increasing I
drew the janky-ass graph just cuz I
wanted there to be a graph because
that's how people know things are true
there are graphs all right so like
I told you to bookmark this right
there's a lamp stack on the left and
that is the world that all of our tools
that were used to using were designed in
where we could really fit it in our
heads what we should you know which
component is broken
oh you can tell immediately the middle
is the driver of cars and this is the
electrical grid and the systems that
we're building and designing and trying
to understand and increasingly look like
this where some problems can only be
seen in the hyper local level you know
if you're looking at a city block some
problems can only be seen if you zoom
way out and look at systemic patterns
and and your tools need to really speak
to both unknown unknowns predominate or
they should otherwise you're not doing
your job and fixing the things that you
know about and then I have these slides
are all on the web so you can read
through them if you want these are the
best practices characteristics and best
practices the one that I wanted to jump
to is just talking about why the health
of the system is irrelevant I know it's
it's kind of a kind of a inflammatory
statement health of the system is
irrelevant the health of each event and
every high cardinality grouping of each
event is what you should care about if
AWS you know you guys use it'll us
mostly if an availability zone is down
you should not care your users should
never notice you know this is totally
trivial your dashboards will all be red
fuck'em nobody notices you shouldn't
care you should sleep blissfully through
the night but if your users are unhappy
if your users are getting errors or if
they're not getting errors but the
experience is terrible you should care a
lot and this is where the limits of site
reliability engineering really come into
stark relief and this is where you guys
step in right understanding what our
users are experiencing is a prerequisite
to making them happy
and the good news is the good news is
that like your reward for embracing all
this is vastly fewer paging words you
kind of have to declare bankruptcy on
the entire model and if you have
confidence in your ability to debug and
answer these questions you should only
have to have about four only four you
know request rate or latency maybe
saturation and then a couple of
end-to-end checks that stress the
critical path somewhere around the thing
that makes you money that's it
so congratulations any questions
there's my list of oh this is all right
so if you've ever googled for like how
to how to how to fix your high
cardinality woes and you find a bunch of
people going like well here's how to not
have those problems those are metrics
people you can't not have those problems
you can't like look at this this is
literally all of the kinds of
information that you will ever care
about and is are just all extremely high
cardinality because that's what makes
something identifiable it's rare so I
think that it's the jig is up on that
particular line in my opinion anybody
have questions all right in that case
I'm just fast forwarding to my favorite
means I love that one and this so we
have to test in production we should we
should embrace this we should plan for
it we should plan on that fourth
trimester being one where we coddle our
systems right we need to nurture them as
they grow up so they can stand on their
own two feet like services need owners
not operators obstacle like me are not
going away
but we increasingly live on the other
side of the API from you you know we're
not sitting next to you to save your ass
and I don't want to get woken up anymore
either I'm over 30
which is why like these operational
skills are not optional I believe that
no software engineer should be promoted
to senior engineering level if they do
not demonstrate the ability and desire
to own their own systems even Android
and iOS engineers like this is and this
is not a fate of doom this is like this
is how you do your job well you should
take pride and it's super fun it's
really hell of fun lots of dopamine
involved everyone should be interested
in what happened to their code after
they hit deploy watching a run in
production and then Gregory's last two
slides
my last two which is that when you're
thinking about observability and
monitoring think about distributed
systems because like if you think about
it distributed systems are really just
the computer science of complexity you
know far-flung data Coordination
graceful degradation
you know minimizing that critical path
and all of us run systems that are
getting massively massively more complex
so distributed systems will help you
feed future proof your code so thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>