<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>End-to-End Automated Testing in a Microservices Architecture - Emily Bache | Coder Coacher - Coaching Coders</title><meta content="End-to-End Automated Testing in a Microservices Architecture - Emily Bache - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>End-to-End Automated Testing in a Microservices Architecture - Emily Bache</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/vq8o_AFfHhE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Sukie a developer I've been writing
software since professionally since 1998
and I've chosen to specialize in test
automation more and more over the years
so this talk is about some of my
experiences I currently work for pragma
which is a consultancy company but most
of the experiences I'm talking about
today were at my previous job when I was
employed at a product company I wrote a
book a few years ago about coding dojos
and learning test-driven development and
that's probably what I'm best known for
and you can follow me if you want on
Twitter so let me tell you a little bit
about the giro which is the experiences
that I'm speaking about today so we have
a product for financial supply chain
networking which basically means that we
facilitate the exchange of electronic
documents between businesses mostly
invoices so for example a large company
would engage our services and they would
say it to us ok
we want to receive all our invoices in
this particular format from you so that
it goes very smoothly into our whole
accounting system and Peguero would say
yes of course we will phone all of your
suppliers and contact them and get them
set up to send all the invoices to us in
whichever formats is convenient for them
from their accounting software and we
will then transform it into the format
that you want it in and deliver it to
you so it's basically a huge cloud-based
document transformation service and this
services proved very popular in the
Scandinavian countries where it's
growing strongly and figaro as I speak
is expanding out into Europe and
providing this service to more and more
countries so I joined the company in
late 2013 and they were just moving to a
micro services architecture at that time
so this is an architecture diagram now I
don't know if you went to Simon Browns
talked earlier about architecture
diagrams they're not he says they don't
have technology choices on them
well I've got loads on mine I'm afraid
and these may not be technologies you're
really familiar with us we were using
rabbits rabbit thank you for sending
messages between
micro-services written in scala and that
huge great micro-service in the middle
is not a micro service that's a former
monolith written in Java which we also
derived and deployed in the same way as
all the other micro services originally
we had this huge Postgres database and
more recently we moved a lot of the data
into cassandra because it's distributed
and can handle more data and the the
reason that we we did this we started
with this great big monolith that had
been in production for like ten years
we needed to scale so that was the
reason that starting to build all the
new functionality in micro-services to
try and handle the the volume of
transactions we were meeting to handle
so I've got a few numbers so you can get
an idea about this when I left we were
about 45 developers split into seven
teams and we had about sixty
microservices and that figure is growing
all the time but among this as I said
had been in production for nearly 10
years already and the whole
microservices change was ongoing it's
still being split apart so there's no
numbers on the graph because that's
commercially sensitive information but
you can see that the growth in in
traffic we were handling was just
growing exponentially basically and so
we needed to do something our model this
wasn't handling it and you can see the
regular dips in the graph that's some
July the British sends invoices in July
and in Scandinavia apparently so as I
said we were several teams of developers
and we organized it so that teams were
largely responsible for a service or a
feature area or a number of services but
one of the teams was different that was
when I was in the infrastructure and
architecture team so our job with
with to provide the infrastructure that
the developers and the other teams
needed to build features so that they
could go and build micro services and
get functionality working and provide
business value so we built all the
deployment tools we built all the build
pipelines and we also built of course
the test infrastructure that they should
use or its offered we offered them a
test infrastructure we this visit was
our service to the developers we wanted
them to build great features and have
regression tests for them so we try to
make it as easy as possible for them to
write those regression tests so this was
kind of how we had things set up we were
at the same time is moving to micro
services also trying to deliver more
frequently move to a more continuous
delivery setup because we could see that
if you if you deliver more frequently
you reduce the lead time the customers
get the features sooner but also smaller
batches should imply higher quality it's
easier to see when the error occurs in a
smaller batch so that's what we were
trying to achieve and when I joined the
company the release schedule looked
something like this it was like we were
getting a new version out once a month
with lots of changes in it and
unfortunately all too often the days
following the release was a bit of a
panic of hotfixes that's the kind of
black and orange stars there and this
happens from time to time that we did
have two emergency hotfix the system so
three years later then we we had all
these micro services and they are much
easier to deploy and we were able to put
them out much more frequently so that
the release schedule started to look a
lot more busy there were a lot more of
these smaller releases going out and we
we did actually see a reduction in the
number of hot fixes that we needed to do
hot fixes being a bad emergency release
as opposed to kind of a normal routine
scheduled release so the the reason we
were able to achieve this was obviously
partly because of the new
architecture the microservices but also
I like to believe it's also due to the
testing strategy that we put in place so
that's some what we did we had fewer hot
fixes a few years after introducing
better testing practices so that's kind
of an introduction to set the scene of
where we were at and let's look a little
more closely about the actual testing
part of this so I've got some theory
about testing now the test pyramid is
often cited as a good way to think about
deciding what kinds of tests to do Mike
Cohen introduced this in like 2009 he
was trying to point out that it's good
to have a lot of unit tests because they
can find some very important issues at a
minimal cost and they are very good for
the developers to write to help them
verify the code does what I think it
does we still need these end-to-end
tests at the top of the pyramid for
testing the whole functions to make sure
that things hang together and these
tests are really valuable because they
test from the user perspective they're
looking at how the user would behave in
the system and they will find issues
that the users would really care about
so there we need some of those but Mike
Kohn was pointing out that if you do all
your testing here that gets very
expensive and and you can have more cost
effective testing by pushing the testing
down the pyramid and he points out this
lay in the middle which he just calls
service tests and it's kind of yeah this
is when you haven't got the entire
system up and running but it's more than
just a class or a method and we're going
to and it's a good balance perhaps
between testing stuff that's relevant to
the user while still keeping the costs
of these tests lower
so when I came into video we we had a
testing pyramid that actually looked
fairly good compared to this kind of
ideal I mean it wasn't perfect we did
have probably more GUI tests than you
needed and we didn't have quite enough
unit tests that if you would like to
have but still there were all these
layers for the monolith we had unit
tests and we had GUI tests for the whole
whole thing in between we had some data
layer tests because the large part of
our system was the object relational
mapping layer that was talking to the
database so we had a lot of tests around
the integration point there between the
database and the layer of objects then
we had service layer tests and this is
where we have an API to access the the
application and test the whole feature
so I hope you know this already about
unit tests I'll just recap that unit
tests are testing just one small piece
of code if they touch the network or the
database or something then they may
still be a useful test but they're not
really a unit test these are the ones
that run really really fast
and you can run them very frequently so
I've as I mentioned I wrote this book a
few years ago about how to learn
test-driven development more or less how
to learn to write good unit tests and I
still stand by this I think it's good
thing to learn these skills and when I
came into bagheera I was all ready to
start doing coding dojo z'n and I give
some and I discovered though that
actually the developers were already
very good mostly and then you had to do
this stuff generally so this wasn't the
focus of what I was doing at biggera and
I looked at the the data layer and the
service tests and again they they think
mostly all right be they were quite slow
and they didn't break very often and the
developers were still adding new ones
from time to time but it was a lot of
work actually particularly these service
tests that are testing a whole feature
there was a lot of code in one of those
and it was a lot of code that got copied
and pasted to the next test and if you
recognize that and it's it was becoming
unwieldy
I also found when I started working with
these tests that Java RMI and if you
know this technology but this one is you
have to have exactly the same version of
the server code as the client code or
else they can't talk to each other which
makes it very frustrating when I've I've
deployed a newer version and I just want
to run the same test and it doesn't work
so I found these tests frustrating and
they were also very very slow when you
access them from outside the docker
container once you get out of process
with Java RMI all the calls grow over
the network when you're in process and
you're testing in the same like JVM as
the code it optimizes away or the
network calls and suddenly your tests go
ten times faster
but once we docker eyes dar on monoliths
we couldn't do that anymore so we we had
some of these tests but they were they
were a bit clunky and when we moved to
micro services it wasn't obvious to me
but we needed the same kinds of tests
there are a lot of our new micro
services maybe they didn't have a
database and and you certainly weren't
addressing them with Java RMI we were
using different protocols so this these
tests were kind of there but they
weren't something I wanted to build on
we had these Giri tests as well and for
our web application and this is the
login screen you know yuri say we had
tests with selenium that would log in
and do stuff and they were as good as
far as they went but there were certain
kinds of issues that they would never
find so i like to show this if you if
you put some you put some dancing ponies
on this page just you know some
developers feeling a bit bored sometime
and they they decide it needs jazzing up
none of my tests would find that and
even if they were really determined
support ponies on the front page and and
they wiggle their nose in a very
attractive manner and that this kind of
test is not going to find that kind of
issue
so I was looking at the testing strategy
and thinking we needed probably to do
something a little different with the
new architecture so this article came
out about the same time and I really
regret that I didn't find it at the time
because I do think this is a really
comprehensive overview of all the
different ways that you could decide to
test your microservice this article by
Mantid phyla in with these so his
testing pyramid has even more layers and
he has so many different colors for all
the different parts that you can test
together and what kinds of issues you'll
find if you write tests around those
parts so this is this is great and I do
recommend you have a look at it if
you're doing microservices so just going
back to the giro the the pyramid on the
left is what we had before and this is
what we came up really for the for the
micro-services we decided that the
natural next layer of the pyramid above
unit tests was actually just test the
micro service now micro service is
independently deployable so I can deploy
it by itself on my machine and it also
has an API that I can use to address it
and that makes it a really useful and
abstraction for testing because I can
deploy it locally and talk to its API
and that's is a way for me to test it
kind of black box but I still thought we
needed the Giri tests for the whole the
whole shebang that that was still useful
to have and system tests where you you
try and avoid those costs associated
with using the user interface and and
that's what I'm going to talk about
quite a lot more the end-to-end system
tests but it is worth mentioning that
them we had micro service tests too as I
said you you basically deploy the
service on your local machine and and
possibly if it has a database you could
deploy that too and I would also
probably deploy some essential services
that the micro service needed like all
our services are using a
and lookup service for getting
configuration and it's like a read only
database and they're also using a queue
service so rabbits and queue to talk to
the other services so we would deploy
some of those but basically you're
trying to test the Microsoft by itself
you trigger the public API of it try and
get it to do something and then you have
to the test has to then respond to any
messages it tries to send to other
services so you have to kind of capture
the calls it makes to the collaborator
and return something that the test wants
to test with so there's so there's a
fair amount of code in one of these
Microsoft service tests and and but they
did find useful issues just for one
service and if I did this again I would
probably be looking at if we kids avoid
some of the overhead of these tests
because it does slow them down to be
running the tests over the network
talking to the micro service through the
queue it does make it more realistic but
maybe it doesn't actually give you very
much more security and it costs time so
we had this person I think this is
useful but I as I said I've gotten a
whole lot of ideas now about how we
could test these things better but I
also want to talk more about the system
test that we did so let's move on a
little bit I wanted I mentioned already
we were doing trying to do continuous
delivery so we were setting up the
delivery pipeline and you start at the
left side with the programmers working
on new features writing unit tests maybe
they're doing pair programming maybe
they're doing some mother form of review
but any way that the code comes into
version control and that that's where
our automated deployment pipeline picks
it up makes sure that the unit tests are
all passing test all the smallest bits
and then if they all pass maybe we'll
test the micro service by itself and
then if the Microsoft by itself works
then we'll deploy it in with the other
services and test it end-to-end if
everything still looks good then maybe
we'll devote some actual people time to
this get some manual testing done
in the staging environment and then if
we still feel confident then we can push
it out into production and monitor what
happens when we do that so all the way
down the pipeline we're moving the code
into a more and more production like
environment we're devoting more and more
hardware to the testing we're testing
larger pieces of code together and
seeing if they integrate and the test
costs increase and that's not just
because they take longer to run and they
take more hardware of course that is a
factor that is a cost but really the the
major costs of these other tests is the
the maintenance cost when you have a
bigger piece of code being tested it's
more likely that you'll get issues with
latency problems or the database is slow
or or something happens not quite in the
way you expected and that the test fails
for no good reason and then somebody has
to go and look in workouts is this
failure because something important
happened or is this just a flaky test
and that's you spend a lot of time
writing these tests and maintaining them
the bigger they get so that's that's
really why the whole testing pyramid
thing is saying look invest in unit
tests these are the cheapest tests that
you have but they don't find all the
issues so you do have to have the other
ones as well you can just have less of
them so let's talk about a little more
about these end-to-end tests which
aren't using the user interface this is
where I put a lot of focus and this is
because well when you start looking at
your architecture as I put it up before
and you start to say well ok now we need
to have a test case in this architecture
that's going to trigger things happening
and work out what should happen and
assert that it didn't happen and this is
where it starts getting really
complicated and your test has got so
many moving parts to worry about and
it's got so much going on and this is I
find this kind of problem fascinating so
I put quite a lot of time into this and
I wanted to tell you about what we came
up with
so the end-to-end test strategy that we
came up with with well we don't want to
have too many of these tests because
they are expensive let's just have the
crucial work flows the really important
use cases let's try and use an API the
GUI just adds another layer of
complexity and costs let's have an API
to trigger the workflows we need to test
and then I found these three techniques
useful data driven testing approval
testing and event monitoring so I'm
going to say some more about that but
the basic thing is all of this test
strategy is I want to find the important
bugs by keeping but at the same time
keep the costs of these tests as low as
possible the cost in terms of my time to
write them and maintain them and not
just my time but all the developers I'm
providing this tests framework approach
to the developers who are developing
features and if it's too costly and too
slow they just won't bother so I have to
do something that the developers in my
organization are going to want to use
because it helps them so just another
note on the thing with why I'm wanting
to avoid the user interface you can test
the whole system through the user
interface and that is usually the way
the user would would go in and you would
see the same bugs as the user if you use
the user interface but the user
interface is not designed for a machine
and an automated test as a machine and
you have all these timing issues and
threading and the buttons move and the
test fails and you just had laid out a
whole new layer there an API is
generally more reliable particularly if
it's already a public API so our cloud
system does have a public API it's a
REST API and a lot of our customers use
it to send their documents to bagheera
online so this was a great starting
point for the tests so we started by
saying well let's just use the public
API
and that that worked for about three
minutes until we realized that actually
there's a lot of stuff we want to do
that we don't want to let our users do
so we don't want to expose a very wide
public API so we built an additional
REST API just for the tests to use that
kind of firm was built on top of the
existing public API but added a load
more functionality that we wouldn't want
to expose externally so we built it in a
kind of a separate and it wasn't
actually separate micro-service but it
was separated enough that we could just
not deploy it when we deployed to
production which meant we couldn't run
the same tests in production as we could
in staging but that was price we were
prepared to pay for the security that
knowing that no one could gathered it
because it wasn't there in production so
that's a so I should also mention the
the main reason we needed this API
actually was to create new entities in
the system so in order to send an
invoice through our system you need to
have an account so the test would create
an account as the first thing it did and
it would create a unique account just
for that run of the test so you create a
user and you name it user 1 2 3 and the
next time you ran the test it would
create the same user with all the same
attributes but it would be called user 4
5 6 so you'd know as it's all the data
one test run was working with was unique
just just for that test and then you
could run them in parallel and you could
wipe the database and run them again or
not wipe the database and just run them
again and it was all fine it would set
up everything for that whole scenario so
then we found though we were really
doing data-driven testing here so the
the main use case of this system is
sending out documents from an issuer to
a recipients that workflow stays the
same and you can test a lot of the
features in the system just by varying
the way you set up that issue and that
in that document so that's that's pest
data so we had that defined in in text
files so we had a like our own JSON
format for defining the properties of an
issuer for this test case and in another
test case you'd have a similar JSON
document only with slightly different
property sets and then you could run the
test and see what happens so the
observant among you will realize that
this is only two parts of the test case
it's the you're setting up what the
scenario you're running the scenario and
then you have to check the result so the
thing with data-driven testing is that
you can define a whole new test case
just in terms of new data you don't
necessarily need to write any new code
if you already have the workflow set up
but if you then have to make some
assertions about what happens then
you're back on writing code that's
different for every test case and really
what we want to make assertions about
just in this particular use case is well
what it was it that the recipient
received did they get the right document
in the right format so data-driven
testing is only the first two parts of
the test you needed a way to do
assertion and the classic ways as I said
you write code to assert things about
the outputs another way to do it would
be using property based testing where
you define invariants that the document
must always be contain the name of the
recipient the document must always have
one of these formats these things that
you can say are universal for all of the
test cases that there must be a document
for a start so that you could do that
but then the the kind of generic
property based tests that you could
write for all test cases is they start
to get kind of complex when you start
looking at well this particular test
case these invariants don't apply anyway
we didn't do property based testing
although it would have been an option
what we ended up doing was approval
testing
now approval testing is saying that
instead of having to define a bunch of
assertions what I do is that when I'm
designing the test case I take a look at
the output output so take a look at the
recipient presentation and I examine it
carefully and determine if it's correct
and if I deem it to be correct I might
need to check with some business person
who knows these things but if I deem it
correct I approve it and then the next
time I run the test at a conceptual
level I just do ad if I dip it against
the approved version and if it's the
same then the test passes and if it's
not the same then there might be a
problem and that's where it starts
getting interesting so I've mentioned
that often the recipient presentation
could be a PDF file it's equally likely
actually to be some form of XML but in
all these cases I want to do some kind
of transformation on it to make it into
a standardized plain text format and
there are utilities for converting PDFs
to text we use a Python tool but there
are others if it was an XML file then I
would use a kind of a lint tool to just
lay it out beautifully with all the tags
indented at the right level and then
when you've got it in this beautiful
plain text format then you you might use
a bit of filtering I'll come more to
that and then you just do a disk a plain
text disk and you make sure that it
matches and if it matches the test
passes and if it doesn't match then this
is where you want to be alerted to that
so you've got the approved output on the
left and you are looking at the new
output that has come out and the
observant among you will notice that
those those ponies that I was so worried
about have crept in here and we can
clearly see from the diff that we have
an extra line here it has to failed we
have ponies that weren't expected and if
we were doing assertion based testing
I would have been picking out some
things to assert in this documents I
probably would have picked out the the
bank account number the right person is
going to get the money I'd probably pick
out to check the amount payable is
correct I'm things like that but as an
assertion based test would very unlikely
to have a certain Oh extra line item so
it might do but yeah but with the
approval test I'm seeing that kind of
thing immediately so this this could be
a bug and I've now found it with a test
or the other scenario is it could be a
feature and that means this is actually
intentional our customers have requested
a new feature that they want us to add
this to the invoices so okay in reality
and we probably wouldn't be adding
ponies but it was it is one of the
features of this system that it will add
stuff to the invoice are on behalf of
the recipients so what we want to do at
this point then is update the approved
output with the new version and so we
want to do this replacing and update our
test suite and this you could do this by
hand it's just a question of copying a
file into the test Suites and committing
it to your version control system and
but it actually really helps to have
tool support and this brings me to text
test which is the tool that I've been
using for this that I'm one of the
developers of the tool and this is a
tool that explicitly designed for
approval testing and makes this kind of
firm copying files around really easy so
it's a open source tool for approval
testing and it works very well with
data-driven testing it's not the only
tool in this space I would also
recommend these approvals tools which
actually were designed for dotnet I
think from the beginning so they would
definitely be worth a look if you're in
that space and then there's this really
quite recent tool that just came out
called jest which is for testing
JavaScript and this tool I haven't
actually used it I just read their
marketing materials
like oh this is doing a pre-war testing
except they're calling it snapshot
testing so that's fine okay there's
facebook whom entered this tool decided
that it was called snapshot testing so
maybe in a few years I'll have to change
my my language and call this like that
we'll see but I think it's the same idea
you're basically doing a diff against a
version that you've previously approved
so I mentioned before that you you have
to layout the version you have to
convert it to to plain text actually you
don't some of the versions of this tool
will work with images text test you can
probably tell from the name is really it
works best with text files so one thing
you can do with the text file is you can
do filtering so one of the things on an
invoice you might display the current
date of course the due date of the
invoice shouldn't change but the date
that you printed it that might change
and that's going to change every time
you run the tests and you don't want the
test to fail every time the date changes
because that's uninteresting so with
text test it allows you to define a
regular expression to filter out
something like that so this is a regular
expression for that date and it will
replace it with a six-string date so the
document ends up looking like it does on
the right when you've done the filtering
and then of course the diff works every
time could you do the same filtering on
the approved document as you do on the
test document but you also notice that
regular expression will only match a
date if it has the right format so it
will of course help you to fight if
there is a bug introduced that means the
dates don't get printed at all this will
find it but yes it will find it because
the replacing it with a fixed string in
the approved version and it will notice
it was gone in the new version but if
the date it has the right format but the
wrong contents then I'm afraid this test
won't catch that so it's not a panacea
it will it will only catch certain kinds
of of issues so you do have to be a
little bit careful about filtering
because you can of course filter out too
much and end up comparing
documents that are essentially empty
because you filtered out everything in
them I've done that so you have to be
careful with your reg X's but if you
compare with a case when you were doing
assertion in the assertion case you
you're kind of picking out things you
want to check whereas in the filtering
case you're picking out things that you
want to filter and the rest is going to
be checked so it's kind of you you're
all is kind of reversed as a test
designer instead of picking out what you
want to check you have to pick out what
you don't want to check and that means
you catch everything else and this has
some consequences it has some good
consequences in that you spot those
unexpected issues like that why did that
developer just add that pony there that
I didn't expect that but it's appeared
and now I my test fails and shows it to
me so that's good but it does also mean
that your tests are not isolated
you get related failures so let me
explain what I mean by related failures
so if you familiar with the unit test
you really try and test just one piece
of functionality at a time so when that
piece of functionality stops working
one test fails in the ideal case and you
have only one assertion in that test
case and that's absolutely pinpointing
the piece of code that is now gone wrong
and you know that the majority of your
system is working but that one piece of
functionality is broken because you have
one failing test that's kind of an
extreme it doesn't always happen like
that
even with unit tests but that's kind of
what you're after when you're looking at
an approval test that very rarely
happens that you just get one test
failing most of the time you get a lot
of tests failing at the same time
because they are related you're testing
a whole use case you've got a large
piece of code being exercised and
effectively that that disk that you're
doing it's like having one assert on
every line of that file
it's you've got multiple asserts in your
test case and then multiple asserts that
are shared but because
have similar documents so I've got an
example here we've got two different
test cases and these are the two
approved documents for those tests you
can see they're not identical there are
differences in the invoice and they
represent the differences that we we
want to be there because we are
exercising different scenarios but if we
think of a new feature that's added to
the system that's cross-cutting and is
changes a large number of invoices so
for example if we start printing the
address differently we start printing
the country on the invoice as well as
the rest of the address and this might
mean that all our tests suddenly fail
because they've all added an extra line
for the country and this this can be a
little bit you can get a bit worried by
this when you run 50 tests and all 50
fail or even 49 of them fail you're like
oh my goodness what I do now but then
you start to look at it and realize
actually all of these are the same issue
I just want to approve this because
that's what I intended and this is where
tool supports again becomes really
important with approval testing you you
need to have a tool that will help you
to identify these related failures and
this is a screenshot of text test and so
if you look on the Left I've got a list
of four test cases I thought I wouldn't
do 50 I wouldn't scare you with that and
the top three failed and the fourth one
is passed and on the right hand side you
can see the summary we ran we ran four
tests three of them failed and one
succeeded but you'll notice that the top
two test cases are highlighted and so is
the line on the right highlighted saying
Group one that's saying that these are
grouped these failures together in the
tool is noticed that they have exactly
the same diff they have the same failure
and all you need to do then is to just
look at one of them and make a judgments
about whether that is a bug or whether
it's a feature and if you judge it's the
feature you can just approve
the whole group because you know they're
all the same and then that's third
failure that was different you maybe
need to go and look at that because it
had a different diff so what I'm saying
is that the tool helps you to spot the
related failures and then like I said
you then apply the same fix to all the
tests in the same group so either you
bulk approve them all or the decide are
well now actually I need to filter that
I'm going to write a new reg X which I'm
going to apply to all of those tests to
filter that thing out so the tests pass
again or maybe you'll identify that
actually they're all suffering from the
same bug and you just write one one bug
report so this as I'm trying to point
out approval test has different
trade-offs than other kinds of tests and
tool support I think is crucial so this
is the big picture then of what a test
comprises in this system we've got some
specifications of data saying that we've
got these actors this document we've got
this workflow and we're going to store
the actual presentations for reference
but actually what we're going to assert
on we're going to prove the textual
representation of that output and that
will determine if the test passed or not
and the whole idea of this is that we
want to minimize the amount of work it
is to create a new test hopefully it's a
case of identifying new data that
triggers the feature we want to test
looking at the outputs approving it and
then checking in a bunch of files into
our test suite when the tests fail we've
got tool support to help us to identify
those related failures and maintain
those tests and we want to maximize the
potential for finding those bugs we
didn't anticipate we're going to find
those things that appear in the output
that no one really expected so this is
good and this was working pretty well
for us I in my humble opinion but there
was there's another thing here what what
you do when the test fails and there's a
there's a bug
the presentation that you get out
doesn't look right where'd you find
where in your whole system the thing
broke this is one of the advantages of
unit tests they absolutely can pinpoint
your failure but this is saying well
somewhere in this whole thing with loads
of microservices something went wrong
and the wrong out wrong our answer came
out so we want to be able to at least
find well whereabouts that things go
wrong here
was there a service that didn't respond
correctly or was what happened and this
is where the test case and can actually
give you some insights just by listening
to the traffic I mentioned this mark
services architecture and all the Micra
services are talking to one another over
a message queue so they're constantly
like publishing events that they say
this happens to the document and all
they're saying please do this to the
document for me this is its ID so you
have the test case listen to the traffic
concerning the entities that it's
responsible for so I mentioned already
that when you create a new recipient or
issuer in this system I give it a unique
ID just for that test run which means
that the the test will just listen to
all the messages on the queue but it
knows the ID of the entities that it
created and it will just write to a file
all the events that concern those
entities so you end up with a log that
looks something like this with these are
the events that happens this is the
messages that were sent regarding this
this document and this can really help
you to debug what happens when the test
fails you can a compare the approved
version of the event blog against the
actual event log that you got from your
particular test run and this gives you
some insight into what what happens
quite often events is missing or an
event is mal forms and some service
doesn't pick it up with the way they
should so this actually gives you some
clues about what went wrong and where to
start looking for the
the problem so we store this in the test
as well the test case basically
comprises a folder with lots of files in
it and a link to what code to run for
the test workflow so this is what we are
storing in our test case and version
controlling in version control system so
that's kind of like the static view of
one test case I've talked a lot about
that and let's talk a little bit more
about how we ran these how we arranged
them in our our delivery pipeline so as
I mentioned before we were doing multi
team developments and a team would be
responsible for one or more services and
that meant that when you look at the
delivery pipeline this is this picture I
showed you earlier in the system test
you have several services deployed and
those services are kind of owned by
different teams so that has a means that
actually this is too simplistic the
delivery pipeline looks more like this
you have a team that will be working on
their services and running their unit
tests and their bit of the pipeline and
run the tests for their micro service
and then they will deliver to some kind
of shared pipeline where we're going to
do system tests and this point where the
streams meet team a and Team B suddenly
start have to care about each other's
work up until that point they are
working in kind of isolation testing
their small pieces of code that they are
responsible for the system test is where
it all starts getting interesting and
this is a where we we ran into some
difficulties when we first set this up
having come from a monolith where you
run the system tests your monolith we
didn't quite set this up the right way
at first I think so we set up our build
system in go C D which at the time was
had a much more sophisticated way to
handle pipelines than other tools that
are available I'm sure there are other
tools that can do that the same thing
these days at the time this C
to be the best choice but the pipeline
structure looked like this you'd kind of
build the services and then you would
update a bill of materials that lists
this is what the file is basically a
text file that just lists all the
services and which is the latest version
of them which is the most recent version
that was built and that's the versions
that we're going to then send to system
test and system test is going to run all
the tests and when they pass it will
deploy it to the staging environment for
manual tests so there's a problem here
it's that little thing when all your
system tests pass because our experience
was that they didn't pass some somebody
would make a mistake in their service
and it would some test would fail and it
would it would just be difficult because
they something would always be failing
and so the first thing we did was split
apart those that one suite of system
tests we needed to do this anyway
because they were getting too many of
them to run at once so we ran split them
up running parallel on different bills
agents and focus have one of the Suites
focusing on it one feature and the other
Suites focusing on another feature and
actually we had more than two of these
just like we had more than three
services this is kind of a
simplification so this was this was an
improvement we were getting faster
feedback because the tests are running
in parallel and we get a result sooner
and we also found that we didn't maybe
need to deploy everything if we were
just testing feature a who might not
need all the services so we saved a
compute power as well but it still
happens that people would break the
tests and it would still happen that we
couldn't get stuff out into staging and
that becomes more obvious if I just
highlight the areas that each team owns
so so team a owns these two services
here and this feature and Team B youngs
these other service in this other
feature and so say team B makes some
mistake in their service that they don't
catch and when it gets to the future be
tests it all fails and that's really
team B's problem to solve but it
unfortunately means that team a can't
get their stuff out into staging because
we we want all the tests to pass before
we deploy to staging and so we built
tooling we built dashboards that would
show Team B you are causing a problem
you know this is kind of slow make it
visible and then the problem will go
away but unfortunately it didn't
people would just yeah say oh yeah I'm
fixing that and it would still slow down
the other teams so we realized that we
were thinking about this wrong we needed
to make sure that our teams were not
just building independently deploying
independently deployable services but
they were testing them independently so
they could they should go further go
potentially all the way to production
without being impacted by another team
messing up so we did the we reject our
pipeline structure to look to extend the
the period where a team could work
independently of the other teams
basically so I've shortened Bill of
Materials to be OEM there but if you
remember that's just a list of all the
versions of the services that you want
to test together so what what we did
then was have a kind of a feedback loop
so that when team a wants to test a new
version of their service they grab the
Bill of Materials of what's currently
passing that the known good versions of
everything and we'll take that and we'll
just put my new version of my service
into that bill at for materials and then
I'll run the tests
this is before anyone else has seen a
new version of my service and so if if
it fails it's only my team that has a
problem of course if the tests pass then
I say great I'm going to send this into
the the overall whole bill of materials
for for manual testing and staging and
that means that they can get their stuff
out and if Team B has made some mistake
in their feature tests are failing they
don't
they don't get blocked by them but of
course if you're observant you'll
realize here that some if team a is
missing some test cases and they break
team B's stuff without realizing then of
course they will still block team B but
it's hopefully a little bit less likely
because at least their own tests passed
and if you're breaking stuff for another
team without realizing it that means
that you are missing a test in your
suite and hopefully you can talk to that
other team and write that test case and
next time you'll find it before the
other team gets affected the other thing
we we realize also you might not have
run all the tests against all the latest
versions of everything so you might need
to run the tests again before you deploy
to staging which we set that up but I'm
not sure it was needed and I don't think
they've failed very often so this is
kind of a work in progress I'm kind of
showing you where we got to with our
pipeline structure and hopefully it's
it's helpful and this is I've got some
more later about where I think this is
going but this is about where we got to
so that was one plank of our testing
strategy we had these end-to-end tests
for new features that we were writing
with synthetic data the test created its
own data so that's that was very good
but of course when you get into
production the data might not look quite
the same as your your data that you've
designed for your test cases so we did
this wasn't the only kind of testing we
did for the whole system so if you if
you think about testing and staging
versus testing in production this is a
testing and staging is kind of safe in
that sense if you deployed something
that really doesn't work none of your
users can see it so it's fine and you
can try anything out you like and unplug
cables and really it's not going to
bring your whole production environment
down and so this is a
why a lot of people use staging because
it's safer
the trouble with staging is that it's
got less hardware than production and
less data which means that some issues
that you see in production just never
arise in staging and that's that's bad
enough but even worse is that when you
find issues in staging that you discover
never occur in production so you find
you've been chasing this bug and
actually it's in production you have
more hardware and it just never happens
so this is this kind of thing where
actually maybe this shouldn't be your
only part of your end-to-end testing
strategies the only test in a staging
environment with synthetic data so one
of the things we were also doing was dif
testing where we would we would take our
production system that was running
production code and doing stuff and then
we would deploy into it a new version of
one of the services with some a kind of
a sandbox area of production where it
couldn't talk to anything else it
couldn't affect anything and then we
would so that's called a dark deploying
where it's there but nobody can see it
and then you start directing a duplicate
of some of the production traffic to it
so your new version starts to see some
of the traffic and can work out what it
would do with it and then instead of
then sending that response to somewhere
where anyone could see it like a user or
no it just logs it basically and
probably compares it with the value that
the production version of the service is
returning and then you can see what
happens and whether your new service is
behaving mostly the same as the old
service so we were doing this and we
were mostly doing this by hand actually
just having it log and then leaving it
there for a few hours and then looking
at the logs and see what it did and this
this was good we found issued like this
this gave us a lot more confidence that
our service would handle real data and
there's this tool called DC that we
never tried but I think him it would go
it would be something I would try now if
I had the opportunity which basically
automates that checking did it do the
same thing as the production version
what were the differences so that might
be worth looking at the other thing we
did was regression testing bulk bulk
regression testing so we would take a
portion of the production data into
staging obviously the production
databases is enormous and we can't
duplicate this is the hardware and
staging to handle that much data but we
can take a portion of it to test with
and then we can rerun thousands of
documents and just compare and I've got
the manual testing little thing here
because I tried to automate this I tried
quite hard to automate this so that we
could put in our pipeline but its
production data was too messy I found
there were always differences and always
needed to look at it and make a judgment
about whether this was ok but maybe in
future I would find some kind of way of
doing that diff and making it more
automated so that's kind of what we did
do and now I'm going to speculate a
little about what we should have done
some more off and here this is what I've
seen pipelines ended up looking like but
as I said we still had this staging we
would still test things in staging
before we went to production and I've
spoken to people with a much bigger
Micra services setup than we had and
many more developers and they're like
this this doesn't scale once you get if
you only have one staging environment
that everyone has to go through it
doesn't scale so at some point we may
have experienced this so what a lot of
what people do then is basically and
keep the pipelines for the different
teams entirely separate all the way to
production so they don't affect one
another and they don't have this
bottleneck of staging and then you you
have techniques like in incremental
rollout so that you can reduce the risk
of deploying versions of the services
that have never been deployed together
before because you've never deployed
them previously and staging together you
can roll out your new versions and
reduce the risk by only showing it to a
certain small proportion of your user
until you're fairly confident that by
monitoring it everything's okay and you
can roll it out to everyone so this is
kind of where I think we would have
probably be going in a few years when
the size of our mic receivers
architecture is bigger and our
development teams are bigger so that's
kind of where I think it's going we
didn't get that so just to summarize
this is my last slide I'm just going to
go through some of the ideas that I've
presented so the testing pyramid I think
is a good metaphor to help you think
about the proportions for different
kinds of tests you might need and how to
optimize that so that you get the best
return on investments you're not paying
too much for your maintenance costs but
you're still finding useful issues I
think it's useful to think about the how
you make a deployment pipeline and what
tests you put at each stage of that
pipeline and it it's so for me at the
end-to-end automated tests are the
that's the the hardest ones to get right
and the ones that can potentially cost
you the most so that's where I've put my
focus I've introduced techniques like
data-driven testing and approval testing
and I'm using this tool text test which
I there are alternatives it's just the
one I used approval testing as a
technique is is entirely platform
independent but I think it's good to
have a tool that will help you with
related failures and help you with
filtering and help you to update
approving approved versions I don't
think you should just roll your own I
think you should find a tool and then
just at the end I was talking more about
the keeping teams owning different micro
services independent of one another and
keeping the tests independent of one
another as well so that failing tests
that one team has owned owns don't stop
another team necessarily
from deploying their things so thank you
very much that's what I came to say
today</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>