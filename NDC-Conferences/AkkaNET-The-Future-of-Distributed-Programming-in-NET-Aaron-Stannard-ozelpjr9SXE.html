<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Akka.NET: The Future of Distributed Programming in .NET - Aaron Stannard | Coder Coacher - Coaching Coders</title><meta content="Akka.NET: The Future of Distributed Programming in .NET - Aaron Stannard - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Akka.NET: The Future of Distributed Programming in .NET - Aaron Stannard</b></h2><h5 class="post__date">2016-08-31</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/ozelpjr9SXE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right well that sounds like the
sounds like the Bell
we'll go ahead and get started here so
my name is Aaron Stannard and I'm one of
the cofounders of the aqua dot net
project and today we're going to talk a
little bit about iodine net actress
systems and the future of distributed
computing in.net so quick show of hands
from everyone in the room who's actually
used akkad on that before all right so
we got a little bit who is familiar with
the actor model who's heard of that
before quick show hands did bigger group
great and who's currently working on
what you would call like distributed
systems development but today a quick
show of hands all right cool so they
want to get a little level set for sort
of who's attending today so I'll tell
you why you should care about anything
that I'm gonna say over the next hour or
so and that's that if you're a back-end
developer today the expectations for you
and what you are expected to deliver at
work have never been higher than they
are right now in the Big Data space
there's this phrase called the three V's
you have to worry about so the first one
is velocity which is that's the amount
of work our servers are expected to do
is increasing in terms of the amount of
requests per minute or requests per
second we have to serve so the velocity
with which people are beginning to
access our services and the way in which
the beginning to use them is increasing
all the time
the second V is the concept of variety
and we're going to hear of a variety of
different experiences people want to
have with our back-end services so a
couple of good examples of things we
have to do today we didn't have to ten
years ago we have the service mobile
clients now who want access to their
data in real time on a device that has
much more limited bandwidth than what
you'd normally get from a desktop or a
laptop so you have to cater and
experience to suit them as well as our
existing sort of web clients - another
example of variety who is using signal
are today quick show of hands the
real-time web is a totally new type of
experience that's only really been
possible for the past five years or so
and that's yet another class of
experience we might be asked to deliver
to our end users at some point I'm in
the lasts of the three V's you have to
worry
about is volume so this velocity volume
and variety volume refers to the sheer
amount of data we're expected to use
retain and analyze in order to produce
the most value for our end users sir
expected to maintain a system that can
be available during all three of these
sort of increasing demands on us with no
downtime at all and so what all this
amounts to is that a chief concern that
back-end developers have had to get
acquainted with over the past 10 years
or so is the concept of scalability and
availability and what I'm going to tell
you in the next few minutes here is that
the reason why technology is like a
cadet and the actor/model are taking off
is because the obvious ways of achieving
this are all inherently wrong let me
give you some examples so your
traditional cred as followed this sort
of design over the past 20 20 30 years
you have a load balancer that
round-robin some requests to a couple of
web servers then you might have a
private zone with a sequel database
sitting in it that might have a slave
that it can fail over to you might have
a little ol lot process that goes and
you know grinds out all of your business
intelligence and analytics and then you
have your internal line of business
applications that all consume that data
for the different business units in your
organization so your analyst your
marketing team your finance people your
sales folks etc so this is sort of what
the traditional architecture has looked
like even today for your typical
enterprise application well let's take a
look at how some of the different
changes and you have lost the volume or
variety might put this system under
stress so based on this diagram if we
experienced the giant surge and user
activity so we experienced an order of
magnitude increase in the velocity of
the requests that we're handling any
given moment which part of this system
is going to be your bottleneck shout it
out if you know the answer sequel server
all the arrows are pointing there so
it's pretty obvious that's going to be
where the problem is well
the obvious solution for scaling this
problem is to do what throw more
hardware at the problem we're going to
use sharding so the idea behind sharding
is we take the same master slave system
that we had you're running one database
and one slave and we run multiple copies
of it in parallel and then we have a
router or coordinator help us partition
data equally amongst the different
shards so if you're partitioning data
that belongs to your customers
you might shard by the first letter of
their last name so shard number one here
might have customers a through D this
might be e through G etc and then we
have all of our actual clients in this
case our web applications all connect to
the coordinator so they can get their
requests routed to the right shard so
this is the obvious way of trying to
solve that bottleneck problem that we're
going to run into as our volume and
velocity as our velocity increases well
there's a couple of issues with this
design the first is that downtime is
inherent in this model if a master goes
down one of the new slaves needs to be
elected to become the new master what's
going to happen during the period in
which there is no master for all those
requests he guesses anarchy they're all
going to be failed so any requests that
tempted to go through during that period
of time to that shard will all be
unavailable but that's not the most
insidious problem the real failure of
this design and this was state of the
art like 2003-2004 is the fact that it's
brittle who's familiar with the concept
of a network partition quick show of
hands all right this is what a network
partition looks like so imagine there's
a hardware switch in your on-premise
data center that fails briefly you can
might only need to be down for a handful
of seconds in order for this to happen
these masters can't communicate with
their slaves on the other side of the
partition anymore all the server's are
still running so there's no machine
that's down but they just can't contact
each other what do you think is gonna
happen with these slaves can't see their
master anymore we're going to end up
with two mad
for one shard this is a specific type of
network partition known as a split brain
is the name of this and it's the most
dangerous type of partition because most
of the time if you don't have good
monitoring tools you won't even know
that it happened is it's a software
error it's not a hardware error so what
can happen when you have a split brain
is data corruption so imagine you're
using like auto incrementing IDs and
sequel server
well one record might go to one master
and another record might go to the other
they both have the same ID but they're
totally different pieces of data that's
data corruption data loss is also
possible so this is a pretty dangerous
design but this was the obvious way to
try to scale that system we had before
but its weakness is that it can't detect
and handle partitions very well now
another scenario we're going to look at
the variety aspect here let's say you
get asked to take your existing
application and add a component of
real-time user interactivity to it
so here's the little data flow for what
that might look like user generates an
event let's say it's a click stream on
your website so someone's clicking
through buttons and links and you go
ahead and record an event for each one
of those if the user produces four
events four particular events out of a
possible set of hundreds of thousands
you want to send that user a specific
message maybe if you're running an
e-commerce site you check to see if the
user is clicked on these four products
and if they have you offer them a fifth
one that might be related to them that's
one example of how this might look if
the user hasn't produced those four
events you just want to keep waiting and
try to observe in real time are they
gonna do it or not and I had to actually
build this system in production to
handle hundreds of thousands of users
simultaneously and this is part of the
origins story of akkad on net two so the
obvious solution of this problem is to
keep using our database that we had
before and use a strategy called read
after write so we have our same little
hardware setup and here's what we're
going to do a users going to produce the
four events are looking for so we go
ahead and write the first event to our
sequel database and then we
what are the range of events that have
been written back out so we write zero
we read zero back we write one on the
next server we read zero one one back
and so forth until eventually when the
fourth and final event is written we
read back the full set of events we are
expecting and fire off our notification
now the way this actually works in the
real world if you try this design which
I did is you can actually predict the
order in which anything on the network
will happen even under ideal
circumstances your database can't be
responsible for the level of concurrency
that's happening above it in the
application layer so the truth of the
matter was eat them with very high
consistency settings if I went and
started writing events and reading them
back out I'd get totally different
results back than what I expected
and so the truth was was just
frustration was all that I got for my as
the fruit of my efforts here so read
after write is not a practical solution
for doing for doing real time user and
activity and the other reason why
doesn't work very well is because it's
slow round tripping to a database incurs
network i/o overhead disk i/o overhead
of the database layer serialization
overhead in both directions and on top
of that you usually have some IO
completion port overhead - and all that
adds up to be something that may not
necessarily work very well quickly at
scale so these are the sorts of problems
that we're being asked to deal with and
the obvious ways of solving them don't
work so distributed programming is hard
for the following reasons the first is
dealing with state that was
fundamentally what we were trying to do
in the last diagram was we were trying
to build a stateful application that
could observe a stream of events and
react appropriately dealing with state
in a web application is hard because why
who can guess HTTP is a stateless
protocol makes it very difficult to
guarantee your state ends up in the
right place in the network so that's one
reason and we'll explore a couple of
others who makes this concurrency raise
your hand if you think shared state
currency with locks semaphores critical
regions is easy good that's the correct
answer
no one concurrency sucks it provides
tremendous benefits but doing it right
is hard at least it used to be
next is topology and discovery both of
those architecture diagrams I showed you
earlier followed what's called a tree
architecture where you sort of have your
load balancer at the very top of the
tree then one layer leaf nodes your web
server and then you have your database
server underneath that none of your web
servers know about each other under the
load balancer as far as they know they
exist in isolation from everything else
that lack of topology awareness makes it
very difficult to deal with state
appropriately in a distributed system
that's one problem in and of itself the
other is discovering who's available to
do work in your network it's not only
knowing like which addresses should
servers be at but who is still there
who's died in the past few minutes who's
come alive again that sort of thing we
have a module and akkad on net called
akka dot cluster that deals with this
problem very specifically next is
recovering from failures so one of you
probably attended some may be a micro
service talk before and they talked
about this notion of fault isolation
that's one category of problems you have
to deal with on the network which is
what happens if a one service crashes
you want to have some sort of partial
failure mode so the rest of your
application can continue what about more
insidious types of problems like that
network partition what happens if those
services aren't completely unavailable
they're just not reachable right now how
do you deal with that appropriately how
do you deal with more localized failures
like what happens if one particular
stateful entity in your system suddenly
crashes as a result of a software
failure how do you heal from that and
recover well the actor model has an
answer to that
next is bottlenecks so people like these
sort of master oriented systems like
sequel server because conceptually
they're easy to understand there's one
node who dictates what the right answer
is for each transaction it's pretty easy
to follow
but what you give up in order to do that
is you give up the ability to scale
linearly you're stuck with this one sort
of bottleneck node that has to be there
at all times in order for you to be
available and as soon as the capacitor
load on your system exceeds that nodes
capacity to stay up you have a problem
then on top of that there's the matter
of consistency
this means all nodes seeing the same
data at the same time now the truth of
the matter is once you have more than
two computers in a network its varied
it's not possible to have perfect
consistency the speed of light is your
minimum bound there but you do have to
keep in mind sort of what levels of
inconsistency can you tolerate
temporarily from nodes this is the
concept of eventual consistency that's
another issue that we have to deal with
and lastly there's availability this
means the ability to stay up and be able
to successfully respond to requests so
you have a service to be available it
has to be able to go ahead and return
the equivalent of like HTTP 200
something like that these are all hard
problems in and of themselves one gonna
tell you today is that they're hard with
the tools and what we've used been used
to using as web developers primarily we
have to look at these problems from a
different perspective and they become a
little bit easier to manage so what
we're going to use to sort of solve some
of these problems today first is we're
gonna embrace state state is no longer a
bad thing and it's not going to live in
our database anymore it's going to
become part of our application next is
we're gonna embrace a concept known as
protocol driven design these are ways of
building distributed systems that plan
for a failure as an eventualities not
something we sort of you know stick our
heads in the sand and hope to avoid we
go ahead and base they anticipate the
failure of the network is something that
is inevitable and we factor that into
the design of our protocols fault and
resource isolation is another thing
we're going to use we're gonna come up
with a strategy for dealing with
failures locally so they don't become
some problem that a central coordinator
node has to handle decentralized
architectures are another thing we're
going to
this means no more masters actually the
right way to really phrase what a
decentralized architecture is is it's a
peer-to-peer network but on the server
side that's what that is and then the
cap theorem this is our decision-making
framework we're going to use for
deciding what sort of compromises need
to be in our distributed system in order
to fulfill our business requirements so
these are the you know consistency
availability and partition tolerance now
one thing I'm gonna state before we dive
into the gist of what the actor model is
and how it helps with these issues is
that don't assign any moral weights to
any of the cap categories I meet a lot
of DBA s or turn programmers now who
think consistency belongs like an altar
above the other two it's not true
they're just different currencies you
have to balance and then design your
system according to what your business
requirements are so enter the actor
model this is gonna be the tool that
we're going to use to try to address
some of these problems the actor model
dates back to the early 70s the original
actor model white paper by Crowell
Hewitt is only a couple of years younger
than the original relational database
white paper 1973 was when the virginal
actor model white paper was written so
it's a fairly old concept and where the
actor model originally came from was
this vision in the 1970s of how big
servers are going to be designed it was
gonna be a single machine that had
thousands of very small CPUs built into
it so lots of 486 processors and that
sort of thing and that's not how reality
turned out for how computers are going
to be designed Moore's law saw to that
instead we have servers that have a
relatively small number of course maybe
as many as 64 rather than the thousands
that crawl Hewitt and his team were
imagining and they can are much more
powerful than anything that was imagined
back then but the actor model sort of
found its place in the late 80s and
early 90s when we needed to develop some
modern telephony software for the first
digital networks so Ericsson had an
engineer named Joe Armstrong who was
tasked with developing some software to
handle these sort of modern data
networks think of it as like a big
backplane for handling all the phone
calls
will not text messages but other types
of data packets that be going through
the network they had to come up with a
system for routing all this this is the
original web-scale sort of problem back
in the day so Joe invented a commercial
implementation of the active model known
as Ericsson language later renamed to
Erlang so this is the real first
implementation of the actor model that
was really accessible by developers and
it allowed them to build telephony
networks but a little bit later let's
say we jumped forward 10 years - the
first dot-com boom where Erlang and the
actor model saw some action again where
some of the first really big publicly
traded online companies doing things
like real-time advertising networks or
doing multiplayer games that sort of
thing those models were all pretty
naturally suited to the same sort of
design concerns that Erlang had namely
you have massive concurrency so millions
of operations happening in parallel
cross the network at once but you also
have this sort of real-time component to
it how useful would a telephony system
be if it delivered all of your of voice
packets in batch 30 minutes later it'd
be utterly useless right it'd be like
AT&amp;amp;T the United States sorry there I
always make fun of them they didn't
deserve that but the gist of it is all
these systems have these sort of
real-time concurrent scaling issues that
they had to solve well jump forward
another 10 years to the advent of cloud
computing a lot of the applications you
work on whether you're in insurance or
e-commerce or healthcare or doing
Internet of Things which is a category
that didn't even exist
all that long ago you're all subject to
a lot of the same sort of forces that
these other older applications like the
telephony networks and advertising
systems all had to deal with 10 20 years
ago the difference is today that the
actor model is now available on more
runtimes there's akka on the JVM akkad
net and the CLR and if you attended the
Orleans talk earlier today that's
another implementation of the actor
model so here's the core concepts that
make the actor model simplify a lot of
these distributed
Gaming problems I spelled out earlier
the first is that actors are a
fundamental unit of work and concurrency
you could think of them as sort of a
self-contained little micro process all
communication between micro processes is
done via message passing kind of like
how IPC would work with a normal full
blown Windows process so these are how
actors communicate all messages the
actors share are immutable and there's a
very important reason for that that will
touch on a next sender and receiver are
always decoupled from each other and are
fully asynchronous so when you tell an
actor a message you don't get a task
back in alkanet that doesn't mean it's
not asynchronous just that we typically
don't give you a handle back for waiting
on what a message was received there's a
lot of what Erlang and the sort of
original active model implementations
try to encourage our things like one-way
messaging because they're fast and
they're cheap next in terms of what
actors can do they can process messages
actors do work by chewing through the
contents of their mailbox so these are
all the messages that have been sent to
them sit and a little cue that the actor
processes actors can also spawn other
actors and and acha
this concept is known as sort of like a
family tree when I create an actor I'm
creating a child of myself that actor
can go on to create its own children and
so forth you can have these sort of
hierarchies that go several layers deep
actors also have the ability to change
their behavior between messages so
imagine you have a bunch of what are
called receivers little statements you
declare specifying how to handle certain
types of messages you could switch those
depending on the state of your actor so
this is where the concept of a finite
state machine comes into play so here's
a good example of a finite state machine
with as far as actors are concerned
let's say you're building a chat system
and you had an actor represent every
user who is trying to connect your chat
server that user could be in one of
three possible states at any given time
unauthenticated
authenticating or fully authenticated
and the unauthenticated state do we want
to allow that user to send messages to
the chatroom no we want to discard them
if a user starts to authenticate we
transition to an authenticating state
and now let's say a user tries to send
some messages of the chatroom then what
do we want to do with those maybe we
want to buffer them and hang on to them
in case the user successfully
authenticates then we can deliver them
and if the users fully authenticated we
just want to deliver the message at that
point that's an example of behavior
switching in action the last thing
actors can do and this is key is they
can contain private state actors can
have their own internal members and data
structures that they use and you can use
those to accumulate state inside an
actor over time this is what makes
actors effective for building these sort
of stateful systems now actors also make
some promises - the first promise and
the most important is that actors only
process one message at a time so if they
have a queue of messages in their
mailbox they're only ever handling one
of them at any given time next those
messages are always processed in
first-in first-out order otherwise known
and the order in which they're received
so actors make a guarantee that's how
they'll process their messages now you
as the developer using akka Dannette can
modify that for instance we have this
concept known as the mailbox this is
where actors cue their messages that can
be overridden by you as the developer to
use a priority queue if you want so you
can prioritize certain messages ahead of
others the last guarantee the actors
make is at most once message delivery so
when we send have an actor send a
message to another that's it by default
we don't go and check to see if that
message got delivered the reason why
that is is because the core akka
philosophy is to be extremely dumb and
fast so the reason why we do that is
because we view akka as infrastructure
we don't try to guess what you want to
do is the end user you explicitly tell
akka what you want our philosophy is
that it's a lot easier to add and
elegance where you need it than to go
through and turn it off where you don't
that's the reason for that philosophy
the last thing is that every actor even
in a big Network where you might have
millions of actors and thousands of
servers every actor has a global unique
address their own unique URI you could
use to send them a message but typically
you don't need to know that you or I is
the way you communicate with actors is
through a construct known as an actor
reference it's a handle to an actor now
I'm sort of spelling all this out now
before I go into detail in each subject
so if you're worried about all the
information don't worry about it
we're gonna cover it a little bit more
extensively as we move on so these are
all the core concepts at work here and
I'm going to spell out for you sort of
how these give you some benefits for
being able to build these distributed
systems so algodón that gives you all
this for.net and akka dinette consists
of a handful of modules we're gonna be
spending most of our time talking about
the core actor library which is akka
this gives you all the core actor
functionality all the ability to send
messages the ability to go ahead and
have actors that are stateful actors
that can run on the UI thread of a
windows forms application that sort of
thing so that's what the core akka
library gives you Alka dub remote gives
actors the ability to communicate with
each other across different windows
processes on the network so that's sort
of the next layer up when you want to
start doing some networked work with
actors then we have aqua dot cluster
which is a module that gives multiple
akka dot remote nodes the ability to
form a decentralized network with each
other then we have a cadet persistence
which is a library that allows actors to
use events sourcing to record their
state to some durable store and we
support like 12 different databases
right now
everything from sequel server to
Cassandra to events store to raven DB
have even seen out in the wild so
there's a lot of different targets we
support for that if you have questions
about some of the other modules on here
I'll take those at the end now what's an
actor actually look like this is an
example of what's called an untyped
actor it's just a class that haratz than
this untyped actor base class so there's
multiple different base classes that
akka Dianetics poses
untyped actor is the dumbest does the
least amount of work for you
typically in production I use an actor
that's known as a receive actor this
gives me these sort of typed predicate
functions I can use for matching
messages in c-sharp 7 when we get
pattern matching a first sort of first
class language constructs you'll
probably see the untyped actor get used
more commonly again now the most
important method on this class is this
one on receive every time an actor
receives a message when the actor is
ready to process that message it'll be
handled inside that method lets him to
keep eclis what you do when you receive
a message is you do some work so that
might be maybe making a web service call
over the network maybe it's doing some
sort of validation maybe it's just
transforming the message into some new
type of object and sending a reply back
to the original actor you could do any
number of things that's the most
important method the other ones up here
pre-start pre restart post stop and post
restart these are what are called life
cycle methods these are built for having
an actor initialize certain resources it
might need when it first starts so you
might put that in your pre start method
or imagine what would happen if an actor
through an unhandled exception if you
had a process crash on your Windows PC
what would you do with it what would you
hope the process would do if it was
critically important restart it right
one of the things that actors do is they
have this philosophy of when you run
into an unhandled exception or some type
of failure you're much better off just
letting the actor crash and restart back
into its initial original state and the
reason for that sort of philosophy is
this idea of all the error handling code
you typically have in your application
how well tested you think that is it's
simply in that area where if you're
using dot cover it's typically in the
area with all the red highlighting that
error modes and fault paths typically
aren't covered very well so lot of them
try to go and come up with these
intricate and typically brittle error
recovery systems why don't we just go
and reboot the components of our
application that faulted back into the
original safe state in the state they
were when they failed and that's the
akka philosophy buying how we typically
handle failures you just let it crash
let it restart and so with actors that
are using things like akkad uh
persistence the original state of that
actor will include whatever its last
recorded the state to the database was
of the time it crashed and actors don't
lose their messages when they crash
either the as you'll see in a moment the
mailbox which is the sort of cue that
holds the actors messages is separate
from the actors state itself so we'll go
ahead and destroy this simple actor
instance and replace it with a brand new
copy of it when we restart so that's
sort of how the actor lifecycle works in
those sort of failure states now when it
comes to actually doing with state and
being able to manipulate it sort of
concurrently in a distributed system
actors really simplify that problem
pretty dramatically so internal state of
an actor looks just like any other
normal net object it's just some field
or a property that you set inside an
actor no more complicated than that now
what's interesting about this state is
that it's always designed to be private
actors don't expose their state as a
property that anything can go and access
anywhere else moreover that simple actor
instance we saw earlier when you start
that actor you can't get a reference to
that object anymore it's hidden inside
this sleeve known as the actor self this
gives us the layer of isolation from
other processes in our system in order
to make sure that actors can experience
what's known as a side effect who's
heard of that before that term side
effects Kolb's about third of the room
the side effect is what happens in a
concurrent system where one process
modifies another state of a something
else that process B is depending on we
try to avoid side effects that's how you
end up with unpredictable havior in a
concurrent system so actor state is
private and it's only ever shared or
modified by sending messages or or
receiving them so actors when they go
ahead and build like sort of flush
themselves
live in this family tree structure you
have a rude actor in this case this is a
built-in system actor called user this
will create some top-level actors then
we have some children underneath them so
this is sort of what an actor construct
looks like in production and here's
what's kind of interesting about this is
that every single actors address its
unique your rhyme is a composition of
who is above it in the family tree so
this grandchild has the name of its
parent baked into its address and so the
way akka tends to work itself is there's
no central registry or coordinator no
that keeps track of where all the actors
are all that information is
decentralized into very small bits eat
only this actor knows who all of its
children are and so whenever we want to
try to deliver a message to an actor via
its address we sort of recursively
iterate down the tree until we find the
correct actor this is designed to help
allow al Qaeda yet to be very lean and
memory efficient that's why we do that
now giving back to this idea of
processing messages I mentioned that
actors have internal state and they're
considered to be a fundamental unit of
concurrency the big goal of the actors
system from the point of view of disk
concurrency in your application is to
allow you to have state inside your app
with no locks no critical regions and no
synchronization mechanisms and no
contention and the way we achieve that
is through our one message at a time
processing guarantee so imagine this
sort of initial state of the system we
have a mailbox with three messages in it
and an actor and then this sort of
sleeve right here represents the actor
cell the actor will begin processing
message zero at that point in time maybe
another message message three gets
queued into the back of the mailbox
message one does not get processed until
this actors on receive method exits once
it does that the next message will begin
getting processed so quick question for
someone in the room to answer if an
actor can only process one message at a
time that's guaranteed by the system
if we modify the state of our actors and
we're processing messages what can never
happen if we're only processing one
message at a time the state can never be
modified concurrently it's safe all
actors state is inherently thread-safe
this is what allows us to build
distributed systems that can be stateful
and can avoid all the classic pitfalls
of shared state synchronization what you
do is you divide your state across a
large number of actors each one holding
on to only a tiny fraction of it well
people tend to do if we go back to the
previous diagram what people typically
tend to do when they're modeling an
actor system is let's say you're
building an e-commerce application you
might go ahead and model a sort of actor
hierarchy like this well let's say this
part of the hierarchy represented all
the products in your catalog and you
want to have one actor represent each in
vain' pH piece of inventory you're
carrying so this actor might represent
all the total inventory for one product
then it might have another sibling named
after another product and another like
that and you tend to sort of flesh out
your state across a small number of
actors they'll all have the exact same
code but they represent different
entities this allows you to write code
that is very simple and easy to follow
but also work scales beautifully in
production now the next thing
unfortunately actors are not magic they
do run on threads so the way actors tend
to work in production oops so I just
realized I forgot to start the timer on
here the way actors work in production
is that they typically split time across
threads but that's sort of done under
the covers that you need to know about
it so a one on this case going on core
one might have a message to process and
so my a two and they'll go ahead and go
through the core and finish there
basically they'll finish their
processing they'll have finished a run
of messages typically an actor will do a
batch of like 30 messages or so each
time they're scheduled and they'll go
ahead and yield the thread to the next
actor in line
then the rest of the actors might go
through gets in you're processing and
you'll see a one whoops a one gets
scheduled again to execute so actors
share threads the reason why I mentioned
this is that in order to process one
message at a time with an actor
we still need to use a thread but what
we do is we basically guarantee that for
a brief period of time an actor can hold
on to a thread whether it's in the TPL
thread pool whether it's running on the
UI thread if you're using a synchronized
dispatcher the actor will go ahead and
basically complete a run of messages and
then yield and wait for the rest of the
system to go so these are how actors
fundamentally work so I'm giving you all
this as background to talk about just
the concurrency and state part of
distributed systems so far we haven't
touched on any of the other major
classes of problems you described yet
it's one thing that's really important
to note about akka actors is that you
don't necessarily need them just for
building distributed systems there's
lots of folks who use them in
client-side applications and even some
folks who have them running on xamarin
Android and iOS right now for basically
just handling UI events that might
percolate up concurrently akka scales
down to support that use case as well
too now when it comes to the network we
deal with messages as sort of the
primary way actors communicate messages
versus the so there's a couple different
ways you can think about communicating
over the network most of us are web
developers I'm assuming in the room and
the primary way I think a lot of us tend
to think about the network is in the
form of like our PCs remote procedure
calls well I'll go ahead and send HTTP
verb and some state to a web api method
and I expect some response back so these
are these sort of request response
driven systems messages when you work in
message oriented programming and this is
the sort of thing you'd get with actor
systems or the message bus like rabbitmq
and service bus these allow for a couple
of different modes of communication you
can't normally achieve which is plain
old RPC so messages are always comprised
of two parts the payload and they're
applied to address the actor that sends
a message
to someone else on the network might not
be the same actor that gets the response
back at the end this allows us to
decouple who the sender the receiver and
the final destination for a response
might be and allows for some
communication patterns they're a little
bit more flexible than what we're used
to with RPC message sending is always
asynchronous the other thing that's cool
about messages is they can be serialized
and stored so one of the reasons why we
use event sourcing as the model for
allowing akhada persistence to work is
you can have a persistent actor decide
to journal messages it's been receiving
as part of its state when it needs to
rebuild its state down the road what
does it do it DC realizes those messages
back out of the database and replays
them during our recovery phase that
allows it to go ahead and rehydrate its
state back up from nothing so these sort
of message driven systems over the
network play very nicely with that as a
persistence model now the other thing
that's cool about messages is you can
exercise what's called a deferment of
processing a message so that finite
state machine example I had earlier
remember when I mentioned that during
the authenticating state we might want
to buffer some messages before until we
get their reply back as to whether the
user successfully authenticated or not
that's an example of a deferment we're
deferring processing of those messages
even though they arrived first because
we're not on a state where we can handle
them properly yet this gives us some
more flexible message processing
capabilities - you can't really defer
processing of an HTTP request you have
to serve it and move on so the client is
in timeout the actor model allows for
more flexible modes of communication
than that which is another reason why I
can help us solve some of our network
topology and communication woes the
other thing we can do with messages is
we can delegate who executes them to
someone else one of the things you
typically see in these actor hierarchies
is the parent actor closer to the top of
the hierarchy usually delegates
processing of messages to its children
so you tend to see these sort of
messages trickle down from the top of an
actor hierarchy down towards the bottom
that's very common
and the last thing you can do with the
message is you can do broadcasts or
multicast messages where a message can
be sent to multiple parties for
processing so a good example of that is
in a couple of systems that helped some
akkad ainít users design they have to
have control messages but these are
particularly true for some of our I Oh
tea customers well what they need to do
is be able to send a like kill message
out to a number of devices when a
controller goes down this is part of
like a safety regulation we have people
using akkad on net in the oil and gas
industry for instance being able to go
and broadcast that and confirm that
everyone received it is a very useful
communication pattern in that sense so
these are all types of more flexible
modes of communication you can get with
these message driven systems that you
can't very easily do with RPC what this
allows us to do is use some types of
messaging patterns we can use to
communicate over the network so
broadcast is one example one node can
take the same message and broadcast it
to multiple destinations proxy is
another example where a node can go
ahead and by the way node in this case
can also mean actor I'm sort of using
the term interchangeably here I can
basically proxy the message down to a
different node than who originally
received it and they can fulfill the
request and reply back this allows for
more flexible types of routing in our
system pub/sub is another great example
so we can have a couple of nodes
subscribe to a publisher who will go
ahead and notify them when a message of
interest arrives and then they can go
and do some work with it the way people
tend to design a lot of big scale actor
systems is they have lots of little
layers of pub/sub they use to construct
a protocol and that allows the system to
be very reactive we're an actor at the
top of the publishing chain receives a
message and causes the sort of Cascade
of work to flow down from it those
systems are very easy to design and
debug that's why this pattern has to be
popular and then my personal favorite
because it's fast one-way messaging when
I go ahead and I fire it's like
fire-and-forget messaging I send a
message and I don't care what happens to
it I used to work on analytic systems
and the majority of our communication
looked like this because it was too
expensive to build in requests for
Bonz so these are types of communication
patterns you can use between individual
actors well this allows us to construct
a proper messaging protocols the way you
want to treat with issues over the
network isn't by thinking about the
design of specific actor classes or the
design of specific messages rather you
want to design a protocol for
communication between actors that can
account for failure so this protocol
about to show you I think as it can
sends this protocol I think that's what
this example is where right comes into
one actor and this actor needs to
coordinate with some replicas of itself
over the network hey are all three of us
in a state where we can accept this
right is this a valid and consistent
thing we can do and the other two nodes
reply back with yes then we can go ahead
and commit the right in all three places
this is design to achieve a measure of
consistency and all the data that's
being modified over our network the
reason why I show this as an example is
this is the way people think about
designing systems and actors there could
actually be a whole hierarchy of actors
underneath any one of these nodes
participating in fulfilling this
operation but that detail is abstract it
away from the protocol itself if you
treat the protocol as your specification
for how individual actors talk to each
other
whether the local or over the network it
gives you a very flexible design so I
haven't shown this yet but how actors
actually talk is they communicate via
reference so this is an actor system
this is the sort of shared namespace
actors used for talking with each other
it sort of provides a little fabric a
context that they can use for naming
themselves for being able to go and
address other actors on remote systems
etc then we go ahead and we actually
create an actor here this will be a
little greeting actor and we're giving
it a name greeter when we want to have
an actor actually process a message we
get this thing called an actor reference
back right here and I can tell the actor
reference any arbitrary dotnet object
and that object will be delivered to
that actor regardless of where it is on
the network
this is because this actor reference
object has an important property known
as location transparency who can name
something you use every day that also
has a transparent location well got an
example on the slide your cell phone
number has a transparent location so if
I want to give you know my best friend
from childhood a call he's in Washington
DC and I'm here in Sydney I don't need
to tell AT&amp;amp;T how to manually route all
my voice packets to him in Washington DC
I just need to know his phone number and
his transparent is location in the world
physically is transparent to me as a
detail there another example of
something that has a transparent
location is the domain name system we
imagine a world would you had to
manually memorize all the IP addresses
for Google home servers that'd be pretty
awful right the DNS system helps make
the location of where those servers are
in the world relative to us
transparent and the load balancer
sitting beneath those does the same
thing again what the idea of location
transparency is really about is being
able to go and interact with systems
without needing to explicitly program in
your code whether they are a local or
remote system so this code I showed you
in the previous slide I could specify in
Houk on the configuration form at the
akkad on it uses that this actor is
actually gonna live on a remote process
in another datacenter this operation
would still work even if that actor
lived you know on a totally different
machine thousands of miles away might
take it a little bit longer to get my
message but it would still work and the
reason why this is a good thing for
building distributed systems is it
solves the problem of topology if you
don't need to care where an actor is on
the network in order to interact with it
it makes it very simple for you as the
developer to go ahead and build an actor
system that implements a protocol for
achieving some goal without having to
worry about editing configuration files
without having to go and spin up a bunch
of machines to test it you can design
code that works locally and
expect that to still work over the
network as long as your protocol is
designed to account for failure so in a
NACA dotnet cluster what you tend to
have is you have a number of different
these are actual like let's say these
are servers for argument's sake these
servers can each have actor systems that
have hundreds of thousands of actors in
them in memory any given time I can have
an actor on system a get a reference to
an actor on system II and they can send
a message back to it without needing to
know that node II even exists under the
hood akka dot cluster and Nakada promote
give me that transparent location on the
actor reference and that's all I need to
worry about I just have an actor ref and
I send it a message so this is the next
big thing that akka dontoh actors give
us is the ability to go ahead and
transparently extend code that works
locally over the network it's not magic
just good design one of the other things
that helps us I'm sure that's possible
is each one of these connections here so
these are aqua dot remote associations
is what these are in order for them to
work and preserve all these actor model
guarantees I showed you earlier one of
the things we have to do is preserve
message order on the wire so messages
written from node a to node E also obey
a FIFO ordering so that means that any
actor on node e receiving messages from
node a will receive the messages and the
order in which that actor on node a sent
them that's guaranteed by the way the
framework is designed now let's talk a
little bit about state one more time of
these two architectures I have on screen
here we have this sort of stateless app
that does request response to a database
server whereas we have a stateful
application server that has all the same
information but it's available locally
in memory which of these two
architectures will produce the fastest
response time
given the same data sorry stateful right
by an order of magnitude at least maybe
two orders of magnitude
the idea behind stateful applications is
that base or the single source of truth
is in your applications memory so you
might have a stateless web server that
does some work and it goes and talks to
a stateful app server the APIs over will
go ahead and serve a response available
immediately from its own memory but
it'll asynchronously flush and read data
from the database server as it needs it
here's what this model is really all
about
we're inverting the role of a database
from being the single source of truth
that we depend on for every single
request to treating it like a dumb
backup that's the idea behind stateful
application design you still have a
database but its role is different it's
just there for recovery purposes now and
so this actually this type of design is
capable of achieving speeds that are
unheard of in traditional stateless crud
designs and this is because we benefit
from a principle known as state locality
raise your hand if you've heard this
term before
okay good this will be new then what
state locality refers to is this idea of
the data your application needs to run
is adjacent in memory to the code that
runs it so this means that you don't
have to go very far to get the data you
need to do your work so remember that
second scenario I showed you the real
time event processing how fast would
that be if all the data for processing
those events was available inside the
Actor's memory who was processing them
it means that's the difference between
getting the data you need much looking
at a register adjacent to you in memory
versus serializing a message going over
the network to a database having that
database read something from disk
serialize it but you get you get the
idea
state locality allows you to build
extremely fast systems and this is what
all these real-time systems tend to use
now so the full stream processing
example I showed earlier would only
really be able to achieve its goals by
leveraging this principle and actors
make that very easy by allowing all the
state to be something that resides
locally inside it so that's the idea
there now
the reason why I bring up state is state
as well allows these protocols we talked
about to work during that consensus
protocol example I showed earlier what's
really going on under the hood is that
each of those actors who are
participating in that operation all have
some data about the current state of the
object there they're modifying and about
all the other requests that might be
happening in parallel for that same
object where is an example of state at
work and a different type of protocol
who's heard of at least ones delivery
protocol before raise your hands or
exactly once delivery all right cool
those are protocols that use state to
guarantee that messages are received and
processed by their destination so a lot
of people who use Akkad on network in
finance and they're paranoid about
transaction never going through right
for good reason usually they end up
losing so on
often themselves a lot of money if they
don't do it so at most once message
delivery requires no state that's why
Akkad on it uses it by default but the
consequences messages will be lost
eventually as soon as there's a network
failure well let's say we want to make
sure we have reach viable delivery of
messages so we have a technique known as
at least once delivery well what we do
there is we go ahead and have some state
on the sender about which messages we've
sent and to whom and how long has it
been since we've sent them we expect
with some form of acknowledgment back
from the receiver letting us know it got
the message if we don't get
acknowledgment back we'll go ahead and
redeliver the message that's the state
the sender has in this under this
protocol and as a consequence of that
you might have duplicate messages
potentially but at least you can
guarantee that messages are never lost
in exactly once messaging protocol we
have state on both sides of the wire the
sender has the exact same state it did
before an hour at least once delivery
scenario but now the sender also has to
keep track of which messages is observed
before this is what's known as an
acknowledgement buffer has to keep track
of which messages it seen because why
would you want to keep track of which
messages you've seen before
scenario what are we trying to avoid
duplicates we don't want to process the
same message twice do you think it might
be a problem if we process the same
trade twice on a stock exchange probably
so the receiver also has to have the
state here so we design your protocol
between these different actors in your
distributed system thinking about the
role that state plays is pretty
important actors still make that really
easy but you just have to sort of
exercise a bit of a sort of awareness of
what you're gonna need to make it work
then the last part will sort of close
out with here in terms of talking about
distributed systems with actors is the
cap theorem it's a quick show of hands
who's heard of this before
okay cool about half the room so the cap
theorem I really think of as just a
decision-making framework that allows
they sort of offers some trade offs
between different quantities and
distributed system I think incorrectly
people state that you have these three
quantities CA and P pick - it's really a
lot of sense is a little bit more like a
gradient to some extent where you might
have some systems that are more strongly
consistent some that are more available
etc well each of the terminologies mean
is first consistency different than the
consistency in acid this refers to all
nodes seeing the same data at the same
time an eventually consistent system is
one where the time between the is the
current state of an object on one node
is gonna be there's some lead time
between that among the other nodes get
updated availability is a guaranteed
every request receives an explicit
response and partition tolerance is the
system being able to continue despite
arbitrary partitioning due to failures
on the network so that the split-brain
was an example of partition intolerance
right essentially our system wasn't able
to tolerate that partition and as a
result our consistency suffered mightily
for well what the worldís plays a role
in terms of this sort of the cap theorem
is it affects the way we design our
protocols a proto
have to basically be designed in such a
way that it takes into account our
businesses cap requirements so quick
example reddit they have a system that
basically values being able to serve up
content on their home page no matter
what the vote count that you see in the
right hand corner whenever you look at
an article ever refresh the page notice
that value jumps all over the place
there an example of a system that really
values availability way more than
consistency because they can't serve ads
they can't serve content and they can't
keep users on the site that ever changes
an example of a system that really
values consistency would be a patient
record system could you imagine a
scenario where let's say you have two
members of a hospital staff treating the
same patient one hospital staff member
makes a record of a medicine that they
just dosed a patient with and the next
hospital worker comes along and can't
see that state in the system yet did you
see their potentially being some some
accidents that could occur as I was
little aback that's an example of a
system that values consistency you'd be
way better off having your patient
record system go down and force the
actual you know caregivers to talk to
each other in real life then you are
serving up an incorrect result and
having the patient get the same medicine
twice right this is an example of how
cap effects are protocols to on the top
I'm gonna have you guys guess which one
is higher consistency versus lower on
the top we have a sort of a consensus
protocol again we're basically a write
comes in for a given entity and we go
ahead and have a couple of actors agree
that this white can be done consistently
across all three and then then the
transaction gets committed at that point
on the bottom we have a slightly
different design where the protocol
basically states that a write can come
in this node will immediately accept it
and then notify other nodes who are
subscribed to this information after the
fact this is called a commit and notify
model so quick show hands who thinks the
diagram on top is the more consistent of
the two
all right who thinks the bottom one is
the more consistent of the two who has
no idea what I'm talking about
got a couple hands alright so the answer
is the diagram on top is the more
consistent the one on the bottom is the
more available now the reason why that
is in a high consistency system where
you basically only allow a certain so
there's this concept of interleavings of
writes in a given system so quick
question for people in the audience to
have a relational background could I
update a record in a database after I've
deleted it so we'll want to shout out
the answer no you can't right that's
part of sequels consistency model the
data has to exist in order to be updated
in Cassandra which is a more a database
with more relaxed consistency
requirements if I have a delete on one
node and I have an update on another
node it happened at the same time let's
say if I'm running on relatively low
consistency settings what's going to
happen well yeah he shrugged that's
actually the right answer probably who
knows what's gonna happen the answer is
if the update happened last that will
override the delete so you basically
have this last right wins issue the idea
was consistency is that and that first
design you're going to be unavailable
during your update command you have to
give that a negative response you're
choosing not to be available then
because that would violate your
consistency model and that's the right
thing for that business but if you read
it you're kind of a little bit more
yellow about it you just want to serve
ads it doesn't really matter if an
upvote overrode a downvote or whatever
that's not really the business that
you're in so the reason why I bring this
up these are the sorts of trade-offs
that you want to think about when you're
designing the protocols your actors use
to talk to communicate is you want to
say okay what's more important to my
business do I want to make sure that
patient gets exactly one dose for their
medicine or I want to keep serving up
cat photos and never go down not I said
there's no value judgment on either of
these right these are just quantities
you have to battle
what actors helped you do is very
precisely design these protocols and
even test them using stuff like the
akkad on that test kit last but I wanted
to touch on is a little bit about fault
and resource isolation with actors so
academia activists follow a life cycle
during the starting phase and actor will
initialize and run its pre start routine
then an actor will enter its receiving
phase this is when the actor can begin
processing its messages and that's same
the actor too stops it might stop
because it was intentionally turned off
you might terminate an actor or maybe
the actor shot that needed to stop
because it crashed through an exception
well what will happen in this case is
the actor will go ahead and restart in
place and that can happen transparently
to everything else in the system well
this allows you to do and here's where
the sort of the the idea behind the
actor model comes in is you can treat
errors locally in a cadet one of the
core concepts behind how actors fail is
this notion of and it's kind of a
real-life analogy here parental
supervision parents supervise their
children so when a child actor fails the
parent will receive a message indicating
hey your child failed and here's the
reason why what do you want to do with
it in response you might be a tolerant
parent you might go ahead and tell the
actor just to restart or to resume which
is effectively a way of ignoring the
error and keep going or you might be a
parent who is a little harsher and you
might kill your child you might do that
my hearken back to the sort of Roman
Empire days there or you can also be a
parent who believes in collective
punishment you can go ahead and kill all
of your children in one of them
misbehaves so there's all sorts of
different ways you can treat failure in
your system typically you don't see that
sort of collective treatment of actors
unless the children are executing a
cooperative algorithm or something
mostly you deal with actors one-to-one
this is an important idea behind the
failure models that a cadet allows you
to detect is it gives you the ability to
deal with errors locally and just
restart the parts of your system that
failed
so isolate errors down to individual
actors and then either restart or kill
them depending on how severe the error
was this might be the only time in your
career is a Donna developer that typed
exceptions are actually useful
so yeah just let it crash is sort of the
Erlang philosophy now part of akkad net
Anaka the last thing I'll talk about is
detecting network partitions and
failures over the network there's a
really important tool the Akkad on it
has known as Deathwatch what Deathwatch
is is it's an ability to subscribe to
another actor's life cycle and know when
it dies there's all sorts of McCobb
analogies we use in Akkad on it I guess
this one is watched people die the sort
of the idea behind this so this these
two actors here just sort of part of an
application I designed this actor on the
right is being watched by this actor on
the left across the network
now if the server process crashes this
is a type of network failure right this
is one category possible failure that
can occur on the network where software
happens
yeah happens the crash what will happen
is alkyd up remote will detect that it's
association of this node is failed we
can't we're here we don't get any
heartbeats back from it anymore so this
remote death watch your actor here will
go ahead and mark all the actors we were
watching and that server is dead and
we'll get a termination notification and
at that point we can decide we want to
try reconnecting back to that node or
you can try connecting to a different
node redirect our work somewhere else
this is the idea of being able to route
around a failure
so akka dinettes sort of built on this
idea of being able to react to these
sorts of events and just simply redirect
our work somewhere else if we need to
not so you'll see this show up time and
time again sort of larger distributed
systems built on a connect so what I've
tried to sort of give you during this
talk is not so much a prescriptive like
here's how you design actors and ATC
it's more of here's the conceptual
framework for how actors are used to
build distributed systems and how I
think and how some of the other folks
who work on akka Donette think about how
you actually design for these sort of
networked applications
okay let's say that the equivalent of a
hook coming to pull me off stage but the
idea behind this is just sort of give
you an overview of akkad on net what it
does and the concepts that are behind it
one thing I recommend checking out I
don't think I have a slide on this one
thing I recommend checking out is if you
go to get Akkad net we have our
documentation there and the last thing
we're looking at is go to learn Akkad
net that'll actually put you through
Akkad on at bootcamp where you'll learn
how to write a few Akkad ina
applications on your own sort of using a
kinesthetic learning learn by doing and
we've had about 5000 developers go
through that over the past year or so so
definitely give that a try and if you
have any questions about acha acha
dotnet I'll stand here and answer your
questions so thank you very much and we
have microphones so people are asking
questions okay cool go ahead and raise
your hand and the one of the folks will
bring one by hi I have a quick question
actually two questions
it does acta provide a consensus
implementation out-of-the-box
out-of-the-box it does not I've seen
someone implement raft before and they
published a blog post on how to do it so
that's available but no we don't have
any out-of-the-box components for that
right the second part of the question is
if we were to build a custom consensus
our protocol among a cluster of acronyms
can it can be dynamically scale out that
cluster yeah you can scale out that
cluster Aqueduct clusters just appear to
peer network and what will happen is it
uses a gossip protocol to sort of
determine what a new node joins you can
basically subscribe to a notification
for that and so you'll receive an event
and that actor let's say you needed to
have the list of all the addresses of
nodes participating in transaction you
can just go and add that to your set if
you wanted to fantastic thank you very
much you're welcome I know yes yes it's
on cool
so could you compare and contrast
quickly quickly to assure a service
fabric so sure service fabric actors
were
Saku net well I would say one big
conceptual difference is the service
fabric actors kind of a adopt a
different philosophy than Aki dinette
which is that they try to do a lot of
work for you in order to build reliable
systems but you pay for that with
overhead and essentially a lot of
choices that were made for you by
service fabric itself it's a good
example we had someone who was
evaluating service fabric actors versus
akkad on net and akkad on that receive
actor can handle about six point seven
million messages per second service
fabric was about a hundred and forty
messages a second that's one big
difference between the two there and
that's because service fabric actors are
serializing each message and persisting
them it's not because they're inherently
bad they're just trying to do a thorough
job of basically persisting everything
for you and giving you some reliable
state recovery mechanisms whereas akkad
on net by default is dumb and fast
that's it the other thing that service
fabric a naka dinette having common
actually is if you look at the docs for
how the deployment model works like
let's say you want to go and update a
reliable service filled with service
fabric actors that deployment process
looks very similar to how a naka dinette
cluster would work the difference is
that service fabric gives you the
orchestration tools for doing that right
out of the box
whereas with a KU net actually kind of
ironically you'd want to plug into
something like service fabric to help
you do that the service proud but really
also has the concept of a runtime built
into it whereas Aki dotnet does not it's
just a new get package you install and
whatever else you're using whether
that's a console app windows service and
asp.net application etc the answer your
question good any others any good
anecdotes riddles one last thing I
should mention Linux and dotnet core
support the core akka library will be
available on dotnet core pretty soon we
have an alpha of it already and we'll be
publishing that the new get within the
next week or so and we already do fully
support mono so we have people using
academic clusters on mono as of a couple
of years ago actually so we've been
supporting that for a while but we do
want to get on top of dotnet core
quickly and so we're working on doing
that now might take a little while
particularly akkad up persistence we
have to support about ten different
database drivers for that so that's a
bit of
a bit of a mission as I guess you guys
would say so all right one more question
we don't have a document DB driver we do
have table storage and blob barakatuh
persistence but I don't think anyone's
done a document DB one yet
no don't think so that'd be a good
opportunity to contribute though all
right yes
so if I understood your question
correctly one of those some way for
actors to sort of broadcast their like
telemetry sort of being able to say like
okay well actors working on this out of
the box know what you can do though is
you can actually go and override some of
the built-in like message handlers
inside actors and go ahead and base the
in should put some instrumentation in
there and do one of your own base
classes we have some folks have had to
do things like write auditing systems
that are run on top of their actors and
they'll have like a little filter that
basically checks to see if this message
has the AI auditable flag on it and when
it does they all perform the special
audit action you can have a special like
telemetry tracing action do the same
thing if you wanted to but out of the
box yeah we don't provide a lot of
out-of-the-box tooling for doing that
stuff right away just as part of the
keep it simple sort of design right well
good question what type of transport do
we use the transport layer is pluggable
but by default we use a TCP transport so
essentially it's a single TCP connection
and it's running on top of a socket
server called helios today we're gonna
be redesigning that to use an even
lighter weight transport that's designed
to be just a simple sort of I guess
we're calling it the network stream
transport its Helios - a lot of the
infrastructure that it has and it's
designed to be much faster and lighter
weight so the transport layer is
pluggable though the craziest one I've
ever seen was we had some Wall Street
users who needed to support IBM
WebSphere MQ as a transport those think
by the way the licenses for that are
about a hundred thousand dollars a box
so they were they basically had an
existing like auditing system built into
that and they're able to rewrite their
transport to use that under the hood so
I've seen that before
I've seen folks do a do a UDP base
transport before which is a little bit
risky because that message ordering
guarantee can be easily implemented over
UDP we've also seen people try to do
things like a named pipe transport
before I've seen that personally the TCP
one is what I've seen like 99
point nine percent of applications use
keeps things simple JVM dotnet Interop
that's actually been at a interesting
topic because it's come up on the JVM
side a lot to it'd be possible to do
that
the difficult part isn't actually the
network protocol it's actually the
object representation taking an object
serializing it in the CLR deserializing
as a JVM object the way you could solve
that though would be something like
defining your own Google protocol buffer
where you basically define all the
message types that can be interchanged
and that will solve the object
representation problem for you so that's
one approach that we've recommended
you'd also maybe have to customize some
parts of the transport a little bit JVM
akka is moving towards a new remoting
implementation that's built on top of
air on if you've heard of that before
and that thing is blazingly fast they're
trying to hit a million messages per
second per connection they're at about a
hundred and sixty thousand per
connection right now so they're still
working on that but that uses I think
multicast UDP under the hood so multi
ply basically a bunch of UDP connections
that are multiplexed so in order for us
to interrupt with that we'd have to have
something that can deal with negotiate
the Aeron protocol as well and there are
attempts to port that to dotnet today
but I'm not aware of sort of what the
progress of those are yeah all right
well I'm actually gonna be giving the
next talk in this room too so the
stay-put here but thank you all for
attending and for the great questions
thank you very much yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>