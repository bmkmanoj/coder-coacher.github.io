<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Taking Elixir to the Metal with Rust - Sonny Scroggin | Coder Coacher - Coaching Coders</title><meta content="Taking Elixir to the Metal with Rust - Sonny Scroggin - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Taking Elixir to the Metal with Rust - Sonny Scroggin</b></h2><h5 class="post__date">2017-04-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/lSLTwWqTbKQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome everyone thank you so much
for
joining us today this is a talk called
taking elixir to the metal with rust my
name is Sonny Skagen an elixir developer
also
erling as well obviously but I'm really
excited to talk today about this because
it's been something uh there's a project
that I've been working on to kind of
integrate the two together so that you
can take advantage of the wonderful
things that each of these languages
provide and so for those of you are not
familiar with elixir it's a dynamic
functional language it runs on the
Erlang p.m. and it's a fascinating
language because of the fact that it's
got this Erlang VM and it has been
around for thirty years you know and
it's been known for building scalable
fault tolerant applications and so you
kind of have this holy trinity of these
three things of concurrency fault
tolerance and distribution that our
length provides that kind of allows you
to build systems that don't go down and
if processes crash and things like that
you will have something that actually
restarts these things and and allows you
to keep your systems running for long
many many years at a time so but one
thing that I think that people who
aren't familiar with about Erlang is
that it's really an integration platform
and earlier this this week Brian Hunter
was speaking about Interop between
f-sharp and elixir and and how the
Erlang VM really provides a lot of ways
for doing that and so you know you can
use things like ports which are
essentially like pipes where you talk to
other programs via standard and standard
out and you also have something called
Earle interface and Earle interface is a
C API exposed by the Erlang VM that
allows you to kind of talk to external
programs with erlangs
distribution protocol and that opens you
up to be able to do all kinds of
interesting things so see nodes are a
version of that where you have a C
program that uses url' interface and so
from the Erlang VM you can actually talk
to a c program like it would like it's
actually an Earling node so really
interesting stuff there's also stuff
like port drivers which the files like
if you want need to talk to the file
system it goes through a port driver and
so those are all implemented in C so
they're all kind of native functions
they have you know really fast execution
and stuff like that and then we also
have native implemented functions or
NIF's for short and those simply are
native functions that you can call
so some integration examples the mix
tool with elixir will use ports for
instance if you have a dependency in
your application that uses git it will
actually use the git on your system to
go and fetch the dependency another cool
example is the eye net driver in Erlang
it is a port driver which allows you to
do networking so TCP UDP all that kind
of stuff and of course it's written in C
as well and then an example for as an if
is this library called jiffy and it's a
really nice library that that does JSON
decoding and encoding and stuff like
that and that's all implemented in C as
well so this talk is going to focus on
writing NIF's and knits are as I said
before native implemented functions is
the acronym and they are usually
implemented in C or C++ and obviously
with that there's a lot of unsafe things
that can happen and so it is a feature
that is reserved for Wizards people who
know what they're doing and are going to
to not do you know things like null
point
out-of-bounds checks and stuff like that
and crashed crash your VM so when you
write niffs it comes with this gigantic
warning that basically I'm not going to
I'm not going to read it but it's
essentially you are in the like land
where you have to be safe and you have
to be very careful otherwise there are
consequences for your actions if you
write an if that crashes or causes a seg
fault you will crash the entire Erlang
virtual machine and then obviously is a
big problem when you are writing fault
tolerant applications who you can't
guarantee fault tolerance anymore
because you have some C program that
actually takes your whole which takes
your whole program down so NIF's
they can be called just like any other
Erlang or elixir function so you have a
module that has functions inside of it
and anytime you call a function on that
module that is an if then it gets the
native code gets executed and so NIF's
live in a dynamically loaded library so
I shared object or a DLL for Windows I
think is what that is usually I'm not
familiar with Windows stuff so but NIF's
when the module is loaded actually ends
up replacing the bytecode that would
normally be written in an earlier line
module and replaces it with native
native code so the NIF functionality
itself there's an API that allows you to
read and write Erlang terms you can have
there that was like some special
operations for doing binaries there's
also these things called resource
objects that we'll talk about and it
also has some functions for doing
threads and other concurrency features
so to get started if we were to kind of
create something like a JSON module we
could have this onload module attributes
when Erlang loads is load
this module it's going to hit this
attribute here and it's going to say hey
I want you to call the init function
when I'm when I'm loading when you're
loading me and so this an it function is
now going to find the path to our
dynamic library and then call Erlang
load NIF with the dynamic library and
then these are the functions that you
would you'd put them in your module
still so in code and decode but you can
just simply throw an error or something
if it was ever to be called in the NIF
is not loaded for some reason and these
are well actually are the functions that
will be replaced by the native code so
why would you write an if they seem
unsafe right so but really you know
Erlang was not designed for sheer raw
CPU speed it was done designed so that
you could have a nice consistent run
time where everything performed you know
pretty linearly if the more processes
that are in the system you can
understand how how the system's going to
perform at scale a lot easier and so you
know if you need to talk directly to
hardware there's no other way to do it
then to use kind of native code if you
have like you need to interrupt with
some graphics library you'd want to do
that in some native code and you know
maybe the functionality that you need
already exists and maybe it doesn't
already exist in an ER Lang or an elixir
library but it exists in some C library
and you just want to use that
functionality because rewriting it in
Erlang would be you know too costly or
whatnot so so let's take a look at the
structure of an if in C generally you're
going to include the Earle NIF API so
all that from the header file and all
nips have this signature so it takes the
first argument is a pointer to an
illness environment type it's got an
integer which
says this is how many arguments I I take
and then you have an array of of NIF
terms that are going to be of the length
of that is going to be the count of the
integer of the arc C and then the
function itself just needs to return an
earnest term so this NIF environment is
essentially what what when you call an
if this NIF environment is a it's
essentially the like the environment of
the calling process and so it represents
the the calling process itself it's got
some transient information that you
would never really interact with itself
but it's it's an opaque type and it
allows you to essentially create terms
and decode and encode and stuff using
this environment and the erlan if term
is very similar to that where it's
opaque you can use it you pass you have
to pass it in to all the API functions
and you can test to see hey is this term
an atom or is it a is it a binary is it
is it a boolean you can have just
different functions that will test those
things and such like that and there's
one thing that's interesting too when
you read the documentation the
documentation actually talks clearly
about the lifetime of terms and an
environment so terms cannot live longer
than an environment that they're that
they're bound to and we'll see how that
plays out in rust later so the next
thing in an if is you're going to say
hey these are the functions that I
export and you provide this the first
thing here is you know you have a code
and then which is the the Erlang
function name or elixir function name
the arity of the function which how many
arguments does it take and then it's
basically a pointer to a function in
them in the NIF itself that it's going
to call when it does it and then you
just simply load it with earlness
in it
and you can see here you pass in a
module name for where it's going to
actually live for that code and so in
for all licks or modules if you're not
familiar when you create a module in
elixir even though I created a JSON
module called JSON when it actually
compiles into the beam code that module
name is elixir dot JSON so that's why we
have that there alright so but I don't
know about you but I am NOT a C
programmer I don't know how to do any of
C programs I would not trust myself if
my life depended on it to write a safe C
program but rust is here and promises a
lot of great things to help us along the
compiler is absolutely amazing it
essentially will not let you write a
program that will cause dangling
pointers or you know unbound checks and
things like that and so it's really fast
and it keeps you safe so it causes the
compiler will not let you compile a
broken program essentially it doesn't
mean that the the logic is correct but
it will at least compile and guarantee
safety so so some other things that are
that stand out with this here this is
the list on their website you know the
kind of bullet points of what it does
and so it's guys like zero cost
abstractions guarantee memory safety
threads without race conditions which is
a great thing
there's also pattern matching which is
similar I mean you do we use pattern
matching and elixir and Erlang which is
nice so let's get a nice match it has
type inference as well which is good and
it also the the bottom one here is
efficient C bindings so the Erlang NIF
library you know from Erlang is written
in C and so that means that Russ can
actually be a wrapper around that and
actually use use it directly and so this
allows us to use or niffs written in
rust within our
or elixir and so that brings us to this
project here it's called Rustler and it
was started by this guy Hans Josephson
and just a couple months ago I went out
on a journey looking to do this and I
found this project at the time it wasn't
compiling correctly for for max and so I
took upon myself to make a couple pull
requests to fix a few things and became
a collaborator so this project is really
really fun and it's now allowing us to
to build niffs in rust which is nice so
Ressler itself is you know obviously a
library for writing rolling this in rust
but it provides facilities for
generating boilerplate and things like
that that makes it nice to to get up and
running and get started really quickly
so it handles encoding and decoding
terms from from Erlang terms to rust
types and rust types back into Erlang
with just a simple function call which
is really nice
it catches any rust panics that might
happen for unhandled things where you
actually say in the code that I don't
know what to do here so I'm just going
to panic if you do panic in your in your
Russ code it will catch those before it
unwinds back into C causing a seg fault
and blowing up to the M and so the goal
really is is that the the code that you
write in a rust NIF should never crash
the Erlang VM so to get started you just
simply create a new elixir project with
mix so mix new and then your project
name you install or you add the rustler
dependency right now this is going to be
the next version that's that's published
0.12 but for now what you can do is you
can use master you can just pass in
github and the kind of user name and
repository there and then because
this project in has both the rust code
and the elixir code all in one repo you
can use this parse option to specify the
path to the to the actual directory
where the elixir project is so then you
affect your dependencies mix a depth
socket and then Ruster provides this
Rustler new tasks and it'll just kind of
prompt you through like hey what's the
name of the module and what is the name
of your rust library that you want to
create and so in this case we have a
module named JSON and I'm calling the
the library fast JSON and overriding the
the JSON because we'll actually be using
a rust crate called JSON and we can't
have the name closure in there or so so
then you just need to add the compiler
the rust rustler compiler essentially is
a compiler that's written in in elixir
that keeps track of where the files
should go and invokes the the rust
compiler with the right flags and things
like that so which is nice and then we
just set up this option here for called
rustic crates which we call this
function here
and this function just sets up some
configuration for the crates themselves
and that's what you call a rust library
they call it a crate so this just shows
you know the path and also the mode in
which we want to invoke the rust
compiler so if we're running in the like
dev mode in a lick sir we'll probably
just want to compile the rust code with
the debug mode so that it's a faster
compile time but if we're running in
production we want to release it with
the release mode so that it's better
optimized and and all that stuff but it
the compiling step is takes a little bit
longer so if we go back to our code this
is what we had before and with Ressler
it becomes this here so you just say use
rustler give it the name of your
location and then it can go ahead and
find the crate that you intend to use
you could also with with a project have
multiple crates within your project and
so in that case you can also specify a
crate name that you want to use and it
will go ahead and find that so you know
we go from this to to this so much nicer
alright so let's take a look at some
Russ code so the main files live RS and
in here we're just using extern
hey I'm going to use an external library
so we're calling rustler and another one
called lazy static which is for like
creating our atoms and stuff like that
and right here we're using also the JSON
crate which is an external crates from
from the Russ community that does JSON
parsing and and stuff like that so right
here we're just taking advantage of a
library that already exists I don't have
to go and write a JSON parser which is
nice right here we have a couple of
other modules in our project so the
decoder for calling the decoding and
then we just export so we have this
macro called Wrestler export niffs and
you provide the name of the module you
provide the kind of exports themselves
very similar to the the scene if so we
have the function in the module for your
Earling module or elixir module you have
the arity and then you have the rust
function that you're going to call and
then this nun down here
that is if you have additional things
that you need to do when the NIF is
loaded you can do it in another function
and you can provide so this nun if
you're not familiar is kind of a monadic
type where it's it's an option type so
it has it's either something or it's
nothing so this in this case it's
nothing but if it was if we did want to
provide a function we could just call
some and then passing
the function that we want to call and I
will see the example later on that that
so the simple approach or the naive
approach is simply just use existing
rust jsonparser
that we don't have to do any extra work
you know we're going to take in a string
or binary from from Erlang side and
we'll convert that into rust types and
then we'll convert the rust types back
into Erlang terms so this is the decoder
and all NIST NIF terms this is the the
decode function here is the this is the
signature here so it takes the
environment right here it also takes a
vector of NIF terms as arguments and
then it returns what's called an if
result which of NIF terms and you'll see
these tick a things in there those
represents annotations for lifetimes so
it helps the RUS compiler know that you
know you know when something can outlast
the other thing and so all of these
things are kind of bound to the same
lifetime across the board so alright so
the next thing is we just grabbed out
the first argument from the vector so we
can say args 0 dot decode and that will
return us the actual binary itself and
then we can use pattern matching when
we're calling this json.parse function
we pass in the data and then we will
either get so it returns a result so we
either get ok or an error and this is
also very very common and similar to how
you use Erlang and elixir a lot of
functions will return a tuple of okay
and the value or an error and the reason
and so this is actually kind of plays
very well together and so if we get a
good result then we get some JSON types
back and now we can call a function to
turn those JSON types into Erlang terms
and then we will just return right here
will return a tuple of the atom okay and
the actual result of calling that
function and that will end up being
returned as the result of the function
in the case of an error we'll just
return an error to pool so that JSON two
term here is just essentially a
recursive function that if it has an
object or an array it recursive over all
the items in in of those things and
essentially gives us one data structure
back and then we can send it as the
result so and all of these are simply
just calling encode on all of the
different types and turning turning the
rod rust types directly into an ER Lang
term so let's time our NIF so if you get
if you if you run this on like really
small inputs it's going to be fast and
it's going to be performant and nice but
when you get some like big data you know
you have some big JSON file this one
here is like eight megabytes and you run
it and you time it then we get something
like this which is really bad because it
it actually only it took almost 1.5
seconds so 1.5 seconds
of CPU of blocking the CPU blocking the
scheduler in Erlang is a bad thing but
why is that so in order to really
understand why that's bad let's take a
look at the warnings a little closer
that you get here so a native function
doing new lengthly work it doesn't
really specify which how long that is
but before before returning degrades the
responsiveness of the VM and it can
cause miscellaneous strange behaviors
this is actually verbatim out of the out
of the docs so such strange behaviors
include but are not limited to extreme
memory usage and bad load balancing
between schedulers
so so again so let's take a little bit
deeper dive into the Erlang VM and see
how this architecture works and why we
need to be careful when we're writing
this so if you have a machine and that
machine has eight cores then you have
the operating system and kernel threads
on top of that and then if you start the
Erlang VM you have one process one our
link process and that Erlang process VM
or VM process is going to then spawn a
scheduler thread for every single core
on your machine and each of these cores
now are each of these schedulers rather
has what's called a run queue and it
actually in reality has more than one
queue but the main one is the run queue
and the run queue basically holds all of
the Erlang processes that are going to
be executed and so you have a queue here
and it just pops off the head of a queue
runs the bytecode that that process is
supposed to run and if it reaches some
code some opcode that says hey I'm I
need to get some file i/o or I need to
make a network call or I'm waiting for a
message from some other process then the
Erlang VM can preempt and actually stop
executing that process and move it out
into another queue until that message
arrives for that process and so then it
can pop that one to the back of the
queue and then pick the next one off and
keep going and so it can either do that
for like if it's if it's going to do a
blocking operation or it also has this
thing it has a limit of things that it
can do so it can it gives each process
what are called reductions and you get
2,000 reductions and then you're talking
stick is taken away until the next time
you're scheduled so and this essentially
a reduction is roughly equivalent to a
function call it's not exact oops so one
thing that's interesting is that the
schedulers
actually use this thing called thread
progress and there's a really
interesting article or markdown document
in the the Erlang repo that you can read
here and and thread progress is quite an
interesting thing instead of using you
know that while the schedulers
themselves they share some data
structures and so when you have shared
data you have you know definite problems
of race conditions and corrupting memory
and things like that so instead of
protecting them with locks or ref counts
which don't scale very well
instead they actually frequently kind of
give a progress report out to all of the
different schedulers and so what that
does is it allows the schedulers to
understand what work has been done what
data structures are still being used and
when it's okay and when it's safe to
actually like get rid of stuff and so if
you block the scheduler that's really
really bad because now you block thread
progress and it makes all of the other
schedulers wait so if you block even
just one scheduler you can now cause the
other schedulers to have to wait around
to ensure that memory safety is
happening within the VM and also the
another big problem is that if you block
scheduler all the other processes that
are in that same scheduler can't run so
an if should never take longer should
never block the scheduler for for more
than one millisecond is what the
documentation says now one millisecond
in CPU time is like an eternity so even
that feels really really long so so when
you're writing this you should also
count reductions and there's a way to do
that but a lot of people don't actually
do it because it's been introduced quite
recently so so one way we can count
reductions in our in our code just to
like test to see how our NIF is
performing we can write this function
here we just basically send send ourself
a message in the end we we get our start
time
we calculate we prop were responding a
new process to actually run run the
calculation or run run the computation
and we get the reductions the starting
reductions for that process we run the
function with the data we get a time
difference we get the reductions
afterwards after running it and then we
send the parent process a message that
just basically shows us the time and and
and all that data there so and then we
just wait for the message there the
actual result here so when we do this
with our big data we can see it took two
seconds we started at six reductions we
ended at sixteen reductions with a total
diff of ten so we have two thousand
reductions and reductions are way that
kind of helped the VM understand how
much work you're doing how much time
it's going to take you and when we don't
have proper reduction counting it throws
everything off and so this is this is
this should be much much higher with
running running a block in the schedule
for two seconds so we can do better so
one option is chunking so rather than
calling an if once and waiting for the
result you can hit it once it'll turn
you back a partial result you can keep
kind of chunking it and calling it
recursively and then that way when you
are returning on the erlang side the
Erlang scheduler now can preempt the
process in the middle of what it's doing
and then you get kind of much more
better behavior out of it so in order to
do that though we can't use that JSON
crate so we have to actually do some
work we have to build a parser so so
this this way here we're going to have
to do is we're going to have to NIF's
we're going to have to one that
initializes and then and then calls the
second one and then can allow us to
actually call this this iterative NIF
over and over and over again so what we
do here is we have our decode in it and
decode it err and right here in decode
we pass in the data and we pipe this
data into decode in it which then will
call the NIF decode in it and it will
then internally call decode it err and
when we get a result back we're going to
if we get this more tuple here we can
now take the data that's returned from
that and keep chunking it over and over
again in a loop and recursive loop so
this is going to require us to learn
about something else though which is
pretty cool it's called an if resource
object and resource objects are
essentially like a safe pointer and so
it's a safe way to return pointers to
native data structures within rust or or
C or whatever from anis and it can be
stored it can be passed around to any it
can actually be passed from process to
process it can be passed and shared
amongst processes you can actually make
copies of it and things like that and so
you can have multiple processes actually
having the same resource which is
actually quite a interesting thing when
you think of Erlang with immutability
and stuff like that because now you have
this handle to something that you can
actually kind of almost mutate inside
the thing so and really the end result
of a resource is to pass it back into
Erlang so that it can continue to be
used over and over again
and a resource object is not D allocated
until there's no more processes having
reference to to the to the data
structure so this is going a step
further we have now a parser and a sync
to store terms we have our decode in it
and it err and now we're using the sum
and load now so we have a load function
where we actually need to initiate our
resource object so we we have a special
struct called parser resource and we now
have this allocated so that we can use
it within our nips and so decode and
knit simply
we have this parser resource which holds
a mutex of our parser struct and
obviously we need to have a mutex
because the fact that those resources
can be shared with multiple processes
and if you have two processes on
different schedulers running at the same
time then you have the possibility of
you know data corruption things like
that so you have to be safe and careful
so with decode in it we do the same
thing as before we get the source we
create this resource and this I wish
rust had the pipe operator that would be
really cool because then you could write
this much much nicer so reading it
inside out we're creating a new parser
from the source wrapping that in the
mutex putting that into the parser
resource struct and then we're creating
this resource self that comes from
rustler and then we create a new empty
vector and we send it in to decode it
err which is that which is another miss
so what we've done here is we've set up
the arguments for passing in and calling
decode it err by just essentially making
them up here on our own so when this
gets called we now have a resource that
we can grab we can decode that we get
our sink stack which is essentially it's
a place to hold terms outside of the
parser because the parser is going to be
stored in the resource and it can't have
access to terms or the environment that
are going to be that are not going to
outlive the call of the NIF call so so I
have to separate those and make sure
that there there are two distinct places
so we create this sink so that we can
stick our terms in we have to get a lock
on the mutex for the for the parser and
then we use this thing called consume
time slice so consume time slice allows
us to report reductions kind of to the
to the VM every time we call it the
is going to tell us whether or not we're
up like our times up so if it returns
false then it will go in and it will
actually parse it'll do some work so
it'll call parts on the parser and if it
returns ok true then we return the
results of the end of it if it returns
false that means it's not done parsing
there's still more stuff to do so return
continue and then if there's an error
return the error if we end up getting
we're consumed time slice returns true
that means your time is up you're done
you got to give over the talking stick
so we return a three tuple of more and
then the the resource itself and the
current stack state of the of the sink
and these are these terms that we can we
can now act and treat as an accumulator
for the chunking so the result of this
is much different oops so we now have a
diff here where we actually are doing
11300 reductions which is much much
better
we didn't block the scheduler and what
probably didn't block scheduler but this
is definitely much more on track it
still took a long time but we were a
good citizen of the beam which is nice
so there's also a way that you can do
what's called rescheduling or yet they
called yielding and there's a function
in the NIF API called eNOS schedule NIF
but and you can if you were to combine
it with the consume time slice it allows
you to instead of having to return back
to Erlang or or elixir you can simply
just reschedule another niffle
internally so instead of chunking from
the outside where you have to call the
NIF from Erlang over and over again you
can actually do that within the nests
and have the NIF rescheduled likewise so
unfortunately right now it's not
available in rustler and simply because
it's unsafe to do so right now one of
the goals of Rustler is to make sure
that you can't do things that are unsafe
and cause crashes and cause bad things
to happen and so until we can find a way
to support this in rustler we've got to
kind of do some other stuff but I'm sure
eventually we'll be able to get it in
it's just a matter of the documentation
specifying that you have to do these
things in order to do it and if you
can't guarantee at compile time that you
are using it that way then we don't want
to put it in a library yet so that
brings us to another option which is
threaded Mis so simply you can call an
if that NIF spawns an operating system
thread to do the work and once it's done
it will send your process a message and
so what's cool about this is we can go
back to using the JSON crate which
simplifies our code because we don't
have to you know manually create a
parser that we have to maintain that's
slower than the original one anyways and
so this one's called decode threaded and
same as before we get the source we
spawn a we call this thread spawn from
the rustler crate and it takes this this
trait called a thread spawner you pass
in the caller so if you notice up at the
top the NIF environment i've it's still
an if environment but I've named it
caller to specify just so that we have
because we also have an invariable
that's passed into this closure over
here and so to keep the two kind of
distinct I use the caller as the
variable so this passes in the caller
and the caller is an environment for the
calling process and we can just get the
pid' or the process ID of the calling
process so that we can actually send a
message to it from what's returned in in
our value here so
we can just call json.parse on that we
get the value that's returned there and
in internally underneath it's going to
send that value to the process directly
and then here we're just returning
immediately after this thread spawned so
we returned back to the caller just an
okay tuple to say okay I did the the
thing now you can go ahead and wait and
this would be the elixir code that you
would write in order to do that so you'd
have your decode you would have you'd
call decode threaded and then you would
just wait in a receive block for the
result if you get okay results and
you're good you return that if you can
narrow return that and if it if it takes
like longer than five seconds then just
throw a timeout or something all right
so another option is call is is
dirtiness and dirty NIF's are a way to
basically never block the normal
schedulers because you can actually
compile Erlang with this enable dirty
schedulers option it's currently an
experimental feature but they are
working on it with Erlang OTP 20 version
20 and it should be pretty much stable
by then I think they're going to try and
make it stable
so it'll it'll just be there you won't
have to compile it specially which is
nice but essentially it allows you to
call NIF's without worrying about
blocking the normal schedulers because
in addition to the if you have an
eight-core machine as an example I had
if you have an eight-core machine and
then you if you have dirty schedulers
enabled now you have eight more threads
that are completely separate from the
normal way of scheduling processes so
normal processes are just not even
scheduled on dirty schedulers it's only
for niffs that are are things that are
going to could potentially take too long
and block the scheduler so
dirty nips simply you can pass in a flag
here call it dirty cpu so if it's a CPU
bounds kind of works then you use dirty
CPU if it's an i/o bound thing that
you're doing there's dirty i/o as well
so there's a couple people I have to
thank for this talk
one is the creator of Rustler Hans
Josephson and also Jason Orndorff who's
a good friend of mine and he's been
mentoring me and rusts he's actually
currently writing the O'Reilly rust book
co-authoring for that and he's just an
amazing guy both of these guys have been
really really helpful in this process
and I'm really excited about what we've
been doing and so with that I'm done
thank you if there's any questions I
think there's a microphone that can be
passed around
so I'll ask you I'll ask you later about
the safety concerns with the yields
because I'm curious about that by I
suppose that's longer but a shorter
question was do you get into any sort of
interesting troubles where the fact that
in Erlang when you have the reference to
safe references they can be sort of
copied around and stuff
does it interrupt in any funny way with
the with the rust sort of ownership
checking or does it what caused any
troubles there so the the resource
itself is is stored in such a way that
the lifetimes it's not dependent on the
lifetimes and so it can essentially be a
data structure that's in memory that's
actually in the VM that's that's there
and so the Erlang VM will keep keep a
hold of it inside until there's no more
nothing else actually using it and
they'll just get D out D allocated so
that answer your question okay
cool
so I had like two kind of minor
questions on the parser was it just
mutating the sink stack when you're in
it so the sink stack itself it was it's
essentially just a vector of NIF terms
in rust and then when you when you
return it you actually encode it into
Erlang terms and send it back to Erlang
I'll ask you I want to look at the codes
in more DDS you just get a get something
explained and then um I don't think the
other question needs needs asking all
I'll talk about it's super unimportant
cool all right anything else awesome no
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>