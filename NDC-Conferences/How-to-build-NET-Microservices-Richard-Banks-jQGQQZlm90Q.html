<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to build  .NET Microservices - Richard Banks | Coder Coacher - Coaching Coders</title><meta content="How to build  .NET Microservices - Richard Banks - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to build  .NET Microservices - Richard Banks</b></h2><h5 class="post__date">2016-09-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/jQGQQZlm90Q" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">publicly so welcome to Friday morning
the energy in the room is palpable guys
are so pumped like how's my hair coffee
alright so quick introductions I've got
my name on the screen you can read it
for yourself
Twitter handle if you're looking for me
online I Bank 64y the 54 because when I
first signed up for an MSN account
it was the auto-generated number it's
not my age it's not the Euro is born
it's not the number of follicles of hair
left on my head
now that I blog a bit I've been bit
quite lately
principal consultant with ratify scrum
dog trainer Microsoft MVP etc etc I do
stuff basically just means I talk a lot
so I'm going to keep talking so this
particular one we're going to be
covering is building micro services in
net so I was asking the room before for
those who weren't here just how many
people have been to other micro services
talks I assume is probably about half so
far by the responses that I got though
it could just because you were all
asleep raising a hand too much energy in
the morning who's at accuracy who's
looking at doing some sort of micro
service type implementation for reals
versus just kicking the tires crap okay
are you guys all nuts close because you
understand that there's a little bit of
complexity here right it's not just you
know make tiny little bits and throw it
out there and it all just magically
works and there's pixie dust and
unicorns and rainbows and flying poop
emojis and whatever else it's more the
second than any of the first by the way
all right all we do is we'll run through
things the why architecture stuff and
then I'll go through some of the
implementation things and then we'll
talk through some deployment factors in
the dev environment specific things this
is not going to be a talk that gives you
the full details for everything micro
services end to end
show me how to implement everything 100%
with all the complexity that's involved
in an hour yeah you're kidding so it's
it's more an intent to run through the
concepts the things to think about and
show you some implementations to give
you some inspiration for things to do
yourselves
so start off with everyone who put their
hand up to say they're doing
micro-services odds are you probably
don't actually need them wait why so is
this talk where the guy at the front
says no you don't need them go away yeah
that's it there needs to be business
value for you your micro services there
has to be a reason to do it other than
resume driven development other than
Netflix think carefully about doing
these things if you can't build a and I
say this a bit later and if you can't
build a good modularized monolith then
there is no way you're going to build a
good micro-services solution just keep
that in mind
tooling around these things by the way
is still definitely improving
but there's a lot of activity it's
almost like JavaScript frameworks in
terms of micro-services tooling and
approaches so expect that to keep
evolving over the next little while and
what i've seen i've talked to a bunch of
people about their different approaches
in terms of what they're doing for micro
services there's what I suppose you call
purush I don't know if there's a really
a definition of a pure micro service
approach but there are approaches a lot
of people have variations on a theme if
that works for them perfectly fine I
have no problem at all I don't believe
that there's a one way to do anything in
terms of software development
architecture and anything we build is
all about trade-offs so a micro services
approach is trading off something for
something else it's trading off
flexibility of deployment for complexity
of deployment for example it's trading
off small components
for complex network communications so
it's all about trade-offs whereas the
mana list says you don't need to have
the complex communications but you do
need to end up with a large code base so
you kind of you always these things so
if you don't have what Piarist or
bloggers talk about as a pure
implementation don't stress
if it works for your organization your
business and it provides value and
you're getting the benefits you want
from it
then you'll see a smile on my face if no
one else's and through this I'm only
going to be showing you one way of doing
things just one there are many many many
many many different ways to do this
stuff okay it's not the only way you
know there's also other approaches as
well lam during functions who's been to
the lambda talks or the functions talks
so far because it says serverless and
that's exciting right
as I was saying before for those who
weren't in the room personally I find
the whole server list term a bit of a
joke because where do the functions run
on servers whoa just because we don't
maintain them doesn't mean there's no
service service fabric platform as a
service isn't approach who's played with
that by the way or at least had a kick
around of the ties so only a couple okay
so if you're genuinely looking at a
micro services solution have a think
about service fabric because it deals
with a lot of the complexity that you
would otherwise have to look after
yourself in terms of service health
migrating services between things
dealing with the communications
registration all sorts of stuff it's got
a lot of benefits in there
it's an opinionated framework or an
opinionated approach but again if it
works for you it has benefit then that's
a good thing
akka anyone been to the akka talks yeah
you liked what you saw its kind of cool
huh actor/model
all that sort of thing who knew Erlang
was going to be a thing all right so the
microscope is pitched why are you guys
doing this probably because of this
reason
huh shiny shiny sany sany sany sany I
like shiny we're all here we're at an
NDC conference we like shiny I
personally love shiny Boober everyone
sees that all UBA UBA super successful
because they do micro services or
Netflix the granddaddy of how to do this
stuff
granddaddy being like you know six years
old right
Amazon micro services Pizza teams etc
etc and it's all about these you know we
see the unicorns in the industry these
organizations that have billion dollar
plus valuations and they all seem to
have this common thing if they run micro
services so of course it must be the way
not true it's a way it's an approach if
you're doing it just because it's
exciting and because you want to update
your resume again I'm going to say it
again don't do it you'll hurt yourself
more seriously though there's things in
here to think about the business
benefits that we'd get flexibility and
scalability being able to deploy these
smaller components more regularly gives
us more ability to respond quickly to
changing customer demand and sorting out
our business needs that's a good thing
definitely well worth doing because if
you have to go through that painful
process of deploying the model if all
the time it it's a little awkward right
how long does it take by the way for you
guys in general to deploy a new version
of your software anyone take more than
three months yeah two months one month a
couple of weeks
when's your ad you have specified outage
windows by the way where you're only
allowed to deploy on the Friday
afternoon at well Friday afternoon what
am i doing Friday night 3:00 a.m. right
so that you've got all weekend to
recover when the deployment goes wrong
and you've got to write the document
that says you know do this step this
step this step and then someone takes
that runs it manually makes a mistake
and then calls you guy and the
deployment didn't work did you follow
the steps and not really anyone got that
change approval boards you got to go
through the cab meeting ITIL all that
sort of stuff it's great fun isn't it
slows down the agility of the
organization Micro services are meant to
help resolve that that said I've seen
places where the idea of deploying a
micro service goes through exactly the
same deployment process as the monolith
does which kind of defeats the purpose
right
if the organization's not ready it's not
going to work we have more evolvable
systems that's always a good thing
independently deployable you know
technical agility so as technology moves
you want to start doing some dotnet core
stuff because you want to run a
particular service on linux or just
because shiny shiny shiny you can start
switching parts of your app around and
change technology stacks you want to use
a graph database or you want to use a
document database for this particular
need you want to use the right tool for
the right job
perfect no problem at all and again if
you've got multiple teams then being
able to have different teams responsible
for different subsets of the system and
control their own destiny and not feel
like they have to conform to the crap
that everyone else has to conform to
sometimes that can be a benefit Tiger
teams for example how many people have
multiple teams that they're dealing with
okay more than five teams okay
good size there's more things resilient
so you know one thing fails we don't
wipe out the whole thing if the monolith
has a bug in it the whole thing ends up
becoming a mess versus we lose a single
component of the solution so again
there's business benefit they're smaller
services are easier for devs to
understand and it's a potential
migration approach for legacy apps so
doing this with one particular customer
who's got a 20 year old application yeah
it's only 20 years old right who's got
older how do we move these things
forward and bring them across right the
typical approach is going to be the big
rewrite let's just start again
napalm er nuke it from all that
and rebuild the whole thing because
rebuilding a 20 year old system with all
the development that's gone into it's
going to take six months right three
months because that's all the budget
allowed for we don't have that so what
we can do is we can basically bite off
chunks of the elephant convert those
into little micro services while leaving
our big legacy core sitting there and
then we just communicate to it so that's
an approach and then you gradually eat
away at the core until there's nothing
left and you've got a new system and
you've managed to rebuild it without
taking the old system down and while
avoiding a rewrite that said there's
complexity in doing that the reality
though for most people is they go and do
micro services and they end up in this
situation where they're pulling their
hair out and they're looking frustrated
and they're swearing and they're all
right you know wasn't this meant to be
easy
I can't tell help this together anymore
everything falls over as soon as I
change something here this breaks over
there I thought that was only a model
less problem performance sucks yeah all
these things that that occur who's got
to this point by the way yeah
distributed systems are hard really
really hard a monolith is easy to
understand because you're taking out the
big issues of network latency and
availability and all that sort of stuff
it's all there in one spot you're
running in process all the time as soon
as you go out of process there's other
problems to deal with you're dealing
with data across different systems so
you have to start thinking about
eventual consistency that's a mental
shift that's difficult to get right
first time it takes a while to work
through and it's really easy to fall
back into the bad habits so you end up
going back into those bad habits and you
you just create a distributor ball mud
which is instead of piling you know the
teenager's bedroom instead of piling all
the clothes in the corner we're now just
spread their crap all over the floor
it's everywhere and across there are
other rooms in the house who's got
teenagers who is a teenager still
internally well okay and then there's
the big one which is the one that no one
really
talks about too much but it's the people
and culture problem there's various
talks you can find around the place on
how systems architecture reflects the
organization hierarchy if your
organization is built and structured
effectively as a top-down organization
you will find that organizationally you
can't even build micro services because
the approach will still be silos
monoliths whatever else if you don't
empower your teams and you don't let
them have control of specific things and
Trust and get teams communicating with
each other versus having to communicate
up and then back down it will be very
difficult so keep that in mind wrapp
sometimes for this to work the reason
why those unicorn companies are
successful is because their company
cultures already support this they're
built from the ground up with that
culture in mind so it's much easier it's
like a an organization who's working in
a traditional waterfall style
organization or one that used to be and
they're trying to do agile so whenever
you hear the word doing agile you know
you're going to fail just so you know
clear you either are agile or you're not
the Netflix and the ubers are agile
companies they're not traditional
waterfall with project managers who tell
people how to do their daily scrums and
you know all that sort of stuff it's not
commanding control it's and empower
people and get them to do things you
need that environment for this that said
that said - to do - I've already covered
most of this DevOps you will need to do
DevOps for this to work distributed
systems multiple things to look after
got to stay on top of it and make sure
there's an underlying reason and in all
these things don't make it more complex
than it needs to be we have a tendency
as dads especially with it's new and
shiny to take on cargo cult type stuff
to add things to our solutions that we
don't actually need because someone else
said that that was helpful for them just
because I'm mentioning something in this
talk doesn't mean you need to use it
use the gray matter that's inside that
nice gently thick skull of yours to come
up with just the things you need keep it
as simple as possible and don't add
weight to your solution until there's a
business need or a functional need to
drive that so don't over engineer it
don't gold plate it don't build it just
because it looked interesting don't
build what you might need only build
what's in front of you and then go from
there because regardless of what we're
doing the return on investment and total
cost of ownership equation are still
really important and a microservices TCO
is much generally much higher than a
monolith because of that DevOps need so
again keep these things in mind all
right so this is your chance to run away
go find a better talk if this doesn't
suit you if you're still here then
firstly are you nuts
don't answer that question and you have
been warned let's have some fun shall we
all right so what do we want Micra
services you've come across this stuff
independent loosely coupled services
cheap easy to scale replaceable throw
stuff away very much the UNIX
command-line approach small things that
interact well with each other that's
good so architectural II have you seen
this port in adapters hands up okay for
those who haven't the idea here is that
this is sometimes called hexagonal onion
clean architectures there's various
approaches they're all kind of the same
theme the idea is that you have at your
core a single domain logic piece of code
something which works in isolation for
it to interact with the outside world or
to be interacted with it opens up ports
which are then implemented through
adapters
okay so then client applications for
example make a call to an adapter which
might be a Web API call for example
which then gets forwarding forwards
through to make a call through the port
to something that happens internally so
the port just being the public methods
and things that get exposed by that
central piece of logic
makes sense and there's various ways you
can do this and you'll see different
pictures around the place you know so
webcore going into an adapter which goes
out of an adapter into a database the
database is not part of the core
application it's an external piece this
approach works really well because I can
muck around with different
implementations if I'm testing I can
have a mock database or a full database
it means no change in here nice isolated
encapsulated functionality and if you
were to take that concept and then apply
it to a full solution then conceptually
each micro-service being its own little
hexagon thing diagram circle stuff they
can all work with each other and
understand where each other is based on
whatever particular needs they have they
they need to do something they make a
call via one of their ports and adapters
to another service through its adapters
make sense fairly easy and if you put it
on a diagram like this it looks simple
because you know everyone's solution
involves six things right should be easy
yeah everyone's solution involves six
things
there's Netflix's network diagram as at
what year was that again 2004 Oh
fourteen I don't remember
yeah there's kind of a few things going
on there
twitter is not much going on right all
these things have to talk to each other
but they all follow the same basic
pattern you've got something that's
fairly easy to implement so we'll see
how that works in general what you want
to do is try and keep the communication
in particular through your adapters
fairly consistent the consistency
reduces the complexity there's enough
complexity as it is try and keep things
fairly consistent if you're using an
agnostic platform agnostic comes
mechanism such as HTTP then it doesn't
matter someone one team does it in Java
one team does the service
Rubi one team does a service in net one
team does a service in no doesn't really
make any difference at that point you've
got that tech flexibility because the
communications between them is
consistent in general try and keep a
single approach for synchronous
communications where you need to have
two services talk to each other directly
and a single approach for your async
communications again reducing complexity
if you end up with multiple approaches
for async comms then your services have
to understand how to talk all the
different dialects because you don't
know when you'll need one of those
things some also in terms of the
approach client applications don't call
directly to your micro service you want
to have the flexibility to change the
way your services work you want to be
able to decompose larger services into
smaller ones or aggregate smaller ones
into larger ones without impacting your
clients so what we tend to talk about
are things like edge services or API
gateways and so forth which also let you
do load balancing and proxying and other
things like that I'm not going to go
into that as part of this talk too much
I'm leaving that aside because I really
want to talk just about the the backend
piece but again what we're trying to do
here is just that architectural
principle of encapsulating and isolating
change change in terms of how we deploy
our services internally shouldn't affect
the client applications that are out in
the wild make sense all right again
talking of synchronous comms if you are
using that you have automatically a form
of temporal coupling both services need
to be running at the same time it's
synchronous I make a call I wait for a
response if the call I'm making to some
external service is down if that service
is down then my service is going to time
out and have an error so I need to
introduce into my code some mechanism of
doing a circuit breaker pattern or
handling those things and doing retry
logic or falling back into a what
happens if this service is an available
approach so there needs to be some
thinking around that I'm not dealing
again I'm not dealing with that really
in this particular case or in this talk
there
a whole lot more complexity there as
well and the reason I tend to try and
avoid synchronous communication is
because of this system uptime is going
to be the product of all the various
components that need to be up together
so if all your components have four
nines availability which means they were
down at most what's that two minutes are
you is that what four nine oh five
that's five nines whatever the hell it
is it's not much but if I've got say
only thirty services which is not that
many then I'm automatically at the point
where I can fail up to two hours a month
even though my services themselves
individually are up pretty much the
entire time and when you introduce other
things like network issues and drop
messages and stuff like that it can get
a little worse so keep that in mind okay
now client makes a call to your API
gateway to do some sort of business
transaction that when it gets processed
might end up with lots and lots of
different calls going across lots and
lots of different services how do you
trace those things how do you debug it
how do you identify where my data went
and if things fell over where in the
pipeline did they fall over
I don't know well I do know just as well
you need to have some way of tracing it
so a common approach is to in every
client call put a correlation ID some
identify that says this is the
originating message from the UI or the
client that triggered all these
different messages from here and make
sure you pass that through so if you
make a call that goes to one service
that then makes a call to another
service make sure that correlation ID
passes through and again this is where
DevOps and monitoring become important
if I wanted to trace how a single call
spread out through all the services
especially as the number of services
grows and it gets more complex and
larger than my little brain can contain
then I need some sort of tooling that
shows me how that works
correlation IDs help me trace that stuff
and
then again there's tooling that's
evolving and maturing around helping
visualize that as well so that us as
developers can see what's happening in
the system so that traceability aids our
debugging but also aids in our
performance so if we have a call that's
going really slow and we are able to
trace it a message with a correlation ID
through the system we can see where all
the synchronous calls are and more all
the async ones are and where our wait
times are we've got a way of then go
looks like we've got a bottleneck here
this particular service is running hot
we might need to run multiple copies of
it for example service discovery anyone
remember uddi what does stand for again
Universal something discovery in a facie
something or other XML soap i don't care
anymore
that concept isn't you in fact a lot of
what we're doing with these micro
services is not new concepts it's just
implemented better you'll hear people
talk about micro services being service
oriented architecture done right it's
kind of true you need to think about how
your services discover each other if I'm
able to move things around internally
and I'm running things on different URLs
and I take a new service and introduce
it where's that service located
discovery mechanism so for example in a
dotnet space there's console IO you
could run that it's a discovery tool or
service registry you run that as a
docker container and you use microphone
for example as a dotnet client to talk
to that make it easier to program so
when you start your dotnet micro service
you simply ask where are the things I
depend on and or register availability
and so forth worth having a look at
again I'm not going to cover that today
just to mention for you data duplication
who's got DBAs that like to make sure
that nothing's duplicated single source
of truth third normal form databases
don't you get anything or they get
really upset and pull their suspenders
out and look angry
yeah few of you who doesn't have DBAs by
the way Wow who is the DBA who am i
offending not enough of you services
need to be independent therefore
services need the cash the data they
need which means by default you're going
to have some form of duplication that's
okay
data is cheap these days disk is cheap
cheap cheap cheap cheap cheap with micro
services of each services storing its
own data we don't have to deal with the
problems of the one big database to rule
them all anymore
in fact if all your services depend on a
single sequel database because that's
where they store stuff guess what
where's your single point of failure in
your database and if you're doing that
what's been the benefit of going to the
micro services in the first place just
build a monolith build it with plugins
change the plugin deploy it so we don't
want that we don't want that temporal
coupling we want to make sure we cache
data things like that so again there's a
design approach that needs to be taken
into account we'll see some of that API
is versioning api's anyone go to the
packed talk Wednesday was it so there's
a thing called consumer driven contracts
the idea being that pact is a way of
testing those and verifying the
contracts are met which is a nice tool I
want to know that my services will
coordinate well with each other without
having to run them all at the same time
for example contracts are important
api's are important keep on top of those
things this is very similar in concept
to what WSDL and XS DS were meant to do
but again hello soap um so if you're
doing synchronous calls pact is a nice
tool to look at if you're doing async
this becomes less of an issue it's more
then around making sure we have
well-defined messages and
vents so that the consumers and
producers understand each other we'll
all right so let's get into it
implementation patterns so what we're
going to see are a few different darka
textual patterns and so forth so the
first is domain driven design so there
is a DDD talked a little later today I
think isn't it
dd the good bits go to that if you've
not come across domain driven design too
much I tend to to try and take the
approach of aligning most services to
domain context because I want a service
to be an encapsulated piece of
functionality and logic there for a
domain context aggregates service
something like that is one of those
discrete pieces of logic it makes sense
it's much easier to decompose a system
that way so keep those things in mind
and also then if you think about what
happens with domain driven design and
this idea of bounded contexts we have
what's called an anti-corruption layer
to move information between contexts
does that me that's you I just heard my
machine-gunned interview and getting
distracted because you know a TD ports
and adapters messaging between
anti-corruption layer the concepts of
wine well okay so keep that in mind
CQRS separating our commands and our
queries or our peas and potatoes make
sure you never mix peas with anything
peas are disgusting
it also allows us to scale our reads and
our writes independently from each other
so we can optimize services for reason
for performance so that our UIs are
quick as the reason the ubers and the
Netflix's and the Amazons work so well
is because they've scaled their reads
quite differently to their writes a
model if you don't have that flexibility
as much can be done with some clever
hacking but generally you can't database
choice equal or no sickle couldn't give
a flying um I'm more consistent with
using the
right tall for the road more consistent
more interested in using the right tool
for the right job make sure you've got
cases that are easily rebuildable for
your query services and optimize your
storage for the read models that you
want to do if you want great performance
generally that means you will want to
look at a no sequel database or a highly
optimized sequel server depending on
what you're doing but again inspect and
adapt on that figure out what works
versioning make sure you think about
versioning and what happens over time
with your API s and your contracts and
so forth a message bus is important if
you're going to do async communications
you need to have some way of making sure
that's reliable otherwise you would just
lose data on the wire it's probably
going to get people upset with you
so message bus is good for that
optimistic concurrency that should be
fairly self evidence evident if you need
to lock any information ever these days
then rethink your design it shouldn't
happen event sourcing we will look at
this in a minute the idea here is that
our domain services are where we're
doing our writes we're going to store
events not application state and I'll
explain that when we get to it
the big reason for that though is to
avoid two-phase commit distributed
transaction coordinators and all the
pain that involves and there is plenty
of pain there an api gateway as i
mentioned before so all these things are
here by the way the reason there's so
many so much text on some of these
slides is so you guys can come back and
look at this later I could do this talk
with lots of pretty pictures and memes
and you know cats drinking out of
toilets and whatever else but it's not
going to help in terms of coming back
and looking this after the conference I
know that at an NDC it's really easy for
you guys to take stuff in and then go
that was a great talk hopefully lots of
green cards and then forget it all come
Monday morning because there was a
weekend in the way and lots of drinking
and alcohol and whatever else so this
will be available for you all right so
then sourcing itself the idea here is
when a domain objects updated what we
want to do is we want to communicate
those changes to all the interested
other services some of
which might be query services some of
which might be things that do other
processing on them whatever else their
different domain events that will get
raised so a command comes in makes a
change we create an event that says
something changed and any interested
party subscribes to that which is cool
but instead of then updating the state
of the domain object and then saving
that to the database like we would
normally what we do is we save just the
changes or just the event that happened
the advantage of this is that I don't
need to really worry about making sure
my state's consistent anywhere else I
simply take the event I publish it on to
the wire I am done I don't have to to
save to the database a new state and at
the same time publish events to
consumers if I'm having to do two things
in one operation there's a chance that
if something fails I will lose data
who likes losing data by the way whose
boss likes them losing data it's
probably a better question not a lot of
hands it's a surprise I'm pretty sure
there was a bonus for losing data if you
work in some organizations because then
you know plausible deniability things
like that now we could use two-phase
commit for that and you can read the
comment there it's pretty accurate whoo
and I'm who was using this before where
was the DTC hand someone was doing it
you don't own up it's okay we can hug
later so we just want to persist so
we'll see how that works um another
question often comes up how small should
a micro service be anyone heard the
hundred line rule yeah don't do that
it's just dumb don't let this number of
lines of code dictate how bigger
services services need to be about
functionality right so if you end up
going for a nano service approach then
you're effectively turning your entire
application into lots and lots of RPC
calls it's complex enough as soon as you
start distributing things don't go silly
unless you know you want to do lambda
and run your entire application as a
series of functions and the f-sharp
people in the room or those who like
functional stuff will be going yes me on
the other hand I think of your services
more as deployment units right domain
context deploy them together if you've
got located functionality and your
service ends up being you know a
thousand lines two thousand lines I
don't mind if it ends up being two
hundred thousand lines is probably a
little big just saying so it's all about
this units to functionality a lot lines
of code so generally think about it
service has a single purpose whatever
it's going to be it could be as we say
managing the state of an aggregate or a
domain object of some variety sending an
email converting a PDF calculating
Commission's updating shopping cart you
know whatever else it happens to be all
those sort of things
units of functionality inside each
service you don't care about whatever
else might exist because what might
exist will change over time all you care
about is I am responsible for myself I
do my thing so the single responsibility
principle applied to a service which is
cool so from a design perspective again
you've got to think about you know your
use cases bounded context this is where
that domain driven design comes into it
okay everyone needs boxes and lines
right who's a full-time architect in the
room okay so this is going to be the bit
you understand when the code gets on the
screen I'm sorry all right there you go
feeling at home I was going to take a
whiteboard picture just to make it
better but you don't want to see my
handwriting so the idea here this is the
big picture is that a UI request comes
in from a claim generally over HTTP it's
then going to come in to an edge service
or an application api gateway or
something like that which is then going
to figure out what the request is is it
a command that's going to update state
or is it a query
to read state if it's a command we're
going to send it across to a domain
micro service something responsible for
managing the state of domain objects if
it's a query it'll go across across to a
query micro service for reading data and
we separate those two things distinctly
because again we need to scale our reads
and writes independently the domain
micro service will store its data in a
database in this case we're going to be
using events store you can use something
else if you want we're also going to
publish events onto a bus those events
will get picked up by the read services
the query micro services which will
update their pre computer results so
they can respond to queries with
effectively or as best we can order one
type operations single i/o make a query
here's the answer ready to go if I can
respond to all my queries in one I oh
I'm going to have a freaking quick
system that's a good thing if I have to
go and you know do a joint across 14
different tables and everything else
that's not really what we want because
there's going to be a slow query it's
hard to maintain and in this case we're
going to be using Redis whose use Redis
by the way yeah it's pretty cool it's
not I wouldn't use it as a it's not a
permanent database it's a cache if I
ended up having a query Microsoft's that
had more data in it than my Redis cache
could handle I'd probably start looking
at different storage mechanisms because
it's yeah it's a cache has a limit Redis
runs in memory once I hit that memory
limit I'm going to need to store data
somewhere else so if I was storing
terabytes of information querying off
that different approach for the example
here perfectly fine alright in a domain
micro service as the request comes in
we're going to pick that up it's going
to be a command request we're going to
use Web API it's going to forward that
call to a command handler which is then
going to do a couple of things it's
going to update an aggregate so a domain
object and then it's going to also that
will create events saying that things
have changed we're going to then persist
those events into
the event store repository and then
publish those onto a message bus at the
same time the service can listen to
events from other services because it
needs to cache data of its own for
example I'm doing a change that needs to
do some validation so you send me a
command that says updates or add product
X to the shopping cart for example and
I'm responsible for the shopping cart
I'm not responsible for the products
though so how do I verify that the
product exists that you know just giving
me a dummy product I need to have some
way of listening for those so I know
what my current products are so I would
cache that data so I'd be listening to
events from a product service for
example go from there does that make
sense
yes okay a remodel is fairly simple the
idea is that we will respond to queries
from the UI for information we have a
query handle that simply reads data from
the cache on the other side of the fence
as events get put onto the bus we
subscribe to those events if we're
interested in it for the state of our
object here and we'll have event
handlers that simply update the cache
pretty complex if I ended up needing to
scale this further I could split things
depending on what was going on I might
have even more reads I might need more
CPU I could split this service along
these lines here or this line here so
that I have one place where I'm handling
events separate to another place where
I'm handling queries so there are other
ways to split this just keep that in
mind specific software we've got those
things they're easy net Q is a new get
package for interacting with rabid mq
makes it quite easy and stack exchange
Redis is from the stack overflow guys
nice easy library for interacting with
the Redis from net so you don't have to
deal with a whole lot of that low-level
REST API calls now this code here is on
github that code on github is not fully
complete intentionally sort of
intentionally because I kind of got lazy
and didn't bother finishing it but it's
there for inspiration not duplication I
don't want you taking the code and just
copying it without thinking which is
another reason why it's not really 100
percent there but you can definitely
have a look at it poke around with it
see how things work and again that code
doesn't deal with all the complexities
you need to think about but it's a start
so the Micro Cafe is what we're doing
Starbucks doesn't use two-phase commit
is a blog post that was done a while ago
and had this diagram in it talking about
how things work so we have the coffee
shop here where customer places in order
a cashier takes an order that order gets
queued barista makes the drink drops the
drink in the output area that gets
picked up and there's a correlation idea
to track the order you know so what's
your name your name's Richard okay we'll
write that on the cup or you want these
three coffees together so we'll put like
a number like three dashes on the top of
the lid so that we know they're grouped
together all these sort of behaviors
that happen customer finds money once
they told the cost they pay for it
they're not allowed to pick it up until
they've actually got the payment
completed whatever else if the order
doesn't get paid for the coffee gets
thrown away there's compensating
transactions there's all sorts of
interesting things that happen if we
were building this as micro services
first question we need to think about is
where are my services where are my
domain contexts is this customer
operation here a domain context yes show
hands yes no all right so since not many
people put their hand up you're either
dead or you don't know what this is what
is that think about it it's not a
service to client application the
customer is the client right they're
interacting with the domain coffee shop
within that though we've got these other
things we've got this barista and we've
got this cashier are those potentially
services does the cashier have a
different view of what an order
- what a baristas view of an order is
probably different information does the
barista care about pricing not really so
in terms of transitioning information
cashier would take an order with pricing
would handle the payment all the
bristlenose and cares about is what are
the products on the order so we have
these this idea of a domain context and
we would be transferring information
between so it starts making more sense
question is though what happens to
master data this is one of those things
in micro services people don't tend to
talk about very much what happens to
things like reference data lookups and a
product list where does that live
where's it living the diagram here it
doesn't live anywhere who owns the
product the cashier cashier decides what
a product is there's a context not shown
here which is the store owner storing is
going to define what the products are
right and make them available to the
cashier and the barista I would hope so
we might have to think about our
boundaries a little bit more so use a
story if we think about a user story as
the coffee shop owner I want to define
the products that are offered for sale
so I can make a billion dollars and you
know pinky to the mouth within that
though there's kind of a few other
potentially related use cases that we
could think about so we've got managing
products which are kind of cruddy
operations what about a read model thing
like view the menu show the menu update
the price list whatever else it is or
something like running a promotion where
do these things fit this is the design
thinking that needs to happen when
you're putting together your services
and not just take a bit of code and
write it and it's a small one and job
done so what we're going to do is we're
going to look at the product domain
object in an admin service so again
coming back recapping our little picture
commands queries they're the dapped is
important our reads and our writes the
domain entity itself the product
how we manage a product that's here in
this application call a cashier service
is going to listen to changes to the
product so they can update what they're
allowed to verify against a barista is
going to listen for changes in the
products so they know what they're
allowed to make makes sense we're not
going to listen in the admin service for
changes from the barista because there's
nothing that they do that interests us
not in this service we've got other
things we might be interested in like
inventory stock on hand how many coffee
beans do we have we've got enough milk
etc and we're also not that interested
in the cashier take an order that
doesn't really affect the products okay
so not really listening the other way
around at this point so there's the
admin micro service we also have just in
terms of what's going on here these are
our ports and adapters now so a port
here being a repository float sorry for
those at the back it's a little bit
small product in the middle the
repository is our port and the adapter
is going to be an event store and
potentially a bus publisher onto the bus
because we're going to store events
we're not storing state so I can take
that event push it into locations
without a problem I also have a command
handle here so Web API is coming in
that's our adapter it's going into a
port being the command handler which
updates the products makes the domain
context change etc all good does this
make sense see how it implements okay so
I've talked about this before I'll jump
through that very quickly just one thing
one benefit of event sourcing is that
you can use it to quickly replay the
state of an object if I've got some bugs
that were causing issues so anyone ever
had the situation where you've run into
you're doing a transactional type system
you have a calculation problem and then
you realize that after three months and
you've then got to go and write some
code to go and correct all your bugs and
try and correct the state of the
application anyone done this so you go
to the audit logs and you're trying to
reverse engineer change
just based on what you ordered realizing
things aren't there no one's worked in
logistics stocktake systems okay all
right so here's a product product is an
aggregate so we're inheriting from
aggregate class which has just got some
base information like a grid for an ID
not much gone beyond that and we have a
constructor here which has you know ID
name description decimal price that
constructor is going to be a creator
fair enough that would be our UI makes a
call creating your product it's going to
end up calling through to this so we
have something to create things but
you'll know we're not actually setting
any properties here we validate that the
name is supplied because it's a
mandatory if it's not there we'll throw
an exception let the exception bubble up
to the client no big deal and then we
simply create an event called product
created and apply it this is the pattern
command handlers don't change state
command handlers raise events and we
apply those events and through the
applying of event we change state the
reason we do that is for replay and also
so as we listen to event off a message
bus we can simply apply those events as
needed and it's the same pattern over
and over and over again nice and easy to
implement so we apply the product
created event and that's what changes
state all good all right so then we have
agree a base class it holds stuff
replaying events there's a few funky
things in here such as casting is
dynamic so we don't have to worry about
knowing all the types beforehand which
is cool there's code in there that you
can grab just to see that and we also
increment the version of our object
every time we update an event which is
where we're going to be doing our
optimistic concurrency checks makes
sense all right
so similarly on a command
we have changed name another command it
raises an event validates thing
if the validation fails we throw an
exception we do an apply we push that
back same pattern again you can run
through this code in a little bit more
detail later on alright we've talked
through all of this I'll leave that
there for you guys later
the command handle the repositories are
outgoing port in this case so we have a
command handler we're going to handle
sorry an event handler create product
command brain engaged so the UI sends us
a create product command before we
update the demand we're going to go and
say ok here's the correct product here's
the message we're going to take that
call that save it fairly straightforward
it's almost a pass through it doesn't
have to be you don't have to have a
one-to-one implementation it's quite
okay to have a UI command come in that
ends up causing multiple commands to be
fired internally perfectly fine ok all
right so that adapters themselves HTTP
rest our Web API no big deal they don't
need to be restful it's not a problem if
you want to implement this as a REST API
great but HTTP API is enough you could
if you want to do soap you could do
WebSockets you could do whatever you
want
it's an adapter ok so there's a little
bit more code here but effectively this
is our controller action with a post
we're taking in a create product command
from the UI we're doing some validation
on it to make sure it's ok and if it's
not we're throwing a valid response type
we're going to give them a forbidden in
this case if you've got another wide
space is not allowed to go away we could
throw something else whatever you like
it's no big deal
and then we're passing through to our
internal part where we calling handle so
we create the command for the internal
use and then pass that on make sense
now you can see here I've done something
naughty I've hard coded a URL because
it's sample code this is where you would
potentially call a discovery mechanism
to say where are these things going to
live what URL do I give back to the the
consumer to know where this product that
we created now lives pretty common in a
HTTP thing if I'm going to return a
created to our Creator I want to give
them the location of the object I just
created and then if we've got any errors
I can return not found conflicts
whatever else so commands don't return
values commands are void operations they
either succeed or they throw exceptions
queries return values commands don't
okay all right
outgoing interactions repository message
bus let's have a quick look at some code
now you'll see here by the way that
we're doing two operations in one which
I told you before is a bad thing again
sample code inspiration not G plication
I could in this code fail to publish an
event if the power gets knocked off at
exactly the right time or there's a bug
so we can prevent that by basically not
doing the persistence to the event store
we could publish the message to the bus
and have something else
read off the bus and then update the
storage mechanism does that make sense
so we're completely async at that point
or we could use our event source event
store as our message bus it's an option
to do that as well so we just query that
all the time effectively though this is
our save here's our repository we've got
some code in here just getting some
naming but the event store mechanisms
there we append to the stream we store
it and then we publish the event on the
bus using easy net queue away we go
again it's not a huge amount of code
once you've set this up that then
becomes a pattern that you can apply to
all the other services query on the
other hand
very simple we take things you'll see
this looks pretty much the same we
subscribe to events and we do some
subscriptions to that using topic
filters so we only get the events we're
interested in from a rabbitmq
perspective first thing when we start
the app we do some Handler discovery
just do reflection to figure out all the
things we're subscribing to and then
you'll see here we're listening for the
events and then we're doing an apply so
we're doing this dynamic thing again
this is boilerplate code that we just
dumped in the start of every micro
service so that we don't have to worry
about new types causing problems and
then we filter the messages and they end
up coming into something like this this
is a view this is a remodel aggregate so
these handles these different messages
or events and then again we're doing
apply same pattern but what we're doing
now is we're creating DTO is ready to be
queried so I'm not creating domain
entities I'm creating denormalized data
D TOS ready to be picked up by the UI
when they want to make a query all right
Redis itself there's some code in here
for you guys to have a look at it's
again fairly straightforward we're doing
some Redis queries reddit has this idea
of sets so if I'm doing a collection I
store a read a set and it will
dereference to the individual keys
avoids n plus 1 queries but really this
is the key here where credit transaction
to update Redis we set some values we
commit the transaction again really easy
API stack exchange dot regice library
provides this functionality we're good
to go
last thing we got a couple of minutes to
go so let me just run through this
quickly deployment docker we have to say
docker
we have to if we don't say darker then I
should be walking out stage right now
how do we do local development with
micro services good question
it's a tough thing to figure out you can
use docker docker for Windows is now
running if you've got the anniversary
update you could have a look at Windows
containers they don't run together at
the moment by the way I tried last night
doesn't happen but really the question
is as a developer what am i testing
against what's the version of the app in
micro-services the version the app is
really fluid there is no version anymore
it's simply a whole bunch of services
kind of working in concert as a mashup
in in some respects so you'll see some
people talk about you know just keep a
version of each microservices and have a
collection of all the known good
configurations and when I'm doing local
development I take a known good
configuration and I update my service
and make sure it works in that
environment or you ignore it all
completely and you simply build based on
using a lot of attention on your
contracts make sure your contracts are
ok if your service behaves well and
meets its contract then it's a
responsibility of all the other services
to behave and then you use production
monitoring to figure out if things are
going wrong which is the Netflix
approach just deploy the damn thing so
how do you upgrade a micro service good
question you don't don't they're
replaceable bits of functionality don't
upgrade them replace them if you start
thinking that way you start lining
yourself up with container thinking
containers don't get upgraded containers
get replaced in docker it's exactly the
same approach so you isolate your
service and its execution environment
and you simply drop a new version of new
version a new instance into production
you don't upgrade the only time to think
about upgrading is in data storage but
again if you're storing events there's
nothing to upgrade you don't have to go
and change the schemas you simply apply
those updates again all those events
again so you're getting benefits for
this I won't go through doc you've
probably seen enough of that already
you've been a docker talks yeah ok again
we don't upgrade we promote containers
to various environments so you don't
deploy to production you
you know a new version of software you
deploy the container to prod from a dead
perspective you're going to be looking
at doing something like docker compose
if you were using it locally you don't
have to by the way and then you run a
set of containers that your service will
interact with and you can check how that
works together and you can have mock
services that do things without then
passing stuff on to elsewhere so you can
create this subset it does require a bit
of knowledge around how everything works
though so again think about the
trade-off here do I want that complexity
or do I focus on my contracts and then
just go there's a risk trade-off there's
all sorts of things to consider around
this space if you're going to go this
way and you don't have great testing
DevOps and all that sort of practices in
place then you're looking for danger
it's going to hurt again right so it's
not just how do I build the services how
do I put everything together all right
so if you don't want docker you don't
have to here's what you do always grab
the latest code of everything you might
want to test rebuild it all locally
manually build manually run all those
things using you know start this one
start this one start this one start this
one have 480 different console apps
running all with the different services
in them
make sure you got a lot of RAM by the
way you probably need that but hey
everyone likes more RAM in their box and
you know if you want run a little bit of
scripting so that you can run a script
that says start dev environment ps1 and
then wait 12 minutes while all the
services start it'll be great you can go
get a coffee
update you sell your social media status
check Facebook find a Pokemon um that
said the pain involved in that has a
really good side effect which is it
keeps your number of services low you
start creating larger services because
the cost and the pain of adding a new
service it tends to prevent that ever
happening so you end up finding services
that stop being micro and start being
MIDI services and then start becoming
monolith services
but that's pretty much it all right so
it's been an hour run through there's
enough reference material for you guys
here to have a look at the slides are
already on SlideShare again look me up
our banks 54 we've gone through the why
some of the architecture decisions some
of the thinking that you're going to
have to put into play around this
showing you a little bit of
implementation as you can see the codes
actually not that complex which is great
and we've talked briefly about
deployment so thank you very much
I'd open for questions but we are done
if you want to ask questions just come
up and grab me and we'll go from there
enjoy the rest of the day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>