<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Going Serverless with GraphQL - Steve Faulkner | Coder Coacher - Coaching Coders</title><meta content="Going Serverless with GraphQL - Steve Faulkner - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Going Serverless with GraphQL - Steve Faulkner</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/94dS3kWDswk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you everybody for coming welcome
to go into service going sir let's craft
kal hopefully you're in the right place
I really appreciate everybody coming to
my talk I know there's like ten of the
toxic appear right now additionally
there's like five other service talks
just today so maybe you're hitting all
of them you're just learning everything
my name is Steve Faulkner I'm at South
Pole Steve on Twitter on github on the
internet anywhere online if you see that
that's me I went to the South Pole once
I used to work there not anymore though
that's a different talk for a different
day you can ask me about it over beer
later I came all the way from
Philadelphia so never been to Norman
before first time super excited to be
here and I work for buffle which if
you're not familiar with bustled is a
women's media company where in the u.s.
we have over 60 million unique readers a
month one of the larger media companies
in the US and we were founded in August
of 2013 so to start out I'm going to go
back in time just a little bit to 2016 I
haven't given talks on servers for a
while now started around March of last
year
surveillance really blew up and we were
doing a bunch of several of stuff people
wanted to hear about it the reason you
know surveillance was such a big deal
there's a medium post that says so
buzzword for 2016
serverless I've got to go to a bunch of
conferences it was fun and I was giving
this talk called the The Hitchhiker's
Guide to service fast forward to 2017
and I started getting some more you know
feedback originally people were really
interested in just what it was in
general nobody knew right every still
trying to figure it out I got some great
feedback at my last conference said I
didn't attend this talk I think your
survey is broken I got some feedback
says could he have used more buzzwords
so that was the answer I can in fact use
more buzzwords so that was the what
inspired reading name to talk to us but
really this talk is a just about trying
to bring some reality to service and now
also graph QL about how we use it a
bustle why we do things what we do a
little bit less previously than I've
done of you know what are these things
and the readme if you want to know about
them and happy to point you in the right
direction but much more all the stuff
that you need to take away when you're
adopting these technologies because
they're still really new there's still
some big pitfalls
especially when you're doing the at a
scale like bustles and hopefully you're
going to be able to you know take those
home and actually learn something so
back to Brussels like I said women's
media we get about 60 million unique
readers a month so pretty high scale
pretty high traffic and we are 100%
serverless
mostly so there are still some servers
there I'll get into where those are
later but if you go to Buffalo comm you
are going through an entirely
surveillance platform every single one
of those requests is going to hit AWS
lambda at some point so we do really do
do it we do it in production people
still don't believe me like I go give
these talks and people come up to effers
and like let's not really in production
right like no like open your phone go to
the website it works I wouldn't be very
good at my job if it didn't so before I
kind of get into how we do it and how
this works I really want to talk about
serverless I still have to give a little
bit of an overview about it because some
people might not know what it is there's
a lot of confusion about what does this
term mean and the very first thing
people say is well there are still
servers and you know like guess you win
pedantic person on Twitter of the Year
award right I get it there are still
servers I'm not disputing that I think
it's a terrible buzz word I agree with
most people that server list is a really
bad word I didn't come up with it
unfortunately though it's kind of what
the communities standardized around to
describe a new set of practices right
and I've tried to slow that down as
simply as possible into the slide so the
practices are instead of talking about
servers as a primitive we're really
talking about platforms right so this I
don't think is like a really new or
novel idea that we've been doing it for
a while it's just now the platform's
finally got good enough that we can use
them for all the parts of our
application rather than having some
parts be servers and some parts be
platform the parts that we've kind of
been doing for a while
anything you describe as a service
you're describing the platform databases
logging caching storage like s3 even
servers so ec2 is like serverless
servers these things all been around for
a while they're not they're not new and
a lot of people's applications probably
make use of them but the difference is
is that there's always in this kernel of
stuff that's your application right the
business logic what makes your
application unique and does all the
stuff that makes you money or makes your
business money or whatever and people
gotta figure out where does that live
and it's always it's been on servers
that's the primitive we use in order to
talk about those things and build those
things that changed so functions as a
service came along and now we have the
ability to finally replace that last
little bit so business logic has
somewhere to live that is not a server
and that's functions as a service
there's a bunch of platforms that will
give you functions of the service as
there were houses or functions Google
cloud platform has Google Cloud
functions is in beta still I believe IBM
has this pretty neat thing called open
wisk which is actually an open source
functions as a service so if you want to
see how it works under the hood you can
go play around with that this is really
more about Amazon so I you know not to
try to offend anybody in the room but
like I think Amazon is it's pretty far
out ahead especially in this arena of
everybody else everybody's starting to
catch up it's getting there but really
Amazon has the most you know robust and
feature full functions of the service
platform and that's because the meaning
of service is actually changing even
more and this is just in the last few
months people Steiner realize it's not
about platforms it's about events so if
I look at this really terrible little
diagram of the cloud this is an Amazon
specific cloud but if we drawn for any
of the providers there's other different
things that I can do right so there's a
elastic cache for my cache and stuff for
dynamo or SNS for you know sending
notifications and the truth is mostly
things don't really talk to each other
very well one thing I think Amazon is
pretty terrible at is making all these
things work together right if I want to
take some record in dynamo and send it
through Kinesis and cache in elastic
cache right I have to deploy a server
that handles all of that for me well not
anymore
all these little green things can be
lambdas right so that's where functions
as a service come in comes into play
it's really the kind of like last
missing piece that allows us to glue
together all of these different cloud
platforms and different ways of building
new architectures so serverless
sort of really functions as a service
which is really just cloud glue so
a quick overview of like what serverless
is if you want to go into any more depth
and any of the individual providers or
house of Orcs offers I'm happy to talk
more about that but I'm now going to
kind of jump into you know what we do at
bustled we went down this path starting
in about August of 2015
lamda had already been out for roughly a
year and API gateway just got released
so before API gateway there was no way
to publicly expose lambdas to the world
there at least the way that you would
want to to users you had to sign
requests and bill kinds of you know
Nesta AWS stuff so once this got
released suddenly we were like well
maybe we can actually build like an API
on this it seems like it could be
possible so we tried step one is we
built one API endpoint we have this
single API that is essentially are like
metrics ingestion service and it's one
API endpoint it's one very simple API
that just type stuff into Kinesis it's
not very complicated but very very high
traffic so for us it was this was the
the proving ground for was blend are
going to work is the scalability really
going to happen is it really going to
you know be able to scale to what Amazon
says it's going to and the truth is it
mostly did right we were super happy
with the results this side is going to
be used again as a marker for good times
it just kind of works I I wish I had
like a better story about like how we
made the transition but it was a nerd
service that I I'm not joking we copied
and pasted code into like the lambda
console and then ran it and it just like
things just worked right it was kind of
impressive how easy it was in very
simple case costing us a roughly $2,500
and months to run the ECT coaster that
was handling all those before moves over
land in api gateway started costing $400
a month now this isn't to say that
server lists and lambda and api gateway
are completely always going to be
cheaper there's definitely cases are
there going to be much more expensive
but that might be worth it to you it's
definitely worth it to us in all of our
cases to move stuff over to these
services because we end up spending a
lot less money and other things like ops
the reason this works is these services
are paid per request they are actually
charged for the processes and they scale
magically
I put asterisks here because you should
not trust anybody that ever tells you
something scales magically because it's
not true and I'll get into a little bit
in a second but for the most part the
the isn't individual you know lambda and
isolation does scale very very well and
that we've been very impressed this
ability to do that additionally I talked
about you know why is it cheaper even if
the individual surface cost more you
know we we about to spend a lot less on
ops than we used to so we don't have a
full-time dedicated ops person we have a
couple contractors who just part-time
work for us there's a hashtag the
fourths around that people will use
called no ops I'm not a fan I use that
hashtag ops is just the facts of life
you always will have ops in every
environment it's how you deploy your
application right that's just how and
even if you don't have servers there
still has to be some way of doing that
and it's how you maintain your
application as well so ops is always
going to be there but maybe just a
little bit less ops in a service world
all right so this talk or this side is
the indicator should be thinking
critically about the next part because
these are the parts that maybe are good
maybe are bad kind of depends on your
use case so for service this has been
addressed by a lot of people before
about Cold functions so these are little
lambdas are actually sitting in
containers on servers somewhere and the
first time you hit one it has to you
know boot itself up and get going
additionally anything you do outside of
the main process handler has to happen
that time as well if you're running
servers and you're not rebooting your
servers every you know two minutes then
things like loading a bunch of big data
synchronously before you actually start
serving requests maybe not a big deal
lambda big deal so this is something you
really don't want to do
additionally lambdas take have maximum
execution time of five minutes so if
you're doing something very long-running
not really going to work on lambda or
you have to think about how to split it
up differently
testing still a big challenge testing
the individual lambda functions is not
super difficult it's like a UNICEF scene
other and the other function the problem
with these tests is that you know I
talked about the evented nature of these
systems in these architectures how do
you test all of that in in unison right
like how do you test something is going
from Kinesis to elasticsearch back to
back to API Gateway correctly and the
truth is it's really hard or impossible
right there's a lot of stuff that's
still being worked on to figure this out
but it's one of the biggest struggles
like I currently have with how all this
stuff works tooling is something that's
getting a lot better when we first
started there was really not a lot out
there but there's a bunch of stuff
that's coming into the arena that allows
you to deploy and maintain these
applications build them easily abstract
stuff away from you some examples
there's a thing called serverless
framework I am NOT a fan of the name
because it confuses the highlight of
everybody because I come to these things
that people think I'm talking about the
framework of not it used to be called
jaws there's no lambda if you're the
node world apex is written in go and
supports all the different runtimes
which include c-sharp notices like a big
data net c-sharp conference apex or
Sparta is actually written and go and
only supports go but it has some cool
little features because it just focuses
on go as well or we could also use the
one that I wrote so a buffer we have our
own in-house framework it's no js' only
but it is what we use to deploy all of
our functions to api gateway in lambda
so it's called ship check that so that
kind of brings us to phase 2 of our
server list adoption and that is the the
lambda front-end so we moved over an API
and we started writing some other api's
on lambda api gateway and that mostly
worked in and was all great and we were
pretty happy kind of with the caveats I
just said so the next step was well can
we actually serve HTML from this thing
all right can we actually make an end
user facing application the API requests
our end user facing but you know HTML
then we did that so romper comm is one
of our smaller properties we move that
over against maybe like 5 to 10 million
uniques a month we move that over
completely the lambda it's a server-side
rendered pre acts this is kind of what
the architecture looks like so HTML and
JSON served up by API gateway then
lambda does all the server-side
rendering talking behind the scenes to
DynamoDB and Redis remember I said that
we saw some server some places that's
with little asterisks as for so that's
what our servers live we're huge Redis
fans we're actually moving away
generally from dynamo and putting all of
our stuff in Redis
using Redis as a primary data store so
that's that's a whole other topic and
might scare some people but it's working
very well for us so far and we're very
happy love Redis once we did that that
really showed us that okay this this
works this can be used both for api's
and for these front-end applications and
it's performant and everything works we
went all in so over the next year
roughly we moved all of our
infrastructure over to API gateway and
Lamba took us about a year but November
2016 we were a hundred percent on lambda
except like I said for a few small
things like a Redis but mostly for all
of our end-users stuff all of our API is
all over HTML applications are all being
served by API gateway and lambda alright
so this slide is supposed to indicate
that you're going to shriek in horror at
some of the things that'll happen this
is where I tell you about the bad stuff
what happened what really went wrong
first thing is the server's went down so
we we switched all this stuff over and
we had you know some of our stuff that
was not quite serverless yet still went
down and we had to figure out what was
going on quick pop quiz does anybody
know the default max number of
connections for a Redis instance and you
just boot it up by the box
anybody knows I just shouted that yeah
nobody all right ten thousand ever watt
it's a lot of connections and we never
even got close to this before with our
old easy to set up the connections would
get pruned in time if we're rebuilding
boxes never really was even remotely a
problem well it turns out of lambda and
its ability to you know infinitely scale
it's a problem we started seeing all
these connections get dropped all of
these really bad problems because the
lambda instances were starting they may
have gotten frozen or in a container
that wasn't actively serving requests
but they were still holding open the
Redis connections so all of our Retta
stuff freaked out and you know we had
some Retta fish ooze that we fixed
worked around this we were able to you
know craft our Retta set up such that it
prunes connection more aggressively and
just some tcp keep a lot of stuff but it
was a big problem that you know we would
never run into before a big big gotcha
the lambda currently has account level
concurrency limits on functions
so they've
raising this and less of an issue but
out of the gate when lambda came out it
was a hundred concurrent really running
functions at a time huge problem because
count level so if you have your test
environment and your beta environment
and your production environment all in
the same place
and one day you're sitting there and
you're like wow I want to make sure this
is going to work for this new query I'm
going to run so I'm going to run a load
test against the beta environment
well that will bring down your
production instance and that totally
happened to us so all of our production
functions stopped running because I was
running ridiculous amounts of queries
against our beta environment big gotcha
I this is like one of my biggest pet
peeves about lambda and I really just
hope they make this go away and lets you
set individual function limits
additionally a bunch of other stuff
metrics all this stuff has just been
getting better and better over the last
year it's it's still all new people are
still trying to figure it out security
we are pretty happy with I am and the
built in AWS security but there's other
needs that other companies have that we
might not big issue observability
there's some startups that are springing
up to kind of deal with observability of
the cloud not just with lambda but all
kinds of things it's a particularly
affects lambda though exception
reporting it just these are all things
that you know you can't ssh into the box
anymore and so you're throwing away
about three decades worth of
battle-tested tooling in order to you
know go serverless and so there's
there's stuff that you're really given
up there and that that was painful for
us at certain points but overall i do
want to say like super happy with how
things have gone everything's very
stable running production and we're
happy with server lists so that's that
I'm going to like totally switch switch
directions out and talk about graph QL
and then at the end I'll kind of talk a
little bit about them together same deal
I'm not really going to go into a bunch
of detail about what graph QL is if you
want more talk to me afterwards I'm
going to just talk very briefly about it
so Gretch well is a tight squeal anguish
for AP is this is what defining one of
those schemas looks like you can
basically say I want a user thing that
has an ID and a name attribute I want to
have a query for me which is just
returning a user from the system
you then write those queries in this
JSON II looking thing and then you get
JSON back so it's low by Facebook super
cool there's a ton of information out
there online and a lot more than
serverless so it should be pretty easy
to pick up like what's going on there
although the first admit that I was not
a fan when I saw this we were looking at
it and one of our engineers is like I
really want to start using graphical for
some stuff and I was like no way I was
like rest is so great this is like soap
and woods they're all over again I was
like I don't want anything to do with
this and then you know I I gave in a
little bit I said like you know let's
start doing some stuff and it turns out
is amazing so I was totally wrong talk
about why it's amazing first-half types
turns out types really good things I
think that at this conference
particularly I won't have trouble
convincing a lot of people that but
types in your API make it really easy to
write api's my found amount of relief
api's our contracts right so imagine you
rent a car and you want to go mountain
biking with your buddies so you have a
rental contract and that contract says
give me a vehicle well what if you got
that it's not really going to help you
go mountain biking with your buddies
right and that's one of the problems
with rest is rest is not really a good
contract language people will adopt all
these conventions to make it a better
contract language and there's certain
technologies like hell or JSON API that
you can use but out of the gate it just
doesn't provide enough to really you
know write a good API contract well Brad
well does so graphical is more like this
give me a car with six seats that is
read in the bike rack it includes the
bikes with mountain bikes and the tires
so that would be my graph QL API
contract and when you actually run these
things in production the good news is
that you can vary you give a lot of
feedback to clients without having to
actually set up things document things
it's kind of all handled for you by a
graph QL this is I'm going to show off
graphical in a second but this is a from
a graph to L builder interface it
actually in the interface will give you
a little red underlines and says hey
you're trying to get a field called user
on a post and that's actually not
accessible that's something you can't
get super nice much easier to
communicate with clients and people
building clients through
and API is rather than actually having
to talk to them right human
communication is very slow this is what
the error would actually look like so if
I made this query you would get an error
back that says can't query post field
user on type post and then will actually
tell you where in your query you broke
and one of the things that allows you to
kind of do all this is this app called
the graphical so this is officially
supported by graph QL comes with it out
of the box and it is amazing it is the
killer app for graph QL right
it is like makes developing these
applications way way easier you can
actually check out our live instance so
graphical bus comm and see a bunch of
our graphical endpoints that we have
like four or five and this is what
graphical actually looks like I'm just
going to like walk through it real quick
so you can see what the different parts
are it's all real small on the screen
first after the history pane where has
histories of all the queries that you
ran the second pane over or second
things on the left is where you actually
write these queries third pane is the
data that you received back the fourth
pane is all of the information about
your API all of the types all of the
fields everything that can be returned
the fact that it's very specifically
typed API means that you can execute
this thing against your graph QL API
called an introspection query which
returns everything you need to know of
it about the API is very very
reminiscent of with Bill and stuff but
not terrible so there's some other
really good things about graph QL first
off most of the implementations segreto
out sort of the spec it's not language
specific at all but most of the language
specific implementations actually do
field level resolution which to go back
to the types means that you know it's
going to request you say I want an ID
and a name and URL and image all of a
user it's going to fetch these in
parallel and it forces you into a bunch
of good patterns that you probably
should be doing already right I think
I'm guilty of this where you are using
some back-end and you or some database
that's really easy to just dump an
entire object out of the database and
send it back to the user not really you
know thinking like well what happens
when we you know have to change this
later or change this in production and
gretel out of the gate makes you do a
lot of work a little
extra work to actually think about okay
individual pieces of this of data here
how am I actually going to get them and
it allows you to get them from different
places if that's what you need to do
talk about that in a second but what if
you're requesting all four of these
things individually you making four
trips to the database that seems them so
there's this thing called data loader so
this is one of the things that
especially you if you're doing graphic
QL you need to be using day loader and I
don't know why they don't talk about
this more it should be like on the front
page of the graph QL website like Oh
welcome to graft well you should also
install data loader data loader is
really simple it's only three hundred
lines of code it's also a face book
project and it takes requests like these
if you in parallel or you know
requesting in different parts of your
application three different things from
the database a node it schedules them
all to be resolved as promises on the
next event loop and on that next event
loop it actually batches them into one
request and it handles all this
automatically super awesome like I said
not very complicated but very clever and
how it does things and has some caching
things some other cool things you're
gonna want as well
so now syncing times talk about relay so
if you are adopting graph QL you'll find
out quickly that Facebook the graph QL
is capable of doing all these different
things I mean set up in lots of
different ways and Facebook uses a very
specific way and they have a spec for
how they do that's called the relay spec
and they have their own client for graph
QL that is called the relay client and
it's kind of complicated and you're
looking at graph QL and you're saying
well this is really nice and it's not
really that complicated and it's pretty
easy to wrap my head around and relay
introduces some complexities I was asked
a very anti relay when we first started
using graph cause like wow relay is like
complicated I don't want to deal with
any of that like graph QL is nice let's
do it and then it turns out there's all
these things that you probably want and
the Facebook people are kind of smart
and they thought about it and that's why
they made relay so my advice to you is
seriously considered using relay even if
you don't think it you need it yet you
may one day so we've switched all of our
stuff to be real a compliant things you
get with relays things like paginating
sub-fields chunks of results client
mutation ID which is a way for the
client to keep track of the mutations
it's sending back to the server partial
data fetching so making really efficient
requests for partial objects as well as
mutation structure in general so I
didn't talk about this at the beginning
a grass 12 section but graph QL has the
ability to mutate data on the server
through a thing called mutations which
brings me to horse stories so the first
horse R is mutations so I think that
mutations feel to me very bolted on to
graph QL so graph QL to me seems like
this very nice way of querying an API
letting clients determine what they want
from the server using types in order to
enforce a bunch of stuff about that and
then it was like all we need to use we
already have this thing so we want to
figure out some way to also mutate data
with that that same and that same kind
of paradigm and so they made mutations
and while they work and you can use them
and we use them all over the place to me
they feel very bolted on so I think you
it takes some work to kind of understand
what the best way to go about doing
mutations is so the hint is use relay
authorization out-of-the-box graph QL
has no ability to do any kind of
authorization or authentication it's not
at all handled for you there's no way to
hook into stuff it's you can do it
there's people written about it I could
give a whole talk on how we do
authorization a vessel but you know can
I look at a specific field on a specific
type is something that is really just
not even addressed by the framework and
I'm really hoping they fix this as well
because it's not not something if
something everybody needs and not
something that I think is well card
query complexity
another thing that graph QL does not do
for you out of the gate let's look at a
example schema so this is a simple
schema that has posts and comments and
users and I can you know get
relationships between those things if I
were to execute this query right give me
all the posts give me all the comments
for all the posts give me all the users
for those comments give me all of those
users posts and gave me all the comments
so
posts and give me all the users for
those comments I'd probably have
something like this going on so out of
the gate there's no way with graph QL to
actually determine statically like how
much a query is going to return from the
data server additionally there's no way
during the runtime to actually reject
and say or there's no built in thing for
rejecting and saying hey you you
executed a query that is just way too
complex and we're going to stop you so
you have to add that yourself we've done
that another thing that I could probably
like kind of do a whole talk on but it's
something that again people are I hope
graph QL comes out and actually solves
this officially in the framework it's
something that we we solved internally
and there's a few other people that have
written about it but not actually a ton
so it's something that's still a little
bit unexplored another thing that I
think that you should be wary of is
Facebook monoculture so we use pre
actress as a react alternative as well
as graph QL but I get very skeptical
about when all of our technology gets
tied to one one company or one company's
open source technologies so you really
need to think very very hard about our
Facebook's problems really your problems
in this case for us that was true so the
data loader API I listed this quote
right from it and it actually explains
why they came up with graph to L and
data loader in the first place and it is
to coalesce the sundry key value store
back-end eight guys which existed at the
time so this was the problem Facebook
had and this is why they built these
things we have that same problem we had
a bunch of different backends we had a
bunch of different key value stuff we
were using multiple reticences multiple
Dynamo tables and we needed some way to
kind of roll it all up so it worked out
well for us but think very very
carefully about if facebook problems are
your problems so kind of to bring it all
together talk about graph QL and
serverless
at bustled and you know more
specifically about how our architecture
works and kind of how we made that
transition I'm just going to walk you
through our the kind of phases of our
architecture and how they got built so
the first one is super old legacy stuff
this is REST API is this is Rails so
stuff I don't want to talk about it is
all old and been around since the
beginning of bustle running on ec2
then came along lambda and so we started
building the api's on lambda there were
so rest api's but that's you know it was
doing better then we tried out graph QL
and that was also running on lambda
graph child plays with lambda just great
there's not really a ton of secrets to
get it to work or anything like that
and then that's also acquired a company
so this just happened very recently and
so we have the need to integrate with
some of their stuff and get their
content into our system so third-party
APs
so just to like emoji reacts to these
different for different kind of like
buckets I would put bustle services into
we have the really horrible old stuff
the well this is better but still not
really a fan press api's on lambda our
graph QL stuff which the first attempt
we made a bunch of mistakes and did
stuff wrong but we were overall happy
with the direction is going and then
third-party it guys which you know
ideally we wouldn't have to worry about
but we just bought a company and we need
to make money and we need to you know
make that that company to purchase
worthwhile so God do something about it
so this is what we want we made one big
graph QL API that's new that is going to
do everything and this actually went
into some of the first stuff for this
one into production roughly two months
ago and some of our like largest stuff
moved over to this production
new production graphed well API just
last week so I'd say like eighty percent
of our calls are going through that now
took three primary approaches to making
that transition so the first one
building the API is on the new new API
it should be pretty basic right like
whatever the new hot thing is do
everything on there right if it's
something new but something greenfield
like we had a push notifications project
that we could just build entirely with
that that was our first production thing
on the new system to is wrapped legacy
api's so graph QL is pretty good at
doing this there's kind of four
different steps we took strategies you
can take the first is obviously read
through the legacy API is so we started
switching all of our read stuff over to
just reading directly through graphical
into some of these legacy things copy on
read and write so copying data over to
new systems and new databases from old
systems doing dual writes so you can
kind of take either approach we've done
both of these things and I would
generally say that dual rights is worked
out a little bit better for us but
that's very anecdotal and I don't really
have a good reason why it just does
happen to be the projects were most
successful and lastly replace so once
things are kind of in sync between your
legacy system and a new system you can
replace that but this only gets you so
far
so really bad data is still bad data
across the old data is spellcraft the
old data and this is honestly where the
you know the grass cue ball comes in so
this is like the most important part is
that we ended up importing data into new
systems using graph QL with mutations
this example of elite daily the company
we bought what you know like an import
looks like for them so we actually are
able to we had their engineers spec out
you know their data and what it was
supposed to look like we actually wrote
typed parts of our graph to LAPI that
correspondent to those and we were able
to import data into their system from
there our system from their system using
some of these import mutations and the
great thing about graph QL is that it
rejects if the types are incorrect so
something like a URL not actually
looking like a URL or being a valid URL
we can reject the that and not allow bad
crufty data into our new system keep it
nice and pristine and clean and then we
can go back to the you know client who
is the legacy system and say sorry
something's wrong here you need to like
work on fixing it up or you know we
generate reports for stuff like that so
I would describe it our runtime types or
just dominating our old crufty data so
that's like everything I'm going to
recap real quick so there are still
servers server lists really just about
platforms but actually server list is
really more about events and those
events are really tied carefully to
functions of service which I also called
cloud glue service is not magic the two
lean part is hard you really want a
framework you should use Shep because I
wrote it graft rel is also a really cool
tool API is our contracts types and
graphical make for good contracts
graphical is the killer app for graft
well it's something you should try out
and you will instantly fall in love with
graph QL
delivered also really neat really
important to use the graph QL forever
monoculture growing service with graph
QL you can build new API is wrapped
legacy api's and lastly is the last
resort you can import your Krusty data
with graphical mutations and it makes it
easy to keep your new API nice and
pristine and clean that's it</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>