<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serverless - reality or BS - notes from the trenches - Lynn Langit | Coder Coacher - Coaching Coders</title><meta content="Serverless - reality or BS - notes from the trenches - Lynn Langit - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serverless - reality or BS - notes from the trenches - Lynn Langit</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/PgZ2dxnj734" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello to everyone this is serverless
reality and I'm Lin Lang it
some of you might be familiar with my
work I've been a technical speaker for
many years
I'm a former Microsoft employee and I've
been an independent cloud architect for
about seven years now I do most of my
work in the United States I live in
California I also speak and travel
internationally and create courses on
cloud and big data topics for this work
I've been recognized by Microsoft with
the MVP award Google with the Google
cloud developer expert award and Amazon
for the community hero award because I'm
independent this gives me a unique
perspective that I'm going to share with
you today I'm going to be very frank and
honest and if there are people from
Microsoft Google or Amazon in the
audience I don't mean to insult you
my primary audience is the working
developer I am one of you I have
deployed several solutions I have had
pain I've also had happiness and I want
to share both so in this talk I will
talk about what my definition of
serverless is because it's very
important to start with a common basis
I'll show you examples of serverless
from the different vendors in case
you're new to one or more vendors I'll
talk about patterns architectural II
because I do work as a cloud architect
that I'm seeing both presently and on
the near-term future and probably most
importantly and hoping you'll have the
time and inclination to stay to the end
the end I will have very frank talk
about the lessons that I have learned
working in this space so to get us
started I'm going to take a use case
from the country of Australia in
Australia there was a large effort to
put the national census online now
whether or not this is serverless
comes into play later in the story the
point is it was a very large countrywide
enterprise project and the government of
Australia proudly launched the
Australian cents
us on a Friday evening and this is what
the Australian citizens were greeted
with so the question becomes clearly
didn't work how much did the government
spend on this project what was the
architecture and what does this have to
do with serverless the government spent
over nine million working with a vendor
was IBM in this case over a more than a
year long period and had a complete and
utter failure to students at a hackathon
a month later in Australia after having
attended an Amazon community event built
a complete functional copy of the
website in three days using a server
list pattern at the cost of five hundred
dollars and load tested it so that it
could bear the load that was experienced
on that Friday this is a really dramatic
case not every workload is the right fit
for server lists but for those that are
there can be incredible economies of
time and money and that's why I think
all of you are here today so let's start
with some definitions
what is serverless there's a whole bunch
of terms out there is it functions as a
service is it servers server less
without servers is it micro services is
it Amazon lambda is it functions as a
service is it using actual VMS nano VMS
for example from Amazon what is it well
you're in my talks you get my definition
my definition of the world of service
started in November 2014 when Amazon
launched lambda now I'm not so familiar
with the Norwegian cloud market I don't
do professional work here
but in the US Amazon is utterly dominant
currently in the cloud they have 16
times the business of all competitors
combined and at reinvent in November of
2014 when they launched lambda they
again changed the game
there was immediate and intense interest
in the economies of time and money that
land been made available and in fact in
the professional work that I'm doing in
the US I would estimate that fifty
percent of the projects that I work on
now have some sort of a serverless
component most usually on Amazon but
increasingly with some of the other
cloud vendors as I'll talk about when I
get into this a bit more so in case
you've not seen lambda before in case
you're entirely new to it I'm going to
show you what it looks like now because
we're out of large conference and I'm
talking about the cloud but we can never
be dependent on the speed of the cloud
what I've done is I've recorded this and
I recorded this in Norway so I did this
in Bergen I've been in your beautiful
country for a bit of time now I did some
traveling in North fjords beautiful
anyway so took a break when I was in
Bergen this is the Amazon console and
you just bring up the lambda service and
click the blue button like you do
anywhere on Amazon to get a sample when
you're first starting I suggest taking
with the blueprints there are blueprints
for node and Python although c-sharp is
now supported significantly you can just
click on a blue blue print you could
associate your lambda with a service and
Amazon this is one of the strengths of
the Amazon offering but for the simple
first example I'll just run some code
and now you give your function a name
and I just happen to select node because
it was simple but again as I said you
could use c-sharp or Python or your
favorite language basically and you can
see on line five we have an event that
we're going to fire and now we need to
give it a security permission and we're
going to go ahead and create the
function
and in the interface you then can see
the function and you can test the
function you can configure an event
that's appropriate to the function
capability in this case we're just
passing some values in
and once we click test the function will
execute and we'll see the results and
we'll see that we had a successful
execution and we see summary of the log
now one of the things that's different
of course in the serverless world is
your build on executions and resource
consumption which does differ by vendors
in the case of Amazon you set the amount
of memory 128 Meg's being the basic
amount and there is of course monitoring
via cloud watch
here's your logs and I invoked it a few
times there just to show it looks like
and a significant aspect of working with
functions is allocating the appropriate
resources and there are my invitations
and my duration and I didn't have any
errors and that's really all there is to
a basic function it's just executing
code so when I was driving around
beautiful Norway with a colleague of
mine who happens to do more work in the
Azure world his name is Anton del cinq
he and I came up with this definition of
the serverless environment rather than
saying serverless i like we like to say
that lambdas are container less so not
only other servers abstracted away from
the developers but also the containers
so as an architect I always have to
scribble on a napkin so here's my napkin
drawing there are quite a few talks in
this conference about micro services and
if you're coming new into this era of
micro services and server lists it might
be a bit confusing and one of the
challenges that I see when I'm designing
architectures is when to take a micro
service approach and move it into
serverless because they're two different
things and this is the way that I like
to think about it on these two axes on
the left side I have management and
control so less a more up here sorry so
you have more control of your physical
server but less managed
moving down to a virtual machine moving
down to containers and docker moving
down to lambda but of course in terms of
service costs the service costs are
dramatically less people ask often ask
me sea level people how much difference
can it be and although others always
going to be it depends as a rough
guideline it's very typical that a
lambda implementation will be 1/100 the
cost of running servers now there's an
interesting sort of additional pivot to
this
I just overlaid this here and this is
the thing that I mentioned earlier but
I'll continue to mention because this
does come up with an alternative in the
service environment sometimes when
you're in micro service architecture
serverless is not the best approach
you want to have micro services but you
want to have servers and in the Amazon
environment I've done quite a bit of
work with nano VMs as well which are $5
US a month so you get the economies in
cost but you still have a server so
that's kind of one of the first things
to think about micro services versus
serverless another aspect of service is
most people to think of services as
compute and that's really to narrow
serverless in some ways was launched not
in 2014 as launched in 2006 when Amazon
launched serverless file storage with s3
if you're not aware s3 is the most
widely used cloud service on the planet
by far and it's interesting to note that
not only lambda and s3 are indicative of
the serverless services that are being
offered but really in a broader scale
all of the cloud vendors and I just
happen to be most familiar with Amazon
are creating the entirety of their
offerings going forward in a serverless
basis so what does that mean you have
file storage you have compute but then
serverless offerings that i've done
quite a lot of work with over the past
12 months have been servers server list
services around Internet of Things
so IOT brokers machine learning flowing
data Kinesis
so this is a sort of general pattern in
cloud services more and more of the
offerings are offered in a serverless
manner not just compute so here's my
definition server lists to me is public
cloud services for compute for data or
files and other processing such as
machine learning there are functions
that abstract away both containers and
servers actually as an aside this will
be a bit controversial I'm personally
not very much interested in docker I'm
not very much interested in docker I'm
not interested in container
orchestration I am getting the best
economies of scale for my customers by
either selecting servers and/or
serverless I find docker in containers
to be a bit of a kind of a distraction a
bit of noise and I know I'll probably
have people that really disagree with me
but that's just been my personal
experience so server let's define
continued service is build on executions
not server instance sizes and services
that are based on events and easily and
nearly infinitely scalable so that's my
definition of serverless from a
high-level the general types of use
cases and patterns that I find server
list to the be the best fit for our
three the first one is a huge volume of
activities so running web requests queue
messages transactions also to isolate
and scale tasks another common use case
is dynamic workloads like the Australian
census that I showed you run something
infrequently once a day a month a minute
whatever and avoid paying for servers to
get those economies of scale
alternatively I've also used server
lists for scheduled tasks or jobs again
trying to get the scale economy by using
a services only build on execution not
for an entire server so
on a certain piece of code on a schedule
so in the Amazon ecosystem this is the
core the basis pattern that you see over
and over and over and this pattern is
really emerging to me as a similar
pattern in both Asia and in the Google
cloud so there's three types of service
services in this pattern the first type
is around the bottom here these are the
data services so you have generally some
sort of s3 buckets and then you have
some sort of data repositories it's most
often shown as dynamodb which is a no
sequel database then you have a layer of
compute which is n number of lambda
functions and then if you need
additional capability in the most common
scenario is you're going to expose this
outside of the Amazon Cloud then you're
going to use a different kind of
serverless service like the api gateway
so this is a pattern that's a core that
you build on over and over and over and
of course in for example as your the
azure blobs and it would be no I think
it's cosmos DB used to be document DB as
well as as your functions and then the
interface pieces that would sit in front
of it and similar in Google speaking of
vendors I'm going to show you a bit of
demo just so you can see what the
function interfaces look like with two
different scenarios just really simple
event-driven listen on a bucket or a
file bucket if you will or a timer for
lambda Google and Azure
so here's the bucket and I'm going to
create a function using a template
against s3
and there the triggers pre-populated I
just need to set it to the correct
region by the ideas speed test one is in
Norway and I found the EU London region
to be the fastest and I can talk to you
separately on how I do speed tests but I
kind of something to do for fun when I
travel so this is setting us to this
bucket I'm setting the event type and
I'm enabling the trigger so when an
object file is placed into the bucket
then the lambda code will run again very
simple code you can see if I scroll down
here
that on line 10 I have an event handler
for the context and then on line 20 I'm
calling s3 instance with get object
passing the parameters now this case my
I am has to have permission to read that
bucket using the best practice of the
permission only for executing the
function and the bucket not using you
know admin which you should not do
obviously
now anything I'm showing in the console
of course you could use a command line
tool and or use an SDK and do this
programmatically and that's what you do
in production but it's just faster to
show the console demos a little bit
better than wall of command line so here
I'm uploading a picture of beautiful
Norway extra credit if you know where
that is and then once this upload
completes the lambda will fire and of
course you have to put make the bucket
in the same region as the lambda for
this to work so if you're testing it out
I recommend you guys use London and
there's the trigger and it takes because
of the warm up time that it takes a more
time than you'd expect initially and
there's the log and you look in the log
and you can see that you've got a JPEG
now there's a reason I'm citing the logs
when we get to the how do you
programmatically work with this you
can't of course ssh into a VM or docker
container or anything like that so you
will be using the logs quite a lot when
you are developing you don't have to
access them in the console you can do it
programmatically so here's Google as of
today Google functions are in beta so
although they are powerful
I wouldn't recommend using them in
production until they go to GA so you're
creating a bucket here Google is
interesting in terms of its buckets it
has four different options multi
regional regional near line and cold
line which correspond to Amazon but it's
a unified API so I really like working
with their file system also in the
Google implementation you create a
folder in a different bucket and that's
where your zip JavaScript code for your
function goes when you work in the
console in Amazon you don't actually see
that and I do like that in Google that
you see where your code is another
concept in Google there I'm turning on
the API Google
as this concept of reducing the attack
surface and also as a concept of a
container for your cloud services you'll
see on the top says Oslo demo up here
that's a project container which is
really kind of a nice feature so I've
turned on the API and now I'm creating a
function in the console again because
it's data it's only available in u.s.
I'm sure will be Europe the memory
allocated goes higher for Google they
have three scenarios cloud pub/sub cloud
storage and HTTP trigger web hook so
there's your cloud storage bucket so the
UI is nice and familiar very simple to
compare their sample codes a little
cleaner you see on line seven there have
a process file which is collecting the
event data and here I'm making a bucket
because this is required in the Google
implementation to store the JavaScript
code so even if you want to test to
listen on the bucket you have to two
buckets different than Amazon and once
you do that then make a folder and then
it's executing the process file function
and then we're creating the function
similar UI in terms of the trigger of
the source and the testing can configure
test events similarly to Amazon and then
inside of here you just upload a file
and then the event will trigger so the
familiarity is useful actually because
considering least in my world most
people started with Amazon there's
another picture beautiful Norway and you
have the upload and then the event will
fire which will run the code so
there's the staging code which is zipped
it's another implementation detail with
functions you zip the JavaScript or
whatever the code you're using there I'm
switching back to functions and in the
UI I'll see that I have one execution
you can see over to the right here
that's the execution then I'm going over
to the logs the logging story is super
important as I said because that's you
know a key tool for you and Google's
done a really good job they purchased
this company called stackdriver
and they have very extensive logs even
though the product is beta which i think
is great and really useful so now once
this is done those are the resources
we'll go over to azure so ezra has an
interesting interface that's separate
from the main console that i discovered
and i really liked so you can do an
azure function in the main console but
you know again just to try things out
this is really kind of nice so you go to
this URL and i'll post this so you guys
can see it after and you can try out
functions with no credit card or
anything it's kind of cool
so I just recorded this off of this
console rather than the main one because
it's quicker so you can see that c-sharp
has a first class language here with
examples JavaScript there's many more
languages supported but these are the
most common scenarios you off in some
github or something and then this is a
serve your test harness user interface
you get an hour where you can just try
things out it's really nice for just
testing they're going across systems now
something significantly different in the
azure world as you see on the right they
have a function JSON which I'll show you
in a minute this is just running it so
this use case is just running a piece of
code I didn't bother to listen on the
bucket here this is a timer basically
assuming that most this audience knows
c-sharp not explaining the code very
much
so what's interesting about the
implementation here is this function
file with bindings so amazon has does a
really good job integrating with Amazon
services I really have to give it to
Azure in that they do a really good job
integrating with Azure services but they
do I think the best job integrating with
external services as well and so this is
done through bindings there's a key and
then there's a monitoring functionality
so that's like a really really quick
preview through the three different
interfaces just in case you've never
seen functions before so the state of
serverless compute right now like I said
in my world Amazon is utterly dominant
I'm doing all my work on Amazon and
production I am really interested though
in what Microsoft has done I was at
herbalist comp in Austin Texas a month
ago and really got to kind of see what's
going on with Azure functions and then
like I said my colleague that I did the
road trip with he works more in the
Azure world and I'm really pretty
impressed with the offering and I will
be you know doing more bake-offs between
the two because of the breadth of what
Microsoft's offering that being said
though Amazon's not sleeping they have
introduced what they call lambda at the
edge for IOT it's called green graphs
that actually came out last week so if
you are working with IOT sensors that
kind of world I really encourage you to
take a look at their new Greengrass
implementation it allows lambda to be
executed at the edge at a CDN or on
devices it's really interesting
functionality in the Azure world
something that I think is really
interesting is something called logic
apps which is a higher level abstraction
that allows a less code it's a GUI
designer to do integrations I encourage
you to take a look at I think there's
talks on it here really excited about it
another thing that is interesting in the
azure world is there's two billing plans
one is basically identical to Amazon
which is called consumption billed on
how many times it executes there is
another
plan that acknowledges that customers
will have this sort of mixed world will
they'll have some servers let's say web
servers and they'll want to co-locate
functions and that's called an apt
service plan so again I haven't done as
much production work in the Azure world
but when I was talking with my colleague
he was talking about the use cases and I
could really see how that would be
interesting to a lot of people so that's
something to be aware of in the Azure
world in the Google world I'm really
hoping that Google can bring their
functions to GA as soon as possible
because I think they're very performant
and very excited about them but I'm just
not going to use beta technologies in
production Google is interesting though
not only for functions just peer compute
functions they have a whole bunch of
other services that are delivered
serverless and some of them have been
around for a while so I did a whole talk
at service comps that you can see online
called serverless sequel and this
service which is called Google bigquery
is something that I has been enamored of
for many years and it's been around for
many years it basically is the ability
to upload CSV files or some other types
but text type files and to do full ANSI
sequel queries against them at a very
very cheap price so I'm going to do
something really crazy because I just
like bigquery so much so we'll see if
this will work I'm going to try to run
this query live so this is a really
complicated genomics quarry I've been
doing some work in bioinformatics so DNA
sequencing and stuff like that and one
of the things that's great about
bigquery is they have a lot of reference
data up already loaded for you so in
genomics when you're doing matching you
match against a thousand genomes
reference database so that's already up
there so you can really run some queries
very cheaply because they don't charge
you for the data that they're already
hosting so this query is really complex
has some really complex sequel inside of
it so you take all the sequel you know
and love and for those of you who know
me I haven't actually written three
books on sequel server I'm a very big
fan of ANSI sequel as it as a language
for processing and so you know you can
leverage the things you
right so if I go ahead and I run this
query and I hope I'm connected to the
Internet
yeah it's running ok good so this query
will process near over 4 terabytes of
data and when I ran it in beragon it
took 30 seconds so see how long it takes
here and it costs $5 a terabyte for the
scan so in the u.s. I have a lot of use
cases where people just want to I call
it party on the data whether it's
bioinformatics or whether it's you know
social media you know that kind of stuff
and I have a lot of customers that no
matter which vendor they're working with
they're using bigquery and that's pretty
good Hey right I'm in Norway this is
running on a US data center on a
conference Wi-Fi and I process nearly 5
terabytes of data in 36 seconds and I
aggregated 84 million rows down to 2500
rows I mean this service is very
impressive and it's surplice serverless
sequel it's been around for many years
just serverless its kind of service
before serverless is time so it's
interesting in that so that's the
results there that it's so impressive
it's something that Amazon is paid
attention to in their annual conference
reinvent in November last year they
introduced a service that is similar but
not identical so sequel on text files if
you will
it's called Aurora so very interesting
to look at some of these new services
that are coming out that are server
lists providing us with functionality
sequel in a server list fashion and I'm
finding lots of use for this in addition
to compute and some things we talked
about so talking about the basic
services in the world of Amazon is
really interesting to see that the core
compute services can be nearly free
there are 1 million requests
than a free 4 lambda and if you use
those small lambda the 128 Meg's which
isn't all is going to work but if you do
it's basically free forever if you add
up the it says X number of seconds free
so if you take that into seconds into
minutes into hours into days it's
basically free now if you use bigger
lambdas more resource consumption
they're not going to be free okay and
it's not always going to work this way
but there are some relatively well-known
use cases there's a company called a
cloud guru that runs a set of training
videos and they actually designed a
serverless architecture and they kind of
joke that they've never gotten beyond
the free tier and they have ten twenty
thousand customers a month so it's
interesting on the other side just to be
complete I've also done blended
architectures that have nano instances
as I mentioned earlier and then I'm
starting to do architectures that also
have spot pricing you know for bursty
workloads so you really have this sort
of different options around compute the
high-level
situation is that compute and file
storage are becoming commodities for
Azure Amazon and Google that's good for
all of us kind of these companies are
not you know they're they're in business
to make money so why are they doing this
lock-in this is the thing for us to
really consider this is the cost that I
can talk about that none of the vendors
are going to talk about this is where
the battle lines are being drawn if
Amazon or Microsoft or Google can get
you to use their server list services
starting with core compute and files and
you put especially your data up in their
cloud the chances that you're going to
move it go lower and lower with more
data that you put so this can sometimes
be a case for using a certain language
or using a certain architecture now give
you an example from the real world I was
lead architect on an enterprise IOT
project two years ago or so and
mission-critical the company makes
industrial devices
and I think that there's a lot of use
cases like that here in Norway and so
they chose as a language node even
though there are nets out because they
did not want to be locked into a certain
vendor and they felt that if they use
node they could then move around to
different cloud vendors depending on
what was most advantageous they also
chose to use nano instances in some
cases rather than lambda so that same
reason because those were like VMs that
they could move around all right let's
talk about patterns so this is the core
pattern and I kind of introduced this
earlier but now this is an actual
implementation this is the sort of the
canonical reference architecture and
Amazon so for those of us like me who
come out of the relational database
world this looks kind of familiar dare I
say it almost looks sort of like stored
procedures right sort of kind of
but I mean mapping what you know to the
new architecture I think can be helpful
for those of you that have that
background so you can see from a design
pattern we have here create read update
and delete so access to a database we're
abstracting it away through these
lambdas and most importantly we have one
lambda per function one per verb very
very important one of the most common
things I see done incorrectly in
serverless architectures is lambdas that
are too bulky lambdas that are too bulky
is a anti-pattern so you can see here
you have a static storage in s3 you have
lambdas for access you have API gateway
you have dynamo DB in this case you're
just connecting out to services as well
as a LexA you see this pattern over and
over and over so is this the pattern
that Netflix used Netflix is always at
every Amazon conference they are the one
that changed it all they are the one
that went server list they are the one I
don't know you guys know this but Amazon
actually sometimes will run one third of
the US Internet traffic the entire US
Internet traffic yes we're watching too
much TV but that's the different
discussion so are they the one that kind
of puts serverless over the top now they
are icky day it's beer
beer kind of kidding but kind of not
kidding
so simple viewer service is an
implementation of the reference
architecture that I just showed you with
one twist in the front rather than a
website it literally is a kegerator so
here is the github repo and I have a
homework for all of you who want to
actually build something serverless
make the world a better place you can go
here and you can get the information
starting with the hardware so you can
set up the kegerator and connect it to
the Amazon Cloud or Azure if you want to
it doesn't really matter but I just
happen to have the the Amazon one here
and you can then add it this is a goal
for me I would like to see an Oslo entry
here before I leave on Friday and I will
hack with you so if you want it if you
want to build this with me I'll be here
all week this is the dashboard that
shows from the kegerators in the Seattle
office the San Francisco office and in
Sydney what the beer flow is coming off
the kegerator and in addition to you
know being sort of fun it actually is a
reference architecture that implements
serverless like I said the difference is
its using the IOT services rather than
straight lambdas but it's an interesting
use case and again I'm thinking you guys
in Norway have a lot of IOT interest
because of the sensors and oil and gas
and all that kind of stuff so fun to
build
that's the architecture so if you want
to look at other architectures those
guys from a cloud guru one of the guys
Peter sparse key published this book and
although it's serverless architectures
on Amazon I think it's also good across
Asher and Google its patterns so he has
some of the patterns that he's made
public and I just want to highlight a
couple of them here because I think
I really recommend this book I mean
highly so you should get it if you're
going to be building on this in this in
this situation so he starts with lambdas
themselves and this is a really a common
pattern and not just in lambda but
implemented in lambda that you have a
lambda out in the front that's a command
lambda so one of the situations that you
run into with lambda is because it is
running in a docker container it's as
you know control the container is you
might need to have a lambda that's an
invoker that sits and listens to see if
the other lambdas are actually alive or
not and if not wakes them up so again
this is sort of practical reality now
you can do it in front like this now
hits the API gate where comes in from
the API gateway the invoker sits there
and says are these lambdas awake no wake
it up so a lambda that wakes up a lambda
and then send some information to a
database or you can do it the other way
you have data coming in going into some
sort of queue and then you need to send
this data downstream and you need these
lambdas to be awake to minimize latency
so this is one of many patterns that are
that I've implemented but just wanted to
share just to give you an idea in terms
of the chaining of lambdas now taking it
a little bit more broadly and going
beyond compute lambdas I build big data
pipelines that's what I do
professionally so snapchat clones
Instagram clones YouTube Ramana ties
errs bioinformatics stuff so big data
lots of attitude big data so what are
some of the overall patterns that I work
with that are serverless or mostly
serverless so this is an IOT this amazon
IOT this is similar to the pattern that
I built for the enterprise group so
Amazon has a very strong story around
integration with mqtt protocols for IOT
and these I Oh T rules are basically
specialty lambdas that when data comes
in from the device you set the
thresholds install GUI base so it's very
simple to implement and then notice the
core of this arc
texture is the server list you send the
data that has been processed through the
Dynamo and then you probably do
subsequent processing on lambda and then
you serve it up to the dashboard on the
API gateway so hopefully there's some
familiarity here and notice no servers
whatsoever none zero reference
architecture but again going back to
that slide about lock-in vendors are
going to show you these architectures
it's in their own best interest the real
world sometimes can be more plinth
blended for example in this scenario we
had a special security requirement and
we used small ec2 instances as our
custom security servers because we
wanted to have complete control over
that so you see this pattern a lot this
is a data stream coming in through
Kinesis pipe and then you have a cold
path over here the red going into the
bucket and the hot path going to the
lambda going back to dynamo and then you
have some processing going in they call
it a Kinesis app so at the serverless
conference there was an architecture
competition for server list
architectures and the US retailer
Nordstrom won with basically a more
sophisticated implementation of this and
this is what it looks like it looks kind
of intimidating but it's really just
that separation of concerns so you know
you have you take a picture of some
product and then you send it in with
some lambdas to the API gateway and then
you partition based on functions I call
it based on verbs if you will and then
you store you know cold past some
information here or some reference data
out of your bucket you do your
processing and then send your
information through dynamo for State
because of course lambdas are stateless
and then you know do subsequent
downstream processing with lambda so
this is the sort of high-level
serverless architecture that can be used
for certain use cases just to be
complete google has a set of services
like I said it's interesting of their
services I think the actual core
functions obviously if they're beta are
least to mature but they have many other
sophisticated services like this is a
similar one with the hot and cold
half like pub/sub which is like Kinesis
which is very mature so I have built
these streaming batched I'm sorry these
streaming big data architectures very
very successfully with Google using some
of the really powerful services like
bigquery and this is just a more complex
version again you've got the it's
probably too much to consume in great
detail but you've got the streaming path
and you've got the batch path and then
they're serving up with services like
bigquery and data lab which is Jupiter
notebooks another use case that I'm
doing quite a lot of work in and I would
just share with you I again I don't know
the Norwegian market because I don't
work here other than speaking here but
in the US there is a huge skills gap
between developers who can code machine
learning and what my customers need I am
actually literally going to universities
and I'm getting I'm hiring university
students while they're still in school
because they've had machine learning
courses machine learning is coming fast
really really fast all three vendors
have very compelling offerings and where
I'm working on it is this use case up
here which is bioinformatics I actually
have a different talk in this conference
on Friday about some work that I've done
but the idea is the scale of data
requires predictive analytics or machine
learning because you can't just use in a
simple aggregation anymore anyway so in
the world of the vendors they have
machine learning as a service they have
specialized api's like an Amazon poly
Lex and recognition Google vision speech
and video API and then they are working
on these open source projects that have
started out of academia for the really
computationally intense problems the
deep neural nets and Amazon has put
their hat in the ring with MX net and
Google has tensorflow very interesting
because these computationally intense
workloads take advantage of GPUs and all
the event Amazon and Google have GPUs as
a service I'm just not as familiar in
the Azure space there's lots
as your people here so I'm assuming they
have similar offerings because all this
is everybody is really really trying to
get offerings out there so I talked
about this from - two reasons one
customers want it to educate yourself
and I guess I'll just take my little
one-minute sidetrack here I don't care
how old or how young you are a if you
are interested in learning this stuff it
is highly highly possible I have been
working on learning advanced calculus I
think there is a talk here on
implementing the lambda calculus that
I'll be sitting in the amount of
learning that is necessary in our
industry to be able to service our
customer need is significant and those
of us who embrace lifelong learning are
going to be very successful in this area
and those that don't aren't so seeing
that lessons okay so let's talk about
some real-world problems I've
implemented lambda in production with
several customers so these are known
problems but again you came to my talk
to get reality so maybe you haven't
experienced this yet warmup time is a
known problem because of if you need
always-on lambdas that there's a there's
an initial warmup time because the
docker container understand how to
properly store state is not really a
problem it's just an architectural
challenge and then there's mystery and
freeze and thaw errors the scary things
so for warmup time I showed you the
pattern warming trigger you can do cloud
watch events instead it I just put five
minutes you can put whatever time you
want basically for state I've shown you
the pattern over and over to store the
state externally either in s3 which of
course you should encrypt for anything
that has a high security need or
dynamodb this is a little bit more
subtle for mystery errors allocate more
lambda memory remember how I said you
get what you pay for 128 Meg lambdas are
pretty much free but you get what you
pay for so sometimes you have to bump
the memory up and if you're working with
node this is just my project about a
node use the latest node.js versions and
on cloud because that's what they're
optimizing for and use shorter
operations common sense but very very
important in the world of serverless so
lambdas are more than coding so you're
going to look at is lambda available in
your programming language the previous
guy was talking was talking about
c-sharp in the C sharp community I was
really happy to see Amazon announced
support in lambda for c-sharp I love
c-sharp haven't done any work in c-sharp
unfortunately it hasn't had any demand
and I'm really hoping that you know like
he was making a call to the c-sharp
community to be more open and be more
inclusive
I love c-sharp it's a beautiful language
I feel sad and I'll tell you that in
California I'm having very little demand
for c-sharp it's all Python and node so
you have concerns around debugging unit
testing integration testing or
orchestration and deployment so
debugging patterns Ezra comes out really
strong here Microsoft's always had a
great tooling story they have a local
emulator the visual studio tools are
great fantastic if you're a.net
developer very compelling the story on
the Amazon and gtp side is not as happy
I just what I did for testing and
debugging I use mocha chai and mocks so
there's a lot of pain basically these
are libraries for node you want to code
the ax testable pattern supports an
adapter so it's on you to code properly
and there are starting to be a utility
libraries such as lambda tester and
there's an alpha version on github for
GCP so it's a painful kind of story in
the world of security what I see
whenever there is a paradigm shift and
technology is developers don't like
caring about security and they tend to
let it drop and this is just this is
nothing new it's just one slide for you
know follow best security practices
credentials that are unique small attack
surface test your external connections
minimal permissions granular policies
nothing new but just don't ignore these
things this is a picture of
as er logic apps again I encourage you
if you're working in the Azure
environment to take a look at this when
I was traveling around with my friend
Anton he said he was frustrated because
whenever he was thinking of writing an
azure function he went and looked to the
logic app and the integration was
already written for him so you know
kudos to Microsoft for that that they
have so many of the common integrations
so this is an orchestration UI that
generates JSON code and it really
showcases the ability to orchestrate
functions very powerfully on the Amazon
side they have step functions of course
you can use cloud watch alarms and
triggers but step functions which is in
beta and this is more of a focus on flow
rather than integration but I do have
one customer I'm working with so if
you're interested in getting some real
world information about this I will be
blogging and writing about the
implementation of step functions in it's
a bioinformatics workflow and Amazon
starting to publish reference
architectures here so again they're
pushing all same server lists and
they're publishing these architectures
around orchestration which I'll be
leveraging when I'm working with my
clients I wanted to make you aware
they're already doing this in terms of
deployment again a jar has a great story
kind of same thing they have nice
integration with Visual Studio they have
a RM or as your resource manager JSON
templates and you can use PowerShell to
deploy always a strengths with Microsoft
on the Amazon side still got some work
to do although the cloud formation which
uses yamo files similarly to the RMS now
has extended to support functions by Sam
templates there are a bunch of
third-party templates that I've seen
more often over previous time terraform
is commercial service framework claudia
j/s so the Sam templates work in the
cloud formation designer and I actually
have a little demo of how this works
you've never seen this
this UPS let me get out of here
got it here there you there okay so if
you're not familiar I'm just going
through the environment saying I have
nothing there nothing there nothing
there so I'm going to deploy that
reference architecture so I'm going to
do this with the cloud formation stack
and I'm going to do it through the
command line so I have I have a yamo
file and you can see on line six there
this is the sam extension so type a WS
colon colon serverless colon colon
function so this is configuration of
code which is a extremely important
practice in cloud even more so and
serverless has got more objects to deal
with and this is going to deploy all of
those lambdas those buckets and the
DynamoDB and the api gateway and then
this is the that they put all the lambda
code kind of sloppily in one index j s
just to make it quicker it should be
should correspond to each lambda of
course and this is as you can see like
on line 33 event stop put this is
putting into on 44 dynamo hood item so
this is using the lambda to connect to
the dynamo DB so I'm running this from
the AWS CLI the first thing that I'm
doing is I'm running on line one when I
put this into my terminal AWS
CloudFormation and I'm taking that
yellow file and I'm specifying where to
put it because it has to in order for
cloud formation to execute it has to run
from a bucket so I'm just saying put
that yamo file in this bucket which it
does and now it makes a new yellow file
that says where it is basically because
one of the things CloudFormation does
for you is it versions the stacks or the
ML files so it's like a github in a way
or source control I guess if you will so
now I'm going to deploy this and I have
the capabilities flag because I have to
create an I am
or a permission for this and this will
deploy that entire architecture so it
will deploy definitely recorded this
because it doesn't go as fast as in the
video okay and on this is from an Amazon
sample so I can put the link in the
presentation if you guys want to try it
and I did this from here so it works
just fine you have to put it in you se
still unfortunately and there's all the
creates of all the lambdas so
everything's done it takes about five
minutes and then you get a nice log
so you conversion all this stuff so you
never seen cloud solutions versioned
that that alone is worth the price of
admission to this talk it's extremely
important production don't click on the
console only for demos so there's my Sam
template there's my lambdas so I have a
get put and delete
familiar pattern hopefully by now its
associated to the API gateway there's my
dynamo DB and I can put an item and if
you're not familiar with API gateway
this puts a rest endpoint on your lambda
and you can see that you have basically
rest interface here and you can put
authorizers and all the things API
management so and there I'm just clinks
mines what I'm going to do in the
interest of time here is I'm just going
to move up to there's the designer so
that's what the the cloud formation
designer looks like it's a visual
designer and then you can dip your your
changesets JSON file and then you can
also cleanly remove great this is great
for testing too I mean obviously great
for production this is how you build
your deployment pipeline this pattern is
actually like I said extreme so now I'm
going to delete this and I'll remove all
the resources this is extremely
important for service because you have
more objects to deal with you're not you
know having three ec2 servers or
something and then once you delete the
stack all the objects will be gone all
right
so monitoring so charity is a very
famous speakers DevOps person lots of
experience and she's basically
expressing the rage of the DevOps people
which I don't have any other way to
state it it's very challenging for
people whose careers were made on
monitoring servers to be handed
serverless architectures so the reality
is they're afraid and angry now how we
had success with one of the big projects
I worked on is we use the technique
called mob programming and we integrated
the DevOps people they also went for
Amazon training so Woody's ULA's here
he's the father of mob programming and
you know I've worked with the mob for
more than a year or you can talk to
woody but it is in a very powerful
technique when you have this amount of
change because the DevOps people are
really really feeling unsettled by
serverless architectures and justifiably
all right so let's get real serverless
costs are so cheap coding is so easy
configuration is a breeze transparent
error reporting service is great for
developers monitoring is easy for devops
deployment is simple serverless is best
for everything
boy I sound like I still work at one of
those big vendors don't I nope costs are
cheap yes coding can be easy you have to
think in a services micro services kind
of style and implement that way
configuration can be manageable
depending on how you are comfortable
with the tools whether it's cloud
formation or whatever tools you use do
not click on the console do not click on
the console do not click on the console
really bad transparent error reporting
maybe you might have mystery errors
sometimes you can solve them by just
bumping up the resources sometimes you
just have to learn how to read the cloud
watch logs service is great for
developers maybe developers mostly love
it initially but then when they realize
they can't SSH into a container
they don't love it as much I actually
had a team who told me it was impossible
to implement an architecture that I drew
so unfortunately we fired the team and
built the architecture monitoring is
easy no there are new tools they're
powerful Amazon for example now supports
monitoring of lambda with x-ray Google
has staff driver but they're new and
DevOps people do not like change that's
why their DevOps people they maintain
systems so do not underestimate the need
for education integration and training
for DevOps people and serverless
solutions deployment is Simplenote we
need tools we wrote scripts at one
client because they just refused to use
cloud formation it was hell don't do
that use tools by a terraform or
whatever it is use tools serverless is
best for everything no absolutely not
it's best for the types of workloads
that I talked about initially variable
workloads workloads that have isolated
portions workloads that are spiky not
for everything so what's the reality you
can always use servers and you might
want to so I recommend when you're
making your architecture which whatever
cloud you're working on you actually
evaluate using server based
architectures and you take into
consideration aspects such as control
such as learning curve such as estimated
cost the full picture and you'll most
often end up with a blended solution
pure serverless is for things like
simple beer not necessarily for the
things we work on yet the market status
of course Amazon the market leader
building new features Azure I see
copying Amazon but also adding you know
the tooling is great and then adding
these integrations I'm really very you
know kudos to Microsoft I'm going to be
shown
customers as sure as well who are
interested in that ecosystem Google
please get your functions out of beta I
really like your serverless services I'd
like to see your functions and that is
to realest reality thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>