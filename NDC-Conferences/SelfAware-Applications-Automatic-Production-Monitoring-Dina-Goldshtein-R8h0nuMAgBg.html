<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Self-Aware Applications: Automatic Production Monitoring - Dina Goldshtein | Coder Coacher - Coaching Coders</title><meta content="Self-Aware Applications: Automatic Production Monitoring - Dina Goldshtein - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Self-Aware Applications: Automatic Production Monitoring - Dina Goldshtein</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/R8h0nuMAgBg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay hi everybody I think I got the cue
to start so my name is Dina I'm really
really excited to be here especially
since this is my first time in Australia
so you're going to see a sort of
Australian theme going on my slides I'm
going to talk to you today about a
mantra that I'm trying to push forward
and that's automatic monitoring and even
possibly profiling and Diagnostics of
your production environment so what are
we going to talk about today I always
like to start with a little motivation
before we get to business
so first I will try to convince you
while monitoring of your production is
you know pretty important and sometimes
even an absolute must then I'll present
to you sort of a general scheme that I
think that we can use in order to
approach this self monitoring plan that
we that we want to implement and then
after all the introductory hand-waving
and and stuff will actually see four
demos that will show you different
aspects of your dot mostly dotnet
applications that you can monitor and as
I said before perhaps even diagnose on
your production systems before we
continue though I would like to mention
a few things that we're not going to
cover today you know so you want to be
disappointed at the end of the talk so
we're not going to talk about profiling
tools we're not going to talk about
dashboards or like any kind of
representation of the data we're not
talking about third-party monitoring
today we're going to do everything with
our own bare hands so be prepared as I
said a little motivation well in case
it's not obvious by the name and you
know the two minutes that I've been
talking just now
I think that's monitoring is an absolute
must you know not just debugging and
profiling during our development process
but the actual live monitoring of our
products
systems now if you're developing a
server or basically anything at scale I
think it's kind of obvious that you need
to monitor I mean like you have to be on
top of things you can't wait for your
users and you have a lot of users if you
develop a server you can wait for users
to to contact you and say that something
is wrong you have to be on top of things
and make sure to kind of address the
problems before you cause actual
negative value to your users and
obviously you can't do it manually like
you can't just log on from time to time
to your server you know check check its
metrics and check its health and stuff
like that because there's just usually
too many instances to monitor so you
can't do it manually this isn't quite
obvious case though as I said what I
want to add here is that these from my
perspective it's also very very
important to monitor or self monitor
simple desktop applications as well
because unlike in servers where you
usually are always but usually have
access to your servers so you can check
them and you know connect if you have
problems and and monitor them like at
least the simple metrics with a desktop
app you just like ship it to the
customer and they install it and you
have no control over what's going on
there from that point in time you don't
know the exact environment where it's
going to be installed you don't know
exactly what they're going to do with it
and you kind of lose visibility into
what's going on and so in that sense I
think the situation is kind of worse
than with servers and so to have the
ability to self monitor and to be able
to kind of provide the extra data and
not just like our usual login like we're
doing this we're doing that this was the
input you know some error happened they
actually be able to to know more general
flows in our application like what's
consuming time what's consuming
resources that's a very crucial ability
for our desktop applications so I think
I convinced you that monitoring
monitoring is important why should we
write our own monitor
well I didn't write in the slides but
personally I think that researching
performance is very important so I mean
it's very interesting I'm sorry so like
for me it's a fun feature to develop and
like I hope that for you as well it's
like all about software and how stuff
works and getting into internals of
things so I think it's fun but a more
practical note first and foremost the
reason to write something on your own is
that it means that your monitoring can
be tailored to your specific business
needs it's not just going to be about
this generic metric such as CPU and
memory and garbage collection I don't
know disk whatever it can be for your
actual application it can be your
algorithms that are monitored your
queues your requests whatever it is that
you have in your application you can
monitor it specifically and it's going
to give you much more insight than just
generic monitoring the second reason you
were going but to benefit from writing
your own art or is that the diagnostic
Diagnostics data it will flow from
ground up and what I mean by that is
that you don't have to kind of redirect
the data into external dashboard or tool
wait for it to analyze the data wait to
get a notification and alert in the
middle of the night
wake up scratch your head start thinking
well what should I do
know like the application can become
aware of itself self-aware it builds
like it collects the telemetry and it
knows what's going on and you can even
actually and we're going to see examples
of that later
you can even perhaps you know do
something with that data and try to
mitigate some you know some negative
value that might be going on or like try
to restart or well again we'll see later
some examples of what you can do and the
last ring is and that's what all the
cool kids do right so I mean I think
that like currently with a DevOps state
of
mine the development community kind of
convergence converging on the idea that
it's very important to automate well
basically anything but especially
monitoring so again like I'm not
advising you to do something just
because like everybody else does that
but there's good reason the good reasons
that we just discussed just now why
people are converging on this idea of
automatic monitoring and you can't stay
behind if your software doesn't do as
well as others you will be left behind
and you don't want that I guess cool so
how do we go about implementing this or
a grand target of self-awareness
self-aware applications after all we
can't just you know attach a profiler or
a debugger to our production system
because you know obviously the overhead
is going to be too too big so I suggest
I think it's not surprising to use a
kind of a hierarchical scheme okay so
what we're going to do is that we're
going to use the cheapest tools
available for us to monitor anything
that like we need to monitor frequently
for all of our basics right so that's
that could be CPU memory disk all of
those generic stuff that I talked about
before
usually these would be just numerical
values that represent resource
consumption now if we have something
which is a little rarer or requires
slightly more resources to analyze we
can use more advanced tools so for
example if we have some rare exceptions
or if we're afraid we might have
deadlocks then we can I mean that's
something that doesn't happen a lot we
don't have to you know monitor for
deadlocks
every hundred milliseconds so excuse me
so we can invest a little more time into
that but just like do it less frequently
and then if worse comes to worst and we
actually diagnose that our application
is having a problem
it's deadlocked it's using too much CPU
does too much GC it leaks memory I don't
know your queues are too large or
requests timeout
everything's failing well everything is
so bad anyway so we can just you know
use some more resources and do some more
deep deep analysis of what's going on
and perhaps even diagnose memory leaks
or what our application is doing where
the CPU is spending time and again this
is very important because not always you
can like reproduce these problems and
again in this information right from
production we'll give you a huge benefit
in debugging later and trying to figure
out what exactly happened we'll just
have the information coming straight
from your primer application so before
we continue though let's just do a quick
overview of the tools which are
available for us in each of these
categories so I think that the easiest
way on Windows at least to get to get
information about our system or the
process is performance counters
performance counters are kind of like
these data emitting objects and windows
which provide numerical information
sample numerical information about all
sorts of aspects of our system both from
a specific process could be our process
and from system-wide so you can get the
CPU usage of your process you can get
the memory usage of your process you
could not get the number of handles now
the cool thing about these performance
counters is that you don't have to
restore it your application to get them
or anything like that you just need to
turn on the specific performance counter
that you want to monitor and kind of tap
into it using an API which is available
for us both an and C++ as a side note
I'll mention that you can also emit your
own performance counters so I was saying
for that you can monitor for example cue
Silas you can emit these cue sizes as a
performance counter and then that would
sit like very nicely with the
architecture of the monitoring if we're
monitoring performance counters anyway
then we can also monitor our own custom
values this way if you don't want to use
performance counters for some reason for
example because of locale localization
issues actually they have like string
names and they can depend on the locale
of your machine so you might have some
German name for a performance counter or
even worse I know Japanese or something
like that
so type it so you might want to not use
performance counters so you basically
have win32 api is to do the same things
i mean after all the performance
counters are implemented using such such
native api's so you can get for example
CPU information using get process times
that will give you how like how much CPU
your process uses and if you want memory
information you could use get process
memory info or if you need information
about specific threads in your
application then you can get then you
can use get read times so all of that is
available for you and if you need
something very specific a specific
component a specific function inside
your code then you can of course always
use stopwatches or some other similar
mechanisms to measure very specific
locations in your code now all of these
tools that we talked about they provide
you with those numerical values that I
keep talking about and they're great in
the sense that it's very easy to
diagnose that you have high GC pauses or
that you have high CPU consumption or
high memory consumption but they have no
way to tell you where the source of the
problem is
you just know that you have high
resource consumption but you don't know
why you don't know where your CPU is
spending time you don't know which
objects were allocated and where so we
have a solution for that as well
windows also comes with a built in
structured logging framework which is
called etw event tracing for Windows as
I said it's a structured login framework
so what it provides you is that it can
give you not just numerical value values
but also other data regarding this trace
point that the log message is emitted
from and similarly to performance
counters etw is also incorporated inside
Windows and it's really all over the
system it's in user mode functions in
kernel mode it's in drivers and services
and all over dotnet you can get lots of
information about dotnet from e TW
instead third-party components in fact a
while ago I found out that even chrome
can emit it to W if you configure it in
a special way so so it's pretty much
everywhere and it gives a lot more
information that you can use excuse me
at this point it's worth mentioning that
in fact Windows relies on etw for some
of its own monitoring so for example
some of the events in the Windows Event
log are actually the result of some
analysis of etw messages that windows
collected collects so why am I saying
that because this gives rise to the idea
that maybe you can analyze your own logs
in a similar fashion now why would you
do that the same reason that Windows
does it you have the data and so you can
analyze it now you're probably asking
yourself well ok so I just you know
wrote down the data in my log why do I
need to write it down then you know read
it
Aarseth try to figure it out why not
just like pass the data straight to my
monitor well kind of again for the same
reason that Windows does its separation
of concerns collecting the telemetry and
analyze and get are two separate things
so by keeping them separate you allow
your application to be more flexible and
more extendable in the sense that you
could always add more telemetry and you
can add more analysis logic and the
things are going to be kind of separated
so it's most in architectural thing now
another route you might choose to take
is the use seal our MD seal our MD is an
c-sharp open-source library it's
available in nougat it's developed by
Microsoft and what it gives you is a
programmatic API for all sorts of
debugging operations which before this
library came to be we're only available
when you were using like a fully fledged
UI debugger so you can attach to a
process you can read its memory you can
look at its treads look what the threads
are waiting for
so you analyze locks you can see the
types that are allocated you can get
information about the generations and
like everything basically that's in the
memory space you can get using CLR they
be MD sorry and it's actually available
both for both for managed and native
applications so just take note of that
now the good thing about CLR MD aside
from it's convenient API and it is very
convenient that it's actually able to
attach to applications in a passive mode
non-invasive and that means that the
same terms exists for when you attach
the bugger to an application I think
that when the bag asks you if you want
to attach passive were non passive
and what it means is that if you
attached an application in a
non-invasive manner then the time that
it pauses is going to be well
non-existent or at the very least
minimal and that's very important
because you're in production right you
don't want to pause your application for
too long because you're collecting
statistics you need to do work so that
was an advantage of CLR MD if you're
willing to invest more time into your
Diagnostics on production you can use
the CLR profiling api's they're much
more extensive than what CLR MD provides
they give you a ton of information
basically about anything that happens in
your dotnet runtime so that's app
domains assembly loading JIT tread
creation everything that's going on in
GC but as you can imagine it has quite a
large overhead and even the official
documentation states that using the CLR
profiling API is not supported on on
production for high availability systems
so this is really a last resort if you
absolutely like all hell broke loose and
you have to do something along with the
CLR profiling API there's also a sailor
debugging API which again provides much
more functionality than what CLR MD does
it actually allows you to set
breakpoints to get notified about
exceptions to modify state really I
don't think you're going to use it but
just felt like you know if I'm talking
about the CLR profiling API I should
probably mention the debugging API as
well and lastly there's always the
option of hooking the API that you want
to monitor
now the overhead of using hooks
basically depends on the amount of work
that you're going to do inside the hook
so I wrote it down as an invasive
analysis API it is invasive it's very
invasive but it doesn't it doesn't have
to be costly but the main problem with
hooks is that it's usually pretty hard
to implement them like a hundred percent
correctly and from my experience at
least when there are several software's
on your machine
the do hooks and for example anti
viruses tend to do that and like all
sorts of security software do that if
it's not done a hundred percent
correctly and all these applications
kind of start clashing with each other
and it doesn't end well so I don't
recommend doing that unless you
absolutely have to and in general today
we're not going to see examples of
anything on that slide both because it's
too complicated and like I don't think
that you'd usually get to it we will see
examples of etw and shield RMD which I
think are suitable for production and
you can get lots of useful information
from which finally gets us to ending all
the hand waving and the introductory
stuff and we'll finally see some
examples of what can be done and what
data we can get from our production
systems so the first thing we're going
to see is CPU profiling now I have to I
was talking before how we do our own
monitoring because it's going to be
tailored and customized through our own
specific needs and like then all my
demos are going to be generic stuff like
CPU and memory and well first of all
because these are stuff although they're
generic they're important but also
because I just want to show you like the
general idea of what can be done and you
obviously like there are a lot of people
in the audience each of you probably has
different business needs so I want to
show you the general stuff so that you
can later use the tools and ideas that
alertly learn today and apply them to
your own applications so back to CPU
profiling it's going to be relatively
straightforward but I think that even
that is going to add a huge benefit to
your applications imagine
that instead of the users calling you in
complaining that the application is
hogging CPU and then and they don't know
how to reproduce it like they don't know
what happens right and so instead of you
having to immediately schedule a support
meeting with them maybe one of them in
the states another in Australia another
one somewhere in the Middle East so
three different time zones you have to
get all the people together start
attaching a profiler and like you need
to get approval with a profiler on the
customers machine which is trust me it's
not trivial
so it's gets messy and imagine that the
application could just you know like
write down in the in the log file here
and you know at this time at this date I
used 80% CPU this is the function that
you know was cold most of the you know
use 70% of the CPU and this one was 10
30 % of the CPU and here's all the data
and you know like go fix it so that's a
huge thing and and especially huge on
these desktop application scenarios that
I mentioned before because the
environments of the users are so
different and many times they really
don't know how to recreate the issue how
to reproduce it you have no idea like
they say I click this button and you you
know you click the button and everything
is ok
plus their machines are different they
have you know maybe they have two cores
on your development machine you have
eight cores so it's all very different
so this will allow you to just kind of
get the answer that you were looking for
so that was little motivation let's
let's actually start how are you going
to get about this so as I said before
the first thing we're going to need to
do is to monitor the basics right so a
simple numerical value representing the
resource consumption and in our case
that CPU usage so we're going to use
performance counters to monitor that
there's a performance counter which
provides CPU usage for every application
on our machine
and we could for example you might have
a better logic like on your machines but
what I'm lamented in the demo that we're
about to see is that for example if the
application uses more than I don't know
say 80% CPU over 10 seconds then you
know something is wrong let's start
getting more data and what this data is
going to be is that it's going to be
data from etw I didn't tell it to you
before but etw is actually able to
provide me with call stacks for each of
the events that it emits and so in fact
by simply sampling the CPU every say 100
milliseconds I can get a pretty good
sample of what the application is doing
and this is in fact the same result that
you would get by attaching a sampling
profiler to your application so we're
going to turn on etw and collect these
call stacks for a while now usually what
you would do with etw is that you would
record it into a file and pass it to
development for analysis in you know
some freely available etw tools but
using an open source project which is
available on github called live stacks
you can actually translate the program
pointers the addresses memory into real
function names and so you will be able
to figure out these call stacks live on
production and actually print them out
to the log file making the developers
lives very very easy so once you have
these call stacks you can find of course
the hot paths of your application you
can produce flame graphs and you can
even suggest some recommendations for
what can be done to solve the issue now
if you're wondering well what on earth
can we suggest how can we fix the
problem so
here are a few examples just like a few
things at the top of my head let's say
that your authentication controller is
taking a lot of CPU time you might be
getting attacked alright you might be
getting DDOS'd so that's interesting
information if you know where the CPU is
coming from it might give you hints as
to what the problem is or maybe you have
some data processing component in your
application that suddenly take in a
hundred percent CPU okay so a good
recommendation might be to scale and in
fact if you can even do that
automatically the scaling based on your
CPU consumption how cool would that be
right so we have automation all the way
DevOps for the whim and you know at the
very least if you don't have anything
smart to say then you can say well okay
there's a problem
please reports to develop and hear all
the details or you can even you know if
you're connected to the Internet you can
even no report it yourself from the
application with all in all of the
information and hope that the developers
will know what to do and again I'm sure
that you will have more ideas that are
more relevant for your lines of business
okey dokey so let's look at some code
okay let's look at some code so we have
a web application here here is amazing
web application doesn't do doesn't do a
lot of interesting stuff just some fine
Taylor demos with problems that we're
going to encounter today so we're going
to start looking at the CPU let's first
look at the code for the CPU usage
monitor and then we'll run the
application and see what happens
can everybody see the phone like right
back in the end no you can't right I was
hoping it was too small
hoping now I was afraid it was too small
sorry is that
so we have our CPU monitor before we
look at the CPU monitor let's just look
at some base classes that we have here
I'm not sure that like code wise this is
the best design so don't necessarily go
copying it the way it is it's just
something for the demos but here the
idea is that we have like this general
concept of a monitor which is something
that samples something and wait for a
certain number of violations so for
example in our case it would be sampling
the CPU performance counter every gosh I
don't remember few milliseconds and if
it passes 80 90 whatever percent then we
start doing some intensive sampling okay
so this is the base class it does
nothing so there's nothing inside here
but here we can see the implementation
so we have the performance counter and
we have a timer which samples the
counter every interval and we can see
that here we sample the counter using
the next value API and we count the
number of thresholds and if we passed
the number of violations if we passed
the threshold but we're never supposed
to pass then we start our intensive
sampling or intensive data collection
and so again in this case the intensive
data collection basically does nothing
this is the base class it just calls
start then stop and then it marks that
we're done and again in this base class
it just does not so our case is the CPU
monitor
which is so we can see here that it uses
the performance counter from the
processor group the percentage of
processor time that's what we're going
to monitor and this is the threshold
that we want to monitor for but this
specific monitor it actually inherits
not from the base monitor but from the
event stack monitor and you can
understand from the name what it does
and this monitor actually takes samples
of the stack of the CPU stocks when on
the intensive mode so let's look there
so this is a type of monitor again and
here is what we do when we start our
intensive sampling we're not going to go
over the entire code it's available on
github and specifically live session is
copied from the live stacks project that
I told you about I just want to show you
the general idea like the data flow that
goes on because talking about you know
reading etw and parsing stacks can take
an entire hour on its own so you're not
gonna dive into that just know that it's
copied from the live stacks project then
it works so what we do when we want to
start the intensive sampling is that we
start an etw session and in this case
this is the base class the CTW session
is just going to collect call stacks
it's going to sample the CPU every 100
milliseconds and when we stop the
session after a sampling duration we
will just be able to get a call stack
tree representing everything that
happened in the application in that time
and so this session that we created here
actually also has a property stacks
which provides us with the top stacks so
these are the top usage stacks the
stacks that used most CPU during that
time
and what we do is just print them to our
log file so let's see that in action
I have perfmon here it's monitoring my
IAS application which in the meantime
stopped running so I will start it again
excuse me
starting it again okay here it's running
and I have perfmon perfmon is just a
tool that comes with Windows and it
allows me to monitor performance
counters which I select so we can see
them here
I'm sorry it's a little small I don't
know how to make it larger but we
monitor the processor time that's the
blue line here that we see so I am going
to login into my website and we will see
right away that CPU has gone up to
basically a hundred percent so so
there's something going on here and it
was bad it was unexpected and our
monitor is going to catch that so let's
look at the log file this is I have to
admit this is a log file that I created
before before the talk because now all
the monitors are turned on and I wanted
to have a log file for each monitor just
so it's easier for us to understand
what's going on but it works so this is
a real log I didn't manufacture anything
so let's see this is the start
everything is fine there was one one
violation of CPU second violation of CPU
and third violation of CPU and that
kicked in the etw collection for CPU
stacks and here are the top three stacks
that were gathered during intensive
sampling so let's start looking at them
we'll just scroll quickly to where the
important and interesting things are so
the first stack here and this is
actually we're going to talk about it
later
the first stack is actually for the
monitoring code itself which is a little
sad I know but this is a very weak
machine it's a VM it's on my Mac it
doesn't work very well and I will talk a
little more about it later so if we go
down more we see more stacks and and
this is actually this is actually
interesting I'm not sure if there is
much to do about it
can you see the font at the end by the
way good
so this stack is actually from asp.net
itself and so I'm not sure if like
there's I'm on asp.net expert so I'm not
sure if there's anything we can do about
that but I think it's interesting
information to see that like building
the controller or whatever it is that it
was doing here took a lot of time and so
we scroll down and the log and oh there
were more CPU violations and finally we
find our own code in these call stacks
and what we can see here is that account
controller called a good hash function
so the name is already suspicious right
we calculated hash might take time right
let's look at the code and see if
there's anything there to explain what
was going on so let's open our good hash
function here it is and it indeed
calculates a hash but maybe it's like
it's not clear this is a lot of
iterations for for calculating hash so
that explains why it took such a long
time but we're not sure why it was
called
so I mean this has to do more with like
knowing your own code but we can see
that in our specific example only emails
that end with Gmail call the good hash
function so we have a CPU hog in our
code and we found it because the log
actually contained the data saying which
function was using all that CPU and I
think it's pretty cool okay so our next
example is going to be about monitoring
for GC performance or in fact not
exactly GC performance but rather
certain usage of memory traffic in our
application then can lead to GC
performance and specifically what we're
going to monitor is the is the
allocations the rate of allocations that
our application does and the reason that
I want to monitor that is that again if
we have too much allocation then we
might cause long GC pauses and these are
very important to avoid of course in
servers where we have to answer requests
we can't we can't allow ourselves to
stop for a long time but it's also very
important in those simple desktop
application they keep coming back to
because imagine a UI that has hiccups
because of long GC problems users are
not going to like that in a sense I mean
I like I'm not sure but like as a user
myself I think that when I you I get
stuck it's more frustrating for me than
like having to wait for Google to return
results I don't know because like you
know the server is doing something ok I
don't know it takes a while but when new
UI is stuck it's really annoying
so we needed to avoid that and I want to
be able to monitor for such potential
problems in our applications so very
similarly to what we did with the CPU
we're going to monitor the rate of
allocations performance counter and when
it exceeds
threshold again similarly to what we did
with a CPU we can use more data from
other sources to get more information so
for example we can use etw to get
information about GC and about
allocations we can actually get
information about all the allocations
that happen in our application what type
is allocated what's the size of their
locations we can also get information
from etw about GCS about how long GC
takes about how many GCS we have about
what kind they are what generation how
much memory was reclaimed how much
memory was promoted and we can even
attach and we're going to see CLR MD in
action with this demo we can attach CLR
MD to analyze the heap and see even more
information about what's going on inside
our application how many instances we
have of each type what's the type of the
memory what segments we have and so on
so let's see that in action this time
we're going to look at sorry not the
leak the lock monitor so a lock monitor
is again it's inheriting the event
stacks monitor because we're also going
to be interested in stacks but this time
it's not going to be CPU stacks it's
going to be the stacks of where
allocations are made because the egw
provider that we're going to turn on is
the one providing us with information
about allocations and as I said etw is
able to provide a call stack for each of
its events so this time the events are
of allocations and so the call stacks
are going to be of the allocations and
we will also have information about the
type and the size as we will see in a
moment so let's just quickly have a look
like in the CPU monitoring we're going
to monitor the basic data using
performance counters use
we are located by its per second
performance counter and once we pass
this threshold we are going to invoke
the intensive mode data collection and
as I said in this case what we're going
to be interested in is the event of
allocation and let's see what happens
here each time we get an allocation
event the type of the data is GC
allocation ticket race data whatever but
it has some interesting properties for
example it has a property of the
allocation amount and it has a property
of the type that is allocated the name
of the type and so what we're going to
do is that we're going to keep this
dictionary here Alex per type which will
tell us how many allocations we did
throughout the time of the intensive
sampling from each of the types in our
application so like in the end you would
know we had 10k of strings 1k of ends
and I don't know a hundred mega of byte
arrays or something like that so that's
the data that we are going to collect
throughout our intensive mower and when
we're done what we're going to do is
that we can just take all of these
allocations order them by the size and
print them to our log specifying the
most allocated types during the
intensive mode another thing that we can
do is to print the heap breakdown now
what's the difference the allocations
data were allocations that happened in
those five seconds of intensive mode but
the heap breakdown can also provide
information about what's going on in the
heap like this moment
because maybe there were things that
were allocated before we started at the
intensive mode so it's also interesting
to see what's in the heap right now that
didn't start like five seconds ago but
from the beginning of when our
application began running so again I'm
not going to go deep inside the code but
the idea is as we attach data target is
a steal our MD type we attach it to our
process and and then we have you know
all sorts of useful properties like for
example the total heap size or the size
of jens zero or the size of Gen 2 and we
can just enumerate all of the objects in
the heap and I'm not going to go inside
this very long link doesn't really
matter its technical but the point is
that we can traverse the heap get types
by name get their sizes get all the
objects sum them up so we know like the
total amount of strings that we now have
the total amount of byte arrays and we
can order them and we can print them to
our log so let's see that here we have
our perfmon and I will try to make it
make a lot of allocations so I'll just
go to the about page oh that's sad out
of memory yeah let's start it again
don't have a lot of time okay bout bout
about let's see okay good so the green
graph is the number of allocations in it
spiked we have a lot of allocations
right this moment and and now it calms
down but like while I was going to the
about page it caused a lot of
allocations so let's look at the log and
so again everything is okay everything
is okay and then we start getting
violations
so here we actually got two violations
and then the allocations went back down
so the counter restarted but then just
right after that we got we got three
consecutive violations and so we invoked
our intensive collection mode and here
is the first call stack that caused the
largest amount of allocations and we can
see straight away that it comes from
string concatenation which comes from
our own home controller about and we can
look at the code and we can see that we
do some sort of xml processing here and
so it's probably not the most efficient
code and we have a lot of string
concatenation z' and we know that that
causes a lot of intermediate objects and
so we have this allocation spike let's
look what else our log was able to tell
us so first of all straight ahead here's
the problem very cool
let's also look at the statistics okay
here we have the statistics so we know
how many allocations we had during the
intensive mode so of course most
allocations were from string but we also
had some others it might be interesting
to know and here is the total heap
breakdown and of course most of the
objects are strings problem solved
our next demo is also going to be about
memory but from the much-feared scenario
of a memory leak so again it's going to
be very similar we're going to be
monitoring the total size of the memory
this time because we want to know that
there's a week now in this case though
there's not much point and looking at
call stacks because we just like
basically need to know what's going on
inside the heap and we want to diagnose
a memory leak and a memory leak is
by a difference that like going on over
time in our application so what we can
do is that we can take several snapshots
of our application and compare using CLR
MD which you already saw that it has
access to the heap and all the
information all the object information
and compare the snapshots and find the
objects that weren't released from
between the snapshots so let's look at
that excuse me leak monitor so again
this we don't need coal stacks here so
it's just a monitor and it's monitors
the bytes in all heaps performance
counter and what it does in the
intensive mode is that it simply takes a
heap snapshot several times from our
application in the slope here using
using CLR MD now note that before taking
a heap snapshot we call GC collect and
that's because if we want to compare
which objects weren't released we need
to make sure it's kind of like a clean
heap snapshot because we don't want to
take into account objects that are about
to be released anyway so we take a
snapshot wait a little take another
snapshot wait a little and after we're
done with that we just compare all of
the snapshots to each other so again
I'll just show you really quickly
there's a big link query here basically
what it does is again it creates like
dictionaries by type of the number of
objects and the that's the number of
objects and the total size that these
objects take in the memory and once we
have these two dictionaries for each of
the snapshots its
really easy to just like go over them
and this may calculate the difference
between them I won't go over that
because first its technical and second
we don't have much time
and also I'm afraid that because of the
time I won't show you the demo live but
like believe me that there's a certain
page that I can go to and it's going to
you know what I have to show it to you
so okay we have our perfmon here maybe
we should start again to make it clean
okay here we have our perfmon it's nice
and clean and I will try to register
and let's see what happens here so the
bytes in all heaps is the red graph and
you can see that it's growing see every
few seconds it grows so we have a memory
leak let's look at the code at the log
file leak okay
so again like before at first everything
was okay memory was pretty pretty flat
and then suddenly it passed the
threshold that we defined so it invoked
the intensive sampling mode and it
calculated all those dictionaries and it
took three snapshots and differentiated
between them and what we got here is the
well they're sorted by by size so the
most memory consuming type that we have
are byte array is byte array and so in
the beginning there were 26 of them and
this was the amount of memory that they
consumed and then in the second snapshot
we already had a hundred and sixty six
of them and this was the amount of
memory that they consumed so it grew now
here of course the log is not able to
tell me well this is the leak right like
I need to know my own code and indeed if
I go to the code to the account
controller which is what caused the leak
and I searched for a byte array this is
not the one then I can see that we have
this byte array which is for some reason
created every 200 milliseconds and added
to this static list so of course it's
not a real-life example but this is
indeed a leak and we were able to see in
the log that what we leaked or byte
arrays and once we have that data we can
now go back to the code and try to find
the actual source of the problem
the last demo that we're going to see
today is the case of a deadlock
now deadlocks are a tiny bit more
complicated to diagnose or maybe not
more complicated but like memory
monitoring is a little more
straightforward because there is no
single numerical value which tells us
that there is a deadlock right so we
need to kind of think about it
what in our application could represent
a possible potential deadlock which knew
easy to calculate numeric value
represents such a case so here I have a
few ideas you might have more for
example if your application is only
using very low CPU you might be bad
locked if your requests start timeing
out then maybe like the tread the
handling tread is is blocked or maybe
your tread pool suddenly creates more
and more treads than maybe that's
because other treads are blocked and so
it has to create more of them in order
to handle whatever it is that it's
handling so these are all examples again
you might think of more but I think
what's more interesting here is that you
can actually diagnose the deadlock once
you suspect there's a deadlock you can
check it you can check it using CLR MD
so far we saw how we traverse the heap
but you can also get stack information
and blocking objects information about
each tread and so by simply traversing
all of the treads and doing a simple
search you can find out if you have a
deadlock now in the case of a deadlock
I'm not sure there's you know something
you can do pray for a miracle
I don't know but at the very least you
can totally log-log it and you know and
report it to development so let's see
good
I have the deadlock monitor so I didn't
implement the performance counter
monitoring because we saw a lot of it
and it's less interesting in this case
so I'll just show you the deadlock
detection itself so basically what we do
is that we attach using CLR MD to our
process to our process and we go over
all of the trends and by the way along
the demos that you see you can see how
simple the CLR MD API is and I think
it's really nice you should do more
stuff with it and basically for each of
its treads you kind of use a simple
recursive search which goes over all of
the blocking objects of that tread and
you keep a list of all of the treads
that this tread is waiting for that's
the visited tread
IDs and basically if you hit a loop if
your list already contains that tread it
means you're in a loop and you have a
deadlock and in that case you can just
write it to the log and with all of the
information I know I'm kind of jumping
from place to place but like it's really
if you take five minutes and look it's a
simple recursion just to search for a
loop in a in a graph okay and for each
of the treads we keep the call stack so
that when we finally report that there's
a deadlock you can see the tread IDs
which are deadlocked and the call stack
the functions that they are inside that
caused the deadlock so let's cause that
lock will go to contact and although the
site wasn't fast to begin with I think
you do get the idea that this specific
link is taking even more time than the
rest of them and that's because there is
a deadlock and it's stuck so let's look
at the
log that I have here and okay so first
time we try to find that locks
there was no deadlock everything was
fine second time it already found a
deadlock this deadlock was in a thread
number so-and-so and it was deadlocked
in the process details function along
with this other tread which was also in
process details for some reason so let's
look at the code and what we see here is
that we have LOC first and locks second
and what happens in between is that we
call the same function only we reverse
the second with the first so that's a
classic deadlock trying to take two
locks in reverse order cool so again
report the development and problem is
hopefully solved so that was our last
demo for today of course there are many
other scenarios possible just a few more
ideas for you to think about for example
you could monitor heat fragmentation and
that's important because you can use
that knowledge in order to invoke large
object heap compaction the CLR is
actually not going to compact the LOH
for you unless you explicitly ask for it
but it's large and it takes time so if
you monitor heap fragmentation you can
make an educated decision whether you
want to spend that time or not second
all the demos that we saw were for
managed applications but a lot of the
stuff are also applicable for native etw
collects information about native CLR MD
can connect to native applications as
well it wouldn't have as nice API is for
traversing the heaps of course because
it relies on dotnet metadata but but
it's still it's possible to do some
things and there are two side notes that
I want to mention here about other
things that you can automate and the
first is dump analysis we're talking
about CLR MD
me in this only in the sense of
attaching to live processes but it can
actually be used to analyze dump files
so if you have crashes in your
application you can totally analyze them
like at least triage them automatically
using CRM D which is pretty cool and
second if you have a lot of problems I
would definitely suggest to aggregate
and with solid items somehow you don't
want your developers to go over this you
know similar logs over and over again so
it's a good idea to to aggregate those
and just before we finish it's obvious
from everything that we saw what the
upside of these monitoring scheme is you
get a visibility into your production
you don't have to reproduce problems you
don't have to reproduce problems you
have to you can now grow your product
scale your product without having to
grow the team these are big advantages
but they do come with a price and I'm
you need to be aware of it so the first
problem is I think that's pretty
understandable is but it adds complexity
you add code to your system and the more
code you have the more problems you
might have
but this risk can actually be reduced
because in all of the cases that we saw
today we implemented the monitoring
inside the application but most of the
things that we did we could also do them
from an outside watchdog process because
performance counters and etw are
collected in the machine level anyway
and seal RMD I mean you saw that we just
passed the process name it doesn't have
to connect to my own process so we can
totally do most of the things from an
outside process and in fact in
containerized environments it's already
pretty common to create a separate
container which does monitoring on each
of which notes so for example you can
look up sis dig which is a such
monitoring agent that you can use on
your containers the second thing is of
course that it adds overhead and we try
to overcome that by using this
hierarchical scheme but it adds overhead
I can't
to you and in fact you already saw in
the logs today that some of the stacks
were from our own monitoring code and if
in fact it happened to me with like a
real clients a couple of weeks ago
client was complaining him about high
CPU usage and we attach the profiler and
we saw that our code was writing down
stacks and that's what was causing the
high CPU so extremely high CPU so it was
already in high CPU so it wanted to
write down some data and it only made it
worse it was a laptop with a single core
which we don't see much these days
so you know I don't feel too bad about
it but it happens and of course it adds
development time but it's up to you or
your managers to decide whether it's
worth it or not
so that's it I'm sorry I'm a little late
a little recap of what you did today I
hope I convinced you that Martone
monitoring is important no matter what
kind of software or what kind of the
deployment scheme you use we saw how to
approach the problem using a
hierarchical structure and we saw some
samples of what can be diagnosed on
production all of demos are available
here thank you
and I'm sorry for keeping you a little
late again
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>