<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Video Transcoding at Scale for ABC iview - Daphne Chong | Coder Coacher - Coaching Coders</title><meta content="Video Transcoding at Scale for ABC iview - Daphne Chong - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Video Transcoding at Scale for ABC iview - Daphne Chong</b></h2><h5 class="post__date">2016-09-19</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/AaD0BQL7j30" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I'll get started ABC iview streams
thousands of catch-up TV programs to
millions of Australians every year
oh this is going well
that is better okay the ABC which is a
public broadcaster it's over 80 years
old but I view is a relative newcomer we
first launched in 2008 and it's now one
of the most popular streaming platforms
in the country I can only say that
because I really don't know how many of
you use netflix today is going to
introduce you to Metro which is the
ABC's new video transcoding service
which is the service behind the scenes
of eye view and it's the one that's
processing all the content to make
available and that's you know everything
from playschool to Doctor Who Metro was
built by a small team mid last year and
it was launched in december and it's
been transcoding all the content sense
so things that we're going to
specifically cover about metro one what
do we mean when we talk about a video
transcoding we're going to go through
the process and show you why video
transcoding is really important for I've
you there are a lot of options available
to actually transfer video why did the
ABC decide that we were actually going
to build our own system we're going to
cover those reasons and how it's
actually turned out to be really
advantageous for us what does the system
actually look like I'm going to be
walking through a metros architecture
which is a workflow system and I'm going
to be showing you the steps that a media
file goes as it flows through our system
for is a what technology choices do we
actually make and we were deciding to
build our system i'm going to show you
the language choices that we've made and
also the specific sort of AWS services
that we've decided to plug together to
form the system this is my favorite part
which is auto scaling how do we scale
and how do we actually cater for all the
different demand of content throughout
the day how much does it cost to run
we're going to go through what a typical
day of transcoding costs for metro and
also how much is going to cost for a
whole year of I view content
and the numbers were really surprising
to us so I hope you find them
interesting as well lastly is what are
we actually planning for the future of
Metro we're going to take a look at
other features that we can implement in
future so first off are what is
transcoding it's a process right we take
an initial input video or audio file and
we convert it to a variety of output
formats which we call renditions
renditions are a really important
concept in metros architecture and
system so I'm going to be referring to
them a lot throughout this talk what
kind of actually you know what changes
are we actually making to these videos
we create a lot of different renditions
here and there's a lot of different
changes that we make which is things
like the resolution so the size of the
video the bit rate which is the amount
of data that you download per second in
order to actually play the video we've
got the video encoding so you know the
file format of the actual video that
you're playing back we can add logos to
the video and we can also do things like
change the audio levels which is a
really necessary part of transcoding fri
view so our goal is to really produce a
standard set of renditions stuff that's
all consistent for each video for eye
view we've got six different rendition
types and we've got 55 video versions
and one audio only version it's not
Netflix scale but we really don't have
Netflix's budget this is what we do for
the ABC now that video on the left is
what we receive in metro and through the
transcoding process we turn it into
their renditions that are on the right
why do you have so many sizes we
optimize that video size for the device
size so you know large formats are
really good for things like desktop
machines or your TV's and smaller
versions are much better for things like
mobile devices you're going to get a
different rendition depending on your
network speed
and you know it's also capable you know
what your device is actually capable of
playing so the higher bitrate versions
the larger renditions are obviously
going to require a lot more data to
download and it's not going to be ideal
for mobile devices you won't even be
able to tell the difference when it's
playing back on your mobile device as
well so we change these rendition sizes
depending on the speed and it's your
video player that's actually responsible
for selecting which rendition to play so
it's the one that detects your network
speed and changes changes it accordingly
and it will do that amid play as well so
it'll adjust according to what you're
currently using is I've use current
highest quality version is 1500 k or
kilobits per second our lowest quality
is 220 k you'll notice that's not HD but
hopefully that's coming in future for AV
distribution we convert everything to
h.264 mp4 and it's really important that
Metro standardizes all that video to the
same encoding so that the player doesn't
really have to worry about different
codecs and trying to deal with you know
different codecs so as an example of a
couple of different sources that we
receive we get a file format from
broadcast format called gxf that's a gxf
container it contains an mpeg-2 video
and for raw audio streams we also
receive files in apple's mauve format
and those two are all normalized down to
this standard h.264 and before so let's
walk through an example to actually you
know show you what we're doing so first
we prepare watermark that we're going to
end up putting on the bottom of the
video this is the ABC one logo here we
make it about thirty percent transparent
so that we don't burn on your TV and we
also don't be so distracting in the
corner and then we resize that down we
resize it to a file size that is
actually relative to each rendition and
that's because when we switch between
different renditions we don't want the
logo
oh to be moving around or to change in
intensity so if we take this input video
file now which is the episode of utopia
we see an ABC series and it's in gxf
format this black bar that we've got at
the top of the file is a thing that's
used in broadcast it's got time code
information in it and it's also got a
bunch of captions information in it I
view doesn't use any of these so we
actually want to crop it off so that's
the first thing we do here and next
you'll notice that there are in 43
format there they're a bit stretched and
we really want to actually play that
back in sixteen by nine so we adjust
that format and set it in the header of
the file as well and the reason it's
actually stored in 43 is historic it's
called anamorphic widescreen you can
actually store more information in that
format and then stretch it out to
widescreen than just by story and
widescreen itself it's also really good
for a lot of our historical TV equipment
that's been produced for 43 so we've
adjusted now the ratio everybody looks
great we're going to now add that
watermark that we prepared earlier and
we position it very precisely as I said
according to each rendition size to make
sure that when we flip we don't notice
it moving around we're now ready to
stream at 1500 k which is our highest
quality version these are the other
rendition sizes that we also produce
there's a 1006 5500 220 and that audio
only version so that's the audio in
terms of video we have to do a bit of
preparation to actually make that
available as well
so this is the audio for the same video
at utopia it's a half-hour show and you
can see that there's a block at the
start and the end which is the more
intense than the others sorry this is
this is audio intensity so the height of
the bar you know indicates how loud it
is at all of the bar the louder the
volume and start in the end you know the
credits are usually covered with music
so they're they're louder than the rest
of the episode this is what the previous
transcoder for I've you used to produce
it's much more intense than what's in
the gxf file if I flip back and forth
you can you can really see that and what
we want to do is actually make sure that
Metro produces the same level of audio
intensity then as this our previous
transcoder and that's because we've
actually got a few different reasons why
first is that we do have some old
content that's still in the system
that's been transcoded by the previous
transcoder and we want you viewers to
not notice a difference when you play an
old version of a show and something
that's been transcoded newly in metro
number two is that between different
shows they might be recorded with
different audio audio levels so we want
to actually normalize everything so that
if you watch one show here and then
another show here you're not having to
adjust your volume so that you know you
watch different shows and that's also
important between the renditions of the
same show right if the player ends up
flipping between a different rendition
you don't want to notice that the audio
levels are jumping around so audio
normalization is really critical for us
this is metros new output of the same
thing so it's much more intense than the
original version and it's pretty close
to the previous transcoder so if we
didn't process that audio at all you
would really notice the difference if
you were playing different things as it
was coming back through the player
so that's a lot of changes that we've
made to these videos right we've
adjusted the audio we've adjusted the
acota encoding we've done some cropping
and and bitrate changing how do we keep
track of where all these changes should
go ideally we want all the changes to be
listed in the same place so that you
know I get a gxf file I know okay I've
got to do all this stuff to it so that I
can get this standard output so we
encapsulate all that somewhere and
something called a profile and that's a
set of instructions that we can look up
and we can apply universally to
everything that is of this type of
content and the way that we work out how
to match a profile is through location
folders source source folders metros got
our source location and that's where all
the content gets dropped and inside that
location we've got different folders
this is a pretty MVP sort of solution
but for our MVP here we map each folder
to a specific profile so all gxf content
here like utopia that has all the
similar properties to utopia gets
dropped in there and has that same level
of instructions applied to it to get all
the output out so here we perform all
those changes we get utopia otherwise if
we have a different set of content this
here is for the Apple ProRes content we
only have to do we have to do less
changes to it basically it's already pre
watermark it's already in the right
format in terms of our sorry it's
already in the right we don't have to
crop and we end up with this content
here which is from the ABC arts channel
so the next question then is with all
those changes that we've actually just
listed right how are they actually
applied how does this magic work and our
answer is ffmpeg it's an open source
media transcoding tool that's been
around for 15 years it is incredibly
powerful this is a really simple example
of what you can do you can take an input
file in gxf
and convert it to an output file and
metro or play ffmpeg will do a huge
amount of assumptions on this right at
all it'll assume what you want in terms
of like encoding quality levels that
kind of thing but really this is what it
looks like in our system this is a real
ffmpeg command that we use and this
command is linked to the profile we've
got six commands here and to produce
each of the six roundish ins and and
every profile has its own list of ffmpeg
commands to produce the renditions that
we want so that control controls things
like you know encoding cropping
deinterlacing scaling aspect ratios some
stuff to do with the watermark video
quality audio and just some other
settings for a good measure so I'm not
going to go into detail because ffmpeg
is incredibly powerful and huge there is
a lot of information available through
its official documentation and the
community is also am really quite
helpful to with any kind of inquiries
that you've got so just emphasizing here
that basically is it's such an
incredible piece of open-source software
that we really could not have built
Metro without so that's an overview of
transcoding that we do with metro and we
take input videos and we do a bunch of
changes and we end up with a standard
set of renditions at the end so let's
talk now about why we decided to build a
system ourselves we've got three main
reasons here and the first is costs we
had a really good opportunity with I
view there are a lot of commercial
transcoding options that are geared to
producing content really quickly right
now you have a piece of content you
submit that file it spins up 10 million
things for you transcoded it quickly and
then sends it back to you so that's what
the previous transcoder for I've you did
but the thing is either gets a lot of
its content in advance we've already
recorded these dry
shows you know we're going to get them
weeks or days or sometime in advance so
we really don't need to pay for that
content to be transcoded immediately we
could choose to batch it or Q it and and
process it in a bunch and do it later at
night or you know on some cheap kind of
computing hardware in the cloud so where
the ABC we love saving money sounds like
a good idea for us I can't go into the
cost of what the previous transcoder
costs but I can give you an analogy we
were previously paying for the
transcoding Porsche of the world right
it had a lot of features and it was very
fast but we really needed something like
a mini we needed something to just be
reliable and get our content from A to B
we just need to know that our content is
going to be there and available before
it goes live so a reason to build this
system was to actually help reduce costs
by sacrificing a little bit of speed and
paying for building something that was
going to service needs that we wanted
features that we wanted we also have a
larger range of content we've got a
large scale of content I view is just
one of our products we also have videos
on our news sites and we have a
commercial arm of the ABC which produces
content for third parties things like
iTunes you can go and buy ABC series off
there if we could handle I view content
efficiently then why wouldn't we use
this on all the other areas of the ABC
as well and that suddenly becomes like a
much more attractive proposition so we
could also build this in the cloud
everybody loves the cloud it scales as
far as you want it to and there are no
restrictions you know requiring a
certain physical number of transcoders
to actually transcode your content or
there's no amount of hours of transcode
that you need to buy in advance to be
able to process all of your content we
can actually just pay for as much as we
use and that applies both if our content
grows for example if we add new types of
renditions higher-quality renditions or
you know if we're having a quiet month
and it turns out that we're not actually
producing as much content as our
contract is required so the last reason
is also flexibility as I mentioned the
ABC is 80 years old our content has a
lot of quirks we have a lot of custom
broadcast settings and formats if we
have our own system we can customize a
lot of features to suit our own systems
and formats and i'm going to give you an
example of a quirky thing that we have
so this black bar at the top that has
broadcast information in it it requires
a symmetrical cropping and there's not a
lot of commercial transcoders around
that will actually provide that system
that that feature we would have to pay
extra to be able to do this the black
bar also contains captions in a format
called Opie 47 and Opie 47 is a an
obscure caption format it turns out and
again there aren't that many commercial
transcoders who provide that so we would
be paying extra for this support instead
if we build our own system we can
actually cater to these specific
requirements using software like ffmpeg
or plugins to ffmpeg and we can deal
with our content specifically so by
building our own system we can save
money by sacrificing a bit of speed we
can benefit from the scale of our
content and we can also be flexible with
the abcs specific requirements in future
so having desired decided to build our
own system let's take a look at how it's
actually designed metros our workflow we
all the content that goes in will follow
these steps so each file gets
transferred into AWS
we then log and cue that file and make
it ready for processing we transcode it
by running ffmpeg on it we then move
that those resulting renditions out to
the CDN and then excuse me and then we
notify I've you and say that that
content is now ready for publishing so
here's what that workflow looks like
from an architecture point of view all
of our incoming media gets uploaded to
an s3 bucket when that media is finished
uploading we use s3's inbuilt
notifications to put a notification on
to an amazon SQ SQ so it tells us that a
new file is available for processing we
have written several small Q listeners
here and one of which monitors this
queue and it's only got one task which
is to send an HTTP notification to
another component in our system and say
hey something happened so as soon as our
message is put on the queue this Q
listener picks it up and it tells
another component in our system which is
at an api called the orchestrator that
this new contents available the
orchestrator is the brains of our system
it's the only component that is state
aware and it has a data store in it it's
responsible we're truck for tracking
where every single piece of content is
in the system it also controls the
number of transcoders that we've got in
flight so while it's saving this job in
the database it also looks up that
master list of our profiles that we've
got it matches the new video that's been
dropped to a profile and then that
profile tells us a few really important
things the first is how many renditions
were actually creating here second is
that ffmpeg command that we use / KHOU
rendition third the location of the
source file and forth is where to save
all those output files we've got extra
metadata that we send along with that
but those are really the four things
that we need to know in order to be able
to actually transcode something so now
we have enough information to act
save our transcode begin our transco so
the orchestrator and Q's a new message
her rendition on to F transcoding Q so
if there's six renditions to produce we
put six messages on to this Q it also
calculates whether we actually need to
spin up more transcoding instances to
process this content or if the in fact
there's any transcoders running if
there's not then we start one up all
those transcoding instances that are
startup that I started up we'll look at
this Q they'll take a message off one at
a time and actually do the transcoding
with that content so one rendition goes
to one machine so this is where all the
really intensive work with ffmpeg is
done in our system and it takes the most
time you know like up to ninety percent
ninety-five percent of the times is
completely done with ffmpeg the lengths
to transcode is going to depend on how
long the original content length is and
also the quality of it high quality
rendition is going to take much longer
to transcode then a lower quality
rendition once that transcribes done
it's sent to an s3 location that we
specify so that output location for the
ffmpeg the resulting rendition from the
ffmpeg command so the orchestrator will
then update that job say that the
transcoding is done and it will send a
message on to our CDN transfer queue
that process then we'll take those
finished renditions and send them up to
our CDN securely and that means that
they will now be ready to publish on I
view so the orchestrator then logs the
fact that they're done and uploaded to
the CDN and then also chooses to examine
the rest of the system and if there's no
content left there it can choose to spin
down any other transcoders that it's got
running because when we've no longer
processing any content once that's done
we notify I've you and say okay all
these videos are now
ready to publish on overview on average
it takes just shy of eight and a half
minutes to process all the content
through the pipeline so that figure
encompasses everything from file upload
to s3 to notifying I view we've got a
variety of different content though so
things like five minute children's
videos and documentaries that can be
like an hour or two hours long so the
time spent in the system is really going
to be dependent on how long the original
source content is and how high quality
that rendition is so here's a bit of
information on some averages the lowest
quality rendition that we produce here
is the audio track and it tends to take
around twelve percent of the time as the
original content links highest is 1500 k
and it will take around seventy percent
of real time so for a one-hour piece of
content the audio will take around seven
minutes and the highest quality video
will take around 42 so that's a summary
of our workflow architecture built in
AWS now we're going to dive a little
deeper into the system and look at the
language and infrastructure choices that
we've made while building it our code
components are written in two different
languages node and go this is where the
code sets in our system and here's the
orchestrator again that that's the
brains of our system it's the only
component that we decided to write in
node why did we choose one is that we
had existing team experience before the
ABC we'd actually had a team back in
team that was experienced in Norwich and
we'd written several api's before there
are also a quite a good collection of
good quality modules available to help
you write things quickly in node so
Express for example which is a great
framework and there's a lot of
middleware that's been supplied for it
as well the orchestrator isn't that
complicated the most responsibility it's
got is to actually look at the number of
transcoders that are running and decide
whether or not we need to increase
that and that does that every time a new
piece of contents dropped into the
system the sad part is that JavaScript
isn't typed and so that makes it you
know kind of crappy to refactor it also
means that there's a lot of boilerplate
testing code it's also you know not
great for the other kind of components
we've got in our system which are much
more long-lived polling apps that just
watch a queue so we decided to look at
another language for those components
and these are Q lessness here and
they're written in go so there are small
independent long-lived programs they
each monitor a queue and they do one
thing every time they receive a message
from that Q so there's three different
types here one is the step to register a
new file that's dropped in s3 number two
is to actually transcribe the content
using ffmpeg and the third one is to
send the content to the CDN now go was
an experiment and this is the first time
we'd really used it at the ABC so that
typing was really nice for us compared
to JavaScript yay it's also compared to
compiled to a binary and you can
actually select the platform that you're
targeting at Build time so you don't
need a runtime like net or JVM you can
just take this binary and drop it
somewhere so that makes it really really
easy to deploy as long as you've got a
consistent kind of architecture you're
good the downside is go has quite a
hefty learning curve the way it does
sort of interfaces object declarations
and how to actually design your code
well can be a little daunting and
challenging at first I personally found
it quite hard to find how to design
patterns of success in go so we ended up
at doing things quite a few different
ways in our system here but
yeah we ended up doing quite a few
different things and ultimately we've
taken some learnings away from metro to
other projects within the ABC we also
use quite a lot of AWS technology and
we're going to walk through some of that
now so I'm going to focus on things that
we use slightly differently or that have
sort of a more unusual challenge with
them so easy to is amazon's hosted
service for machines on demand aside
from our transcoding instances we don't
do anything to unusual with that we're
using it fairly ordinarily we've got
auto scaling groups for redundancy and
it also helps us to scale horizontally
so anything we deploy code on here is in
an auto scaling group the really nice
part we like obviously is any unhealthy
instances get replaced and we don't
really have to worry about it however
our transcoders here have unpredictable
demand and we frequently change the
number of instances running for cost
efficiency so I'm going to expand a bit
more of that in the next section looking
at amazon's q service SQ s we have a few
q's in our system and we really like
them for data resiliency if you're not
familiar with Amazon's queues they
operate on a first-in-first-out system
basis so a single message can only be
processed by one consumer at a time each
message also has a visibility timeout
and that's a kind of a flag saying hey
I've got this message whenever you pull
one from from the queue I've got this
message for the next X time period and
if you pick it up but then you happen to
die that message reservation ticket will
eventually expire and the message would
turn back to the queue after that's done
that timeouts configurable we originally
had it set for a really long time which
is a 2 hours and that was because we
needed the machine the tickets to
actually last as long as our longest
transcoding instance would go so we
needed to be able too hot to handle high
quality transcode
for a long piece of content this is
obviously not ideal because if something
dies one minute after its picked it up
then you've got to wait two hours for
that message to expire to return to the
queue we later change this because we
experienced it a little too often to be
an adjusted timeout extended
periodically so every five minutes we
now say yeah I'm still working on it
please update and extend the visibility
time for five minutes so that now means
we have no upper limit on the length of
content that we can process it also
means that we can reach you unsuccessful
jobs much faster so that that was a
win-win for us in terms of file storage
we use s3 nothing too surprising here we
purge all this content after seven days
and we keep a rolling window open if we
ever need to re transcode something we
just make the content providers
reuploaded again in terms of our
database we originally started with
DynamoDB but we let it move to mysql
dynamo was probably the biggest mistake
of our build and will first look at what
it does and then i'll explain why it
turned out it wasn't suitable for us
dynamos is no SQL and it's a key value
storage sort of mechanism it's ideal
just for user key and value pair storage
user ID session data you can only
retrieve objects by this key and this
key has to be unique so if there's
something in the session data that you
really wanted to retrieve things by like
for example I don't know a user has a
preferred language and you want to pull
out all records where they have a
preferred language of French you can't
do that don't doesn't let you do that
you can only retrieve an object by ID
that's it so that's obviously not ideal
if you're trying to aggregate things
which we like to do and it's not like
something like elastic search for
example which is no SQL but you still
can query things by old stuff in in the
in the content here
you also pay for the number of records
you retrieve per second right so if you
retrieve a single record per second
dynamo is cheap if you retrieve
thousands of records per second it's not
so good for you anymore as I said this
didn't really work for us because we
rely on aggregations things like what
jobs are being transcoded right now
right what the current queue wait time
we will we want to know because you know
we want to take an action if it's slow
trying to aggravate data in a no SQL six
system where you can only query by IDs
really sucks we can either have to
retrieve all the records and then
manually aggregate them which sucks or
we have to storm that same information
in multiple places multiple sources of
truth right for every single piece of
aggregate data that we want and that
sucks too so we opted to go with
retrieving all the records which as you
can imagine is not not not cheap and it
doesn't really scale well this is a
hundred percent our fault we did not do
our homework when we were looking at
dynamo I think it's a fine thing with
you if you know all the data you want is
a key value information things like user
ID with session data that's actually
fine but our system doesn't really suit
that and we made that mistake so bad
luck for us however if you decide to go
with dynamo there is something that you
should know it doesn't scale
automatically things like easy to you
can say hey if if my machines hit a
certain threshold of CPU I would really
like you to take an action at that point
like spin up another instance for me
dynamo however doesn't do that you can
say I would like you to allow me to do a
thousand records / a second as a query
if you breach it dynamo will send you a
message saying hey you've reached it but
it won't do anything for you so you have
to actually take control of monitoring
that situation and you have to decide
what action you want to take with that
so it's a much more hands-on system than
AC 2 or in it a lot of the other amazon
services it's not an automatic scaling
having gone to know SQL we retreated to
the relative safety of a relational
database hosted on Amazon and we made
that switch in February we still get
managed hosting because amazon offers
that we get automatic failover between
availability zones it's all great we
also get aggregations because we get
sequel the unfortunate thing for us is
that because we just ported our data
street as is beer from dynamo to mysql
our design probably would have been
different our design would have been
different from the start if we'd done
this on to cloud formation we deploy
ninety-five percent of the system using
cloud formation templates cloud
formation is Amazon's a templated system
for creating AWS components so basically
it's like infrastructure configuration
is code everything on our architecture
diagram obviously excluding the CDN is
templated using cloud formation we can
we also deploy it through a build server
so everything in here can be deployed
with just a few button clicks the
templates are defined in Jason like this
one as an example having everything in
that template lets you build things
really repeatedly which is very
convenient for us and it you know also
their version of all you can check them
in it's good our real templates are many
many sizes larger than that example but
we also reference one of them want
reference them by one another and so
ultimately you end up with a few really
high top level templates that can deploy
entire sections of the system just by
themselves so we define things like all
of our ec2 instance settings our auto
scaling settings regions ports tags
security settings V pcs that's all done
in cloud formation most things that you
can configure through the AWS console
we've made available in our cloud
formation temple
there are some things that aren't
available through there so we do have to
do a few steps manually and that's
unfortunate not everything is available
in cloud formation that way and you you
also have to kind of take a balance
there they can be hard to maintain we've
kind of opted to go through a templating
as much as possible which means that we
can repeatedly and easily keep deploying
and know that it's a reliable thing but
there is an option to you know do some
more manual configuration and have more
more kind of less pain with the cloud
formation tablets so that's a look at
the different languages and
infrastructure choices for a metro we
use a node and go for their relative
strengths and we use quite a lot of
different AWS technology that we work
through now we'll start to look at one
of the really interesting pieces which
is how to transcode all the content in a
really sort of timely manner as
mentioned earlier we changed the number
of transcoding instances that we've got
running very frequently so this is
really useful for us because if we've
got a lot of content we can spin up a
lot of transcoders but we can also get a
zero to save costs but how and you know
when should you decide to spin up or
tear down an instance there's there's a
lot of different factors here at play
AWS has got hourly billing so as soon as
you've started an instance for two
minutes you have paid for an hour and
you might as well get your whole money's
worth there's also a balance between
cost and speed if you have a large
instance size then that transcript is
much faster but it costs more so if you
span up an instance and it's only you
know you're only using five minutes
you're actually better off kind of
paying for a cheaper instance that's
going to take much longer a percentage
wise of an hour to transcode so that
balance is going to be affected by the
type of content you've got and the
quality that you're producing how
quickly does the content need to
actually be available we get a lot of
content in advance but there are some
things that we transco to make available
like live shows so the news for instance
you know we can't get that in advance
we only get it once it's finished
broadcasting so those things ideally we
want to process quickly once they've
been added to our pipeline sometimes we
also get things like a takedown request
for sure so somebody wants to update a
version of a four corners or something
because we we get a request to remove
that so because we have 1q if a
high-priority piece of content gets sent
down all the content that's been in the
queue before that actually needs to be
processed quickly before we get to this
high priority piece of content we also
really don't know when people are going
to put things in the pipeline people
will match things up to go at random
times of the day they also then just you
know add things in dribbles whenever we
want if we knew when it was all going to
go in on a regular basis we could you
know spin things up in advance so that
it's ready but we don't we also get a
variety of different content length from
you know five minute videos to those two
hour documentaries so you can process a
lot of five minute videos in one hour
but those documentaries might take one
hour by themselves to process AWS also
takes a little longer to react right it
normally takes five minutes for auto
scaling metrics to react when you
monitoring something you can you can
tell it to actually monitor a queue and
say once it gets past a certain size
it's been something up that's fine for
most of our content but if there is
something high-priority going through
our queue that's probably not as fast as
we would like we would like to react
faster and particularly easy to
instances themselves take an additional
few minutes to spin up so we really want
to react as soon as we know something's
gone in the pipeline that's high
priority there's also no automatic
shutdown instance at the one-hour mark
you've got to keep track of how long an
instance has been running and then
choose to take an action once the time
is close to to running out
at the time we put this as well you
really didn't have control over which
instances in an auto scaling group would
get shut down amazon would just pick the
oldest ones and turn them off for you
but that was really not ideal for us
because that that instance could
actually be processing content at a time
right we don't want that to happen
they've just released something cool
they have now released something called
instance protection which means you can
you know I will put a lock on this
instance and say please don't shut this
down it's busy doing work and then once
it's finished you can release release
that lock that was pretty much my face
when trying to decide how to solve this
problem right there are a lot of
variables here and they all kind of
counteract with each other which one of
these actually gets priority so instead
of tackling everything we decided to
just focus on our MVP we have one queue
and we have both regular and priority
content in there so don't make things
wait too long because we always want the
priority videos to flow through as soon
as possible so to do that we have to be
really proactive about supplying enough
capacity to handle everything in the
queue at any given time so that's how we
not we know that it's all going to be
processed within you know a particular
time frame a given time frame our best
way to calculate capacity is to actually
look at the profile when you drop the
content in the system so if you remember
this slide from earlier this drop folder
tells us the priority of content and
that's because we created specific
folders to say hey this is high priority
content please do something with this
but it also tells us the quality of
their renditions through the ffmpeg
commands and how many renditions are
being produced so we know those three
information pieces of information the
priority the quality and the number of
renditions from that information we know
situations when we'd want to proactively
spin up new instances to be able to
actually handle the content or to
process the content and keep the
pipeline moving so particularly for
priority and slow content that's when we
want to take some action
so that particular folder wasn't high
priority but it did produce two
high-quality renditions and they take a
long time to transcode so we want to add
extra transcoders to the auto scaling
group one pair rendition so that we
don't have stuff waiting behind those
two really long renditions on the other
hand if we have high priority content we
check to see how many renditions there
are normally for a lot of strange
business reasons our high priority
content actually produces only four
renditions and that's the four lower
quality renditions so we only need to
start up one transcoder and all those
four renditions can be processed by that
on transcoder they actually flow through
really quickly there if it's neither
high priority nor high quality we check
to see the ratio of the jobs in the
queue to the available transcoders if
the ratio is fine we don't take any
action we just leave it as is otherwise
if the ratio is too high we spin up
another transcoder if there's no
transcoders running we spin one up to
ensure that the pipeline is actually
moving so there's never they should
never be an instance where there's stuff
in the queue and nothing to process it
to adjust the number of transcoders is
one line of code right we calculate how
many transcoders we've got in service
and starting up so launching plus the
number of trance critters that we want
to add and that gives us a desired
capacity that we want for our auto
scaling group however before we issue
this command we check to see how many
transcoders we've got that are idle so
how many jobs are actually need to be
processed versus how many transcoders do
we have running and if we've got jobs in
flight sorry more transcoders running
than jobs in flight and those idle
transcoders are less than the number of
extra ones we want to spin up then we
don't take any action if we do need
extra capacity and we execute this
command AWS will process it within
seconds and a new transcode to start
spinning up pretty much immediately so
that is much faster for us than waiting
for those automatic five
scaling checks that AWS provides you on
auto scaling groups we build a machine
with custom configuration of ffmpeg on
it and that helps us a lot because
ffmpeg takes 15 minutes to compile we
don't want to pay that cost every single
time so we have an image and we use that
for all of our auto scaling instances
that they spin up as soon as possible
which instance size should we be using
in an auto scaling group you can kind of
specify as like one instance sighs you
can't really kind of mix it up so for us
for simplicity we decided to choose just
one transcoding is CPU heavy as well so
we want something with a lot of CPU
power we decided to target the AWS see
four series of instances which are quite
high on a price to compute power ratio
this is a graph of all the instances
inside the c-4 range and we our
benchmark machine was a macbook pro and
that's my colleague Nick McCarty's
machine you can kind of see that's about
equivalent to and ce4 to extra-large but
in terms of trying to decide which one
we want we want something with a
reasonable level of power for a cost we
really don't want to pay a huge amount
of cost and not get that much benefit in
terms of extra CPU power we decided to
go with a c4 extra large for hours it's
a slightly less than the next instant
size on that graph feel sorry each each
step there is actually twice as much as
a previous one so scaling up there is
easy right if you've got a lot of
content and you think that it's high
priority or you don't have enough
comfortable capacity you add more
instances to the group we step up in
those increments right however scaling
down requires knowing which instances
are busy so that you're not stopping a
trance code that's in process so how do
we know which crunch transcoders are
actually busy and our answer is we don't
for our MVP we need to wait until that
entire pipeline is clear so that we know
that none of them are busy and
turn them down instead this is an
example of the number of transcoders
that we've got running in action over a
four-hour window and you can see quite a
lot of scaling up and down activity here
you can particularly see the
inefficiency of kind of waiting to see
all of the content flows through before
we decide to turn them off so there's
always these cliffs right we can because
we can scale it steps but then we wait
till everything's gone before we turn
off you can also see the effect of us
tearing things down immediately and then
triggering new transcoders to spin up
when we got new content in so there's
times that we've spun everything down
and we only we started up like a minute
later ideally we would tear everything
down after when only when an hour was up
and get the most out of our instances
here that's probably something that
we're looking to do as an optimization
in future so here's another view of
those transcribing instances this is a
graph of instant lifetime over a
four-hour window and that's not just
current instances that'sthat's
everything that was in that previous
graph it's heavily skewed to short-lived
instances which is pretty inefficient
we're paying for a whole hour of compute
time but we're you know only using a
fraction of it these ones in blue are
actually what you would consider
efficient right they're running more
than over 30 minutes of an hour and
everything else is underutilized this
was probably a much worse average
picture than normal because there was a
lot of short content dropped in on this
this this particular day but you can see
we do have inefficiency so the auto
scaling part though is not complete that
it is a really interesting puzzle we've
taken a very minimal approach to
profiles at the moment and that roughly
indicates how long a proto piece of
content takes to transcode or how pro
high-priority it is and that tells us
when we can scale so we trigger scaling
whenever new content gets added to the
system and we shut all the instances
down once the pipeline is clear it's an
area of the system where other tweaks
can have a big impact on throughput or
on costs
so speaking as a cost now we're going to
have a look at how much it actually
costs to run Metro on this architecture
this is a sample day in our system we
get a lot of different variety of usage
patterns and we just I'm just going to
show you a couple of examples here this
is a view of renditions per hour ten
a.m. to ten am so day times actually
mostly on the left there we got a lot of
content here dropped in by a lot of our
content producers down towards the end
there's there's kind of some of the
content that you would get from news
broadcasts or live shows like QA this
was a Monday night how much did it cost
fifty seven dollars and 22 cents it
looks even better in u.s. dollars this
is what Amazon you know shows you in the
cost centers so this analysis here is
also in u.s. dollars so this is a
breakdown of all of our different
service costs ninety percent of our
costs is related to ec to its things
like auto scaling the actual instances
running our database take six percent of
the costs s3 file storage takes four
percent and because you pay for SQS
messages by the millions we don't even
register on the scale it'll totally free
to show you the very nature of our
output at this next 24 hours this the
next day has a really different usage
pattern somebody batched a whole bunch
of content to go at three in the morning
and it kind of just shows you that we
can't run instances at any of it like we
can't predict and we can't preempt and
know when people are going to put things
in because these two days had just
really different usage patterns that was
thirty four dollars so you might be
wondering what it costs for a whole year
of of your content assuming that the
current bit rates and the current number
of renditions we produce stays the same
we've estimated it's going to be 16 and
a half thousand australian dollars to
produce the whole i view catalog for a
whole year but it also looks better in
u.s. dollar
so this is a massive deal for us right
our costs are so reasonable that
suddenly a lot of the inefficiency
problems we have with those those you
know scaling with transcoding it's sort
of less of a problem it starts becoming
something we want to solve when we when
we look at producing extra ABC content
like news or the commercial things or if
we start to produce higher renditions
with I view which are going to take
longer going back to our car analogy for
this we you know we managed to change
the cost of the system from this Porsche
here to something more like a bike but
we still meet a really reasonable time
frame right and that makes us all really
happy looking at some future features
that we would look ad for here at the
moment again we cater for just I view
content and Metro works just fine for
that but if we needed you know high
renditions or more quality renditions
then we can look at some more
optimizations we can introduce a
priority queue instead of you know
juggling 1q with a lot of different
types of content so the idea that you
would pay extra to have a different time
to be able to actually process your
content faster so stuff that its
priority would instantly spin up a
larger transcoder box that would process
its ffmpeg content faster but everything
else could sit and wait and be batched
overnight when it's cheap we could use
things like spot instances in AWS which
are eight times cheaper than regular on
demand it would also help us solve our
problem with underutilized instances
because that batch can you know
obviously collapse and be processed by
one instance rather than all these
separate ones we could also start
transcoding in segments you know at the
moment we take one file and we process
that on one machine if it's a long piece
of contents going to take a long piece
of time and if it's one hour and one
second then that's annoying so instead
we could kind of look at things like
transcoding ten-second batches
ffmpeg is capable of breaking a file out
transcoding it we could transcribe that
in sections and then push it back
together again we actually looked at AWS
lambda when we were doing this initially
is it something that we could try it was
a in its infancy then this is about mid
last year and also not available in
Australia so we would be using all that
Australian internet fast internet
connection to send stuff to the US and
everyone's been paying it out today so
you can see that that wouldn't be a
really good solution for us doing it in
segments would obviously be really
beneficial in terms of an ETA you know
we would know that comp there would be a
constant transcode time basically to
actually produce this content if we're
splitting it up into ten-second chunks
let's put up into as many ten-second
chunks as we need and tell you that your
content is going to be available in two
minutes or however long it's going to
take you also really don't get stuck
behind content that takes longer than
others everything takes two minutes then
you're just gonna get your content soon
the last thing we could do is actually a
third thing we could do is to remove our
reliance on that hard coded trance
profiles we could use something sorry
sorry just to remind you hear these
profiles are hard-coded with our folders
so they're not ideal right every new
type of content that we get is another
permutation in our profiles and another
hard-coded folder so how do we get
around it we can use something called FF
probe which is part of ffmpeg it
actually tells you everything about the
source file when it comes in you can
just run it against the file and you get
all these best information so things
like the resolution that we've got here
if we looked at it I can look at that
and go that's not one of our standard
resolution sizes so I know it's
something that has this black bar at the
top that I need to crop off things like
the frames per second hey i know i need
to actually change that to 25 frames for
a second because that's what we want for
eye view else what we're producing
this here is our stream 5 which is
unknown that's our caption stream that's
our subtitles track and if we saw that
in the file we could go oh great I'm
going to take that and process it and
actually produce captions which which
would be available in eye view as well
that's something we could add to our
system that would be incredibly useful
so all this information that were hard
coding in profiles we could actually
derive from the video using FF pro
rather than putting it in there in the
profile and that's definitely some
features that we would like to add in
future so just in closing now at the ABC
was really looking for ways to improve
our cost efficiency for a transcoding we
had some pretty odd requirements things
like the cropping or captions and we
really don't need everything to be
instantly processed we can afford to
wait and pay pay less for them so we
designed a new system using node go
ffmpeg and a lot of AWS components we're
taking advantage of a lot of auto
scaling techniques so that we can meet
changing levels of demand but pay for
only what we need and our system can
handle unique requirements for things
like cropping or filing coding from
different sources that aren't standard
we can also still do this in a really
reasonable time frame so our costs are
drop dramatically and we are really
happy with that so thank you very much
for following through this journey and I
really hope you've enjoyed watching an
insight into a new video transcoding
service to the ABCs future
how's that time we are up one question
yeah is there a reason why we didn't use
elastic transcoder yes a it was more
expensive than doing it with ffmpeg
ourself particular for the volume we've
got elastic transcripts of all elastic
transcoder also doesn't do the cropping
and and things that we need so yeah
there was just extra quirks so for the
existing content we have do we have to
write we didn't have to write any
extensions no for ffmpeg now so
everything that we wanted was available
out of the books i am happy to continue
answering questions but i might just do
that off the side so thanks very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>