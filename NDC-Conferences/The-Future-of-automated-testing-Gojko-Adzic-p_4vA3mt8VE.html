<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Future of automated testing  - Gojko Adzic | Coder Coacher - Coaching Coders</title><meta content="The Future of automated testing  - Gojko Adzic - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Future of automated testing  - Gojko Adzic</b></h2><h5 class="post__date">2016-11-10</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/p_4vA3mt8VE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so I'll try and kind of give you a
couple of ideas I think where automated
testing is going in the next five to ten
years there are some very interesting
trends happening the space and things
that were stupidly expensive five years
ago are now reasonably expensive going
to cheap which means that a lots of
opportunities are opening up the other
thing that is happening at the moment
that I think is going to become massive
challenge for the future in terms of
testing is fragmentation and that's
going to create lots and lots of
problems for us going forward if you
want to build software properly the I
you know remember the horror days of web
development where we didn't have
evergreen browsers and kind of pretty
much you had to test stuff in Internet
Explorer and Netscape and who knows what
else and there was kind of stupidly
difficult then and then we had kind of
pretty much five or six years of free
riding and that kind of thing is over
now I'm doing it come on come on I'm
working on a kind of online
collaboration tool at the moment and a
couple of months ago we got a bug report
that our app doesn't work on the samsung
fridge which is you know an interesting
thing to think about and needless to say
you know we were not even planning that
anybody's going to use it on a samsung
fridge but computers are now pretty much
everywhere I I remember reading ken
textbook explained in maybe 2000 and
kind of the book really spoke to me
because he talked about how developers
are going to rule the world and you know
low and behold we do computers are now
everywhere and developers are kind of
pretty well positioned to cause the end
of the world by copying page
think something for stock overflows so
III think you know that that's that's
one of the things that scares me the
most that we've won and you read about
stuff like self-driving cars how you
know people now Snead's to start solving
problems what we do if you know you
cannot finish a situation without
killing anybody do you kill the driver
do you kill you know people on the side
and then you read about Russians
developing autonomous units of six tanks
that decide on their own who they're
gonna shoot so yeah
computers are everywhere Gartner
estimates that there's kind of four
point nine billion devices connected in
one way or another to the Internet at
the moment that's more than the age of
the earth in years kind of there's an
estimate that kind of the earth is 4.3
billion years old so pretty much if from
the start of you know microbiomes and
every every micro microbes and
everything if kind of we created one
device connected to the internet for
every year we'd still have more devices
now than kind of if we did that I and
the estimates are that by 2020 there's
going to be about 20 billion devices
connected to the internet now there's
kind of the estimate is going to be 7.5
billion people then so pretty much for
every person we're going to have three
devices connected and I certainly hope
most of those are not going to be
Samsung fridges but it's unlikely that
testing in chrome is going to kind of be
satisfactory by that point so
fragmentation is going to become
horrible and anybody's done any mobile
app development especially for Android
is starting to feel the pain but that
pain is going to increase tenfold in the
next couple of years the other thing
that kind of is really really
interesting that's happening is
people are moving away from dedicated
infrastructure to magical infrastructure
and that's opening up a completely new
set of risks it's you know like Gerry
Weinberg said you know once you solve
your number one problem your number two
problem gets a promotion so we've solved
the problem of maintaining machines and
things like that but we've introduced
some other really interesting problems
ten years ago I worked mostly with
companies that would buy immortal
Hardware and immortal UPS's and discs
that were supposed never to die and
things like that now most of the stuff
runs somewhere where it's actually kind
of dying all the time and it's supposed
to kind of restart without anybody
noticing the risk profiles are changing
much more to kind of communication
between the things and where stuff is
executing and and especially kind of you
know who is who has access to that stuff
and and what do we do with this because
there are some really really interesting
opportunities in that space as well I've
read a research from IDC that talks
about how 65% of the companies worldwide
are going to be doing some kind of
on-premise cough cloud half on site
monster by the end of next year so I
assume you know people coming to
conferences are a bit more
forward-looking so but the percentage is
probably even higher you know with the
people in this room but although
everybody is talking about how cloud is
wonderful and things like that it
introduces a completely new set of risks
at the same time you know it's making
stuff that was ridiculously expensive
stupidly cheap now I think you can dent
something like a 4 terabyte memory
instance on Amazon for nothing for a
couple of hours so if you have some
really really stupidly memory intensive
test
you want to run well you know you don't
have to buy hardware anymore for that
and with most of my banking clients the
biggest problems that their teams had is
getting access to production quality
environments now that's no longer the
problem but there are some other things
going on so those things are creating
some interesting opportunities and and
kind of risks as well and that's kind of
what I want to talk about where these
trends are going now a lot of the stuff
I'll mention today you can do already
with a bit of sticky tape and kind of
smoke and mirrors and glue and things
like that but I think what's really
going to be interesting is when we start
getting better tooling around this so if
you are from one of the kind of software
vendors and you don't know what to do
next I hope to give you a couple of
ideas to inspire you and the last thing
they told me to say is I'll be doing and
ask me anything session on level 2 which
is kind of just out there after this
talk so if you want to talk about
anything we can kind of chat about that
now let's get started so the first thing
that I think is really really going to
kind of change over the next five years
is changing the balance of what's
expected and what's unexpected testing
for expected testing for unexpected
stuff and I think if you look at kind of
a couple of really interesting stupid
things that have been in the news last
couple of years for example there was a
bug in Skype where if you typed HTTP
colon without anything else the client
would crash so badly that restarting
wouldn't help it have to uninstall and
then install it again now you know this
2016 somebody typing and incomplete URL
shouldn't come as unexpected and yet
most of the teams I work with today they
have this kind of policy of okay we're
gonna unit tests and integration tests
for expected stuff and then when are
going to explore unexpected things and
all those kind of data formats you know
putting minus one in the amount
think that they're all unexpected and
there was this fantastic question on
Quora a couple of years ago where they
said some people doing some kind of HR
software got a client from Vietnam and
there was an employee there whose last
name is null kind of completely broke
everything and again you know the we as
developers in 2016 we tend to treat
those things as oh that's unexpected and
it's not it's really not there are
databases of that stuff available for
free there's max wolf created is
fantastic github repository encourage
everybody to look at it's called a big
not a big list of naughty strings there
is about 65 kilobytes of strings that
tend to cause problems so it's out there
it's it's available there is a ton of
heuristics that we've known as an
industry for 20 years how to generate
this stuff there's Elizabeth Hendrickson
Street list as there's a ton of stuff
already available like that I even wrote
a chrome plug-in that you can just
right-click on an input field and it
gives you kind of a bunch of things to
try like valid email addresses invalid
email addresses different formats with
names different formats with addresses
incomplete strings and things that so we
can't claim anymore that these things
that are unexpected the document that
they're you know people know how to do
this stuff but yet still for most of
what we tend to do is unit testing does
this stuff and then oh this is for
exploratory testing which is kind of a
waste of time for some really clever
people who tend to be bottlenecks in the
delivery process because we overload
them with testing stuff that the machine
can do there's a ton of unexpected stuff
but this is expected I mean in 2016 if
somebody's umlaut in a name or an Irish
last name breaks your system well that
series possible that's not unexpected
now what I think the big problem here is
testing for that stuff is stupidly
expensive there's too many of these
things there's too many input
there's too too much that can go wrong
and we are consciously prioritizing not
to test that to test some other things
because testing that is too
time-consuming and too expensive but
going forward I think that's one of the
first things is going to change testing
for this stuff will become reasonably
cheap and there's already some you know
that I can see emerging services like
the Amazon device farm that can allow
you to run a test simultaneously on
hundreds of real devices
we're owning a device farm and
configuring a device farm five years ago
was unimaginable you know if you were
Google or something or somebody like
that you would be able to do that as a
two-person company or a 500-person
company that will be too expensive now
you can do that on demand from Amazon
and kind of now we can start getting
into these things where for example
mutation testing as a concept has
existed for 25 years where you know
heuristics randomly change stuff and
then we see if anything's broken that's
too expensive to do at the moment but if
you can run it on lots and lots of
devices at the same time and get reports
you can do potentially something
reasonably cheap with Maxwell's list or
create your own list or something like
that and kind of one of the loveliest
projects I've learned over the last kind
of couple of years is Jason Huggins
lobster boat Jason is I think the
originator selenium and he created the
original top step what was kind of 3d
printed and I think he had a version
built out of Legos and stuff like but
now there's a kind of proper thing that
you can download and print yourself the
order did the call the source is on
github that you can use in 3d printer on
tops turbot and taps turbot is basically
something is gonna take an automated set
of cons and tap on a device where most
of the mobile testing that's done at the
moment is done through accessibility API
isn't things that simulate software
within software and then we have all
kind of it was unexpected that you know
somebody pressed here or I can't test
this but you know with tapster what if
you I think the Amazon
device farm is currently using
accessibility API is but I can imagine
you know five years from now a huge farm
somewhere with a ton of these tough
stupid secretary clicking my stuff and I
think that's going to become
ridiculously cheap because of the trends
of how things are happening now and kind
of in terms of not just mobile device
testing but where we're going with the
web and browser stuff there are already
amazing services that make stupidly
expensive stuff cheap
so the browser stock site allows you to
test how the website looks like and play
around with the website in over 1,000
combinations of browser versions and
operating systems and it does that in
your browser so it's kind of a couple of
seconds until you get access to IE 6 on
windows vista with something and then
kind of you can try out lots of
different things so you know that there
was this whole joke that chrome is used
for developing software Linux is used to
test to serve software and sorry chrome
is useful to to develop software with
the windows used to basically brand
software little explorers used to kind
of test that it works in Internet
Explorer so now you don't even have to
have internal split for that you can
kind of use it use your Chrome to test
it in Internet Explorer on the actual
Internet Explorer and that is reasonably
cheap now and if you want to automate
stuff there's kind of sauce labs that
allows you to kind of run selenium or
appium tests against all these weird
combinations of things again the
services like that are emerging so if
kind of it's perfectly reasonable to
imagine that we can now you know get a
mash up of these things and five years
from now what I would love to see is
kind of getting a combination of cloud
device farms and kind of these browser
farms and stuff like that they're going
to allow us kind of to take what we
already know take all the knowledge that
we already have about the testing
heuristics and kind of just mutate
the stuff half an hour later get a
report that kind of okay you know in if
people put in a semicolon in this field
it breaks the site that's not unexpected
that something you should be testing for
and I think that's going to become
ridiculously cheap so there's no longer
going to be an excuse of somebody typing
HTTP and breaking our stuff horribly
badly and there's of course a problem
with you know computers are always going
to do stuff that's predictable they are
going to do stuff that's unpredictable
and this is kind of the known unknown
part of things but I think even for
unknown unknown will start getting much
better support if you want real humans
to look at something at the moment you
have human farms as well on the cloud
there's Mechanical Turk on Amazon that
allows you to kind of farm out the tasks
and get ten thousand people to do
something reasonably cheaply you can't
do give them anything particularly smart
to do because of the way the tasks are
distributed but if you wanted to see
what happens when ten thousand people
come to your site and kind of start
clicking around yeah kind of reasonably
cheap and of course somebody's going to
start farming out testers from you know
somewhere in Asia but I don't think
that's going to be particularly a useful
service on the other side there are some
really interesting services email
imagine this space this user testing
that helps people do hallway style
usability tests where you get people
from a kind of target audience to look
at the site and try and use it and then
they'll film them remotely and they'll
send you the videos how people are kind
of traversing your site so there are
already some kind of augmented services
around testing in the space the problem
with this stuff is no longer how
expensive it is to organize it or
coordinated because there's services for
that the problem I think why this is not
more popular at the moment is it's so
difficult to consume the results at the
moment I can pay ten thousand people to
go and click around the site but if I
have ten thousand videos I need to watch
that's too much of my time
can't do that every commit I can't do
that even overnight you know that's
something that's maybe we can do on a
smaller scale maybe we can do it once or
twice per year it's not something that
is kind of doable in this sense now what
I'd love to see over the next five years
and what I think there's a big gap is
coordination and management tools for
this stuff where you know I can imagine
something like a git push happening then
as part of the CI build the new version
of the app gets installed and then we
get 5,000 people to try to do something
differently and this is what I think is
going to be become really really
interesting because maybe maybe maybe
maybe we'll be able to get statistically
significant usability tests is it the
moment people are doing usability tests
so you know I've invited three people to
click on this and two of them have
clicked it's good no it's not it's kind
of three people it's you know we're
making stupid conclusions based on on on
random crap and I think what is going to
become reasonably cheapest is getting
this kind of unpredictable smoke testing
as a service will something break
horribly badly for release this thing
where we can do unexpected unexpected
stuff and kind of this is where I think
we're starting to transition interface
how do we test how do we assist humans
in kind of doing this half automated
half manual thing and then if we take
that a bit further I think there's
another really interesting opportunity
that opens up and that is basically
getting people who know how to test and
assisting them in making decisions
because we will have expertise expertise
is required in the future we're not
going to replace people with machines we
can automate what they do and we can
assist them in making decisions because
the more fragmented the space is the
more complicated things are the less we
have control over the environment where
the software is actually run like on the
cloud the less it's going to be
actually predict where things can happen
and what can happen and the more moving
parts we have in our software kind of
where I think at the moment we're still
kind of having it easy you know there's
a server something's running on the
cloud is a device that connects to it
when the Internet of Things finally
comes along things are going to break
randomly in places you never know I mean
I was chatting to somebody in the
hallway where they have these tracking
systems for cows now with RFID chips and
analyzing stuff and you know cows are in
the field and who knows what can go
wrong there I have no idea about the
kind of risk factors that happen there
but I think what we're going to get more
of these moving parts that are
physically moving that are now going to
create lots and lots of unpredictable
scenarios and this is where we'll need
to have completely different approaches
to testing one thing that is kind of
starting to happen as a trend in the
industry and started to happen about the
thing pharmacy C's ago is this whole
approvals testing thing where for things
that are not necessarily possible to
predict how they're going to happen or
if it's too expensive to sit down and
actually kind of write the whole thing
how it's going to play out we run the
system and then we see what happened and
then the tools assist people in
estimating whether that was right or
wrong one of the first tools I've heard
about in this space was text test text
test was doing really really smart
comparisons and text files log files
sequel dumps Excel exports and things
like that and the text test pipeline was
designed so that you have a baseline of
what happens in the log file you run
stuff through the system then you text
test we'll compare the new log file
really smartly I'm ignore timestamps
figure out what parts are important show
you the differences say this thing is
what happened is that kind of what you
expected to happen and instead of kind
of if you think about a really legacy
horrible
placated system with lots of moving
parts we're unit testing is easy you're
gonna pull your hair out something like
text test makes the extra dick Leslie
cheap now text test is a fantastic tool
you can use it on text files and things
like that but I think where the world is
going is is away from text files
the world is going visual it's going no
UI I mean I have a Amazon echo now that
my son is shouting at all the time
there's no text file there where you
know this voice there's cows moving
around fields there's lots of really
interesting stuff that's happening and
we need to kind of figure out how to
deal with that and I think one of the
things that's also emerging in this
space is now we're getting really
interesting ways of exploring our
software the complexity is so high that
people are coming up with those
interesting ways there's a if we if you
play video games you probably know about
no man's sky no man's sky is an
incredibly revolutionary space
exploration game where they have this
mathematically generated universe of 18
quintillion stars now I have a degree in
math I have no idea what the quintillion
is but they've generated they're
generating 18 quintillion three planets
and each of these planets is supposed to
be playable for years and years and
years so as a player you can decide to
land on a planet and then kind of you
know play around there for a long time
you can decide to take off and kind of
land on some other planet now the
combinatorial explosion of things there
is absolutely amazing the what they've
tried to do with each of these star each
of these planets is naked grounded in
reality
make it grounded in physics so houses
are on the ground animals walk with legs
and you have windows and houses you have
roofs on top and stuff so what they've
done is they've come up with some really
really smart models for animals
buildings and things like that
and they do some kind of randomization
for example they start with the giraffe
then change the colors or extend the
neck or extend years or shorten the legs
and things like that and they have this
thing that kind of they're the product
director Graham Duncan cause a big black
box of math that then kind of comes up
with these things now there's no right
or wrong here there's no unique test
that can say I expect this thing to
happen it's supposed to be fun
it's supposed to be interesting it's
supposed to be visual and it's supposed
to be kind of grounded in reality but
how do we estimate whether it is or it
isn't and with 18 quintillion planets
that are playable for years and years
and years if we set out we're gonna just
kind of you know do exploratory testing
on this how do you do that now what
they've come up is absolutely amazing
and they decided to do exploratory
testing the same way sci-fi authors do
exploratory testing of space or NASA
does exploratory testing space they've
built software probes that fly through
the universe and take videos and
developers rooms they have screens
showing what those probes are seeing so
it's kind of a slightly random but then
these probes spend a bit of time on this
planet spend a bit of time on that
planet and occasionally somebody kind of
developing with spots and oh that's
weird
pause rewind back and then you can look
at kind of why that's been generated
like that change curve your math model a
bit blue play that thing again it's kind
of deterministically predictable but
it's completely undescribable what is an
expected result and I think if you look
at that thing that's what I think that
the future of a part of automated
testing lies the more complex our
systems are going to get they're going
to be predictably deterministic but
they're not going to be explainable up
front and with these things I think
we'll be able to kind of deal a lot
better if we can support humans in
spotting weird stuff and saying
this is right this is wrong instead of
trying to spend a lot of time describing
what's expected and there's already a
couple of tools emerging this space that
are really interesting for example at
the BBC
I wrote this tool called the Wraith that
is taking a old screenshot and a new
screenshot comparing that and just kind
of visually outlining the differences
you can do this thing with image magic
in one command line if you know what to
do and you can set up pipelines for
these things now what they do is you
have a change on the website it kind of
highlights this stuff it's a ball this
thing these areas changed is this what
you expected to change or not and
instead of spending hours and hours and
hours maintaining user interface tests
you can very quickly go through where
what's changed on the website if you
have a probe that kind of flies through
that and takes the right screenshots and
although rathe doesn't really have any
workflows that are good for this there
are already tools that kind of support a
bit of workflow around this thing as
well so zbr wrote this thing called
visual review and visual review has kind
of a workflow where it takes a couple of
screenshots it highlights this stuff and
says is this what you you know is this
okay and if you say yep that's okay that
becomes the new baseline and then next
time you kind of deploy the system it's
going to do the same thing and say well
this page changed in this way is this
okay or not
and this allows people with experience
with expertise to very very quickly go
through all those changes now the these
things are comparing stuff visually and
the convenor currently comparing it on
one browser and stuff like that but
there are tools like Dom reactor don't
react reject real deprecated now but I
think it was a valiant attempt at
something and I'm hoping somebody's
going to resurrect that Dom reactor was
doing a side-by-side comparison of how
things look in two different browsers
and highlighting the differences so you
know you've tested it in Chrome
what's different in Internet Explorer
very quickly where do you focus your
efforts on when you want to kind of
invest at the time of those three
testers that you have on the team and
where do they spend the most amount of
time so I think I'd love for somebody
kind of to take this idea and you know
figure out how to resurrect it the other
thing that's really interesting in this
place that is a service that's recently
launched is applitools applitools is
doing this kind of probing through your
site and filming a video and then doing
a visual diff on the video not just on
what's changed on a single screenshot
but what's changed in a timeline of the
interaction with the website and you can
script it using selenium we can script
it using up here we can script it using
coded UI
I think they will have support for those
horrible tools that HP is making but the
the what I would love to see over the
next five is and what I'm hoping kind of
the the ecosystem is going to produce is
the combination of this with kind of
automated cloud services all this is
kind of a single browser single system
single journey and and it's still kind
of relatively expensive you have to
manually look at this stuff to figure
out what's what's happened where what I
would love to see is something where you
know you have these cloud services you
do your probe through five hundred
browsers at the same time on 20
different systems they go through
purchasing logging in whatever the key
workflows are and kind of highlight the
differences and then somebody can say
yep that's kind of you know I've made
this change that's that's a good change
of why this thing break and that's going
to become relatively cheap now another
kind of interesting set of tools that is
emerging in this kind of visual space is
testing the layouts and layouts are kind
of one of those very very tricky things
where you know I I remember working with
the team five years ago we
one of the designers kept reporting that
there's a bug in the screen and kind of
saying oh you know this is off this is
off this is off and the developers are
kind of moving things around and at the
end just realized that you know they
actually have to sit in the same room
and to figure this thing out
and one of these I said well this is
gonna three pixels off and the opposite
just three pixels and this whole world
of kind of things came crashing green or
crashing down around three pixels
whether it's supposed to be three pixels
off or not and for developers that you
know developers will not actually didn't
register it's kind of three pixels to
the left you know what you want it's
kind of where I think what's going to
become possible is to bridge that gap
and kind of eliminate developers as
middlemen there because in that kind of
stuff developers really are middlemen
you have designers who want something to
look like that and then they ship it off
to somebody who kind of frankly doesn't
understand the difference between green
and other type of green and you know I
can make out about five colors I guess
III just don't have an eye for that I
don't register those things but
designers do and and we're just slowing
down the process there with the
bottleneck and I think things are going
to emerge that allow designers to have a
much quicker feedback of that and I
think if you look at kind of the tools
emerging this space that's kind of
starting to become possible but not
really yet so there's Jim Shores Quixote
that is the result of his work on the
let's called JavaScript screencasts
where he needed some way of proving that
it works in different browsers okay and
he created a unit testing framework for
CSS but not testing files testing the
actual results where you can do
expectations like the top page of nav
bar was you know the law Lord and or not
this is attached to the left this is
these many pixels away from this object
and things like that so what that's
going to do then is going to run this
stuff and if you have for example karma
running or something light it can do
stuff in different browsers it's amazing
it's as well you know
these are the differences now this is
horribly technical I I can't imagine a
designer writing this but there are
other tools emerging in the space like
the Galen framework where you can do a
bit of kind of given when then and
something cleaner and things like that
and it automates it across different
houses for you automatically and runs
these workflows and that's still
technical but we have a technical
capability of doing proper layout
testing now there are tools for that now
the interface for the designers is not
there yet but we have the technical
underlying framework so you know
somebody can build a nice interface on
top of that and I think there's a couple
of really interesting things that are
emerging in a completely different side
of things there's this app called pop-up
that's absolutely amazing that allows
people to do prototyping of mobile apps
on napkins and post-it notes you kind of
draw what you want to you know the
screen to look like on a post-it you
take a photo of that and then pop up
allows you to say well this is kind of a
button and when I press this button is
going to go there so it's used to
mock-up applications now I can imagine
somebody sitting down for a couple of
months and taking this concept of
describing the user interfaces mixing it
up with Gale and framework or mixing it
up with gin shots Quixote and actually
allowing somebody to visually specify
just like this thing is supposed to be
five pixels wide and this thing is
supposed to be below and this thing is
supposed to be right and round and
things like that and then kind of
executing those tests as nice clean
expectations rather than kind of
comparing the whole browser and then you
can combine that with the stuff I've
mentioned earlier way trans probes it
does all sorts of weird things it
compares it to different browsers the
technical capability is there we don't
have the expressive language for that
yet but I can imagine something visual
like this just kind of coming in and you
know conquering the world so my next
prediction for and of 2020 is will will
seeing many more much better expressive
languages for describing these kind of
tests and then hopefully you know we can
just eliminate the middleman there we
have a designer that kind of draws the
wireframe and instead of putting that
into Word and then sending that and then
somebody coding that and then somebody
testing that and somebody complaining
that it's not right and then people
saying well it is right it's kind of
float:left and then somebody said well
you know it doesn't float left enough
and things like that what I'm hoping to
see is you know the designers actually
kind of being able to do an automated
test and then using that as part of the
cycle and proving that on multiple
browsers and stuff like that now that's
kind of doing the expected doing stuff
that we can kind of envisage and we can
predict and there's a whole set of risks
that even to the best of our knowledge
absolutely impossible to predict and I
think this is where we're going to study
star starting to see really interesting
things because kind of with automated
testing and automated test only tests
for kind of what you tell it to test for
so if you're looking in the wrong place
then you know it might all be very well
but for nothing and there's this famous
article about doing that in real life
that Mary poppendieck wrote called the
tale of two terminals fantastic reading
absolutely fantastic reading it talks
about the launch of terminal 5 Heathrow
in London and terminal 3 in Beijing and
the differences between those things
terminal 5 famously launched where
during the first week they misplaced
something like 15,000 bucks and it it
was so bad that they had to kind of ship
those bugs on the planes to another
Airport where they got sorted and then
sent to destination
that's how broken it was where Terminal
3 in Beijing that was kind of comparable
size launched flawlessly and many
compare that and said well you know the
terminal 3 in Beijing was launched where
a couple of weeks before the launch
they had 8,000 people come in and for
those 8,000 people they got them to
check into something like 146 flights
get seven thousand pieces of baggage to
get processed actually processed through
the airport and then they get we are not
look at some statistics and said you sir
are gonna be a terrorist you are going
to be you know mother that's lost the
child's you are going to be a busy
person trying to catch a plane that's
late you're going to kind of you know
lock yourself up in a toilets and need
help and can I did some interesting
statistics for this and because it was
kind of statistically relevant they
caught a ton of stupid stuff they fixed
it and the terminals flawlessly now one
of the conclusions was that you can do
that kind of stuff we're in control of
the Chinese army so you have like you
know 8,000 people for free to do stuff
and that would be prohibitively
expensive in the UK now although that
conclusion is nice it's not entirely
true UK being UK they had a
parliamentary inquiry why things went so
bad and that the paper is public now so
you can look at it it took them a couple
of years to publish it and they actually
had about 15,000 volunteers
participating 60 something trials of the
airport while it was built but they were
just looking in the wrong places so they
had even more people than the Chinese
testing this stuff they had lots and
lots of trials but their test was just
not testing in things that are kind of
statistically relevant or kind of things
that stuff happened that was impossible
to predict now even with the best
heuristics we'll still have to deal with
that kind of stuff and learn new
heuristics and the one of the things
that is really interesting in this space
is how at the moment the kind of
best-in-class are letting things fail on
production and then figure out how do
you stop something that's horribly bad
expanding too quickly for example
there's this fantastic article I think
on how Facebook does deployments where a
new feature is deployed to 1% of the
users with the developer who develop
that feature sitting at the screen and
watching what happens and then if
there's nothing horribly wrong then kind
of it expands to 10% a developer
supposed to go home and then kind of you
know they expand it to everybody so I
don't maybe I'm kind of misrepresenting
the exact numbers but that's kind of the
idea and there are there's a fantastic
article I strongly encourage anybody who
wants to kind of do usability testing to
look at that it's not what single
articles call thread of these things
it's called the 40 shades of blue
happened at Google in 2009 where the
head of the head of design at a guy
called I think Doug Domino or something
something like that asked the developers
to change the color of the hyperlinks on
the home page for Google Ads
and for whatever kind of reason
developers were kind of fighting a
silent war against him and kind of asked
him to describe why which is kind of
always a good idea and the explanation
was that the color is much more
noticeable to the human eye according to
the color theory and
blah-blah-blah-blah-blah people are
going to click on it a lot more it's
going to be wonderful you know who's
gonna make a lot more money and the
developers being developers instead of
deploying that that night they deployed
that color plus 4039 other colors of
blue and as a result of that depending
who what you read because it's kind of
covered in both places Doug either quit
or was fired and he wrote this fantastic
post on how it's impossible to do good
design where you asked to prove
everything and I think he went off to
work at Twitter now a couple of years
later there was a conference in the UK
and I think Guardian covered it where
somebody actually got some financial
data from Google
that and there was a episode mentioned
at the conference where developers
preventing I changed the color measured
that the difference between that color
and the existing one expanded to a whole
year and a hundred percent of the users
would be something like 250 million
dollars in lost revenue so kind of at
this point you know you have somebody
who's obviously smart has a lot of
experience to rise through the ranks to
become head of design at a company like
Google and made the decision based on
the best kind of information available
to him then but then something
unpredictable happened and you know
people didn't click on those links
people are on principle there's an end
because these guys kind of measure that
contract that they were able to kind of
you know save 250 million dollars which
is kind of a big deal and you know I
think originally I'm not intelligent
thing that works a Twitter at the moment
where they have a fantastic shade of
blue but they still not making money so
this is it's yeah it depends on kind of
what kind of approach you want to take
to development I guess so what I think
is going to happen at the moment these
things are stupidly expensive these
things are you know for most of the
companies the solution is running on
production a limited number of users see
if something unexpected happens and
don't get me wrong guy I have you know
huge respect for people that rise
through the ranks and become really good
at their job and I think you know it's
always easy to second-guess people after
the battle but what's really important
is that even with with some with the
level of experience like that and even
with all the possible color theory that
people came up with he hit a problem
with kind of something unexpected humans
are unpredictable and we're going to be
keep hitting that and keep hitting that
the question is can we do that better
because if you look at kind of I I've
worked with a lot of banking clients and
proposing that maybe we should kind of
run this thing on 1% of the users
you know that's never going to happen
but still unpredictable things will
happen so you have to catch it somehow
so there's a couple of technologies that
I think are emerging this pace and with
the fragmentation we've kind of you know
devices running and broken stuff running
all the time things like tracking what's
actually happening close to the client
are going to be really interesting if
you have RFID devices attached the cows
moving around well there needs to be
some monitoring on the cow as well not
just on your service so there's a couple
of things that are really interesting
this space this kind of hot Jar what Jar
is kind of Google Analytics or steroids
it's giving heat maps is giving user
journeys giving you a ton of things that
are actually happening right now and
allowing people to consume a lot of that
and another thing that I kind of really
like is truck Jaya structures is kind of
doing exception monitoring on the
clients and reporting that back to the
mothership and so you can kind of look
at unexpected stuff I mention this
collaboration tool I'm working on at the
moment we had after a particularly a
huge spike in exceptions happening on
clients client devices in Spain and
Mexico now that's kind of odd because
our software is not localized at all
it's only in English and there's no
particular reason for a territory to
have a huge spike but if you look to the
data it's clear kind of you know that's
where this error spikes are and then we
found a couple of people who we know
from Spain that are kind of using this
and said you know is do you know what's
going on you know what is well you know
if I press this button it kind of no
longer works it's like well what button
is sending me screenshots there's
something in Spanish why'd you get this
this is not a site yeah it is your site
can I use Google Translate to translate
Spanish and this is kind of again one of
those you know okay it's predictable now
if I was smarter than if I had accessed
that information then then
you know but it's one of those things
where I made a stupid decision and what
had happened is we completely stupidly
and I'm embarrassed to say this used the
label on the Dom button as a selector
for something and you know with Spanish
you have these weird Unicode symbols
that kind of you know question mark
turned up and down and things like that
and then because they use that in a
translation broke a ton of other things
and yeah so I I you know III caught
myself in one of these kind of
unexpected expected things but fair
enough humans are unpredictable we can
we caught that and we fixed it we
expanding on to the cloud and things
like that people change stuff that you
don't necessarily know they changed we
integrate with dropbox dropbox when they
decided to change something in their api
without telling anybody and we had a ton
of errors on the clients that were
logging onto dropbox we're using a
special stuff to dropbox because we had
good air or tracking on the client we're
able to look at this and say well you
know what's changed and investigate and
fix it without that kind of operational
awareness that's impossible
and I think going forward with
fragmentation with the cloud and things
like that pushing this kind of
monitoring outside of what's under our
direct control is going to become really
really interesting really important so
one thing that I would love to see is
combine these tools that already exist
now with the tools that are going to
merge with something like Mechanical
Turk with something like user testing
with something like you know a human
farm that does unpredictable crap on you
know unpredictable stuff but being able
to do that before production being able
to do that as part of a CI step where
you know I have passed all my automated
tests and now tester now can all of this
goes to 15 minutes of you know monkeys
playing around and we do error
monitoring on the clients to see if
something weird is going to break
I hope you know my friends doing car
monitoring are gonna have an actual farm
of cows where you know small Amazon
drones go-go drones go around to install
new software on the cows so you know you
can kind of see what happens but I think
we're going to start seeing that kind of
stuff
integrated into CI I would love to see
that because then kind of you know the
the banks insurance companies and people
who are horribly scared of testing stuff
on on real uses now well here's a
service for you we give you five
thousand people to play with this for 15
minutes you pay us 30 bucks or you know
whatever but I think that's going to
become really really interesting
especially kind of in Amazon automating
their warehouses so lots of people who
carry boxes around there are no longer
going to need employment so I can see
kind of them expanding into this or kind
of uber with all the drivers after they
automate the cars so but I think what
I'm trying to say is these things are
now you know they're emerging that
they're done by kind of best of class
companies and the dump our own real
users in production and what I'd love to
see is kind of a push of that before
production so that we can kind of figure
these things out before they actually
starts have perhaps it's not happening
to people now the last thing that you
know I think is both an opportunity and
a threat for the future is how much data
we are generating and and what we're
doing with the data I've read research
that says that in 2020 we are going to
be generating something like four
zettabytes every minute I have no idea
what to zettabyte is but kind of sounds
cool but there are kind of systems in
place now to analyze large volumes of
data and to do something useful with
that and there are systems now that are
emerging that kind of do really
interesting unpredictable things so kind
of big data as a buzz word is kind of
you know arrived in one way or another
in 2012 does this fantastic story of
target the US retail chain where they
were starting to send some kind of baby
baby
would coupons to a girl that was 16
years old and then her father went to
the local target shop yelled to them
yelled at the manager saying you know
you're insane what are you doing you
know things like that and then it turns
out two week later she's pregnant
target was able to deduce that she's
pregnant before she even knew that based
on her shopping patterns so yeah and
curvy pretty much every day when you use
Google big beta is serving ads to you
when use Facebook it's showing you kind
of crap based on some stuff that you're
supposed to have done or whatever which
is really interesting for somebody like
me where I travel a lot so it starts
showing the odds in weird languages and
my children use my computer as well so
kind of showing the odds for toys in
weird languages and stuff like that so
you know big data can go wrong horribly
badly but I think we are kind of
improving in that space and and if you
look at the stuff that's happening now
somebody talked about the two-factor
authentication
yesterday where they're doing machine
learning to do predictability on your
network patterns whether it's you or not
you and kind of people with machines I
started to make some weird decisions
based on the data that's available to
them without us being able to explain
why and coming up with kind of those
things and I remember listening to this
talk by somebody from kaspersky a couple
of years ago and they said it kind of in
in the very near future security is no
longer going to be kind of a matter of
blocking people off your system because
that's not going to be possible and what
we need to start thinking about is how
an organism defends against viruses
where you need to spot something
unexpected it's happening in isolated
and kind of figure out matrix around
that and then I recently read about kind
of security analysis systems that are
doing this kind of machine learning to
figure out when you know one of the
machines in your system is doing
something funny and then trying to
isolate it and kind of
figuring out things like that so kind of
that kind of stuff is possible if you're
Amazon or Google or Facebook and you can
kind of have a budget to hire people
that have PhDs at you know rocket
science and things like that but what's
happened last couple of months is really
interesting first of all Google
open-source tensorflow tensorflow is
kind of the key part of Google brain
that makes most of the Google Earth
decisions and now you can kind of
benefit from that of course you need
stupidly powerful hardware to run that
but hey there's kind of you know Amazon
for you so you can do it for 30 bucks
and Microsoft kind of is a fast follower
that kind of they're famous for in open
source the distribute the machine
learning toolkit kind of again that kind
of stuff so when companies like that
start open sourcing that kind of stuff
you know that there's no competitive
advantage in it anymore it's not secret
anymore and you know everybody should
start doing that and that everybody
includes you now this means that we can
actually run some kind of you know weird
stuff and let machines learn and and I
think that's gonna be fantastic for
testing from several perspectives the
first thing is people have been doing
experiments with automated unexpected
kind of testing for a while the first
I've heard of that is marks three back
at 2009 at Expedia in London spam
fighting was the big thing then and Mark
was talking about how they took the
Google machines that are doing spam
fighting and try to figure out can they
improve their tests somehow because he
was kind of leading the testing
department something then I don't
remember exactly what he said well you
know tests are plain text spam is plain
text we're getting pretty good at
machine learning what spam is can we get
this machine to tell us which tests are
spam
which tests a kind of a waste of time
what are we you know on a scale of
Google where are we wasting our CPU
cycles running these tests and even they
had this criteria what's a good test
what's a bad test and they said if
between the test failing and the test
passing you change the system code
that's a good test
if between the test failing and the test
passing you change the test that's kind
of a spam test and they ran that and
they had had some kind of really
interesting conclusions for example
there was a signal where if a test has
end in the name it's likely going to be
less spam test and then you can kind of
deduce sockets testing too many things
it's brittle and kind of things like
that but you know we might be able to in
the future run these things to tell us
what is a good test is about this out of
you know these the set of tests that
takes you a long time to run and it's
heavy and it's expensive to maintain
well this portion of it is just going to
spam I don't know why but you know my
system is telling it spam and things
like that and we can use machine
learning on that and and you know for
people like Google because they have
thousands of developers and you know how
many I don't know how many thousands of
tests and stuff like they can do machine
learning on that you might not have
enough of a kind of data source for that
but that's where github comes in and
there's this fantastic research project
from MIT that I absolutely love you can
find it on this URL they've done machine
learning on github and made the robot
that automatically fixes some of the
most common bugs which is amazing stuff
it's it's kind of um you know is
something where I can imagine in a
couple of years having part of the CI
telling well this looks a bit dodgy I I
don't know why but looks a bit dodgy
maybe you should kind of look at that
part of the code or you know this button
here looks like something that typically
causes problems maybe if you have only
ten minutes to the exploratory testing
you should kind of really test that part
you shouldn't test kind of the other
crap and this is where I think you know
hey you know I'm gonna fix it for you
would you like me to fix it for you it's
kind of a spell checker for kind of
stupid stuff that's going to happen so I
thinking of the last big opportunities
in in Big Data kind of threat Alice
modeling where the more complex the
systems are the more fragmented they are
it's going to be really difficult to
deal with everything but if you have big
data telling us focus on this part now
because that's risky that's going to
come up with some really really
interesting things so if you do this
side kind of to jump into this and you
know combine that with Maxwell's list of
mutations and probes and and who knows
what else I have a personal request for
you please please please if you make a
code assistant for this make it look
like this
so then kind of we can you know go back
to the history so that's pretty much it
I hope of kind of tickle your
imagination at least a bit and I think
kind of the questions let's let's you
know do questions at the ask me anything
session so that's pretty much it
thank you very much for spending an hour
with me I hope of tickle your
imagination list a bit yes</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>