<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>The Hybrid Docker Swarm: Mashing Windows and Linux Apps with Containers - Elton Stoneman | Coder Coacher - Coaching Coders</title><meta content="The Hybrid Docker Swarm: Mashing Windows and Linux Apps with Containers - Elton Stoneman - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>The Hybrid Docker Swarm: Mashing Windows and Linux Apps with Containers - Elton Stoneman</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/MBLgP82uchg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning how you doing thank you for
joining me my name is Elton I'm a
Microsoft MVP and I'm Pluralsight author
and I work for docker I'm going to talk
to you about docker today in Linux and
Windows I usually ask the same few
questions I assume you've all heard of
docker can you raise your hands if you
use docker on Linux and if you've used
docker on Windows with Windows
containers and if you've used a hybrid
swarm with Linux and windows shame
because if I want to put the hands up
they could do this for me so that's fine
let's really talk about today's how you
can you can run a mixture of Linux and
Windows applications in a single swarm
so the advantage of that is you have a
single deployment model a single
management model you don't really care
whether it's Linux or Windows you can
take all this great stuff that's out
there in the open source world you can
bring it into your application without
having to read a book this big about
Linux and grow a big beard you don't
have to do that anymore
ok so this one really go through
segments start by talking a little bit
about Linux and Windows containers and
explaining why you can't just run a
Windows container on Linux machine and
vice-versa
so we're going to go into the details a
little bit about how docker containers
actually work so you can understand why
you can't just run anything anywhere
then I'm going to spend a little bit of
time talking about why this
cross-platform stuff is really useful
why it's worth especially if you even a
Windows background like me I spent 15
years writing dotnet up some windows why
it's actually worthwhile investing some
time seeing what's out there on the
other side of the fence for then it's
stuff the open source tablets that you
can enterprise great stuff you can bring
into your application and then lastly
I'll show you how to do it so I'm got a
docker swarm running in virtual machines
on my on my laptop some windows some
Linux and I'll show you how you can
start with an application as all windows
containers and move bits them over to
Linux so Linux versus Windows now you've
all seen the Microsoft loves the next
slide well yeah that's great but they
are Windows and Linux a fundamentally
different operating systems so the file
system is different the way to manage
process is different how you actually
start a process is different those are
all those are all important things
and it's just the same for containers as
it is for ordinary processes but you
can't download OpenOffice for Linux and
run it on your Windows machine you'd
like just doesn't work same as if you
copied Windward Exe - as an expression
you tried to run it nothing would happen
they don't know how to talk to each
other and the same is true with
containers so in the windows world if I
were to package my application up in a
docker image so that's the package that
I can run a container from it I'd run a
command like docker image build and
soccer would run through all the
instructions in my docker file and it
would produce an image and that image at
the end has got everything my
application needs
it's got my application with all this
configuration it's got asp.net it's got
the right version of.net framework that
i need is all built on top of Windows
server core and that image will only run
on a Windows docker host now in the in
the Linux world the process is the same
the docker commands are the same I still
run docker image build with my docker
file and then docker would produce an
image which is the package of my
application but in this case I've got
I've got a Linux application so I'm
starting from Ubuntu I'm adding in the
JDK for a job application and in Tomcat
and then my up with all this
configuration so the principles are the
same I've got this image which is a
package of my application but this image
is a Linux image it's only going to run
on a Linux host and the reason for that
is when you start your application with
docker container run you give it the
name of the image you want to run on
Windows what it will do is it will it
will start the process of your
application on the host so the container
thinks it's running in its own little
server but actually all the processes
are running natively on the host with
this logical boundary around them so
they can't see other processes that's
what the container is so the only way I
can run my w3w PXE is if I've got a
Windows host to run on and the same is
true on the other side on the on the
Linux side I've got my my linux based
image to run tomcat i need to have a
linux server they can understand the
filesystem in the contain in the image
and understand how to start and manage
to process I can't just take my Windows
image and try
run over here because it's never heard
of an XP it doesn't know what to do with
it it doesn't know how to manage it
probably can't understand the file
system so fundamentally I can't run that
application or not on a different
platform but docker itself is
cross-platform it's written in go there
are some bits of it that say this only
works for Windows and this only works
for Linux but fundamentally it's a
single codebase and that's true of the
command line as well as the backend a
service that runs on the host so I can
take my my Windows my Windows client
running in PowerShell I like to manage a
remote Windows host or remote remote
Linux running docker doesn't matter I
just connect to it and I talk to get in
the same way and vice versa I can run a
Linux client command line and I can
manage my remote machines in exactly the
same way and the backend the service so
in in Windows it's a Windows service in
Linux it's a demon that sits there and
runs the containers though is back in
machines can talk to each other as well
and that's what we call a swarm swarm
which is the cluster of machines they
all have dr. installed and you manage
them as a single unit so your command
line your client says doc or whatever
and it's actually talking to the whole
swarm and the swarm if you tell to run a
container the swarm will decide where to
run it and make sure it stays that sort
of thing and that swarm can be a mixture
of Linux and Windows machines which is
where you get this notion of a hybrid
where my application could be consisted
of Windows and Linux components and I
don't care where they run I'm just going
to tell the swarm to run them and it
will run the Linux ones here and the
Windows ones there and the containers on
different hosts can all talk to each
other over a virtual network and all
benefit from the same security you get
with with secure communication between
the swarm and the state ability and the
high availability and all that stuff so
why why would you want to do all this
stuff so there's other on Windows right
I've been doing everything in Windows
for years there are three reasons this
isn't a Windows passing session not at
all but there are things in the Linux
world which are worth taking advantage
of and the first one is
so if I were to have a really basics
form with a manager and a couple of
worker nodes and I wanted to run that in
Azure it's going to cost 5,000 kroner a
month for a fairly modest set of
machines if I can change my application
to make use of Linux parts where I've
got open source pipes and I can use a
Linux manager as well then instead it's
gonna cost more like three and a half
thousand program so that's for a really
basic sportin the saving is like 1,600
cronut a month it's very nearly enough
to go out to a restaurant and have a
meal in also but you wouldn't have a
small cluster like this so if you're
running production stuff you would have
high variability for your managers you'd
have at least three nodes you want at
least two nodes for your windows part so
you're probably talking half a dozen
machines and your bill would be five
thousand kronor month instead of ten
times something like that so cost is a
fairly significant factor the second one
is choice so there's software in in the
Linux world it just doesn't really work
in Windows
so nginx is a web server that's very
popular in Linux it can run as a web
server for itself or it can run as a
proxy for your web server so I've got my
asp.net application one of the easiest
ways I can boost performance is to put a
proxy in front of it the proxy cache is
anything static like images and CSS but
my app doesn't need to serve and I can
do SSL termination the proxy nor what
sort of stuff inject is fantastic for
that Redis which is a key value store
you can use as a lightweight distributed
database it's also got publish/subscribe
mechanisms so people use it as a simple
message queue and get lab which is it's
like running github on your on your
laptop it's got all the mechanics for a
git server but it's also got CI built in
it's an excellent piece of kit these all
emerge from Linux they're all open
source they all work fine in Linux not
so much on Windows so nginx explicitly
say you can run it on Windows but it's
kind of like beta because with Linux you
can get really deep under the covers and
tune things for performance which is why
nginx does you can't really do the same
thing as they need to do in Windows with
Redis a while ago Microsoft made their
own port so you can run it on Windows
but it kind of hasn't
up with the main using development and
it's just kind of sat there on its own
and get lab or debug uses Redis and
nginx so they don't they don't run on
windows either so having this choice
that to bring this stuff interpretation
is really valuable and the last thing is
about stability so don't you seen a
similar graph to this when Microsoft
were releasing Windows Server 2016 and
alongside that nano server the cut-down
version they did this retrospective
analysis of the previous 12 months worth
of Windows updates and looked at how
many needed a reboot of the machine here
we do Windows Update I'm going to take
your machine down bring it back up again
good luck well often that happens when
you're presenting with your values on
Mac now what they found was for that
12-month period if you're running full
Windows Server with the UI which you
shouldn't do because your server
shouldn't have a UI it would have
rebooted seven times so on average every
month it's going to go down will tell
you to take it down you've got a plan in
whatever applications are running and
sort that out if you're running Windows
Server core which you should be doing
because your server shouldn't have a UI
it would have been six times every other
month nano server even smaller three
times now going to so it doesn't run the
full suite of windows up so you can't
run dotnet framework apps on nano server
so I'm focusing on Windows server core
so six times it reboots over the same 12
month period my Ubuntu server doesn't
reboot at all it still gets updates and
you can still manage that these two
other security patches but because of
the components and the way that then
it's works rebooting because of an
update is incredibly rare so you get
this ability of knowing that when your
starts running up there you're not going
to have to worry about regular regular
reboots so it's cheaper you've got a
wide range of stuff and it's going to be
up for longer with less interference so
that's why is a good thing to be able to
look at doing so that's mostly it for
the slide so it's all mostly demos from
now on my demo application starts off
with a whole bunch of windows containers
so the starting point for this is
actually the end point for the session I
did at NBC London if you want to see how
I got here then you can go to Vimeo and
you can watch that session I had long
hair then and no beard but it is still
me out of dock your t-shirt so you can
tell what this is these are all windows
containers I've got an ASP dot
webforms up which I start off with a big
old model list and I put it into a
windows container and then I start
breaking features out and put them in
other containers so what happens is that
it's like a sign up application to
register your interest so you put your
details into the web application it
drops the message onto a message to
there's a handler here that picks up
that message and saved your data in
sequel server and there's another home
that gets a copy of the same messages
and it saves the data in elasticsearch
right at the far end there is cabana
which is a a analytics tool on top of
elasticsearch so the idea here is and I
fixed a performance problem by putting a
message queue in here so this thing
stays really nice big name I've got a
handler that deals with my transactional
data beta sequel server I've got another
handler that deals with my reporting
database so my users can go and get
their own data without having to talk to
me so that's fine but half of those are
Linux compatible or emerge from Linux
and have been kind of ported over to
work in Windows
so the message queue I use is called
Nats open source ludicrously
high-performing message queue written in
go particular server even runs in Linux
now elasticsearch is Java that obviously
runs in Linux and nginx sorry Cabana is
a node.js application it's about
obviously runs on notice too so what I'm
going to do now is I'm going to start
from the point where everything is
running in Windows I'm going to move the
stuff over so that then it's compatible
bits and pieces running Linux containers
Blue means windows and orange means
Linux if you haven't just to tell the
skin ok so that starts we're going to be
showing you so that's what we're doing
for the rest of the session showing you
how that stuff works so what I've got
here on my Mac I've got three virtual
machines that are all server server
operating systems just running dockets
all they've got in store all docker -
grunting machines and a Windows Server
2016 machine and in this console here
I'm connected to my swarm so they're all
joined here in the swarm to create this
one all you do is you run docker swarm
in it on one machine and docker spawn
joined on the other so I've already done
that so what I've got here if I look at
the daka version command
tells me that my client on the top there
is dire wind that's running on my Mac
and the remote server the 1992 which is
my VM is Linux or that's my Linux
machine so that's fine what I can also
do because it's a swarm is I can look at
the nodes that's all the machines that
are joined in the swarm and I can see
that I haven't been consistent with my
naming schemes but I've got a bunch of
machines in there any resource in the
docker world has like a friendly name
like my you b16 name and a ID that
docker randomly generates you can use
either of those four containers and
nodes and images they will have that
sort of two ID
principle and I've got one service
running at the moment which is called
visitor visualizer and all that is is a
little tiny sample application that
looks like this that shows you the
containers in your swarm so this is a
visual view of what I can see from the
docker API so I've got my three nodes
I'll go into what those labels mean in a
little bit and I've got one container
running which is this application the
visualizer so when you start building up
a distributed application in docker
you'll start off with a with a docker
compose file I compose file just
described all the different components
of how they fit together so what I've
got here is a big lengthy compose father
describes all of those containers that
I've shown you this is all up on github
you have to follow me on Twitter and
then I'll tell you where the link is so
you can go and play with this yourself
if you need to the interesting thing
about this is all these images all these
wrapped up packaged applications they're
all public and they're all on docker hub
too so if you want to run this
application you literally just need this
file and you do docker stack deploy
it'll pull down all the images it needs
and it will run them wherever it needs
to run them if you can see that the
database credentials in there in plain
text yeah I know that's not very good
there's a much better way of doing that
but this is a nice quick way to show it
the interesting thing about here is I
can put a constraint to say I only want
this to run on a node where the platform
OS is Windows and talk of work style out
for me it knows that this node is a
Windows node I don't have to do that so
when I run this docker will will will go
and get the image it doesn't know from
this image identifier whether it's
Windows or Linux it'll grab the image
and then it might find that it can't run
so it will try it may be one of the one
of the Linux nose will pick up the
request to run my container it'll
download ten gigabytes of image and then
to account run it so rather than let it
do that this constraint is just a hint
that says this is a Windows thing
running on Windows so that's how you
would normally do it in production what
I've got here to make it simpler and a
little bit easier to follow I've got a
bunch of script to do exactly the same
thing so for each of these I'm creating
a like a virtual network the overlay
Network means it can expand all those
nodes whether they're Linux windows
project cap and then I'm creating these
services manually so what I'll be doing
is I'll be replacing those services so
it's a it's an easy way to see what's
going on so I've got my sequel server
database here I've got elastic search
I've got and that's my message queue
I've got my web application my handler
for a sequel server my elastic search
angular and then Cabana okay so that's
my full applications back so what I got
here
run zero one separate services and it'll
just a lot of random IDs for each of the
things that it's created so if I flip
over to the visualizer will see that
these containers are popping in that so
there's my database message queue index
Handler there green when they're ready
to run and they're red when they're
starting up so what we'll see here is a
few of them are still register they just
get themselves started it's it's quite
heavily unbalanced this swarm so there's
nothing running on my central node
there's one thing on my left-hand node
and all the other stuff is on my right
hand mode because they're all Windows
containers they can only run on this
Windows node so that's all up and
running the web application is still red
because it's got a health check in it so
a health check is a way you can tell doc
oh you write it in the docker file how
to test of the applications healthy so
not just whether it's running whether
it's actually healthy and I've got a
health check in my in my web docker file
that says every 5 seconds
ping the the localhost so that the
health check runs inside the container
so as a powershell command that says
ping the localhost and if the response
is at 200 then everything's ok and if
it's not then something's wrong and then
docker we'll take evasive action so if
my web
application kept failing the health
check and I had another window snowed
doctor would take it down and bring it
up somewhere else it's just on green
which means the health check is passed
and my whole application stack is ready
to ready to roll
so let's have a look and see where it is
so I've got my nodes here if I inspect Z
mu which is my Windows node I can see
the IP address of my virtual machine
just so you know there's no fakery
involved
not that you would suspect me about so
when I browse to this this is my demo
application so don't worry too much
about it other than the fact that
there's a blatant advert for doctrine
which is coming to Copenhagen in October
the application itself isn't
particularly interesting what you do is
you click on sign up and you get some
stuff we can put your details in so I'll
put my name other bits and pieces in
here and what's interesting about this
is these drop downs so I'm in Norway
right now these drop downs are populated
by by the application itself so it uses
entity framework and toad first so when
it first connects to the sequel server
rotting in a container it could also
connect to a sequel server running
somewhere else or sequel - it doesn't
matter this happens to be running in a
container it's got a completely empty
instance of sequel server so it deploys
the schema first then it deploys a lot
seed data so when I get to that screen I
know it's all working otherwise that
wouldn't have happened
there's no today when I first launched
this web application because of the
health check the health check had kicked
in and effectively already warm during
me up so it started the work of
processes did that entity framework
deployment everything was ready so the
first user doesn't hit a cold
application it's already running and
ready to go so that's my application so
that's fairly that's very
straightforward and also on here I've
got cabana running so I should be able
to browse to the same IP address but
port 5 601 and I should see Cabana
thank you bye on is just this just the
front end that comes on top of
elasticsearch it understands about
elasticsearch and it expects to find
when it's been it's packaged up it
expects to find a container called
elastic search so all I have to do to
use it is make sure that I call my
container elastic search and it will
find it and that's what's happened here
so I've already
one piece of data in there from my
friend when I did my sign up that's gone
through the message queue one of them
has picked up one handed picked up and
put in a sequel server the other
handlers picked it up and put it in
elasticsearch so when Cubana connect it
can see all the data fields because
there's a piece of data already in there
and when I click on discover I can see
my my first prospect sign up I put in
them so that's all up and running so
that's cool but it's all running in
Windows so we're going to start shifting
this around now in my second ripped I'm
going to replace I'm going to get rid of
my Cabana service get rid of
elasticsearch and create some
replacements so let me start that up and
then we'll have a look bit more closely
at that script so on my visualizer we'll
see oh it's already happening so
elasticsearch and Cabana now have moved
from my Windows machine onto it just
happens to have gone into the middle
node it could be any node so when you
schedule a container to run or a service
to run docker spawn will look at the
nose that are applicable and it will say
yeah this guy's got capacity from CPU
and memory point of view are scheduled
one in there and it will monitor them if
I would kill this VM now those would
move over to here this will make sure
that my service level is what I request
so this script that I just ran the big
difference here is that I'm using a
different constraint I'm saying that we
need to run on Linux and I'm using the
official elasticsearch image rather than
my own windows image that I've locked up
one evening when I had nothing better to
do today in the Cabana so I'm using
Linux and I'm using the official image
which is kind of looked after by my
people a docker so I'm hopefully god
I've got a more resilient set of
components here and they're running on
Linux but fundamentally they're the same
thing so when I want to see what's going
on
I can do a docker service list and I'll
see them all running some are on linux
some are on Windows doesn't matter if I
want to see what's going on inside there
I can do a docker service logs and I
could look at say my index handler v7
these are the logs that come out from my
console application which is my my
message handler it tells me the the node
name so if my
if my container moves around or if I've
got several containers I can see the
logs from all of them and if I do the
same for my cabana and have a look at
the logs where it's Cabana qw w then I
can see the output from from the node
logs like Cabana writes so this is a
node application running on Linux I'm
going to manage it in exactly the same
way as if it was a as it as I do with my
top net application running on my
windows now I don't care about that I
don't have to get down into the world of
Linux and understand how to deploy this
application how to manage it and how to
look at it and look after it it's just a
container okay so if I go back to my web
application so this hasn't changed this
is still running on my Windows machine
so if I put in a new piece of data and
click on go this works in the same way
if I try and refresh in Cabana that's
gone because this is on my Windows
machine so there is nothing listening at
55 601 not because I've moved that
container off that's a Linux container
now
so back to my visualizer that would tell
me I should be on node 2 wiki banner and
again I can just do a list of my nodes
and inspect the Cabana node which is sy
38 and that's the address of the node
where BOM is right so I should be at a
point to that and get exactly the same
experience five six oh one okay so it
looks the same because it's the same
version of Cabana the UX is the same
because it's still talking to an elastic
search container called elastic search
but this one happens to be in Linux I
could have moved in one at a time but
this is this Way's easier and when I
change this to be prospects again I've
already got some data in there so it
sees all the fields I click on discover
and I've got one piece of data which is
my to-to-to that I just put in I've only
got one piece of data because the
previous elasticsearch instance that was
running on Windows that's gone now the
data it was with it's gone too because
of the way I constructed the way I
constructed that that elastic search
service losing your data isn't great
obviously but there are other ways to
manage that so doctor has this notion of
volumes and like a data volume which is
separate from a container so I could
have a volume containing
all my sequel server data another volume
with all my elasticsearch data and then
if I move my elasticsearch container as
long as it can reach the volume all the
data stays intact so at the moment we
don't have a way of building with
doctors form we don't have a way of
having shared state across different
nodes that's coming next year but you
can use a volume plug-in for something
if you're in if you're in a data center
of your own but HP however have a shared
storage component that works with docker
same with Cisco and the other guys up in
the cloud you can use shares or a
component like there's your file storage
or whatever works for you soon that will
be part of the platform itself ok so my
first piece of data is gone but actually
everything's still working which is
which is pretty cool I've cut out the
the reporting side of it and everything
is continue to work as I trying to hoped
it would so the next thing I'm going to
do isn't going to replace the message
queue so same principle I'm going to run
this script it gets rid of a message
queue starts a new one using specifying
Linux and using an official image which
is the Linux based image so back here
clear this to 0-3 and check the
visualizer and yep so the message queue
now has topped on to node 1 and the load
on my Windows node is going down there
so now I've only got things which
traditionally belong or windows so I've
got my asp.net application my web
application my message handlers a dotnet
framework Tom saw lapses all for.net has
to run on Windows and of course there
got a sequel server on there on my Linux
nose now I've got elastic search engine
banner and this message to not that's
cause they all run our Linux they're all
much more lightweight you saw how
quickly they started up which is another
side effect is that Linux images are
much smaller than Windows images and
then it's containers start more quickly
than windows containers so windows
container will still start kind of
sub-second but a Linux container will
start in milliseconds ok so that's all
looking good so now my application
should still work so if I replace this
with some 3yz and click on go there's
going to be a large and the reason is
due me alike is because my web
application has built a connection pool
that it keeps for connecting to the
message queue so that's just a part of
how that that particular component works
so it's going through no satisfying the
reason
was fastest because it's picked up a
connection from the pool let's try to
use it and of course it's gone the
virtual IP address and my message queue
has changed because it's in a different
container now so it ditches that
connection from the pool it goes back to
it goes back to docker to find out the
IP address for the new container which
is moved on to the notes and once it's
got that then the message goes through
so part of what you're doing when you
start moving stuff to docker is thinking
about resilience so making sure that if
you were using a component that expects
a separate component to be able to
answer that it's got stuff like retry
logic to deal with the fact that maybe I
containers moved or maybe it's drawn
down and it's going to come up again in
a few seconds just like when you move
your if you move to Azure and you're
using a sequel as your database if
you're using the entity framework you
would use the sequel as your connection
provider that does all that retry stuff
for you it's the same principle but they
use the same connection provider in this
application because I can't guarantee
the seat will be available when my
application starts so those sorts of
bits a retry they tend to be the only
application nology but you need to
change when you move to docker because
you can run anything in docker but if
your application expected the database
to always exist and always be up and
expected the message queue to always
exists and always be up and never
retried then your application will hang
and doctor will start a new container
for you okay so that's gone through if I
look at Cabana and click on discover so
there's my new entry gone through there
so everything else stayed the same the
the message handlers carried on this
thing to the message queue they did they
did they did the same process that we
saw the web application do so the next
time the message times I went to the
queue is that have you got anything
McHugh stop there anymore so they were
put in lag when it goes and finds the
new queue and then it brings it forward
ok so that's pretty cool and again the
the management this stuff is all the
same so running my services now if I
have a look at my message queue so fine
to a docker service PS that lists me all
the tasks in the kind of history of my
message queue it's reassuring I've got
one message queue and it's running on my
docker instance and if I look at the
logs for one and I call it three aww
Oh service logs then I'll see that these
are these are the logs that come through
from my from my container that's running
my message queue on Linux so we've got
all the data there from from that that
message queue does it go application
it's writing to the console again but as
far as stock is concerned it's just
something that's right so he doesn't
care that it's go on Linux I supposed to
go on Windows or dotnet or Windows and
the same with my message handlers so
finally look at the service logs for my
elasticsearch handler which is v7 then
it's showing me it's initialized
elasticsearch check to the message queue
it's received a message and index to
prospect so it tells me all the stuff
that it's doing and there's no there's
no there are no error messages in there
so as it happened it connected when my
message to you moved away and when
elasticsearch moved away the
reconnection logic worked fine so it
doesn't log any errors if it had errored
then and if the console application had
errors and exited then docker would just
start a new container and that we
connect to the new services so even if
my application is not resilient then the
platform is resilient and it will take
care of some that stuff for me okay so
now where are we the last one is a bit
scarier so I'm going to replace sequel
server with sequel server running on
Linux
so sequel server on Linux it kind of
just works the same way whenever I run
this I expecting not to work but it
always does at the moment we're in
community tech preview 2.1 but I build a
couple of months ago Microsoft said when
sequel server 2017 lands it's going to
come out on Windows Linux and docker
all at the same time so it's interesting
to see what you can do with this stuff
under the under the hood it uses the
same file format and all the same
semantics so there's no difference from
a client perspective connecting to
sequel on Linux or sequel on on Windows
or secretly docker so I could connect my
sequel server management studio on my
laptop into any one of those posts and
it working the same way okay and the
other thing we do is I haven't I'm going
to effectively restarting my web
application because of that entity
framework
first business my web application is
currently connected to sequel running on
Windows when I first started my web
application it found an empty database
Lloyd the schema deployed the C data got
everything up and running I'm swapping
the the database out from underneath it
without telling it it's not going to try
and recreate the schema so I could still
push the button and send the data
through but nothing's going to happen if
i refresh it it's not going to find the
schema with the C date or anything like
that so I'm forcing it to an update
excuse me so we'll find the new database
and then it will it will as part of a
health check it will recreate the the
schema and deploy the data so that's
number four and on my visualizer now
I've got my database running on my Linux
node now one slightly unusual quirk
about sequel server on Linux especially
other moment with CTP is that it needs
at least three GB of RAM or won't start
that's why my workers all have slightly
odd amounts of RAM so my manager is a
Linux manager managers don't have to
work very hard so what you all know that
right
so it's seeming this seeming docker so
my manager has got one point nine four
gig of ram that's not a recommended
amount that's just the amount that this
one's got my windows node is two point
60 gram my other Linux though my other
Linux worker is three point three year
of RAM
now I want to make sure that my secret
survey database land on this node
because I want to make sure or another
node that's got enough RAM otherwise it
just won't start so that's what this
stuff here is this ram equals s prime
equals l ram equals m those are no
labels that I've added to my swarm so
you can add like any arbitrary stuff you
want to know to identify it so I don't
need to say that this is Windows and
this is limits cuz doctor can tell that
for itself but if I want to say this
guy's got a small amount of RAM a medium
ram and a large amount of RAM three
bears style then I need to add an
arbitrary note and that's what I've also
got in my script I've got two
constraints one constraint saying this
has to be Linux one constraint saying it
has to
no that's not the lamb the RAM label set
to large if I had multiple Linux nose
running multiple VMs that were actually
running mock dakka dakka service in
themes form and they all had large Ram
labels then it would choose amongst them
Tony on how hard they're working as
happens I've only got one I'm going off
memory on my on my macbook to run like
five ok so that's where we are so that's
what we've got now so this is much more
even the visualizer was the thing that
we started with and then deployed
everything on Windows and now I've moved
things around so I'm getting a better
share of compute resources and maybe in
in the real world I could maybe stay all
day on my Windows machine now doesn't
have to work so hard and and I've got my
Linux machines that are sharing the
workload so now when I go back to here
if I go back to the home page 8 so
that's working still when I take a sign
up I can see my seed data so it's
obviously done its stuff again there's
no lag because of the health check it
kicked in and it deployed lustre for me
I don't get I don't get the first hit
but it's deployed everything that I need
to deploy and it just happens to be
working on Linux which is always the
point where I think well this is highly
highly unusual but that just works
ok so let's put this stuff in again the
rest of the application is the same is
running on the same components elsewhere
so it still behaves in the same way my
cabana I haven't replaced elasticsearch
so now when I click on my discover I
should see the most recent one right so
there's my four four four I'm also now
that will be saved in Sigma server on
Linux so how can I show that that is in
definitely indignant well let's have a
look here if I do a look at all my
services so I can see I've got my
database now which is running on
sequencer with Linux CTP - and if I look
at my save handler which is called Oggs
docker service logs Boggs
then I would see my incrementing IDs
this is this is identity column from my
prospect idea here is one two three and
it goes back to one because it's hit a
completely new database is a new
prospect if that's not good enough I
will attempt to connect to it from from
visual studio code so visual studio code
excuse me has this really cool plugin
for sequel server and what you do is you
do sequel and I can connect and it's on
55.7 so I've already set that up and if
I have a look at the output it should
show me this connecting hopefully and I
should be able to execute this hey cool
this this plugin doesn't always work so
so what that's doing is it's connecting
to my virtual machine which is the the
central Nova's running particular server
at the moment because of the way I've
deployed that like container because of
the way I did this I've exposed the port
the sequel server listens on so I don't
need to publicly expose a port for my
containers to talk to each other so my
my sequel server container has got port
1433 open so my web container can talk
to that that's fine I don't need to
publicly expose it but if I do publicly
expose it there things outside can talk
to the host on that port and it kind of
tunnels through into the container so
that's what I've done here I've run this
I've run my sequel query connecting to
and connecting my virtual machine on
port 14 33 but that port is being
listened to by Daka
so it's routed the request into the
container and sent by the response so I
can see my my prospect that I put in
there with my fort or for details and
this this query which was always always
pointless up until now getting your host
info in your operating system because it
always just said Linux always just so
Windows but you can prove they have a
hard-coded it because now it says Linux
and it tells me it's running running
bunty 1604 which I wouldn't necessarily
know just by using just by using the
container so that's Linux running
running my sequel server instance now
and I've moved kind of everything I
wanted to move over to to Linux running
in the same in the same swarm okay so
that's the
that's that that's the beauty of being
able to do this stuff so if you wanted
to maybe trial sequel server or Linux
then this is a great way of doing it
without having to go and work out how to
actually deploy it and dealing with your
init system and which will be different
for every flavor of Linux you'd have to
care about that stuff I can just run it
in a container plug into my system with
all the rest of the things that I have
running and everything will just carry
on talking to each other in the same way
okay so back to some slides any second
now cool so that was the end point so we
got there without any kind of hiccups
the application didn't always stay
available but then I'm carrying the the
inside out of it and I'm running any
kind of demo mode so I'm not I'm not
running in a way that allowed me to
replace the database or replace of
elasticsearch and maintain the data so
but you can kind of do that so if I was
to set up on if I was running on the on
cloud machines instead of on my local
machine I could have a shared storage
layer and I could potentially take down
my elasticsearch instance on Windows
bringing up on Linux pointing to the
same data store and all that data would
carry on being there the only real the
only real lag from an operational point
of view is when I switched out the
message cube because the connection
pooling here the kind of caching
mechanism that expected it to be on the
old container but built into the the
NuGet package that I used but now it's
already got the the ability to try again
a little bit later on so it waited a few
seconds I found this one and it pushed
out through these guys obvious messages
about any problem and then the only big
the big problem was sequel server
because of the way I'm deploying my
database so I'm just using the base
sequel server image from from Microsoft
I'm not doing anything to it because
everything is done one my application
that's one way that's that's fine but it
does trying to mean if your if your
container changes to something else than
your whatever is populating your
database needs to run again and if that
only happens when your web app starts
then you need to restart your web app
alternatively I can have a custom
database image start
from Microsoft sequel server image let's
draw all the stuff I need but I would
bundle my schema scripts or I would
bundle a DAC pack and as part of my
image I would have it set up so when you
run a container it deploys the schema
and if I did that then I wouldn't need
to restart my web app because the data
is part of the container the the initial
data and the scheme is part of the
container so I would be able to just
connect directly okay so kind of key
takeaways from from doing this stuff at
the moment you can't run cross-platform
containers so I can't run a Windows
container on a linux host or events in
here on Windows host so Microsoft are
adding Linux container support to
Windows but that isn't going to come
good till the end of this year maybe
next year so at the moment that doesn't
give you all the benefits that you get
from running on a native Linux host so
what Microsoft is doing with with their
ability to run that in its container is
they'll have my Windows host I'll have
docker running on Windows and if I want
to run a Linux container
I'll get my Linux container with a
really thin virtual machine underneath
it so I'm going to get a Linux virtual
machine that just hosts my container and
then they can all play with the other
containers that are running on that
hoster on that swarm so we have any miss
Unitec previews apart yet but that's
going to come later in the year when we
do we can start looking at the
performers impact and security questions
that sort of stuff but even if that
works really nicely it's still not going
to give you things like the cost benefit
of having a genuine linux server
especially if you're in the cloud so
think about Linux running on Linux
Windows on Windows certainly for the
time being if you're going to adopt some
of the Linux technology that's out there
there's potentially a huge cost benefit
running in the cloud and when you're
you've got the option to add in all
these bits and pieces that are either
native Linux and don't work at all on
Windows or native Linux and work better
on Linux and the door windows and
there's a stability point in there so
when you start moving your applications
to docker what you've got is a bunch of
servers that have the operating system
installed and docker and nothing else so
my virtual machines just had that Ubuntu
and docker or Windows Server 2016 core
and docker
that immediately reduces the surface of
stuff that you need to update and
maintain anyway but if it's a Linux
server than the chance of you having to
do an update that's going to mean a
reboot and much more and by doing this
with docker it lets you get all these
great Linux stuff without having to dig
deep into into the world of Linux so
once you've set up your your server
running docker or used like a script on
own as your then you don't even need to
do it yourself it is all for you you're
just managing jocket you just managing
containers and nodes and swarms and
without having to deep deep on how these
things are starting how they're how you
get to the logs how you check how hard
the processes of working all that stuff
is coming from the platform and you can
treat everything in exactly the same way
so it can gives you all the benefits of
all this Linux stuff so I've shown you
elastic search engine banner and that's
sequel server and then also things like
nginx so I could put I could put that
proxy in front of my web application now
just by running it in a New Guinea new
container on my famous form that's the
entry point it does all the caching it
does all the the SSL whatever else I
need to do I could replace my message to
you with register for one to two because
I've got a Linux node that's doing that
now if I want to I could spin up get lab
and manage my holes deployment and CI
process running in a container and get
everything in the same way because I
wouldn't have to dig deep and become a
limb expiry to make all that stuff
happen because I'm just running
I'm just running containers there's
somebody else owns somebody else looks
after so as a for instance the the nginx
image and the get map images they're
they're owned by those teams so the
nginx guys build that image so you know
it's going to be production quality ok
and the next thing so if it's not
interesting then up on this is our short
URL thing doc early without the e dr.
Lee slash labs on github we've got a
whole load of self-paced labs but you
can do some our Linux or Windows as a
sequel server one there if you're
interested in that bundling and being
able to run a container that's got your
schema there's one that walks you
through all that stuff our next
conference is coming up in October
Copenhagen you can get a t-shirt like
this if you go and you'll see me there
and that's me on Twitter so I'm always
like this is literally my job so I'm
always doing samples about stuff showing
you how to do interesting things
tweeting about it so you can get me on
Twitter so I'm a little bit short so I'm
happy to take questions but other than
that thank you for listening you don't
have to ask a question to get sticker
there are lots of stickers on
Pluralsight passes another bit of easy
to</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>