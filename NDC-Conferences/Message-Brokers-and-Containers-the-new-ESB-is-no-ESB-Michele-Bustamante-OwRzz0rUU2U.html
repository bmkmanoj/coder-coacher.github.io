<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Message Brokers and Containers - the new ESB is “no ESB” - Michele Bustamante | Coder Coacher - Coaching Coders</title><meta content="Message Brokers and Containers - the new ESB is “no ESB” - Michele Bustamante - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Message Brokers and Containers - the new ESB is “no ESB” - Michele Bustamante</b></h2><h5 class="post__date">2017-05-01</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/OwRzz0rUU2U" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning let's be calm
so my name is Michele aru Bustamante I
think I've already had an intro sort so
I'm just going to jump right in this
talk is about really about moving
towards a message based and or event
sourcing system I tell this story based
on my own sort of earned experiences in
the last couple of years because this is
actually you know only since we started
doing like a service practice in our
companies Alliance I've been working
with some of the smartest people in this
industry who've been doing this for a
really long time so I like to bring in
people that know way more than me when
we go help customers right and so we've
done a lot of docker platform
deployments we've done a lot of
different types of enterprise level
deployments and there's a common theme
across many of these enterprises which
is they struggle with certain visibility
into the system and structured data and
reports and dashboards and things like
that and so I think that that is what
brings the passion for me in terms of
moving forward with message file system
and I'll tell you that story in my way
so I called this the new ESB is no ESB
because apparently there is a hash tag
pound no ESB and it's the one that all
the people that produce ESB is complain
about on Twitter because they want to
say well yes but you need all these
things so we're going to talk a little
bit about the progression here so
everybody remember hello world 1992 if
you're you know near my age I guess it
looks something like this right we had
this one big thing we hit compile we
left for lunch we came back it still
wasn't done so we played doom or
counter-strike or whatever and then
eventually you know we reached today
which is something like this for hello
world right so right out of the gate we
have a lot to think about if you're
coming out of school I feel sorry for
you but the point is we have a lot of
moving parts right every system has you
know front ends of different types we've
got mobile apps and web browsers and
different styles browsers and different
Java libraries and then we JavaScript
libraries and then we've got the backend
which is our API is called from
different paths some of them for
third-party consumption that we want to
meet her and some of them for just our
back-end for spa
applications and then of course we've
got our back-end which usually revolves
around API and we got here after a long
you know progression since you know say
something around 2000 ish where we have
HTTP services and then soap services and
then now back to HTTP because it just
seems to be simpler and fit the mobile
model so it's complicated and you know
we're introducing micro services on top
of all of that which is fun because of
course that can be complicated as well
right and so the question you might ask
is why would we bother to do that and I
think the answer is that there are
business reasons so micro services solve
certain problems right it can help a
business transform that's a very
high-level bullet point that sounds like
a marketing pitch though and then we
have the optimizing of platform choices
because of docker container ization the
ability to choose the language that fits
the top of the problem the ability to
have developers that are better at
golang than they are node or c-sharp and
let them choose the language that fits
but just build these things that we can
you know compose into one system and
then system resiliency which is out of
the gate something that's just necessary
right because we're going to have all
these moving parts so when we say micro
service can help with this it sounds a
bit strange because micro service also
introduces the need for it so what does
this all really mean well only if it's
done well it will help you so maybe
there's that right and you know the way
I like to look at it is this you have
these well-defined set of functionality
but you want more control over and used
to fit in your head so you can do things
like style messages and payloads and
services and evolve that story and the
schema and the storage and not worry
that it impacts other areas of the
system so it should be contained and it
should align with a business domain so
that the business can ask for features
to evolve from that because that's the
whole problem we have today is that
business tries to add features or ask
for things and we're afraid to hit
publish on that Coach production because
the thing that they asked us to add all
SoCo mingles with lots of other things
across the solution and we're just
really not sure if our regression test
we cover that full scenario so this
isolation gives us the ability to
control that a little bit and then you
know the idea would be that you build
this system the solution in
micro-services world so that you can
deploy these updates and not impact
other parts of the system that would be
nice right so this is the goal and it's
already complicated right so what we
have today with our hello world is
already complicated so what's the harm
of adding a couple of more components
right and the idea being that what we're
trying to get to is this
compartmentalization that matches a
domain that gets in your head that you
can somehow evolve separately and
actually be successful with not only the
features that are needed but the
deployment not touching other things
right so now the business can say new
features everywhere and they can of
course be in their own domain and ask
for their features and each of them you
know separately updating without
touching the rest of the system that's
the vision would you agree everybody
must agree ok laughing is sort of a form
of agreement so I'm going to go with
that
so there are some barriers and some of
those are cost because it costs a lot to
add the resources that are needed in the
training is needed and the bodies that
are needed to do this well and manage
the complexity of it and then the
complexity itself is barrier because
people aren't sure can we be successful
at this and you know there's no simple
answer to that you know this is
complicated in some respects but there
are things that it simplifies in other
respects
so then sometimes customers come up with
this idea why don't we just get the
magical micro services platform that
will let us put these services and put
them into you know this sort of block
box but I don't have to really see all
the things and manage all the things
because they're going to give me a
clickety-click pointy point do something
and the workflows are just going to
happen and I'm going to have full you
know data oh wait no they don't handle
the data okay we still have to deal with
that they're going to give us a business
orchestration tool you remember those
like be pal
things like this talk server again there
were times that that made a lot of sense
EDI transformations and there are
probably places where that's still
really useful when you have legacy
systems but that doesn't mean it needs
to be your hub-and-spoke around
everything right so we need a business
orchestration tool and of course they're
going to give us a monitoring and
alerting management tool and this is how
they sell these products right because
it's just going to solve all your
problems oh wait but you stuff to build
your docker containers and harden those
and do all that no no but we're solving
all the other problems what are those
exactly I'm not sure I remember so you
know let's more just learn more tools is
really what we're saying right like I'm
going to have the magical platform that
I have to learn and now I'm locked into
the vendor and if I need to figure out
what's going on inside the magical
platform I might struggle because I'm
not really sure right so then I call
them and they say well do you have a
support contract and if I pay for
support contract at the tune of a
hundred thousand a year then I'm
probably going to get reasonable support
if I pay two hundred thousand I might
get good support and you know I'm sort
of just saying that because I've never
heard that before
and then there's the logs and audit that
is promised right because everything
that happens inside the magical platform
is actually going to be fully audited
and I'm going to have a history trail
and I'm going to be able to you know use
that for business oh wait how do I do
that how do I use that with my business
report start to build those tools anyway
yeah I guess I do well that's okay it
solves all the other problems inside the
box so we're okay and so now we've got
the other problem of aggregation and
system logs where do those go in the
magical platform probably not I've got
my Amazon and my azor and my logs from
BMS and my logs from containers and I've
got my logs that I output from my app
and failures and exceptions and all of
those things still have to go somewhere
but they're not going here because this
is a closed platform so I guess I have
to get the stuff out of this platform
and put it over here but they're solving
all the other problems inside so it's
really still a good thing okay so I
probably made a point you may or may not
agree with it and that's okay too let's
continue why don't we just go lighter
weight and get an ESB because all that
is connect messages back and forth
between the parts of the system and
what-what it gives me is hmm well are
there uses for ESP s still today are the
reasons es B's existed in the past and
the answer would be in the past for sure
yes but what happened is they started
out with just monitoring of messages and
giving you connectivity and
transformation between say soap and some
other protocol and giving you a way to
manage that because in a large
organization maybe a TIBCO or something
like that made sense especially with the
EDI transformation so there was that was
the real reason we started with it and
then they added things like security to
those endpoints which of course we never
need to know anything about the user or
the you know original login or token at
the services that we build right so of
course they could just do it all for us
not really though right so you know
there was reasons that was useful back
then before we had evolved to now and
maybe a little less reason to use it
today the things that were the promise
were protocol e.message transformation
so I've used things like mercury and viz
stock and you know there's others like
them message augmentation message comes
in I go get some additional data I pack
on some new stuff and then I send that
message to the downstream service
because I couldn't write that code and I
wouldn't want that to be in a
microcircuit I did manage myself and
actually understand what it does right
so that wouldn't be any good that might
be sarcasm sorry just pointing that out
workflow of choreography of services so
workflow can be useful we do have a
problem if we don't have the ability to
understand where things are in the
system that's one of the number one
reasons that we think about a message
architecture write message based
streaming or event sourcing gives me a
way to know stuff that happened all over
the place in the whole solution though
not just a symbol a single micro service
so the thing is how can another tool
give me a way to truly choreograph based
on that what will I have to put into the
tool to get value out and that comes
back to the business tooling that we
would need anyways that we're going to
have to build anyways so we can choose
to build it
into a platform that now owns my middle
tier and adds overhead or we can choose
to build it outside of that out-of-band
async because I think async is a popular
word these days just thinking out loud
and then there's the security aspects
which I would say maybe because I'm
painted and I do a lot of security work
it's not really that hard to validate
tokens and boundaries at services these
days there's lots of middleware that
does this for you or API gateways which
don't add extra overhead to processing
inside and stuff that we can't see and
then audit and logs I would argue gosh
there's an awful lot of tools for that
too and wouldn't I rather everything go
to one audit and log storage that I can
see everything and build fantastic not
magical dashboards that I put work into
but because I put work in I get stuff
out that actually fits my business I
don't think that these platforms for a
very large organization will solve all
of the problems because there's too much
complexity and my fear is always lock in
and I don't have the flexibility to
control make sense yes I see the SS and
that's also good for me so what's
missing is things like then that
integration of audit logs with other
things in the system outside of the USB
and odd is special that's not the same
as a history of things that happened in
terms of you know exception throwing in
debug logs and so on this is a
particularly do when we access the
service and access is denied for example
and that's an audit point any you know
illegitimate access to a service should
be recorded and every time you let's say
change a user's privileges permissions
or so on those are auditable points and
then there's an awful lot of other
things that could be auditable points
like access to PII content and so on and
so that list goes on with your
compliance and regulation and that
should actually not go in these async
logs that we normally do it should go
into a place that we will fail if we
can't write it somebody tries to access
a service
and it's successful or fails then if I
can't write the audit log the whole call
should fail and the consumer of that
should just not get what they came for
even if it was successful because if I
can't write the audit my system won't
have the integrity it's supposed to have
around audit make sense
that's audit separately we got logging
logging can be a bit lossy not too lossy
of course we want to keep an eye on that
but you can do things like get file bead
on your docker containers file bead on
your VMs ship those logs up to
elasticsearch that's a very common
popular tool there are other ways to do
it right but that's a very common
popular tool the point is we want to
have a baseline something we can invest
in that we can kind of use for lots of
stuff because this is time consuming and
we're investing in learning how to build
dashboards and have visibility and so
things like messages are one thing
things like logs from my system and
diagnostics are another and then audit
is another we've got at least those
three categories and sometimes we want
to see all of them together so we still
want to have an audit the message has
happened and then we might want to treat
messages with some extra special care
too that's a mouthful okay history
tables how many people write history
tables only a few okay
well you will one day and then you'll
say hey I remember that conversation so
you know I can't tell you how many times
from years and years past and I've
actually been guilty of prior to you
know message based and event sourcing
popularity recommending that we make a
history table for things like every time
you update a user go create a doc DB or
an O sequel and record that thing
because we we need to know what happened
I've had customers have trouble where
they can't figure out what happened to a
user record or a student record in their
system teacher students that kind of
user and that's because they have no
history zero history and then they start
creating the history but it only starts
now it doesn't go backward so I don't
really have my full picture do I because
every time I edit a record I'm only
editing the current state you get that
kind of for free if you do messaging of
course the not free part is the stuff
you do to go work on building
setting system but the rest is free
that's a good thing free is good the
other things weren't free at all so
there's that and then we've got the
operational tools which I've already
mentioned so this is sort of what's
missing when we think about working with
just an ESB or a magical tool in the
middle and I think at the end of the day
I'm pretty sold on designing micro
services with the idea you may actually
want to go with a message based system
not everybody should you also don't have
to go all in there are ways to do a
partial step on that for the big impact
items in your business right so it's
obviously going to depend I know that's
what everybody says so let's talk about
design when I think about a micro
service architecture I'm probably going
to have you know these buckets of things
well if I'm a product online that sells
software or sells something in a
shopping cart I'm going to have
customers I'm going to have products a
catalog that's going to grow and evolve
over time separately from the shopping
cart which is the interactive you know
thing that customers actually use when
they're online they're going to place
orders from that that's a separate thing
because that's after I've already gone
to the shopping cart
we've got fulfillment which is how do I
ship that stuff to you and the list goes
on and identity management I put at the
bottom here is really just one example
of a domain so if I was going to the
white board with a customer about their
business I probably come up with a bunch
of these types of high-level buckets and
then those would be the things that I
have to open up and see how many micro
services fit inside there what do I see
right and there's some finessing to that
but let's continue
so with Identity Management I might find
four buckets entitlements might not be
as common but for sure I've got the
concept of the sign-on part runtime user
login that's got to perform
it's a runtime service and it's got to
be current in terms of like the users
credentials their state are they active
inactive locked in locked out or not
that kind of thing and then I'm going to
have user management some ways to create
users register users invite users some
way to have that user data be updated
and of course the new years is have to
sum
now get over to the single sign-on
service but these could be considered
separate things and then permissions of
course is separate but people coming
bill that often with an identity service
mostly because we have this concept of
claims and we've been sort of
brainwashed hey you put a role in the
claim and now we can authorize masking
for small systems that's kind of good
enough but for most systems we have the
need for more granular set of
permissions and we need to manage that
so that's what we would end up doing
here makes sense so I now have three or
potentially four if I go to entitlements
which is which students do have access
as a teacher that's really just
relations right you know it's access to
things in my system but some people like
to centralize that so they can audit
that as a thing and so when they go into
the you know I guess mindset of
entitlements being the centralized thing
for their whole ecosystem of apps then
they will invest in that but not
everybody needs to do that sometimes you
just look up do I have the rights to
that user and you look for patterns so
you can replay that through the app so I
now have potentially three or four micro
services in domains inside this and you
know I came up with that but think about
your domains and how many things might
pop up when I go to the whiteboard there
is no step-by-step guide on how do you
break down your domain it's a domain
driven design philosophy where you think
about and finesse about and reason about
what is the type of data and use cases
and workflows that the business does
around this and where am i finding the
lines between them so I might start with
the big picture drill down and then
realize wait a minute these are related
I think maybe there is a bit more to
this micro service these things should
go together and you'll figure that out
as you go unfortunately with no
particular guide just thinking and
reasoning and okay the worst thing that
could happen is you get it wrong but
nobody else knows that because at least
you have these separate eye silos that
you can manage that fit in your head so
we've got a step ahead already right
there's lots of wrong ways to do
everything so yeah as long as it's
heading in the right direction you're
still going to be successful so when you
think about micro services it's not
necessarily one service
one endpoint it is potentially multiple
services that are co-located that is the
micro service because the meaning of the
micro service is that I deploy that as a
unit it shares schema it has
dependencies across the things but if
I'm CQRS I automatically have two
services right a right and a read that
is you know bucketed into two into
sharing potentially the same data store
unless I separate those right so there's
dependencies between them therefore they
roll out together therefore there
multiple services in a micro service
hopefully that makes sense
so taking an example of identity because
it's something that crosses over you
know everything we do and hopefully it
makes sense just thinking about I might
start out with a single permission
service that looks like a domain to me
that's probably a single micro service
and I've got admin or system permissions
that are sort of the starting point of
the system and then I've got these
tenants that create apps and they're
going to take on maybe by default the
system permissions over here and then
maybe they're allowed to modify that and
say hey I don't want an admin to have
all these permissions I'm going to
uncheck a couple things so you know
you've got this concept of tenancy right
and then you've got the runtime which is
I go to an app I've logged in the user
goes and looks up their permissions or
the runtime does the middleware and it
needs a way to find out you know based
on this tenant and that user do a look
up what are you allowed to do so you
could argue that then this runtime API
has to co-locate with this data and all
of these together that's one view and
then I can start you know thinking in
terms of well how though if I made it an
optimized read-only cache for permission
lookup and now I've actually done an
eventually consistent you know copy if
you will of whatever is the users
permission and that eventually
consistent result is my highly
performant read optimized path which I
could now think about isolating from the
rest as a separate service because now I
don't have the dependency between the
two right I could evolve this and the
question is is the
effective that's what you have to think
about when you think about the bucket of
the microservice right can I evolve them
separately can I build version tolerance
into the schemas if this is no sequel
and I now added some new features here
is it okay that you know there's extra
data now that maybe this service doesn't
know about yet or that the consumer of
the service doesn't know about yet
potentially right again it all comes
down to how you think about it but as
long as you're you know making sure you
can do this deployment and not break
everybody that's the goal right so
that's one way to reason about
permissions when we think about micro
services for then like breaking it down
fully I would have admin tools using
this micro service creating system
permissions which would eventually
become consistent with the users
permissions that we create for tenants
and then this would eventually become
consistent with our runtime cache and I
could potentially build these to be
tolerant between each other so that
they're actually separate micro services
that can be independently deployed and
there's a whole process of versioning
that we could go through but I'm going
to just keep going on the high-level
design what about just identity we've
got the concept of identity server for
example for login but if I'm doing the
concept of CQRS
then I might think about reads and
writes separately for optimization and
right now what I'm doing here is
thinking okay for configuration
identities the runtime service to get
the read and maybe initially I'm sharing
that read with my management service
that writes and creates configurations
for the identity server like which apps
can login and what the rules are on
which providers we support are we
federating with you know o office 365 or
other things and then over here we've
got our user runtime for login we want
that to be speedy but maybe we start out
sharing that but we've broken the
services into the readwrite sort of
model the CQRS sort of model and then
eventually we can evolve this to break
up the storage into separate write to
have an eventually consistent optimized
read for runtime so and then another way
to look at it that would
put me in a position where I actually
have potentially four separate
microservices once I break up the data
and right now I have to because it's
sharing in the data and the schema okay
so all of this is leading up to messages
and events and things that happen right
and so now thinking about identity still
what are the things that might happen
well when I go to the identity server
I'm going to log in log out or maybe
fail logging in and after that get
locked out so these are activities these
are things that happen in my management
portal I might create users and edit
them maybe delete a user by delete a
user how do I go back and find out what
happened with that user last year or
last month not going to work right but
if I have messages and I have a history
of all the things that I can go back and
see that that user was here here here
and it was deleted on this day right
that's a good thing not that I've seen
that before exactly that scenario with
customer in the past year of course I
have so in management portal we got
things like unlocking users inviting
users which could generate an email so
there's activities that happen related
to the user and then maybe there's a
profile or some sort of portal where the
user self register right they invite
themselves and then they get an email
then they confirm the email and then
they want to reset the password and they
get sent there to do the dance right
with the email and the tokens and making
sure so all of these produce again
events right so instead of just having
services now and thinking about
optimizing for reads I can now think
about how could I have a full history of
all the things that happened with the
user which security that would be a very
important place to do such thing and how
can I make that so that you know I still
have my runtime data available for query
and runtime activities but I still have
a log if you will that audit that
history to do something and that's the
idea that I'm basically getting to here
so that's my talk just kidding
I'm gonna go do demos now so you thought
it was kidding wait no just kidding
now I'm kidding twice okay the jokes
just get better really yeah
okay so the first thing I want to do is
show you an example with Casca and so
I've already given you the picture of
the identity story and what I have is a
little example here that I'm actually
just going to run it so I can show you
what happens so let me do that first and
then I'll explain all the moving parts
so I'm going to go to my Kafka directory
here and I've got a start
Kafka command so that's going to start
do keeper locally Kafka locally I'm
doing this for performance reasons just
to get through this quickly so you can I
also have a DCOs deployment that also
has all of this on it but I'm going to
look at that in my talk later this
afternoon
so we're writing all this locally and
I'm actually again I'm going to be able
to ship messages up through so let's see
this is oh is that a problem I hope not
oh no it's not it's fine
hang on just checking do I have to I do
I've got this guy I've got this guy hmm
that might not be so good I'm going to
do this I'm going to shut that guy down
let me just start that over again if you
don't mind because that looks a bit
strange I might have just hit the enter
key or something and it stopped it so I
could tell that there was something a
little off okay so here's what we're
going to do I have a web app that's
going to run and when we take a look at
it you'll see what I can do with it I'm
going to generate some messages around
creating a user and around you know
resetting the password and so on so for
now I'm just going to forward through
that actually you know what I think I
want to run that without debugging first
so let's do that
see you bug start without debugging okay
and what we're going to see is I have a
consumer somewhere here we'll find the
right one I know we will
which one are you going to be runtime
consumer that one
I have to writing there I think I had
one running already so I might have just
needed to restart that okay it's like
Groundhog Day so I'm just going to do
that all over again hang out a sec do I
have anything running Yes No maybe hang
on okay I think that should have done it
so I'm going to just do that one more
time I say one more and as soon as you
do that you just really never know so
hopefully it's really one more
I've already done a Michele booster so
I'm going to do
Michele LaRue and Michele boost at gmail
and I'll call this Michelle boost a two
it's not going to really send me an
email
it is a demo okay I know how to send
email people so it's going to send a
message and I'll save my password so all
that did is basically send a message
that should be picked up by this
consumer so I basically have a CAF
consumer that's looking on that topic of
messages right now and when that happens
I should be able to go to my dog DB over
here and I should be able to see in user
management because I'm using the remote
dock DB instead of the local let's see
where is my I want to don't do that
don't do that okay
yeah so that's my collections but I want
to go to my query Explorer okay so I'm
just going to do the run and I see
Michelle boost is there and I should see
oh I've got a lot of me where is the one
that I just put though mm-hmm very
curious oh no that's my email sorry I'm
not even looking excuse me for a sec I
know I can find what I'm looking for
it is room somewhere let's just do that
again
I'm not seeing that one two three maybe
it's taking time we're going to see
what's happening there hang on let's
just go in here for a sec management
I see another record ah there it is okay
uh I know what I was doing I was in the
wrong table sorry okay
so that's a Canadian sorry and so
there's Michelle my original user and
then this is the user that I just
managed to create okay you can clap if
you like it was just one really I mean
really you don't have to it was that was
nothing please okay so I've got this you
know workflow that I've built instead of
showing obviously instead of going
through a complicated sample this is
actually specifically showing all the
messages of course so I'm going to just
have a verification token that we're
going to say I got and that would be the
email that I got and so I go to some
site and it's some page on the site with
the link and it's going to validate my
email because I obviously received it
and then I'm going to go ahead and try
and log in and that's great and then I'm
going to log out I'm going to log in
again and then at some point I'm going
to go in here and say hey let's have
about four failed login attempts which
will be the limit and that's going to
lock up my account and then as a result
I need to unlock the account which is
usually timer base I'll you know that's
something we would typically implement
but you can also explicitly unlock a
user from the admin and then maybe I'm
going to go and reset my password and
then I'm going to log in again and here
we go right so I did a bunch of things
and if I kind of head over to my my
running you know all these messages are
being received by my consumer so what
it's actually doing is its producing
from the messages a state and the state
is the current state of my user table so
everything's recorded in messages but
what I'm actually doing is producing my
table right so now I don't have the
history if I do that right
so what's all this stuff about how
automatic history while I still have the
messages so the idea is I would keep
those messages literally forever maybe
there's an archived process at some
point to achieve storage but I can keep
say you're of audit available and then
back up everything else literally
forever and then if I ever need to
reproduce that state I can go back and
replay the messages to produce it again
for example we have a bug in our code we
forgot to write a certain calculated
value we need to recalculate the way we
have the value so we're going to go back
to the messages process it through the
updated better code and have a new state
and snapshot that if we like so the idea
is I'm working on a current state
instead of having the messages be my
state which would be more like event
sourcing so with event sourcing the idea
would be the messages the events are my
actual database right those are my state
those are my system of record which
means every time I want to do some sort
of query or report or gather information
or even update a record and know that I
can update it I would be hitting the
message store and that would require me
to use a tool something like events
store which I'll show in a couple
minutes
so without a venn store just thinking
about a messaging system message
streaming I'm looking at keeping the
messages forever so I could do event
sourcing but maybe this is a baby step
towards it so that I get my audit I have
my history I might not even have the
time to build the history projections
yet so maybe I wait and I don't do that
right away
but because I'm keeping the message I
could rebuild that at the time that I'm
ready and in the meantime I have my
current state store and I have a way to
go back and fix things so what did I
build is over here right so if I come
back and refresh on my management and
select this user all this is showing is
that I had four unsexual login attempts
and then when I was unlocked my code was
you know probably buggy and forgot to
update me and say you're not locked out
anymore so it still says I have
unsuccessful attempts so at least that
proves I did edit the record so I
clearly left that there on purpose okay
so what about history though
I don't have a history right now so we
need to take care of that and I have all
these messages sitting in the in Kafka
which I could archive but right now I'm
just going to you know keep it running
obviously locally and if I was doing
this in production I would probably keep
maybe for seven days you know the
messages that are running through the
system and I would mirror or something
to archive forever the rest of it and I
probably want to offload that to cheap
storage at some point because it's going
to get difficult to manage at some point
right so that's the idea but it's there
are tools for that so that's all good it
gives me the backup it gives me the
ability whenever I'm ready or need it to
rebuild right in the meantime I have my
8020 rule I have my current state okay
so what I'm going to do now is go back
to this code here and let's go into the
solution and let's go into the history
consumer so I have another consumer in
here and what this guy does is he I'm
just going to kind of float down a
little bit here has a message processor
he's going to listen on the same topic
as the other consumer was and so since
he doesn't yet have a cursor you know
into the topic it hasn't received any of
the message it'll start right from the
beginning and start building me a
history table so as soon as I turn this
guy on when he gathers it he's going to
create a record in the history store
instead and so and then of course his
cursor will be maintained if I shut him
down bring him back up and again another
time he'll do it again
so I'll go ahead and start this guy and
we'll go to debug I guess I can just do
that
and so this is have started receiving
the messages you notice go go go
I don't know how many there were maybe
seven eight nine something like that and
I'll head over to the dock Phoebe and
that has nothing to do with this table
but it has everything to do with the
history table now I'm not going to
really be able to read this very well so
I'm going to go over here to the query
Explorer and we'll grab the history
table which we have and first I'll just
run it this way so we can scroll down so
we've got the michelle boost a-- history
we got Michelle aru Michelle the Ruth so
you see a bunch of entries for me the
new user that I was running with and
that history has different types of
messages but it's a bit hard to read
right now so I'm going to go ahead and
make a change so let's go ahead and say
I want to see C dot underscore our
message type type with a capital T
probably and we'll go ahead and run that
again and now you can see mesh type user
created logged in failed locked at etc
so I can now build that full history and
I can do reports on that I can see
exactly what happened with user ID one
two three whoever and gather you know
that at any time I can also do
interesting heuristics around how often
people are you know failing their login
how many retries it is typically all
that data is available which I can
repurpose in different ways by having
other consumers or stream analytics on
that same set of messages coming out of
the message broker any questions so far
no because it all makes sense doesn't it
we're ready to do this okay yes so I'm
completely sold on at least attempting
to fit this into the important parts of
somebody's business model if it's if for
no other reason than because the history
the audit and the ability to do
different views on the same data because
of the messages being available and you
know archived it's just too too awesome
for words I know okay so I'm going to go
ahead and stop this I clearly amuse
myself and maybe that's what counts
sometime
and I you know really used to be a
comedian too perhaps so let's go ahead
and take a look at a Venn store so I'm
going to run this different way so I
have just a simple example with similar
messages and what I'm going to do is
actually just run it first so let's do
that I can probably just go oh you know
what I might want to actually start a
vent store first it kind of has to be
running just just just to point that out
so here's what we'll do we'll do the
stop kafka because that guy's finished
and that should do it okay oops I always
think I'm on the other type of command
line and then here is my event store so
I guess I can just give this run so this
is just running a local copy of it right
now
so I have customers right now that are
using koepcke the way I just showed you
right like so that's their message
broker technology that of choice writing
in DCOs or running in its own cluster
doesn't you know can be done both ways
and then I have customers that are using
this in a multi regional way so there's
another very viable option except that
this takes you the full distance so
we're Kafka you could decide to maybe
project current state do the 80/20 rule
it's comfortable we understand it I can
keep my micro services they fit in my
head this is the data I'm working with
these are the messages that fit that
data it's manageable if I need to evolve
the messages it's all part of the same
micro service that message will never be
used again in another micro service the
names are unique the names have sources
where they come from which microservice
they're part of and it's manageable
because you're not going to have 10,000
message types in a single micro micro
service so you can evolve your data
models your schema and your messages
together in one unit and then we go to
another micro service and do the same
and repeat so you do the first one and
you do all the hard work of setting this
up and you do the 80/20 rule where
you've got a projection of the current
state and then as a migration step start
looking at projections but do say the
history projection and
make it possible to do querying and so
on and then eventually you could
consider dynamically engaging the events
to create the current state on the fly
that's like super advanced right so
people who do that with Kafka have to
write a bunch of Java code and you know
that's maybe not always desirable not
because of Java necessarily although
that could be a thing too but because
you know it's a lot of work right it's
not built-in so do the baby stuff and
this is a good story and it doesn't have
to be Kafka it can be event hub if
you're an azure it can be Kinesis if
you're an Amazon and you know you could
argue that there are a number other
potentials right those are maybe my
first choices if depending platform ok
and if I'm in the cloud it's actually
nice if you can use a Kinesis or or
event hub because then you have a
software-as-a-service and you don't
actually have to manage the cluster you
just have all that data the difference
is you remember you can't store it
forever in those systems you can store
them for 30 days you're going to still
need an archive route that's all you
have to do right and then later you'll
write code to replay those messages so
that's not hard stuff right so you can
do it you know do the archiving and then
do the rest of it later so when we come
into event store it's more pushing all
the way so that your actual store is you
no longer have the doc DB production you
no longer have these other storage
locations you know you've got event
store and that's your cluster and that's
got topics and separation partitions if
you will right so coming back to that
now that I have a vent store running I
can go back to my sample and give it a
run so here is the console the mother of
all consoles that is thinking because
it's connecting to the service and I
don't think at a breakpoint so we're
just going to be patient for a moment
I think it's coming to life now yes yes
no oh oh you mean I didn't run a fence
store hmm maybe not good night oh you're
right pair programming I wanted to prove
that somebody in the room had a heart
and it worked
look at you look at how good you feel
right now let's give him a hand okay so
as I was saying I'm going to run that
again because it's probably just hanging
there wondering what's going on waiting
for an act of kindness
okay oh that's a different problem
okay yeah I know what that is okay it
kind of partially ran is a problem and
it's sort of been designed to like run
once if you know what I mean so like all
production code really yeah I amuse
myself okay so let's just restart that
little guy and we'll come over here and
oh I know what else I'm going to do
excuse me while I load up localhost okay
I don't know what that is oh are you
kidding me that's hilarious how
intrusive though
I've never seen that before really
actually sorry I planned that I'm still
funny okay um so yeah so the stream like
I said hey focus people there's really
important stuff to do here so we're
going to go over here and I'm going to
give this a run now okay okay see this
is what I'm talking about
things that work so I'm signed in this
is sort of choreographing a series of
things on purpose right so I'm going to
act like I signed in and it's going to
obviously write an event that I signed
in past tense and I'm going to fail sign
in and after I failed sign in it
actually went ahead and did a valid
eight three times which we didn't see
but we're going to go look at and then
after that happens it will actually fix
me and put me back on line so basically
you'll do a time out and after some time
passes it'll go ahead and unlock the
user so let's go see what it did here is
my stream that was just created and so
you can see the history then of the
events that are right here of course I'm
not coming in here to look at my data
right like this is just a tool like
administrative tool for events tour but
the idea is that this is now my system
of record I have access to all the
messages that played I can see the
contents of the message the messages
only contain what they need for their
domain right on for their actual target
so some of them are really just sign and
seceded and here is the time right
there's nothing else of course there's
probably going to be other data but you
get the idea so I can take a look at
each of the messages I can also excuse
me go back here and take a look at
things like how often did sign and
failed happen for example for this user
or for all the users that kind of thing
so I can take any of the data that's
being stored here and I can also build
projections
again looking at the history of the
stream this is the stream that I just
created
this is now my system of record the
messages are past tense just like you
would do with event sourcing but even
when I do message based systems that are
not yet going to be used as event
sourcing I try to do the past tense
rather than the command version because
I like it that the message means
something happened and I like it that
that payload is significant enough to
represent the state of my data and I'm
still going to play that to my current
state I'm going to operate off that in
this case I'm going to operate off event
store which means I need a repository
that a client that I can use to interact
with it right so if we come in here you
know there's there's a couple of things
going on right I've got a description
for each event sign and failed sign and
succeeded each of these inherits a base
class event each of those events when
they're plays let's come back over are
basically you know written through the
repository so somewhere in here I can go
to the password user repository and
it'll get its event store connection and
it'll write those events right so it'll
create the events that it needs to as
things happen so for example somewhere
in here I've got a register user let me
see if I can find that under load right
so register register register getting in
there create an instance of a password
user for example so that's going to be a
password user created event there's
going to be the lock out so somewhere in
here let's see okay load here's my
password user repository that's got all
of the different capabilities so saving
the data is just implemented as part of
the repository pattern right so that
implemented so I got my Store connection
and I'm going to load the data and then
somewhere in here I know I have my lock
out but I'm not really seeing it so
right let's see if I can go down here so
append is what's adding to the log so
this is basically appending the actual
messages so this is my password user
registered somewhere down here I've got
a sign-in so this will create a sign in
and we'll see
depend on that a pen signed and
succeeded a pen sign and failed that
kind of thing so these are just again
it's the syntax that's used it for the
pretty event store implementation but
the idea is I'm going to have to define
a bunch of events where do I put those
all in one file of course please these
are all in one file that's exactly how I
would do that not really though no
you're going to have a library of events
as part of the Microsoft solution you're
going to have a library of models then
services that are for the front end of
the API is that do work you're going to
have the services that are part of the
micro service but that one solution
should represent the thing that is the
unit of deployment that is the unit of
the business context that is the thing
that deploys always together and those
messages and models don't ever appear
anywhere else they're not shared right
and so what do we do about shared code
in that case like common I you know
authorization code against services or
rest based models those things can't be
in the solution they have to be nougat
packages that I opt-in to update so that
when that's versioned it doesn't impact
all the micro services running in my
system it impacts the ones that chose to
update right and if it's a mandatory
update then that's a thing that you're
doing right so of course those things
are going to happen so two models
examples building micro service having
all in one place not one file but one
solution the idea of all of the messages
that can happen all of the payloads that
can happen one way you're storing it
actually with the target system another
way you're actually building it wait am
I in the right space where do I want to
be oh oh that's where I want to be yeah
so the other way you're actually storing
the messages and that is your system of
record which means I have to learn how
to work with that so my customer that
before I became there working with them
they had already chosen to go with
events store so they already have this
multi Friesians appointment all we're
doing is converting identity server to
work with it
but I guess my point is
no they chose that for a reason because
they were fully bought in that for the
size of their system that's deployed in
Amazon they needed to have that
visibility and they wanted to do the
true event sourcing path out of the gate
and they felt like that was a good fit
for them but they have the engineers to
manage it and I get other people that
are sort of timid and new to micro
services and they're saying you know
what that's way too much for me let's
just take that baby step I hope that
makes sense those are the two sort of
things so I would summarize to say this
a message based solution really really
thoughtfully helps you with the audit
trail helped you with history helps you
with being able to have new views into
the data giving you that tracking and
activity workflow so we have full
visibility into everything you tie that
to your logging story to where you know
you actually have also your whole system
ready for activity tracing through plus
the messages that happen I've built you
know Cabana dashboards with our team
whereby we've had really rich interfaces
being able to click from a message to a
full stack trace of everything from UI
to the back and that's really powerful
so you're logging story can actually
stitch with your messaging story but the
messages give you the data and now the
business when I told some of these guys
who invested in a POC recently that we
were going to be you know holding onto
these messages forever and you could
actually build new views into the data I
mean they were literally drooling it was
almost rude and so I mean it's for the
business that's why you do it so I
encourage you to think about it you know
combine that with your centralized logs
which can produce monitoring you can
have monitoring on the messages to write
because those could be why is so many
users having reset password that kind of
thing so auditing on certain types of
behavior for security audit as well and
then of course remember that those
magical tools any SPS although they
might provide some features you might
lose some control and you're always
going to have to build custom business
tooling on top of that in other words no
pain no gain thank you very much
that's what I mean yeah thanks I almost
never finish early am i early I'm three
minutes early what's wrong with me today
wow thanks for coming see you later
today I guess so yeah</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>