<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Introducing ASP.NET Core Sockets - Damian Edwards &amp; David Fowler | Coder Coacher - Coaching Coders</title><meta content="Introducing ASP.NET Core Sockets - Damian Edwards &amp; David Fowler - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Introducing ASP.NET Core Sockets - Damian Edwards &amp; David Fowler</b></h2><h5 class="post__date">2017-02-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wIsync6vTfQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">not quite
yeah hello everybody those lights are
really bright they're really really
bright we're here to talk about
something that doesn't work yet so there
might be some imagination required
shooting certain parts of this talk no
no it's all going to work just fine so
we've David Damien Microsoft Ethernet
eight love of luck we've spoken to
probably many of you and lots of people
attending see as of how to use about
signal are very something very fond to
both of our hearts I'm having a chance
to work on it for a while we've been
busy chipping a spinet core but we're
back working on signal or again or at
least some people are so we here to talk
to you about the plans for signal are in
the world of Ethernet core and we're
going to look quite a lot at the
underpinnings of this new signal our
world something that we've currently
called a spy net core sockets you can
throw all of your abuse at us around how
we're terrible at naming but that's what
it's called right now Ethernet core
sockets so let's dive right in
and I will warn right out front I said
there is a super super early like a lot
of this stuff is incredibly aspirational
all right so everything you're seeing
here probably will change some of it I
mean the concept hopefully will will
stick around but some things here might
change over the coming months so signal
are as it is right we all know what
signal our is real-time web framework
for each p.net C sharp client C++ client
as of a couple years ago JavaScript
client Java client which are vaguely
good but it's there and as you know a
great way of building real-time
application a real-time web
functionality into your application when
we set out to build the new signal art
the one in ethernet cord there were we
learnt a lot over building two major
versions of signal arm and there were
some things that given our time again we
would choose not to do this time and so
we have an opportunity now to kind of
start afresh with new eyes with a whole
bunch of years behind us after having
built the last signal so there's a few
things that you're not going to see
next time we know more jQuery dependency
which people have been very vocally had
seen her opinions on on github for a
while we're starting out with no j.crew
this time so there will be a new
JavaScript claim no more Auto reconnect
with message replay this is one of the
things that signal I did for you before
where if a connection was made to the
server and then for whatever reason the
connection dropped with the physical
underlying connection dropped the client
would attempt to reconnect underneath
the same logical connection from your
point of view and try to make that look
seamless you in the client and that
required a lot of gymnastics on the
server we had to store messages that
were otherwise would have been sent to
that client that weren't being sent
right now and it really before signal
our to do a lot of things that you would
more typically associate with a durable
messaging platform then with just a
real-time messaging platform and while
it worked okay it really did complicates
the the design of signal on the server
and it was frankly a bug farm there were
a lot of issues in supporting this this
reconnect problem it also led to issues
of memory use and people wouldn't quite
understand why there was so much memory
being used in the server it was because
you know we have to store these messages
for clients that are in this phase of
reconnecting those things were
configurable but it was just an area
that we felt when we looked at people's
code and how they were using it it just
wasn't necessary for us to do it in the
framework you're better off leaving
concerns like do I want messages to be
able to be stored for particular clients
and then replayed on connect as an
application concern and if we make the
framework more flexible composed of
better pieces you can plug those at that
logic in yourself so that's not going to
happen by default it will still happen
for one particular transport the long
polling transport you have to do it for
but that will very specifically be done
just for that transport rather than
being a core part of signaler which it
was in the beginning
no more hub state we had a feature
wasn't really used much from what we saw
which basically enabled you to have the
client in the server both party on a
shared state bag you know you might see
sharp on the server and JavaScript or C
sharp in the client and it would get
round trips anytime to state
changed between any message going
through quiet and server it was a bit
messy it wasn't a particularly nice
thing for us to support and because how
many people used it we're just not going
to do it this time around unless you
know lots of people scream at us and
they come out of the woodwork and say we
really want upstate then we can look at
bringing something back
no more Multi hub end points so
previously in signaler you would create
you know a series of hubs you might have
more than one and then you would connect
to the hub end point on the server and
all your hub traffic would go over that
end point by default now that seemed
like a good idea at the time but the
reality is that confused almost
everybody and everyone would always use
terminology like I'm connecting my
clients to this hub and reality you were
never connecting clients to a specific
hub you were just connecting clients and
we did all the work of trying to figure
out what hubs you know all that we are
routing all the hub traffic over that
single connection it meant we had to
multiplex multiple hubs over one
connection which meant we needed a
complex sort of payload type and
envelope that knew the hub tier ladder
data bar it made things complicated and
it didn't really give us much benefit
and so in the new world you when you
create employ when you create hubs you
get a specific URL to a hub basically
right and nice and easy no more single
scale out model so we had this one thing
in the old signal R which was message
bus and it was the root of the world and
if you ran in memory you had an
in-memory message bus and then we had
these pluggable scale-out providers
which kind of replaced or augmented the
one true message busting all messages
for signal I in a little signal Oh world
were routed through this one message bus
and that's really because we started out
designing signal R for long polling
right in the beginning everything was
designed around how long polling worked
because WebSockets didn't begin when we
didn't but it didn't exist when we
started with signal and that's also the
same reason why we did Auto reconnect
previously was because you needed it for
long polling let again over time the
single model scale out it causes issues
the way that we do it in signal our
today doesn't scale particularly well it
only scales well for certain payload
types so if you're building a system
where you just send out broadcasts to
all the connected clients and you're in
control on the server side or when that
happens it scales pretty well okay
assuming you're only doing you know a
message every few
or you control the payload size that's
fine as soon as you start building
something more collaborative where you
have clients sending messages to each
other or they're in control of what's
going on that just doesn't work okay
because you can't control the rate of
messages going through the message bus
and if you've got lots of different
people trying to send messages at the
same time the way we did it is that you
know you have lots and lots of servers
scaling out your traffic they all share
a message bus and every message to any
server to any client goes over to every
single server so you can't for example
have all the really busy people on one
server and all the lots of busy people
on another server signal I didn't know
it just sent messages to every single
server so you would get to a point where
that just wouldn't scale and if you
wanted to do anything else you had to
throw all that away and just do
something completely custom which was
not great now we had some teams in
Microsoft build systems where it can
took the entire server done because they
had the button scaler on on the cloud
get one team hit on entire address time
while you're having this are building
scale up by all oh my default I'm kind
of said you know that that is kind of
the knife solution if you have skill
that is very superior to your workload
yes kind of have your own logic to
understand what which things should go
into it which servers and then things go
better that way yeah and so they
redesign those stuff with our help and
now they have a very nice scalable
system that works in as well but yeah so
we don't have a place like one out of
the box that works around this simple
scale that model that we expect everyone
to do we have a totally new model and
we'll show you an example this later
which is much more pluggable and we'll
ship you own one based on Redis and
moisture will show you the different
strategies but we think this is going to
be set us up for a much better sort of
scale point in the future and the last
thing is no support for multi server
ping pong so when you have a scale out
scenario and you've got clients that
might be connected to one server for one
part of the connection but when they
send the next message they ping pong to
a different server because they're being
load-balanced in the old world that
would work because all the servers were
sharing a single message bus and we
maintained sort of enough state or we
would recreate State on the new servers
when you ping pong from under the other
doesn't work in the new world we require
by default that you have to have sticky
sessions enabled when doing scale out it
turns out not to be too much of a
problem in the real world from what
we've seen so far and the reality is if
you did want to enable a ping pong you
could write code to do that yourself
anyway the new system is fairly flexible
so you could get in there and rehydrate
things if you wanted to and make that
work again but out of the box it's going
to require you to have sticky sessions
alright so that's all the bad news the
socket change not really bad things are
going to different things different
things here's all the new stuff some
people have wanted for a long time that
we're actually going to do this time so
binary data support is coming and we
have support for that already I think
actually so you'll be able to send and
receive binary data
it'll be host agnostic so you'll now be
able to run signal are the signal on
infrastructure or the ethernet sockets
infrastructure doesn't isn't really tie
to HP it sorry isn't tied to HTTP the
programming model that you use hubs
endpoints they don't talk HTTP they just
deal with connections okay and you can
host those on whatever you like and I'll
show you an architecture diagram in a
minute that might make that a little
clearer that will enable us to do things
like Oh Connect TCP clients to signal ah
okay which is really nice has something
people are wondering for a long time
this low-level API under hubs we ripped
out the persistent connection API that
was what we had in the old signal that
was prior to HTTP we have a new API
called
endpoints okay and we'll show you some
examples of endpoint endpoints are very
very flexible and there's a now the
building block of essentially what will
become all non-http workloads that run
on Ethernet core which was something
that we aspire to do by the end of the
year we'll use this endpoints API that
we're starting out with in signaler our
supporting multiple protocols and
formats so today signal is basically
just speaks Jason right if you have
signal oh it's always text and it's
always Jason and we own the shape of the
messages in the new world that's going
to be a lot more pluggable so if you're
at the end point a level you can do
whatever you like right you can send
protobuf you can send Jason you can send
custom protocols and your endpoint code
could look the same
no matter what type of connection is
currently connected to it so you can
literally have different connections
from different clients that speak
different languages all go through to
the same endpoint which is kind of nice
you have to write code to do it but out
of the box you can get that but
something like hubs we will most likely
ship both a Jason and a protobuf version
of hubs out of the box and you'll be
able to have a single hub with multiple
different clients talking to it speaking
either
or protobuf which is kind of nice
support for pure WebSocket clients so
today when you build signal I you have a
JavaScript client that we produce and
you use it and you kind of have to use
the client if you don't use the client
it's practically impossible to connect
to a signalized server okay that
requires you have a jQuery dependency
and yadda yadda yadda in the new world
we want to make it possible to say well
if I have a WebSocket if let's assume
the best-case scenario I have a
WebSocket it's full duplex
it has framing it has all these nice
features that we want in a transport
okay let's assume that's the default why
don't we build a system where I can just
connect you with a WebSocket and then as
long as I speak the same protocol as the
endpoint that you've connected to that's
all you should need right you don't need
any other client code from us so that's
what we've done if you want to speak in
a different transport if you want to use
service and events or long polling then
sure you're going to need a small client
library to emulate that connection for
you just like we had in signal or
evolved and then if you want to speak to
hubs you'll need a library that formats
hub messages okay so you can send hub
invocation to the server and you can
receive hyper implications from the
server and maybe even send results back
which is also a new feature that we're
looking at doing so that's kind of nice
and we're going to use some of these
features and some of the demos we have
after these slides so that's the next
thing returning results from client
method invocations one of the first
things that people often ask when they
program the signal are is they type
their code on the server that looks like
it's invoking a method on the client
right clients are all dot something or
client stop this client ID call this
method and they want to get a result
back they expect to be able to get a
result back from the client we never
supported that but David just spent the
last hour and a half hacking that
feature into the new signal autonomy
that we want to do and we have done it
yet I thought what am i grateful you're
done with that can you make that work
yeah and so we actually have I think
something working that climate
demonstrates what that might look like
rebored it's terrible but it's a very
interesting idea to effectively turn
signal rather than being a client-server
technology it's basically just a full
duplex pipe right and it has two parties
and it might be that the server has the
server and your system has lots of
different things connected to it so it
is logically the server but from any
given connections point of view it's
just two parties and they're calling
each other back
thought you're kind of doing RPC back
and forward right opens up some really
interesting programming paradigms
especially when you consider async/await
on the server and async/await in the
client with typescript you can just call
a method in c-sharp that's actually a
typescript method in the client or wait
that and then the client can do some
work as a result of that method being
invoked block on some UI and the client
and then return a result back to the
server who's just sitting in an async
you know state machine waiting for the
result for the client you can block the
entire server from blocking on so now
you could deadlock you with your server
that's pretty good by writing bad
JavaScript we can do that isn't that
great yeah we're not kidding I'm right
thank you so la we were as I said
typescript so we've rewritten the client
from scratch it's a completely new
JavaScript client which is a few written
in typescript and I think the demo that
you're going to show later you actually
broke the code in part script as well so
you get a lovely typescript experience
when writing your client code which is
great and then lastly as I mentioned
before as a result of dumping our or
dropping our one model tries to sue all
scale-out design we have a much we think
much more flexible design for doing
scale up which should allow you to
either drop in pre-configured things
that do scale out in drastically
different ways or write your own scale
out that's really suited to your
particular workload without you having
to reinvent the world which is kind of
nice so what does this look like so in
its basic it's sort of basic
architecture for the low level stuff or
a snake called sockets in general right
at the bottom you have a host okay so
that everything else is host agnostic
really so okay
someone is hosting you all right then
you have transports transports of things
that know how to get bytes out of
something turn them into something that
can be passed further up the stack it's
pretty straightforward
WebSockets is a transport for example
you want have a TCP transport transport
typically or belong to a host right so
HTTP host of some description will speak
various HTTP transports all right now in
existing signaler we only had an HTTP
host and we only had HDD transports okay
we had four of them then you have the
the the gray arrows which David
convinced me or didn't but insisted was
better than another block in there yes
the actual connection object so we do
have a type quarter connection and that
effectively sits in between transports
and endpoints and that's what you
program against inside your endpoint
class so then we have endpoints which is
what you program with if you're building
a low-level thing and then we have this
other thing on the side that you can
optionally use called for matters which
Devo is not quite sure about yet but I
like the idea of a lot and so we're
still having big debates about how far
we'll go with this format I think the
idea is that they're effectively like
serializers but they understand the
connection and they understand metadata
from the connection so a connection can
say hey I've connected on this transport
and I'm going to pass you a string that
says this is the protocol I want to I
want to talk okay independent of the
transport type and then somewhere else
in the system you can say well I'm going
to register a formatter that understands
this protocol name and can produce this
key like this C sharp object so that in
your endpoint you can just say okay I
have a connection I don't care what
protocol it speaks just ask the system
for a formatter that can read the T that
I want all right so your endpoint code
becomes very generic just like control
flow reading your objects writing out
your objects you don't have to worry
about protocols and transports those
types of things you just read and write
T's okay and then all that logic to deal
with bytes and how to turn a bite into
this T and vice versa is all in the
format of system and we have some
examples about it all see that and then
on top of all that is the high level API
that if you've used signal are you
typically would use as hubs okay you
just write hubs and all this other stuff
taken care of for you so with something
like signal R where it's let's plug into
the two different hosts underneath on
the left-hand side we have HTTP
transport so we have web host which is
the API in a spinet call that boots a
snit core and talks HTTP and then on top
of that you have middleware okay that
sits in the ethernet cord request
pipeline and there will be a middleware
it'll basically be the signal our
middleware so all the sockets middleware
I should obtain and it will have a bunch
of transports and the three that we're
going to support a WebSocket server sent
events and long polling for is a frame
the fourth one we have killed no you're
out the back and we beat it to death
iframe was an abomination yay it really
was that was probably the biggest one of
biggest bug farm transit bugs and like
no one uses ie anymore so we're fine
they can use one polling it's all good
it's all good on the right-hand side in
an alternate stack in the same
application I can have a different host
so I have a TCP server I that speaks or
the TCP transport of some description
right and then they both sides of these
both talk to the same hub endpoint that
hub and point code is agnostic to
whoever is giving it bites it doesn't
care right and so this way we can have a
bunch of hubs that you write up in the
top right hand corner that's generally
where you'll live and you can fire up a
TCP server fire up an ethernet core
server or can TCP call it server inside
network maker or server which is kind of
cool and you can accept connections from
different types of clients and you can
imagine extending this to various other
types of transport so we have examples
of MQTT endpoints that speak in PTT
funnily enough AMQP is another protocol
that comes up or you can write your own
custom protocols which we have an
example of here which we'll do in a
minute okay it's time for demos demo
that's all the slides all right so I'm
going to start out with a demo of I hope
works because I'm using like physical
hardware so anything's go wrong this is
basically a board that has a Wi-Fi chip
on it and then a bunch of resistors and
capacitors there's really not much else
on it it's basically a Wi-Fi board that
runs Lua from what of it as far as I
know right this was given to me by a guy
on the signal of team he's been playing
around this and he's actually blogged
about this this last week so if you look
at this and go I had that board at home
this looks amazing
or I like the idea of this then you'll
be able to follow on so I just plugged
it into my machine the way it works is
it actually connects to Wi-Fi so I'm
going to open up the hotspot on my phone
because I can't get it connect to the
conference Wi-Fi so I've been doing this
through my phone actually already on and
I'm going to open putty down here and
I'm going to connect to this profile
here so this is the name of a board it's
the esp8266 knowed something board
something something so I'm going to try
and open it and then I have a lure
initialization script and then I have to
hit the reset button for it to work
currently there we go so it has a Lua
script that runs on boot which connects
it to the Wi-Fi
and so you can see here it has a bunch
of modules it has WebSockets it has
Wi-Fi and some other stuff all right so
then what I'm going to do is I'm going
to run do file and I have a social
weather dot Lua file that's already on
this board and if I've given it enough
time to connect to the Wi-Fi
it's very mean I'm literally talking
over comport to this board right now so
I'm gonna hit enter and I'm going to
hope that it connects to my server in
Asia because I have a server up running
an adder which will see the guy says
it's connected so that's good it's a
good start so I have my app here running
so I'm going to connect another client I
have a c-sharp client here so we'll run
that one so that says it's connected as
well so that's a good start you know
every time I resize this window I regret
it somewhere down here is my text nope
up here come on yeah I lost my text
scroll scroll is there a trick what you
do I resize the window under you I'll
control f5 again and just live with it
being big how's that out all right so
that's that and then over here somewhere
I have the actual server app so let's
reboot that alright so I have my web app
running up in Asia and I have my lure
board connected over my phone's Wi-Fi
and then I have a c-sharp app running on
the console if I come up here and hit
send report if all goes well they all
update which they did which is great ok
now what's interesting here that you
can't see is they're all speaking
different protocols alright so the
JavaScript in this page is speaking
Jason that's sending Jason back and
forth a pretty standard if you've ever
done signals that's what it does
the c-sharp app is actually using
protobufs anyone use protobuf in any of
their stuff ok a few hands ok so
protobuf what our protocol buffers was
made by Google and it's a very a binary
format very highly packed very highly
all laid out nicely for running over the
wire and there's a c-sharp library for
it and you basically decline a decline
you define a shape of your thing like
this using a dot profile and then it
generates c-sharp for you ok so this
program here is using protobuf opening
up a WebSocket connection you can see
down here client web socket and
speaking protobuf over that means not
much code like it's pretty
straightforward and then when it gets
the message from the server over here it
spits it out in the in the console and
if I hit enter over here it'll send so I
can hit enter and it sends one and I
should share that one get updated over
here and I should see this one I got a
second one down here under the last one
which is a Lua script is speaking a
custom protocol it's actually a pipe
delimited protocol that's just written
into this into this application and so
I've got a little command here that I
have to run so I have to send over the
active WebSocket so I'll see WebSocket
send and then there's a pipe delimited
protocol I send the the temperature in
Fahrenheit so I'll say it's 44 degrees I
don't know what it is I don't know
Fahrenheit
- which I think is the weather it's
partly cloudy or sunny or something like
that zero which is I think V I can't
remember it's something else it's
there's four fields one two and maybe
it's the client I can't remember and the
last one is the zip code and I'll just
use the redmond zip code then I have to
end that with a new line and then I'll
close that off and so I'm just typing
into my comport down here now if I send
that that went up to the server came
back down to this client and was also
reported out over here in the prototype
client and it was updated here in my
page over here okay so I've got three
different clients using three different
languages and three different protocols
and three different connection
techniques all speaking to the same
endpoint so what does the endpoint code
look like because that's really what it
comes down to is you want your endpoint
to be fairly straightforward right let's
zoom this in a bit alright we're not
done I don't know how much that's like
that's way too much my control seems a
little over zealous there all right so
effectively I have my endpoint derived
from endpoint here I get in this
persistent connection lifetime manager
thing all this API is very much in
progress okay so what are these types
only exists in this sample right because
we're literally building apps writing
boilerplate and then deciding what
boilerplate we want to get rid of okay
so there's a lot of stuff spread out all
over the place but the concept of an
endpoint is pretty solid that's going to
stick around all right we have this idea
but thing called a format
resolve this is the thing I will use to
get the various to say when I want to
read a tee off the wire please plan the
right format for that and then a logger
so I can log stuff out when someone
connects to this end point I get a
connection object I register it with the
lifetime manager so I can track these
connections pretty simple
then I await process requests and you
can see this looks a lot like socket
programming you're basically just sit in
a loop and you read stuff off the socket
okay so if you ever done TCP socket
programming this is pretty similar
except this is a think it's just a nice
async/await read loop which makes it
much much nicer so now that I'm in here
on ER a certain route certain connection
reading requests I say get me the
formatter for the weather report please
which is my c-sharp type that I created
and passed in metadata from the
connection so we could look up the right
formatter and then sit in the while loop
and say please read me off the current
connection a message which is a new
low-level primitive it's what you get
off connections as a message I have a
buffer on it and then I copy from that
buffer into a memory stream so I can
pass that memory stream through to the
formatter and have the formatter read
the bytes in that stream and turn them
into what I asked for which was a
weather report so this is a little
clunky right now I'd like this to really
sort of be like two lines of code rather
than the four or five it is now but you
get the idea and then finally once I've
read that I can turn around and say to
my lifetime manager please send this
weather report to all the other clients
to a listening right now okay pretty
straightforward really really simple to
do none of the nasty pausing stuff is in
here this is just the basic control flow
it's kind of like you can your
controller right in MVC all the other
stuff was like dealing with the input
and output like that would usually be a
model binder or a formatter in MVC world
very similar here so my formatter for my
weather report is here somewhere up here
protobuf weather stream so here's the
one that speaks protobufs so I have a
formatter for weather report per
protocols I've got one for Jason one for
protobufs and one for my custom pipe
delimited ones so here it is here here's
the custom one I wrote for pipe it's
kind of like a serializer if you've ever
written a serializer in.net for a
specific type and you serialize to xml
and or something else or you see all
those two jason or something else
because these are all being sort of
coordinate
by a single single thing called the
format a resolver so yeah that's kind of
cool
poppin all right so I know you've got
some demos now fellow hack stuff is
probably going to work a lot where kind
of devil if we switch over to the other
machine please
alright let's kind of go the fate of
very nice very nice
so some very professional so I thought
was your Mac I feel relaxed as a Mac I
realized fades in when everything else
so this is a sigma solution on its neck
or as we speak right now is very
experimental there's tons of stuff on
here that doesn't work in fact you
coined it in about three hours ago
wasn't it completely broken it's still
kind of cool to be broken by smoke and
mirrors you can't tell so I have a
sample here called it's Apple it
has a very basic setup for a socket
wrench Sigler let's look at the start
pops this the something so I did so
ignore these for now so kind of ignore
this I had socket which is like the the
services required for for its neck or
socket I add signal error and I can say
I want to add these for matters which
are called implication ad absurdum
reasons but they kind of still in very
much in flight ignores this kind of the
stuff is just a lot of things that can
see ads and stuff I can talk heard above
our taught lines and these are kind of a
very Sigma specific for matter for the
invocations so I guess this is kind of
method name this is the result so you
have a looked at the traffic in a signal
or app like you look at the Jason has
like a knob a method a for M method a
for I right Lang right kind of same
thing but are different or much yeah
yeah so there's an advisory that's that
is comes it out for scale up later I
will show as a bunch of stuff out of
that services I've not for now and
configure
there's a new app that you signaler
which takes roads and now you're mapping
individual hugs to individually um you
have actual route it's a route builder
yes nice so we actually use routing to
map and individual hubs two endpoints
versus the old model where you had a
slash house by default that was there
for all all hugs I'm a big change from
before the lower level API is you
sockets and you still map and points
with you you re still map the URL with
the amount employees are hubs the wave
map hubs works is map hub actually calls
map endpoint and it mapped the hub
endpoint so every single help you get to
and point it's kind of a nice model for
composing this kind of system let's run
a sample and see what it does
wearing you think cattle directly and I
think I have luck and turned on because
logging is awesome
let's see there's a messaging a sample
and a signal example next thing this has
a raw endpoint that does kind of a chat
but with raw endpoint and it has
different transports all I'll boot up
all three service in event so you get to
see on the screen know up today long
polling here and WebSocket it feels like
five years ago
oh my god same demo memory see website
if it's kind of broken oh it works now
perfect of good they say hi okay
nothing but up oh let's talk this part
just refer tend if it works like this
pretend everything is God daily super
brainless debug on stage nope there's
some stuff I said open so exactly oh my
gosh is completely busted but just a
 it
so every else works it's kind of nice so
it's a it's a chat pretty basic example
for hubs is the same thing that there's
a clock sample that just pumps octet
connect I come to that OneNote let's
skip the phones to chat for now chat is
working oh god that's a little button so
it just works
oh yeah wonderful my pockets works fine
I can do this open up a new URL hit
transport long folding put these
side-by-side connect this side works do
one more do server-sent events connect
this zob warrior because i'll just like
this little stuff it always works so
it's a code look the same as before
little bit the code we look at a little
bit different then maybe the endpoint
code so tad bit different okay all right
let's start off the ten point so I have
an endpoints folder here over the net
with one endpoint commented endpoint and
what it does it has a connection list
because I want to throw all connections
I can do a loop and then broadcast for
each one in previous Sigma we had a bus
as Damien was saying so broadcast really
was like a publish to that bus and that
bus was pluggable so if you're if you
want Redis it was a publisher editor if
you're on a bus service bus in this
model we want to be because one bus up
altogether so what we did was we made it
so we made it feel more like a TPP so
when you joined so when a question guess
get about to an endpoint you can score
lift up connections and then just do a
for loop and call broadcast which one so
the old signal was much more of a very
high fabric lab system at its heart but
you you dealt with it like pub/sub this
is much more akin to what we're really
trying to go for originally but we never
did which was just it looks like I'm
programming on sockets I don't know
who's feeding me this locket I don't
know if it's TCP or something else but
it's just a socket and so this is really
getting us closer to that so in that
world
this is stateful like this connection
object this endpoint I have I'm going to
get this connection per connection and I
can put them away on the server in
memory accordingly and list and if I
want to broadcast I just go and go
through them now if you want to build a
pub sub system on top of that you can
and we did that with hard hubs is
actually based on pub sub and that's
what enables us to make it very easy now
I plug in other things but at this layer
you just get ecology Lister's or
something you can or you don't have to
use if you don't want to you just have
an endpoint you get a connection and you
write a while loop and everything else
is up to you all the magic is in the
transports underneath if it came in on
WebSockets you don't know if it came in
a long polling you don't know we take
care of all that the transport you just
focus on writing your while loop by
typically so the reason that sticky it's
important is because since your stats
all you have to be on the same server
for all connections this list if it was
on one server and then you fit servers
you wouldn't get the same list of
Corrections
oh no Colin so it's like socket
programming exactly so let's put a
breakpoint see you how this whole thing
works hit f5
let's do this much work just in a bit
loading very slowly then it connects
today perfect so whenever - comes in the
the hosting layer tells the transport
hey tension joined a crit section called
unconnected async and this code is
supposed to run for as long as a
question is life so when it stops
returns it means that the connection is
dead so in it so might end point I throw
this term connections for the endpoint
itself and then it broadcast to all
connections that sometimes joined all
this does is it right horrible ugly code
ignore that buffer stuff for no it is a
for loop and does write AT&amp;amp;T mention the
underlying API that we're using is a new
API called channels it's in core FX lab
if you've never heard of corpus lab it's
kind of a playground for experimental
features in.net
we actually some of them are becoming
very much less experiment tomorrow yeah
some are becoming real somewhere
somewhere just there for fun
so core FX lab done it quickest love
there's a bunch of things on here
they're kind of cool I'm the one to
think they're on here is a system
threading tasks channels and this is
what we build Sigma on top of well focus
on top hooks and what it basically is if
anyone use goes channels go has channels
they don't any when you go yeah right
yeah she knows I'm from a bicycle on
that I mean just think about it as a
formalized way to do a publish and
consume a model so you get a readable
channel on a writable channel and once
it does bright one one still is read and
you can push out about objects back and
forth between the booster and consumer
so the way it works and in socket is the
endpoint is kind of the middleman if you
can actually your place your so I can
kind of show that um I think into your
slide right now keep it up as we flip
back to the other screen please mister
tech no no no
almost okay
no okay sorry that's that's fine so the
endpoint itself has to transport and the
transport hazardous all right so the
endpoints have a transport and the
transports have the endpoints a channel
so you have so each each side has one
side of the others so the transport is
reading from the application and right
into the actual socket and the
applications in the transport are into
the actual application so foot back
light by the machine that place thank
you
so when you do a write you do transport
and the different way to consume the
actual data you can do writing read a
sink right I think after you throw if if
the connection is gone so so to avoid
that I did a away wait to write a string
and then try right
this pattern just like you not throw
exceptions up for channel closes so this
code just says I'm going to loop over
every connection and then try to write
each one as it comes by does that right
click succeeds it just breaks up break
into the link keeps going it's a very
simple loop if I send data hey it does
wait for read yield I get the message
back from the channel I put in the you
think is disposable and I broadcast so
it's very simple pattern we remove the
connection which group when it goes away
when the connection itself dies select I
close this brother if s is a hat out by
design simplicity supports what kind of
crash the whole thing unwinds and it's
cleaned up normally that's a very simple
and point obvious showed on this end
point code works for any transport so if
I were to make the TTB transport or the
WebSocket is long polling whatever
transport all the same code where all
things it's a transfers job to take the
actual data from the underlying network
and socket enter into a message object
that's passed on to the actual arm
transfer connection so to show you some
code Acton Sigler itself may be the most
simple code shows like server sent
events
some sockets if you look at the
dispatcher and just put it all they
create Lisa doesn't look too hard when
data comes in from the from the TV
connection for a slash send we find the
connection society and we just call wait
to write a link so remember I told you
that the the the transfer itself has the
application so so the transport says I'm
going to wait to write on the
application and then call try write on
the applications channel so that will
yield the the reading on the other side
of the Army's got two sides
I'm the transport you're the application
I call write someone you call read
someone gave me a message ship you've
called read and then I call write on you
giving your read releases release get
nothing get better and I go back to
listening yep things over here sample
rate and the other way around if we
reverse it if you look at the service
internet chance for it pretty simple
there's a wall of all appear as it says
wait to read from the application and
whenever I read data I just end it over
the wall once in socket burg
all my up forever here we are loop
primitives that just as luke loop
members I wigs it or anything you just
have to throw or break and that sounds
awful it's while true and like
everywhere in this code like I guess
someone's while away that's not too bad
a lot of it yeah well long us still lot
still luxurious basically Walter yeah
lovers but that's very simple if you
look at the code in signalized that we
had to write before async/await
right and before we had this quite a
socket layer it was horrific like we had
jumps we had go to I'm not kidding you
it was actually the easiest way to do
when they think about the got is you
write the go-to like I'm not listed
pocket alright I go to Bob Hazen is
awesome it was the only way to make that
code maintain a ball to the fact and it
was very fast because when I stack
frames it was always in the same stack
frame so all right so let's show
something a little bit different let's
show TCP transport so I have this end
point message that point CMM point I'll
be happen before I'm going to run again
the server and if you look closely at
the logs for those of you who saw it
this thing right here starting PPP
you see it because this is TCP service
running in the application that starts
on fly closer than two so this new
feature internet core isn't I mean in
Internet core 2.0 that isn't really out
in the future in the future it doesn't
example come out called a hosted service
so trying to refactor it's in a core to
be more non HTTP based model so you can
host you know your other thing pvp
endpoints here
so especially a server host yeah server
host a generic server host a second of
any pain points any server it could be
background code it clock round code yep
another socket can be anything because
part of that we added a new API called I
hosted service to look at my chart class
if you add one of these things you get
called I never start but whenever we
boot the application we call start never
we care don't you call stop so it's very
simple interface like it's nothing it's
the start stop
what if you do is you have a place to
write code no that kind of runs for non
HDB things so background things like for
example this clock example i inject an
eye hub context which is very similar a
few decimal before we can get the Sigler
quiet aside in the hub itself it's kind
of like a singleton that subscribes to
the last time foundation but gets
resolved immediately also right right
yeah it's a very stable thing that
traffic connections so you can actually
broadcast them on demand for the clock
service just it's Michael to service
itself I would never start hopping I
make a timer and on tick I just
broadcast to the all client set or
listening and I'll stop I dispose
so when you have di so you just yeah I
can eject all context that you want it
very clean waiting to get services and
do an on HTTP thing in the same
application space on top of that I just
built this like five minutes ago this TV
people to serve it like very tcp car
service tcp this is the one we're going
to ship it says adrian let's see is
awesome it's beautiful it's pushing code
all right so what this thing does it
just takes an endpoint type which is any
endpoint type in your system and it
resolves it in the container first thing
it does wanna start it creates a new age
and you tcp listener and it runs this
loop but it says get connections
whenever that happens run don't do this
very often the funeral you're doing as
off awesome whenever a client comes in
it creates two connections one for the
transport off the application simply
speak up before
then it makes a new connection object
cause the end point the end point on
that today sink get the network stream
and then starts to task that's say I'm
going to continually recent reefing the
application Emmerich's to transport and
vice versa so this is effectively it's
full duplex i/o the device I can be
reading and writing at the same time
which is why there's always like to see
two things from the same time okay and
then basically this thing is trying to
shut down gracefully in case anything
dies so if you if the read died is kill
the entire thing at the right let's cut
the entire thing at the app by first
kill the entire thing so very complex
feeling yeah yeah that's risky
language and then the loot looks like
this I have right to transport it if we
take a network stream reads by top of it
1k of bytes and then it says I'm going
to call transfer dot right and this will
this will call the same code in the
actual endpoint saying I got there from
some other transfer way so why should be
able to do now is connect from WebSocket
just work it it's working out perfect I
touch it
meltem putty and then I'll launch this
thing
so now you've connected to a socket suck
it
okay okay okay here this work oh wow
so it's better going over the socket and
it should print out yeah there you go
 server HTTP hosted service three
bytes came in from the connection so
again it's it's a single endpoint single
point
you wrote one import my same update in
middleware and you'll maps it to TCP yep
so that's one place where you write the
code for the endpoint okay it's the same
instance so the state is the same
usually the same instance of the class
yeah so the foil is going over at the
TCP connection and the one from the
browser and but very undoing a broad
cache so unified API same model
different different um so this is part
of a bigger effort that was going on is
in a net core sort of to and beyond that
we want to take a lot of the one of the
primitives and ideas that we built for a
spinet core logging configuration
hosting di pipelines for middleware
configuration all the patterns options
building blah blah blah we want to take
all those things and wrap it up and use
it outside of HTTP because we don't
always speak HTTP right especially in
the world of soccer and containers and
IOT and Microsoft is at and pub/sub and
all that type of stuff we want to take
all that nice goodness that we did
loading cloud applications and spread it
out to other things and this is the very
very early beginnings of this very very
early but you can see the potential here
so that was kind of cool
okay so hub hub hubs so hubs are a
little bit different but just enough to
anybody free to annoy you differently
right but they're pretty slow for you to
be we kind of got over dynamic it was
kind of cool kind of gimmicky and kind
of nice to look at but hard to look at
hard to debug hard to get a sense for so
you have this wonderful method called
invoke I think that in the string it's
not trying to at all but you can't get a
job then we plan to have support for a
hub of T do we not have that yet no like
okay we're going to have that yeah
somebody fault today hub is help give
you a client object and plan to all
clients out-group client sought client
clients whatever we have from before
everything's all that stuff that group
oh good intellisense that's a bug you
know this is a bug all because of waits
on the next line yeah yeah clients
thought so all is client there's group
remember to move the code about when you
finish it's fine right be a fix up for
that move code one-liner bonus and this
property is typed to whatever the T is
here right all right so if I do have
dynamic in the future you can get your
old code right we actually had that in
old signal alright we added support for
T of get my own hub yeah so we just have
my own use that by the way in the or
signaler you can normally talk you can
declare an interface public interface my
client my client stuff it could be hello
and you can see a hub of I client stuff
anyone have used that in the old signal
signal or - yeah so that will be the
basis of the new signal are instead of
dynamic being the default it'll be the
string based in change one Wizards fault
they'll only hit the ching this one
prefer dynamic I mean so will support
dynamic you can pass into amicus of T so
you'll always be able to get back to
that so if you're porting an app you
don't want to change it you'll just be
able to derive from harbor dynamic
instead of yeah yep put your code is do
have a dynamic and I and be happy that
over time you can get
Bugman right another close um okay so we
call things they think no and in Sigma
everyone we had to Virgin to calling
things a thing I don't know why it would
be native but we were kind of hardcore
but I really the whole thing's a saint
we can't call anything no we do because
everyone knows does so you know whatever
invocation is what's called skin api so
look pretty similar so on connected all
in both clients are all that invoke a
singly because of broadcast his same
idea of blah left blood joins send sent
a groove join group different those
methods are just ones on your hub right
but the clients are going to call those
ones right so that's the other ones are
overrides yeah exactly so run this again
our bill uses gulp and it destroys the
performance with the bill
this one does basically should make a
increment look at this thing we should
make it incremental the worst thing ever
sender use gulp how do you do don't hook
any name is bill look at this thing it's
like 17 seconds 17 seconds to Dooley
nothing good node looks Weiss
I'm time to think it's not gulping it's
just the way it's configured in the date
build scripts are we holding our own
we're probably holding it wrong okay all
right there at the hub I took a
breakpoint shouldn't a nice lie if you
want to say anything this is a great
point okay protip the last that the
first one is always the correct one
dozen matter what is it's the first one
in the list if you have more than one
it's always the first one I best right
look at it always is I always it I
didn't believe you do that every time
rather than trying to look up the
process ID and stuff I just tweak the
first one it's probably is right so I
can trust me
alright so hit f5 the client went away
connection left
connect somebody joined very basic I'll
do a broadcast everyone reaches me again
apply at all I will send to a group this
is the worse like ey ever it's the same
as the really bad you why we wrote for
the first
they still haven't we did I copied the
code literally took the phone well this
is the message and I think this is the
group name so I shouldn't get anything
now send the group wonderful on to join
a group I say group I click the joint C
group button
look you guys pretty you'd join group
you haven't got any better doing you
eyes in five years I know yeah
looks like now I'm in the group so it
works it's pretty cool so signor hasn't
changed out that much a few few tweaks
groups got a group remove one big change
we made you can only ask the group
inside the hub itself groups are super
hard so yeah so it's one of those areas
we have a big bug farm in the old stuff
and yeah the biggest issues we
still have is in the old world groups
was a think because when you add it to a
group or remove from a group it sent a
message through the bus so that you
could add as a client that was on a
different server to a group or remove
them from a group but that required that
they get a message and send an ACK and
that meant that a lot of people would
like a wait groups like you're doing
here actually and it would hang because
you want a wet group by add that and
then sent it then it seems as if maybe
rear-ended roses they get that message
right if you have a two servers and a
client over here client over here and
you groups that add on that client over
there and the server goes down when you
I wait the way and you await the group
dies what you never get like you'll get
every 30-second timeout but who time
though and it was like a bug farm so
there you go yeah I mean even what just
wasn't what people expected yeah thanks
so we got rid of that for now we'll see
what people will see how people react to
it but react nothing they don't care
good we're fine alright so other sample
I plot service you get stops before it
does a tick every second and principal
ticks so same application background
service here's a clock and differently
long folding well I'll point it because
why not goes why not
now is it real hub we're still in hub so
the hub okay
looking back on service the clock
service is broadcasting every second the
tick's to all the clients in sync
yeah that's pretty basic in the old
world to do that you had to call a
static API yep Global horse that gets
updated with the horse is dead
we have Janus of using a 2d limo
struggling yeah so now you're just
basically here statics so if you statics
you're not going to like us anymore we
do Gotham you can't test seaguar don't
need statics anymore in HMA yeah we're
so it's fine all right so we should be
to each other
we got scale out to create I'll scale oh
ok the imperfect lane demo to try if I
ready let's get ready your arm so I'm
going to do this magic line anyone use
Redis today with Sigma so scale that
just like mine where who ad already we
need something else so scale out the
signal Siegel server thing whatsoever
yep service bus you know no one okay
there's less key treat everyone else
isn't scaling out that I've this one one
server doesn't you signal others to you
to take a nap okay cool
okay let's see what I can do so Redis
via chocolaty is the best thing ever
reddish server
front of server Redis CLI let's monitor
what's happening launch the application
you're running too late put this up or
off my fingers
building go you could have commented
that stuff out for the purposes of the
demo by the way we use typescript which
is beautiful it is view is wonderful
yeah they think away is like the best
thing who's using tip you're doing
client-side color he's not even tax rate
yet but thinks they probably should at
some point okay okay you really like you
need to be assured I was a ionically
high high tech sector and then I
converted I thought I was lying now I am
a full convert alright so let's look at
the monitor because that shows actually
what happened was happening oh the clock
the clock clock is destroying the the
money I won't win zoom and you could
turn it off let me cook clock play it
off and reboot through my link up run
again
dead that air dead time typescript yeah
very nice they sink a wave yeah oh no I
didn't use it cuz it worked somewhere
else yeah I'd use it it's in the client
it's in the clients all over the client
so we use it sink away it like
everywhere if I could find it somewhere
there's anything start oh my gosh
prepared okay over finished whatever you
are ready there's a bunch of sleep stuff
happening here we are again
oh client what I own on here I see okay
clock is dead perfect
good okay let's open up hubs connect so
quiet connects and we subscribe to
inventors itself we subscribe to the
individual signals that for that
specific connection so this is a big
difference from last time right so now
the server has one connection to Rytas
which is the same as last time but it
has multiple subscriptions we also to a
dynamic write multiple subscriptions to
writers to pub/sub which are dynamic
based on the connections that connect
right in the signals that come up so
like a hub is a signal to sockets
sampled a hub search at any groups any
connection IDs they're all different
signal area and we basically dynamically
create and destroy subscriptions to
write us on the fly so that any given
server is only subscribing to the
messages that it has clients that care
about that's the big change from prior
versions and this is kind of one
implementation we had one where we had a
row discussion for every connection on
the right client which is kind of insane
but of probably those it works
apparently it is yeah yeah but this is
one connection multiple subscriptions
you could do a connection per client
right which we did do and it worked but
we think there's a little nicer so I
said to the send broadcast la publish
curators if I disconnect the client
sometimes very live in the actual things
and without works if you have a new
abstraction in signal are called
a bad name it's a it's a very name
we'll come up with a bed in the hub like
my manager and what difference does give
you full control of the entire lifecycle
of the hub so anytime someone joins a
hub anytime someone's connection one hub
anything someone import anything from a
hub it goes through this abstraction
basically when your Navi clients thought
anything maaan anything goes anything
goes through this thing right and so you
can just replace this thing and take
over complete control of how hubs send
their messages this is how you do scale
out now all right your buddy's getting
under the covers ready fault default
annotation as an example has a list of
connections and whenever everyone you
mean yep yep all my someone joins we
just add to the list when someone
removes you from the list for a
broadcast we do a fourth overall
connections that are currently on on
that server and we just send all sent
each one of them yep that's kind of a
bit very basic implementation you could
have one that use the old model where
you had a bus so the whole idea is that
you can implement different kinds of
strategies based on what you think is
best for your hub documentation and this
is all the hub layer previously dis
underpinned all the signal uh right
but the sockets layers they said we're
really trying to go for the computer
socket like abstraction which has
transports that our pluggable but we're
not opinionated about this type of thing
like you would if you want to do this at
the endpoint layer you would just create
another type take that into your
endpoint and just funnel everything
through yourself that's what the hub in
point the hub endpoint literally has one
of these whatever one was registered
creates it and funnels everything
through it and does all the hub
discovery and that's basically the hub
endpoint no you write a quads a skillet
that was like sequel yeah so I'm at a
different scale at provider that used
sequel server to store a table of active
connections so you could actually query
the database and say just give me all
the connections that there are right now
give me their user names give me all the
signals there that they're interested in
and then it connected to Raiders to
actually do the sending of messages
right so it was a stateful scale-out
system where state was in a persistent
thing and all the messages went through
writers so it's a super flexible now and
there's not a lot of code like great
fault one is a couple hundred lines the
reddest one is probably less than the
quadratus is pretty simple simple
whereas the old message bar system was
horribly complements in and went through
many many iterations to try and make it
better and less bug pronestyl buggy and
it still buggy I mean it works fine the
scale that one in particular was
particularly complicated um okay a
couple harmless 300 business Redis
there's a bunch of stuff an example of
what groups do whenever you add join a
group in Redis it adds it adds a
subscription to that connection in Redis
so if we look at the thing here and I
and I join a group actually join gufu
disconnect in the connect first join
group subscribes to focus on salute at
gufu and I can broadcast to that group
since a group go through Redis for the
publish so you have full control of the
entire lifecycle of of every four up
connect disconnects sends receives the
entire thing we want to enable you to
taxi round-trip data to the client in
case you want to round-trip cursors if
you want to apply implement you're on
somebody for four reconnect and you can
round-trip you the last cursor you solve
for messages you can actually get the
entire cycle in the lifetime I could
effectively get back to the old signal
our behavior yeah because we're going to
add enough hooks for you to do that so I
won't say reliable messaging but you
know commissioning and okay so you've
got one last thing so there's a minute
in the harbor general okay so 60 seconds
this dental makes no sense but let's
just do anyway so remember I said that
what we wanted to enable was the ability
to when you invoke a method in a client
to get a result back alright which is
kind of crazy on the server I invoke
some browser and I get a result back we
hacked something to go Fowler hacks on
imagine you want to use an image
leverage because there's no network and
you want to invoke JavaScript in a
browser and send the image back okay
ridiculous but nothing is magic yeah why
would you want to use that just use
what's in the browser right so actually
when we first built signal I'll Phil
hack the first happy right was how do I
get stuff back from the client I'm
trying to build a game and I want the
server to say ask a question from all
the clients and just sit there and wait
until the clients an earlier crazy and
we thought he was crazy and that fly
these later we're building it so I
finally so Phil is right Phil was right
it's actually pretty cool let's put a
break my hair so game needs to two
players
let's client to clients the person
always let augment it perfect all right
two brothers okay
game the civil button disabled their
game here
alright the button should become enabled
at some point so it's a breakpoint it's
going to start the game so it invokes on
all clients in the game so far the asked
question Matt asked and it doesn't win
any say now when any of those half yield
summer one alright so the first little
button when it's the game
so since I'm doing myself this is going
to be super dumb but if I'm fast enough
I can win so I click me and the task
videos but with that that actually a wit
that away it was like waiting on the
client to respond I think earnest but
it's actually sitting they waited she
just way too small this is blow your
mind this is a crazed way on the clan to
respond so the client responded with a
click button and then it used to happen
stuff from the server and we get a
result back and somebody one connection
nine one seven congratulations you won
even the price right and then if I hit a
five you win yeah the other one who's
alright that's it
can we put back to this machine please
just for the end here got one more slide
alright so the timeline for this is as
you can probably tell this is in
development right now we are hope to
preview this about mid this year and I
with a goal to release it by the end of
the year so a speed of 200 is currently
slated for around the middle of the year
so we're targeting this will not release
at a cm at the same time there's a lot
this is too much work to do and it's
being underpinned by a whole bunch of
stuff in FX labs which just isn't ready
yet but we're we're hoping that by the
end of the year signal our encore and
the stuff underneath will be ready if
you want to track along with the madness
as it is right now while we still figure
all this stuff out you can do that on
github
we're active development there's a team
of like 4 people working on this every
day right now at slash HDNet slash
signal so thanks very much for coming
and putting up with the craziness it is
a work in progress project but yet this
is the last talk and we'll see you all
guys next year so thanks</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>