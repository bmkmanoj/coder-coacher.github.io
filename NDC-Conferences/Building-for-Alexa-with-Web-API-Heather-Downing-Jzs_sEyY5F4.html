<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Building for Alexa with Web API - Heather Downing | Coder Coacher - Coaching Coders</title><meta content="Building for Alexa with Web API - Heather Downing - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Building for Alexa with Web API - Heather Downing</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Jzs_sEyY5F4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">Alexa tell NDC aza to say hello there
was a problem with the requested skills
response doesn't that sound like every
single debug session ever hello welcome
my name is Heather downing and thank you
for joining me to talk about Alexa I
actually do all sorts of things in voice
in case you were interested so I do
things on Google assistant as well as
some Siri work I've done many years of
mobile development and I've gotten to
work fortunately on some fantastic
projects right from the get-go so when I
started as an intern my very first
project was a very well-known American
company that would do your taxes for you
and I had no idea what I was getting
myself into but ever since then I've
never looked back and I like solving
problems in the enterprise world well I
really enjoy doing little side projects
from little hello world style and code I
found that it's not usually applicable
to the real world would you say that's
also the case yes so the kinds of things
in woods teach today is a little bit
more about how we make things easier and
how easy it is to integrate with Alexa
itself since it is such a popular
platform if you're interested in
following me I have some social media
links up there and at the end I'll give
you a bitly link to this deck in case
you want to use it for reference so
let's get started
this is an interesting statistic I'll
throw a few of them in front of your
face but 30% of our interactions they're
seeing will be through conversations
with smart machines I actually think
that's probably a little bit
conservative we already talked to our
personal assistants on our phones now so
when we say through voice we're actually
not talking about mobile we're just
talking about standalone voice activated
devices are purely just to be in a
neutral place in the home or perhaps in
a business that's a pretty big
significant number so since that is
growing and growing year by year and
there are over 12,000 skills right now
in the Alexa scopes or
why aren't we more excited about that I
love that personally loved the keynote
earlier from yesterday because he kind
of demonstrated a little bit of
frustration that we experienced when you
talk to a voice assistant 69 percent of
the around 7000 Alexa custom skills
alone have one or no customer reviews
ouch
that is not good for something that has
so much potential there's an example of
one of the reviews I have a brand new
$80,000 vehicle and all they can do so
far is have her lock his doors and he
can't actually check if they're locked
or not what's interesting is that this
user goes on to say I know it's probably
not the platform which would be we would
call a power user or user who's well
informed as to what his technology can
do I know that BMW just simply hasn't
made their skill smart enough yet
so again the technology is available but
the decisions that we make maybe aren't
that great so I'm going to give you kind
of a two-for-one in this presentation
I'm going to give you a little bit about
why you should do a skill and how you
should think about it and then we're
going to build one so I'm going to you
great before I go too far
my mom doesn't believe I actually speak
technically so I would love to take a
picture of all of you if you wouldn't
mind release them three two one
Oh nobody sees their arms up I'm
disappointed perfect so let's get down
to the Rat Pack shall we
why should you build for voice this is a
question I get asked all the time I'm
a.net developer and like why should we
stray at all from what we're doing now
it's just a fad it's just going to go
away right yes just like the internet
was a fad to the sears CEO and that's
why they didn't have an online presence
and then Amazon swooped in and took away
all of their online shopping business or
maybe another well-known company that
said Mobile is a fad is really going to
go away and then entered the market
years too late to really take the market
share when it comes down to what we
invest our time in is developers the
first time I saw like a really good
platform which is one we're going to
talk about
today I got excited because I felt like
now we have a lot more direct contact
with our user there is no visual
interface that means that we are more
responsible for the communication than
ever that's why this is a game changer
voice has been around for years right it
has been around who has ever called up
their utility company and gotten to
voice prompts right is that not terrible
you go through 40 of these questions and
make you feel like you're on a night
crime television show and you never get
to the person that you want and finally
you just ask to the operator
so that's IVR right those are voice
prompts that don't really have any sort
of intelligence behind them but because
we are in the age of machine learning we
can actually hook this whole interface
up directly to some of those options to
have a better experience and give us
more insight as to what the users
actually going through remember that
longer lasting products have tapped into
some sort of basic utility that when
applied to the technology have actually
made their life better so for example
right now the most popular
Alexus skill that is out there that is
in the e-commerce world is Domino's so
Domino's Pizza has thought this really
well through and in the first quarter of
2017 they took an additional 8% of the
overall market share in the pizza world
I mean that's crazy just because of
their voice interface work because they
thought about would this be better how
long does it take to use this on my
phone or call somebody what if they
already had a profile stage and all they
had to do was ask to read order a pizza
and confirm that they want it now I mean
that was huge that Inc that convenience
has kind of led to a little bit of a
renaissance in terms of the voice
interface world because again it's been
around for a while but it didn't really
have a good way to be built until a few
of these products stepped forward so
when we talk about the right way to
build voice these are some Maxim's that
Paul Grice has come up with right I
would say he is sort of the father
in a way of modern correct voice
communication all right he says there
are four things you really need to do in
order to have it be effective you need
to make sure that your quality is there
make sure that it's a very truthful
interaction with your user that your
quantity is very minimal so you don't
want to go on and on and on and drone on
for a long time as if this was a script
from Lord of the Rings
you need to make sure that you just say
just enough to let the user get a word
in edgewise right you need to make sure
it's relevant to the situation because I
I work at a company that right now deals
with brands all over the world
so we have we're responsible for Wendy's
or responsible for Ford Motors
responsible for lots of these huge
companies and it was very important at
this point that we say you this skill is
not a walking or talking advertisement
for you this is how you directly
communicate with your user and of course
lastly the manner in which you do it
being very very clear sometimes because
we are trying to be overly precise we
lose clarity because we think the way
our computers think right and sometimes
that comes across as cumbersome to the
people who try to use a skill so what
good is it for you to build a skill that
I send you guys off with today without
knowing these Maxim's you won't be
successful unless you think about them
if you take away nothing else from the
session just know this we do not train
our users in voice voice is natural
therefore we have to make the experience
natural there's not it's not intuition
it's just nature therefore do not train
your user how to use your skill make
sense ok so let's go over the
co-operative principle shall we
this is kind of what a common pathway
might look like and sure many of you
probably have a voice and active device
right so the happy path we might think
of when we're building this is you know
the user might say set an alarm and you
say ok for win and you say Tuesday at 6
a.m. because all the context is within
that respond
right and the UI might say yes done your
alarm set for to physics a.m. but if you
think about somebody who might be
getting ready in the morning and maybe
they have little ones or maybe you just
have a lot of animals I have horses but
you know some people have little dogs
running around and they're trying to
make sure everything is going according
to plan
people use voice 10 to multitask so they
may only give you part of the context as
you see over here
so much more cooperative way to do this
instead of putting your hand up and
saying I'm sorry I didn't understand
what you were saying kind of like what
we did right in the very beginning here
is that okay if they give you part of
your information take it and then
clarify or ask for the additional piece
don't completely outright reject the
path because that's not really how we
talk if you glean anything from what
another person is saying to you you gain
a little bit of context use that context
when you build your skills and people
are more likely to be able to use it so
conversational implicature have anybody
ever heard of this before all right
here's a good example Jacob says I
really need a drink and Todd might say
well have you been to the Scotsman this
kind of response is something that is
comfortable for us there's a lot that is
implied by this response right first of
all if we were to code this how would we
think about it does that look like a
question or a statement it looks like a
statement I need a drink
what you're really saying is I need a
drink and you are asking or begging for
a suggestion right that is the way that
we are in envision parts the world that
might be a little different that's the
way we are in our culture right we have
all of these little isms that is to be
known that is either verbal in some sort
of brevity or nonverbal so what is
implied by this statement is that the
Scots are served drinks the drinks
alcoholic The Scotsman is open for
business it's nearby and it's someplace
that I might really like right because
what is also implied by here is that
when Jacob said that I was standing
right next to him
so you don't have all that context when
you're building a skill you don't know
who's also in the room with that user
as a sidenote pub compass at The
Scotsman
so you all should go if you're
interested in the documentation of some
of the things we're going to go through
today you can get them pretty easily at
this look at this link so let's talk a
little bit about what we want to build
okay so now we've kind of gone through a
little bit of the guidance of what good
conversation means but it is up to you
and this is not a design session I just
want that to be the first thing you
think of and you think I want to build a
skill the next question is what do you
want to build in the world of Amazon and
Alexa they have three different kinds of
skills that you can build and it's
actually expanding more and more every
week but these are the main three you
can either have a flash briefing skill a
smart home skill or a customs go flash
movies they look something like this
basically a flash briefing is a part of
an RSS feed that's accumulated from all
sorts of different skills that are
presented to the user every day so
usually this is a very brief little
snippet of information that can be
dynamic that changes daily a good
example of this is the weather and maybe
some current events that are happening
for anybody who may follow Wendy's on
Twitter this would be a perfect example
of what I might suggest to my client I
might say no you do these little tweet
wars between yourself and Burger King
and McDonald's you know maybe I want to
listen to the snarky tweet of the day
in my flash briefing that's a perfect
example of how you can bring that to the
company work for or maybe an idea for
yourself a smart home skill is probably
one of the earlier examples that were
used for Alexa is being able to turn on
a smart devices on and off and not just
on and also it may be with thresholds of
how much and have whittle this there's
actually a whole kits it's very easy to
do something that I really enjoy is that
you can actually do this with anything
if you have a Raspberry Pi or anything
small you can build your own whatever it
is it doesn't have to be something
that's prepackaged in order for you to
interface with it but this is the one
we're going to spend the most amount of
time with because this does not assume
that you have any sort of aggregated
information that you want daily and
there's no assumption of any sort of
physical devices although you certainly
can tie into those as well the flow kind
of goes like this because we're asked a
question or give their command and then
the Alexa interface on their server will
identify the skills named but they're
asking for analyzes it and understands
the customer's request and then sends it
off okay then we get it so there is a
little bit of natural language
processing that goes through on Amazon
servers okay so what we get is we get a
little knock on the door just like a
click event ok saying hey this event has
fired and here's some dynamic
information that you asked to go along
with it here your parameters directly
from the user so at that point we do not
have the audio file we already have
parsed information in text form and not
the whole thing just whatever parameters
that we have identified we need in order
to carry out our function ok so then we
can decide two things we can either send
it back as a JSON file of this is the
way I want you to structure the response
and say it to the user or you can also
send over a little visual counterpart so
something that kind of comes along with
users who have the skill is an Amazon
Alexa app and you can kind of see
anything that you have done today
anything you said as anybody ever used
to Alexa before in this room oh cool all
right so at least about half of you
that's pretty good
it actually has changed and it's
improving so sometimes they just
recently put in with the ability to call
people it's pretty cool I liked it and
also additionally is that given the
custom skill builder the ability to add
things to their Amazon Prime shopping
cart also really compelling especially
if you are trying to build this for a
company who wants to put items in a card
right because that way you can maybe
fine-tune the process a little bit so
what are the components that we're going
to be building right let's take a look
the first one are intense so these are
the different terms I'm going to use as
we're building this out and tents are
basically commands user
and access and you can think about them
as events this is kind of what a little
example of the JSON looks like and it's
very simple it comes in as an intent
object and it has different slots for
different pieces of information maybe
the user is additionally giving you or
maybe not at all if there isn't anything
specific and they're only just invoking
the event and there's sample utterances
so these are specific words and phrases
that the user says for them they can
differently so many different versions
just to put into a single one some one
to many relationship right all of these
different ways of saying it can invoke
that what's important to know here is
that Alexa does have some we're going to
call it fuzzy logic both into it right
they have an a back-end but often I have
to add them myself so as a developer you
need to think about how many different
ways can a user say this and mean this a
good way to try this out it try someone
who's very very young like under the age
of eight try somebody who is not
technically savvy maybe another person
somebody who is technically savvy who
learns pretty quickly and somebody who
knows a skill already ask them to do
something basic and instead of telling
them what to say see what they're going
to say it's actually really fun to be
able to do with people who are
non-technical I like I like having skill
sessions
I usually just give everybody skittles
and popcorn and we just come up with
different ways we can invoke this skill
that would make sense for them next we
have invocation name so invocation name
really has to do with your skill itself
so there are many things you can say
that are built into Alexa and it will
assume you're talking directly to Alexis
back-end unless you're invoking someone
else a third party so instead of saying
you know Alexa tell me what time it is
it I might say Alexa ask the charmer
what time is it I don't know and maybe
that is a charming response maybe it's
it's formatted to be very flattering and
all of the responses to the person you
never know there are many schools for
many things and we never saw Angry Birds
coming so you just never know what voice
goes we'll go
to take off alright for also you're
going to think about your cloud service
now you can instead go ahead and use a
to the rest lambda which is just a
function that's inside of their
ecosystem but because we're going to
build this on the Microsoft stack stack
I decided to kind of just label this as
the cloud service in general it doesn't
have to be hosted in a particular place
just a couple of things to do
differently but primarily this is where
you're going to do all of your business
logic then your portal configuration
this is where a lot of your time is
going to be spent believe it or not is
staring at a web page and tweaking your
schema and tweaking your sample
utterances that is where you're going to
be spending a little bit of your time
this is probably the best example of
building for our project that requires a
test-driven development approach you
have to test it and you have to
understand that you are not the one that
is parsing any of the speech from the
user
that's Alexa so because of that you
might run into things that she doesn't
understand and that's okay if you get
that kind of a situation sometimes it's
because the AI needs to learn your voice
across the street for me I have a
neighbor from Afghanistan and his
daughter likes to go right up to my door
my apartment because I have an echo
right next to my door and she likes to
shout to the door at it to see if she
can talk to it I know sounds kind of
silly but she has a very heavy accent
and after about one or two sessions it
learned that this user profile has an
additional user on it that has this kind
of an accent so it runs it through a
different NLP processor so it learned
and it's able to respond better and
better each time it's kind of
fascinating the way it's done Cortana is
very similar as well I just thought that
that was neat that she decided to check
out all the different things that I do
so I actually have a what's new skill
that I just add many time I make changes
to custom skills that I do I just add
the names of them and what they do to my
custom I what's new skill and she shouts
at the door
Alisa that tell me what Heather's new
skills are today and that's how she
learns it without even going into my
very silly I understand but it still
kind of drove the point home because I
was able to capture some of that data
later on to discover I actually had like
two different users and yet one alright
so let's talk about the components a
little bit of any sort of visuals right
so this is kind of a real basic
stripped-down version of HTML that
allows you to in addition put any sort
of instructions or maybe something that
this is sort of review material this is
something that you can do alongside your
voice requests so it's all built into
one JSON schema right you can write down
you know what you want to look so to say
but also what you want to display inside
the app this is fully functioning HTML
so you can do additional links you can
put video in here you can put all sorts
of custom styling it's pretty nice but
let's say that maybe your user doesn't
have a phone maybe your user is younger
remember your users older you can also
do each other's screen this is kind of a
cool example not something that my
company did but another one out in
California where Nestle decided that
they wanted to help people who can't
retain a lot of information I happen to
be one of those people I have memory
issues so while you're baking they
decided that some people might have a
television or computer in or near their
kitchen
so while they're talking to alexa that
get the next step they also kind of
mirror some of that information visually
and set that out that's like just a note
app and kind of cycles through that
listens to the same kind of events it's
pretty cool there's lots of things you
can do as things are grown all right so
our cloud-based service that we're
choosing is Microsoft Azure today and
what does it seems like a lot of
different things it's always changing
and Amazon has kind of really dedicated
themselves to improve you rapidly as all
sorts of other competitors are entering
the market like actions on Google or
Google assistant has been around for a
while and they have a very compelling
case to use it at Google i/o this year
and then of course WWDC they just had an
announcement from Apple that they were
also going to be a standalone device
theory but only mostly around music
that does not mean though that we can't
extend it through sirikit so because of
this they're trying to pare this stuff
down and make it a little bit easier to
understand for developers but also make
it secure Amazon is the most secure
voice assistant right now because it
does not hand you the audio file you
don't get to have it access to it sorry
it's the way that it goes so it's
actually easier in some ways because you
don't have to run it through your own
custom processor however when you're
building this there are some bumps in
the road right I found that they're very
specific about what kinds of audio files
you can play and write down to how you
encrypted them and how you encoded them
so just kind of go over a little list of
the checklist in the beginning of the
portal tour that I'm going to show you
and that does change probably about
every 45 to 60 days just bear that in
mind so now that we have kind of an idea
of the verbage that we're going to use
let's go over custom slots and built-in
intents this is an example of a
whiteboard session that maybe you would
do if you're trying to decide on what
kind of skill to build you put the
intent name because usually the the
intent needs to come first now nine
times out of ten that usually works the
best however sometimes you can invert it
depending on how you want to structure
your grammar then your sample utterance
which is maybe like give me this thing
and then your custom slot so right here
instead of just saying get me my
horoscope today you don't know
necessarily which horoscope side to use
so in this case you would use a custom
slot so when your data comes over in the
JSON structure it would come over as a
slot with a key value pair and whatever
the user spoke there so this might be
Pisces this might be Virgo right and so
then it's up to you at that point to
match and go on from there this is a
very traditional way to build any sort
of voice scale not just Alexa alright
let's take a look at the portal shall we
okay
there we go so if you have just a basic
Amazon account you already technically
have access to this portal you just need
to go ahead and sign a little I agree
session okay all right I got to do two
things that wants them and I'm
multitasking here too all right
are you serious we have such a good
internet this morning I am now
disappointed oh there we go
okay so when you log in as a developer
in the console you have all these
options at the top they recently did a
redesign so now if you want to kind of
go and start in the Lexus Co you have to
click on the actual exit tab up there
and then a couple of things will come up
there are two different kinds of ways
that you can interface with Alexa you
can use Alexa voice service which is
what you might use in a connected car or
anything where you don't want to go
directly through an Amazon device you
want to go through maybe your own device
but still user the power of their
service that would be the Alexa voice
service there but we're going to do
Alexa skills kid all right
okay now I've done a couple of skills
already so you can kind of see a list of
different ones that it's refreshing
right now and this is also the place
where you would add additional languages
so if you notice right here under NBC
Oslo I have both US and UK now I chose
UK because I personally like the accent
of hearing somebody from the UK but it
also works a little bit better in this
region so there are reasons for it
there's also a German as well all right
so let's say that we're going to dig
into this okay so the first thing that
you're going to come upon is just what
is the name and the invocation name if
you notice I actually spell out nd see
up there that's really important
especially to do any abbreviation that
way the NLP parser will be able to
direct them to your skill and that's
something else it sounds similar to it
you also have options whether or not you
have an audio player or not in this for
this example we're going to go ahead and
leave all the podcasting to another
session so then we'll go straight into
your interaction model this is what
tells Alexa exactly what to give you and
what you're going to be able to do with
it
it's pretty easy pretty simple you just
go ahead and put your JSON right up
there any custom slot values you put
right here so you might just add a slot
type and call it whatever you will and
then you can go ahead and add any
specific values this works really well
for a predefined list a predefined list
so this is important to keep in sync
with whatever you have in your back end
and then sample utterances so this is
where you would put them anytime you
have a slot name it goes in curly
brackets right there and then that
brings us over to configuration so if
you notice there's two different kinds
of endpoints that you can use we're
going to go ahead and use HTTP protocol
and this one is set up in North America
but we can also do Europe and you can do
a different endpoint if you wish right
okay and then over here down here in
permissions this is going to become
really important as you build more and
more skills so additionally you can
just start an ad a scale by saying the
skill name currently there's no gated
process you can just start talking to a
skill however if the skill requires any
sort of authentication you're going have
to stop what you're doing and then
direct your user to finish off
medication on a mobile device so that
they can keep an either passwords
separate it also will prompt them to
give access to when it says device
address we're talking about the devices
of like the specific echo device not a
phone okay so this means wherever that
device is currently and you as a user
have the option to set it up ahead of
time so you don't have to keep answering
those questions from different scopes
and then of course you can read have
access to read and write access to the
list option within Alexa over here and
the the test section if I can get over
there maybe well come back of course not
that's alright okay so basically over in
list in the Test section if it will ever
come up maybe one of these days nope
doesn't like me that's alright no
problem then the test section you can do
all of your testing as a speech as a
text-to-speech so instead of having to
own a device that's where you would
actually just type out examples of what
you're trying to invoke so you can start
debugging what you're building in your
service and I probably spent a good 20
percent of my time on this pad it would
be great if they would show it to you
that's alright
not to worry and then publishing
information will come at the very end
once you're really happy with everything
that you're doing you just answer a
couple of questions about what you want
to put on their app store and you're off
to the races
maybe it'll show is this that would be
awesome
all right so let's just talk about a
basic skill kind of looks like this I
just started a new project into whether
the VI project the first thing I did was
I created a little folder called speech
assets while this is not going to be
used directly by your service it's
important that you keep some sort of log
of what you're using right now in this
case it would be your intent schema
maybe right here and any sample
utterances this is a place that I store
any changes in additions to I touched
this a lot and that way you can go ahead
and just copy this right over to the
portal and everything should be in sync
all right and then let's go into the
models shall we so right now like I said
there is not an SDK for dotnet for a
c-sharp specifically there's all sorts
of example projects on node and Python
and even go but there isn't anything for
us a sharp it's not really that big of a
deal
Walter Quezada actually
reverse-engineered the way that one of
their node SDKs were and discovered the
JSON behind it so thanks to his hard
heavy lifting we actually just have that
it's pretty easy so over here and the
controller's I created a controller
right it's a really pretty basic one
here I'm doing here is setting up any
sort of launch request so that means
when somebody just says Alexa launch the
name of your skill you can handle any
sort of launch requests immediately
intent requests means you might say
Alexa launched my skill and tell me X so
tell me X would be an intent okay and
then such an any requests would be if
you were to say cancel or exit you can
actually stop a little bit of that
process and give a custom farewell or a
reminder on the way out the door
mix-ins okay what I have here that is
commented out is important for anything
that you're doing for publishing right
so basically all we have right here is
checking whether or not this application
ID is the same than a request that is
coming in as the one that you have
registered so this is just a good way to
keep somebody
from fishing for information in your
service and then under that is just a
basic timeout good deal so now that we
have that all set up we're going to go
ahead and add a couple of models so I
have a request that will come in and a
response this one is a little bit more
fleshed out shall we say but in general
the way that it looks is kind of like
this so JSON will change based on how
much information you have set up in the
portal I've done a little bit of parsing
myself to see what is the easiest way
for me to have like a starter kit and
I've thrown that out on github so you
guys can take it and kind of expand on
it there's a section here though I want
you to pay close attention to if you
noticed under attributes I have some
custom attributes this is custom for
your skill this is not built into Alexa
you just have to define what you want
it's a JSON key value pair you can
decide what you want to call it I've
added a member ID in the last intent
name and then this will get shuttled
around as long as the session is live so
a session whenever you say Alexa and
everything keeps going that is a session
but once she's done answering your
question and her light goes away then
the session is over so that means you
lose that any sort of variables that you
stick in that JSON make sense good deal
I do the same thing in in the response
down here at the bottom if I wanted to
I've got output speeches and we grab
that real quick there we are
I've also have session attributes in the
response so when I am building the
response to send over to Alexa I'm also
just letting it set there so I'm both
receiving it and sending it any
questions so far
good deal
all right let's get into the meat of it
then let's go to a request Handler
launch request is pretty easy I like to
put additional comments up there so that
you can kind of follow along especially
if you're in a team and everybody is
working on this at the same time no I
don't think you need comments in order
to explain everything but it's
incredibly helpful in voice so that you
can see the intent of the both what the
users saying and the results this is
what we're going for here this is the
voice happy past if you will so
basically because we created that that
model that kind of models after the JSON
we can do something very very simple and
just set the title the content any sort
of outputs speech that is a repro so if
you don't say anything for about four
seconds you can define exactly what you
want to look for to say to follow up
with the user and then you can define
whether or not you're going to end that
session so maybe you want to keep the
session alive if you want to keep the
session alive you set that flag to false
and then you wait until maybe the user
gives you another piece of information
this works really well for one two and
three step conversations in general
though Amazon likes you to give brief
replies so whenever possible try not to
what we call do intense sequencing is
preferable so that means that you want
everything just to be quickened to the
point and of course down here at the
bottom we don't really need to do
anything with that because Alexa handles
all of that but in the event that you do
want to say something custom to say
goodbye you could do that right there
most of the time though is spent inside
of the intent requests so because I
added that session variable you saw
earlier I'm able to go ahead and do some
case switching so let's say I say Alexa
asking to see also to say hello and then
you see she says hello and then I say
hello again so because I have already
defined that the very last intent that I
had was the hello intent I can actually
send it off to a completely different
handler it's kind of nice so that's the
way that I handle a contextual intense
sequencing
I just kind of break it down by whatever
text the JSON is giving me and send it
off from there so let's look a little
bit at what those handlers look like all
right here's a handler very similar to
what we had in a launch request a little
bit additional pieces of information
here if you notice there's an output
speech type here
it's called s SML we'll get into it in a
little bit but normally if you just
wanted to just say something very very
basic you wouldn't even have to define
the type you could just use direct text
without specifying and then you'll get
by default whatever is set up through
alexa so if you have somebody in the UK
again might have different inflections
in the way that she says things versus
the US but you don't have control over
that if you do just what we call a basic
response s SML lets you do more so this
is all it is to it it's pretty basic
isn't it you're basically setting that
JSON for something else to read it's
important to note then when you're
putting this together if you're pulling
forms from a third party let's say
you're pulling some Twitter there's
emoticons right in a little emoji use
right that is important to strip out
because she will say :
not smiley face so it's important that
you curate your content here this can
come from anywhere
I hard-coded it here just to show you
but this information can come anywhere
it's very very simple to set up and it's
important also that you have some sort
of a way to handle a custom stop or
cancel Amazon looks for this when they
approve or deny a skill in the store and
then down here we have a default so if
all up sales in my case which it usually
goes to my default this is so I can
control the user experience and not have
it be something that Amazon does alright
everybodyy with it so far good deal so
that we set all of that up
most of this again is when you just
found a project it's just built into Web
API I'm using weather vi2 here and if
you notice right here I kind of have
something commented out basically I can
override any sort of validation so
Amazon looks to make sure that you're
validating a whole bunch of different
pieces of information and that's kind of
how I would do that here I just wanted
to kind of give you a quick overview of
that so now that I'm not quite sure if
the Internet is going to work with me
I'm going to play your video instead all
right so this is kind of what that might
be like computer ask KC dotnet to say
hello KC dotnet user group right so this
is earlier and I use a group that I got
to work with and that's pretty much
simply what we wrote they're very very
simple maybe you want to do something a
little bit more complex though right
this is all just basic information and
remember we went over how important it
is to retain context we have a little
bit of context retention now right I
might be able to say hello and then she
might say oh hello again it's you again
because now we've controlled both that
context and a sequence alright so we
have that let's see so I just did you
have basic demo let's talk about
expression so what I showed you earlier
with speech synthesis markup language
that's something where you can interject
little audio files or you can control
the pitch you can make Alexa whisper you
can say anything you like in any way
that you'd like you can make her shout
all of it is now controllable through SS
ml and this is also not a new spec in
case you're interested in that it came
out in 2003 here's an example of what SS
ml might look like okay right within
just a basic string you'd write out what
looks a whole lot like HTML but it's
spoken
so this is maybe the place that
front-end developers could pivot and
spend a lot of their time it is to
really craft something really cool if
you notice you can put in pauses you can
add a little audio file that might play
something really quickly in my case I
really like Star Trek so I added like
the start of noise of the engines
and you can also have little little
interjections so that means that
interjections are being added to alexis
library all the time these are things
that she can say with extra what we call
extreme expression so she might be able
to say hooray or Booya for example right
this is how we can kind of pepper our
voice interactions and if you notice we
can also separate sentences so right
down to write in a bedtime story skill
you have the ultimate control over it
and if you want to know what the
essential spec is it's actually a LEM w3
you're welcome to go ahead and grab it
there and I'll kind of show you what
that looks like over here all right
so right there if you notice I went
ahead and just put in a little audio
file right let's play that and see what
she does
computer ask KC dotnet to say hello mm
hello counselor right so what I did is I
went ahead and I made her completely
monotone believe it or not Alexa is not
monotone especially lately they've tried
the very best to make sure she had a lot
more expression okay
so now that we've kind of done a little
bit of that how far can you go with it I
actually played around with that just a
little bit and I'd like to play probably
one of my favorite demos ever computer
start I'll pause hello this is starship
USS Enterprise hello yes commander how
are you feeling well well booyah this is
the access code alpha alpha three zero
five command code alpha alpha 305 has
been verified proceed red alert aah red
alert for Starbase sts-112 warp 6
of course Layton's for sts-112
ready at your command engage
yes commander so that's my vehicle
acknowledged so those are all examples
of something that I find really nerdy
right I really like it it was fun for me
to do I found the official but just for
those of you who don't know the name of
the computer aboard the Starship
Enterprise is called L cars and is also
a visual interface to go along with it
so I went to their official L cars
website and was able to grab some of
those audio files to kind of serve that
up it's really fun and it was the very
first skill that I ever made that
actually went all the way through the
publishing store so I was really fun it
kind of is up to your imagination
well that one might be more novelty I
have since built twelve thirteen
fourteen other skills for my clients
that are completely useful this one
though I mean every day I kind of use it
not going to lie if you want some
additional references on how you can
build this there's a great article about
intense sequencing if you should be able
to do that all on your side okay also on
SS ml you can play play around with
audio there's another really great one
if you want to know how I built that
skill I actually threw that on github
and you can take a look file by file
again it's all written with a Web API -
and then there's a fantastic voice
design video from James Jane gola from
Google i/o well I understand that it's
not necessarily just for Alexa it's
about voice design in general and since
we're the ones who get to play with this
since there isn't a creative person
right it's working on this we're the
ones who get to build the experience
it's 40 minutes and it's completely
worth your time also many things to
alter cassada he has a great pearl sight
course on the beginning stages of how to
build with Web API and if you're
interested in my slides you can kind of
get all of them here at this bitly link
and or at the very end I'll also tweet
it out so before I go too far I wanted
to see if maybe we got this back you
just never know
Alexa asked NDC Oslo to say hello there
was a problem with the requested skills
response so very important to note that
when that comes through that just means
that she can't reach the service so that
comes directly from Amazon servers and
not yours so it has to actually get over
to you in order for you to do custom
errors that actually happens quite a bit
in the very beginning especially when
you set up something new out on Azure or
maybe any other host where maybe the
service went to sleep okay if you don't
make sure that it's always on it will go
to sleep and that might be their slots
you get no you can try again maybe Alexa
opinel cars hello this is starship USS
Enterprise cancel acknowledged so the
difference between this one and the one
that I showed you in the video is just
language so there are three options in
the portal that you can have that one
was the exact same skill redeployed for
the UK right so when I asked you know
just Alexa to say hello she actually
says something different for the UK and
something different for Germany and
something differ for the US because
everything's about cultural context
within the voice it's very important to
get all of that right and so you will
have to deal with globalization a little
bit and while right now the US and
Europe is the focus it's not going to be
for long China and Japan are getting
ready to launch probably within the next
month as well so you're going to have
lots of opportunities to serve many
people worldwide and in their own
language and cultural context so in
conclusion don't just come up with a
voice idea instead come up with an idea
that can be best solved through voice
right so a good example of this is that
recently you guys have a fantastic
transit system here in Norway I have to
tell you I've gotten to ride all over
the place but there are moments you know
maybe it won't show up on time
back in Kansas City where I'm from we
don't actually have any sort of really
good way to tell how anything is going
or how far away it is so just kind of as
something that we wanted to do pro bono
I got to write a skill for our Kansas
City Transit Authority right so I got to
do questions like Alexa tell me when the
next 152 is heading north or because
that's what somebody who's a frequent
user who might always know and she's
saying oh it's at 5:30 or it's not
running right now or I might say
something a little bit more simplistic
like Alexa asked AC transit to take me
to boots right or a certain restaurant
name and so because of that we hooked
into Google's Maps API and then we just
discovered about how far away that was
from your users current location because
remember the device information that you
can get from it in the very beginning
and then we started calculating about
how long it would take to walk to that
bus stop or to that train staff or
whatever different types of transit
option that you had that was another way
that we did that and once we launched it
it was used immediately right away by
people who actually didn't have a whole
lot of money and we're city dwellers so
these are things you can do that are
actually very very useful and always
have to be something fun although that
never hurts
so in conclusion please keep skills
short and to the point
build efficient and executable code in
less than four and a half seconds well
that's very specific isn't it basically
if you start doing some sort of enormous
machine learning algorithm processing
and you require the user to wait until
you get that response Alexa takes over
and said you know the requested skills
takes too long to respond I'm sorry and
just cuts off the session right there so
it's important now that you take those
big huge monolithic enormous micro
services that shouldn't have been
monolithic but are and really go down to
the smallest that you can cache data if
you if you need to it's really important
that this is speedy and fast
and adhere to the voice design
principles again don't be part of that
69 percent that have a really bad skill
because all of this is completely within
our control usually when a user or a
client comes to me they actually don't
know what they want
does anybody have a client that knows
what they want right away exactly you
have to help so it's important that
developers become educated as to what
that is what that means I gave you a
couple of things to think about being
you know cooperative and being using
context and dealing with any sort of
inference these are things that you can
control on your side if you have a user
profile start saving information against
it this is a user who asked for help at
least once a week clearly they need a
different kind of flow maybe you can do
something with that information this is
perfect for AI so if you do any sort of
tinkering around with that it works
brilliantly and most importantly please
have fun with this it takes less than a
day to set up your first skill is if the
internet had cooperated with me I would
have just done it live for you because
it is that easy to do and you can start
tinkering around and doing more and more
with it but the beauty is in its
simplicity so pay attention upfront I'm
not telling you not to have an agile
project I'm telling you to just think
about who it is you're serving remember
that your user will not go in just one
direction that means that you might have
only three intents that you serve it
might be to respond to a hello it might
be to give information about it's some
sort of transit time or it could be that
your pizza is on the way either way your
users will say it differently instead of
putting your hand up and saying no
that's wrong you have to precisely say
it this way you have to think about what
would make them not be frustrated that
includes any profanity so yes I have
absolutely added sample utterances that
are slightly profane just so that
instead of stopping my user in their
tracks and saying I'm sorry I didn't
understand what you're saying you could
say mmm I get that you're frustrated
here's your information sorry about that
because now we have context
and that's perfect also for machine
learning again because that means you
can offload that to a process that takes
a look at what kinds of intensive
hitting or if you wanted to remember the
big huge sentence that we had with your
invocation name and then your sample
utterance and then your slot you can
make that whole thing a slot for example
I for someone's address I just say what
is your address and the user gives me
their address so there is no intent
right there that they have to speak then
how to speak the name of intent they can
just give me their address and that is
one big long slot so because I get that
parse directly it's called literal so
it's an Amazon literal slot that right
there is the power that's when I can
start taking that and processing it on
my own time in my own servers and figure
out more about that user there's just so
many different things you can do with
this and it's not just limited to this
so once you start getting information
from the user in this context maybe you
start helping to build that ecosystem so
that no matter what they use whether
it's a screen a phone or a voice
assistant it all ties in together that
is the goal and that's the reason why I
threw it out on Web API because it's so
easy to make an API that you just extend
another endpoint to serve a mobile app
or to serve a desktop so remember that
varied user responses are opportunities
not errors this is the biggest shift as
a developer I had to go through and let
me tell you the nested-if thing is
terrible at first so that forces you to
stop and reevaluate the way that you're
building us right big pieces of context
as you're given them and that way you're
going to delight the your user every
time the best skills that have stayed
and have the best reviews can parse
specific pieces of information and keep
them contextually and allow the user to
move forward instead of forcing them
training them to go down a path that
they don't understand thank you very
much
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>