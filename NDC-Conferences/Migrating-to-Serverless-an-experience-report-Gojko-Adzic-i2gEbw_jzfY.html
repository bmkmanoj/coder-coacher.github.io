<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Migrating to Serverless - an experience report - Gojko Adzic | Coder Coacher - Coaching Coders</title><meta content="Migrating to Serverless - an experience report - Gojko Adzic - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Migrating to Serverless - an experience report - Gojko Adzic</b></h2><h5 class="post__date">2017-02-24</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/i2gEbw_jzfY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">yes you can start yet good well thanks
very much for kind of coming in this
morning I'm going to and I want to talk
about our journey last year moving from
Hiroko to a SS lambda we've moved a
collaboration platform kind of pretty
much completely into lambda now and it's
been a really interesting journey
there's a couple of things that we've
kind of done horribly wrong that
hopefully I can prevent you from doing
if you decide to do something similar to
that and generally I think that the
whole serverless platform although it's
kind of buzzword still then you know
there's a ton of confusion what actually
it is and what it isn't is one of the
most revolutionary things that happened
in IT architecture over the last 10
years it's probably the biggest shift in
what we can do as developers since 2007
when Amazon enables people to spin up a
virtual machine in a few minutes and II
I was kind of looking at this with some
colleagues a few months ago where we
just kind of joked how much the spin up
time is reduced over the last 10-15
years in about ten years ago when Amazon
was kind of releasing their first
version of the clouds I worked as a
consultant for a big telecoms company on
implementing some kind of software for
them and we were a third party we
delivered our craft and they were
supposed to kind of just spin it up and
it took them nine months through their
internal bureaucracy to get a virtual
machine allocated at this point it's you
know pretty much easy to now think about
Amazon giving people the ability to spin
up something in about five minutes at
the same time and seeing how that was
obviously going to win with a double ace
lambda the spin up time for a new
container now if
running nodejs is less than one second
which is completely crazy because it
starts changing constraints that we're
working under Simon worldly who used to
run canonical and then started writing
some really smart books on where IT is
going as this theory that a huge amount
of what we call best practices today in
software architecture and design are
still influenced by the average time to
recovery that was a major constraint 20
years ago in because if your machine
died 20 years ago
you'd have to buy a new machine you'd
have to get people to come into the data
center install it the average time to
recover is a few weeks and that's how we
developed all these good practices like
Bluegreen deployments failover server's
multiplicative deployments load
balancing and a ton of other things that
we now take for granted now with the
average time to recover of less than one
second the big question is which of
these best practices are no longer
relevant or important which of these
things is just shackles that we are
running with because we are used to
develop applications like that we used
to deploy applications like that and
that's why I think the whole kind of as
several as lambda thing is revolutionary
pretty much all the cloud vendors have
jumped on the bandwagon I think
Microsoft is doing as your cloud
functions now Google is as your
functions Google is doing as you're so
GU GLE clouds functions iBM has this
thing called open Wisc there's a bunch
of other people can running services
like this so I think we're in very very
early stages of what this is actually
going to open up because it truly
changes the constraints under which were
developing systems now I'm just going to
throw some numbers at you that I
discovered on the internet five minutes
ago and you know like anything
discovered on the Internet it might be
completely relevant or or a lie but kind
of Gartner estimates that in 2019 75% of
corporatize
spending is going to be on third party
platform services so that's opening up a
massive massive opportunity for software
companies to offer some you know
services in the cloud and grab some
market there and for me at least the
whole civilized Inge if you take away
the buzzwords is what platform
as-a-service was originally supposed to
be before it was completely hijacked by
the marketers because it actually allows
us to use platforms as a service and it
allows us to offer something as a kind
of as a service to other people
Amazon couple of days ago enabled people
to sell access to their api's so you can
build an API you can launch it on Amazon
you can use Amazon billing to basically
provide people your service and it runs
on the whole kind of servicing our
infrastructure there which means that if
you can find a good business model where
kind of the cost of the service is less
than you know what you charge that's
basically it you make money and you
don't have to worry about you know
managing servers security installing
operating and a ton of other things you
just takes a lot of kind of that
headache away the other thing that I
found is a statistics on this statistic
on the internet five minutes ago is that
IDC estimates that in 2020 67% of the
software is going to be running on the
public cloud because nothing else is
going to make sense economically and I
think that call pricing of lambda as an
offering is pretty much more
revolutionary than the technology that
the kind of technology behind service is
not really particularly new it's been
around for at least five years what's
really revolutionary about the whole
thing is that Amazon is now at such a
kind of high utilization point that they
can bet that it's better for you to pay
for what you actually use them to pay
for reserve capacity lambda is charged
per 100 milliseconds in the processor
which means that if I have a million
users now this
moment I will pay for kind of all that
usage and if they all go away in one
hour I don't have to pay for anything
and that means I no longer have to think
about reserving capacity and I'll longer
have to think about provisioning
machines and no longer have to think
about a ton of other things because the
economic cost of that is gone a huge
amount of how software architecture is
is kind of built and how we design and
my brain is still hardwired to think
about reserved capacity I design our
applications to kind of think about well
you know we're going to have 50,000
users next month then we're going to
have a hundred thousand then now we need
to kind of fail other machines we need
to do distribution we need to do this we
need to do that we're one of the kind of
most important things about this whole
new platform offering is taking that
thinking away and the platform being
responsible for stuff like that where
I'll give you an example why I think
that's important about seven years ago I
worked with a gambling company where we
had lots of different payment providers
and the way we'd kind of structured this
thing is we do all those nice design
practices solid
isolation loose coupling everything
everything everything TDD brilliant
stuff and with greatest nicely isolated
modules that in theory do not influence
each other and then because it was so
difficult to secure and provision
machines we put 30 of them on the same
machine and we had a bug in one stupid
payment provider that basically caused
it never to release resources and all
the time can we took all the ports on
the machine it's kind of then the
Machine started freezing up in the sale
of a machine start was freezing up and
then we lost all the payment providers
for a couple of hours until people
figured out what's going on because we
took all these kind of small isolated
modules and we bundled it into an
application because kind of reserving
capacity for the application was
important we had one machine and then
kind of we kind of pretty much ruined it
for us because when it was all bundled
it was difficult to monitor it's very
very difficult to know that all this
particular
module is kind of causing problems when
it's all running in the same application
server and things like that were kind of
forcing us not to benefit from small
isolated modules during deployment when
we started deploying mind up to Heroku
something very very similar happened we
have the I don't know 20 30 exporters
for different formats some of them are
used quite often some of them are used
very very rarely I think I'm the only
person that's using the market on export
that I built it for myself
I use it once a month and that's pretty
much it the PDF one is being used
several times a second the SVG is being
used as an hour once every minute or so
and because we were paying Heroku per
virtual machine it made absolutely no
sense to provision a separate virtual
machine in a sale of a virtual machine
for each of these because we the whole
capacity of you know 30 exporters we can
do weekly virtual machines why on earth
would I pay ten times more and this got
us to bundle all the exporters into the
same application and deployed somewhere
where we can secure the scale deploy it
easily and then we had a bug in the SVG
exporter that again kind of caused
resources to go out and cause the temp
space to fill up and then all the other
exporters kind of started breaking
because Linux doesn't work that well
when you fill up the temp space and then
the failover export is broke and then
everything kind of went south and again
it is this thing where because we have
to think about reserving capacity and
kind of bundling things together um we
ruined it for ourselves we're with
several as platforms and technologies I
you're effectively paying for usage so
there's zero benefit putting the SVG and
the PDF exporter together they cost
absolutely the same is there separate or
together and even worse because it kind
of it's memory time is CPU if one of
them like the PDF is a memory hog and
another one like SVG is not really using
any memory it actually costs more to
bundle them together so I think this is
the first time at least in my
programming career that the deployment
architecture
is providing financial benefits for good
design where if you do it badly you pay
more and it's very very clear that you
pay more because you're paying for
reserve capacity for a memory you're not
using and if you separate it out into
small isolated modules that kind of can
work independently then you pay less so
that that's kind of a really interesting
thing so the the third number I stole
from the internet is Gardner's estimate
that in 2016 the value of the cloud
market was 32 billion dollars which
makes software the second most
profitable clouds on earth that the most
profitable cloud is of course marijuana
which is 40 billion and kind of that
means that in 2017 software is going to
be bigger than drugs think of all this
from that perspective and the estimate
for the next ten years is that the
valley is going to grow to about 280
billion dollars for kind of cloud
offerings and and the cloud market and
that's kind of completely insane
IDC estimates that cloud migrations are
growing at double the speed of
virtualization car virtualization was
growing ten years ago and that means if
you know you're not already in the cloud
you're pretty much going to be in the
cloud in the next couple of years and if
you're twenty percent in the cloud
you're going to be 70 percent in the
cloud in a couple of years and this is
where I think that the whole offering of
all these different severa services
however idiotic that sounds is going to
be absolutely amazing and however are
kind of two small children and I've
learned there's kind of three types of
toys when you kind of think about from
that perspective so the first type of
toys is Lego that the whole purpose of
Lego is the joy of assembling that's
kind of you spend the time assembling
the whole thing and after you've done it
it goes on a shelf somewhere and that's
pretty much it the kids do not play with
the assembled Lego toys
the second group of toys that's kind of
probably 90% of the toys are those
stupid toys where you buy them in a box
and then it takes half an hour to
assemble until the children can play and
that semester specially if you forget to
buy batteries and you're taking it as a
present because then you know they can't
play and it's all a mess and I think
that's where most of kind of how we
deploy software is now and the 10% of
the toys that I think children find
really enjoyable to play with are the
toys that come with batteries included
and the big thing about service for me
is kind of services actually code with
batteries included
because what they've done is they've
taken away almost everything that's not
your business code all of that is
provided by the platform and that's one
of the most amazing lessons for us as
we're moving things from Heroku to to
londes how much code we've deleted
I think we've dropped about one third of
our code which means that we have a
third of code less to maintain we have
you know we're paying 1/3 less for
development for testing for maintenance
and everything else and we're benefiting
from these services that were built for
Amazon scale or Microsoft scale and if
you think about this in this perspective
there's probably very very few companies
that can do infrastructure as well as
Amazon or Microsoft Google and from a
kind of running a business perspective
it's much much better to actually kind
of use their infrastructure for that and
use yours and the lovely thing about
lambda is you actually get all those
things for free it's kind of included in
the price of what what what's an offer
so I'll do something that you know
nobody's supposed to do and try and do a
live code deployment now just to show
you what what the batteries included
mean so okay so I'm going to treat the
bit and I'm going to use a deployment
tool because it would take too long to
just configure everything to the website
and I hate websites so what we're going
to do we're going to create a Web API
I'm going to just initialize the new NPM
project and NPM install
a utility library to configure api's and
i'm going to install a cloud deployment
tool and that's pretty much going to be
the slowest part of the process so now I
can create something called ap ijs and
up let's do it this way so it gives you
to see so I'll say this is kind of the
configuration helper I'm going to create
a new API and I'm going to export it and
then I do get /hello and we're going to
say hi there that should pretty much
bitch let's see if I've kind of made a
stupid mistake so I can now say
we're going to deploy to us east one and
we are going to tell it your API module
is API hopefully that's it
now if I've not made a stupid mistake
typing this this should kind of go live
in a couple of moments so it's now
deploying this whole thing to AWS lambda
and we are going to create a Web API
that is not really active yet it's
deployed it's created there in their
registry and I have a URL now that I can
go to and spin up a new container so
I've called this thing slash hello so if
I do curl this thing slash hello we
should get hi there so kind of now is
that what I like about this is kind of
its code with batteries included because
although this is very very simplistic
with this thing I get automatic
automatic scaling when more people come
in so if a million people start hitting
this thing now that's not a problem at
all if nobody hits it that's fine it's
kind of not really working with anything
I get automatic monitoring its automatic
statistics I get automatic crash
reporting I get automatic security
because I can secure this in kind of
lots of different ways that amazon is
offering using api keys using usernames
and passwords using I am roles using
federated logins using a ton of other
things that you generally need when
you're kind of building an application
but it's not your business code is a
bunch of infrastructure so if we go to
now I will kind of try and spin up just
to show you the stuff now so if I sign
into my AWS console and go and come on
come on
so
I have a new lambda function called NDC
London I have kind of monitoring set up
or invocations and and stuff like that
sunny to select the latest things so I
get you know that there was one
invocation of a the duration number of
aristotle's and a ton of other things
that generally people need when the
building applications I have completely
centralized logging that is telling me
what got executed when it got executed
how it lasts how long it lasted I have
log collection to all these services I
have a million people hitting this thing
now and a million containers spin up I
already have centralized logging that's
kind of you know that the first month of
building up a stupid application and
kind of that's what I meant when I said
code with batteries included kind of
that the whole infrastructure thing is
just there magically at Amazon scale or
at Microsoft scale and I think this is a
fantastic opportunity for people to kind
of build up in the services because
really that most of it is just kind of
most of the headache that is potentially
interesting if you like building Lego
bricks is you know is gone unfortunately
but the the if you're really trying to
run a business spin up the business with
software most of the infrastructure
headaches been taken away and that's
kind of the the service part of service
so in terms of kind of batteries being
included the stuff that we've not really
had to worry about since moving to
lambda is scaling this does require a
bit of a rethink how the application is
structured but once you do it right each
the platform takes away the role of
deciding how many containers to run how
many containers to shut down when to do
it when not to do it and again you're
not really paying for containers even if
they're sitting there and not doing
anything you're only paying for the
container when it's actually doing
something for you so the whole worried
about well you know do we need five ten
sixteen how do we scale it up at what
point do we scale it up is gone
the big problem with kind of automatic
scaling and things like that is of
course kind of the whole monitoring
thing and at least Amazon has fantastic
monitoring capabilities they're
partially because they need to be able
to charge us the right amount of money
and that kind of opens up some real
interesting possibilities because with
such a low level breakdown of billing
this is the first time at least I've
been able to say well this module of
code is costing me this amount of money
to run is the SVG exporter profitable is
my you know login function costing me
too much do I need to use a different
database don't need to do and a lot of
these kind of enterprise architecture
decisions that are based on gut feel
that's all you know it's too much
operational cost we need to descale this
we need to scale this up you get like an
x-ray monitoring to how much things
actually cost and how much run on on a
very very miniature scale so it's an
incredible on it's an insane amount of
visibility kind of that it comes for
free with this that the next thing that
we've never really had to worry about
with lambda for kind of a year running
in there is recovery and that's again
going back to what model was talking
about mean time to recover is really
relevant now because the containers spin
up and die on their own we've kind of
engineered the app not to count on a le
container surviving so me time to
recover is relevant I count on every
request being executed on a potentially
new container and this you know that
enables us to open up some really really
interesting things around well you know
how do we catch things do we catch do we
not cache how do we kind of load
balanced stuff or do we care about load
balancing or failover at all and and
things like that and in most of those
cases kind of it just gone the next
really amazing thing that I think is one
of the biggest advantages of the
platform like this is proper support for
versioning I don't know how many times
the worked with people to start doing
feature flags and then shoot themselves
in the foot
and the code becomes a horrible mess of
spaghetti and nobody can maintain it
anymore we're with them lambda I don't
know about the other surveillance
platforms but with lambda at least you
get for free the way Amazon is doing
multi versioning for their codes every
single deployment gets a numerical index
and you can invoke any single version of
your function that you've deployed ever
I can deploy a new version of my API it
gets a new numerical index and I can
call both and the beauty of the whole
thing is because I'm just paying to use
it it costs me absolutely the same
amount of money to have 20 versions
deployed and to have a single version
deployed if you think about the whole
kind of a lean analytics space and and
lean startup and everybody talking about
how you need measurements and testing
and things like that most of the stuff
that people talk about in that space is
front end because front end is the
easiest thing to a/b test and the front
end is something that kind of people can
actually measure easily but to properly
a be test stuff you probably need to
completely separate deployments now that
costs an insane amount of money for most
people because it costs twice as much
than to run your stuff if you want to
run 20 experiments you need 20 separate
deployments and then because it costs 20
times as much what people do is they
will kind of deploy everything on a
single platform and then you have
experiments kind of messing each other
up and polluting the data and things
like that because it just costs too much
to operate 20 different copies of the
system with lambda it costs exactly the
same amount of money to operate 20
versions 500 versions of one version
because you're paying for usage if you
have 5% of your users using this and 95%
of use that same as you send the kind of
descent to each other's versions so they
top it up some really interesting
possibilities and I think experimenting
on code like that and and generally kind
of version code like that up until a
couple of years ago was only possible if
your Facebook
I spoke to some guys in Australia a few
months ago and they were completely
pissed off because Facebook is
apparently constantly broken in
Australia Australia is a big enough
market too so they can done
statistically valid experiments there
everybody speaking English so they don't
have to translate the software so kind
of experimental versions of Facebook
features get released there and then
measured and then you know they piss
people off there once they start making
money they deployed to US and Europe and
things like that and this was only only
possible if you're running its Facebook
scale now lambda gives you something
like that for free although all the
versions of your functions you can kind
of load the a/b test you can ABC test
you can kind of balance that the
infrastructure is provided there and
that's absolutely amazing and this also
allows us to kind of slice development
completely differently what we started
doing a lot with my map is we develop a
features so we know it's going to be
slow and we actually released it to 10%
of the users and we can do pretty kind
of well targeting and we can say oh
we've developed this so only people with
about a hundred nodes can actually use
it and then we can direct people who
have a map of a hundred nodes to that
new version of the function we can send
people with kind of the olders larger
maps to the older version of the
function that skills table and
experiment on this and I think this
opens up some amazing opportunities for
people that you know will just cost a
stupid amount of money five years ago
and that you now get for free and I
mentioned the last thing that kind of
lambda pretty much provides for free is
this kind of whole centralized logging
it doesn't matter how many versions you
have how many different kind of
deployments how many containers the logs
go into the same place which makes it
very very easy to kind of figure out
what's going on and they're still
improving this I think they released
last month a new product for placing
inside the code and things like that
it's also working at this level and
these are typically things that building
up even on kind of second-generation
cloud as Heroku or Google App Engine
it's very very difficult to figure out
what different parts of the software are
doing because it's all bundled together
and now we get this kind of amazing
visibility for almost free so kind of
the next lesson for me as he said was
that the time to recover is really no
longer relevant as a concept and then a
lot of those architectural principles
that you know we hold dear like
blue-gray deployments or having a sale
of a version available or having a cold
started then and kind of hot started
containers and things like that they
really become not that important anymore
and the big question then becomes which
other kind of development of design
practices do we have that what
influenced over the last thirty is that
you know we're just using because our
brains are hard-wired to think about
well you know what happens if this dies
and one of the kind of really
interesting things that lambda is a
platform it has forced us to do is
actually from the start to consider the
fact that almost any part of this can
die at any point and that we just
shouldn't care about it which none opens
up some really really interesting ideas
around well where do you keep state how
do you ensure that the users are getting
consistent information and things that's
going to eat does solve a bunch of
problems but it opens up a completely
different set of problems that's kind of
really really interesting and of the
third lesson is again that this whole
multi versioning thing is absolutely
amazing especially because the cloud
infrastructure is kind of magical and a
lot of the stuff that we I used to do
like I'm about to make it testing geek
and I like to kind of automate testing
or everything but if you look at kind of
the stuff around infrastructure testing
for example what happens when your
service disconnect from the database
unless I guess your nature and you can
launch a nuclear attack on a data center
that's impossible to simulate anymore
it's not something that I can cause it
doesn't depend on me I can kind of try
and prevent those things in the code
that I can kind of code around that but
with the whole idea of the
infrastructure belonging to somebody
else then the big question is well how
do you do development testing production
how do we upgrade things from one thing
to another and does the whole sequence
the development testing production even
make sense anymore is that one of those
constraints that you're working under
because hey I can have 40 different
versions now I can progress that through
lot more kind of stages so one of the
kind really interesting things about
this and I'll show you how lambdas done
it I think the others are still catching
up so I don't think you can do something
similar to us you're to this one as
you're functions but if I do something
like this see so I'll to send the new
version up I can do and I'll just say
version dev and then we can say release
and we will say version prod so let me
change the codes so if I say something
like hey there
so now this is what a kind of package up
a new container
version going to send it up and because
of used version del you'll see that the
URL is kind of changed the bits come on
come on
so the URL is now slash dead and we have
numerical version two so I can set up
all my data sources to call in the
medical version one still or call
version two and if I kind of do this
stuff now it's going to say hey there
and I can now do NPM run release push up
with the production version that's going
to probably be less than three I can
then go and break the development
version carefully and the production
version is still going to be working
because they all have kind of a
different version number kind of I can
set up a URL to be this to that and the
kind of the completely insane thing
about this is that this is supported
throughout the platform back to back so
if you have a service listening to cues
listen to emails listening for file
conversions listening for anything else
you can say well you know always called
the prod version or always call the dev
version or always call version Boyko
always call version London and kind of
because this is so cheap and cannot
search it it's it's the equivalent
amount of cost actually what this allows
us to do is say create a version of our
system that only works for people in
London and experiments there and once
you get to be that expanded to the rest
of England or create a version just for
people at this particular conference and
go live very very quickly because of the
constraints that these people have so
it's kind of opening up the holy grail
of agile development where instead of
dividing the solution to kind of release
if you slice the problem you solve a
smaller problem for a smaller group of
people very quickly and then kind of
start expanding on that and it creates
kind of this whole idea that you can do
small and valuable stuff very very
quickly so since moving to this we've
been able to kind of slice our
forty's and denise is much much thinner
than we were before because that the
infrastructure is kind of built to
provide that and build to support us in
doing that so come on so the kind of
that the next big lesson for me is that
the true benefits of this thing actually
come from embracing the platform not
just kind of using it as a service once
we started moving from Heroku to lambda
we were still under the mentality of all
you know we're just going to use this as
a cheap way to run web service or we
just want to use this as a cheaper way
to run queue processing and everything
else is going to be under our control
kind of we're going to keep usernames
and passwords in a database we're going
to kind of authorize everything
ourselves because that's kind of you
know at the entry point of the server
I'm going to validate this is valid user
and then I'm going to kind of trust the
requests coming out and that just
creates an unnecessary bottleneck it
creates kind of more services that need
to be used and different kind of routing
and different constraints where the
lovely part about the whole kind of
lambda thing and I think kind of if
you're in the dotnet space as your
functions are moving into that as well
is it just becomes a very very easy
thing to glue together the other
services available on the platform kind
of one thing that we've kind of started
looking at is and I think that that's
probably behind this kind of marketing
stupid buzzword of service is that the
traditional roles of a server process
are taken over by the platform where one
of the kind of key traditional roles of
the server process is to be a gatekeeper
where you know you're you're you're
sending a potentially risky request to a
server the server does the input field
validation in the sanitization it does
authorization it doesn't occation and
then after that you kind of trust that
thing but what that means is that
basically you have to get somebody to
talk to one server that and talks to
other services and talk to other cell is
just going to blocks all these threads
unnecessarily we're what Amazon is kind
of offering here is a distributed
authentication service
so they have there five or six ways of
authenticating requests but one of them
is kind of Cognito that allows you to
create policies for browsers to talk to
service like s3 queues the database
actions directly and the server know the
server process no longer needs to
authorize that they have distributed
authentication working on the Amazon
scale which means that kind of disco
thing can get pushed out and I no longer
have to get the web request web browser
to go to a server to wait until kind of
some much-much highly scalable much more
highly scalable service goes out so for
example for my map one of the kind of
heaviest processing things are file
conversions it takes a couple of seconds
to produce the PDFs so what I can do is
I can get a browser to send something to
a server then wait a few seconds until
something else converts the PDF then
kind of send it back or I can kind of
let people actually upload directly to
s3 which is stupidly scalable then get
the lambda to kick off when a file was
uploaded to s3
and kind of save it back to the team s3
and get the browser to talk to s3 and
get the file back I've just removed all
the bottlenecks in my software and push
the commas or scale and I don't have to
pay for most of those processing anyways
because I'm not waiting on anything the
browser's awaiting which means that kind
of the client is paying for CPU time
effectively on his machine so that opens
up some really really interesting
possibilities on reducing the
operational cost of the up reducing the
time it takes for something to run
because we can use these services that
are built for ridiculous scale without
even having to think about how do we
kind of get the million people to upload
files at the same time like Amazon's
dealt with that the other thing that
kind of the platform can take over if
you're not kind of too scared of that is
scaling and well you know in my previous
life I was CT over startup I worked as
an architect for a gambling company I've
done lots of kind of things where I need
to be very very smart and kind of
besides how do I ramp up how do I ramped
down how do I manage operational costs
for you know how many databases how many
servers and things like that and the
modern more can we push the service into
lambda we realize the d3 engine if we
designed this thing properly so it's not
really the bottleneck then we just don't
care about the whole thing because
deciding how many containers you run or
when they run or when they shut down or
you know what what you need to do with
those things kind of works pretty well
actually because I assume they had to do
it for Amazon scale anyways so kind of
just benefit from all those algorithms
and the third really interesting kind of
traditional role of the servers that's
actually causing a lot of change it
caused a lot of change in our software
is orchestration the server process
would normally do orchestration you'd
get one request and then would say all I
need to send it here I need to block on
this queue and after that I need to do
this after that I need to do that and
you can kind of still do that with a
lambda container but at the same time
that means that kind of you're just
paying for something that doesn't
actually need to execute there because
most of the at least for what we were
doing most of the orchestration was done
in a single process because we were
scared to let the clients do
orchestration I don't you know I I also
has it in one place and when I've
authorized it in that place I can
orchestrate because we can now use this
tribute to the authentication every
single function gets oh I can call you
or he can call you or you know only this
group of services can call you or this
lambda function has access to this and
that the whole problem with
orchestration or in one place goes away
and we can let the client code actually
do orchestration so we've pushed an
insane amount of orchestration logic to
the browser we're kind of it executes a
horrible scale because or at a massive
scale because you know every every
single client that comes adds another
processor to our application and you no
longer have to worry about any kind of
capacity for orchestration there but
that's taken kind of a bit of a mental
shift for us to realize we can do that
and to start the engineering the app
Amazon is also offering
several workflow engines fork and
orchestrating this whole thing so even
if you decide to kind of you need to do
art installation on the kind of platform
side it's not necessarily something has
to be done in a server process it can be
done through the different word for
engines and for me that's one of the
biggest kind of mental changes that we
had to do to actually embrace the
platform so kind of the the last big
lesson for us migrating the whole thing
was that civilus as a kind of buzzword
and as a platform is often sold to
people as stateless you kind of just
think about every request that you can
independently design it up like that and
it's all magical where the current
implementation is actually not the
designing for stateless actually caused
us to shoot ourselves in the foot a few
times because the environment is not
actually stateless the environment spins
up containers on demand and reuses
containers as it wants to reuse
containers and there's pretty much no
guarantee that two requests from the
same user will hit the same container
even if they are kind of in sequence or
parallel there's no guarantee that they
will hit different containers as well
which means that it definitely
absolutely something you cannot
influence and for example a couple of
times we shot ourselves in the foot by
caching stuff because we realize that we
can cache a database collection and then
it realizes that the next requests
coming in were using a completely log
database connection because it's cached
at the same time there's lots of people
complaining especially kind of trying to
use traditional sequel databases that
cost a lot to contain in terms of
connect to in terms of time so you know
it costs a couple of seconds to connect
to an Oracle instance if for every
single request you want to connect to an
Oracle instance because you're treating
it as stateless you just pay a stupid
amount of money because you can't kind
of reuse some of the things but don't
use the stuff that you shouldn't
and this kind of overly gets overly
complicated with multi versioning
because the containers are tied to
numerical versions and not tied to kind
of environment labels and I'll kind of
deploying the previous thing I've shown
you that I now have development and
production but I also have version 2 and
version 3 and there is actually just a
quick way to reassign label results I
can reassign production to version 4 now
and because containers are tied to an
America version a couple of times what
happened to us is with spin up a service
to test it well and we use the testing
label we tested everything we want and
then we reassigned production to that
numerical version and it ends up we're
just kind of reusing cached testing
environments and it's going to testing
database and things like that so kind of
lambda deceivingly remembers and you
need to figure out that it's not
remembering more than it should and
thinking about this is stateless is not
really good especially kind of for me
stateless means that I can ignore the
environment I can pollute the temp file
space I can leave memory kind of taken I
can you know just stop request halfway
through and you know ignore what happens
with the rest of it but the current
implementation actually is not doing
that one of the most surprising things
for us was that lamda by default is
using node.js
is configured to respond to a customer
request as soon as you provide the
response but not actually kill the
container until all the events from the
event queue are NT emptied out what that
means in any kind of plain English is if
you connect to a third-party service and
the HTTP request takes too long and you
decide I'm just going to say this took
too long and you know tell my cast tell
my user hey it's kind of you know too
long timeout but you don't actually kill
the request going to the other service
that container is stuck and the next
requests coming in is just going to be
stuck and and this caused some weird
weird timeout issues before we realize
that now of course you can kind of recon
it's really really not useful to think
about this thing as stateless it's much
more useful to think about it as
probably hundreds of containers running
and kind of share nothing architecture
where you do need to clean up after
yourself you do need to kind of think
about that multiple requests by coming
to the same thing and you need to
isolate them properly and if you're
using multi versioning the same
container that was two seconds ago used
for testing might now be your production
and there was kind of a massive massive
kind of a brain melt for us until we
realized that we need to isolate these
things properly now of course there's
lots of support for doing that once a
function is executed in lambda through
an event you do get the context of easy
to production is its testing easy
development is it version 25 or 26 and
kind of there are ways of then saying
well you know I'm going to cache
connections for my current label so I'm
not going to cache the database
connection as a variable I'll cash it in
a hashmap that says I got called with
production do I have a production
connection and things like that as it's
much more useful to think about this is
designing for share nothing then
designing for stateless so kind of as a
kind of finish to this that I think
generally kind of the the strengths of
this whole new world that's emerging and
I think there's a ton of changes that
are coming in November Amazon did this
reinvent conference where they've kind
of released a ton of new features and
changed a bunch of things so this is
kind of changing all the time but I
think kind of one of the biggest
strengths of this is a platform for
developers is it time to blow time to
deploy is minimal takes a couple of
seconds to kind of upload the new
version of the code there and if using
node or Python it takes less than a
second to spin up a new container time
to recover with something like that
becomes irrelevant and the really big
question that kind of is you know
messing with my mind at the moment is
which of the things I'm just used to do
because you know I've been taught to do
it like this are because I'm protecting
against a long time to recover and it's
really kind of causing me to revisit
lots of these kind of practices the big
advantage of lambda is a platform for
for companies that are kind of operating
software is a service is multi version
because it opens up brilliant
possibilities of limiting you know this
version to ten users opening up this
version 200 running a version for London
running a version for UK running 20
different versions and kind of it just
costs the same amount of money which is
brilliant and I think a lot of kind of
our current software practices are based
around how much it costs to operate a
version of software which is no longer a
constraint with this platform for us the
whole platform forced us to kind of be
much much more strict about small and
isolated code modules lambda is a
event-driven processing thing so you can
make a lambda get called on a HTTP
request the database triggers a record
being deleted and email coming in
message coming on to the Q Analytics
record popping up and a ton of other
small things that kind of can cause
stuff to do and what really forced us to
do is break away this kind of mentality
of building up large modules that need
to be deployed together and doing this
very very small single purpose single
usage modules that have their own
containers and one of the really
interesting side effects of that is I've
realized we are throwing away in a
rewriting software a lot more than
updating it we've rewritten the PDF
exporter about four times so far and
because it's about a hundred lines of
codes when we need to introduce a new
feature we very very rarely kind of go
and update it we kind of throw the whole
thing away keep the knowledge with it
for writing the previous hundred lines
rewrite it from scratch using a new
exporter or something like that so it
allows us to kind of this whole legacy
technical debt thing is no longer a
problem I can afford to throw away these
small pieces of code all the time and
rewrite them because the platform has
forced me to create small independent
pieces of code and by the way because
mal
versioning is there it doesn't matter I
can kind of rewrite this and still use
the older versions this one is kind of
worked and it's two seconds to kind of
rewire the cartoon is the old version so
the another really interesting strength
of this is a platform is that you do get
very very fine-grained cost of operation
metrics there's kind of a synergy of the
platform forcing people to do small
isolated modules and having to kind of
build this thing correctly so you do get
to kind of learn that all you know this
particular function is costing us five
hundred pounds or this particular
function is causing a 10 second delay in
the process and then you can you can do
educated guesses around where to
optimize how to optimize and what's
really not worth even kind of touching
at this point which i think is
absolutely amazing and the last big
benefit of this is kind of from a
perspective embracing the platform is
you do get to use services that are
built from massive massive massive scale
a week ago we built a chat system for
browsers that can potentially support
millions of concurrent users in about
two hours
because we abuse the AWS IOT gateway
that does WebSocket support so I can do
this tribute it also allow the browser
to the click connect to their web
sockets that are built for in stupid
scale I can have a lambda function
receiving those kind of messages
responding to it in an automated way if
it needs to and because we can use these
things built kind of to massive scale
we've built something that I don't know
seven or eight years ago I worked with
this gambling company they were paying a
third party provider to push messages to
browsers something like you know 100,000
quit a month where now you get that for
free and you get it so that it's you
know probably built a better scale than
what these guys were offering and you
get it with distributors vacation
logging authorization everything and you
can use it in about two hours if you can
kind of wire these things together so I
think this is kind of just the beginning
of this whole kind of again Gartner is
estimated is going to be 75 percent
platform spend in a couple
is because we will be using a lot more
of these services and if you are a
service provider here this is a
brilliant opportunity to kind of you
know plug the service in just offer it
to other people like that so they can
use it at massive massive scale kind of
in tells us the weaknesses the biggest
weakness for lambda at the moment I have
most experience with that was going to
look to the other platforms but I can't
really kind of talk about them is you do
not take it really get any stronger
slays that the stuff works we've never
really had big problems with it there
was a day where it was working slightly
slower over the last year so for my
performance needs for my risk levels
that's okay but there are no SLS offered
on this so if you need to kind of
support 99.999999 it's probably not for
you now it doesn't it doesn't mean there
is not going to be in two years but at
the moment is just not there the other
thing is the whole thing is built for
throughput not for latency the latency
we're seeing are a couple of hundred
milliseconds to kind of get a browser to
educate something and kind of return it
back which is absolutely fine for most
web applications we've moved from
dedicated VMs to lambda and we have
really good monitoring on kind of end
users request timings we've not really
seen any big changes there but high
frequency trading anything that depends
on kind of sub you know sub 10
millisecond latency or stuff like that
just kind of this is not the platform
for that yet technically there's no
reason for it not to be is just not
there yet I guess they need to improve
capacity performance and things like
that the other thing is there's similar
to kind of no no SLA is there's kind of
they're not really offering any any PCI
compliance or anything like that so kind
of storing secure data no starting any
kind of data generally no because
anything can die at any point but
storing and processing cards starting in
processing kind of sensitive data
probably not at this point Amazon does
offer a couple of other services
everything called the key management
service
managed encryption with hardware and
things like that but that's not that
cheap and it's not that performance so
we've kind of farmed out our payments to
PayPal and stripe and things like that
so again it's going this direction where
you do get forced to use other services
all kind of platforms for that that the
big problem or not the big problem that
kind of you know the inherent thing
about the platform being something that
controls the scaling and spinning up and
scaling down is that there's no good way
to keep an open connection from a server
process to something else we try to
build a Twitter bot and Twitter doesn't
have web hooks the way you communicate
Twitter is you start up a process that
connects to I kind of data feed and they
will pump stuff into your data feed but
you need to keep an open TCP connection
that's not really possible to do with
lambda because lambda is limited to five
minutes total execution AWS will kill it
after 5 minutes and restart a new server
so yes you could you know do something
where it kind of dies on its own after 4
minutes 59 and then starts up another
process using async and then do this and
later but theoretically it's possible to
do that but it's not really kind of the
cleanest thing to do and I think
generally keeping open connections is
not something that the platform is
designed to do so it's going to force
kind of a redesign of that another
weakness I think off of this thing is a
platform going into the future is it
does actually in order to get the
financial benefit you know to get
architectural benefits require a
complete rethink on lots of the stuff we
used to do like how do we do versioning
how do we do the deployments how do we
do caching how do we do authorization
and things like that you could literally
take a kind of Express up or or
something like that as a web app migrate
it to lambda it will kind of work but
it's not going to give you any benefits
of distance um so I think it's generally
going forward that the whole kind of
function is a server
servus the real benefits are breaking
down the application to modules not
keeping these kinda monoliths running
and like with anything that's so
dependent on lots of different moving
parts configuration does become quite a
big challenge and there's a couple of
configuration tools and platforms Amazon
is slowly building up something they
call cloud formation which allows you to
kind of configure the whole landscape do
transactional deployments and things
like that but it's still catching up and
I think the platform is moving a lot
faster than the configuration tools
that's why a ton of other open-source
tools emerged in this space to allow
people to configure deployments what
would that the thing I showed you
earlier was actually something that we
open sourced as kind of an and built as
part of suffering through configuration
challenges with my map there's a couple
of alternative platforms it is the most
popular one is called the service
framework when we started mind map that
was internal migrating my mother was in
February last year I very quickly
realized I'm too stupid to use the
service framework because it was overly
complicated for what you needed
I think they've simplified it
significantly since then there's another
thing called 8x there's a couple of
things kind of four most popular
platforms Amazon does their own thing
called Charlie's for Python I think
they've released support for dotnet
recently so I don't think they're any
dotnet deployment tools for that but
configuration really does become a
challenge and the first lambda function
we did just with kind of shell script
deployment had 20 lines of code and had
a hundred and forty lines of deployment
scripts at that point kind of testing
the code is irrelevant you need to test
the deployment scripts and that's why we
kind of ended up again I'm a testing
geek so I wanted to unit test my
deployments and that's why we well kind
of a deployment tool that's kind of
properly tested so I can trust it and
kind of the opportunities I think that
are coming out of this
four people are kind of first of all
this really is a next generation kind of
deployment architecture and Simon
worldly had this post a couple of weeks
ago where he said that if your
organization's not done DevOps yet just
don't bother because kind of used
several s and 99% of what DevOps is will
be provided for you by the platform so
there's not much point kind of chasing
up this because in five years time you
know it's going to be much cheaper
anyway to pay Amazon to do everything
for you and you might as well just skip
the whole generational update then it's
going to process architecture and
everything like that so the other big
opportunity I think although can I see
that is partially a weakness as well
where we need to rethink all these
things actually getting people to
rethink the best practices is kind of
not that bad because we can figure out
how to run faster we can figure out what
parts of our course do we not need to
maintain we can figure out how we kind
of running with those shackles that are
no longer applicable because we're still
thinking about mean time to recovery and
things like that the I'd mention that
they've released a way for people to
actually sell their api to Amazon and
this kind of opens up some really
interesting possibilities to change
billing module models where at the
moment you know people are typically
paying for using an application or some
kind of a subscription but with so low
level visibility and such kind of great
opportunity for metrics in the whole
thing you know there's a possibility to
actually build people for individual
functions if we're offering a service or
build different people more for
different types of usages or kind of and
and pretty much all this stuff comes
more or less for free but what I hope
we're going to see more especially
because these estimates where you know
billions and trillions worth in platform
services is that there will be actually
kind of marketplaces opening up for
these services a lot more so I think
that's probably where you know like I
don't know how much money Apple and
Google are making on their App Store for
mobile apps I think we're going to start
seeing
API stores very
soon where you will be able to kind of
develop an API and going to be operated
and run by the platform they're going to
provide billing they're going to provide
charging and you know you get pay the
money or some percentage of the money
there and of course they'll take a card
but then again you know with the whole I
said we deleted 30% of our code so I'm
happy to give somebody 30% of the profit
where just because you don't have to
write if it's kind of financially make
sense so and I think kind of the whole a
be testing the top opens up for back-end
as well is amazing where most people are
just not doing that at the moment they'd
be testing is something that's kind of
typically reserved for front-end where
now it becomes free so kind of why not
use that and kind of do to finish this
thing off I think kind of there there
are two important threats here that I
you know people need to worry about the
first thing is really kind of
everybody's talking about vendor lock-in
and and not when the locking in terms of
the code there's relatively little code
there that's not my business code I I
develop a lambda to say hey a request
came in for file conversion this is how
I do file conversion so you know I can I
can drop hair request came in and rewire
it to another platform in ten seconds
the big problem is that the actual
benefits out of using something like
this come from embracing a platform so
if I've deployed the numbers and I'm
going to use the s3 I'm going to
dynamite egaita I'm going to use a ton
of other Amazon things just because
that's how I get benefits from this
platform if I'm deploying on Azure on
probably use because your Secret Service
and their web services and their cues
and their authentication and I think
that's kind of a massive massive
platform locking so for me but for me
I've you know been really happy running
on Amazon and I don't really care about
being locked into Amazon but if people
are scared about vendor lock-in this is
going to be horrible and I think the
really kind of interesting risk here is
that as we are pushed to use more and
more of these platform services the
source will become a lot more reliant on
third parties which means that the big
risk in testing is not kind of your
quota
broken it's somebody else somewhere else
changing something without telling you
and then kind of start behaving
differently and that now kind of starts
creating this whole problem of probably
testing in production a lot more than
testing before production kind of having
much better monitoring much better kind
of operational awareness so those are
kind of the threats that I think so
there's two links for kind of more info
here that if you want to look at that
kind of tools I've shown you to deploy
stuff with cloud edges that comment I
tend to blog about these things a lot
because my mind's exploding at the
moment with all the possibilities so
there's some more articles on my website
he can slightly then over time so I'll
probably kind of just go outside and
answer any questions you might have and
let the other people come in thank you
very much for kind of spending this
morning with me and they've told me
please please please rate the session I
shall personally kill a kitchen for
anything that's not green so thank you
very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>