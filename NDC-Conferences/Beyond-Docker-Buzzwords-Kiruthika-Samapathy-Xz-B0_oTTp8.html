<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Beyond Docker Buzzwords - Kiruthika Samapathy | Coder Coacher - Coaching Coders</title><meta content="Beyond Docker Buzzwords - Kiruthika Samapathy - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Beyond Docker Buzzwords - Kiruthika Samapathy</b></h2><h5 class="post__date">2016-10-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Xz-B0_oTTp8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay we get started so we are wonderful
hard just before lunch or maybe during
our lunch you should lunchtime so we'll
see we'll try and make it in us
interactive and as interesting as
possible i'ma qo I'm a consultant with
thought works we are a technology
consultant company and we are in four
cities in Australia including Brisbane
and Perth as well so I could start with
da you know assuming that if you play on
our bingo a game using all the bus word
so I like pretty much everyone in the
room will be a winner you know within
five minutes of a talk you know in any
talk in this conference because
previously if you use the CEO things
used to change you know once in ten
years once and you know five years now
it's like pretty much things change
every few months and especially if you
take things like darker so you have a
major you know version released every
two months so whatever you learn
whatever you do three or four months
back might be kind of in a change now or
become absolute so that is a kind of you
know pace of how things changed nowadays
and before we get into all the technical
details and all art like let's start
with a simple question kind of what's
the feedback loop between your you know
organization on your end users so in a
sense like you know how comfortable are
you with responding to you know they're
changing needs so whatever changes we
are talking about need not be really big
so it may not be totally a new set of
you know cool feature you need to think
about develop and give it to them but
like why simple things like how do you
respond to you know changes another real
time even a very simple example like
enough your organization is supporting a
full you're in a supporting a particular
team and they are playing a deciding
match or you know semi-final match and
you know it's like the game went to an
extra time so you're on that second half
of five minutes and you have like 18
goals each so the game can go either way
but till your team is and the game you
need to react them you know respond in a
way
and depending on the game result
probably you may want to change
something so this is a very simple
example but depending on the type of
business you do depending on what you do
on based on the D all time even you may
want to in or react and you know do
things more quickly and frequently so
whatever we are talking about like kind
of I am y le to market putting things in
customer hon you know generating that
value more frequently and repeatedly
it's not anything new for us right
that's what we have been trying to
achieve you know for a few years now so
how did we start with it so initially we
started with automation so I know edges
back everything was in a manual and
unpredictable so we started with
automation and as you can clearly see
that as we get better with automation it
had a clear impact on the speed of
delivery but sooner or later like you
are going to hit a threshold point
beyond which you know how much ever you
automate you cannot go any fast and
there are lot of reasons for that and in
most cases and one of the major
underlying reason is how the system is
design and how it is organized
historically you know this is how our
applications look so we have like one
single large system and which will offer
you know as many business capabilities
as possible so even if you're offering
you know or XYZ something a different
capability which is totally in a
different to it but still everything
gets packed into one single IT system
and if I have to do a very small change
whether be just or in a single line of
code just a lock statement it is a part
of my entire system and for me to get it
to production I need to basically deploy
my entire system enough to my prediction
so historically that is how we have been
doing but in the recent few years kind
of we are moving away from that Manila
you know one large application into more
towards kind of fine-grained and
architecture more of my chrysalis
architecture so today kind of we can
compare our system to something like
this very have multiple components and
each component might deliver a subset of
features or in the best case probably
you know one single
this capability so it does only one
thing or very few things but does it
well so the very first glance if you
look at it it looks as if you know
everything is so easy to do very
seamless they all talk to each other so
nicely so I can just break it down you
know kind of you know improve my cycle
time make things faster but actually
whatever you know these are features
right most of those features are you
know the characteristics of the I&amp;amp;O
single application so if you have one
single application it's basically easy
to manage it's easy to in our debug it's
easy to deploy compared to us you know
have been managing you know 10 or 20
different components seven if you go
back and refer to I know the definition
of fine green architecture right or a
definition of micro services there are n
number of definition there is no inner
one legal definition for that but the
one I like the most is like how sound
defines it it's like small autonomous
services that could be you know that
work well together and also which could
be deployed independently so though you
have 10 or 20 different components
unless you have a good deployment where
you can you know each has its own life
cycle where you can deploy each
independent of others until we reach to
that maturity level it's not going to
actually give us any benefit so why is
why is it different so deployment is not
anything new for a site like we have
been doing it for many years now so
basically you know we should be good and
that so we learned a lot of lessons over
years so ideally we should be good in
what we're doing so the main difference
you know now is previously we had like
one application or at the marks like we
had like three or four different
application so probably you may have a
big database component and you have a
couple of you know web components and
you may have your you know a player so
we had kind of in a dedicated
environment for them to be deployed and
run so even the days when we moved to in
a cloud but they had an isolated
operating environment just take for
example in this server with a beta
physical server or OBM
or somewhere on a cloud but when I try
and deploy this particular component I
have an isolated operating environment
for that component so nothing else gets
into in the way but the moment we try to
deploy multiple components onto one
single server what happens is like kind
of you know you might end up with
conflicting dependencies so you may have
like you know two different components
one is in you know still in you know
Ruby 19 for some reason the other one is
mood ahead something new which is
started yesterday so I want SAT it on to
take something on the conflicting and
especially if you are in a large inner
enterprise like world very have like
Java coexisting and you starting with
angular and you're starting with
something else you want to try out
something functional I'm pretty sure
you'll have something on java 6 and Java
7 and Java 8 so you might end up with
conflicting dependencies on one single
silver and what else can happen say for
example you have you get an alert from
mission so how do you debug that how do
you know you know what's the reason for
it what's the root cause say you need to
look at all three components for that
and what if you know one of my component
ends up using all my resources on that
server so it's kind of you know denial
of service for everything else deployed
on that silver so all that we are trying
to you know think about is like I want
my component to be deployed to be
treated as a black box I don't you know
I want to bundle everything whatever is
required during run time into the black
box I'll just give it to any environment
to be deployed whether it is on my inner
dev machine whether it is on my test
mission or whether short prediction I
just want that particular component to
behave exactly the same way and all that
I really worry about is how do I reach
that component how do I talk to it if
it's a service you know what's the
contract or if it's a database like okay
what's the entry point for that kind of
does it all sound familiar two beams so
you know then a couple of reasons to
start using VMs but you know one of the
few reasons is like I want my dev
environment to look exactly similar to
my test or I want to replicate those
environment you know in my you know
mission and I want the isolation between
the components how many of us are like
using viens and some form of the other
either on dev or broad a lot of us but
we all know you know what happens like
say this is how we started you know
before using a BM so have your hardware
and you have the OS nothing much in a
special piece of software and you have
like components directly deployed on
that and then we started with our you
know William's so it introduces a layer
of hypervisor hypervisor is nothing but
you know another special I know piece of
software it just depends on you know
which vendor you choose to use and all
that it does is it up stocks the
underlying hardware from the OS so it
takes away all the hardware specific you
know devices and drivers and everything
so that gives us an opportunity to I
know introduce any operating system you
know independent of you know what's your
host and then I can deploy my app in the
beam so over here you get that complete
level of isolation so the know the app
one is completely isolated from up to
but we all know in a demerits of vm
right so you know I can like if I try
and do a demo so I might you know at the
max i can run four or five different
beams that's it and you know if you have
worked on beams on your local machine
you know you know how large they grow
once you start using them and if you are
someone like me who never shuts down
your machine is just you know keeps
running and it's just in a gross to you
know gigabytes so what the other
alternative so the other way is like
kind of I are using our container and
again dr. is just one in a way of
container docker doesn't mean that you
know it's a container and so in this
case like we need a linux operating
system so we'll come back to that and
see you know why we need linux OS as of
today and then you can have a dr. Damon
running and if you have a dr. Damon you
can deploy multiple containers on that
and very similar to VMS how you get an
isolation you know between the VMS you
get some level of isolation between the
containers deployed on the same mission
so we'll go a little bit deeper into an
understanding how we get that level
isolation but you know for you to go
back so if you want to go back and try
something do a spike using docker or use
it in your project so you don't have to
know anything about it you will not end
up you know changing anything in these
but I feel as a dev you know it gives a
satisfaction you know to have an
understanding of how things work at MIT
so in the previous one we saw that
there's a hardcore dependency on the
linux OS so for me to run docker so what
if I have to run docker on my Mac
mission or on windows so I need to have
you know a layer of Linux underneath so
I might end up using a vm mission so a
linux vm on top of that i'm at installed
or current drawn so why is there a
dependency on linux here because you get
that isolation you get those isolation
between the containers using the
capabilities from the linux kernel so it
makes use of combination of cgroups
namespaces and the copy-on-write storage
so it makes it sooo of these
capabilities which is offered by the
linux kernel to give us that isolation
between the containers so just a very
quick look at understanding you know
what these terms mean on how it actually
you know helps is so the first one is C
Group C Group it helps us to limit the
resource usage so if you remember
previously we spoke about if I deploy
multiple components like what if one
component ends up using all my resources
so it ends up using all the memories so
the other components deployed on the
same host you know cannot you know Ron
so you can use the concept of see groups
and you define this particular group of
process can use only this much resources
say for example so the way it works is
you know it maintains a tree hierarchy
structure for process so the moment we
start our mission so it starts the inner
process or in at our system d depending
on in or whatever Colonel be used and
you get a pit one process one and by
default it is allocated to the default
group and the default rules whatever you
specify will apply to this group so
whatever process we you know create
after that will fall under the deep for
default group on under those you can
also create you know different groups so
under memory I can say okay someone you
know and
special memory this particular set of
process will never need so much memory
so a no allocate less memory for this or
probably even have a different set of
process you know DB so these need more
io allocate more I offer this set of
process so you can create different
groups and you can associate n number
process under these groups and for each
group you can define different set of
constraints and different set of rules
and that is how you can you know get
that isolation you can ensure that the
resources are available for you know
multiple containers running on one
single host and going to the next one
namespaces this is one of the most
interesting are you know one from the
Linux kernel we're using namespaces you
can actually define a very limited view
of the underlying colonel so in case of
vm what happens is you have every vm has
a complete OS you know replicated again
but in case of container basically you
know it reuses the underlying you know
linux kernel so what you can say is this
set of you know process can see only in
a row one and different set of process
can see only the inner last row on a
different set of process can see only
that corner of the room so you say that
these process can see only this much so
for those process okay that does the
entire amount of resources available so
if I don't even know that the last Oh
exists so for me you know trying to
misuse that are you set resources you
know impossible and in this case the
resources could be you know your
networking your ports are you know your
user and you're you know build and your
mount your devices so whatever you can
think of as a resource in a measure so
pretty much for all those resources you
can you know create this underlying
constrained view so very similar to what
we saw NC groups so even char you know
it maintains artiste I know kind of a
hierarchy structure and then you can
also see eight different rules so by
default everything is under the default
grew and this is I know kind of
applicable here in case of docker so
when you start a container what doctor
does underneath us it creates a
different name space for that container
so okay container one is started so it
has its own namespace so whatever
processes create
the container once it's under this so
this is the entire world for container
one so according to container one there
are only two processes armpit one and i
have another process 1008 running along
with me that's it and this pit one if
someone from the host machine is looking
at it it will not be paid one so it will
be a process ID with a different number
so this is privileged and you know only
within container it's a kind of that in
a similar to you know very recently we
had our name username space introduced
as well so you know the initial few
versions we didn't have a proper name
space for you sir so if you create a
root user in the container and you know
even on the host machine it used to be a
route but now what you can do is you can
create a root user just within container
and if the user escapes or if you try to
use that user you know on a host machine
or from a different container it's just
a normal user second similar to that you
can create n number of containers on
again in every container will have its
own fit one and if it leaks or escaped
on the host nation itself in a normal
process and coming to the last month so
we spoke about see groups which will
help us to you know limit the resource
usage and then we saw names pieces where
you can you know say this is what is the
resources and the next one is
copy-on-write storage so we all know you
know how long does it take for us to
start a beam so every famine image even
if it is like in a compass and
everything but it does take a couple of
minutes for us to start a vm but
compared to that you know if i have to
start a container it's like really quick
and pretty fast so how does it happen so
it makes use of something called a copy
on write storage so we know that you
know you can create a you know container
on my local mission and take that and
replicate it on any in ohio environment
or just share it with you know my
colleague so the way it works is for a
container the container is started based
on an image so the image is nothing but
our template for a container so it's
very similar to how you have a no vm box
image or if you are on AWS you'll have
an ami so it's basically a template and
this image can be created from the
dockerfile so Dhaka file is nothing but
a set of instructions
you say okay what gets into that image
and every steps which is defined in
dhaka file gets translated into a layer
in the image say for example you can
start an image either from the scratch
where you don't have anything or you can
start an image based on an existing one
so i can start someone something based
on you know nodejs and then I'll build
something on top of it are so is it
could be a scratch or it could be you
know based on an existing image and then
you can have a set of instruction so
these instructions will tell you what
gets into that image second install
couple of things copy the files you need
to or exposure imports you want to so
you can do whatever is required for the
app to run so just pick a simple example
so this is just adding some metadata
saying who is the maintainer for this
image so in this case or doesn't add any
you know bytes to it and then you say
that you're updating something and
installing into next and it's adding you
know as a layer here and every layer it
adds is going to be just read only so
what happens I install engine X here and
in the very next line I go ahead and
remove engine X so all that it does is
it a large another layer and say a
remove engine X so it doesn't go back
and rewrite what is already written so
that we get is based on the dockerfile
you get a layer of read-only images so
that's how you know these images could
be reused between containers so it can
expose a particular port here and then
you say what's the entry point so when
someone is trying to start a container
you know what is the entry point for
this container and if you're trying to
scale right so I have an engineer so I
could you know have a dog image created
fine genex and I started a container so
when you say started a container already
you pull down that image so you have
that image on your local machine so what
if i want to start 10 containers instead
of one already have the image in here so
for starting the other nine containers
exactly same copy doesn't download
anything new so it just uses the same
image and starts you know whatever n
number of containers so it's pretty fast
so everything is a read-only layer so
the way it does says
on the content of each layer it just
creates a harsh so based on the hash you
know what is that and if you have a
difference so if you have creating a
different one for angular if you're a
different image for your app and one of
the you know commands in that stays
install engine X so it will not do
anything new so it will just be used
exactly the same layer so it'll just
refer to the same layer and what happens
when we start a container so we are told
okay it's a read-only it's all I know
read-only you're a layer so when I start
a container based on a given image and
it adds a very in a thin writable layer
just in a specific for that container
and whatever process we start will be
you know within this container so when
we say start a container so it creates a
namespace it creates the sea group and
then it starts the process so all that
process is visible only within this
namespace and the moment you stop your
container whatever you would write in
this layer whatever process you started
in this layer disappears and as you can
see here the underlying kernel is I know
shared between containers you know on a
contrast to VMware for every vm you'll
have in a complete OS ink bundled with
it so when in the container this entire
sludge is going to be just read only
layer and only this specific one is
going to be right whatever right you
know our file system is specific to you
know the file system will live only you
know when the container slimming so the
moment you stop your container your file
system and disappears so this is a
typical silac so pretty much if you go
through any docker and I 101 or dr.
intro I know slide you're not miss this
so they say that okay if I have a beam I
have my app so what if I want to run
exactly you know or two copies of my arm
so I need to end up replicating my
guests always completely copy all my
lips and then copy all the files
required for my app so pretty much you
have to replicate the entire stack in
case of vm but in case of container you
don't need an OS you can just use the
underlying colonel it reuses it and very
first time when you try to run something
it downloads the image which will have
all your lips on
all your files for your app when you try
to you know run exactly the same copy
the underlying images we used only you
know the container right layer is in
replicated for container too and when
there are slight changes so only those
changes are replicated here so this is
what we see in a slight sounder lying
you know that's how it works that's how
you get that to use between containers
any questions still here like or is it
too technical should we go but fast yeah
okay so this again similar so coming
back to a problem whatever we are trying
to solve like okay I have multiple
things to deploy I need to make it
easier I need to treat my deployable
component as a black box the way i
deploy on android dimensions should be
exactly same as what i deploy msci or
the test environment so dr. actually no
makes it much easier though you can
achieve something similar using you know
other different technology and all that
but it just makes the whole in a
workflow very seamless so in case of a
developer I just need to worry about
what gets into a container so what's my
long way to watch my framework you know
what are the files required you know
what's the data required and for the
deployment all that I need to worry
about is you know for me all the
containers are going to behave exactly
the same way and I can worry about how
do I network how do we enable you know
the containers to talk to each other how
do i enable logging how do I get data
out of the container if something goes
wrong if a container dies you know how
do I get the information out of
container so you can clearly see you
know in a two distinct or you know
responsibilities you know if you're
going with contain docker so don't know
like everything sounds cool so I'm most
of us what I've heard about dr. and some
form or the other you know you tried it
you know going through the 101 slides
you know the basic commands so in most
of our cases like kind of you come to a
point where you think about everything
is good but whenever actually use it not
in a knot and all projects not in all
companies you know you'll have a ground
where you can just go ahead and die
an app and start using it on day one
probably you might be in a scenario
where I just know a little bit about it
I know a lot of people are using good
but I would like to learn more about it
but I'm not in a position to go today
and you know rationalize something
change one off my app a problem it could
be a window shop you know where it's
really you know at least as of now it's
not you know don't have a great support
but where else can I use it how do I
learn more about it so lots of use cases
other than just you know going ahead and
docker izing an existing application the
lots of different things we have done it
with in da car in different I know
projects so what I thought is in the
next you know 40 minutes or so we'll
just pick few examples where other than
just Dhaka raising an existing
application where else you know docker
could be used maybe we just start with
the typical workflow so this is what
generally they say you know you can use
docker for say can use docker for you
know building your app as our docker
image so that you see the template and
then you can ship it so it's basically
just show that image somewhere centrally
so that it can inner can access it in
the other environment and you can run it
so based on the image you created and
you shipped you can run container based
on that image and it could be for any
application because all the only
dependence you have is you know you have
the underlying linux kernel so if it's a
lie next mission you can run it
straightforward just install doctor and
run it or if it's a different OS if it's
a mac or if it's a windows you just need
to have a Linux VM on that install
docker and then you can run exactly the
same container and you can run anywhere
where you can install on a dock up a
typical blocks workflow looks something
like this so you have your in a code
repository everything is checked in and
you have a CI server along with your
code repository is specific to that
project you are going to have a docker
file which will tell you how to create
the image for that particular
application so based on the instructions
from the dockerfile you're going to
build an image and do all the testing
and package it and then push that docker
image to a registry so this not
necessarily be a doctor registry it
could be any repository are already
using it could be
pro or it could be artifactory or
whatever you're using as of today and
then when you try to deploy it and
protection you can search for the
particular image again just based on the
name on the tag and pull down that image
so once you have one copy of that image
you can run n number of containers based
on that image so this is the typical
workflow you know if you want to darker
eyes and application but in much of you
know because me being a consultant right
like kind of a get to see different
projects different clients in different
you know their needs are different so
this may not be the need for everyone
and not a given point in time so what
else can i use dhaka for so let let me
start with one of my most favorite thing
so setting up my in a local dev
environment so at least for me it's like
kind of interesting because you never
know what the span of your project so
for me few projects have been like you
know a year or two and then few months
and in few cases it's like just few
weeks and few days so if I'm in a place
just for a week and you know they call
me to evaluate something and give some
feedback and if I'm not able to run that
application on my local machine on day
one kind of there's no value it's like
so daunting you feel like you know you
don't have a lot of freedom to play with
and every time I try to set up something
install something you'll always have
like one very last thing to do and in
most cases that will not be the last
thing so if it dries simple things like
you know you saw cool in a dashboard
especially it happens with the dashboard
for me I don't know why for some reason
because I'm not a UI person so I just
try to copy from other people so you see
something on open source you just you
know download you know consciously and
unconsciously my mind does a git clone
and you try to run it and you were
tweaked something change something
change config get it working and then
you're like so happy go and show it to
people on Monday and they're like yeah
it's really cool let's use it in our
project put it on a bill dashboard put
it on CI then you
lies ok I have no idea how we got it
working I just have it working that's it
so a lot of problems like this even
things like uh huh has anyone tried
installing on super no no window
smashing know okay okay I was it easy
goodness yeah I know Vicki's hurting and
civil like you know I ended up far okay
sound of a tangible and then it needed
pison and then it just not quite them if
needed a specific car in a package
manager for Python so i need to go
behind VIP and then like it just went on
and on and on so it gets into that you
know vicious cycle of where you try to
fix something and then you see a weird
error and then you ask google and then
ask chapeau flow fix it just gets into
that you know cycle so in most of the
cases what you know help answers
creating a docker you know image for the
local development so this could be
specific to project or you know common
to a domain or your or it again depends
how you know different bit is your
projects how different is a technology
what is the knee so all that you need to
do is like get an image put things
install whatever you need so if someone
is you know new is coming so just tell
them installed acha the only thing you
need to install is dhaka install it
start a container start doing work so if
you go through like how we used to like
do it like okay ages bad we tried and
documenting it i'm pretty sure the very
next stage will become absolute and then
you try some rapper script surrounded
put some shell it's okay to some extent
if it is just within a small project it
still works but not you know if people
are changing you know so frequently
right or if something is a long lip
thing if it is just not specific to dev
probably you might end up picking a
conflict too but again like you know i
don't know it depends sometimes it
becomes an overhead actually i'll pack
things into a vm again you have all this
constraints like again like most of the
vm sweded where money managed to Wigan
vagrant again underlying is Ruby
there'll be a lot of you know bad people
like me will go ahead and change
something in Ruby and then
I'll have a different you know question
there'll be a lot of parity and stuff or
run it as our container and I'm not
going to get into the details of how to
do it but that's like really easy if you
just go and search in Google create a
docker file create an image create a
container you have plenty of tutorial to
you know get it so I'm not getting into
the details of how to do it but this is
more about just creating in our banners
creating an idea about this
thought-provoking about okay where else
can I actually use it but rather I
thought I just I know share of you know
some of the lessons learned in my
experience so initially when I started
okay my dimension is Mark so I had to
run on Linux VM firm it installed docker
so I ended up using VirtualBox vm
because it's free and that's what i have
been using yeah yeah for now with drones
but like yeah i started with that and
then it's like the default share was
vbox efes so even the current one
internally it uses be boxer first share
and when you try to mount files you know
from your local machine on to you know
the container it's really really slow so
a lot of other options so even in the
existing one even if you install it I
know NATO internally it uses the i know
boo to doc erbium where you can actually
in a play but I know what amount are you
want to use so i tried different things
like in our NFS share unison Samba and
finally a sink what the best so that was
more seamless and it was really quick I
felt it more like a dev environment for
me it's like I do some changes I need to
see that you know instantly otherwise
it's not my dep and the other thing is
in few cases actually the bill tools
were broken the law most of these tools
actually actively watch for you know
changes in the files and most of these
depend on in a kind of you know the
vario a specific technology so it might
depend on I notify in case of Linux or
FS events in case of you know Mac I'm
not sure about Windows how it works so
most of these tools actually depend on
those technologies to know if something
has changed or not so sometimes you know
depending on what share you use and how
you mount your files this might be
broken so just ensure you know when
you're starting with the dev you be
careful about what mount you use
and ensure you know what ever built
which are using none of Tartus broken
and interestingly this one third one so
what we were trying to do is whatever
dev environment setup we had pretty much
we are trying to translate it into in
all docker container so whatever I had I
just wanted to get into a docker
container and get it up and running and
then interestingly you know someone in
the team must okay why am i using hash
too so one of the projects actually in
test online production we were using my
sequel server unlike a lot of lot of
tons of data but whereas in local and
NCI and the initial unit tests on the
functional test we'll be using history
database because it's quite fast easy
everything is in memory and then like
witches in love using hash to you know
even in this setup you know for almost
few months and then we realized okay now
it's not really so difficult to run on
my sequel database on a local mission I
can spin up wherever I want I can shut
it down whenever I want so why not just
move from h2 to my sequel on the devil
tried and we tried that and it really
worked it's actually good very seamless
say we're in your case is like start
with something simple start I mean
typically will try replicating what we
have into container and see how it works
right again you know put a pause you
know give a thought is this what exactly
you want to do is there anything I can
do so the main a must try and get your
dev environment as close as possible to
your production and the next thing is
moving on it's okay there was one thing
so where else can i use the next very
good golden opportunity is put it on CI
so you'll be using some or the tool for
your CI so why not run your you know CI
server and the agent as docker container
and in few cases not necessarily the
server so you can leave the server haces
you know we can leave the database
horses but you know potentially can you
run your you know the CIA agents as
docker container so the main advantage
of doctors like it's very similar it's
very easy to scale it so I can just
start in all run n number of agents
because you can run n number of
containers on a single machine so you
don't have the constraint there
or in few cases like talk in a few
projects like we had a very traditional
centralized CI and they were breaking
down the path and going more towards you
know where the sea is owned and managed
by the team or the domain so in those
cases we felt like it was really easy to
do it with Daka or you know when things
are you know internally deployed on
cloud especially if you know when you
put things on cloud you want to ensure
that you know because in few cases we
don't really give too much attention to
our CI servers right as much as figure
for our actual application service so
what if this becomes your surface of
attack how do you ensure that you know
whatever you put on cloud is all saying
and good so it's easy to do with your
doctor again so you can have a base
image so the base image could be you
know created and maintained managed by
some central team or someone who's
responsible for that who will actively
look for you know security patches and
sure that all the OS inner security
considerations are in place and the
teams can just go ahead and you're not
create images based on the base image
and whatever you want install your stuff
add more resources which is required to
build your tooth and then extend on top
of it and the next thing how many how
many of you have heard this statement
okay the tests I'm pretty sure I'm
pretty confident that tests are working
on my mission it's broken only on CI
because something else is broken on CI
happens very often right we ended up
like again the cost of those failures
are different so in few cases you might
want to build something or you might be
building missing a tool which is
required you know to build it or you
know some test components are missing or
even cases like you know your
environment does not clean probably
around the previous bill which is like
fell halfway through when I left
something and something like that so it
is really good because the environment
required for building testing packaging
and publishing are very different and
what we are trying to do is do all
everything on a single you know agent so
you can have a nice water and brown fit
is a builder on it within this container
if it's a test on it within this
container and even if something happens
only the container will go blow wit only
here can clean that container but still
your online
machine your agent will still be fine
you can avoid using your CIA as a test
field so what I mean by that is in one
project we were using a koo kumba for
functional tests and not everyone is the
team is very you know hands-on with koo
kumba such very new for them and we had
a small subset in the team who are very
excited about it adding more tests
adding more stuff and they were the only
ones who are actually you know doing
development the other ones were like
copy pasting the code and changing you
know what is required that happens
always so the majority of the team did
not have koo kumba setup install on the
local mission to run so every time they
change something they'll do it is okay
pray God and push the button and just
run it on see I just hope that it will
be green so if it is red I have no means
to replicate it on my dev I'll just go
through this again primal latke gain
change again and again push it so if you
have it if you have a context to run I
know that within this container I know
the Kakuma test for this project can run
such very easy to start the container
either on a CI emission or on your local
on the test so you're not end up
spending more time and understanding
tools and learning different tools but
rather you can focus more on your
application and you know have these
things ready made and last cool thing
which we are doing it in my current
project is no wait time for any of the
bills so it's like we have like tons of
projects and the way it works is in a
one particular project and up kicks in a
build and that is like kind of a ripple
effect so that will start none other you
know triggered ten different pipelines
and they'll occupy all the agents and
everybody else in the queue has to wait
forever so what we wanted to do is
depending on what job is in place I want
to create an Asian I want to run it and
once the job is done I want to the agent
to be removed so we started adding tax
to the jobs so every job will have a tax
so these tax will tell you what are the
resources required so I may need you
know Gradle or I mini Java I may need
Ruby koo kumba so we have predefined tax
so when you submit a job so the job will
you know the tax defined based on these
tags I can dynamically you know create a
container with all those resources in
place so I can create a container and
say this is the agent and then the job
will be scheduled gender on the job and
then once you know on the container
becomes Idol it's very easy to actuate
in for them so pretty much we don't have
agents up and running so we used to have
like a lot of heated debate what should
be our scale and should I be running ten
agents should I be running 20 agents how
do i scale it or should I be running
starting something at 8am and finishing
at 5pm you know like even to have all
that debate look what is the right
amount of scale for the team but this
becomes like more dynamic and more
real-time so when there is a need when
there is a job waiting in the queue
create a corresponding agent run stuff
there and then stop it so this we can do
for any project sale if your project is
old school so you for some reason know
that this is not the right time to
change stuff or you know think other
things are burning I don't want to touch
anything in my project or it's a
microsoft thing not a thing I don't know
how well it is supported as of now but
these are the things it can pretty much
do for any language and any framework
and what the next one kind of civic and
dude dev environment and you can do lot
of cool stuff on CI where else can I use
docker other than for my application so
the other big thing is like we have used
in a lot of places for testing making
testing easy making it you know
accessible and stuff so we were getting
into those stories maybe just want to
have a real quick look at one of these
surveys done in that testing community
so this is just to understand you know
if for all they hesitate to test if they
don't want to write tests when will be
that scenario they want to understand
these scenarios so that they can try and
address them so as you can see how are
like a staggering forty seven percent of
people felt they'll hesitate to write
tests or they're less hesitate to add
more tests if they know for sure that
that's going to slow down their
deployment so if it is going to add time
to their deployment cycle
and also the other related quadrant is
like type of person when the field art
okay whatever I'm going to do is going
to slow down my test or if it's going to
make things you know very difficult to
set up then I will be hesitant to you
know add more tests so pretty much like
all that how many of you have like
nightly Bulls which will go ahead and
clean everything right a clean slate for
you and it'll make stuff so I I don't
know for some reason like I don't want
to do that but I end up doing that so
pretty much I want a clean slate to be
there before my every test run but is
like so damn slow that you know you
can't do it every time so we have like
nightly you so the main reason
behind that is like kind of you don't
have an isolator and braun went to run
your tests so that is why you know
that's like kind of a symptom so the
actual root cause is you don't have a
clean environment because you don't have
an isolated environment or on and we end
up cleaning it but rather try and
address it the other way round what do i
do to give you that isolated environment
so try and play around with that idea
maybe you'll come up with something
different I thought I will share some
lessons learned and you know this space
are some different approaches we tried
and what worked well and just pros and
cons so this is no for testing and
application so I'll have code so you
have code and you'll have a docker file
for that along with that repository and
we'll have all the testing sitting along
with the code so you have all that in a
single repository and then everything is
triggered in a CI so you like it
compiles the cord and does all the
testing and then you generate the docker
image and this docker image step
actually consumes whatever is generated
in this bill so this could be you know I
don't know an RPM file or it could be a
jar file so whatever it is which
generated during your bill so this
particular step just consumes it and
then add applause pretty much in most of
my project this has been the default
approach or this is the very
first name approach because it's easy to
do it makes sense I have testing I can
deploy something else docker so I'm
pretty confident of what I'm doing but
being major disadvantages like over time
what I saw is you have too much of
intelligence built into your CI so it's
not that easy to actually in a separate
your build process completely from your
package so you're seeing these as two
different things and if something goes
wrong in this approach it's very
difficult to replicate that on my
definition because I don't know why
exactly it went wrong but actually easy
to do if someone is totally new you just
want to you know do an example you just
want to showcase it then this is a very
nave approach and easy to get started
and what's the other approach like very
similar to that here again you have the
code dhaka file sitting along with it on
your test code and you have the CI
server and then you generate one single
artifact and then run tests within that
so you might end up having your
artifacts here and then whatever is
required for your testing so when we say
artifact for the app it includes the
binaries for that application whatever
is in a bit and it will also include you
know whatever is the runtime
configuration required you know falter
on the I know up later but this is kind
of very obvious right you don't want to
do that so you don't want to include all
your test components and onto your
artifact you know which will eventually
be deployed in prediction it's very
bloated and it's not the right way to do
it's like very obvious and evident but
this is one thing like we tried in fear
for projects and initially we felt like
for testing it made things easier so it
was easy to test so pretty confident but
comparing this with the previous use
case so the main problem here is though
the pipeline was green in few cases
actually you know the app did not work
the main reason behind all testing was
done only whatever it is say jar file
created here or rpm npm crater here and
then you create our docket and image
based on that and that is something
which is not tested which is
not in your test process so if something
goes wrong in that step you will never
know you'll just your app will not work
whereas your pipeline will all be you
know shiny and green so this will give
you that test confidence but again it's
bloated like you don't want to though
the size of the image is much lesser
compared to vm or you know whatever it
is but still it's bloated and you don't
want to do that on the third approach
which we spend a lot of time and
understanding and failing or different
means is the first thing is create your
deployables artifact so very similar to
that using this I'll create a docker
image and I will have all the artifact
required to run it so i'll have my
binaries alejarme config everything to
run it and then generate a different
image just for test so based on this
docker image have the instructions to
generate a different image so this will
this will become the base image for my
test and then only on this image I will
include all my test artifacts oil
include Saeko Komuro or I will include
you know whatever different tools I want
to run it and then i'll include the
runtime so only for tests I need Ruby
because it's a Java or.net app i know i
do not need ruby in my actual
application but whereas i have some vdd
test written which needs Ruby to run so
i'll include ruby only in this image or
include be you know test data runtime
configuration only for testing include
all that in this particular image and
then run your tests and then you will be
more confident to deploy somehow I feel
if you remember that typical workflow
for dhaka red generally people say build
ship under on personally I feel that we
should change that a little bit we
should start seeing it as build test
ship and then Ron because testing is a
very big aspect and most of my projects
where I tried docker like we literally
forget about it like we don't test like
test for the application we do it but
it's likely changes the cause of your
deployment you don't really think too
much about that you know initially and
especially if you are using your doctor
wash and whatnot 11 or 12 and you have
instructions in
I where you can use on build so where it
says okay you know on Burrell like after
the image is created you can I do
different stuff so you can use that on
build command to say that okay only for
tests and the build time a lot of
different stuff you know only for
testing and I have some you know
examples in place if someone is actually
you know working on this if you need you
know working examples or you know more
information about this I can help you
with and generally there are doctors are
useful only if you are deploying
multiple components say if you have one
single app which is not going to change
forever or at least you don't have a
very frequent release cycle you don't
have a you know release cadence you just
deployed once and three months and just
two or three different application then
using all this is just an overhead
actually it's not really what the effect
but if you have like a lot of services
it's more fine-grained I have multiple
components to be deployed a different
scale you know different life cycle then
it makes more sense but once you have
that droid like your integration test
becomes more trickier because in most of
the cases your integration test is like
nowhere closer to what production does
or how the prediction looks so if you
use a container again setting up that
environment on your integration test is
much easier so even without da car it's
easy to have an automated pipeline you
can do unit testing can do contract
testing and you can do even mini you
know integration just with between few
components but in most of the cases
there will be a need to have a long lab
tests like you may want to do
performance or you may want to do stress
tests or you know all of us know about
caves monkey I want to do that here I
want to see how it works in a Howard
drones say you need a long-running
environment to do all that fun stuff so
using docker again it's like very easy
to get that setup up and running and now
here you are you also have like a
default or scheduling orchestration
mechanism with dakka dakka spa it's like
very easy to even you know set up that
networking and in a set of that you know
structure very similar to what we have
in production so in testing benefits
already we spoke pretty much about it CC
to scale staff second you know do that
scalability testing
run thousands of components on a single
mission easy to do load testing and
again it's easy to have a Phoenix talk
testing environment so you're testing
environment is not polluted so every
time you start your test you'll have a
clean state to start with unknown
nightly pulse okay how many of you feel
confident okay if I have all this stuff
like okay I'll be really confident to
precipitin and deploy stuff now of
course there are always a lot of things
to do one thing I missed okay we missed
most of you know during the initial
adopt a shin of docker is like having a
test driven approach for the docker
image creation or the infrastructure
creation has anyone heard about so
respect work yeah so expect kitchen yeah
so where we try and automate our
infrastructure core infrastructure
through code so instead of manually
creating something I'll have a set of
code a configuration using which you
create your infrastructure but how do
you ensure that whatever interest rate
is good is you know is what exactly what
i define so this is more like a test
driven approach for infrastructure code
itself and a lot of different tools on
one of the tools which I know support
acha rod works well with docker based on
what I know is so a spec and this is a
sink I know aspect based our testing
framework it's really easy to use easy
to understand so you can do you know
testing like say in your dacha file you
say copy this file or copy this command
install this software so install you
know in genetics install boo so i can
write test okay this weather this
package go is actually installed in this
image and also in a based on the image
you can create a test container you know
during a test process we'll just start a
container run your tests and you know
stop the container second start a
container and say say if you are
creating a docker container for Griffin
oh where you can say that okay I'm
expecting a service graph on our server
to be in up and running or if it's an
application you can see I'm expecting
you know up fun to be up and running and
it should be you know under this
particular
you sir chicken do like a lot of
different stuff it's very easy it's easy
to do it's like in other syntax is
pretty simple it's like if you know the
weird is like pretty much
straightforward so my you know lessons
learnt is like don't think it's a hard
thing to do don't diner think it's like
an afterthought okay after I how my
first up running I test actually it's
pretty easy to do when you start with
your very first one start with this
mindset and approach and the other thing
like where I pretty much unconsciously
ended up using it is and most of my
demos so I feel like kind of it might
help too I know trigger that innovation
culture in a large company so if someone
is traditionally you know I have been
Java for you know I work with people who
is like so damn good and javed it is no
in and out it's like but the little bit
hesitant to try something new so if I in
acid like talk about Ruby do Ruby
they're like little bit hesitant is like
no I'm so comfortable in this world like
I don't want to come there so if you
just want to try something new like you
don't want to end up messing you know on
your machine just won't like i'll play
with an existing you know application or
a little app dashboard so it's like very
easy to actually you know share it with
people and if if you're thinking about
are planning for you know dr. adaptation
like or any adore patient for that
matter so what i would say this is like
have a plan have a thought so like we
saw in our examples it wouldn't really
talk about dr. izing any application we
just spoke about a lot of other
different use cases so similar to that
like you might have a lot of other
different problems so when you're
starting with something using a cool app
is one thing but that's not actually
directly translating to you know benefit
or it's very difficult to communicate
you know why you're trying to use
something so when you're starting with
something like have a plan like just
thought about okay this is the problem
this is what i am trying to solve this
is why i am using this particular
technology and when you are doing
something like do it end to end so when
I say end to end when you do something
wrong things on see I put things into
production so most of my initial things
where everything's like Saturn why dem
machine or just within you know
team it never really you know went into
the actual application or into
production so when you do our very first
thing do it n2n put things in production
run it on CI so that will give you a
different I know set of learnings all
together while yeah really actually
again this we did and one of the
hackathons recently so we have to use
our interviews of lot of for customer I
know build off lights so everybody used
to bring in different are you know
boards and we used to drive you know
different things it's more like a
competition between us in the team so we
use like raspberry pi and is there
anyone like we used it what yes so if
you like you said you know it's pretty
cool so every time you do it like you
have like envision where you big like so
you have lots of ideas I want to connect
these things in my home do that stuff
and all that but every time you do a
development in that like you know it's
like pain to deploy something so how the
good news is you can run docker
containers on a raspberry pi the only
thing is like you know I mean it's linux
face again but it's not dumb you know
AMD you are into but it's erm so only
thing is you need to package your app
slightly different so people have
already done all the hard works so you
just go search for it you have lot of
rpi based images in doc hub they just
need a download that image add your
little code and just on it so it's
really easy allow it actually and again
just close with anything will do has a
strong foundation on continuous delivery
so whatever work you do you just because
you do services just because you do
microservices your use our different app
or a technology doesn't mean that you're
going to go any faster and the same rule
like applies for dr roseville just
because you're going to use container
you're going to use car it's not going
to make things any faster unless you
have like strong you know foundation on
continuous delivered go so just recap of
whatever like this this is our like
pretty much the goal for IT forever
never changes so started doing i know
continuous delivery on then everybody's
talking about Marcus services like
that's one of the bus words in
bingo and then you talk about you have a
problem with the deployment kind of
doctor and microservices go hand in hand
so once you have a clear or strategy for
your deployments you'll be more
confident to you know adopt and a
fine-grained architecture n things
change so so fast like you learn about
something today that should be you know
bought by a different company renamed
for something else rebranded or
something else you know get in a
different flavor just in a month so
things st. so much so you may not be
able to adopt everything do include
everything in your project but at least
it's good to have an idea about Dre know
what's happening around so so I just
took a slightly different approach today
instead of going through technical stuff
I just want to talk about where you can
use it so feel free to share your
feedback so this the first time I am
doing in a different style so just let
me know how it was like how you felt
whether it is good bad whatever it is
okay thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>