<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Painless visual testing - Gojko Adzic | Coder Coacher - Coaching Coders</title><meta content="Painless visual testing - Gojko Adzic - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Painless visual testing - Gojko Adzic</b></h2><h5 class="post__date">2018-02-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/S30QXoqLyig" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay I yeah I guess we can start then
good so first all thanks very much for
coming here and not to the kind of
superstar thing that's happening next
door what I'm going to talk about over
the next 45 minutes or so is how I think
over the last four or five months some
really really interesting kind of
developments in technology that's
available to us emerged that allow us to
hopefully change the entire economics of
how we test software with a lot of
front-end stuff the components for this
have been popping up for the maybe five
or six years in different places so none
of what I'm going to talk about is a
revolutionary new idea but what I think
is really really interesting is how
these things really started coming
together over the last I said you know
five five six months and what we can
kind of start using for this so some of
the stuff I'll show you we are actually
using on a product that I'm building and
we took a bunch of scripts that evolved
over the last few months and actually
open sourced it as a tool but don't
worry about the tool that much it's kind
of the principles and and kind of the
ideas that you can use with a ton of
other stuff on on your own products that
are important and if water sure does
look nice again the tool is at the
moment I reckon in an alpha stage which
means that it's useful enough for us
it's probably not useful enough for a
hundred percent of your use case but if
it's 90 percent there that's why github
is there so you know tweak the 10% and
commit so one of the kind of things I
used to do in my previous life before
this tool started taking off is I worked
a lot as a consultant helping people
figure out how to do testing correctly
on in short iterations and
kind of that took me to lots of really
interesting places I worked a lot with
banks insurance companies but I worked
with some weird weird companies as well
and one of the weirdest engagements I
ever had was a fetish sex website in
Germany where kind of they were trying
to figure out how to test some
improvements that they had on on the
front page now I'd love to kind of show
you a screenshot of that but I'd
probably get kicked out to the country
for that so kind of this is going to
have to do so the they were replacing
the front page with something that
allowed people to easier find other
people interested in similar stuff now
this is a site for people who want to do
horrible things to other people or
people who want horrible things done to
them so what they were trying to do is
kind of you know customize the header
picture to show something that's
appropriate for your preferences and
then there was a bunch of check boxes
here kind of all the stuff you like and
then they were just putting random
here that you know who knows you might
like you might not like and mixing that
up and the problem they had is that
because this is so so kind of fringe
nobody was finding lots of matches there
so they were trying to kind of improve
matching and first of all you know this
was completely blew my mind what these
guys are kind of doing and the domain
but one of the things that was really
revolutionary for me there is they were
treating wireframes much much
differently from everybody else where
with everybody else I worked before
their wireframes were you know god-sent
requirements from the designer this is
how it has to look like and normally you
would get kind of one wireframe per web
page that's explaining you know how
everything is positioned at where it
needs to go and that's basically taken
without any discussion now what these
guys were doing actually is because this
was so fringing and there were lots of
ideas they were throwing around the word
they took these wireframes and then
developers and testers and and designers
were kind of playing around with this
stuff to find edge cases and to find
of the business rules in a sense so kind
of this what was fascinating for me
because what they were doing is they
were they were treating wireframes very
much like banks insurance companies that
I worked with would treat examples for
coming from the business so kind of the
whole spec for example of BDD or kind of
you know customer driven tests for them
wireframes were the examples and this is
fascinating to me I mean maybe if other
people working in different companies
that already do this it's not that
important but I I never really thought
of wireframes as hey here's one example
of how it's supposed to look like let's
go and find all the edge cases there and
that became a really really powerful
thing to think about later I worked with
a media company where they got to
wireframe for how they wanna display
news and I said well you can do the same
testing heuristics on this that we
normally do on kind of you know
spreadsheet examples so you look at well
where are the entities well you have a
picture and you have some text what are
the boundary cases well what if you have
two pictures what if you have zero
pictures what if you have two pictures
of different sizes what if the title is
too long what is the title is too short
what if the text is shorter than the
picture a ton of these things that would
normally come out when we start
discussing business examples actually I
realized we can do on wireframes and and
wireframes the just examples of how
something is supposed to look they're
not requirements they're not kind of
god-given they're kind of a starting
point for a discussion much like
anything else and this tool that I'm I'm
building now it's a mind mapping tool
where most of our users ended up for
some reason being schools and although
we started building to scratch our own
itch given that kind of most uses are in
schools that means I'm not a
representative customer and when we
start getting these requests it's very
difficult to know what the actual kind
of user needs so we started doing lots
and lots of interesting user research
and realized that all of these kind of
ideas for features that come well the
best possible way to communicate with
people it'll just start throwing out
examples so about six months ago we
started working on this idea that maybe
we don't want to do just kind of
hierarchical mind mapping because people
wanted to start connecting different
ideas with Addison and and things like
that so kind of the basic example we
connected is something like this whole
concept mapping thing that's a slightly
different visualization you know it's
kind of interesting for this use case
but the critical difference between a
mind map and concept mapping is you
don't have a kind of breakdown hierarchy
you have arrows with labels going all
over the place and we started kind of
okay this is our kind of you know this
is what we need to do this was our user
story this was our requirement this is
kind of but from that perspective it's
just a wireframe it's an example you
know there's edge cases there and we can
use our existing testing heuristics that
evolved over the last thirty years to
kind of evolve requirements from here so
I have variables here that's kind of the
number of nodes the length of the line
the text here and then we can start
playing with edge cases what if this
text is longer do I extend the line do I
break it into multiple lines do i how
how many lines and all these things and
then we start realizing well it's not
just they kind of the text there you can
have maybe one node connecting to two
nodes that's another example and is it
supposed to be like this or is it
supposed to be like this
and this kind of started really you know
being a big challenge because I don't
really use concept mapping we had lots
of customers requesting that and we
realized we cannot answer this question
so and this is a very very similar
situation to you know when I worked with
back a bit banks and I'm not a domain
expert that can come up with a bunch of
examples and the best thing I can do is
kind of offer it to business users and
say we can do this so we can do this
which one and kind of thinking about
wireframes these examples became really
very powerful to start kind of evolving
that and luckily because you know this
thing started taking off and we had lots
and lots of people interested in this
we had about 1,000 people who were
really keen on helping us figure out
what to do so we came up with a cane or
survey that's pretty much like this you
know hey here's two options which one
and then we had 10 or 15 screens like
this and then people voted and we
analyzed what they do we interviewed
people about this and we came up with
something that was essentially about 10
times simpler than what I thought we
need to do because we start to discover
new requirements because we were using
wireframes as examples to kind of elicit
requirements not as requirements
themselves and kind of this is a
fantastic kind of part of what you know
in the development community we normally
called behavior during development or
aspect for example we have these
examples they helped us evolve the
requirements we have a good conversation
and kind of the part that's really
missing from here is kind of when we
typical behavior driven development with
it because spec by example you end up
with a nice spec like this and then you
can actually run it as a test and you
can say well you know this thing past
this thing failed I know if I'm complete
or not and kind of we thought well this
Kano analysis that we sent out and
people voted and then we interviewed
people kill the winning combinations are
actually our spec that that's what we
need to do that's what we promised to
people to do and from that perspective
you know we're almost here but we never
ever ever do automated testing on
wireframes and kind of then this kind of
really started you know bugging me like
why don't we do this for your examples
like if if you wireframes the rest you
are examples why don't we kind of close
the loop because then we can do our kind
of feedback better we can you know in
this case this is a consumer driven
product so we don't really have lots of
stakeholders that need to approve or
complain but in other cases we're saying
you know I've mentioned this media
company they had lots of designers that
were all arguing about this and business
stakeholders they came up with some
wireframes
two months before the development
started they pushed it into development
and then kind of of course it went off
the rails but
they were reviewing the wrong things if
they have their specs as you are
examples and they were able to validate
and close the loop then maybe designers
would have been able to get involved the
same way kind of business experts can
domain experts can get involved in the
banks and provide quick feedback we can
speed up the feedback quite
significantly if we can do this now but
we started looking at why you know what
why cannot we do this for your examples
because can nobody's doing this for your
examples and kind of very quickly you
know we ended up concluding that this is
impossible because of how UI testing is
done and you know at NDC and many other
conferences you have people every year
talking about how UI testing is
problematic especially kind of if you
hear from a developer perspective most
UI testing tools are designed for
testers on a different continent they're
designed to optimize hiring 500 people
to click through something and record it
which you know as a developer makes me
vomit so it's something that is horribly
difficult to maintain it's something
that we tend to avoid as much as
possible and kind of we I went on you
know many stages like this over the last
15 years and told people just don't
bother with the UI testing like tests
below the UI leave the UI for
exploratory stuff because it's not worth
it because you know the number one rule
of your testing is going to be slow so
don't just you know as a developer you
don't care about their slow tests leave
it for somebody else so kind of automate
as much as you can that the second rule
of UI testing I think that we've come to
accept as an industry is that UI testing
is brittle so UI tests change if you
have a UI test and then you change a
link into a button everything breaks and
then you have to adjust everything and
that takes a lot of time that's painful
so even when people invest a lot in UI
testing they end up throwing it away and
kind of the third thing with UI tests
especially with automation is that
we've accepted as a rule that generally
kind of regardless of how much you
automate stuff can go wrong on the UI
and the automation is not going to catch
it because automation can only look for
things it's trying to look for and if
you're not looking for things moving a
couple of pixels or if you're not
looking for changing the color then
horrible stuff happens in the UI and the
UI is completely broken but your tests
pass so we've kind of accepted these
things as something that is given and if
you look at you know UI testing gar
tickles online what you find is kind of
this ubiquitous pyramids that ends up
being all you know 90% of your tests 50%
whatever you know is unit tests then you
as you go up the level of the UI you
know start reducing it have only few
tests that going to end now there's 5
million variants of this pyramid it's
whether the top is end to end or whether
the top is UI or whether the top is kind
of acceptance and
genican of all these articles talk about
how you should have only a few UI tests
end-to-end tests and they're brittle so
you're going to suffer but that's ok
test everything below the UI now the
problem with something like that
especially for us is that most of what
we provide is good UI so if I test
everything below the UI but my critical
competitive advantage is good UI then
I'm not really testing what I need to
test and I am in my previous previous
life
I studied maths before you know no
benefit whatsoever apart I'm just
postponing mandatory military service
and one of the things I was kind of
really interested in there was geometry
and how kind of about two hundred years
ago some people independently in Germany
and Hungary kind of took stuff that
kind of the civilization took for
granted for 3,000 years and found a bug
in it and found a loophole and basically
turned it on its head and kind of the
rules of geometry that stood for you
know thousands of years were defined by
Euclid who assume that you know parallel
lines don't touch each other and they're
always at the same distance and then 200
years ago somebody said well what if
that's not true can we you know if we
flip the context do we get something
that falls apart or do we get something
that kind of still holds water and they
actually came up with changing the
context something that is now very very
useful for space travel and things did
they change curved geometry so I was
thinking like um ah is this really set
in stone or is this just our current
mental constraints because we're not
thinking about space travel we're seeing
parallel lines here at the same distance
so that's not a problem at all and
that's why I think kind of these things
are not really rules they're kind of the
Euclidian axioms of UI testing and if we
can flip the context if we can change
the context for this stuff then pretty
much all of these things can be worked
round and that's why I think is kind of
happening with current technology last
six months last year because there's
some really interesting kind of new
releases in popular software that allow
us to kind of flip the context so kind
of I'm going to tackle this one by one
and and kind of the first I wanna tackle
is is kind of the whole brittle thing
because slowness is something that we
can work on by throwing more hardware at
it that's not a problem at all but
brittleness is where humans need to get
involved and throwing more humans that
the problem is never really good so kind
of in terms of brittleness the the big
problem with as I said most UI level
testing stuff is that the UI level
testing stuff tends to be oh I'm gonna
record my interactions with this or I'm
going to kind of put it on a video and
assembly
interesting tech emerging in the market
for example I was in Vienna
two days ago speaking at a testing
conference and as a guy who worked is
developing an artificial intelligence
kind of monkey to click around the
software and find coverage paths to open
up all the screens and then kind of
record what's going on and try to kind
of look for aggression scent is that
it's kind of really interesting stuff
that's emerging there is kind of how can
we record our stuff better but I think
as long as we're getting into this
record and replay mode that that's as a
developer kind of it really feels
horribly wrong because every time a tiny
thing changes over here I need to go and
really cold or my tests so that's you
know it just incompatible with my brain
i I don't want to do stuff like that and
kind of if you look at the language
where we're kind of describing tests so
you know but selenium has you know open
click lick lick lick lick lick lick lick
lick lick open click click click CSS CSS
CSS yellow and then if anything breaks
in between you're screwed so although
this is amazingly good to keep people
busy it's it's horribly bad as a way of
maintained no no it's not it's not
correct selenium there's lots of good
use cases for this I'm not selenium is a
really good tool but this way of
describing tests is just bad and for
some insane reason testing managers in
large organizations love this stuff
because they are trying to optimize the
process of writing a test I've been in a
couple of sales sessions where you know
people that are peddling some kind of
heroine testing tool show oh look I can
record the tests amazing stuff and you
don't need grace for this at all not
like you can you can get somebody you
know who's a student you can get
somebody who doesn't speak your language
you can get so you know it doesn't
matter get to get aliens get amoebas to
kind of click through this and you have
a test case it's amazing stuff and then
people buy there but kind of
for me as a developer the time to write
the test case is really not a problem
the time to maintain the test case
becomes the bottleneck and especially
with automated tests I think I the more
I think about this kind of already is
the more I realize that automated tests
tend to be valuable when they fail not
when they pass when an automated test
passes you know doing anything there's
5,000 tests you run the build they pass
nobody does anything but 5,000 tests you
run the build and two of them fail
that's when humans jump in to
investigate so optimizing the process of
writing the tests is completely wrong
optimizing the process of
troubleshooting is optimizing the
process of reading it is where we can
save a lot of time so this is optimizing
how we write the test that that's wrong
now as an underlying technology to drive
the browser's selenium has a lot of
value but not as a way to describe the
test case that's that's the key thing
now
this some other stuff that emerged it's
really really interesting where people
are talking about don't worry about this
click lick lick lick lick and then you
know something changes from button to
label that's difficult to maintain and
the next generation of tools like this
was something like securely where you
can actually clip things so if a button
changes to a link you just clip that and
replace it in the file system it gets
replaced and it isn't any kind of
although that's reducing the cost of
maintenance slightly it's still
difficult to understand when it fails
it's still tied too much to kind of the
whole process of clicking and and
interacting with the site and it's too
brittle it's just too brittle so kind of
we started looking at this and I
realized kind of this is a completely
wrong way of describing test not just UI
test tests in general because if you
look at something like you know a recipe
for a scrambled egg you say well you
know first you beat the eggs then you do
this then you do this then you do this
but I can bet kind of all my money that
nobody who goes into a restaurant when
they come in and say well you know what
would you like to eat says Oh first
thing I'd like you to do is kind of get
some excellent
and then you know spin them around and
then cook them for 30 seconds and then
do this and do this see my geeky about
scrambled eggs like I really don't care
how you prepare them just bring me
scrambled eggs and if you're you know
heater doesn't work that well then you
know figure out how much you wanna cook
it if I tell you 30 seconds I have no
idea how much this thing is going to
work so maybe it's gonna be overcooked
maybe not so you know bring me scrambled
eggs and good test cases tend to focus
on the intention they don't tend to
focus on the implementation because we
want them to kind of be independent of
implementation so that if we run it on a
slower Hardware they're okay for a
Nutella faster huh if I ran it in Chrome
if I ran it in Firefox I want to test
the intention I want my test to be this
stuff here so kind of from that
perspective that the kind of beady
respect for example community talks
quite a lot about the distinction
between what you put in the spec and
what you put in the automation layer
we're kind of the guideline is that your
spec your examples are what you want to
test not how you want to test it and the
automation layer is how you want to test
it but not what you want to test by
splitting what and how we make things
maintainable we make things easy to
understand because if a link changes
into a button I I flip it here it's I've
changed the process of testing but my
test is still the same if I change
something where I'm no longer using
decimals I'm using kind of strings
that's fine I trained it in the process
of testing at the same time because of
decoupled waton how I can reuse the same
process for many many many examples so I
can add more examples I can manage to
miss a second of this is you know
emerged as a relatively good practice to
manage and maintain very large test
Suites and the thing is can we look at
what we were doing and you know this
whole quickly quickly click or even you
know this image this image this image
that's all talking about how we test
stuff that's not talking about what
we're testing so we started kind of
thinking about this from different
perspective like I really don't care how
we go to the result as long as there is
is okay but how do we describe the top
level there and then one of the things
that we started doing is because our
stuff kind of renders into SVG at the
end I can say well you know if I'm doing
the connector function it should set the
dashes if the line style is dashed so I
will set the line stuff to - the owl
shut it into the system on the test and
if the line style comeback is dashed
then this is okay so that makes a test a
lot more maintainable it makes it
independent of the interactions that led
to that but the problem with this stuff
is it's almost impossible to maintain
and it's almost impossible to maintain
because kind of we we completely did it
at the wrong level these two things are
simple but then you start getting into
some more complex examples and more
complex combination starts looking like
this and a really interesting thing with
something like this it is like cement
it's like cement from a perspective that
you do it once and then when it hardens
it becomes really really difficult to
change for example what happened about a
month after we did this stuff we decided
to change the fonts now you change the
fonts everything moves everything moves
by pixel f2p you know two pixels up it's
still correct and all these things like
you know positions and they are
deterministic but because all of this
stuff moved I need to sit down and
recalculate them on paper to understand
whether the expectation is right or not
if I really want to do TDD properly then
I need to spend two weeks recalculating
all this stuff and this is error-prone
you know my brain doesn't work that well
I studied maths 20 years ago I can't add
numbers anymore so kind of like we
decided well kind of should we just I
don't know throw these tests away but
then if I throw these tests away I'm
flying without a parachute so that's not
a good thing as well and we realized
kind of going back to this thing that
it's not even just what versus how it's
kind of the top of this needs to be in a
human syntax and the middle part is in
kind of the Machine level syntax and if
I look at something like this this is
actually syntax error from a testing
perspective it's a syntax error because
this is not what I promised to people I
have not promised to people that I'm
going to deliver an SVG that has when
you put in these arguments it has you
know translate 80-20 what of kind of
started promising people is well this
thing is going to be left of this this
thing is going to be top here this thing
is going to be right and we started
looking some in other interesting tools
for example a gym short built a UNIX
testing tool for CSS that is cross
browser compatible that allows you to
kind of raise the level of abstraction
and you can say well the navigation bar
is supposed to be 10 pixels above the
bottom of the header and B it's supposed
to be aligned with the left it's
supposed to kind of have the width of
the viewport so there's lots of these
assertions that raise the level of
abstraction significantly and there's
another tool that's really interesting
kind of that came into that it's called
garland framework garland framework
allows you to kind of even do away with
the you know asserts and and the idea of
the garland framework is so that
designers could engage with this stuff
because designers are not going to be
able to write this but designers can
theoretically write this stuff as if
yeah bear with me for a sec so kind of
it's supposed to say oh well on on a
mobile on a tablet the comments section
is gonna have this width and it's going
to be inside the screen so it's kind of
readable but so this is kind of human
syntax but at the same time this is
suffering from the same problem that
selenium automation is suffering from
it's describing how we test something
it's not describing what we promised to
people will deliver because what we
promise to people to deliver is this not
this kind of I don't want people to read
all the this is what I promise to
deliver this is what I read to deliver
and kind of this is kind of the level
that we need to work on and that the
kind of the key thing here is that
once we start thinking about this well
well you know the screenshot is
something that we can automate and test
theoretically why don't I grab a
screenshot and I can have my kind of
expectations designed like this I'll run
the whole thing you know I'll run and
compare the screenshot so there's five
million screenshotting tools out there
now the problem when you start thinking
about screenshot thing like that is
automation really becomes unhelpful
because yes I'm going to take a clip of
kind of this part here but then we get
into the problem of testing only the
stuff I'm expecting to find where UI
stuff tends to be a lot more problematic
for unexpected things you know this is
the cover that now over kind of these do
you have a part of the screen that's
moved too much on and and all these
things are tangental you don't you don't
look for them it's just weird when you
start testing and this is when kind of
we run into a really really interesting
case study from the video games industry
there's um there's a generative universe
video game that launched a couple of
years ago called no man's sky normal sky
is a game where you as a player were
supposed to be able to fly to any of
something like 18 quintillion worlds and
inside those worlds you should find
enough interesting stuff to play and
play and play and play and play forever
in order to generate that level of
variation what they started doing is
they started modeling some animals some
buildings and stuff like that and then
they had random mutations for each of
these worlds no no kissing random
deterministic but the driven by kind of
a process with a lot of different scenes
so you know on this world they would say
well the turtles are gonna be red and
they're gonna walk on two legs and we're
gonna put a chicken head or a turtle or
you know we're gonna create some I don't
even know what this is a mix of the
alien and Stegosaurus with gazelle legs
or something like that now
the problem with this kind of stuff is
it's almost impossible to define
correctness because it's supposed to be
interesting in random but you know is it
a right or wrong that a traitor has
Diego at the head or a chicken I don't
know
nobody knows plus when you think about
these 18 quintillion worlds even if you
had the entire Google Cloud and a SS at
your disposal testing all that stuff
would is gonna take I don't know forever
so kind of asserting correctness here is
is impossible in today's technology even
though the process is deterministic and
what they've done is they've done
something kind of very similar to how
NASA Explorer space they've put probes
that are software kind of probes flying
around this universe jumping to random
planets and filming what they see and
showing that on developer monitors just
you know for a couple of minutes and
occasionally somebody would spot
something weird and they would say look
you know this lion is too big they can't
walk on legs this small let's pause
let's figure out why we generated this
stuff lets you know modify that and then
really generate that world and keep
playing and one thing that was really
amazing for me here is that they
realized that kind of the process of
evaluation still needs to be left with a
human but the process of collecting all
the data is what's tiresome the process
of collecting all the data is what's
difficult and the automated the process
of collecting all the stuff by you know
showing a probe that's flying through
the space and let the human make a
decision whether this is actually good
or not and in that respect kind of I
realized that what they were doing is
they were automating to assist humans
not to kind of replace them and going
back to our SVG tests what we ended up
doing after about three rewrites is
saying okay what I'm gonna do is I'm
going to generate all these documents
and because they're SVG's I will look at
them and I will see if there's some
weird going on
and what we started doing is thinking
about well if we're kind of generating
all these tests mind maps and concept
maps are just looking at them every time
we spend 95% of our time just generating
them so I can you know keep the part of
the process where I need to actually
make a decision for me everything else
can be done by the machine and this
thing really started kind of lifting
things off because then we just threw
away all these bad horrible tests where
we're trying to do minus 80 minus 50 I'm
no longer even comparing that because we
now can compare visuals so this is where
I said we've we've polished these
scripts enough and we're open source the
tool called appraise that's designed to
get people to do approval testing like
human approval way with some automation
to collect the data you can find it on
the appraised dot QA domain QA is a
domain it's for Qatar but hey you know
doesn't matter so I'm gonna very quickly
show you this just so that you know it's
it's not a total kind of theoretical
thing so if I connect to this let me see
if this is going to work so
this is our actual kind of product code
so we have we started building a bunch
of these example pages and in the
example pages let me see so I was
talking about connectors so I'll show
you the connectors so on github we have
kind of the a test that says an example
that says without any properties the
connector just stays like this then we
have a test that says kind of if I said
the color I expect the connector to look
like this then another example is if if
I said the line style I expect it to
look like this and if I set the label I
expect it to look like this those are
kind of some basic examples that can
come from a drawing from a napkin from a
wireframe from whatever we want and
they're kind of in markdown so the
render nicely as documentation for us to
remind us what we need to do but kind of
if you look at this stuff here what this
says is this is how I'm gonna execute a
test and this markdown is at the same
time a fully automated test which I can
run and now I can do and this starts
kind of running through all these things
and saying well for each of these things
I'm going to get the example you gave me
like line style dashed I'm going to put
it into the fixture I'm gonna go through
this whole process of testing it grab
the clip you told me to grip grab and I
will compare it to what I got and if
there's no difference is you really
don't need to care about this if there
is a difference we need a human to look
at this so for example if you change the
font I will change the font all of this
stuff is going to fail and then somebody
can look at this or something is going
to fail so kind of it
so I get this stuff now where everything
is kind of green green green and the
connectors page says well you know these
things all executed with like
documentation let me break it now so
this would be in source right connector
for example so I'm gonna do not kill the
dashes or something like that so let me
make the width so I'm gonna make the
width kind of larger and then if I do
now I'm getting a difference here and it
has no idea whether the difference is
kind of right or wrong but it's letting
me very quickly review this and it's
going to say well you know for this
particular example hey there's something
wrong don't worry about all these other
great out pixels what about this stuff
here and then I can go into this and I
can say well you know this is your
expected this is your actual is this
what you wanted to do like if you want
to get connectors to be thicker I don't
need to go and recalculate five million
SVG points I can see yeah this is okay
or I can say oh this is not what I
wanted to do and then go back to this
and you know that from this perspective
what I can do then is I can just approve
this example and what it does is it
takes this thing it that becomes the
next expectation even if this is okay
this is not okay then you know we do
something well so we've kind of
automated effectively to assist humans
this kind of some really cool stuff we
built here like you can change the
opacity of expected and actually you can
put them side-by-side you
you cannot show the different things
like that it's all designed to allow me
to very quickly make a decision is this
right or wrong because humans get
involved when tests fail and I want to
optimize that processor the one optimize
the process of writing a test but by
kind of splitting what and how here I've
also enabled myself to reuse the same
process of automation for all these four
cases if I want to add another case it's
trivial easy I just kind of have so I
kind of go down and I say well you know
I'm going to set another case here that
is come on what have I done so we're
gonna say in this cylinder and if I set
the label to be
so I've not provided any expectations
here because I really don't know what's
gonna come out and when I run it like
this is going to say well you know what
one of your tests failed and now we have
an NDC test that has no expected result
is provided here's what it looks like is
this okay
it's okay and that becomes my automated
test I have not kind of spent five hours
calculating the actual SVG points it's
something that I can out take it now it
said this thing is relatively raw it's
designed for me I'm a command-line freak
I like doing stuff on the command line I
can now approve this and I can say and
now when I run this stuff it kind of
works okay and then if I do a what you
see is kind of a took something and it
put it into the kind of expected result
and that's it now it said it kind of is
designed for me I'm a command-line freak
so III don't mind playing around the
command line but I understand this is
not what you know most people do but
this is you know 90% there I'm working
on a interactive website where a
designer would be able to review this
and say yes I approve click a button and
because this is markdown withdrawn in
version control I can tag branch magic
have different versions of this I have
all the benefits that as a developer I'd
expect from a testing tool instead of
you know going to record the replay and
having some you know horrible script
saved on some server somewhere on
somebody's laptop that I have no access
to I can do all sorts of weird
things with this because it's it's in
version control now kind of days um what
this means is this this is no longer
brittle that much because it doesn't
take too long to spin it around and it's
no longer kind of that problematic from
a perspective Automation isn't that
useful because this will you know look
at the whole thing if I won't look at
the whole thing and just show me the
diffs so I will you know look for
unexpected things as well but kind of
that brings us to the last point of it's
slow if you want to launch your website
if you want to do by the way the reason
why this is possible now his headless
chrome got released a couple of months
ago before that we had phantom Jas and
phantom J's never really worked
completely as normal browsers so there
were JavaScript differences there were
CSS differences and the fact that
something passes in phantom trees
doesn't really give you the confidence
that it works + phantom Dre's never
implemented es6 and then we had you know
a testing code that would say well if
phantom then do this if not phantom do
that or you know screw that that's not
real testing I can run this in chrome
the way my user seat and I'm actually
doing it in chrome this thing launches
headless chrome takes screenshots and
stuff like that Firefox kind of released
a a headless version in the night list
so that's coming to a production version
soon as well which means that you know
we can cover quite a nice user base with
actually how they're going to see this
stuff and unfortunately as I said run a
website ran lots of code capture the
screenshot it's slow and it's always
going to be slow so as a developer you
know I've been trained to think my unit
test is you know below 10 milliseconds I
can run thousands of unit tests to get
feedback quickly it's useful when I
think of a UI test I'm thinking of
something like two to three seconds so
I'm thinking well you know I cannot
possibly run a 5,000 of these I I cannot
possibly them
20,000 of these because they are throw
and this is where a really interesting
kind of thing starts to come into play
because if you think about this stuff UI
tests are not necessarily slow they just
introduce a lot of late
see what I mean by that is each
individual UI test is two to three
seconds but if there was a way for me to
run 50,000 tests in parallel I will get
feedback in three seconds so kind of the
slowness there is not as much as long as
it is latency and this is where you know
in order to run 50,000 tests in parallel
I need 50,000 machines I told you like
you know I don't have 50,000 machines I
don't have the economic capacity to do
that and yes I can rent it on the cloud
but renting that on the cloud and
keeping and paying for that reserve
capacity is insane nobody's gonna pay
for that now another really interesting
piece of tech that kind of came out a
couple of years ago but really became
usable last year is AWS lambda with
lambda you do not pay for reserved
capacity you pay for utilized capacity
if you use lambda for a hundred
milliseconds over a three month period
you pay for that hundred milliseconds if
you use lambda today for three hours you
pay for those three hours it kind of
gets away with the whole thing on its
own and kind of couple of like two
months ago somebody recompiled headless
chrome to work in AWS lambda which means
I can now provision thousands of
instances of my tests like this and I'm
only paying for it 20 turns and this is
dirt cheap so kind of from a perspective
of UI testing being slow this thing is
the Euclidian thing that changes the
context it's no longer slow and it's no
longer expensive if we design it to work
in this because I can you know only
commit deploy stuff to a table slammed
by the way this is the URL you can get
it from I can deploy this stuff to a SS
lambda I can pay for you know a thousand
machines running for three seconds and
that's it I get my feedback from from
all this stuff now kind of I have not
yet plugged in that the tool we are
building into lambda but Desura said
don't worry about the two
you can implement this on your own for
other stuff once I stopped traveling
like a maniac a bit then I do plan to
kind of just use the lambda to generate
screenshots we've designed the tools so
that it has a pluggable a screen shot
kind of module because we wanted to put
Firefox in it as well now we can put
headless chrome in lambda or you know if
you're using some kind of mobile device
farm that can run your stuff for lots of
different mobile devices you can just
take screenshots and use this stuff to
say well you know on Android I don't
know
version seven million five or on a
japanese locale this thing no longer
looks the same and there's somebody can
look and say well you know that's what
expected it to look like so you know go
ahead and we can kind of use these
principles now that's why I think kind
of did that the time is interesting now
headless chrome came out a couple of
months ago lambda became really usable
last year and you know although most
people still think they can't really use
lambda for production work because of
compliance because for testing purposes
perfectly funny I mean we do use lumped
in productions all but even I said even
if you can't do it for your production
code why not play around with it for
lambda for testing so and this is where
I think you know this turtle we can put
lots of balloons on it and make it a
badass turtle that kind of although it
is slow on its own if we do fifty
thousand in parallel then you know it's
three seconds so I think kind of what
we're getting to here are really you are
unit tests something that I have
thousands and thousands that kind of
look at different parts look at
different examples that are really
making it useful for me to do wireframes
as examples and to use them as they kind
of start to a conversation come with all
these different ways of how data might
modify how the UI looks and then have
something that in three seconds tell me
yeah that this is okay this is not okay
or a human needs to look at this so kind
of a is a conclusion what I think is you
know different now is components for
this stuff existed a long time ago
people were doing different images
that's not a problem at all we had
headless browsers like phantom we had
ways to execute stuff in the cloud
expensive now kind of part of why this
is different now and what we can do with
it is we can really use automation here
very much in the BDD style to improve
the communication between different
roles I don't have to show a designer a
script where they need to modify stuff
by 10 pixel 50 pixels or kind of do all
these weird assertion stuff
give me a drawing like draw it on a
piece of paper I will put it into the
tool I will show you the death and
actually we've done that a couple of
times I had a picture we put it into the
testing tool we executed the software
and then we looked at it overlaid and
said well you know kind of this looks ok
so let's approve the picture to go from
then on we have acceptance tests on a
napkin and kind of the I think first
thing that's really interesting here is
when we start doing this stuff it
becomes really easy to change examples
you know anybody can just take the
existing picture move it a bit in
Photoshop use an SVG editor or even if
you don't draw it again on like I ever
iPad pro I can take a photo and you know
draw something to say I want it to look
like this now then I run it of course
it's gonna fail look at this and say
well that's okay
so examples become real easy to change
it becomes really easy to add more
I just add another line to mark down you
don't even need to have an expected
cases I need to tells you what it is
somebody can look at it and decide
whether it's right or wrong it becomes
easy to kind of keep focus on the
important parts because I you know if my
interactions are important I will have
an interaction test if I want to test
look and feel I can test look and feel
with this and and we can split what on
how we can kind of evolve this in lots
of different ways and kind of finally I
think you know what once I finish the UI
and we have a push button for kind of
people that don't want to use the
command line to approve this stuff this
becomes a little interesting link with
the designers from a kind of developer
perspective these are tests you're not
gonna vomit about these are testers are
not gonna hurt your stomach because it's
not recorded play and it's real easy to
change flow I I open up my script that
kind of runs all this stuff I change it
where it needs to go I'm not damaging
five-minute examples are not
recalculating that from our perspective
useful for us as documentation as well
like I can look at the github rendered
markdown here or even this stuff and I
can see well you know these are the
things how we discussed this six months
ago and we have a ton of this stuff for
for lots of aspects of our system
because when we're changing something I
can say well this is cow you know this
is this is what we agreed last time how
do we want to change it down it's kind
of documentation as well imagine if
you're doing something like reactor or
or or angular and kind of all these
components you're generally think
somebody needs to consume well here's
the documentation if you change this
parameter is going to look like this if
you change this parameter it looks like
this if you change this parameter it
looks like this and it's not something
that is difficult to maintain because
you need to regenerate all the
screenshots this is kind of giving you
automatic documentation and kind of the
last really interesting thing I think
here is can it becomes really really
easy to maintain these fixtures that it
becomes you know it's code I can I can
do all my coding tools on this I can
maintain it using version control and
and kind of it's not there yet but I
think you know it's not too far to be
designed for massive parallelism it's
kind of the design is there we just need
to implement this paralyzation with each
point we have flipped the context and
these things are no longer kind of that
slow brittle and and difficult to
maintain so that's kind of pretty much
it'll hang around if you have any
questions but I think it's lunch now so
I'll let you go and have lunch I just
want to kind of shamelessly plug my
latest book human vs. computers about
people being stuck between bugs and and
stupid assumptions is stupid software so
if that's the topic you're interested in
kind of have a look at the book thank
you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>