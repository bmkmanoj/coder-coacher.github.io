<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Effective Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano | Coder Coacher - Coaching Coders</title><meta content="Effective Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Effective Eventual Consistency with Actor Models + Amazon Web Services - Philip Laureano</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7Gn0IcGCmQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">morning everybody my name is Phil I work
for domain and today just a disclaimer
is anybody here a distributed systems
expert good because I'm I'm not a
distributed systems expert either I'm
just a dev a lot of this talk is really
going to talk about all the things that
we've done with a cadet and actor
systems in general and all the mistakes
that we've made and some of the mistakes
that you could avoid by learning some of
the lessons that we actually did so just
a quick overview a couple years ago what
happened was in domain we had a big big
problem and the problem was that like a
lot of online real estate websites even
our competitors we needed something
called clickstream analytics is
everybody here familiar with google
analytics ok so some of you are for
those of you that are aren't clickstream
analytics is this it's really the art of
understanding what your users do on your
website so that you could collect this
data and then process it later and be
able to create better products based on
what people actually do so instead of
having a product team that would say
well we think this is what people like
you actually use real data and you
collect real data to build better
products but about two years ago in
domain we had a serious problem and the
biggest problem that we had was that not
only we were we collecting the wrong
data we were actually losing events as
part of this clickstream process so when
I sat down and like any other dev with a
new tool and I was playing around with a
canet I said is there a better way to do
this and when we looked at this problem
there's a few things that we ran into
and the first thing is that the old
system was running on a sequel server
database and it had quite a bit of
triggers that would fire every time we
wrote an event
if it would kick every time we get an
event what would happen is it would
completely reject it if it violated any
of the referential can constraints which
is horrible when you're trying to
collect everything secondly this this
was running on sequel server reporting
services so that's fine back and say
2005 when the original system was put
together but this is 2017 it doesn't
make sense to be running something like
this when we were scaling up to millions
of users and we needed to collect this
stuff and be able to analyze it as fast
as it comes in so today I'm really going
to talk about how we put a system like
this together and these are the things
that you would expect out of a
modern-day real-time reactive system but
I'll go over the the points just to give
you an idea of what we're gonna go over
so the first thing is really around
reliability that means that when we
collect data about all our users we
should have at least within a reasonable
amount of margin the ability to say that
we won't lose anything of course it's
not perfect but we want to come as close
to perfect as possible the second part
is really traceability so when we have
events that come in and we want to do
real-time aggregations based on what
streams in and somebody comes to us like
say an agent says well how do you know
that these numbers are correct we have
to be able to look into the events that
we've collected and say here's event one
two and three this is why you have three
click events and that's important
because when you're on when you're in a
real estate bait a business and you're
in the ad agency you have to be able to
sell these ads and say yes we get this
much traffic but the business is
effectively useless if you can't provide
traceable and reliable numbers the third
bit which is fairly self-explanatory is
it needs to come in as fast as
it needs to compute as fast as it comes
in
given that where most of us are running
within the cloud it's very easy to spin
up another box and add that capacity but
as you'll see during the course of this
talk it cap really messes things up and
I'll talk about how we got around that
the other bit is accuracy so obviously
we need to be able to add all those
three things together and we need to be
able to recompute in case of any errors
but as I mentioned before when it's okay
running on a single box in fact you have
no consistency problems running on a
single box the problem is that no matter
how much you how many instances you get
in AWS where you get a super box it's
not you still run into cap you still run
into the problem of what if that machine
goes away and then you're screwed so we
really had to think about this I mean
two years ago domain moved on to AWS we
had all of a sudden this capacity to add
more and more machines and this is more
of a plug for some of the other talks
we've done in domain double week that we
what we did was we put together
something called the robot army which
was a combination of octopus deploy and
AWS and it was this amazing tool that
would allow us to provision machines at
will with a basically a push of a button
so there I was 2015 saying that hey this
looks pretty cool
I started up playing around with a canet
and I wanted to run this on multiple
boxes and it seemed like a good idea I
mean you've got a few different actor
systems that you play around with of
course there's a cadet
there's Orleans and if you want to go
with the JVM that's fine too and there's
also proto actor if you want to go with
something a bit more lightweight but at
the time it seemed for me I'm a very
curious person so I
around with Akkad net and I said well
hey we've got this job that takes
several hours to run what if I were to
take every single that job and divide it
into 86,400 smaller batch jobs or made
it one job per second so the idea is
instead of just letting it sit there
like any other batch job you would run
in any other shop we could process it as
fast as it comes in and in theory that's
great it's it's easy to throw more actor
systems into the mix and hope that
everything is fine but the biggest
stumbling block that we had was managing
state when you have events streaming in
at once how do you guarantee that your
computing the right numbers how do you
guarantee that you don't lose anything
that was the hardest thing for us
because we tried so many different
approaches we even tried using just
Postgres and we thought hey you know
maybe it's just because we had bad
schema and and it turns out that when we
did it in Postgres it would take an
entire week to process something that we
were able to do with just the actor
systems that we had but the trick here
is we need to be able to manage state in
such a way that you don't lose that
consistency or at least in our case the
consistency what the consistency window
was in one day if we sped it up for a
little bit faster than just one day the
agents would have loved us and and
that's what happened but I'd like to say
that everything went perfect but a lot
of the things I'm gonna be talking about
like the theory are things that we
didn't necessarily know when we did it
these were things that we learned only
as an afterthought I was quite surprised
that a lot of the stuff that we did that
we learned was was stuff that was
already out there in different talks and
whatnot but I'm gonna go over some of
the things that you might already know
just for a refresher so first thing is
with strong eventual consistency is this
idea that as long as you have all the
pieces
and as long as you had an algorithm to
be able to take all those pieces and put
them together you can reach consistency
and the order doesn't matter the other
bit about this one is there's also a
weak eventual consistency where the
order does matter but you do still have
that same window to reach consistency
like like what we did so for example
we'd have events coming in every second
but we had till the end of the day to
actually process it so if we're talking
about strong eventual consistency as
long as we had all the pieces and we
were able to process it we did it in
such a way that it didn't really matter
what the order was as long as we came up
with the right totals another way to
explain this is what I like to call the
IKEA analogy so if you've ever assembled
furniture from Ikea the way I always
like to explain is how are you able to
walk into ikea buy the same per piece of
furniture as somebody else without
talking to that other person as long as
you both have the same set of
instructions for the most part you
should be at the end of the day when
you're done assembling it you should
come to roughly the same piece of
furniture depending on how good you are
with assembling things and in that sense
it's pretty close to strong eventual
consistency now somebody under previous
talks told me that yeah IKEA pieces are
not all the same and that's true but in
in this case when you're working with an
enterprise system there's a certain way
you can reduce all your events down to
something that where the order doesn't
matter and I'll get to that so in
hindsight what we were actually doing is
something called conflict-free
replicated data types so the title of
this talk is effective eventual
consistency and I know I some Pierce
will say you can't really cheat cat but
you can sidestep it and it seems complex
but it's actually not and part of the
reason why we needed to have a strong
eventual consistency
we knew that we as a business we
couldn't afford to lose any data but
data loss is something that will happen
and you have to take the steps in order
to prevent that from happening and this
is one of those things that we learned
in hindsight and it did help us recover
some from some failures that happened
last year so does everybody help
remember the AWS outage in Sydney yeah
we were hitting with that too and this
this is the one that saved us so just a
refresher cap theorem consistency
availability partitioning pick only two
at once
consistency meaning that everybody has
the same view of the data at the same
time partitioning means that if you have
multiple nodes in a system you could
survive multiple node outages without
losing anything availability is just
knowing whether or not a operation is
successful depending on its knowing
whether or not it was successful right
away actually the problem with this one
is as you can see here there's different
types of storage providers that are have
their strengths with this one in our
case we could sacrifice consistency
because we didn't need things computed
right away at least we we can wait until
the end of the day to have everything
consistent and that gave us a bit more
flexibility so for C R DTS it seems a
bit weird how do we sidestep the cap
theorem in this case so as I mentioned
you could only pick two so if you look
at this you've got partitioning where we
picked partitioning and availability but
how do we get consistency so the trick
here is that number one even though the
data can only be to pick two parts of
the cap theorem our merge algorithm is
100% consistent that means all the nodes
have exactly the same order algorithm
the same this at the second the second
part of this is that C or D T's
ensure partition tolerance because we
make copies of every single thing that
comes into the network so every single
node that we have has copies of all the
data that streams in so if you take out
a node it doesn't really affect the rest
of the cluster for example at the same
time we do get that availability because
since you have the copy of the data and
you were to run operations over the over
what you have you could tell immediately
whether or not you're successful
depending on what you decide to do for C
or D T's in general there's three
operations for us we only implemented
two of them so we implemented only the
query and the merge operation now you're
probably wondering what why did we skip
the update and the simple reason is that
we chose to be immutable so we wanted to
event source this so that we never have
to worry about tracking deletes so if
you do a bit of research with CRD T's
there's different types of Co Rd T's
that say you can track what's been
deleted these typically these c rd T's
are the ones that you'd see in Google
Docs so if you ever did more than one
document at once and somebody else was
editing it at the same time what it
would do is merge the or deletes with
their deletes and come up with a
consistent state right away in our case
we didn't need to do that and it
simplifies the CR DTS so that we had
just assumed that the data set keeps
growing and growing growing growing and
within a reasonable window we do delete
CR d DS for the sake of just saving
storage but effectively for the sake of
the business it just grows on and on on
forever so as I mentioned the first
operation is querying this is getting
the state this is by the way this is not
a / - be a service it's more of a
pattern a lot of the stuff that we did
with with what we put together was
around making sure that we implement
these two operations so
there's query and then the next one is
the merge operation so the merge
operation seems a bit scary because it
seems like magic because what how do I
actually do something that maintains
consistency and there's three things
that you basically need to be able to do
with the merge operation so commutative
meaning order doesn't matter
associative meaning that the grouping
doesn't matter either so you could order
it whatever you want and idempotent
which is probably the most important one
you could run over it in multiple passes
and it wouldn't matter and the best part
about that is that this merge operation
even though it seems magical you you run
it over a set of data that has the
duplicates with the stuff that is
duplicated on multiple nodes you get
consistency every single time so here's
more of a question for the audience so
I've got let's say I've got two nodes
and for the sake of simplicity let's say
I've got two sets each set has a set of
intz which operator you think would
ensure this set of requirements so if I
go here which one's communitive which
ones associative and which ones
idempotent it seems really really
complex but it isn't in fact what we
found is that is everybody you're
familiar with set theory so it turns out
Union is all you need so if you were to
run the Union on every single one of
these items and do a union between set a
and set a on node one node two and set B
and so on you get something that looks
like this and just a disclaimer this in
no way is obviously not production code
but conceptually it's all you have to do
to maintain that consistency so I've got
two sets with what you have there and
it's I take two hash sets and I Union
the
items together I mean that's it there's
no magic here because you're taking all
the duplicates on one side and the
duplicates on the other side and merging
them together in a single set now I
understand that as developers we work
with very very complex business domains
and you never if you're lucky unless
you're a mathematician you're never
gonna really be working with Justin's
but it turns out that this principle I
mean it also applies to hash codes and
we'll get to that so the other thing I
mentioned before is since we don't
delete anything we don't have to do any
kind of tracking as to what's been
deleted so in terms of working with sets
we only have one set to work with so we
start collecting events and then across
multiple nodes and then we just do a
read across those nodes and then merge
them in all at the same time using the
same Union operator so now that we
talked about the theory you're probably
wondering how does how do we actually
store this stuff because when I first
started I thought we could have done
this in sequel server or something like
Postgres what how did we actually go
about doing this so one of the things
that you'll notice here is that this
looks exactly the same as the other
slides the only difference is that I
just pasted two different data sources
now I recommend using two different
types of data sources because you don't
not only do you want to not store your
eggs in one basket but you don't want to
store your eggs in the same type of
basket so what we did was as events were
streaming in we would store one copy in
elasticsearch and another copy in s3 the
reason why we wanted to store our events
into s3 was we wanted to do long-term
storage but at the same time we also
wanted to store things into
elasticsearch because if somebody had a
question about all the events that came
in during that day we could quickly
search it with elastic search because
that's what it's good at
the other question I mentioned before is
you know what it how do you deal with
the situation where it might be more
than just an int or just a number as it
turns out it's not that different so
here's a sample clickstream event and
what we do is we take all the properties
that you see here and put together one
string that is concatenated and based on
that content of that string we generate
a unique hash code with a hashing
algorithm you could use sha-1 or
anything that is relatively unique so
for us practically anything above
128-bit key space is good enough so we
would take all the properties Union them
into Union but we merged them into one
string and that hash code would be the
equivalent of your int because when
you're dealing with set theory it
doesn't matter whether it's an int or
not provided that you could guarantee
that it's unique in this case it's going
to be a unique string within a space of
128-bit now if we were to pull back a
little bit further things get a bit more
complicated when you're when you start
working with more than one actor system
our clickstream pipeline looks like this
so on one side we've got one clickstream
event flowing into our web servers here
the web servers would make copies of the
events and send them off to a kadam net
now what's not on the slide is that all
of our actor systems are talking to each
other not not directly and not directly
but through sqs everything is done
either through sqs or just standard HTTP
now if you look at the a canet docks
you'll see that they focus a lot on
clustering and remoting but in practice
that's very hard to do within AWS and
you're probably wondering why well when
we started doing it I was quite excited
to say hey I want to do clustering
because this seems pretty cool to have
all these systems talking to each other
but in practice you
the only way to fix it when things go
wrong it's the rdp in and if you know
how hard it is to RDP in into a
production box or an environment where
production boxes go up and down we need
something a bit more robust we need to
be able to send our actor systems out to
remote machines and not have to worry
about whether things fail or not
so in this flow of information that you
see here we've got clicks extreme events
flowing all the way to s3 and elastic
but you're probably wondering well
that's great I'm sending it in two
different directions but how do you
merge what's going on
so that we get consistency between s3
and elasticsearch so what we ended up
doing is we had another actor system
that would watch all the events that
would come in on both sides we keep an
inventory of all the hash codes that
would come in and we swap any events
that are missing from one side to the
other and in practice this works pretty
well because since we have an eventually
consistent system we can wait until the
end of the day fill in the blanks and
then recompute and then we hit
consistency most of the complexity in
fact has that we've run into has been
around this type of communication
because if we were to use any kind of
clustering if any like more than 60% of
the nodes were to fall out we would have
a system that is completely unstable in
our case we found a way to scale up by
having actor systems talk to queues
rather than talking directly to each
other so we could add 10 more machines
and take them out without actually
causing any outages now is everybody
here worked with echo or any actor
system to some extent so there's a few
of you here but I'll explain to you what
actor systems actually are so with an
actor system you could think of it as a
lightweight thread I would even say an
actor system is almost a degenerate
operating system
because an actor is almost like a class
and you can have thousands of them
running in memory at once and they have
this concept of a mailbox so actors
could talk to each other and send
messages to each other what happens is
that there's a dispatcher that would
just do of being a massive for loop and
switch context between every single one
of the actors the other thing to
remember is that when these actors send
messages to each other they're all
immutable so the power and actor systems
is the ability to switch between these
actors very quickly without having to
worry about consistency in fact they're
so thread safe that you don't even have
to put locks inside of a single actor as
long as it's not some sort of static
method that you share with other
instances you could pretty much assume
that everything that runs inside of an
actor is has no problems with threads at
all if you look at the code it's
actually quite simple as well so an a
cadet we've got this is your simple
hello world actor I've got the greeting
actor you here's the constructor and in
a canet it has a strongly typed received
message which is the equivalent of an if
statement in a coup nets that says if
you receive a message of this type do
something with it
the message itself is fairly
straightforward there's nothing magical
here it's just completely immutable and
the reason why you want to make it
completely immutable is it's easy you
don't have to worry about threading or
whatnot and it also makes it easy for a
katana to serialize it if you decide to
use remoting or clustering now putting
together act the actor system itself is
equally just as simple there's a bit
more configuration in a canet but in the
simplest case the actor system is
created in one call there's a bit of
weird syntax here you can see here we're
creating the greet actor and it takes a
while to get used to but there's a few
options there the more advanced options
where you can create multiple actors and
have it scale up automatically but in
in this case this is this is the
simplest possible thing you could do to
create one actor the most important
method that you see here is going to be
the tail method every single app actor
has this concept where you could send it
a message you can call tell and it'll
pass it that message and it's basically
this large switch statement that you saw
up here and eventually when I tell it
with a greeting it'll just get to this
point and say if this is this type is a
greeting type then call this method now
the other thing you might be asking is
this running on a separate thread I
don't know I don't care it could be
running on the same thread but for the
most part the actor system in a cadet
abstracts away this idea of trying to do
any kind of synchronization now if you
looked at the bigger picture here of
course we're dealing with more than one
actor system so if you look at the a
cadet docks they talk about really
simple cases like the one I showed you
but in practice things get a bit messy
when you have systems that cross
multiple auto-scaling groups and one of
the things that we learned is that when
you combine a cadet and SQS you have
this concept of almost like a
distributed swarm because the what we
did with sqs is that we have almost like
a blind dispatch I could drop a job
request into an sqs queue and as long as
I had a cluster of say 10 nodes that
would continually pull from that queue
they would just pull it right off of
that queue and keep processing
that sounds great in practice but there
were even cases where we were almost
took down AWS at least the Sydney region
because we didn't throttle it you you
definitely don't want to be in this kind
of situation where you get a nice phone
call from AWS saying please don't do
that so in hindsight one of the cooler
things that we actually did was we
introduced this concept of self
throttling actors so if you look at this
this is actually a live message from
lack on for a domain slack and there's
three messages here the interesting bit
is that we actually have actors that
scale themselves back or make the what
they do is they make themselves go
faster slower depending on how much
memory they use so in the first line you
could see there that we do have
thresholds so the low threshold is 1.5
gigs other one is 2.5 and high is 5.1
and the idea here is that we have these
actor systems that are completely
disconnected from each other but they
scale up and they scaled down depending
on how much memory is actually being
used on the box so we could have 10
actor systems that are connected to an
sqs queue and as long as they don't all
throw out of memory exceptions it's it's
almost like a swarm that regulates
itself the interesting part about this
is that if you wanted to do this at home
it's actually quite simple I could walk
you through the code here and you could
see that if I could get my mouse back
here we go
it's actually quite simple so don't mind
this one I've got constant expressions
that are just convert your byte values
into gigabytes and megabytes and so on
that's just for syntactic sugar the
important thing at least conceptually
here is that and let me zoom in the
important thing here is that a code on
net has this concept of a scheduler
where you could send the same message
over a period of time and you could send
it over and over and over again in this
case what I'm doing is I have this empty
class here called check memory usage
that I send I also have a message here
for the memory usage metric so I have
the Val so it's quite simple I could
abstract this way into an eye metric
interface if I want to but the idea here
is I just want to be able to record the
number of bytes this actor system is
actually using on a given system at the
same time I want to keep track of the
date sample so if I if I start
collecting these men
shrieks I want to drop off a certain set
of events that have gone beyond beyond a
particular time window so here's how the
message falling actor actually looks so
it's quite simple in the constructor
I've got the timespan in this case it's
defaults to one second when it receives
that check memory usage event it makes a
call out to this method that you can see
here which is just a process call at the
same time I'm pushing it to the event
stream so if you're not familiar with
the event stream Anaka
is basically a bus that exists on a cat
on an akka dotnet actor system it
doesn't it's in some cases it is
distributed but let's assume in this
case that it's only for the machine
itself so you don't have to worry about
subscribers and publishers and whatnot
so the idea here is that on the
pre-start method which is called before
the actor system actually starts it'll
tell itself a message to check the
memory and it'll keep sending out these
messages onto the bus I also have an
alarm actor which is a hypothetical
alarm actor that checks for these types
of memory messages and what it does is
that if you were to do this in
production you would just watch for this
type of message and you probably want to
average it out but in this case I
simplified it so that I have a threshold
that's defined in the constructor so
I've got the high value medium and low
value I can keep sending out this
message of what memory I'm actually
using and as you can see here I put the
two new blocks because you'd probably do
something better than this where if it
goes below the low value you might want
to have it speed up if it's the medium
value then that's when you want to hit
normal speed so as you could see here in
a couple of instances we had the high
value and the medium value and I think
this one is the low value but let's just
say that if it went to the high value
you can just tell it to either stop
pulling until the memory drops to a
certain level and then once it switches
back up to the medium value then
when you could start processing it again
the nice part about this approach is
that in just a few lines of code you
could just check and make long as you
control what's going into the system and
you tell the whole system to slow down
then you could pretty much get any actor
system to scale up or scale down and you
don't have to do any kind of special
clustering this is as simple as it can
get so the rest of the stuff is around
bullet boiler plate code but for the
sake of completeness I'll just go
through it so we've got the memory actor
that I created here with the timespan of
1 originally this was a printer actor
that would just go ahead and print stuff
but let's just assume that in this case
it's just the alarm actor and there's
the syntactic sugar here so I set the
high threshold if the memory goes over 5
gigs then slow down the normal running
memory usage is around 2 gigs and
anything less than 1 gig is is it's just
fine and tilt the speed up as you can
see there's nothing magical about this
if I just run this it's let's see
anyway bill time takes forever but so
the bill time takes forever but in this
case it's fairly straightforward because
as you can see when it runs you probably
want to go ahead and take the average
over a few seconds and then once it hits
over a certain threshold that's when you
would change state but as you can see
there's it's pretty simple and later on
I'll talk about how you could get over
the memory limitation cuz it turns out
there's a memory limitation in console
apps where if you can't go over I think
it's two gigs but one of the things that
we ran into very quickly was that we
needed way more than two gigs in some
cases we need 14 16 gigs on one box so
I'll get to that in a second but so now
that we've talked about the theory with
eventual consistency we've talked about
storage the question here here is I did
mention before what about that case
where we had that outage in June of the
thing was last year or the year before
that how do you recover from that and we
had this process what we called
reconciliation so we would collect
everything into s3 and we collect
duplicates but since we had a list of
hash codes it was easy to figure out
what was missing in this set so we can
look into s3 figure out what's missing
we could look in the elastic search and
figure out what's missing we could have
even put together a Merkel tree and said
I've got this set of hash codes on one
side and I've got this other set of hash
codes on the other side let's just swap
events until we're both consistent the
best part about this is that we did this
every day so we had an end-of-day batch
request and when things went really
really bad we could just go back into
what we saved into s3 pull it out again
and then replay it and we're in a state
of consistency it took a couple days but
the best part about this approach even
though duplication itself sounds a bit
weird if you're coming from a relational
background this did save us again I have
to stress this there's nothing magical
about what I've talked about this is
just Union you could take any two
sources as long as you can guarantee if
you have an inventory on both sides and
do a union on what's missing then you
can recover very quickly so now there's
a lot of things that we learned out of
this process certainly we made a lot of
mistakes along the way
I mean it's if this were a computer
science thing I probably would have
flunked 10 times in terms of how we did
this but the first thing that I've been
saying all along is number one if you
duplicate everything and you've got the
right merge algorithm it doesn't matter
what what you do in fact because you get
the consistency that you want so in this
case we have a slack message where the
reconciliation process says I notice
that this amount of events is missing an
s3 the other on the other side I'm going
to notice that there's 20,000 events
that are missing from elastic and that's
where we swap the other bit that is
pretty self-evident in this case is that
if you want to do some strong eventual
consistency but you don't want to delve
deep too much in the theory it's
basically just hash sets and data
duplication you combine those two
principles and you get your consistency
and order doesn't matter I also
mentioned before that you since we
reduce everything in the hash codes time
stamps don't matter either although time
stamps do make sense in recording it in
your events it it's not really a factor
in resolving conflicts in this case we
don't get conflicts you just do a union
and everything is fixed
the other thing take away from this one
is that since we use sqs cues in between
every single actor system that we have
any outage only results in one cue
starting to fill up we don't have any
offline we don't have any like online
outages where people say well my reports
aren't working we do get a bit of delay
because of the system itself is
eventually consistent and there is more
than a few times where things have
fallen behind but the best part about
that is that when we are working in a
business that expects things within a
span of a day it's ok to fall behind for
a couple hours while we fix stuff so
just a disclaimer this is not real time
in the sense that you we would be
trading stocks with it but for
day-to-day line of businesses this this
was good enough actually we made a
couple million bucks out of this so I
was quite happy the and the other thing
I just want to point out is is everybody
familiar with a setting so for those of
you who are not familiar with this app
config setting if you have a 64-bit app
and say you wanted to create a 10
gigabyte array it'll throw an out of
memory exception unless you had this
setting on we learned this very very
quickly because when we started queuing
up messages that would stream in at once
we get out of memory exceptions and we
needed more than 2 or 3 gigs so it just
seemed useless to have this C 3 double X
larger or quad X large instance with 8
to 16 gigs of memory and we're capped at
2 gigs so make sure when you get into
this you you turn the setting on the
last bit is if anybody has what wants to
get into a canet there's quite a few
examples here so the memory throttling
demo that I I posted here you could get
it here the hello world
a cadet demo is not so important
because the a cadet does have those
examples but in practice a lot of
there's a few things that we didn't do
like we didn't do clustering we didn't
do remoting simply because in this kind
of environment it doesn't make sense the
the last thing I wanted to add in terms
of how we did this is that it was pretty
much a zero config environment we didn't
have to do anything like any config
files other than the app config and of
course the AWS keys for the most part
the actor systems that we put together
were basically self monitoring self
throttling and it makes it easy as as a
Deb because you don't have to worry
about whether it falls over or not we
added a bit of logging as you can see
the slack we also did some Sarah log
logging but overall it's it's it's a
different approach and I hope they you
get something out of this but aside from
that that's pretty much it does anybody
have any questions
oh come on alright well thanks for
coming to my talking and just enjoy the
rest of the conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>