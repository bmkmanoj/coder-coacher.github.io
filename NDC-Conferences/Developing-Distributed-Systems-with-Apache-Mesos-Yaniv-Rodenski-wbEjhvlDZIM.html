<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Developing Distributed Systems with Apache Mesos - ​Yaniv Rodenski | Coder Coacher - Coaching Coders</title><meta content="Developing Distributed Systems with Apache Mesos - ​Yaniv Rodenski - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Developing Distributed Systems with Apache Mesos - ​Yaniv Rodenski</b></h2><h5 class="post__date">2017-01-20</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/wbEjhvlDZIM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone thank you for
conquering your hangover and coming this
morning no it's not easy my name is
Jennifer dense key and I've been
developing a distributed application on
methods for the last nine months and I
want to talk to you about that first of
all we tend to think about building the
spiritual application as that thing that
we do when our stuff don't fit into one
computer anymore and that's that's one
of the reasons why we need to scale out
and Bill distributed application it's
not the only reason why we bill
distributed applications right even if
we would have this giant enormous
computer that can hold all of our
computation and all of our data will
still have one electrical cable going
into the wall somewhere that someone can
plug out and that's a single point of
failure we still have users from
multiple locations in the world so we
need to be geographically distributed so
there's a lot of reasons why we need to
build attributed applications my
specific reason II was the fact that i'm
already and dependent on other
distributed applications when i started
writing my own distributed application
but it's not easy it's the exact
opposite of easy i didn't come up with
this analogy of distributed systems as
herding cats the first time that I heard
about it was from this research paper
that yahoo published on apache zookeeper
which is another infrastructure that
that they built for for distributed
application is actually being used by
metal that is we're going to see that a
little bit later today that is a quote
from that paper i just learned too late
from scott hanselman that i'm supposed
to put a picture of someone but
definitely it sometimes feels like that
i have two cats at home and it feels
very much like herding cats and the
reason for that is that we need to deal
with a lot of things that we don't deal
with when we
building applications that run with the
single computer or are very trivial so
for example we need to deal with Network
communication network communication is
something that we've been doing for a
long while now and we feel like we have
a ton in control we have hips of
frameworks that deal with network
communication but the fact is that when
that network communication needs to give
us the same attributes that local
programming does like guarantee that our
message being received on the other side
that is often very complicated and we
need to give up a lot of things that we
don't think of we need to deal with
things like fault tolerance that we
don't deal when we work in single forces
or multiple process on the same computer
and that introduces a lot of complexity
we need to deal with synchronizing our
different services and part of the
application and that again introduces a
lot of complexity deploying an
orchestration of distributed system is
again very complicated we to control a
lot of moving parts and we will see a
lot of moving parts through this talk
and that's just another thing that we
need to deal with and for all of these
by the way we have solutions in the
distributed world we have frameworks and
tools that help us deal with that and
things like monitoring that we need to
deal with once again much more
complicated in a distributed world and
last but not least is the issue of
resource consumption and governance and
that is something that we are going to
talk about quite broadly this morning so
I apologize for that but at a certain
point in a presentation you can't stop a
running joke so building this routing
system is not easy with that said we
have a lot of different tools and
frameworks that help us to do that but
we are going to look at methods and
metals give us a different paradigm for
building a distributed systems and that
part time is
is in my mind very powerful and very
interesting so what is medals medals is
a distributed system kernel remember
that definition because metal acts and
and is designed as a kernel as something
that you treat as an opera star of an
operating system it started as a PhD
research project by Benjamin hindman in
UC Berkeley part of something called
ampulla and a lot of interesting project
that came out of that I'm going to talk
about another one in a bit it started in
2011 and the whole idea of metals is to
allow developers to think of their data
center at the clusters as single machine
so it really does introduce a lot of the
concept it an operating system will
introduce when you're working against
bare metal one of the focuses of of
Meadows is fine grained resourcing ok
and that means that measures basically
tries to give us more control and on the
resources that we consume across our
data center and it grew in Twitter and
Airbnb ok it started as a research
project Benjamin human if i'm not
mistaken work to twitter at that time
twitter widely adopted us in fact as far
as i know all of their code runs on top
of methods these days or the vast
majority of it Airbnb again as people
ship between those companies start to
adopt metals I know that today Netflix
are using it as well so it's being used
it's really large scale but the origins
of methods actually like every
interesting problem in computer science
these days actually originated in Google
and Google be using this infrastructure
in their data centers for a long time it
needs to be called bored replaced with a
newer version now that is called Omega
and they've been using it for a long
while we don't know a lot about it
Google usually very secretive about
their internal implementations but we do
know a bit now and it's a bit more than
we did when when metal start to come out
so in 2013 Google actually published a
paper about Omega and what they're
achieving with it and how they're
working with it but there's another
interesting thing that came out of that
whole project which is something that
they donated back to the to the Linux
kernel it's called see groups okay and
see groups are one of the foundations of
what we know is as modern containers so
what's the problem that they try to
solve when we're thinking about our
applications in our data centers naively
usually when a white border or
PowerPoint or whatever we do we think
about them like this we have a cluster
of of something let's say we are using a
distributed database less you like a
Sandra okay so this is how we envision
it we're going to have five nodes and
and and this is something we can scale
right Cassandra is a scalable database
we can scale it obviously for databases
will use specific nodes right we need we
need fast disks we need good I ops we
probably need for use of cpu and we need
memory okay that's one profile of
machine and then we'll have our web
services let's say we're using apache
tomcat for that and those are actually
very easy to scale up and down right
it's very easy to understand what's
going on with web web services and web
application we can analyze the requests
that are coming in and we can kind of
analyze the resource consumption for
those and then we're probably going to
have some sort of a caching mechanism
and maybe we want to run analytics and
we'll use the patch its part because no
one uses anything else these days that
is how we tend to think of our data
centers the truth is that they look more
like this
okay and there's an issue with that
there's an issue with that because in
this situation we're actually not using
all of our infrastructure in this
situation we were actually holding a lot
of infrastructure for things like our
database and our web servers that
they're not using right and data bases
throughout the years kind of lifting
that feeling that you know I'm going to
take all the memory that I can on my
machine because it's a database server
I'm going to use it so i'm not using i'm
not going to bother with allocating and
really seen once i have a memory i'm
going to use it but it is very useful a
very wasteful story it's very wasteful
resources and Google is not the kind of
company that will just waste resources
so they came up with with Borg and they
came up later on with Omega and and
metals kind of was inspired by that
those projects so we'll talk about the
mesosphere limitation and metal stakes
two things from from Borg and Omega and
that's to level scheduling which is very
important and I think that we all by now
understand is very important these
containers so this is how Meadows runs
your application on clustered this is
what male tries and most of the time
achieve and if we look at that it's not
easy it's not easy because of all of
those assumptions that we have the
assumptions that we need different
machines for different services the
assumption that some services live in a
world of their own and just don't think
about sharing resources and the fact
that we just didn't have the mechanisms
for for a long time so systems that run
on top of metals are regarded in the
metal terminology as frameworks and we
can write our own framework in a variety
of languages actually to write a metal
framework you only need to be able to
hit HTTP API with Google protobuf
objects
so if you can do that manually you can
use whatever language you want to you
want to use their support from from the
project itself for c++ medicine is
actually a native application
implemented in c++ the JVM python go
obscene just just this week and you
release from the community actually from
from one of the contributors of medals
in ojs there's haskell there's airline
there's a variety of languages that you
can use and as I said at the end of the
day what you need to do is just to hit
HTTP endpoints with Google protocol and
you think that you need to do or the
objects that you need to create two
component main components of the metas
framework our scheduler and something
called an executor ok and the scheduler
for us will be kind of flower master in
the application a scheduler is the thing
that gets from mezzos something called
resource offers and basically schedules
everything and orchestrate between the
different moving parts executors
actually execute our application so
let's see how it works in more or less
realized we have a master tomatoes this
is a demon that front somewhere in your
data center and your application let's
say we're looking at the patches part
has a scheduler now the scheduler has
some work that it needs to distribute so
it goes to the master it registers with
the master and it starts receiving
something called resource offers
resource offers and we're going to see
those in just a little bit are just the
Masters way to say i have on this
computer three cpus and four gigs of ram
i can give you is that now and based on
what the scheduler need or what
framework needs the scheduler we decide
if it want to accept the offer and
basically learn something on a metal
slave by the way in late in the latest
version
change the terminology apparently it's
not politically correct to use matter
enslaving distributed systems anymore
they also reject my offer to use
architects and developers but so so
these things are now called agents so we
have master and agents semi PC but in
our slave or agents we have something
called an executor and an executor is
just a process that is being run by
methods for us and it executes a task a
task is a unit of work it's illogical
think it's not necessarily is something
physical we're going to take a deeper
look at those and then we have another
framework okay for example marathon
which is one of the probably one of the
basic ones that you will be using if
you're using metals and martin needs to
execute something again it registered
first of all with the master and then it
starts receiving offers and yet there's
enough resources on this agent so it
just gonna spin up its own executor and
it's on task and do some work until now
we're looking at executors and targets
as a one to one kind of thing but in
fact might be that when we need to run
another task we are hitting a slave it
already has an executor so we don't need
to do that we don't need to create and
you process the transfer application it
might be just another thread and so on
and as you can see this way we get two
things first of all we have this way for
four frameworks to get and the resources
with the understanding that they can use
it they're not taking the memory or
they're not taking the CPU or the drive
or network ports client from anyone else
there's a metal master that's
orchestrate everything and once the
framework receives an offer it can
assume that it's okay for you to receive
it so we can scale up we can scale down
very easily
and by the way if we look at these there
still is a single point of failure here
of course the master so metal supports
multiple masters and in order to elect
the master because in those kind of
systems who can only have one master
right we we can't assure that to master
see the same things and we can't
basically that situation is called split
brain when one master will give us
resources and another matter will give
another framework the same resources so
we use apache zookeeper that by the way
comes in smaller font in real life and
zookeeper actually has a master election
primitive within it and that's what mens
use is to select the matter and thank
you this not because it's very
interesting from the Eternals point of
view of metals it is interesting because
we can assume that we have zookeeper
around when we're running on metals it's
actually very exposed in the api's and
if we want to use zookeeper for our
distributed application in addition for
what we're using methods we don't need
to care about it we can actually get
details of our soup zookeeper nodes the
form and just use that as a given in in
the environment so let's take a look at
how a scheduler looks like
and okay apparently there's a problem
with network here always so this is a
very simple implementation in Scala and
actually to have our scheduler we do
need in the JVM old two parts so we have
this launcher this launcher is just the
entry point this is the main function
right you're looking at any other
language even in Java you will have a
static object with the main that
receives arcs this is this is scala's
way to say we're different and there are
two things that we or three things that
we're doing here first of all we
rebuilding its part of us object that is
going to be sterilized and used
internally by methods that defines our
framework right so we're just giving it
a name and this is something we'll be
able to follow in the messes you up
failover timeout and this is actually is
important because we want message we
want to control the amount of time that
measures consider an executor to be
failed and we want to control that so if
mail see that an executor is failing for
or can't get any response rate for 10 10
seconds then it will sell it over and
restart again and the user that will be
used on the framework so this is the
users the user that will be executing on
the slaves or agents themselves and then
I'm just creating my scheduler okay
we'll take a look at the schedule but
this is just an instantiation of scala a
class and we're using the metal
scheduler driver to actually register
with the master so we're giving a
scheduler the framework i get a
prototype object and the IP of the
master and run
once we do this can go into our skull
object and there are two things here
this is just a companion object in
schuyler think about it this as a
constructor and just naively I'm giving
my constructor a list of videos to
download I know how much the threading
government loves us to download movies
so I built a distributed application
that can download movies in parallel
because I do review my visa I'm actually
gonna just download movies that type
taken from my phone but if you want to
download movies in parallel across the
data center you can actually use this
framework in production and this is the
scheduler scheduler just extend a
massive object called scheduler and we
have a bunch of functions here that
we're going to implement throughout the
demos the first one is registered ok so
this happens once we registered with the
master not very interesting I'm just
saving internally the framework ID data
that i got from from metals for further
use and resource offers is actually a
very important functional of your logic
will go into em resource offers what
happens in resource offers is basically
the master starts to send you offers i
have these resources on this slave I
have these resources on that slave by
the way if you are writing in framework
pay attention I suspect that we are
going to see a bit of API changes
because of the politically correctness
of this but basically we're just getting
a list of of different offers and for
now we'll just print them and I beg you
to do this because we are not going to
use it we're going to decline the offer
now this is important because of another
aspect of methods other than our
scheduler there's another scheduler that
goes and says ok i'm going to give these
resource offers for
x amount of frameworks and I'm going to
schedule between them now there's two
things that can happen or three things
that can happen we can accept them we
can reject them or we can just wait for
the offer to time out but if we're
waiting for the offer to time out some
of us is being deprived that offer so if
you're not using an offer and I'm going
to repeat that throughout the demo
please decline it so let me just build
this
and while it's building add this vagrant
machine this runs a single node methods
by the way at the end there's there's a
git repos for both the demos and the
vagaries machine so if you want to try
this you don't need to set up your own
messes cluster you can just clone that
repo very grim stuff and you should be
good and for me to run this java
applications just a skullet just a java
application on doing i'm using java CP
i'm leaving it the jar file launcher is
my entry point that's the class the main
class that i'm going to execute and
here's a little bit of a dirty secret
from the java or two JVM implementations
basically what they're doing they're
wrapping the native library in C ok this
is very specific for the JVM if you're
using if you are you need to pass in the
Java library path because in user lead
we have the lib mezzo sesso file so once
i run this I'm starting to receive
offers and you can see that i'm getting
these offers this is the framework that
received it this is the slave ID the
host name for that that i might need to
use right i might need to communicate
with that note on on this hostname
resources in getting a memory and
getting a disk and by the way you can
see that we have we actually have three
types from many three types of resources
we have scalar okay so if we're taking
cpu that's a scalar value wave range and
imports can be range we also have a set
so if it's not a continuous range we can
just give it back those specific values
that we need and so on and so forth
these are the resources that we're
getting back from
so because actually almost forgot to
show you this is the metal cui and this
was my framework so I can actually go
when there's not a lot here right now
we're going to add functionality so I
can actually use this web UI which is by
the way I've just learned it's wanting
things you learn when you plug into a
projector okay so let's do some stuff
with our framework
okay so we want to download movies so
again all of the magic happens in in
resource offers so we're getting the
list of offers now I'm going to actually
look at the offers and analyze if
they're good enough for me for
downloading a movie I don't need a lot
of resources so I'm just checking I'm
checking the tab more than 0.1 CPUs and
more than 128 mix of memory which is by
the way thank you more than enough for
what I need now you notice this I'm
looking for 0.1 cpu and in fact I can
request that I can tell ms slave it's
very nice that you have eight CPUs I
need 0.53 right and I can actually go up
to 3.3 type places after the decimal
point in metals and the thing that
allows me to do that is actually the use
of three groups okay so see groups is a
feature of the Linux kernel the google
introduced and they actually used it
internally footboard and what that
feature allows us to do it allows us to
take a process or a process tree and
allocate resources for that process and
that means that that process will not be
able to consume more resources than than
being allocated to it but also that
these resources are reserved for that
process or process free and this is what
metal fuses and this is what allows us
to get that better granularity and
better density from our machine and if
you think about it the problem that they
try to solve is the same problem that
the cloud try to solve on a data center
scale right the problem with data
centers with traditional data centers
were that we needed to buy the hardware
for our peak times but we didn't use it
so we start to share the hardware but
the one thing that the cloud didn't
should do is to take the same problem is
Kelly down to a physical machine borders
and that is what containers to and that
is what matters help us do and a larger
scale so we have our resource offers we
validate them if we don't have enough
resources I cannot stress enough how
important it disease okay don't Bogart
the cluster it's me insured by the lost
applications if it's not being shared by
the lot of applications you shouldn't be
using medals okay but if you are please
release your resources as soon as you
can okay so we're going to use or we
think we're going to use the resources
the next thing that we are going to do
we're going to take a look at our
download queue this is just a concurrent
q that holds all of our downloads your
eyes and we're going to take the next
one to download by the way the reason it
is concurrent is because we get these
offers are synchronously so we can be
processing one offer or a set of offers
for that we just receive and the matter
has the new set of offers and it just
froze it again to our to our scheduler
so we need to synchronize that for us
it's just many using a synchronized cube
but this is a very naive implementation
okay if it's empty again I'm declining
the offer and for my framework that
that's the end of its life so I'm
stopping the scheduler another thing
that I want to stress after I stress
that you need to release resources as
soon as you can is that metals actually
it's built for long running services so
if you think that this Q is going to get
more downloads or if your application
supposed to be continuously just living
on your cluster it's okay don't don't
close the scheduler if your if your
executors are long living then leave
them don't release them just because I
said release the mo'nique make sense
okay but for our use it's time to to
just stop the driver and now i'm getting
the movie this is just a string that
gives me the movie and i have to build
my task and my executors and here's
another thing that comes out of the book
with meadows if our task is just
something that we can run as a shell
script a shell command there is
something called the task executor that
comes built in with medals so we don't
need to even build our executor and for
us to we're just building a command
which will be w get okay and we'll
download our movie with thing before
that i'm just using print line to print
the console so let's let's try and print
something from our executor so let me
just do
be
okay so I'm just going to run to
commands now one will just print
downloading in the name of the movie and
the other one is the w get and let me
build this
let's run it again before I forget
actually need a web server to host the
movies so
so I'm just going to run the simple HTTP
server to python a simple HTTP server
but that will show us also what is being
done what is being downloaded from the
server and I want this again okay so a
couple of things that we see first of
all we see that the task is running the
task is finished we getting it status
update and I forgot to show you this in
the code but we're actually registering
for status update okay this is another
mechanism that we get out of the box
with them with our scheduler okay this
is not what we're printing this is
something that we're pretty from the
scheduler you can see that we actually
don't see the print line that we had one
thing that is really helpful when you're
working with methyl is this so when
we're running a an executor it runs on
the slave on an agent now in our case
it's a single machine but not
necessarily so what metals does it
actually redirects STD out and stderr to
a sandbox sand box is just a filesystem
location that is being created for our
executor so you can see that we have
here downloading and the name of the
movie disease the echo that we sent from
from the task ask executor and now the
thing that we will be able to see here
is the actual download because I didn't
not very helpful but I can hit the
download and we can see that it is
actually a movie forget their sound here
okay so everything is being executed
within these sandbox the nice thing
about the metal cui is that you can
actually look at your sandboxes and and
see the stderr and the CD out and very
easy to debug that way and we have our
scheduler we actually have more than
that we actually have a very legitimate
metal framework because we are using the
task executor and it looks like
something very simplistic but it
actually is something that is production
great okay so things to remember about
the task execute executors age being
containerized it's running within a
container okay and the second thing is
that smells actually manages a lot of
the life cycle if it will fail it will
be handled like any other executor that
is failing it will try to reconcile and
if all else fails it will actually fail
we see that we get the status update so
the entire life cycle of the task
executor is being managed and if you
have a distributed system that you just
want to use methods for for the resource
management at the coffee but the
internal communication is already being
managed you can actually use that and
some frameworks use the task executor
it's a very legitimate solution in fact
you are encouraged to use that until the
point that you need more and as I said
everything is being containerized okay
containerized in meses is is an absurd
thing messes has its own containers that
are made out of C groups and namespaces
namespaces by the way is another linux
kernel feature that basically determines
what you can and cannot see from inside
your container and but meadows now
natively supports also docker which
actually is built on top of namespaces
and see groups but give you all the
benefits of talkers so if you want to
have a task that is just run
a docker container you can have that as
well in metals but that is too easy so
will complicate things and write our on
executor so let's take a look at how
that looks like
okay so to create our own executor and
this is again very specific for the jvm
family of api's we need a launcher ok
this is specific because again meadows
need to boot dropped the meadow sleep
but we do more or less the same thing we
create an instance of our executor
object okay and we're passing along this
is the URI to download this is not
something that we we need this is not
the matter your eye or anything like
that and we also have a driver we give
it the executor and we tell it to run
our executor which is some reason shown
as being compiled once again we have two
main things that we want to look at
registers ok and this is just a way to
to basically get information when we're
starting our executor and the other one
is lunch task lunch task is something
that will happen every time that that
message needs to create a new task ok
and for our task i'm just going to use
any HTTP client to download a movie and
i'm going to do something a little bit
different ok i actually want to notify
my my matter or my scheduler with
something so i'm going to use something
called framework messages and i'm going
to send a message back to my master or
sorry to my scheduler getting very
confusing at this point so not a lot
going on here again we're just extending
executor our scheduler is a little bit
different
our commanding so looks a little bit
different now we're actually starting
another job of process but we also need
that process or that jar that we're
executing to be present inside the
sandbox right this is going to be
executed in the sandbox so commanding
for let us to let us add resources we're
going to use the edge URI and just give
it our jar it is actually being served
from the same HTTP server but you can
use that for anything you need if you
have dependencies that you want to that
you want to add you can do that you can
actually mark it as executable or extra
okay so if you have a tar file or or zip
file you can just tell metal just
extract that once it's been downloaded
in the sandbox so once we do that we
also need to create this executor
protobuf okay describe our executor but
again the resources that we request go
to the task right so if we have multiple
tasks on the same executors we can
actually request different resources for
each one of them so once again before we
build this there's a nothing framework
message ok so far messages is the
internal communication mechanism used by
meadows and love the network in this
conference anyway it's it's fairly easy
to use ok so we're just sending a
message on one side we're getting it on
the other side and it's a way for us
communicate we can use that for example
to send our executors in
data okay we can use it for for love or
to report something more specific back
to a scheduler but there's one thing you
want to remember that as opposed to
starting a new task or starting a new
executor these are not reliable you're
sending them there is nothing on the
face of this earth that will tell you if
the other side received it okay so you
might want to use in our communication
mechanism and nothing prevents you from
doing that in fact you can get all the
IPS of everything from the mezzos API so
let me just feel this
and we don't have a network
you
as we just use my phone
and
no I don't do not want to use choice
iPhone have to skip this this resource
offer
yeah so first of all now we know that
Telstra have budget for next year but
wants to assemble this and actually have
the jar ready in the HTTP servers folder
I can now run this and if we'll take a
look here you can see that the first
thing that was downloaded is actually my
jar file from that server and then we're
getting all all of the movies but if we
go here okay city out we can see okay
I'm actually printing the response ok so
it will take a look here right oh sorry
wrong version of the jar but I do have a
print line in there to print the
response but I got the messages back
okay so now we are you have
communication between our executors and
our scheduler
as opposed to the next arc 1 i'm very
proud of this i actually first search
for cap like that for think two hours ok
so a little bit about building executors
you do not necessarily need to do that I
cannot stress it enough ok if you're
just going to use the command line by
all means use the task executor it is
great but if you want to do things like
run different dusters threads and not as
processes and you might want to do that
because you want to catch something on
the executor level as we do in our
framework that is definitely a
possibility if you want to use framework
messages that's another reason for
creating your own executor and and
whatever makes sense at this point right
if if it makes point it could make sense
just build your own executor so if we
talked about methods until this point as
a kernel for our data center there is
actually full-blown operating system and
it's called the COS and one of the
things that drove me into Meadows is
actually not the capabilities of metal
for building distributed as a
application it's actually the ecosystem
and I was building a disputed
application to orchestrate big data
processing jobs right and there's a lot
of frameworks that are running natively
on metals and one of the really easiest
way to get started with those is using D
cos or or sometimes pronounced tickles
so diff us gives us a lot of things it
gives us management tools and a nice UI
on tops metals and nicer one this week
and one the creeps in it also gives us
package management so we have something
called universe that allows us to just
select frameworks and install them on
our cluster we also have really easy way
to declare deploy additional cloud so
i'm going to use AWS
to show you DCOs and there's just
CloudFormation template that you can use
by the way it's open source as well okay
there is an enterprise support license
and everything if you need that but it's
completely open source and this is
another very nice thing about it so you
can easily run it on on Microsoft Azure
it's actually in the marketplace so you
just select it from the marketplace a
couple of clicks and you're done you can
run it on vagrant and if I had more
resources on my laptop that is probably
what I would do and there's a company
called mesosphere behind both PCOS and
meadows and they're actually very good
in the resources slide at the end I
forgot to give you a link to their slack
channel but they're very responsive and
very helpful and flak and also their
support so if you just open a support
ticket without paying them a sense
you're probably going to get help so
let's take a look at how it all looks in
D cos and so this point like that can
take over off the screen I'll do it like
this and this is just the D cos master
on my AWS and pressing the tc's that I
actually have to provide a login again
this is e and actually log in as my wife
which is pretty cool next time it is
that this is recorded ok so this is the
main UI for D cos we have a nice
dashboard everybody loves we can
actually see which services are running
and I mentioned muffin briefly before
it's a it's a framework for long running
processes on metals and
running and and basically what it allows
us to do is to create application and DC
and you can see we can for example just
give it the docker image Christopher
okay so we can just have docker images
running on Martin and we can scale this
up and down and it is actually very
useful and a fundamental piece of metal
at this point but to go back to D cos we
can monitor different nodes and universe
this is pretty cool universe is the main
pack package repository 44 D cos you can
actually use a public one or your own
private one if you like and as you can
see we have a lot of frameworks that are
supported so for example if I want to
run Cassandra and I suspect I don't have
enough resources on this cluster I can
do something like advanced installation
and select how many nodes and give it
the resources that i want to give each
and every node so we get a slightly
easier way to install / skip this by the
way datastax are heavily invested in DC
OS others like the confluence platform
okay so we can see of confluent stuff
going on here okay are also very strong
partners you have bitbucket by the way
the blessing cloud runs on medals as
well send our company spark and one
thing I keep going back to spark there's
one interesting thing that there you'll
find there's a research paper that
Benjamin in men and
and so join and and a lot of others
published in 2011 talks about methods
and talks about building framework that
that are built shift with specific
scheduler so they said we're running
things like a duplet has a very general
scheduler on methods to prove the fact
that that frame works with a specialized
sketch scheduler get better results we
built another competing framework called
apache spark spark back in the day
before became an Apache project just to
prove that the framework which with
methods specific scheduler work better
on the framework and they did
brilliantly now it's it's the go-to
framework for big data processing cross
so that's in our case and really there's
heap of framework so if you need the
HDFS or by the way there's another cast
implementation a little bit older than
the confluent one elastic named our
elastic stack here so you can deploy
separately elasticsearch and cabana and
log stash and really there's a growing
ecosystem here and for frost building a
framework that actually orchestrates
things such as spark there are very few
choices for for cluster management and
we went with mel's and to be honest I
couldn't be happier
so so building distributed system with
mezzos is scalable resilient and for
most of the times easy I'm not going to
 you there are hard points every
time you're building distributed system
there they're going to be time for
anything this sucks but but a lot of the
pains go away with with meadows it gives
us better use of our cloud and our data
center and that means a lot okay I know
that we're brought to think that the
cloud you know we're just renting
machine we can scale up and down it's
not the big investment but it does it is
okay just think about all the resources
that we're wasting now I know that most
of it is for us is money of our
employers but to be honest that
electricity and resources that we we
also consume from the environment and I
actually feel deeply about that there's
also a growing ecosystem okay you see a
lot of companies investing in Meadows
building their application to run on
methods and and we haven't start
scratching the surface tears I'm I know
for sure to see I CDs solution that work
on top of methods I think that I heard
of the third one recently and any crumbs
everywhere really everywhere so so don't
be afraid and you're not confined to
using AWS or whatever cloud you don't
want to use yes it does it's in the
marketplace and it's pretty easy to set
up for some reason manager account
doesn't work in Australia so these are
the demo the vagrants machine dc-dc o
sio have a really simple walkthrough for
every deployment scenario that you want
the Apache metals website and I also
urge you if you
send mesosphere support the ticket
they're really helpful in fact they
actually sent me t-shirt so I'm going to
give those at the end of the talk to
everyone anyone that one soldiers very
very helpful and the slack channel so
it's just the D cos dot IO and there's a
lot going on there they're helping
people with anything for very beginners
to two people who stuck in the dark
points of metals so don't be afraid to
just ask questions really they're very
nice and that's it for me I think we
have time for a few questions yes so so
we took a CloudFormation template and
really it really easy to set up I
actually set up sweet clatters this
morning did I stop to but yes yes yes no
so-so Metis month on your infrastructure
as as basically demon so I don't see why
you wouldn't be able to write a
framework that just execute unstable
commands or chef for puppet and actually
haven't thought of that I don't see any
any reason why we shouldn't so if you're
using one of those frameworks and you
want to distribute the load at this
point I think I'm starting to think it's
actually not a bad idea but you can let
me know on Twitter how it works that's
it yes
yes so so the analogy is if method is
the colonel dc-dc iOS is the operating
system it give it gives you a UI
monitoring governance it gives you the
package management and also the
deployment so you're you don't need to
install meadows actually the DCOs
deployment script for every platform
will do that for you yes it's a good
question I know that Google Cloud use
use omega i'm not sure what amazon use
internally i know that that they're
being rumors about microsoft moving
parts officer into meadows and i haven't
seen any confirmation of that okay so
it's all rumors everyone is keeping
their you know their cards close to
their chests but if you want to by the
way for a long time Google actually took
pride in fact that if you're spinning up
a service on Google Cloud it takes
seconds now we know that the reason that
is is that they're not staying up a new
machine they're just being up containers
right the secret is out I perspectives
will see more and more companies use
these type of infrastructure and by the
way Meadows is not only one but from
four first of all what i did and from
what i seen the comparison with others
and played I've worked with yarn which
is very specific for the Hadoop stock
for years for many many years I can tell
you this metals performs way better than
me on okay comparing to coover Nettie's
i don't know i know that microsoft just
tired one of the main architects of
cooper natives for their internal needs
okay it's not a product that they're
going to push it for their it's for the
outer fabric team which is the internal
infrastructure to does that so all of
them will have to use something like
that at the end they want to save
resources
that's the main you know the main need
of the cloud and just make sense that
they will go into the boxes after they
sold the data center scale thing ok so
that's it for me if you want to have
DCOs t-shirts and stickers for your
laptop come to me after top</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>