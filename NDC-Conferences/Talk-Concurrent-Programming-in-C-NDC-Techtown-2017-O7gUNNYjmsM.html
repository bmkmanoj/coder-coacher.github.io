<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Talk: Concurrent Programming in C++ - NDC Techtown 2017 | Coder Coacher - Coaching Coders</title><meta content="Talk: Concurrent Programming in C++ - NDC Techtown 2017 - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Talk: Concurrent Programming in C++ - NDC Techtown 2017</b></h2><h5 class="post__date">2017-11-23</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/O7gUNNYjmsM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">alright let's get started welcome to the
session on concurrent programming in C++
we're going to talk about some of the
multi-threading facilities available in
c++ I have to say that I was quite
pleasantly surprised at the facilities
available because I think they've done a
fairly good job in terms of bringing up
to speed several things that we learned
from a lot of other languages and C++
has done a fairly good job what are some
of the issues though well the first
problem is concurrent programming is
really hard it is it is not something
that we can do so easily a lot of times
when we write code with single thread
the thread the code is fairly easy to
understand easy to maintain people come
to work they smile at each other in the
mornings and then you decide to use
multi-threading and the court turns into
a monster and nobody ever smiles at each
other after that and then we start
debugging endlessly we have to be very
careful using some of those techniques
but one other problem that used to be
traditional in C++ is C+ was always you
know touted portability when it came to
multi-threading though that was not
really the case in the past thankfully
the new libraries actually bring back
portability quite a bit so that's one of
the other things they have done really
well let's take a look at some of the
things they have done in terms of the
library itself the first and foremost is
platform neutrality you can pretty much
take this code they'll map it over and
you can run this across different
machines which is a really good thing
well one of the very first things to
consider is how many threads are advised
on your system so that's basically
called as a hardware concurrency well
let's take a look at this really quickly
you know hardware concurrency what does
that really mean so pretty much I'm
gonna output right here standard let's
say thread and then I'm gonna ask for
the hardware and then I'm gonna say
concurrency and in this case of course
I'm gonna ask for that number on on my
machine it tells me it's eight it's a
lie I don't have eight cores on my
machine I have four cores on my machine
but it still wants you to understand me
that I have eight that's because it's
using hyper threading well the first
question to ask is why why bother what's
the big deal I think this is important
for us
no as developers because we can get
pretty overzealous and say hey I can
create as many threads as I want to so
let's say you have a fairly big problem
and you decide to say I got all these
values in front of me I'm gonna throw
threads on them you could pretty much
write the program in a way and I've done
this where you were parallel code can
and will run a lot slower than your
sequential code that's not the intention
of using parallel programming isn't it
so what does this really mean why should
we really care about and that's what I
want to really talk about in the
beginning because we can be very naive
about it so the question is how many
threads should you use not how many
threads can you create you can create as
many threads as amount of memory is
available in the system we'll all of you
to do how many threads should you create
well the answer to that question heavily
depends on depends on a few factors if
you are programming computation
intensive what that means says my code
is number crunching I am going to get
data and do lot of computations on it
I'm working for a client right now
and what we do for them is we got about
sixty million piece of data that we have
to process and the minute you touch one
piece of data that produces 15 million
babies to process and you can imagine
we're gonna number crunch these through
a series of math equations on one day I
just clocked and found out how many
competition was running when I called
one function and that resulted in fifty
three billion computations and and at
the very nerve-wracking work because
thankfully the clients are extremely
nice people otherwise it wouldn't be
working there they'll come to me and say
how are things going and I would say I
worked so hard an entire day I made
things faster by two seconds and they
would Pat me in the back and say good
job now make it faster and go away and
and and this is really number crunching
work we ought to be very careful how
many threads we throw on it if it's
computation intensive your threads are
going to be busy doing work and the
least thing you want to do is to take a
thread which is busy doing the work
the CPU that's busy doing the work and
say get off so I can put another job on
the CPU so in that case then I'm gonna
threads you should maximum have is less
than or equal to the number of course
that's why this number is extremely
important on the other hand if you are
using an i/o intensive operation you
could go one minus the blocking factor
where the blocking factor is the amount
of time a task you're gonna spend time
being blocked so if you have an i/o task
for a competition to this task the
blocking factor is zero which is in a
number of course everywhere 1 minus 0 is
1 number of course is the number of
threads maximum on the other hand if you
eye are intensive if I'm sleeping half
the time it's gonna be number of course
divided by 1 minus 0.5 which means you
could potentially give me twice the
number of cores as the number of threads
in fact if I am sleeping 90% of the time
you can give me 90 10 times more core
than the number of threads as a number
cores available what this really means
is just because you can create a lot of
threads doesn't mean you should you
should be very careful about how many
threads you create and when you exceed
this limit your performance actually
goes down drastically gotta be very
careful about it and that's one of the
reasons why this number is pretty
critical for you to know so when you
start your process you want to ask how
many threads can i really use on that
given hardware and depending on your
particular hardware you need to decide
what that what that real number is at
work the machines I'm using have
literally hundreds and hundreds of cores
on them so I can configure them to go a
lot more than enough obviously on a
little box right here
so given that how do we really start and
use the threads well that's that's easy
one to do you can take a particular
function and delegate that to a thread
right off the bat very easily so for
example let's say I have a function
called you know print info right here
and this is going to simply it doesn't
really take any arguments right now and
all I'm gonna do is output let's say
info and then in this case let's say
standard and then I'm gonna ask for the
thread and I'll ask for the gate ID of
the thread and then I will ask it to be
printed out and then maybe our end
so this is gonna print me the thread
information but how do I really delegate
to this particular thread well that's
the easy part also I can simply say
thread I can create a thread right off
the bat and schedule the print it for
execute in that particular thread so you
pretty much create a thread object
really easy not very difficult at all
so you basically create the thread
object you can even send a little data
to that method if you're really
interested in this case I'm not sending
any but that's perfectly fine you can
start it but one of the things you need
to really do after this is you're gonna
call it joy in and you're gonna ask the
thread to really wait for the main
thread to wait for that other thread to
complete at this point so you can
actually wait and report on that on that
result when it comes comes out so
obviously in this case that's a get
underscore ID on the current thread not
the thread itself so I'm going to say
this underscore earth right so this is
going to be information about the
current thread or whatever the thread ID
is well that was not too hard we got the
ID of the thread depending on the
machine you are running it's going to be
different I'm running on the Mac right
now this particular slide I created I
think on Windows so you can see the
numbers are fairly different so you can
see that it's going to be some value
being reported on the other hand I'm
going to create a thread one let's say
I'm gonna create a thread two right here
so I can create multiple threads and
then of course I can ask you to wait for
thread one I can also ask it to wait for
thread two to be done and I can run this
and see what the result is and that also
illustrates one small issue that you may
run into notice that in this case I have
them printed and I have a ndele but
these kind of jumbled up this couldn't
have been easier for me because I wanted
to show you this problem usually doesn't
happen so easily today's my lucky day
and you can output really messed up
that's one of the things we have to be
very careful about how these things are
going to appear so when I run this code
the result may actually vary depending
on what you do so I'm just running this
here and you can see that it's quite
jumbled up when it comes to the output
even though I have an end all in there
well what do we do about you know when
things collide like this welcome to that
in just a minute so you create thread
very easily by simply using the thread
object and this breaks the question we
got to know what really is happening
there are two distinct things that you
need to keep in your mind
there is the threat of execution and
there is the thread object and it's
important to keep these two things in
mind very clearly because our human mind
is very good at getting confused between
the two the threat of execution is going
to happen at the up at the system level
you have no control over it most of the
time the thread object is a pure
abstraction a thread object is an object
that allows you to get information about
this thread of execution and - maybe
monitor this execution and you need to
keep these two things in mind and when
you create a thread object the threat of
execution starts running and the thread
object is attached to that particular
thread of execution when you say join
your thread object is going to block
your calling thread until the thread of
execution actually finishes if you don't
care about it you could attack and say
like the thread of execution go on its
own I am NOT interested in monitoring it
anymore you can detach yourselves and at
that point the thread object will be
completely unattached to the thread of
execution it no longer monitors the
thread of execution so keep those two
things in mind the thread object versus
the thread of execution itself so we
create a thread really easily how else
can we create a thread well in this
example I just passed a function to the
thread to create it but there are two
other options available to you as well
one of them is you could actually create
I'll come back to this in just a few
minutes you can also create our object
like in this case I have a class called
sample as you can see and all that the
sample contains is an operator
overloaded parentheses and once you
overload the operator overloaded method
parentheses you actually pass an object
of that type to the thread and it would
then call that particular method that's
another easy way to do it a third way
which is my favorite way is you can pass
a lambda expression as well so here is
an example of passing a lambda
expression where you can just simply say
I want to pass this lambda called well
of course lambdas are anonymous methods
and here's a lambda I'm passing two
thread one and this lambda will be
executed as soon as you kick start this
particular thread so
these three options you can send a
function you can send an object that has
an operator overloaded parentheses and
then you can also pass a lambda
expression as well as the three
different things that you want to send
to the thread but obviously in this
example we just saw there is one small
problem as we saw that the output is
kind of messed up and jumbled up what
can we do about it
well what we are doing here is something
called evil programming and that is we
are using a shared resource from
multiple different threads and that
usually doesn't go really well so what
do we do about it well one solution for
that is to provide a mutex that you can
provide in here so you could create for
example for instance a mutex right here
called let's say see out meu tech or
whatever you want to call it as and then
I create a mutex and then what I can do
here is I can simply say that the sea
out mutex I can say lock on that mutex
and I one might when I'm done with that
I could say in this case unlock and
release the lock on it so you're saying
when multiple threads come in let the
threads you know fight over each other
it is kind of like the bathroom door
right you may have multiple people using
the same house but you have one bathroom
it's good idea to lock the door when you
go in and then as a result of course you
can you know be the one leaf person
using the bathroom which i think is a
nice thing to do but of course if you
have teenagers at your house you know
they go in but they never come out and
that can be kind of annoying that's
exactly the problem with this there's no
guarantee of unlocking and you bang on
the door and say get out of there you've
been too long well how do you deal with
that we'll talk about that in just a few
minutes so the whole idea here is to
lock and unlock so that we can you know
mind be mindful of this resource and you
can see how nicely now they are in two
different lines rather than being
jumbled up on one line because they kind
of synchronized and one used and the
other used no guarantees which one
actually used it but of course one goes
in the other comes out then the other
one can go in so that is an example of
how you can use a mutex to resolve
conflict between threads as well we'll
talk more about this a little bit later
well so think of this abstraction I
talked about separation of the thread
from the threat of execution from the
thread object itself and you want to be
mindful of this talking about which
notice in this example I have two
threads I have created this is more of a
feature in C++ which I'm really not sure
if I like or don't like I'm still kind
of thinking about it I have a thread
running on that still thinking but in
this case when I run this code notice it
is giving you a error right there it's
just terminating bla bla bla what it is
telling you is that you created threads
but you never really bother to join them
and and that's what it's complaining
about so if you don't join a particular
thread you get an error but when I do
join the threads you can see that I
don't get any errors at all so in a way
you could argue this is a nice thing you
get an error if you were forgetful e not
joining a thread what if I don't care to
join a thread what if I don't really
have a reason to wait for it then do a
detach instead of a join and that's
perfectly fine as well and you could do
a detaching of the thread but of course
when you do detach a thread when I run
this you didn't see any output at all so
what in the world is happening
well detach means you have just created
what's called that demon thread so what
is a demon thread a demon thread is a
thread that does not hold the main
thread hostage so if a non non demon
thread usually will require the main to
be running and the program to be running
when those threads are alive a demon
thread says if the main quits and all
the non demon thread squared a demon
thread will never hold your program
running so if you detach a thread you
are simply saying I don't care about you
you can just keep running I'm gonna shut
down and go home and that's basically
what a demon thread s so it's kind of
like you tell a staff saying that you
know wait in this room and turn off the
light when there is nobody in the room
obviously you don't want the staff to
say I am here so I'm gonna keep the
light open usually it means nobody other
than you are in the room that's kind of
the difference between a demon thread
versus a non demon thread a non demon
thread will keep the you know
application running a demon thread will
not
well detaches on a way for you to create
non daemon --thread saying I don't care
if you're running or not so we can join
we can detach either one is fine and we
saw how to detach as well that was not
really hard at all but of course you can
ask if a threat is joinable so there are
two things if a tread thread has been
you've not done anything to a thread
other than create it it is joinable if
you join a thread then it is no longer
joinable because you already joined it
if you detach from a thread even though
the thread of execution is running the
thread object is no longer joinable
because you have detached from it so
that is something for you to keep in
mind if you will so you can go ahead and
ask the question output right here a
thread one dart joinable you can say a
joinable and you can ask that question
whether this is joinable and in this
case it tells you one right there which
means it is joinable on the other hand
after I call the detach if I ask for
exactly the same question you notice
it's a zero right there because it's
been detached and it no longer joinable
so that's a way for you to know whether
you can still you have the ability to
join a thread or not you may have a
thread object with you by mistake but it
is attached already from the thread of
execution meaning don't mess with it
anymore it's pretty pointless to be
using at this point so we talked about
joining but there's one other problem
though what if there is an exception in
the code you always have to worry about
exceptions isn't it so what if the code
blows up if you have a joy in and if you
have an exception your join is not going
to be called in that case of course your
program is going to give you an error
because you neither joy nor detached
what do you do well you could try to put
a try and catch and within a catch block
you could put a joy in outside the catch
you can put a join but that code becomes
really really messy and you kind of
scratch your head and say gosh the code
regularly becomes ugly how'd we manage
this so so here's what you don't want to
be doing putting a join here and putting
a join over here that can become really
really messy so one way to solve this
particular problem to avoid these
verbosity and error-prone
code is to use the so called ra Ã­Ã­-
pattern which is the required resources
acquisition as resource initialization
pattern so what I'm doing here is I'm
creating my own thread class as you can
see so this thread class internally is
gonna create a thread but i use a enum
called join or detach just to make my
life easier you can tell me what your
intention is whether to join the thread
or to detach from it but then the beauty
of this one is that in the destructor I
am going to either call the join or I'm
gonna call the detach and of course if
there was an exception this object will
still be destroyed and as a result
either I throw a join ordered attached
will happen I don't have to worry about
it later on in the code so you can wrap
your thread into this object then you
don't have to worry about calling detach
don't have to worry about calling you
know join you let this object deal with
that by specifying how would this look
like well the way you would use this is
as follows you would say a thread thread
notice this thread now is our own class
not the STD colon colon thread which
then wraps the thread as as part of it
and then manages the you know death of
that particular object if exception were
thrown is gonna take care of it so you
can pretty much wrap your resource
around it and deal with it properly and
of course there are a few things you
gotta be very careful about how do you
pass your object to this particular
thread so in this example I have
something called Sam and I'm trying to
pass Sam to this thread this is also
known as a bad idea because it's going
to try to make a copy of it and I
incremented Sam's age but it's an old
age so what are you going to do instead
what you want to do is to use a
reference so you can send a wrapper
reference rather than sending the object
itself by reference and that way you are
really passing the object reference
properly so little things like that you
gotta be very careful to pass it around
but that's nothing new for as you've
done this in C++ it always surprises you
when you don't expect it so so that you
have to be very careful about how you
pass these objects around now having
said that the thread is the easiest
thing but then the fun begins
No
what happens is when you start running
multiple threads you always want to
communicate between different threads so
what is the worst way to communicate the
worst way to communicate is using what
is called a shared immutability now
think about this for a minute
mutability is extremely common in C++
we mutate stuff every corner return and
a lot of times we do this because it's a
lot performant and so mutability is okay
what about sharing well sharing is a
good thing remember what mom told us we
should really share that's a good habit
so mutability is okay sharing is really
good but shared mutability is devil's
work and the minute you bring and shared
mutability all kinds of problems come to
life and this is when it becomes really
really really sad the way we work so
shared mobility is purely evil we should
try to avoid this as much as we can but
of course there are times when we do
want a program which shared will pretty
like I mentioned especially for
performance reasons we often do this so
it's a risk you are taking quite a bit
so how do you really deal with this well
you have to properly protect your data
to do this so there are some rules we
have to be very careful about race
conditions are something you want to
avoid absolutely when multiple threads
run over each other the results becomes
absolutely unpredictable and these kinds
of errors are extremely hard to track as
you know so you have an error in your
code you run it it gives you a wrong
result you are scratching your head you
call your colleague and say look the
code did not work you gave a wrong
result after looking at this for 30
minutes your colleague then says run it
again and now the result is completely
different right it can be very annoying
because it's very unpredictable you
cannot just rerun it to see what the
result is so what do you do about it you
got to thoroughly examine the code to
make sure that it is really correct from
the concurrency point of view so here's
an example I have a variable called a
count and within this change method I'm
making a copy of the a count
incrementing the copy by that amount and
then setting the value back in now this
is completely unprotected code inviting
prob
then in the in this I created 20,000
threats and then I pushed through the
thread that changed function but I asked
it either to increment by one or to
decrement by one now if it is even an
art well it's 20000 values we know that
there is as many even numbers and 20,000
as there are art numbers so what should
that result be when I'm done with this
the result obviously should be a value
of zero because I increment it as many
times as decremented as many times but
when you run this program you can
absolutely not predict what the result
is going to be it can be a really good
program to generate lotto numbers if you
want to very pretty random every time
you run it isn't it because it's not
really clear how the threads are going
to run and why is that the reason as to
threads may come in and read exactly the
same value and they're competing against
changing the value the last one is
actually going to win the way to think
about this is that you have multiple you
know people trying to put their hands on
a bowl it's going to have things spilled
over that's exactly what's happening in
this case right not very very much fun
so what do you do about this well one
way to decide this is to use a mutex and
then you can call a lock on this and you
can call an unlock on it just like I did
a few minutes ago with that other
example the problem the good news about
this code is now the result will be
absolutely predictable almost unless
there was an exception someplace what if
this code in the middle of lock and
unlock blew up with some exception well
then you're going to have a unpleasant
live lock live lock is different from
blade lock live lock is where you wait
forever for an event that will never
ever happen right this is like you have
a teenager at home who went to the
bathroom but slipped away through one of
the windows you don't even know that
they're not in the bathroom anymore
right like teenagers do you're gonna
wait for a very long time for them to
come out I know those of you laughing
did this when they were teenagers that's
where they're getting a much laughter
about this
so the point really in this case is
that's a live lock you gonna wait for
something to happen that would never
have
so as a result what do we do about it
well here's a way you can actually and
this is the part I really really I'm
happy for in C++ because a lot of
languages don't do this a lot of
languages will come to this point and
then they will give you one solution
which can be summarized in two words
called good luck and the C++ said okay
will be kind to you will give you a bit
more solution and they give you what's
called a lock guard I really really like
a glog guard what is lock guard the RAI
I applied on locking itself and I do
have to admit they have done a really
good job the day I learned about this I
said I really love these guys they've
done a job on this so what does a lock
guard do lock guard as you can see wraps
the mutex and gives you the lock on it
you never unlock it when you leave the
scope the unlock happens automatically
other normally or through exceptions you
are perfectly safe to handle at this
point that's exactly what this is giving
now of course in programming you know
one thing when you solve one problem
it gives raise to another problem so
I'll talk about what the other problem
is in a few minutes so this solves the
current problem we have at hand
we'll talk about the other problem in
just a few minutes so in this case of
course we can use a lock guard which is
really good model of the story don't
ever lock and unlock mutex that's a bad
programming always use a log guard until
I use that use that rule until I change
it in a few minutes so so don't ever use
lock and unlock that's a bad programming
okay so we talked about this but it's
not a panacea we got to still be careful
about how we use this you can still get
into trouble by not protecting things
properly there are places where you
could you could really get into mess
with this also how do you prevent this
well first of all make sure your data
never escapes so let's talk about what
this means let's say I have an object
with me you lock you call a method on me
I give you a reference to an object
maybe an internal state and then we
unlock it well after the unlock is over
you come and change the reference I'm in
trouble again that is called escaping
the object so when you do an current
programming you have to cheer that your
data never
escapes from you so where we return
references we have to be very very
careful because it's possible that you
have just given out a reference that
somebody could come and change it
afterwards when the lock is no longer
being held so things can still go wrong
the next problem to think about is
deadlock so what is deadlock deadlock is
of course where multiple threads are
waiting on each other one of my favorite
analogies to use is you have a boy and a
girl at home the boy grabs the sugar and
waits for the milk and the girl grabs
the milk and waits for the sugar what is
this called it's called parenting
nightmare and and this is when they both
are going to wait on each other not have
breakfast so what do you do you make a
rule you should not get sugar any more
until you have God on the milk already
and that's exactly the whole point about
one way to avoid deadlock is to make
sure that you always occur the lock in
one certain order now the good news is
you acquire the locks in one certain
order the bad news is I have no clue how
to get the locks in one certain order
because you don't it's not like you have
a very good plan where you can take
these objects and put them into order
and any time we do coding what happens
this is one thing I've learned over the
time you let a programmer write code
that becomes a liability right this is
the time and again the more code you
write the more bugs you have to maintain
so if this is something that's got to be
done the right way you want to give it
to the adults who can't write it the
right way I'm saying it sincerely
because when I am working on my
application I have a lot of stuff on my
mind already that's my focus
don't tell me to focus on my app and
focus on infrastructure issues and
library issues this is the reason I use
libraries so I don't have to depend on
those things myself and I can take
somebody who has done a good job and use
their solution so if that luck should be
avoided why don't you guys do the work
to avoid deadlock then tell me lock them
in the right order that's another thing
they have done really really well and I
really am happy what they have done so
let's see what the answer is notice
there's an account here and the transfer
from locks guard one
and then it locks guard too this is also
known as a bad idea never acquire the
lock more than once in your execution
sequence so in other words you should
never acquire one lock and why only hold
on to one lock you recurse for the
second lock that's a really bad idea
right because the lock you're holding
and then you're requesting for another
lock could cause the deadlock because
somebody else maybe think that other
lock and waiting for the lock you
already hold and now your intention back
and forth holding on to this so this is
a bad code don't write this don't get
one lock and then wait on the other lock
so what do you do to prevent this
problem well what you can do nicely
instead of doing that is you can now use
the lock again but in this case notice
this is a not a lock on the mutex but a
lock function directly that lock
function takes a sequence of locks as
you can see right there and in this case
of course it gets those locks
but unlike you and I calling the locks
it is gonna acquire the locks in the
order properly internally so you don't
have to worry about it so always acquire
the locks in one shot never acquire one
lock in Turkish for another and then of
course you're asking for a guard lock
one and then you can slowly ask for the
guard lock do that's perfectly fine and
it will guarantee that it acquires the
lock in the proper order for you and
then you can go back and use it so so
that we can prevent the problem and what
is this guard lock one and guard lock to
do well they are a really for unlocking
purpose so you don't worry about oh my
god I forgot to unlock it it'll take
care of the unlocking properly this will
take care of the locking in the proper
order for you and you can prevent
deadlocks by doing this so this is a
really good way to handle it so you can
do a lock and then you can do a guarded
lock for unlocking purposes when you are
done with it that'd be very safe so
never acquire multiple locks on you know
one at a time always acquire the locks
in one shard and never lock on a object
you already locked already that's not a
good idea and avoid nested locks as well
so given this
there are times when you want to acquire
a lock but unfortunately though you want
to make sure that you are you know say
how do I make sure I don't get a lock I
already have garden this is kind of
stupid right it's like you have a lock
but then you lock yourself out by asking
for a lock again I don't think there is
any better way to feel stupider than the
other day because you're debugging this
for a long time and you realize the lock
is being held by you yourself which can
be very vexing so what we prevent that
is to use what is called a unique lock
when you use a unique lock it knows that
you already have a lock so it grants you
the second time you ask for it rather
than blocking you out so it could be a
really nice way to solve that one bit
problem is you could do this another
advantage of this is you can also do
what is called a deferred mode so you
can just say you can have a dibs on this
but you don't want to lock it until a
later time you could do that as well so
you could use a unique lock and that's
another thing available already you can
say unique lock right there and then
provide the lock that you want to use
and you can say instantaneous R or
deferred and then of course you can then
come back and use it later on when you
really need it so I can start defining
these kinds of locks another of course
you want to also avoid race conditions
that may arise in this form also this is
more related to leaking the object like
I talked about earlier so make sure you
don't leak your resources make sure you
hold on to the locks properly so how do
you deal with that one way to deal with
that is to maybe provide a method
explicitly to acquire a lock on your
object so here's the problem right if my
function is going to do locking
internally and say that I have two
functions you call my first function it
locks and then does its works and
unlocks then you call the second
function it locks and does it works an
unlock but the problem is when you call
these two functions between these two
calls that very small moment when you
release a lock somebody could get in and
that could lead to problems so what you
want to do is do a lock around those two
methods entirely not individual methods
separately and that's when you could
really get a function to give you a lock
and then you can take your time to call
multiple functions and then you can come
back and unlock it when you are done
with it
again you have to think multiple times
about how this works so that's what I'm
gonna do in this example is to make sure
that I acquire the lock outside of this
notice that I get lock so I can call the
get lock method and then I can do my
work and when I'm done with it
I will release the lock on the object
that way I can call multiple methods
without fear of somebody intruding
between my my calls so there's another
problem though that we have to deal with
and and that is let's take an example of
a little example of a singleton you know
what is singleton singleton is the
easiest pattern to read about and the
most difficult pattern to implement
because if you go a search on the web
implement singleton pattern you'll be
surprised that people have seven
solutions and at the end of the seventh
solution they say this doesn't still
work and this is really hard to get
correct from the concurrency point of
view and can be very vexing well here's
an example where in the singleton you
can see that I have a get instance this
text is the pointer is null if it is
null it acquires the log and then again
checks if it's not it's still null
because between the time you checked and
the time you got the lock somebody could
sneak in and and change that too
this is really sad programming isn't it
well how do I avoid these problems it
would be nice if somebody can do this
for us that's exactly what called once
this so call once is a method that will
say call goes only if this has not been
called already
so when multiple threads compete one
thread will do this word all the other
threads will say oh this has been
already done and they can skip over so
in other words you take all the silly
code we do and you move it under a
library so that can be done for us so we
don't have to duplicate our effort doing
it over and over and over and that's
exactly what the call once is doing for
this to work of course you have a
pointer ones or whatever name you call
it and you pass that over here so they
compete on that reference and then they
decide whether to call that method or
not call this removes the burden of
writing all that silly code and
wondering if it's still correct and and
that takes care of that so call once is
a good idea well similarly to
synchronize you can use a
variables to synchronize as well and
these are conditional variables you can
synchronize so this is where you have a
signal and weight so you can say notify
once and then it can wait on that so if
you have two producer and consumers
running and you want one to produce a
result and you want the other to wait
for it how do you signal between those
two threads that's basically what
conditional variables are for so you can
create a conditional variable share
between those two threads when the
thread that produces a result can do a
notify and then the thread that's
waiting on the result can do a weight on
it and then continue doing whatever work
he needs to do after that
that can be very powerful way to
communicate between those two one other
suggestion before we go any further the
rule of multi-threading and I would say
there's a rule not only of
multi-threading the rule of ice and
multi-threading never do anything
without a timeout it is kind of like
finding that perfect love the sensible
person will look for a perfect love and
then you eventually timeout otherwise
you get old and die alone that's exactly
the rule of life and programming also
you never do anything without a proper
timeout you say I want a lock but I'm
gonna timeout if I don't get it after a
reasonable time you can prevent dead
locks as well so everything you do in
concurrency always do with the timeout
never do without timeouts okay so let's
stop right there we have done this and
what is one of the biggest really
problem we see so far the problem so far
is we can summarize it this way hey
great I have a beautiful way to create
threads I can run these threads
concurrently I'm happy for that that's
awesome but one big hole I cannot deal
with mutability I don't want to create a
global stare shared variable and have
all these threads work on it that's
really a poor programming practice
there's got to be a better way to
communicate between these threads
how can I do that so take the multi
threading the thread creation aspect and
mix it with the communication aspect to
exchange data so you don't warn it's
kind of like this glass over here you
don't want to put this glass here and
say you
when I are going to share this that's
not a good idea well I'm gonna fill the
water and then I'm gonna give it to you
with the full glass of water and you can
now take it and move on that way you
know the glass is full when you get it
otherwise you're gonna keep checking the
drank it fill it bit bank it fill it
there's no reason to do that so how do
we really send you an object that's
exactly where future comes in future is
a really nice implementation where think
of a future as an object that goes from
one thread to another with the data that
is being carried over so here's an
example Fibonacci was computing the
Fibonacci as you know this
implementation can take a really long
time
if the Fibonacci number is big so print
result wants to print the result of
Fibonacci when it's done but not as a
signature of print result it is not a
long it's a future long so this says
when you give me a future I'll call it
get on it and I will wait on the get and
then when the get gives me the result I
will print it so this future long is
what I'm gonna print but how do I get
that future Hey look at that thread like
we did before so I'm gonna call the
thread and I'm gonna send the print
result to the thread but notice I'm
sending an async object right now and
async will run in a completely different
thread but the result of async is
actually a future
so what are we avoiding we're avoiding
the stupid global variables you don't
want two threads to go at a variable and
do Muta control that instead you say hey
you thread you go run do your work when
you're done with your work you send me
your result through your future I will
wait here on the future and when the
result arrives I'll move forward and
that becomes a nice way I call this
civilized multi-threading right the
other one is called barbaric
multi-threading where you put a global
variable and you attack each other on it
this one isn't very civilized you go to
your work I'll wait here when you're
done you send me the result I'll carry
on after that that's exactly what this
future is doing so in this case of
course this will run get the data and
the future dot get will be blocked and
that will trigger off and run when the
data becomes available so but
one problem though you are taught
starting an async but remember we are
sensitive to threads you don't want to
be creating too many threads what if the
thread that's creating this code doesn't
have any real work today you don't want
the thread that simply spawned threads
and say you all do work well let's sit
and watch you that's no fun at all you
want to make use of that really well
this is where async can take couple of
different options one option is called
deferred deferred means the thread that
is calling the async is going to finish
its work really quickly and the
asynchronous operation can actually run
on the same exact thread and it may be
called by the thread that's calling it a
lazy and may run never also this is even
better
hey why do the work that shouldn't be
done in the first place so you can put
it on a lazy mode and then if I don't
have a reason to ever run it then don't
bother running it I can and just walk
away so you can do it effort or you can
do an async let's look at the difference
of this so notice in this example I have
a compute and in this case the compute
position and it's returning Fibonacci of
the position and I'm printing the thread
ID in the compute but on the other hand
in the main I did a sink a async but I
called a deferred on it now notice the
thread ID of the main the thread degree
of the main is four nine nine one six
but the thread ID of the compute is also
four nine nine one six and the reason
the thread ID is the same as you said
deferred and the main said gosh I'm
already done with my work I'm gonna
block and wait on the result while I'm
blocking on it I might might as well do
some more work rather than wasting this
thread and this is something extremely
important because you don't want threats
to block and wait and do nothing that's
a wasted resource when a thread is
blocked and doesn't do anything you want
to use the thread to do more work and
this knows to do really do that and
that's exactly what you saw here when
you set Deford on the other hand the
same example I'm running with async
rather than deferred now notice that
thread IDs are not the same at all
because the main is
blocked on get this one started on
different thread all together so you get
to decide whether to use a deferred or
to use a sink there's no really one good
answer it depends on the problem you're
solving sometimes you do want a fresh
thread to be running it other times you
don't mind this threat to really pick it
up and run you can pick and choose what
may make sense well okay so that's great
so far but we come to the same problem
again now you have a future and you're
saying I know I shouldn't use a global
variable I know if I create a global
variable I have to use a mutex it gets
really messy but I have a future now can
I share the future now that is no future
at all right because you're back to the
same problem your contention is over the
future now and that's not going to be
fun if you ever want to share a future
there are two answers to it first is
don't that's not a smart way of
programming and the second is if you do
really want to do it make sure to you
move the future between those calls by
using a shared future so you want to
create a shared future and a shared
future is thread safe our non shared
future regular future is not thread safe
if you call get on the future twice from
multiple threads your code will actually
fail never share a future if you want to
really share a future use what's called
a shared future for the purpose never a
future itself well okay so we avoided
this problem we can pass data across
that's really nice but what if we really
want to implement serious algorithms
with this this is where what's called a
packet pass comes in a pack test gives
you a way to really create tasks in a
way that when you call a pack task it'll
fire off a request on one side and give
you a future on the other side so it's a
nice abstraction around this code to
really create an async so here's an
example of a packed package task so I
say package test tasks compute this
compute method will run on it but when
you start this package task but you
readily get a future out of it so you
don't have to do a hodgepodge of I'll
create a task over here I'll get the
future over here you
have to be brutal about this to end
points you can just package them hey
that's why they call it packaged you can
package them together and say you go do
this work but give me a future on my
hand you're able to get the future right
from it so package tasks really make
programming much more easier and
pleasant keep in mind when you use a
package task you are building on the
future we just talked about so what does
this really look like when you do this
on one side it fires off an asynchronous
request on a worker thread on the caller
side it immediately gives you a future
so this is kind of like when you do this
is goes pin like this and this code
executes on this thread and you are left
with the future on your hand so that
becomes a nice programming abstraction
so don't use future directly unless you
are doing some low-level stuff introduce
a packaged task now like I said earlier
every time we solve a problem it gives
birth to a new problem you say ok this
is great
I don't want shared morality I want to
use future but what if something were to
go wrong if you call a method it runs it
doesn't give you a result instead it
failed miserably with an exception what
gives how do I get that exception on my
side in a very civil way that is the
purpose of a promise so a promise is a
future which can handle exceptions so
when you create a promise a promise may
give you a result or it promises to give
you an exception so think of a promise
as a future which may either result in a
success or may result in a failure and
and that is exactly what this is doing
but the programming group is a lot
easier notice I have a promise on my
hand and I say promise start set value
when everything is good or promise start
set option when something really went
wrong and this exception or the result
will go back to the caller site properly
so if your code doesn't have any
exceptions at all in it if it's purely
number-crunching you don't expect
anything to go wrong in it like division
by zero for example which is a future
that's perfectly fine if we expect
something to really go wrong you want
handle exceptions then you
the promise instead of using a future
that's a lot better so how do we use
this on this site well notice I say
result promise and I say result promised
I'd get future and then of course that's
going to give me the result but if
something were to go wrong
it's gonna blow up on your side so get
future will either give you a result or
get future will throw an exception at
you and you can handle it on this side
and you can deal with it so that's all I
have hope that was useful thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>