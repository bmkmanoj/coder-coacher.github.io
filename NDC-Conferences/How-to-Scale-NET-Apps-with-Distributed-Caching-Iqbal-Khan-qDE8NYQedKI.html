<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to Scale .NET Apps with Distributed Caching- Iqbal Khan | Coder Coacher - Coaching Coders</title><meta content="How to Scale .NET Apps with Distributed Caching- Iqbal Khan - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to Scale .NET Apps with Distributed Caching- Iqbal Khan</b></h2><h5 class="post__date">2017-02-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/qDE8NYQedKI" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay welcome everybody thank you for
coming to this talk my name is Iqbal
Khan I am a technology evangelist at
this company called a large soft which
is maker of distributed cash cashing
product called end cash
today's topic is scaling dotnet
applications with distributed caching
this is not a talk about in cash it's
about the actual topic of what problems
does distribute cash and solve and how
does it solve it and how should you go
about using it if you have any questions
please raise your hand as I'm talking so
that I can have more interactive session
instead of waiting until the end okay
and by my apologies I have a slight
cough so I hopefully I won't be coughing
I've got something in my mouth but if I
do please so let's go through a few
definitions I'm sure most of you know
this already but just for completeness
purposes will first define scalability
so scalability is not application
performance it is application
performance high application performance
under peak loads so if your application
performs super fast with five users it
is not necessarily scalable until it
performs the same way with 5000 or
50,000 or 500,000 users of course if
your application doesn't perform with
five users then you have other problems
than what the sessions all about so
linear scalability is more of a
deployment definition if your
application architecture is such that
you can deploy it on multiple servers
and as you add more servers the
transaction capacity and the word
transaction here means activity the
requests by the clients of that
application it that the transaction
capacity can increase as you add more
servers in a you know in a linear
fashion then you have a linear
scalability in the application if you
don't then you have a nonlinear
scalability which means that after a
certain number of servers adding more
servers actually slows things down so
you're stuck pretty much you can't
really buy your way out of this so you
obviously don't want a linear scalable
solutions which applications need
scalability if you have one of these
applications then you're in the right
session
these are usually web applications
asp.net Web Services back-end for IOT
big data processing through distribution
and other server applications that need
a lot of transactions these days a lot
of businesses are online you know
ecommerce online banking online
everything so any online business that
has a customer facing application
usually needs scalability that's where
you get thousands of simultaneous users
think of a bank or an airline or a
social media company and scalability
comes to mind the backend for IOT is
also all of those devices need to talk
to somebody on the backend so that needs
the backend needs scalability big data
processing is also a very big emerging
space although my focus is net and on
the dotnet side the big data processing
isn't as popular as it is on the Java
side but that the concepts are the same
you can do big data processing through a
distributed model and achieve
scalability other server applications
you may have a large bank that has
millions of customers that call every
day to change address maybe transfer
funds from one place to the other and
there may be compliance issues by
midnight or by sometime at night you
have to process all of those requests so
there's a scalability need where you
need to be able to handle all those so
essentially all of these are server-side
applications that need scalability so
what is the scalability problem first of
all the good news is the application
tier in most of these applications
scales very near linearly you if you
have a web application
in a load-balanced environment you can
add more servers no problem so the
problem is in the data layer the data
storage layer what I mean by data
storage is relational databases your
mainframe legacy data your application
data the data is the one that's
bottleneck if you use no SQL databases
they will help this scalability problem
but a lot of the time you're not able to
move to no SQL because for a variety of
technical and business reasons you have
to use relational databases and no SQL
is useful only when you move to it so it
requires you to move away from
relational at least whatever data you
need to put into it you keep it only in
one place not both so that's why it's
not always the answer
even though architectural e no SQL is a
scalable database so you pretty much
have to solve this scalability puzzle
with relational databases in the picture
you cannot remove them from the picture
and still and hope to achieve
scalability in all cases in some cases
yes you can so how do how do you
actually achieve scalability you deploy
a distributed cache in between the
application tier and your database tier
or your data tier and this distributed
cache is kind of a new best practice for
any application that needs scalability
it is it consists of two or more
low-cost servers where they form a
cluster and that cluster actually pulls
the CPU the memory the network card
resources into one logical capacity so
the more servers you add at this layer
the more capacity you have and capacity
is transaction capacity storage capacity
and throughput in terms of the network
cards so these days if you want to
achieve scalability you pretty much have
to have this infrastructure in your
application in case of dotnet
applications
it's it's good to have all of the whole
stack being net and these boxes
typically are not very high-end that the
most common configuration that we've
that we see is a dual CPU quad core
basically eight cores per cache server
configuration 16 gig to 32 gig is an
average memory on each cache server so
it's better to have more cache servers
with less Hardware power than a few with
a lot of hardware power and and because
the cost also is more manageable if it
is that way once you put this caching
layer in between the application and the
database the goal is to use it for about
80% of your data traffic so 80 percent
of the time you should be going to the
caching tier and 20% of the time you
should be going to the database tier
that 20% includes a lot of updates all
updates of course have to be done to the
master data store which is your database
but and and some of the reads because
the data has to be loaded into the cache
from this so this keep this picture in
mind with this picture you can pretty
much scale quite a bit I mean we've you
know we have customers who've got 5200
servers in the application tier which is
pretty much the high end of ecommerce
these days most customers have about 8
to 20 servers in the application tier so
then you have a four to one or five to
one ratio between the application tier
and the caching clear that's not that's
not a limitation it's just a best
practice based on how much load the
application tier can take versus the
caching here but that ratio might change
if for every let's say for every client
request on the application tier you have
to make a lot of cash and calls then the
more calls you make per client request
the more or the less of a ratio you have
to have between the application tier and
a caching here but the minimum or the
minimum ratio that we've seen is two to
one
and you know where you have four servers
in the application tier then you might
have to in this minimum you need to of
course for redundancy purposes so that
high availability can be achieved so
this is sort of a case into why you
should be using a distributed cache in
your application what problem it is
going to solve so let's say once you're
convinced that distributed cache is
going to solve this scalability
bottleneck the next question that comes
to mind is how do you use it where in
your application should you use
distributed cache what are the use cases
where distributed cache makes sense so
that three categories of it number one
is what I've been talking about so far
which is the application data caching
and you know that's why we talked about
the that you reduce those data base
trips the thing to keep in mind and
application data caching is that the
data exists in two places one in the
caching tier and one in the database now
as soon as you know that data exists in
two places what's the first problem that
comes to mind that might occur
synchronization yeah so the worst that
could happen is that the data in the
caching tier is older than the data in
the database and that data is sensitive
and you really can't afford to have an
old copy and the biggest example of that
is a banking application where you know
you're trying to withdraw funds you
don't want to withdraw a million dollars
twice or maybe you do but the bank
doesn't you know so that's the biggest
problem that any distributed cache has
to solve and if a distribute cache does
not solve this problem then you're
forced to cache only read-only data and
in fact most people when you talk to
them about caching think of caching as a
read-only store you know where the data
doesn't really change much did you have
a question okay but in reality you want
to cache
as much data as possible that means both
read-only data data that does not change
very frequently but it still changes and
data that changes very very frequently
all data has to be cached that's the
only way to really benefit from that use
case and now I'll come back to how you
achieve that number two use case is if
you have an asp.net application then
there's some asp.net specific caching
that you can do the most common is the
sessions and that's also the easiest to
use also the the second is the viewstate
if you are not using the MVC framework
in asp.net then the second use case
would be the viewstate viewstate for
those of you don't know what viewstate
is is an encrypted string that gets sent
by the browser I'm sorry by the server
to the browser only to come back and in
case of a post back so that heavy string
which might be 1k to hundreds of k
travels all the way to the browser and
maybe on the next call comes back so
it's an ideal case for caching if you
could just cache the entire view state
on the server side and only send a small
key it would speed up your overall
application quite a bit it will also
save you a lot of bandwidth cost
bandwidth is not cheap and you know in
terms of how much data you're going to
consume the third use case in asp.net is
the page output so if your pages are not
changing every time why execute them
again every time you execute a page you
you're consuming all those resources CPU
memory and all the backend you're making
the database calls all of that but if
the output is going to be the same why
not just you know display the output
from the last execution Microsoft
asp.net framework has an output cache
capability where you can plug in a
distributed cache so that the same
capability is going to be available in a
web form in case of asp.net the nature
of the problem completely changes I mean
in case of asp.net specification of
course you will do application data
caching also from within
p.net but that's I'm categorizing that
as separate but other than the
application data caching the asp.net
specific caching the data exists only in
one place which is the cache
there is no database you don't store
those sessions in the database if you're
going to put them in the cache so the
cache is the master store at the same
time the data is transient when cache
becomes a master store what's the
biggest concern you have what might
happen if cache is the only store yeah
you might lose the data because cache is
in memory and memory as you know is
volatile so if you put data in the cache
any cache where are you going to put a
session or other types of data as the
master store that cache has to provide
replication without replication if
you're caching the data you're going to
you know you're basically walking on
fairly thin ice there's another problem
which is that memory is limited and
which is true also in application data
caching your database might be terabytes
of data but the cache as I said about 16
to 32 gig per server maybe you have five
or ten of those servers so you have a
few hundred gig of data at most so it's
a subset of the database and that's okay
because you will just remove some of the
data when the cache becomes full because
that data exists in the database right
but that is not true when you have cache
becomes the master store so again keep
this in mind and we'll come back to this
that when when you're using a cache as
the master store you don't want to
remove data unless that data is no
longer that you know it's life is over
so you don't want to just remove data
because cache is full you want to do
capacity planning appropriately that
when whatever data you're storing for
example if you're storing sessions in
the cache
you know the UU expire sessions based on
inactivity so you say if the user is
gonna stop using it the user logs out
and after about 20 minutes of inactivity
the session needs to be cleaned up so
you need to do your capacity planning
we're under peak loads the sessions are
expiring and not being evicted so that's
so the nature problem is is is different
the third use case is something that a
lot of people don't know that cache is
really good for which is runtime data
sharing through events think of this as
like a service bus as a SMS a messaging
platform but it's not a replacement of
message queues message queues have a
different purpose they can work in a
geographically distributed environment
cache runtime data sharing is good
usually within the same data center but
within the same data center a
distributed cache is much faster and
more scalable than message queues for
runtime data sharing because of the fact
that it's got multiple servers you can
keep adding more servers as your
transaction capacity increases and a
good distributed cache provides
event-driven pub/sub based or pub/sub
style data sharing model also other
types of events continuous querying is
another feature distributed caches exist
both on the dotnet side and on the Java
side and all these features that I'm
talking about
other than asp.net specific caching
where the sessions exist also on the
Java side but viewstate is asp.net
specific and output cache there is I
think in education on the Java side but
these these issues are common between
dotnet and Java so runtime data sharing
through events is a third use case that
you guys need to keep in mind and use a
distributed cache for that even there
you may have the cache as the master
store or you may have cache as a
duplicate of the database so you may
often what happens is the database has
the same data but in a different form
cash may have it in a transient form
maybe it's an aggregation of some data
and that aggregation needs to be shared
so that it doesn't have to be
reconstructed every time so if you lost
that data you could reconstruct it from
the master
so unlike the asp.net the runtime data
sharing may or may not have the master
the store as far as the cache is
concerned but if it does then you have
the same issues as I've mentioned up
there any questions so far
ok let's let's quickly get this out of
the way in terms of how do you use a
distribute cache for sessions because
asp.net actually in anywhere there's a
framework where you can plug in makes
your life easy because you don't have to
do any programming so where there's no
framework then you have to make API
calls into the cache and as far as the
frameworks are concerned application
data caching entity framework does not
actually up until a ef6 there was no
framework for caching ef7
or ef-1 a of core has a caching
framework so that you you will be able
to plug in a distributed cache without
having to do any programming and
suddenly application data has been
cached but for as far as the asp.net
specific caching all three examples that
I gave they have frameworks frameworks
means you just use it you just plug it
in so what happens let's say you have
this is your picture you install a
server portion of the cache on the cache
servers you know most of the time you
have a separate caching tier then you
install a client portion which is
usually a client library or it might
even have a client side process it
depends on the cache so there's a client
portion of the cache and that client
portion usually would have the asp.net
provider for the sessions so let me let
me show you an exact
of how an asp.net provider would be used
I'm of course using n cash as the
example but the same applies to any
other cash including Redis so you would
basically go into your web dot config so
after you've installed the cash and
you've created the cache and the cache
itself is working you would go into the
application tier and modify your web
config you'll do basically two things
one you will add do an ad assembly off
your caches session state provider in
case of n cache that's just the line
that you copy and just put it in your
web lot config for other caches you it's
going to be something similar the second
thing you do is you basically create the
session State tag or and then in case of
n cache just copy this but in case what
other cache is copied from their example
and make sure your timeout is
appropriate in case of n cache make sure
you have a cache name specified so I'm
just going to let's say my demo cache
oops
whatever you named your cache so that's
like a connection string so that's all
you specify once you've specified this
you run the application again and all
your sessions are stored in the cache
very straightforward takes practically
very little time the only thing you have
to do after this is do some sanity
testing go through the common use cases
make sure your application still works
you know the reason you want to do
sanity testing is because if you had an
in proc storage model for sessions then
your session object might contain
objects inside which are not
serializable and and your application
will still work because the you know all
the sessions are kept within the
application within the worker process as
soon as you put in a distributed cache
it's an out of process store so out of
process means
serialization and he's any so your
session object is not going to serialize
if the data inside it is not
serializable so that's why you want to
do a sanity test make sure that you
haven't accidentally created a situation
where it's not sure as well but that's
about it there's no programming needed
you just make this change assuming that
you know you're comfortable with the
cash that you're using you've done some
testing of the cache itself you plug
this in and and the sessions are stored
in it okay let's come back to
application data caching which was the
main focus which is where you'll be
spending most of your time if you want
benefit out of distributed caching and
as I said if you don't have a framework
so if you had an EF core application you
don't need to make cache calls if the
cache is provide is has a provider for
EF core but EF six or earlier you
there's no the architecture doesn't
support it if you're using an hibernate
which is the the equivalent of EF which
is the dotnet version of hibernate it's
an or mapping engine for those who don't
know that has a model where you can plug
in a cache without any programming but
other than that you have to make calls
API calls these calls are n cache which
is very similar to the asp.net cache
object as you can see there's a you
connect with the cache assuming the
caches are already running as I showed
you here the cache will be running as if
it's a database it's it's a separate
process the cache is running you connect
with the cache and then this is a cache
handle that you preserve and you use
that to do cache that get you can do get
contains add add async insert remove add
means don't add it if the item already
exists inserts is add it if it doesn't
if it exists otherwise no add it if it
doesn't exist otherwise updated remove
of course is remove the async versions
of these methods say don't wait for the
cache
to be updated just come back and as soon
as you do the a thing that there would
be an over load which will take a call
back so if something goes wrong that
your callback will be called but the
async is very very useful and I'll
actually go through some use cases where
async is becomes really really useful
it's very simple as you can see just a
simple API cache that get add insert
removed of course there's more to it
than this but this is the gist of it so
and I'll actually show you some source
code examples on how to do all of those
things okay so let's come to application
data caching so any cache that is good
that must ensure in application data
caching that that cache is fresh that's
what we talked about right good there
the cache exists the data exists in two
places how does it do that the most
common way is explorations most people
know expressions expressions is you when
you're adding something to the cache
you tell it to please go ahead and
expire this let's say in five minutes
let me show you an example of
explorations so let's say here's a basic
it's a console application again this is
an N cache example but I mean the same
rules apply you reference the caching
assemblies
you spit use the caching namespaces you
connect with the cache you get the cache
handle you add the data and as you're
adding the data you specify let's say 1
minute so you're saying expire this 1
minute from now in case of n cache and I
think this is also the asp.net cache
object also works the same way so
there's a key there's the actual object
that you're trying to add there's the
exploration and you're saying don't do
any sliding expression and other stuff
so by just having that call you
you've specified you've told the cash
expire this item one minute from now why
do you want to expire this one minute
from now if you just think about it
because you think that if you kept it
longer than that in the cash somebody's
going to change that data in the
database and the cash won't know about
it and we'll have that really
undesirable situation of all data in the
cache so you're making a guess
really with expressions you're only
making a guess so there's also a sliding
expression which also has the same name
but the purpose is completely different
its purpose is essentially clean up so
for sessions you're saying when the user
logs out and nobody's touching that
sessions why keep it in the cache so to
remove it so there's a sliding
expression which says remove this item
after this long of inactivity so so that
you don't have to keep track of it of
course so absolute expression is for
application data sliding expression is
for transient data very very different
purposes it's a very important point to
keep in mind and and we've talked about
reference data is data that either does
not change it's read-only or it ain't
changes but very infrequently maybe
every hour maybe every day or every week
something this could be your pricing
this could be or something else
transactional data on the other hand is
your customers accounts activities that
change you know maybe every five 10 15
seconds 30 seconds and so you need to be
able to handle both and expressions you
specify different expression intervals
for different type of data that's why
you have control but explorations as I
said is making a guess so X although
it's good for some data it's it's not a
foolproof system no you might still have
situation where the data changes in the
database if that happens then you need
the cash to be smart enough
to monitor your database so whatever
data you're putting in the cache the
cache should be smart enough to monitor
that data in the database so if that
data changes the cache will be able to
take care of it or synchronize it itself
and there's a feature in sequel server
called Seco dependency or C which and
there's one in the ad or net framework
for Oracle coracle dependency this these
features essentially use database events
whichever application uses these
features let me show you example so
let's say oops not this one let's say
that you're trying to add something to
the cache okay so you're going to do
cache that ad is everybody able to see
the source code okay okay so you you
want to add this object this is some
product it has a key so but you want to
tell the cache so that if this if the
corresponding row in the product table
changes that this item should be removed
from the cache and the cache should be
able to handle that the cache can
actually use a sequel dependency where
it will use this sequel statement and
use a connection string to sequel server
and the cache becomes a client of your
database so think of this picture hold
on this picture here so your application
is running here it adds something to the
cache and it tells the cache please
monitor the database so the cache opens
a connection with the database and uses
the sequel dependency feature of AD or
net and then becomes a client of the
database and from that point onward
sequel server sees the cache
as a client and it notifies the clash
through database notifications if that
corresponding data set changes whatever
that sequel statement meant and that
means now you have a situation where
that exactly so sequel server is going
to push the notifications to the cache
it's an event-driven model and the cache
will immediately then take an action you
you have a chance of very short interval
but it usually it's fairly quick so but
it's an event-driven update sequel
server sends an event notification to
the cache the cache immediately does one
or two things it either removes that
item from the cache which is the default
behavior so that when it's removed the
next time your application wants that
data it won't find it in the cache it'll
go to the database and that's the the
common pattern of doing cache cache
programming is that you look for the
data in the cache if it's not there you
go to the database so by removing it
from the cache it's automatically
synchronized another option could be
that it can reload the new version
immediately and I'll come back to that
in a bit how it will do that so you know
again the cache has to become smart
enough that it knows these scenarios if
it doesn't you're forced to then not
cache transactional data or cash
transaction data where you can really
make a guess on explorations very
accurately otherwise you will have
situation where the data becomes stale
yes and I'll go into that at the end of
this page the cash dependency feature
which is also at asp.net cache a feature
that that some of the other caches have
including in cache sequel dependency let
me let me complete that by thought on
that see codependency is a great feature
but if you had 1 million objects in the
cache that needed sequel dependency for
every sequel dependency sequel server
creates a data structure on within the
database server to monitor that data set
could that data set does not have to be
a single row it can be a complete it
could be multiple rows it could be a
join of multiple tables I think it can
be joined but let's say even if it's not
a join of multiple tables it's it can
definitely be multiple roles in the same
table and if it's equal server had to
create one million of those you can
imagine you know since you're thinking
since we're talking scalability you have
to think in large numbers you can't just
think about 1000 so sequel dependency is
great maybe for thousands or tens of
thousands of items for hundreds of
thousands or millions of items it's not
great another option could be which some
of the caches support it is that the the
cache could actually pull the database
now polling is not as real-time as
events but polling is a lot more
efficient because in one poll you could
just say give me all the rows that have
give me all the keys where the data has
changed say in one call you get back
thousands of rows and then you could
take action on those so it's like a bulk
operation but even that has limitations
because when you're talking millions of
dependencies that has limitations the
third option is to use a CLR stored
procedure so if the cache that you're
using gives you a client library that's
compatible with CLR environment in in
the stored procedure either sequel
server or Oracle Oracle on Windows of
course
then you can make the call from a CLR
procedure so the way I see it our
procedure works is that you don't create
a sequel dependency anymore you add data
into the cache and then when and then
you modify your database triggers that
when that role changes the database
trigger calls the CLR procedure and the
CLR procedure now knows that this row is
changed and and it knows what the
corresponding object and the cache is or
ought to be so it'll either go and add
or update or remove that object from the
cache so it actually is the CLR
procedure becomes a client so it's like
a reverse thing here
the database is now becoming a client of
the cache through see our procedure the
transactions yes so the CLR procedure is
going to be called within a database
transaction and this is where those
async methods will come in really handy
because if you don't have the async
methods and you're calling multiple
servers to be updated the database
transactions will start to timeout
pretty soon because they're not designed
to wait for that long but if you do an
async call then the cache can be updated
and the database transaction will be
completed again keep in mind that the
cache updates don't fail in the same
fashion as a relational database why
because a relational database can fail
and update based on referential
integrity or other data integrity
violations cache does not check any of
those caches every object is independent
of other objects so the only time a
cache will fail updates is when some
system failure happens you know if
something really goes wrong which is not
I mean which is different than the
normal database transactions would be so
an async method would be called from a
CLR ffice procedure to go into this so
those are three ways where you can
ensure that the cache
stay synchronized so you need to take
into account this really really
important aspect when you're starting to
cache data unless your data is just
read-only then it doesn't matter but if
your data is changes and it's it's a
sensitive data you know you want to make
sure that cache is fresh and the same
the same rule applies the cache should
be able to synchronize with non
relational sources if your data is in
mainframe or maybe you're making some
web method calls you should be able to
synchronize against that as well so the
cache should provide other hooks so in
case of n cache there's a thing called
custom fantasies for other Java caches
they have other names so the cache
should provide some hooks where your
code can be called because only you know
where the data source is the cache does
not know so synchronize the cache with
the database and synchronize the cache
with the non-relational source so you
need to be able to do all of those to
confidently use all types of data in a
cache and finally I'll come to the
question that you had is that there's an
added complexity with relational
databases is that different types of
data has relationships and because
unlike a no sequel database where you a
grenade at a-- so let me think of a
Northwind database and and an order if
you had a no sequel database the entire
order would be kept in one collection
right you have the order and the order
items all in one collection well because
the order items don't really exist
independently they're dependent on the
order but in a relational database you
would have two different tables one
would be an order table one would be an
order item table so you have
dependencies so that's just one example
there are also other examples so a
relational database is known for
relationships so when data comes to the
cache you have different types of data
and if one data changes in the cache the
cache doesn't know if the other data is
valid anymore
and you so in case of an order is an
example if you had cashed the order
object and the order item our object
separately and you remove the order from
the cache maybe you've deleted that
order although and you usually don't
delete orders but I'm just saying as a
hypothetical example if that is the case
then the order item should not be kept
in the cache if you do there's a data
integrity problem so that's where the
dependency feature comes in it's an
asp.net cache object feature which is an
cache also implements it but a
dependency essentially allows you to
tell the cache
this item depends on so you'll say order
item depends on order object if the
order object is ever removed or updated
from the cache please remove the order
item automatically so the application
does not have to do any bookkeeping just
like you are not used to doing any
relational database bookkeeping you
don't maintain journals or any you know
data integrity details right you assume
that your data store will your database
will take care of it the same rule
applies to your cache you should not
have to keep track of all of those data
integrity things so a cache dependency
feature is also a very important feature
allows you to keep track of these types
of data integrity violations any
questions okay
so we talked about so I mean so we've
kept the cash fresh now okay so now
you're really starting to use the cash
you know it's become an important part
of your application strategy application
architecture so now how can we make the
cash more friendly easier to use to
simplify your work one of the features
is read through and write through read
through is nothing but your code let me
just show you example here so read
through is your code that's how you
implement a read through provider
example and again the same concept
exists in other caches too I'm just
using n cache as an example at least on
the on on the Java side so you implement
a read through interface it has three
methods in case of n cache there's an
init method which is called when the
cache is started so it can connect to
your data sources you know it usually
contains your connection strings and
other things there's a dispose method
which is called when the cache is being
stopped so you can disconnect the data
sources and there's a load from source
method where they go there so there's an
overload of that for bulk fetch but
let's say there's a load from source
method which takes a key and it gives
out a cache item which is cache item is
the data structure which contains the
data plus other metadata like
expressions and other things so your
code now goes to your database and gets
the data so this code that I just showed
you will run on the caching tier that
means that your application has less and
less of the database code so you're
actually using a cache as an
encapsulation layer so it simplifies
your application that's one benefit the
second benefit
is that you can use read-through for
example in other cases for example as
you know we talked about explorations
right that you're doing absolute
exploration you're saying expire this
five minutes from now what does that
mean expire means what it means remove
that item from the cache right but what
if you just wanted to reload a new
version of it it was some pricing that
that that was changing so if you didn't
have the reload option the item would be
removed and oh you know that's it's a
really heavy traffic ecommerce
application so all of the clients will
immediately hit the database the first
one that finds it will go and update the
cache but while that is being done
thousands of requests have made it to
the database unnecessarily now think of
that you've got hundreds of thousands of
these items that keep expiring all the
time so you're sending a lot of
unnecessary traffic to the database just
because you don't have a reload
capability but if you could have a
reload capability what would happen the
expiration would not remove the item
from the cache it would actually call
the read-through and say go and get me a
new copy of this so read through will
get a new version of that because read
through knows you know based on the key
it knows where to go and how to get that
data it'll reconstruct that object that
entire thing give it to the cache and
the cache will now go and update that
item instead of removing it it just
updates it that means that the item is
always in the cache it just gets updated
at expiration intervals the same same
rule applies when you combine
read-through with database
synchronization when the data changes in
the database why remove it from the
cache why not just reload a new copy you
know again your application becomes much
simpler so read-through has the benefit
of first simplifying your code because
more and more of your database code goes
to the caching here that way if you have
multiple applications sharing a common
caching infrastructure all of them can
also
the code so they don't have to maintain
that code and second benefit as I said
is the art of the auto reload in case of
expressions and database synchronization
the second is the right through which is
the right equivalent of read through it
has the first benefit is the same which
is the encapsulation it simplifies let
me just show you that right through so
this is read through this is the right
the same way it's got an init method
it's got a dispose method it's got a
right to source now right to source also
tells you what the operation is the
operation could be add update or delete
right I mean the right could be one of
those three so based on that you then go
into your database source and you take
the appropriate action and then you can
do the same with that there was another
overload of this which was a bulk I'm so
you could actually update multiple items
at the same time right here so the first
benefit of the right through was the
same as read through but the second
benefit is actually different the second
benefit is and this is actually a very
important benefit that you can use this
thing called right behind and right
behind the application updates the cache
and does not wait for the cache to
update the database why because database
updates are slow I mean cache is at
least 10 times faster if not more than a
database operation so why not just go
and update the cache in a right behind
manner and tell the cache please go and
update the database for me it's the same
right through handler that gets called
but now it might be called in a bulk you
know because it's going to queue up the
stuff and there are other you know
variations that you can use when you say
go and do bulk update you can do retry
as if the if the operation fails but now
your application does not have to wait
for the day
of course when you do the right behind
there's a callback that you can register
so if something goes wrong you will be
notified you know so that if the
operation fails and and there's no way
to actually perform that update then you
will be notified so that you don't have
that situation where you think the
update was done whereas it wasn't but
the right behind means that you no
longer have to wait for the database
updates one more situation where your
application becomes much much faster of
course data that is very very sensitive
you don't want to do the right behind
you want to do the right through but a
lot of data you can you have enough
tolerance that you can do the right
behind and really speed up the
operations so read through right through
is very very powerful feature any
questions I've been talking nonstop
okay I can talk about n cash every cash
has their own strategies by the way this
feature reads through breath so on
the.net side only n cash has on the Java
side you have other players that have it
in case of n cash depending on what cash
in topology you're using they're
different cash in topologies but there's
let's say if you were using this
topology called partition replication or
partition replica here where you can
have multiple partitions every partition
is backed up on to a different server
what happens is depending on what data
you're updating whichever partition that
data is supposed to exist in the read
through or the right thread runs on that
server so that way it can do a
distribution and load balancing so that
one server does not become a bottleneck
however if you have a different apology
let's say there's another topology of n
cache I don't have that slide here
because I you know I this talk was not a
wine cache but there's another topology
and an cache called replicated where
every server has an entire copy of the
cache so every server has the same data
so in that case all the read-throughs on
the right through go to the primary
coordinator of the time if that server
fails then goes to the next one and the
next one but in case of partitioned
topology it's much more scalable if you
can distribute the read-throughs and the
right through to all the servers in the
cluster right but even for the reads
again keep in mind the read-throughs
reads are being done when the cache does
not have that data in some cases you can
also force the read through and say even
though even if cache has the data please
call the read through because for
whatever reason you just don't want to
take a chance on the read through in
that case or every read will call the
read through but in majority of the
cases read through is going to be called
only when the cache does not have that
so let's say you do a cache that get and
the cache does not have that data
so then cache will call the read through
so the percentage of the time that you
go the database is that 20% as a venture
or less so did that answer your question
any other questions on the read through
right through okay so let's say you're
convinced about cache being a secular
scalability solution you you're
convinced about
these use cases you know how to keep the
cache fresh you've benefiting from the
reason right through that means you're
putting a lot of data in the cache now
right so the cache can no longer be just
a key value pair because if it were just
to keep even though that's how the cache
is underneath it's a key value pair but
if it remained that if that remain as
the only way to access the cache you
would have a your applications will
become much more difficult so the cache
has to start behaving more and more like
a database so the one of the first
things that a database is good for is
ability to query to search to find data
easily instead of finding it only on
keys you want to be able to find it on
other attributes so a good
distributed cache will provide you with
some sort of acquiring language you know
in case of dotnet it's either SQL or
link querying so you should be able to
do something like select customers where
- Murdoch city is London and get all the
customer objects from the cache where
that attribute condition is true so the
more you're able to do these types of
searches the more you're going to
benefit from a cache as a database the
less you're able to do these the more
painful the application will become
because you'll always have to go to the
database for these queries and only for
individual object fetches that you'll go
to the cache which defeats the purpose
in many cases so here let me show an
example of how you would do sequel again
you would connect to the cache and do
all the tables so but whatever data you
have in the cache then you issue a query
in disk in case of n cash as I said it's
you just specify the object name or the
object type and you specify criteria and
the criteria that cannot include joins
but it can include everything else you
can do in operator you can do like you
can you know like wild card and you just
do an execute reader and just like
sequel server you're searching the cache
and with this type of a capability now
you can load a lot of data in the cache
all those look-up tables can just be in
the cache why go to the database at all
but even though you're loading all that
data in the cache in the cache you are
able to search it in the same fashion as
you would a database so the simplicity
of doing SQL type of querying makes your
life a lot easier
same thing goes if you if you like link
you can and if the cache that you're
using has a link provider then you can
essentially get your I queryable let's
sit here and then you can issue a link
query
the same way as you as you would now
behind the scenes that of course is
being converted into sequel searching
and then you know a record set is being
returned so whatever you're comfortable
with whether you want to do linked or
whether you want to just do SQL
searching the bottom line is you should
be able to do searching in the cache now
one thing to keep in mind that when you
do a sequel type of searching the entire
data set that you're searching on has to
exist in the cache so if you're
searching for customers where the city
is New York or London all the customers
have to be in the cache why because if
some of them are in the cache somewhere
in the database you don't know which
ones you're going to get which ones
you're not so that that's an important
thing to keep in mind
so sequel searching is good when you can
load the entire data set entire data
into the cache or that type of data
which is again a lot of use cases we've
got four minutes left okay similarly
because you cannot do joins there are
other things that you can do you can do
grouping so there's a group sub group
tags name tags features that allow you
to fetch groups of objects back which
may you know so and you should be able
to include this in the sequel criteria
so you should be able to do select
customers where customer Dodge City is
London and customer dot group is
important customers and and and then you
can do tags also so for example groups
and tags our fabric had the tagging
feature by the way but the grouping
featured didn't so you could do
something like you can specify here as
you can see here you can do a key value
of key value group and subgroup so this
is so in this case value is also a
which usually is an object and so this
is a group and this is subgroup and then
you can later on say give me everything
that belongs to this group electronics
and then you can search on it the same
way you can do tags so name tags are
good when you for example want to index
text data when you do sequel searching
the searching is only possible if you do
an indexing without indexing how are you
going to find all those customer where
city equals London you know because you
don't want to deserialize every object
in the cache spanning that's a five
cache servers millions of objects
potentially because you don't even know
what the object type is yet unless you
so the time to index is when you're
adding or updating so on the client and
you extract that data and you put send
that as metadata with with the actual
serialize the object and keep those
indexes on the server end and that's how
you can search so the same way you can
do this these also become indices so
because these indices you can actually
do sequel you can include these you can
say this dot group is this this star tag
is this or name tag is this name tag is
essentially used when you have text
which does not have attributes so you
can give it a tribute that you want
there's one feature that I want to cover
which is very important which is called
client cache so you know when you had
standalone caching you know let's say if
you're using asp.net cache object it's
all within your worker process so you're
used to super speed why because that is
that object is being kept in an object
form within your process on your own
heap nothing beats that performance
right so the first thing that a lot of
people ask us is well you know I I
plugged in and cache or let's say
whatever cache and my performance
actually went down I was used to all
those super fast
fetching of objects and now I'm making
those calls across the network well
there's no way around the fact that you
have to store these objects across the
process or in another process but
there's a feature called client cache
which again on the.net site and cache
has and on the Java side you have other
caches that have it some people call it
near cache on the Java side that's what
they do and the client cache essentially
gives you that benefit of a local in
proc cache but you don't want to have
that as an isolated catch that cache is
kept synchronized so whatever is kept so
based on your usage pattern or whatever
you're fetching that copy is kept in the
client cache as in an object form so
it's super fast so you get that same
performance but now that object is being
kept synchronized so this is a very
important feature and I've crossed my
time limit any questions on this I'm
gonna stop the presentation any
questions at this time I would strongly
encourage you I was gonna go into the
last piece which was the the caching
options for dotnet they're basically two
optional dotnet side one is n cache one
is Redis look them both up on n cache
side that the company I represent I hope
I didn't do a marketing job out in cash
here it was I hope it was a objective
technical conversation but you can come
to our website
good download page and you can download
either the Enterprise Edition or the
open source edition the open source is
also available on github and cache is
open source so you know it's the same so
do take a look at both of these and cash
and Redis there's also a lot of detailed
comparison orphan cash would read us on
our website that will make your life
easy but most importantly please do
consider using a distributed cache in
your infrastructure
make sure your applications are scalable
any questions thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>