<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Avoiding Microservice Megadisasters - Jimmy Bogard | Coder Coacher - Coaching Coders</title><meta content="Avoiding Microservice Megadisasters - Jimmy Bogard - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Avoiding Microservice Megadisasters - Jimmy Bogard</b></h2><h5 class="post__date">2017-04-06</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/gfh-VCTwMw8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everyone thanks for coming this
afternoon my name is Jimmy and today I
want to talk a little bit about avoiding
microservice mega-disasters is everyone
ready for story time I live afternoon
story time so this talk is mainly a
story of a company I worked with for
about a year and a half or so to help
turn around their ship from the
impending iceberg that was their
micro-service mega-disaster so in order
for me to tell the story properly we
have to really go back in time and talk
about how the company started how their
IT infrastructure grew over time now to
protect the names of the innocent I've
changed the name of the company so we'll
be talking about Bell computers not any
other computer company you may be
associated with it's totally unrelated
so what we have here is a picture of
their IT system in the mid 90s zoomin to
recognize what this is it's a mainframe
it's an HP tandem mainframe and I guess
they actually still make these things
you need until go buy them and get
support form and things like that
so Dell computers as I started to grow
over time they needed to build a system
to help manage all of the orders all of
their really their entire company and so
they went with the most common solution
at the time in the 80s and 90s which was
a gigantic mainframe and this main frame
held every single piece of information
about the company everything that could
possibly be transacted through the
company was held inside of this one
single mainframe so we had sales catalog
information about the different products
they had orders information their serum
like everything to do with anything with
the company was in this one system and
that was okay because they didn't have
any other system to process our place in
order except for mail-order catalogs or
you could call them up and place an
order over the phone
now of course over time the system got
larger and larger and more junk was put
in there and of course COBOL is not the
most expressive language in the world
so this eventually became the what's
known as the big ball of mud big ball of
who or the monolith so around the around
the year 2000 they said society you know
what a lot of other companies have
websites that actually do stuff maybe
are should be a little bit more than
just call us to play short
and so they decided to build our first
actual dot-com e-commerce website now
the design of this initially was I
thought pretty good
the original Belkin design consisted of
a number of top-level top-level websites
or subdomains of an individual of the
entire application so you had catalog
delcom you had a countable calm yet
order zobelle calm and searchable calm
all these distinct asp.net 1.0 web forms
applications built each with their own
individual database and at some point
they all to communicate with a back-end
system all fulfillment and all the
orders actually getting processed still
had to go inside this single mainframe
so all the supply chain all that other
junk was still going to be inside that
mainframe but the front-end website
these had individual applications and
individual databases now this is how
they design the system the reality was
more like this where everything called
every every everything else through API
calls or so calls or just embedding
someone else's DLL and your and your
project or well it was very hopping
happened very often with these kinds of
source control systems I would just grab
other people's code and just shove it
inside my project and then complain when
it broke later on sequel 2005 introduced
a concept of links servers so I didn't
show here but it's also arrows between
each of these databases as well because
what's wrong with joining tables against
different physical databases if you can
do it if you weren't allowed to we
weren't supposed to do it then why did
they give you the feature it doesn't
make any sense so while they had some
separation now between the different
logical areas of the system this again
turned into now distributed ball of mud
where I had different little balls of
mud and each my in different
applications and of course the big one
was still actually back over there now
the funny thing was this this mainframe
was not built by Bell computers was
built by competitor so it was always fun
to see the competitors consultants come
in when they ever had to maintain this
mainframe because like that's kind of
embarrassing if your competitor has to
support the system that your entire
company is built on that's pretty
ridiculous so looking at this
application they decided of course let's
throw it all away and let's do the
rewrite
now this existing application was in
production for about 15 years which is a
very long time for an asp.net webforms
application it accepted orders worldwide
so you can place an order in one country
and have a chiptune other things like
that generated billions of dollars of
year in revenue through this one
application very significant portion of
the company's revenue came through their
their comm website millions of orders a
day and its peak black friday typically
but they found that there was really no
way for what this exists existing
application designed that because
everything was talking to each other and
everything referenced each other it was
really really hard to make any sort of
meaningful change in this application
and they found there was one particular
business request that they just could
not fulfill that was going to force them
to really throw away the entire
application and start something new and
it's this idea that although it
supported the ability to accept orders
and nationally you cannot place an order
in one country bill it from a second
country and have it shipped to a third
country which is pretty common for
global companies but you could not do to
the existing website and so they were
forcing you to go through the phone to
do so and so if you're a big big
corporation that needs to order
computers over the phone you probably
try to find a competitor as well so this
was about the time you started to see
more and more people talk about
service-oriented architecture and micro
service micro service architectures as
well so naturally they did the smart
thing and just read blogs of other
people and just try to blindly do what
those other people did one of the
pictures they really liked was this
concept of a Netflix oriented
architecture where I have very small
micro services that can connect to each
other via api's standards-based approach
and they saw that's great let's go ahead
and build this architecture they want to
have some core principles around
building this architecture first of all
they used to have a really big problem
with data being shared between multiple
different places so they had a core
tenant of no data duplication I cannot
go to I can ship data to somewhere else
and if you need some information you
have to come to me to get it because I
am the source of truth we're going to
see this one come back in a little bit
about how that really screwed things up
for them they wanted to follow those
service-oriented architecture principles
of isolation and autonomy that
individual services
we're I saluted from each other I didn't
have people sharing code back and forth
things like things like that they want
to use web api is for absolutely
everything so if you needed to get data
or needed to affect change in another
system you must go through a Web API and
the last big one was to get off that
mainframe with a project called Bell on
Bell as opposed to bail on competitor
hardware so 18 months they built a
system around these sort of core
principles and had a pre-production go
live where all the developers came in
over the weekend and they turn on all
the servers connected everything up and
flip the switch so after 18 months
hundreds of developers on Bell top
hardware they flip the switch went to
the website and nothing showed up which
was rather embarrassing for quite a lot
of people so I said ok that's odd we
expected to have some response because
we've been running this application on
our laptops for so long
why is it failing now so they did a
simple sensible thing and threw money at
the problem so ok let's go ahead and put
everything on one single gigabit fiber
backplane Ethernet rack everything super
connected to each other very low latency
and let's operate all the service - you
know you've done this on their website
right where you go to the servers and
try to make the most expensive machine
you can or is that just me so they did
that so let's just go
you know let's go make the most
expensive machines we can with the
insane amount of RAM connect all these
things up reinstall everything get it
all configured and still nothing happens
so they had a suspicion that maybe there
are some timeouts or happening so I
decided to go to all of the web
configuration all the API configuration
and updates all the time out settings to
a maximum infinity timeout so we're just
going to sit and wait for something to
happen on this website and they waited
and they waited and they waited and they
waited for nine and a half minutes until
the website finally loaded this is just
a simple page showing a list of products
for one of the catalogs around this time
they also said maybe we did something
wrong so that's when that's when we got
involved to try to help them try to fix
that situation now the first thing we
had was 18 months to ship anything is my
not micro if you have to take a
year-and-a-half to ship an application
then it's probably not a micro service
or micro anything it's probably
something much larger so we had a
post-mortem after this also known as a
regret respective also known as a blame
storming session to figure out exactly
what went wrong here and we had a few
cute few clues one was they were
complete cetera they were completely
saturating their network traffic with
all the API calls going on and by the
way with a normal application like a
normal monolith if you will if something
goes wrong there's an exception or crash
it's really easy to figure out what went
wrong because you have a single stack
trace that tells you everything that's
executing at once with this kind of
architecture where everything is an API
call there's no one stack trace I
instead have to go through tools like
Wireshark or other network monitoring
tools to figure out okay for this one
request what in the world happened with
this one single request so we took just
that one simple page and and in about
two weeks time we piece together the
puzzle of exactly all the different
calls that were being made and we found
that they sort of misinterpreted this
picture slightly so in this picture we
had the idea of that there's one single
external request that hits a service and
then I make a number of internal service
request calls and they get and they get
back to me
now what's not supposed to happen is any
of those other service calls can't make
additional hops that is they have to be
able to service that request all by
themselves and they can't go anywhere
else to get that information well that's
not what they did this picture looked
like some sort of cascading insane graph
of calls because every single one would
call additional services and those
services would call additional services
those services would call additional
services and almost to infinity well not
something about a thousand different
Network calls for that one single
request so this picture for them was
just basically a filled in green circle
because everything was calling each
other we also found cases where services
would call each other as well service a
would called service B service B would
call service C and then service C would
also call service a and now I have a
distributed deadlock it was really
really fun so in this picture they had
where he had a single request calling
thousands of API calls
and we look to see if they had any
resiliency built-in things like the
service brake or the circuit breaker
pattern now of course not if any one of
those API calls failed the entire quest
failed so we're doing some math for them
say you have each API call has an SLA of
150 milliseconds now because they were
using a windows communication foundation
WCF that pretty much already eating any
one request already hit that SLA because
there's no WCF call that it can take
less than 150 milliseconds it turns out
and they wanted to have a Hyundai
percent uptime which is only three nine
so it's really not that great but they
thought they could achieve that at least
so in this one request that made let's
see two hundred different requests the
absolute best case scenario they can
have was 30 seconds response time to get
that page to be shown so immediately
that's just absolutely impossible but we
also look at the 99.9% uptime and do
some probability math around this if you
look at 99.9 percent uptime times 200
calls through my probabilities class
that I took in college we find that that
site has a zero percent chance of ever
being up so this architecture was doomed
from the start the regional architect
was naturally fired haha just kidding he
left before this went to production to
spread his mess and we went and asked
the developers like what how could you
possibly make it 18 months without ever
seeing this one problem and said look
are we're all hearing 450 milliseconds
SLA and they had the charge to prove it
with from that from that from that one
single request and I founded that way
they were calculating their SLA was only
calculating the code that they ran but
if their service called another service
they wouldn't caught that time in terms
of their SLA so of course everything
running in there one process was going
to be under 150 milliseconds but having
to call to someone else was going to add
time that they just didn't calculate so
the first lesson was you there have to
own your SLA or your SLA is going to own
you and of course they were completely
owned by their SLA the next thing we
found
they had understood the whole concept of
the fallacies that distributed computing
but they missed the first part there the
fallacies they actually thought that all
these were just things are okay to
pretend like they're they're true so
Network being reliable they just assumed
that was true latency being 0 we assume
that's true as well
bandwidth it's infinite absolutely it's
true because again everything worked on
their machine why did it work on their
machine because when they were doing
local development they never ever hooked
up external services they staked out all
those external servers calls mock them
out of whatever you want to do so that
they've never had any network hops when
they're developing locally they we just
have some local cache so of course it
worked great locally because I never
made any one Network hops but as soon as
you try to build a system that has to
make those network hops it would be
immediately apparent
so for 18 months they never actually
test it locally to even see like one of
us be like if I have to actually hit
those other services nope work on that
machine let's go ahead and ship it now
this picture they they had here even
looking at the service boundaries they
drew we're all incorrect and we'll come
back a little bit later about how they
got into this incorrect service
boundaries but it can kind of see why if
you look at some of the literature out
there trying to give you some advice
about how to draw the service boundaries
some of them are terribly terribly wrong
naturally the one from Microsoft is the
one that's terribly terribly wrong this
is the picture they had of their first
application and this is from a this is
from a blog on Microsoft about how to
build micro services so pretend like you
have a normal single interior
application that has the web your
business logic box and your data
cylinder over there and a normal request
it just goes up and down I can have one
server for the web side maybe the one
server has my web and business logic and
then another server has my database now
if I get more traffic then this picture
needs to change a little bit I probably
have to have a load balancer here to be
able to go to different front-end web
servers and then there's probably some
sort of cache layer between that and my
business logic and there's probably some
sort of cache layer between my business
logic and the database in fact this is a
picture when I used to work at that
company this is a picture we had for our
application
everything was load-balanced we've been
doing Bluegreen deployments in the
mid-2000s been able to take things out
of the load balancer upgrade them and
put them back in switching the other
ones out and this all worked absolutely
great with this the only thing we didn't
get right was we were just directly
using other people's code in our code
base and directly calling their database
from our database but otherwise this
picture worked out for us well
now the blog post says from here in
order to build micro-services you need
to break each one of these tiers down
into individual services this is where
they got their pieces wrong on the belle
side they broke all of their services
into different layers and then in each
one of those layers they built out
different boxes for each individual
service so on the website they had
different micro services for just
rendering content they micro services
for authentication on the business logic
side they had orders and account
information things like that and then of
course on the data side they had
completely different micro services for
all the different data pieces they had
so that the business logic was stateless
the web was stateless and then here is
all my data down there now the reason
why this picture was completely wrong
for them was this does not actually map
to any sort of business units or any
sort of business need on the other side
of IT if we showed this picture to ITR
to the actual business side they would
like I don't know what usage analytics
means there's no there's no
corresponding business you know over
here they had a they had a number of
services that were just made up just to
further individuals careers because you
get more money if you manage more people
so let's invent a service so I can have
people to manage and then that's how I
can further my career their true story
so micro Services was not just taking
their inter system and then putting
docker on it that isn't exactly the
opposite of what they needed to do now
looking at a traditional into your
application with my UI layer my business
logic layer my data access layer in the
database or the much better DDD style
interior where I have domain magics and
a repository instead I try to look at
the different areas of change and
different areas of responsibility so in
a normal into your application I have
different areas of change and these are
these are
typically categorize with these
different big vertical slices of the
application so in the original comm
website we had the catalog side we had
the configuration side so when I clicked
on a individual computer and said okay
go ahead and configure this carton
checkout which is that was the team I
was actually on while I worked there and
the key thing we have to remind
ourselves here is that for each of these
different vertical slices in order for
them to maintain their autonomy this
this boundary has to extend not only
down to all the different business logic
layers but also all the way down to the
database so we had to do a little bit of
a reset said okay clearly you try to
build a service-oriented micro-service
architecture but you got something
completely off so first of all let's
just reset what it means to be a service
and there's three sources I typically
typically go to for the training to
define a service the first is the
original service oriented architecture
definition of a service in that
definition we have a service is software
that is owned and built and run by our
organization it's responsible for
holding processing and distributing
particular kinds of information within
the scope of a system can be built
deployed and run independently meaning
defined operational objectives the
independently there being one of the
keywords it communicates with other
consumers presenting information using
conventions or contract assurances and
then finally or not finally protect
yourself against unwanted access and
it's information gets lost and finally
handles failure conditions so that
failure conditions cannot lead to
information corruption if you can kind
of sum all these from pieces up in one
word its autonomy these services can be
run independently of each other they are
able to meet certain constraints and
they define the contracts in which
people can get information in and out of
course nowhere here actually says a
specific technology and that's kind of
the point now on the micro service side
from the micro services book the
definition is a little bit simpler it's
a micro service is small and focused on
doing one thing well and it's autonomous
and can we have that autonomous word
coming back up and they'd like to use
the town planning metaphor this is from
the micro services book
by sam newman and then the final the
final definition like to get to sort of
round out what the service means is from
the domain during design book now the
DVD book is really long and there's a
lot of really useful information but
it's actually towards the end of the
book that no one really gets to so if
you're going to read the DD b book start
at the part that talks about bounding
context and kind of ignore the rest
because all that stuff about entities
and aggregates and stuff like that is
really just not that important the bound
of context piece are the most important
pieces the mountain context idea and
domain-driven design says I have a
particular model and that model may not
make sense in different contexts so a
bounded context says this is the this is
the boundary in which this particular
model can be applied inside that context
we have a logical unified model and you
can kind of see this in your in the
business domain as well if you go to
your business and ask any one person
what's a customer if you talk to the
orders people that have one definition
of a customer if you talk to the sales
people they'll have another definition
and if you talk to fulfillment they'll
have yet another definition what a
customer is so bounded contest says
right we can't all agree on what a
customer means so let's define
boundaries in which we can reason about
what that term means and then have
translation points between those
different pieces when I say oh you mean
we're talking about a customer oh in
terms of an order that means this a
customer in terms of sales okay that
means that and of course it encapsulates
any sort of internal operations so I'm
not leaking those details to the outside
world and we also define explicit
contracts for external communication so
again we have the idea of contracts that
comes back in from SOA and they
typically use the cell metaphor where a
cell has a kind of a completely
encapsulated asset of operations and has
specific receptors in order to be able
to communicate to the outside world so
we came in and said right we cannot fix
this entire mess although you could pay
us to do so they didn't have the money
for that but we'll fix just one single
service to make it sane
from here now we're talking about that
sort of how we fixed at least that one
service to make it actually respond to
requests in a little less than nine and
a half minutes hopefully so this is our
search story first let's look at the
micro service Bell comm search approach
this was their design now any external
requests coming into the search site
would have to go out to a number of
different internal services to be able
to pull those pieces together and
actually present something to the
end-user I only drew four boxes in
reality they're about twelve and there's
four hours here but again in reality
there were about 200 arrows of things
calling everywhere going all over the
place so in this in this approach they'd
arrest API
times about a thousand or so different
API calls and the interesting thing
apart about here is that the search site
itself really didn't do anything they
just pass through all the requests to
all these external places so if I needed
to search something I would go on call
the catalog site and say okay right
someone's looking for Windows 10 laptops
and naturally the catalog site didn't
have a search capability so it said
right well just select the top ten where
name like percent thing and then those
are the things we're going to return so
around this time if you want to go
search the V search Windows 10 laptop on
their search site the first things will
come up we're t-shirts and mugs because
those products queues were
alphabetically the first thing in the
list not extremely helpful in order to
if someone's actually trying to buy some
laptops here so we went back to the
original picture of their architecture
and said right so we have this catalog
site we've got this config site in this
cart check out what you actually need is
this fourth service here for Search
Search is his own individual thing so
but we can't have a search service
because one of our key tenants was we
cannot duplicate data so how can I build
a search service on top of this concept
of no duplication of data well you can't
because none of those other services
have any idea how search is supposed to
work so you have to build a specific
search service to be able to service
those requests appropriately so we went
back to the drawing board in terms of
their data ownership and said right
so you've got this search service that
needs to have data in a very specific
format but it doesn't own the data but
it needs to it actually needs to own the
shape of the data because the shape of
the data is very important about how I
need to be able to search it search also
needs to own the SLA of the response not
just in terms of how quickly responses
get returns but also the relevance of
the different pieces that are being
shown so it needs to own the order in
which things are being shown none of the
other services know or care about all
that relevant information so it really
needs to be searched to be able to do so
however it doesn't own any of the data
that actually exists in those other
systems so from this we realize you know
we can't we can't have a system in which
we don't duplicate data and in fact if
you look at the real world the real
world duplicates data constantly if you
look at you're just looking at a website
that is duplicating some data in the
server and showing it in the browser via
HTML so immediately I have stale
duplicated data yet we're able to
function just fine as a as a society
knowing that I have information showing
on my screen that maybe a little bit old
or duplicated and that's fine so we went
back and said ok let's go back to some
of the kind of core books that around
here and start to build a solution
that's building off of some of these
concepts these are my three favorite
books about these different subjects
first enterprise integration patterns
which is kind of a lousy name for
messaging patterns but it's really about
messaging the same new man building
microservices book so we could say like
okay don't believe us but here's a book
about it and then finally a little bit
older book that's still relevant in
micro services which is a SOA patterns
by Arden Rotom Goya's I don't know how
to pronounce that it's good enough and
what we needed to do was perform service
dependency inversion and I put that in
there just a troll Rob that's just for
you
so in service dependency inversion in
our original picture we have one service
depending on a lot of other ones and
it's depending on what a lot of those
other ones not because it's wrong depend
on them that's okay that my service can
depend on these other ones
it is wrong though that my uptime is
completely dependent on the uptime of
all those other services so we could
take this picture and say all right
let's build the resilience again so if I
call catalog and catalog slow or if I
call catalog and it's slow three times
in a row let's implement a circuit
breaker pattern then we can have some
sort of other cache locally so we could
do that we could put caches and circuit
breakers in front of all these different
pieces but that doesn't mean they can
still service an appropriate search
response because they still have to
worry about the relevancy of the
information so we decided we wanted to
flip these individual arrows around so
instead of a single request from the
outside world calling a multiple to
myriad of internal sources we flipped
all those arrows so that each of those
other boxes would be pushing information
somehow into our search Bell comm
website so that when an external request
came in I only ever had to go to a local
database that was specifically built for
the purpose of search and no external
service requests needed to happen the
biggest thing that's did for us will be
they removed any sort of temporal
coupling that is a lot to worry about
any sort of timing on any of these other
external systems that they can give me
the information ahead of time I only
have to worry about my local database
and also worry about any other person's
data
uptime or latency or anything like that
so we just needed to break all those
arrows and not piss anyone off that was
the other kind of thing we wanted to
make sure we didn't do there was a lot
of people's careers on the line and this
kind of architecture so I said okay well
you can still do whatever you're doing
but we're going to try to make it a
better here by not having a nine and a
half minute latency and if it works then
you know maybe other people can do it as
well so we went to each service one by
one and said ok how can we break that
arrow and reverse it to the other
direction and the enterprise integration
patterns book really told us the right
way to do so our first service we were
looking at was a catalog service now the
catalog service is interesting because
if you go to shop online for some of
these laptops you know there's like a
just insane number of configuration
options available to you you can have
different processors different grams
four hard drives different colors any
virus or not all this all does in same
number of options which is all done by a
couple different services in the catalog
side though catalog was all about taking
those complex configuration and saying
right we need to print a catalog for
someone so why don't we have some
standard configurations we can show
people so they can say yes this laptop
is $7.99 and that laptop has some
standard configuration options you can
change but there's always some sort of
default configuration so though we had a
lot of complex configuration behind the
scenes there were standard
configurations that you could just go
and click purchase and the standard
configurations are what gets showed up
on any sort of catalog browse page I
want to go look at ok what are all the
laptops for education or for home office
there's a certain set of standard ones
they typically show there there's a
known quantity of these different
standard configurations and ours and our
investigations we found there was
roughly about a thousand or so these
well-known ones if I tried to spider out
and cache all the different different
configurations possible it's probably
more than the number of atoms in the
universe sort of number but if I had a
known quantity of the specific top
thousand that they just show on the
website that's something I can actually
work with so conveniently the catalog
site still had an old soap web service
still up for internal applications so we
decided right what we can do is just
once a day ping that soap web service
get this list of standard configurations
and then store those results in our
local document database and if we need
to change them more than once a day then
we'll have some back-end application be
like oh go ahead and update that one
right now so it was a rather easy one
for us because they already exposed a
service existing the next one was a
little bit more difficult this was in
pricing pricing is one of the services
that if we went to the business there
was no business unit associated with
pricing pricing was done typically by
sales or if not by sales by a marketing
group as well they would work with
multiple different organizations on
these two covers but it still all went
down to I need
to have some some really standard
configurations of products I need to
work with supply chain to understand
what's the good price to sell is that
what profit margins do we need a hit but
if I looked in the recipe organization
there was nothing there's no
organization called pricing was it was
something that was done by different
groups that was our first clue that
something is wrong with the service
because there was no analog to the rest
of the analog to the end the rest of the
business it's always funny to talk to
some of the managers there about so how
do you get your requirements who are you
talking to well they just kind of made
them up themselves again that was
another red flag if you have a micro
service that is only making up its own
requirements without any connection to
the business it probably doesn't need to
exist surprising you might imagine it's
pretty complicated it depends on the
configuration that you have so as you
select different options the pricing
changes it depends on the region which
is by the way a trick on these websites
you could go change a region through
like VPN and things like that you may
get better prices hint hint
also if you pick like Home Office versus
our business versus home you'll get
different prices as well something else
to to think upon it also dependent on
the individual catalog like I said home
versus business we also found that it
was actually served with the catalog
information so that previous web service
we were hitting to get catalog
information we happen to look through
response like oh wait a second there's a
price there let's just use that so we
severed the connection and ever called
pricing ever again and pricing said
that's great suddenly our API can
respond well we didn't actually tell
them we were doing this they just
suddenly had much better latency because
very few people were calling them
actually
the next one way to deal with was
localization this one was a bit tricky
because even though the information
rarely changed there was a lot of it
so localization for us was basically not
just showing things in the right locale
and region for people but also all the
titles and descriptions and things like
that need to be correctly shown to each
individual country and region so
although that information rarely changed
it was pretty large we also saw that it
this localization service already served
many many internal clients so there were
already exists there are already some
existing sales applications and things
like that but had to use that
localization information and there's no
way that all those different
applications could change to use this
new Web API so we have to look to see
well what are all those different
applications using in order to get this
information out well it turns out we
could just use an existing integration
method that everyone else was already
using because they had forced the team
to do so in which once a day they would
put out a file on a shared drive there
was just a flat file dump of their
database that said here's all the SKUs
and all the translations of every single
product detail information so we said
right we'll use that then we'll go get
that file once a day and just do a kind
of bulk insert and shove that into our
document database and call it a day now
final one was the most fun one the
content one cotton one was was also
tough because it changed fairly
frequently and those changes actually
needed to make it out to production
pretty quickly as well so it's important
for us that when someone changed
something in the existing service we
need to have it pretty soon afterwards
in our database as well this is what the
business already expected so we knew
that the the content service really was
going to change anything to give us like
a feed of information there was no atom
feed or something like that for us to
subscribe to to say give us this
information as it happens but we knew
the DBA pretty well and after a bottle
whiskey we were able to convince them
that we could put some triggers inside
the database for us so when individual
table changed we would get a message
generated
to feed into our search service that we
would then take that message and then
update our local document database I
don't know if the rest of the team still
knows that this happened there just
again the DBA is a pretty good person
and we bribe them with some good whiskey
so that seems to work well now this kind
of looks like a weird weird approach
that we have database triggers
generating messages that we consume on
the other side but for something like
this where I didn't want to touch the
existing application I didn't want to go
put something on there scrum board to
have developed six months and now I just
want to have something done pretty soon
this is a fairly good approach so for
applications where I have an existing
system where I can't really change that
well I will resort to whatever means
necessary to be able to get that
information out so what does this
picture look like at the end
whenever you did a search from the
outside world it only ever hits that one
single internal document database and
then outside of that on an offline set
of processes each of the other services
would generate some sort of messages in
some format whether it's document
messages or whether it's file kind of
messages or there's trigger kind of
messages push these in to aid you
normalize it that we take all the
information process it and put into our
local document database that way any
requests from the outside again do not
have to talk to any external services
and as long as we didn't change the data
significantly in those coming in we knew
that okay for that data coming in I
didn't even though I didn't own it I
could still have a cache of it locally
in our document database so we did this
put into production the search website
started behaving normally again and went
from a latency of nine and a half
minutes to more reasonable second or two
something like that and everyone lived
happily ever after the end
well that's not true so now for the not
so happy ending of the rest of the story
here one of the things I found over and
over again with service style
architectures is it it you can have
success in one individual area but that
does not necessarily mean that you can
spread that success throughout the rest
of the organization so I went back later
and talked to some of
the teams involved and said okay it's
been about a year how are things going
now oh it's great we've got all these
different individual services each of
these individual teams that have
ownership of the application they have
ownership of the database they're all
collated together they heard DevOps was
a good thing so they brought operations
into these groups as well and everything
was great they said but the problem was
they still had the similar HR structure
they used to have before so even though
each of these teams was able to build
their own application independently they
were still run by crap managers because
the only way you could get promoted in
this company was again to manage more
and more people so that meant that the
product teams had to keep growing and
the products themselves had to keep
growing because that fit into the
motivations of the individual managers
of these different of these different
teams and to a fault every single one we
talked to said oh the work is great man
just a man where you just keep adding
new people to our team and it just
really sucks that everything used to be
really small and focused and now it just
keeps growing and growing and growing
and again that was because of the
motivations external motivations placed
on each of these different managers so
there's not a lot of different ways you
can fix this if you look at applications
like this you'll typically see them
built around what snows Conway's law but
you'll see this a lot in microservice
discussions Connell Zod said any Aaronic
organization that design this system
will produce a design whose structures a
copy of the organization's communication
structure and I see this absolutely all
the time that the systems we build more
or less match these the human systems
that exist in the company I don't think
it's a bad thing but you have to make
sure that the motivations of the teams
can allow this to be set up for success
so I have a core layer corollary to this
as Jimmy's law which is a broken
differential organization driven by
meeting unhealthy goals and metrics will
produce broken and dysfunctional systems
this is exactly what we saw with them at
the in the Bell example
even though individual developers were
all good people because they were put
into a broken dysfunctional system with
bad goals and metrics then they will
optimize the wrong things and build the
wrong systems which is very strange
Rica's when I first worked there about
10 years ago I was on a cart checkout
team and our bonus for our team was
decided on how many people came into the
cart checkout process and completed the
entire process
so my bonus wasn't based on uptime or
SLA s or number of deployments or lines
of code it was strictly business
oriented it said the better cart
checkout process you make the fewer
people will stop trying to checkout so
we did a lot of fun things with this
like turned off all validations because
any red you put in front of a customer
will make them stop checking out we used
to have something that would check your
credit card here's like the the Loon
check that checks the digits turn that
off as well
confuses people they put something in
and there's like oh you put their credit
card unit is wrong no you're wrong slam
to the laptop shut go away yeah well if
you turn that off they're more likely to
go ahead and complete the checkout
process the minimum stuff we did for
meeting those operational goals of
making sure everyone can check out was
just did they fill in all these forms so
they fill in the first name last name
there that it exists they'd have all the
required fields actually filled out well
that was it because again our motivation
was just to get people through the
checkout process now that meant of
course that we had to do further
processing after we got the information
to say who actually that credit card is
invalid who actually that is a date in
the past ooh actually that's not a valid
shipping address but we had all these
things offline because again we're
trying to optimize for getting people
through the process so we have helped us
people call people out to the door and
said looks like you may have mistyped
that and they were trained to be able to
be nice and things like that so that
they could fix all the information and
then go on from there
so if you have this crappy organisation
and you want to build systems for it
you're going to build crappy systems
because Conway's law is the law so what
you need to do is perform what's known
as the inverse Conway maneuver which is
to design
any organization you want and any the
arrestee architecture will follow
kicking and screaming now this this is
daunting right because it says basically
in order for you to build good systems
you may have to reorganize your company
and who else who's done that before you
just a company of one step does that
count okay so this building a building
an application architecture like this
can sometimes require buy-in to the at
the highest level to say you know it's
not just our IT systems that are there
bad it's our entire structure that's bad
we need to organize our company
differently
we need to organize not just the IT
people together we need to have the
business people in there when you have
the operations people together and have
those different groups aligned towards
specific business goals we need to make
sure those business goals are not
harmful and we can cause bad things like
building big teams to gets the only way
you can get ahead in the company and
it's only is that organization is how
they can then you build good systems
based on those organizational structures
so that was my story of avoiding
microservice mega-disasters I thank you
for coming here and I hope you enjoy the
rest of the rest of the conference and
if you have any questions I'll be happy
to take them
any questions yes so the question is
what do I need to do if my service
actually needs to make calls the
multiple things we had we had one golden
rule that says I can only make one hop
I can make one hop from one service to
another but that service can't call
anyone else so if I have that case right
to make multiple hops either I've drawn
my boundaries wrong my service is not a
correct service because I have too many
dependencies amongst other things or I
need to invert those dependencies and
start pushing that information to myself
so that it can have it locally and I
have to call those other people the
question how did it convince people that
duplication of data is good well one way
to go about that is to recognize that we
live in a world of data duplication and
in fact their original business was
built on data duplication because it
used to be a mail-order catalog business
and that's millions of copies at the
exact same duplicated data they pushed
out to hundreds of millions of homes all
over the world so they've already
duplicated data and built a business
around it so why is it any different now
so that was it like you've already your
business is already built around this
it's not like when you duplicate the
data they said well somebody can change
it it's like right so when someone calls
in saying they want to buy a computer
and they said yeah the price is at $7.99
it's 399 that's what it says in my
catalog because they crossed it out and
wrote something else like now you so you
know it's it's $7.99 so you can
duplicate it just fine as long as you
don't change it also the nine and a half
minute latency is like yeah you tried it
it didn't work so let's try something
actually works that helps too any other
questions all right thanks I'll be
hanging out afterwards have a great rest
of the conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>