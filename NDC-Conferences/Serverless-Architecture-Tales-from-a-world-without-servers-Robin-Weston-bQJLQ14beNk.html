<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Serverless Architecture - Tales from a world without servers - Robin Weston | Coder Coacher - Coaching Coders</title><meta content="Serverless Architecture - Tales from a world without servers - Robin Weston - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Serverless Architecture - Tales from a world without servers - Robin Weston</b></h2><h5 class="post__date">2017-02-15</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/bQJLQ14beNk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thank you for coming I
and it's like the range of ridiculously
good talks is pretty impressive so thank
you very much for gracing with your
presence I hope ever good time M Who am
I my name's Robin Weston I work for sort
works consultancy so I'm a consultant
developer go into companies across the
range of business domains and help them
solve problems using technology and but
it's not important for this talk at all
really and and I have to call out
although I am a dirty consultant I have
no ties to Amazon or do or anything like
that I've got nothing to sell you this
is all kind of opinion and so before we
kind of dive into it just a kind of show
of hands so we have an idea of kind of
where one is who's heard of or read
about serverless architecture or server
little functions as a service before
sweet pretty much everyone and who has
used them in anger fantastic fantastic
that's exactly kind of where's pitched
at okay good stuff right so what we're
going to look at we're going to start
with bit of a bit of an introduction
what is a service architecture I don't
want to spend too much time on that a
lot of you have clearly read about them
also the Internet is a wonderful place
and you can read up on those on your own
time you don't need me to read stuff off
the internet for you I'm keen to get to
the second part which is tales from a
world without service that's kind of a
learning we took from a project where we
used a service architecture and then
come the final part should should you
use one now we will talk about them the
pros and cons but ultimately and you
know what are the kind of use cases for
one so let's get started so what exactly
is a service architecture and I think we
need to start by all agreeing that it is
utterly terrible name service is
ridiculous what so we've we've suddenly
found a way of running software without
physical machines of course that's not
the case unfortunately the marketing
folks have grabbed hold of it it's stuck
it is what it is we're stuck with it we
have to run run with it so if we dive
into a definition
we can help them kind of pull out some
of those essential pieces so sorry it's
a bit wordy thought this is kind of the
only worthy slide so service
architectures are internet-based systems
where the application development does
not use the usual server process instead
they rely solely on a combination of
third-party services client-side logic
and service hosted remote procedure
calls functions as a service okay let's
dive into a few of those so component
parts so not use the usual server
process what exactly does that mean
basically means that the software you
write doesn't run on the server that you
have access to you can't log into it you
don't own it it's abstract it away
managed for you and by someone else
there are many benefits immediately that
spring to mind
about not having to manage your own
servers you don't have to worry about
servers randomly rebooting or going down
or any other monitoring monitoring that
goes around that you don't end up with
snowflake servers where you don't know
exactly what's installed on it but you
know it's mission-critical so you can't
really touch it you're not responsible
for installing the software on them and
upgrading that software and even if
you're following good practices like
infrastructure as codes you can re
reliably reproduce servers in a given
state that infrastructure of code is
still code that you have to maintain and
test and all the stuff that goes along
with it there's cost associated so
that's the usual server protostar since
we say then instead they rely on solely
on a combination of third-party services
so what do we mean there we're talking
things like cloud accessible databases
so you've said I don't really want to
spend my time my company's time
maintaining this database that's not our
core competence core competency we won't
be writing our business logic and the
stuff that brings value to our customers
so I'm going to kind of outsource that
capability so for example you could host
an elastic search cluster on AWS you
could use sequel as year you could use
Google firebase so you've kind of
delegated that responsibility to the
cloud provider authentication services
I'm sure some people in this room have
used author 0 why would you write your
own authentication service you know it's
going to be a half implemented buggy
version of something someone else's
written so you got all 0 AWS Cognito a
whole bunch in but again you kind of
outsource that to someone else they
maintain and run it and you pay them for
the privilege and then we talk about
client-side logic that is simply stuff
like rich client applications so where
that may be single page web apps or
mobile apps they're kind of moving some
of your logic from the server up to the
client and the last one which is the
most worthy but the most useful for the
rest of this talk is the service hosted
remote procedure calls and because I
don't want ever to have to say that
again we'll call them functions as a
service which is kind of a common name
that seems to be used now so confusingly
even though service already has a
terrible name it's also come to mean two
separate things the first of which is
this entire definition of what our kind
of service architecture is the second is
just the last part functions as a
service so we already have that kind of
double definition there so I'll refer to
them as functions as a service from now
on sitting at capture the essence what
we're talking about and for most of the
rest is talk I'm going to talk about
functions of the service because they're
newer and they have significant
differences to how we think about
technical architecture and building
modern systems and it's been driving a
lot of the hype around server so that's
what we're going to focus on and for the
rest of this talk so quick kind of
visual representation of what I just
mention traditional versus server so in
the top diagram that's your browse on
the left and they're kind of like
brownish blob is a server or a series of
servers that you maintain whether
they're in the cloud or on-premise
whatever so you've got your browser
calls the server it's got a blob of
logic it's got some authentication stuff
some more logic and a database but
you're responsible for maintaining all
those and at the bottom you've got your
service architecture you move some logic
to the client maybe it's a browser or
mobile app you're calling out to
authentication service like all-zero
you've got your database there as a
service as well and you split kind of
the key bit you've split some of your
logic into individual little functions
of the service that you call
individually we'll get onto the into the
weeds with that in a bit but this is
kind of just a visual representation
of that so it functions of a service
what exactly are they these are the key
points we'll go through in one more line
saying literally when we say functions
of the service we're talking a function
like the function you know about in the
code you write every day block of logic
with a defined input and a defined
output and the logic in the middle
nothing more than that explicit
interface so that's it they run on the
server side logic and independent of
each other they're not dependent on each
other these these functions and
stateless it's quite a key point we'll
get onto that bit later but nothing is
saved between separate runs of the
function because of the underlying way
that they're run you can't guarantee
they'll ever run on the same server so
you can't write something to disk and
expect it to be there next time I mean
you could argue that this is a good
thing to try and do if you're building
apps normally because then you don't end
up tied to your application servers you
have to do sticky sessions and stuff
like that but you have no option if they
are stateless they're also sandboxed so
kind of similar approach containers you
can't like reach outside of your process
and go into the one next door and the
thing like that
they are ephemeral basically short-lived
they're designed to do a job do it
quickly and finish they're not
long-running the revenge triggered and
we'll get into some the different types
of triggers but their event triggered so
something will call your function and
lots of examples of these functions sit
there and they can be called by multiple
and triggers they are scalable by
default and this is like one of the kind
of big wins on the poster functions of
the service because they are stateless
the cloud providers can scale them as
much as as much as you need because
they're not tied to any particular
particular state so they run as many of
you need as many triggers that fire will
run that number of function and they're
fully managed by the third party so
you're delegating the responsibility of
these functions being run to a cloud
provider and I've just around there this
is kind of a leading players in that
space you're a degress lambda of your
functions Google Google Cloud functions
which run on Google cloud platform and
all theory websites
there are a bunch of others springing up
you're pretty much fine now that every
major cloud provider will have a
functions as a service offering and it
will be evolving really really rapidly
so I kind of like to think of this as
the kind of functions of the service as
the evolution of cloud hosted software
so if you just look at this diagram on
the left of the Green Line in each step
is something that you are responsible
for you're responsible for kind of
maintaining and the upkeep of it and on
the right hand side the Green Line is
something you've delegated to the cloud
provider to do so top left is kind of
infrastructure as a service so you know
going on as you're spinning up a server
or an ec2 instance on AWS so fine that
spun up and you didn't have to you know
fill in the form and ship in the bare
metal server but it's still your server
to look after if it goes down you've got
to work out how to restart that you've
got to install the software on it all
that stuff sitting on that server you've
got an application that you wrote
certainly the dotnet web app know that
whatever doesn't really matter platform
kind of agnostic really and that has
multiple functions in it just code
function so then we move on to top right
which kind of next evolution so that's
something like platform as a service so
something like Heroku or as your web
apps I think it's called now what was
with your websites where you say hey I
don't care about servers here's an
application that I've written run it for
me and it decides the cloud provider
specified I'll find you a server to put
that on and I'll run it for you don't
have to worry about patching the server
and scalings much easy you just drag a
slider or something like that so that's
kind of that evolution and then the next
state where we are now is function as a
server so you've actually the
application itself you're moving that
over to the cloud provider as well
you're literally supplying it individual
functions and say hey when I tell you
when to run these functions run them
please so that means you don't have to
write really any boilerplate around it
if you think about some of the simple
apps or any absolute written recently
there'll always be some boilerplate
where you're connecting everything
together and it's not really business
functionality it's just infrastructure
stuff that has to be there
and functions of the service allows you
to move on from that if you're deploying
individual function and an evolution
here doesn't necessarily imply that the
next stage is better than the last
you're just kind of moving the slider
over in terms of smaller units of
deployment so you've got to now pretty
small wing and we talked about micro
services but you could literally deploy
now individual functions and you're also
moving the slider over in terms of
control you have because you're
delegating it to the cloud provider
which can be seen as a good thing can
also be seen as a bad thing so I'm not
saying that each one is better than the
other completely depends on your context
right so this we've only got a few code
samples so you don't worry and this is a
AWS lambda function just to give you an
idea this is the using the node and they
know runtime written in JavaScript all
this does is take in two numbers does a
bit of validation add them together and
spits out a result hmm so if we look at
line one that's your defined interface
every single node eight of this lambda
function will have this interface you
have to conform to it you get given two
things an event so that's all your
inputs where that comes from depends on
how your and being triggered will get
onto that in a bit and context give you
a bit of information about how you're
being run so you can look up stuff like
what the function name is how much
memory has been assigned but importantly
here it gives you two functions on it to
call back when either fail or succeed
and you can give it the result so you
pretty much go through and do a bit of
logging do some validation if the
validation fails you call context dot
fail it's not you add the inputs
together and call succeed and that's it
and this function could be called many
times you want in parallel to do that do
that work
no surrounding boilerplate code just
straight into your business logically
and it's a simple example but there's
nothing to stop you and you probably
will have multiple files so this is a
node app you could have a few JavaScript
files that you know required in together
you can also include third party
packages not a problem with that as long
as you include those when you deploy it
will get on to deployment in a bit so
you it's just like building a normal app
except your entry point is this function
not your kind of top-level entry point
that maybe your startup CS or whatever
in dotnet man so out of the box you can
also write them this one a Carissa
lambda on in Java in Python and now
stock net and they all have similar
interfaces I've got a dotnet example
after this basically the underlying
operating system is Amazon Linux which
is their flavor of Linux and but you can
actually because it is on Linux you can
actually shell out to anything that runs
on Linux so people have written wrappers
to run stuff on like golang or even just
shell scripts you can just use your
scriptures call out to it type the
result back in back out again this is
the same equivalent example in net so
net core we have to run on Linux so it's
a bit more worthy because you've got to
have an input object which you can see
on line 13 this numbers input but again
it's that's defined and you do your work
do some console dot write line do some
logging throw an exception if the inputs
wrong computer result and just return
out again so there's a bit of
serialization that has to happen to get
to serialize that numbers inputs
instance in the input they provide you
with a default serializer you can run
your own if you want it also supports
streams and async so it would happily if
you much as they sink and did some work
like that it would happily support that
and and there are some new there's an
Amazon lambda dot tools NuGet package
you can use which add some command line
stuff for deploying them and creating
them locally to adds it for the dotnet
CLI and there are some visual studio
project templates to kind of create you
the scaffolding for these functions but
from this you mean you don't really need
it you could just copy and paste any
example off the internet and fill in the
fill in the blanks basically so there's
the examples that's kind of all the
codes we'll look at today just wanted to
kind of get across how simple these can
be we talked about event sourcing and
triggering so what fun you've created a
function how does it run a myriad of way
so this is in the AWS world but you can
kind of assume for all of these there's
an equivalent version as Europe or
whatever so you can trigger these from
dynamodb so you can say hey when a table
is modified or added pull my lambda
function with the details of that row
and so if you went back here the event
object in the input you be able to flux
but that would essentially be the row
and then you could pluck all the column
values off that s3 so you could hook up
so it's a far land in there's three
bucket it calls your function and the
event would give you the details of that
s3 bucket that files you could go and
look at that file do some processing on
it SNS which is a notification system
could come from anywhere
you know text messages all kinds of
things API gateway is a big one and
we'll get onto that in a bit more detail
later later so API gateway it's kind of
Amazon's HTTP API the service allows you
to really even quickly spin up really
scalable API even so you can kind of
hook up an API function P say hey when
this endpoint gets called this restful
endpoint take the Jason and plumb it
into my lambda function and run that
function so it's kind of like you're
backing logic for your M API endpoints
so straight away you can get a really
scalable API up vehicle you can also
just view scheduled events so think of
them as fancy cron jobs you can run
these functions on on timers yeah every
Thursday at CPM whatever so really good
to come like maintenance tasks or stuff
like that and and the great thing is
that the lambda functions will scale to
service the level of incoming events so
you know if 10 files drop into s3 at the
same time fine it'll just run ten number
functions to produce them and you could
hook up the same lambda functions
multiple input events if you wanted
totally up to you so it loads more than
even they keep adding more and more
hooks but these are kind of some other
some of the more obvious ones right ok
so we've kind of covered a little bit
about what they are but let's get into
some kind of learnings and some some
opinions because that's what we're all
in it for and so this is I'm obscured by
the S but that's me and the team I was
on em last year and we working for a
client in the events industry which is
quite relevant given given where we are
so we were tasked with building a
a standalone analytics and performance
service with a dashboard for their user
so basically they were building software
had no idea how that software was being
used how it was being performing didn't
know what to build next if it's
basically whoever shouted loudest they
built that thing they wanted data to be
able to make data-driven decisions makes
makes make a lot of sense so we needed
to pay a fee hoitz data out of all these
different systems they had on there kind
of technical estate do some aggregation
do some processing store it and then put
a dashboard over the top so they could
do reports and so on
we built around this system for six
months so some of that I'm going to talk
about it's not just all look how easy it
is to build these functions it's about
one of the operational running of them
and the learnings we took from that
because the end of day we're we're good
citizens we we we try and practice
DevOps and and we want to these systems
need to run in production and be stable
as well and these opinions were kind of
gathered from a team retrospect that we
had at the end so it's kind of me
voicing this team's been you
you may notice we're all wearing stripes
stupid Saltworks thing on a Friday
yesterday Friday strike so I can't
actually I can't comment on whether
wearing stripes on a Friday influences
of success of a serverless project I
don't know we didn't try anything else
so it might be really coupled together
who knows right so just to give you a
bit more context this is the end user
experience doesn't really matter we're
looking at a dashboard for an event
might be London Book Fair for example
some that we run these big events I
think this shows the drop-off rates for
login on one of the online apps so
simple since similar to how you would
have signed up for MVC here this doesn't
matter just to show like there was some
point to it from a user point of view
okay
a bit of architecture there's little
bits of writing don't matter I'll just
talk you through it so we had we kind of
collected our lambda functions into two
services so we had these data collector
services so we're looking at one day to
collect the service here so we had a
lambda we called it a producer lambda
that spun up on a schedule two or three
times a day went and grabbed some work
to do from the client API basically oh
what events have been changed what ones
do we need to grab the data for we'll
pop that on a queue so in SQS a direct
lambda q
put a bit of metadata in a dynamo DB
database and then we had a series of
worker lambdas that would be triggered
when stuff dropped onto the queue and
they would spin up as many as we're
needed and start to process that day to
grab some more data from the client API
Monday around a bit do some aggregations
and then chuck it at this metrics API
services just to the right and this is
the metrics API service so it was a an
HTTP API to use API gateway to have a
few endpoints for example 1/8 and
endpoints of postal sync single metric
one that took bolt met fault metrics
nothing too crazy and they would hand
off to request handling lambda functions
to process as many other needed so this
needed to be really scalable because
over time this would grow and this would
allow it to kind of scale by default we
would process that incoming data add a
bit of metadata just to say what system
it came from like the ingestion time and
chuck it in a hosted elasticsearch
cluster and then we had a power bi
sitting on top pulling from
elasticsearch so the kind of views
interesting bits here are there or
already three things triggering lambda
functions we had the schedule that was
triggering the whole process so go and
grab the data at beginning we had stuff
dropping off a queue and that was
triggering the lambda functions and then
here we have them hooked up to an API
gateway endpoint for already got three
uses there's actually a fourth way but
we'll get onto that but that wasn't core
to the system so just a bit of
architecture so what was good about it
what did we like
scalability so this would like to
recover one of the big cells of
functions of the service they are
scalable by default which is pretty
awesome as I said before it creates as
many lambda functions as a needed to
process the incoming event and this is
like the key difference between
platform-as-a-service and functions and
service in platform-as-a-service if
you've used a Roku or as your web app
scaling is easy there's a slider usually
that you can drag or you could do it by
convict I think they call them like
dinos on Heroku but you could say hey I
need a bit more power drag this slider
across and it takes a bit of time then
you it scales itself out and you get
more performance you don't have to do
that here because it will always service
the incoming events always by default
there is no slider skating is pretty
instant
instance so you don't even need to let's
say you wired up you on AWS and you've
done some really good stuff where you've
done some hooks so you say hey if CPU on
my servers gets above this percentage or
the queue gets this big or memory goes
to this point that's the trigger point
adding a new server into this kind of
load balancer group and it Auto scales
or ever the equivalent is energy oh you
kind of set up this auto scaling system
which is great because you can be
flexible and respond dynamically to to
whatever the demand is however that is
an instant you know you've got a that
new server has to spin up maybe it has
to install the software as well it's got
to be hooked into the load balancer
group before it becomes active there's a
kind of that lead time before it takes
effect even if you're using containers
on some like clustering thing you've
still got to add a new container get it
started up it's not incident where as
pretty much here a few exceptions are
pretty much these functions all just run
run as many as needed so that's quite
that's quite a big win if you're in an
environment we've got really fluctuating
traffic profiles and similarly you'd
have to wait again for that server to be
disconnected when the load has gone down
and you're paying for it while it's up
so again if the function isn't running
you haven't got that issue here I
mentioned with API gateway in
conjunction with a lambda you just got a
really really powerful and scalable
public HQ HTTP API out of the box which
is pretty pretty big win you can focus
on the actual logic and not escaping it
however there are there are hard limits
as we learn so by default
AWS throttles you're running of your
functions few it will limit you to 100
concurrent executions at a time so when
the one hundred and first concurrent
lambda function is triggered it will
fail automatically and with an error
code so gracefully if it won't run it
Amazon does this for it says it does it
as a safety limit for you for your cost
basically to make sure you haven't
accidentally engineered it so you're
just going to spiral off and accumulate
massive cost without noticing so it's
pretty trivial to apply so the form you
fill in online and apply for high limits
once you kind of know what you're doing
you say no fine we take on
responsibility we know what we're doing
we need more than this limit and
and okay fine and turn the switch but
they they have it in kind of safety mode
for you to start with and just kind of
for your own bank account benefit and
the other thing we learned if you I said
there isn't a slider but that plays to
way you can't constrain the scalability
so we had an issue where we have the
client API which is on the previous
diagram and we were hitting it from our
lambda functions to pull back data and
our system of scaling amazingly and
doing all the work it needed to do the
client API could not handle the amount
of traffic we're throwing at it three
essentially kind of created our own
denial of service attack on the client
API which obviously isn't ideal so
you've got to remember that you're part
of a wider system potentially even
though you can get out very well
the you've all dependencies might not
want there might not be able to see
you've got a kind of building for that
so that's why we added the queuing
system so we could kind of and churn
through them a kind of a known rate and
without throwing those requests out at
the same time so it sounds very much so
cost so someone's gotta pay the bills
and another of the big selling points is
the cost savings you can make with these
kind of systems so the pricing model
free WS lambda is basically memory
tellings runtime so you pay for the
amount of time your function runs for
and the amount of memory that you've
allocated to it to run and you you are
paying for runtime code like down to the
nearest 100 milliseconds because either
expected to be reasonably short lips so
rounded various 100 milliseconds that's
what you pay for
compare that to a another type of
application run so you write a dotnet
Weber and you and you know you deploy it
somewhere and it's just sitting there
and no one's hitting it you'll still put
that server they were the server still
running you're still paying for the
privilege of that web app just running
and sitting there waiting or if it's
something that has cron jobs and the
cron job isn't running you're just
paying for that thing to sit there and
run and wait for the cron job to run
which you know if you think about it
doesn't make that much that much sense
so here you're literally paying but just
when the function runs if your function
is never run on the given day your bill
is zero and just an example of costs and
you get like a million free a month with
the AWS creature that's a million free
requests or free function runs but if
you wanted to run 30 million requests
and you allocated 128 megamans and they
all run for about 200 milliseconds which
seems like a reasonable amount of time
for a little bit of processing for 30
million requests taking 200 milliseconds
each that's 10 quid a month so you see
what we talk about so we have to do cost
estimates and we use on this system
and it just is laughable when you
compared it to the cost of hosting data
in elasticsearch this order than orders
and orders of magnitude smaller it just
it wasn't even worth it in the end we
just stopped and start worrying about it
and there's a really great price
translator online and this pricing model
is used by the other you know a zero as
well and it's not necessarily cheaper
for all contexts
I'm not saying this'll be cheaper for
everything I've seen examples if you
really know your traffic profile and you
really know your application and you
want more control you want it running on
bare metal because you can tweak things
you could probably make it cheaper but
if you don't know your traffic profile
it's a new application or it's just not
that important then it's a great sell
and it's also worth remembering that
with any cloud system there are other
fees that you will pay because it's
unlikely that this your Lander function
will run in its own sandbox and not do
anything else if it calls out to other
services and they dress like you're
pulling dates from s3 bucket or putting
data in it you're going to pay some data
transfer charge if you're going to pay
for the storage in s3 things like that
you've got those added fees it for the
pure running of the function this is the
model so testability we're all good
developers we want to write tests we
want to make sure our code works before
we deploy it how does that work so local
unit testing was fantastic it was a joy
and if you remember back to the
definition you've just got a function
with a defined input and the defined
output that's your that's your test that
like all your tests just look pretty
much the same which is great and you
don't have to go about mocking loads of
stuff out and kind of get it to a point
where you can hit your function it's
just there just call it and simple entry
an exit point and works really well it's
quite nice because you can just kind of
write all your tests we found at that
level and if you find instead of having
to write
kind of lower level unit test only test
a small subset of that function you're
getting to that or you're having a lot
of set up that function should probably
be split it's kind of a sign that that
lambda function probably split into two
that do the composite part and what is
harder is kind of functional testing so
typically if you're writing a web
application API you want to be able to
run some tests that fire HTTP traffic at
it and test the responses because
ultimately that's that's what it's going
to be doing so how does that work
because here it's running it runs in the
clouds so you've got API gateway sitting
there but you have no application to run
locally it's not like you can just run a
command line and it's spun up locally so
how do you fire those HTTP tests at it
when you can't run the application
locally so what we did and this is kind
of what AWS suggests if we actually had
each developer had their own little
sandbox in AWS that they could deploy to
we're the command line script it would
deploy the latest version of their
functional functions to AWS in their own
sandbox within trample over everyone
else and then fire their test at that so
we actually just used AWS as the testbed
and you think I'll happily take a long
time but the deployments are so quick
that really I've had much longer startup
times for apps running locally so it
actually wasn't about at least then
you're testing it running in a very much
production like manner because it's
running in AWS so that's what we that's
all you're in with there are other
solutions that do exist and people have
written kind of helpers that kind of
like fake things and wire it up maybe
use docker containers so that it mimics
your function running locally with an
HTTP wrapper you can fire traffic at it
but that is never going to be identical
to what's going on in production because
it's a different model so just to better
in mind the solutions exist but we
decided to run them in AWS itself and it
was fine and so obvious you would do
that before you committed any code so
that was just a local script and then
you would commit and they would go
through a pipeline so security the worst
and fiddling one great thing about not
having to manage servers if you don't
have to manage security patches you are
of course relying on Amazon
to patch the servers but they're pretty
good at that they've kind of got that
down so you don't have to worry about
installing you know open SSL patches
when the next vulnerability comes out or
whatever it is you have the servers on
your responsibility you're paying
someone else to take care of that for
you
also because you can't log into the
servers that's suddenly a much smaller
attack surface area for anyone trying to
get onto them for the forest purpose if
you can't get on
you have no SSH keys no usernames or
passwords to get on so now everyone else
is going to get on and so straightaway
you've really locked that down and you
don't have to do any faffing around with
firewalls or ports or making sure that
you haven't accidentally left big gaping
holes because again you don't manage
those those servers so it's kind of
something else you just don't have to
worry about and so one of the things
that we saw through our the client which
I was describing earlier where we were
working on this system
they were just in the kind of middle of
making their journey to the cloud so
they were taking their existing
applications and moving them but they
still had the kind of process and
documentation and forms that came with
the kind of old-school on-premises
server thing you know yet I want a
server and you have to fill out all the
details before it can be deployed you
know have you installed antivirus on it
is it the approved you know operating
system has it got all these other things
on and so on and so on
a big long tick box with you have to
kind of fill in for each server and we
saw the existing teams battling with it
they kind of kicked this model for the
cloud so people were spinning up ec2
instances and having to fill in these
you know what is the server name I don't
know it doesn't matter and it's going to
be killed tomorrow there's going to be
another one but you have to kind of go
to this process so we kind of took a
step back a lot you know what if we do
this do we have to fill in any forms and
the answer was no they gave us the
former we like doesn't apply doesn't
apply doesn't apply there you go and
they were you know what the security
folks they were like well yeah you have
took a look at it and yeah you've proven
you don't actually chance these because
it's just a different different way of
running so it definitely helps us out
and totally what organization you work
in and of course like you don't have
zero credential
to manage if you're an AWS you've got
AWS access keys and stuff like that so
you still need to be good good citizens
about handling those but you've reduced
the amount that you have to have to
handle so it's not a free lunch but it
definitely helps us so operability so I
mentioned earlier it's all very well
building systems they've got a run and
we don't want to just chuck it over the
wall to ops and let them deal with it
it's lost my slide and how we easy is it
to operate and run your system so
out-of-the-box operability is pretty
pretty good you'll probably want to
customize enhance it out the box is
pretty good so let's go into a bit of
detail so logging we all will write logs
we all want to see logs when stuff goes
wrong how does that kind of work in the
functions of the service world so if you
remember all the way back to a with the
code samples in the JavaScript example
there with a console dot log statement
and in that example there was a console
dot write line that's your logging you
write a log line like that and it
appears in AWS cloud then watch which is
there kind of monitoring and logging
system which we think about pretty cool
because think that the systems we've
worked somewhere you're right into
physical log files you know and then you
have to work out ok we have some log
rotation policy and then we've got to
clean up the old logs but then those
logs are just sitting on servers we
don't really want to log into the server
to read them so we have to use something
like log stash to take those logs and
like maybe pass them and shift them
somewhere else so we can aggregate them
and read them and that's good that's all
good stuff to do but then you've got to
write code to do that that's extra stuff
you've got to maintain it something else
that could go wrong all to achieve a
kind of just move this from A to B it's
not business logic it's not adding value
to your customers directly one
console.writeline
BAM there is an aggregated or in a
logging system that you can search on
and see that is pretty compelling and
just you get straight to the kind of
value of view of your logs so pretty
good and it's not perfect the clouds
watch logging system is a bit clunky
it's hard to search across different log
streams across different functions
because often you'll have functions that
chain together and
all want to kind of see an order in
which things happened across all your
services whereas it's by default you
kind of can only go into each function
so that was a bit annoying and you can't
do aggregation like I said and you can't
do grasp on specific log base E class
they do me a graph on ones that have an
invalid level of error for example so
what we did and this is kind of a WS
suggested and they provide you some code
to do this is to use a lambda functions
this is the other use of lambda that we
had we just attach a lambda function so
it was triggered from CloudWatch so
every time a new entry new log entry
came into cloud watch it called our
lambda function which took that log
message and stuffed it into a stick
search stuffed into an elastic search
cluster so that would just be triggered
as many times as we needed and it works
so then we'd have our logs coming into
elastic search and then we could have
cabana over the top with all the nice
aggregation and you're kind of maybe
more used to and that's that solved the
problem
so another use of lambda that is a
really good one that you can kind of
start to use around to dive straight
into the kind of core of your
application so it's basically elk stack
but without the log stash because we
didn't need it because lambda was doing
that kind of lifting for us so
monitoring so these are the graphs we
kind of had up on our wall on a big
monitor and you get a bunch of stuff for
free it's out the box which is pretty
cool again think of systems you've
worked on you like right we need some
monitoring okay well then you've got a
push some metrics dump somewhere do you
know are you using maybe like graph ice
or something like that with respond or
over-the-top or I don't know New Relic
or something you still got to do some
config to push things around and set up
your graphs and stuff you get this this
out the box for a lot of the use cases
you care about so I'll just walk through
what each of these means this is just
sort of a subset of what you can get
that so the top left is our one of our
lambdas our writer lambda the duration
time it took to run is that red squiggle
in the middle and the other ones are
errors and indications so that can't we
can look at the duration I mean if they
always are getting too much is there
something we should look at here and top
right we've got our API gateway request
so that's the kind of
HTTP API endpoint was sitting over top
of our lambdas again we're looking at
the count that is the live one such as
how many requests to being fired at it
the orange line is how many four hundred
class errors we were getting with state
of code of 400 or above and then the
green line is 500 errors and you get out
of the box it's pretty cool and then at
the bottom is our API gateway latency
for how long things are taking to run so
we could send you know react to it dig
into the logs if we needed to and cloud
watch is pretty cool you can set up
alerting so we had some alerts set up if
things went above a certain threshold
you know latency is a bump above 10
seconds for the last minute far off an
alert which could do anything text us
email us and we can look into it
so these default graphs are fine you'll
want to add more clouds watch has custom
metrics this talking about crowd watch
metrics is a whole other talk basically
you could do an stuff there but we
wanted some more granular things like a
specific status code maybe instead of
just anything in the 400 range or you
might want some business focus metrics
you know like from a user point of view
how is this system being used in terms
of maybe you the transactions or
something like that isn't the actual
kind of technical implementation details
about how does it impact our users and
but it's pretty cool what you get out
the box and it really helps us and allow
us to free up free up time to focus on
the kind of core problem deployment so
you've got write your functions how do
they make it make it to the to the
clouds
and pretty easily is the answer so for
JavaScript it's just a zip file you just
zip up your your JavaScript files and
any third-party dependencies basically
your node modules folder and you call an
AWS API endpoint passes a zip and it
deployed so dotnet and you get packaged
pretty pretty simple and deployments are
really quick it totally depends on the
size of your deployment package but
typically because you're only deploying
either one or a few small functions with
probably a few small dependencies your
deployment package is pretty pretty
small a lot of ours weren't even above
like a mega also so pretty speedy to get
up there
and the great side-effects is there zero
downtime deployment by default because
you're not deploying on top of it an
existing application that happens to
live on a server and you've got to worry
about or do we need to drain the
connections off this you know before I
don't know restarting is or whatever
I've been on teams where that is
considerable amount of engineering
effort to get to the point where we can
deploy and keep the application running
during that during that process and
again that's how you have to write and
maintain is here any after the early
functions that are in process when you
deploy new and we'll just happily finish
and then the next time one runs it will
just pick up the latest version you've
deployed and off you go another lovely
little side effect and we followed
continuous delivery principles with this
and it's really easy to do you know we
just packaged our deployment artifacts
at the end of a build step after we
tested everything and then that package
just gets deployed through environment
so we had the notion of an environment
within AWS and we had the client and you
probably see this a lot is that have one
AWS account so maybe it's a Devon test
and then so maybe production you have a
different AWS account so but you've got
the same a zip file or new yet package
that you can just push to each one so
it's exactly the same binaries so you've
got a high level of confidence it's
going to behave the same way and one
thing to not forget is all it's all well
and good saying are we know is this
deploying function that fits easy
you've got the deployment of any
surrounding infrastructure as well again
typically you're not going to have a
function that's existing in its own
world it's going to call out other
services it's going to have to run in
the context of some kind of online iam
role so it takes on some have-have beams
and permissions so it can allow it to
talk to other services that role needs
to be created somehow you know you might
need an s3 bucket how does s3 bucket get
created if you can have to kind of be
able to deploy all these things as well
and you should have separate you know
deployment pipelines for these that spin
them up separately but there are other
bits of this world than just these
functions you've got to think that a
unified and you don't want to go
clicking around in the AWS console or
there is your console to create them you
know you want to be able to create a new
environment
like that you know could you recreate
your production environment if it
suddenly disappears or would it take a
lot of clicking around and linking
things up and so on so we're thinking
about and also the alerting and logging
that I mentioned we base all those in
for our source code as well so we didn't
have to set those up by clicking around
in consoles
although the loading rules are baked
into the code so we could just make a
change in that with automatically deploy
and it was really easy hey the riff
makes it easy for you and so framework
and I don't want to talk about this too
much there was a talk before we go adds
it to the chapter and kind of wrote
Klaudia J and people to know a lot more
about these but a bunch of kind of an
ecosystem of frameworks has sprung up to
help work with serverless via AWS or or
the earth so what these basically do
from a kind of high level is they
provide some opinionated tooling around
typically API gateway in AWS lambda or
the equivalent on the other cloud
platform they mostly all command line
driven and they help you do things like
deploying so they've sorted the
deployment problem a basis ok if you
write your functions equipment and the
folder name this then you you know you
go on the command line deploy will take
those functions and will put those into
the clouds for you because we know what
you're trying to do they help you with
testing so they've got I mentioned it
earlier help you out by being able to do
some more advanced testing than just
running the functions for example
allowing you to fire HTTP traffic at it
they kind of dump them munging around to
make that possible they helped me with
configurations they say hey if you drop
your configuration variables in here
we'll make sure and label them for which
environment you want we'll make sure we
deploy them to our environment and they
also some of them have some easy shims
other languages so I mentioned something
like Doe Lang or shell scripts a lot of
these have that built in so you don't
have to do that wiring yourself so they
give you some kind of a lot of help
around that and it's most your command
line driven we actually didn't use any
of these it was awhile ago and we did it
and these are very much in flux and
quite opinionated and moving quickly and
we didn't want to be tied to any magic
that they did and if they went in a
certain direction we'd be tied to it so
one to keep things if we just called the
AWS API directly using javascript and it
works fine you have to do a bit more but
it worked fine for us now I would
definitely take a look at these first
especially if you're doing a putting
your demo together
and using one these just takes them
again to some of that slightly heavier
lifting away from it it's worth pointing
out I don't really notice the serverless
logo has a the s has like it's a gifts
got some fire going on I don't know if
that makes it more appealing
also there's handily named it service
which is where I mean we have two
definitions what's what's another one so
why not but they're all they're all
worth they're all whether look so the
pit of success so this is kind of the
learning that we took away that just
just some of you may have heard this
term before but I'll quickly define with
a chatter Microsoft called Rico Marion
re who had a good definition which
basically says the pit of success in
stark contrast to a summit or a peak or
journey across the desert to find
victory through many trials and
surprises we want our customers to
simply fall into winning practices by
using our platform and frameworks so 8os
lamda wants to help you fail almost
accesso fail succeed almost accidentally
so they can do this by imposing limits
so to be able to take advantage of the
good stuff like the scaling by default
and being able to it to be cheap they
impose some limits on you about the way
that your functions run and that they
should be quick and handled small
amounts of data there's either kind of
design for a particular use case so we
bumped into these a bunch so we hit a
kind of bunch of problems that we hit
these limits and have to kind of
re-engineer to work around them so
timeouts is one you get five minutes to
run your function it will kill it after
five minutes is all it is five minutes
and to get around that we added a
queuing system and that was fine
anything you're growing beyond five
minutes it's not really a good use case
maybe you could look to batch it up in a
different way data sizes so and there's
a few limits around the data sizes your
request and response sizes you've got
six megabyte limit on that you get only
500 mega temp space if you want to use
temp space but really why would you need
temp space really we've talked about
stateless so hopefully that won't apply
too much the deployment package that
you're sending up to AWS we go functions
in can only be 50 Meg's
but if it's getting anywhere near that
really should be breaking into smaller
deployments anyway so we got around we
hit this six megabyte request and
response size a few times we just had
smaller requests and that was like
patched it down into small requests
because we were chopping things together
there are memory limits so you can
choose between 128 Meg's all the way up
to 1.5 gig of memory that's allocated
and that's how you're charged so if
you're running out of memory you can
just reconfigure and allocate a bit more
but those 1.5 gig is currently the hard
limit and also when we did it there was
no compression so you couldn't gzip
things and pass them in that's now so so
you could argue that most of the
solutions that we had to come up with
resulted in kind of a better
architecture but the problem was they
were imposed on us and we had to at
times kind of frantically re-engineer
and it weren't done at our pace so this
is all about the slider of control you
handed this control over to the cloud
provider and with it comes from
downsides and this is kind of kind of
one them normally if you were maybe in
charge of the application or the server
a bit more you say you know what this is
it's not great this takes this long to
run but we can deal with it in the short
term there are more pressing priorities
and we're going to tack it at our own
pace later on so the trouble about doing
a talk about service is that every two
weeks you have to update it because they
keep adding stuff so just a quick this
is since we did the project stuff that
we would have used it would have made
our lives easier so I won't go too much
detail about these you can go on AWS
website and read about them but just to
show you the pace at which it's changing
so they didn't have c-sharp support at
the time which is why we use JavaScript
that is now there you can use that
environment variables have come along so
before we have to kind of push JSON
files up with our config stuff in they
now have environment variables you can
set and your functions will just access
them as they would any other environment
variables they've come up with a service
application model which is a bit like
tiles formation it's a way of kind of
templating your deployments that are
made up of API gateway ADA breast lambda
and DynamoDB kind of those three often
used together to easily kind of deploy
all of them at the same time they've
added said letter queues so by default a
lambda function is retried twice it
fails and before it was just discarded
but now it pops it in a dead letter Q
which you can see
scribe - and do some other functions to
exhale whatever reason even if it's
trottle door timed out or it's wrote an
exception or whatever you can pick that
up and do some other work on it scene
hostess if you're a lambda function with
processing payments chuck it in a debt
and it failed tracking a dead letter q
and then you could contact the user or
some flag to perform some action be it
manual or automated and they've improved
a cloud watch search a whole bunch
they've added more dashboard
visualizations they've added percentiles
you can get like 95th percentile for
things which is pretty good they opted
metric retention so before your metrics
would hang around and clouds or for
fourteen days it's now fifteen months
for free so it's charged pretty cool you
get down on the box they've added binary
data API gateway so you can gzip things
and send them in and you're a terrific
on the functions can take binary data
and and unzip them internally so it's
moving quickly and they'll be more stuff
and there's a whole bunch of other
things around lambda that hook into it
I've haven't even mentioned so it's a
fast-moving world so right okay if
you've had some opinions but ultimately
you want to know should you should use
them in benefits hold some pitfalls of
course I'm a consultant
so I'm legally obliged to not actually
give you a concrete answer it does
totally depend on your content and your
context but what I'm going to do is give
some bits of advice
so learnings our team took from this
what we wish we'd have known as a start
what we would tell to a new team that
was thinking about using these or a new
company it's saying you this land of
stuff looks call this server this stuff
looks cool where should we start so and
a lot of these when I was kind of
writing these a lot of these applies to
any new technology really you know
doctor looks cool what should we should
we how should we go about using it the
answer is not rewrite your core system
straightaway you know these kind of
apply to tend to be trying any EXO
nibble at the edges of your technical
technical estate don't go all in so some
suggestions some of which we mentioned
any scheduled jobs you've got almost
every organization I've worked in have
some scheduled jobs whether it's log
cleanup or you know archiving dates or
anything like that they're really good
for that because they're not
mission-critical if they fail find
you've always run them manually but
they've got the timer built in you could
use them for that log streaming an
example
we use it for you need to be logged from
A to B great that will work fine web put
processing something with this need to
be hit run get out there works great you
don't have stand up an application just
have a QM points on it chat box again
there's lots of libraries that exist out
there for helping create chat BOTS and
with with functions as a service and
proof of concept you need to get an API
up and running pretty quickly fine
good example use it this run them in
production for a while then evaluate
monitor and evaluate so the pit of
success from earlier so dive into it
smiling gleefully up fail gently
downwards and so you've used server
functions that say around the edges of
your system you think now we like where
this is going want to use them or
something a bit more mission-critical so
even though it looks tempting to leave
in we've got those limits that I
mentioned you know you've got a lot of
unknowns let's be careful about it so if
you're using for an API know your
traffic profile you should know this
anyway really but you know what those
limits are just do some basic maths and
work out how long them I you know how
long does it takes the pro search each
of these requests what are the data
sizes am i comfortably within those
limits or am I going to have to do some
reengineering first before it will kind
of fit into the traffic area the
expected performance or expected inputs
of them of lambda monitor and logging
from the start again this could apply to
anything but how can you make decisions
or know if you're getting close to
anything if you have no idea what's
going on so based on from the site
they're very easy as we saw to get logs
and graphs and stuff in there so just do
it right from the beginning and then
you'll be--you'll you know you'll have
much more data to be able to make those
decisions with safely replace existing
system you know you can deploy in
parallel and route traffic to both do it
starts launch where it's being fed
traffic for it's not actually being used
as senders discarding it so you can look
at the forms have high-level functional
tests that pump data through so that's
what we did in our system we kind of had
these services joined up but we would
fire in an event at this end and check
called it came up pops out here kind of
kind of a diagnostic of the
implementation in the middle so just
again this would apply to us using
introducing any new systems but think
about it as well and have a back out
plan
have a you know leave those switches in
for a while so you can just turn it off
and fall back to your old old ways so
this is a contention of mine and one of
those things that may not be langree on
another one those things as made people
angry on Twitter and around services
this whole hashtag no-ops thing so you
know in the extreme case you see people
think are well serviced well it scales
and it monitors itself you know we don't
need our operations team we can fire
them you know and move on that is not
the case
no way and just because you just because
you don't have to maintain servers fine
you don't have to set up auto scaling
fine that's kind of pretty much it like
all the rest of operations you still
have to take on so it's very small
subset you're not responsible for and so
you're going to need those operation
skills and mindset in your team more
than you ever would anyway so you know
all things like log aggregation
monitoring alerting the infrastructures
code to deploy your estate notes if your
functions continuous delivery and good
deployment practice and testing practice
all that stuff which applies to kind of
any system really that you want to build
you're still responsible for and you
want to really work with your operations
team on that you have our operations
team however it works but it's not a
suddenly yes developers can go crazy and
not care about that stuff if they will
it will take our some of it for you but
if you just don't even think about that
it's going to cause you a lot of a lot
of problems so another one which
hopefully is kind of a given but it's
increasing with a platform dependency so
anytime you go to the cloud you say
right we're going to run our application
in the cloud you're obviously taking the
dependency on that cloud provider
BAW we're the Amazon or Microsoft or
whatever and you can mitigate that by
going to you know some people will go
multi clouds falling but you're still
kind of tied to them the prices keep
going down but if they decided to hike
the prices up you know what could you do
and if they have an outage you are tied
to that outage hopefully they will do a
better job at managing that than you
would if you're running yourself but
still resides them however with lambda
you're kind of tied even more in because
you don't have that standalone
application that I mentioned earlier you
don't have that dotnet web app you don't
have that
node app that you could just if trouble
came lift and shift onto another
platform you're tied more to that cloud
provider your toy to the interfaces of
those functions so it's worth bearing in
mind you you can do some stuff you know
put some aggregation some kind of layers
of abstraction into you could lift and
shift it at the end of day still code
that code could be moved around but it's
you're tied in more tightly so it's just
worth bearing in mind and on the further
level you should decide to use any of
those frameworks that we talked about
like serverless or Claudia you're tied
to them as well you're tied to their way
of thinking their opinions so applies to
anything you know when you take on any
technology you use any library any
library from you get your kind of
coupling yourself to it you got a thing
if this is a long term thing is it's
going to actually cause me problems in
the future so go into any coupling with
your eyes open
proof of concepts and spikes first see
if you like those opinions and have a
and keep your kind of options open early
maybe before you work out if it gives
you so again towards the ends of a
summary so we talked about what is a
service architecture talks about them
being internet based systems where the
application development of user usual
server process relies on third party
services client-side logic and service
hosted remote the feature calls
functions as a service functions of
service stateless scalable by default
short lives can be triggered from a
variety of events and hooked up from
loads of stuff api gateways are a
classic example we look at javascript
Nannette example we then looked at some
tales from a world without servers we
looked at scalability and cost and
testability or probability security
deployment frameworks we looked at the
pit of success we talked about should we
use them we looked at the techniques so
nibbling around the edges trying things
out on the edges of systems we look to
some examples that you might use to do
that one thing is for sure they like
this server list is not going anywhere
it is it is growing I mean you can tell
just by the amount talks that are on it
here and there a consultancy springing
up all over the place now that just do
service consulting and Netflix is all
over it obviously but the cloud service
offerings will keep growing they're
growing crazy at the minute all the
surrounding ecosystem all those
frameworks continue to grow
if you can take advantage even the
considered and works acute manner and
service architectures can absolutely be
a game-changer so further readings he
wants it there's a good article on
Martin Fowler's website like colleague
of mine battery Jamaica romance so as a
thought Works employee again I am
contractually obliged to mark mention
Martin failed at least once during the
talk and this is it so there's a talk
here on his site and is another one by a
chap called Mike Roberts a bit more in
depth goes into it
about why you should use them so I've
tried to be fair and give you the pros
and cons but if you want the service is
going to change the world you need to do
it now or you're screwed then
there's an article by Simon Wardley why
the fuss about service which is a very
strong opinion in favor of it and got a
lots of attention there's I saw this
being circulated around a lot a couple
of quotes from it is that service will
fundamentally change how we build
business around technology and how you
code he talks about containers which is
interesting because we've kind of
touched on containers it's kind of a
similar approach but Simon's point view
of containers they are important but
ultimately invisible sub systems and
it's not where you should be focused and
finally that's the big one
he claims is he said you thought DevOps
is big but it's chicken feed compared to
this and this thing so look this is
where the action will be it'll be with
you quicker than you realize and yes
you'll have inertia now is not the time
for building a DevOps team and heading
towards infrastructure as a service
you've missed that boat it's gone you
should be catching this waves as fast as
you can
so skate to where the skate to where the
puck is going not where it is now so and
thank you very much for listening and I
hope you have a great time goes to the
conference and please come and chat to
me offers if you dabble with service
you've got some stories got some
questions and please from an ask
I would love to update this or some
other tales from other people but um I
think that's it and thanks very much
have a lovely day</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>