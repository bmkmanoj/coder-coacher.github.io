<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Composing high performance process workflows with Akka Streams - Vagif Abilov | Coder Coacher - Coaching Coders</title><meta content="Composing high performance process workflows with Akka Streams - Vagif Abilov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Composing high performance process workflows with Akka Streams - Vagif Abilov</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/kWU_LxYXMjE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good afternoon and welcome for the first
after lunch talk of the conference who
attended that another talk on streams
it's I think data streams for fun and
profit by David Ostrovsky earlier today
yeah if you odd David presented
available providers of live streams of
data and he also showed what is
available on GA am on dotnet and gave us
a little bit of classification and when
it came to dotnet to show that it was
only Orleans which was available and it
it may have raised the question okay so
if I want streams of data can I use
anything which is ready for me
and yes you can because if you just
don't rely only on streams provider by
vendors there is actually initiative
which lets stream almost any sequence of
data and it's available on multiple
platforms and it doesn't require you to
know the low-level details of actor
model programming or reactive stream
interfaces so it might look like
extremes
it's a junction to technologies and it
requires you to know more low-level
details but actually its opposite so
this are we'll be talking about it
my name is Rajeev and I work for
Norwegian company miles we are one of
the sponsors fantasy conference so if
you looking for a good place to work
then come to stand and talk to us or if
you are happy with your company but just
want to grab some Italian food you can
also come to our stand and talk to us
so enough marketing pitch let's go to
technical staff there is no prerequisite
text text me preface for this talk you
might be familiar with some of these and
that probably give you some
ring some bells for you some common
scenarios but none of that is required
to understand how extremes work and
we'll spend probably like 15-20 minutes
first to go through the motivation line
to explain how you can not just how you
can get to our costumes but why there
was a blog post which I think from 2015
but I just recently read it and it's
explaining why why it's so hard to
explain Manas to people it's everlasting
story like people try to explain moment
and people don't get it and those of
this article he said that one of the
problem that we often get excited about
things and we forget that if you want to
sell aspirin we need to know that this
other person it knows what pain is and
if you can't just explain what pain is
because if you have never experienced
pain you this cannot be explained
so if extreme is after in that what is
the pain so what can be the road to
occur streets and we'll try to identify
as a few ways towards extreme and first
this is actually my story story of my
last year and half approximately I've
been doing acha acha dotnet development
and as for today even though we're happy
with results we are getting I see that
some of the things some some code could
be written in more compact way and I can
focus more on high-level abstractions if
we use our curse dreams then if you
familiar with reactive streams this is a
Kaseem gives you the ability to use them
in practice without going through
implementation of the interfaces then we
will be shown some extremes building
blocks and this alone might be
convincing for you to try how extremes
work finally arca streams are built on
so-called reactive extensions will come
to them later which implements are
called back pressure we're published and
consumer of data they can dynamically
agree about suitable data transfer rate
and this is a quite neat feature and for
many of us it can also be point of pain
because who can honestly tell how many
messages your system is capable of
tackling and what happens if it gets
overloaded so I can achieve back
pressure it gives us opportunity to
avoid that to have contract of how many
messages we get on each processing stage
and what happens when if buffer gets
overloaded so first road is from actors
to at the stream this is a slide from
presentation that me and my colleague
Alan tweak we gave another NTC
conference in London this year and we
tried to explain other points of pain
that led us to use active model everyone
who has been working with enterprise
applications that require multiple
threads and high availability know how
hard is to provide manual thread
management thread synchronization and to
manage shared state so these three evil
faces was for us one of several reasons
why we decided to give akka a try and
even though we are in general happy with
our choice but of course every
technology has its own limitations and
obstacles and there is a claim about
actors that actors do not compose this
one of the blog posts that at if there
are a lot of reference if you google to
this blog post that since actors send
messages to each other then an actors
some rental messages they use addresses
of in inside ecosystems this is
ecosystem and these are addresses so we
have an actor and it sends messages so
it
it's sort of hard-coded of course you
can use dependency injection but as
actor model is defined this is quite
obscure what happens how messages are
floating with an actor system around
cool
one of akka architects he he disagreed
with a regional claim but he tried to
rephrase it saying that what probably
people mean when they say that access do
not compose and since the only way to
communicate with actors to send a
message so basically you have a method
send message which is void or unit and
in this respect there is no composition
between actors because if you can't
build a functional pipeline if function
is doing to turn anything so those who
are familiar function programming know
that this pipeline operator and it works
very nicely if you have functions that
you turn something you transform to next
next next level next chain and you can't
do this with actors then a kun added
commented saying that actors do compose
actually in the same sense are our human
society compose and you might think that
this is kind of different context to
what social human society have to do
with actor model but if you think about
how we people communicate we communicate
using messages and we we do compose
great teams great families and those who
attended gig beer yesterday I mean it we
compose a good beer party just by
sending messages to each other so this
is the same way actors work but still
from technical point of view there is no
composition or which which let us build
functional pipelines using actors
another thing is that often when you
write actor code you write quite tiny
code and then on the top of it there is
some boilerplate code and it's okay if
you have a large implementation but if
you
have to write this code like everywhere
in addition you have similar code to
arrange actors to have functions like
pre-start post start and so on so it's
quite a lot boilerplate code so you may
get lost in a in a large code base
losing actual understanding of how
communication goes so what if we could
use still use actor model but describe
the data flow process differently
focusing on a high-level composition
like link here everyone of course who
does dotnet and even who doesn't
from among developers familiar with this
link statement so you can just chain
using fluent in text link statements you
don't need to write a class yourselves
that implement join aware and this is a
nice functional transformation like here
this is a codon F sharp and even those
who know familiar this effort actually
can get a picture of what's going on
here we read the content of a web page
and then we extract words from it and
then we run spellcheck in control so
it's here we compose our flow processing
flow can we do something with actors
actually we can so this is a actually
our first exposure to extreme do you
know what language it is written in
scala of course Scala
so this is other streams you see there
is no code that man you create any
actors what happens here that we define
some source this out stream source and
then this is think we just ignore
results but we do some interesting stuff
here we define broadcast and merge and
then this is also called in Scala by the
way so from source we send data to
through flow and flow just adds them to
all numbers then we broadcast these
numbers and then on each next stage we
also add
ten then we merge this data and then
again add ten and then we send to sync
so it's very compact actually very neat
way using Scala to define streams
probably for some developers it will be
after seeing this cause they can
consider switching to scholar because it
really looks neat if you look at a
c-sharp
this is yeah so what this code shows us
is that we can unlearn actually our
ability to create individual actors and
instead we can learn instead how to use
high level composition primitives so we
focus on our workflow and our framework
internally we'll create and connect all
these instances of actors and coming to
C sharp this is very simple table the
simplest octa stream in c-sharp
we have a source again enumerables and
then we have some flow we just multiply
numbers by two and we write everything
to console and if you want to create
something more complicated and this is a
graph g7 C sharp it's it's called also
grab this cell like in Scala but there
isn't not much graphical here still it's
quite easy to understand what's going on
here it's just one page you see that we
add broadcast and merge then there are a
couple of flows so we actually create a
counter and with some counters we
created some aggregate even though aqua
stream has its built-in primitive for
that but this is just to show how you
can do it in a different way and then we
merge data and return flow shape which
is a graph which can be processed so
that's one way one road to extremes if
you have experience with ARCA writing
actors individually you can actually
have alternative way of running your
workflows with another road from Roxy
streams to extremes what is reactive
streams it's in an initiative with
several large companies behind
that decided to provide a standard way
for a synchronous in processing so they
defined minimum set of components and
interfaces that stream provider must
support so these streams can be actually
combined in a single processing workflow
and one important quality of such teams
will be the support back pressure but
pressure is as I mentioned in in the
beginning it's a its ability to
dynamically agree about a message rate
between a producer and consumer message
so there are a few original if the
beta's in this initiative and light band
used to be called type safe at that time
and there are four components publishes
subscribe a subscription and processor
that reacted stream specification
requires and there are four interfaces
interface are very simple and it might
look like it's simple to implement them
because publishers have one method and
subscriber has four then we have
subscription with requests and counsel
and process it doesn't have any its own
method it just derives from publishing
subscriber but in fact those interfaces
are not meant to be used by client API
they're to be used by those who
implement stream sources so these
interfaces they let us to support very
important feature which is called back
pressure what is it about you may have a
slow consumer of data what happens if
the stream uses push model and publisher
just keeps pushing data on the
subscriber
well then subscribers sooner or later
will be overloaded to these messages so
push model doesn't really work for slow
subscriber but it's not efficient if we
use pool model and then the publisher
this law because if subscriber just
keeps on pulling data and there is
nothing to to get then this
communication will become inefficient so
what directs streams
vacation implement enables is that
publishing subscriber they can switch
between pool and push model dynamically
within a single session depending on how
fast communication goes so this is
example of test of dynamic of back
pressure on a passive link publishing
subscriber originally publisher was slow
they just added thread sleep to publish
and subscribe of course followed and
received messages on slow rate then they
made subscribers law so it was capable
of consuming about 20% of its publishing
speed and publish followed immediately
then they removed all breaks and all
data was consumed at high speed and
added slowness again works fine and then
then finally removed and publishing
consumed as a process data at the
highest rate so this is illustration of
this dynamic push-pull agreement between
publish and subscriber
so after streams building box they
include various sources flows and things
so a source is a processing stage with
exactly one output you can have multiple
sources that give you data but each
source it just it has no input it just
gives you the data this is your
originally where your sim stops then I
think it's where your data may
eventually come it's a stage with just
one input and then we have flow flow
according specification has exactly one
input and output although developers
often relate to flow as stage with mods
with at least one input and at least one
output although strictly speaking it's
not a flow at the graph graph it's a
combination it can consist of flow
sources and things and not every graph
is runnable only closed shape is
runnable which means that if you have a
graph with open ends you can't run it so
you have some sources you have
to stream the data somewhere and that
eventually data must come to the sink
then you have a runnable graph if you
look at built in source stages for
extremes there are plenty of them and
I'm now showing you a cadet
implementation for Scala it's different
although there is a lot of similarities
but some of these are just a cadet net
for example is from a numerator if you
have ienumerator you can get a stream
out of it from gives you from any
enumerable so actually if you have any
sequence of data anything that gives you
either mobile you can make a stream out
of it at the stream here are built in
sync stages from ignore to some
aggregates like aggregate and some and
of course you can just stream data right
to files or you can send them to some
actors so there is a lot of
possibilities and even big a number of
built-in flow stages and it looks like
link statement or link link expression
types in a way I think there are
probably 83 link expression types and
it's comparable number of built-in flow
stages so once you get data you can do
various things with them like MapReduce
filtering buffering throttling all this
available no matter what is your stream
source so this makes it attractive even
if you not familiar with akka or
reactive streams you can just start from
scratch basically get some ienumerable
as a stream and then start preserving
them stream needs to be materialized so
the actual stream specifications as we
saw it can't be run without active
system so we just declare a stream and
like a link statement if you have a link
statement with some link providers they
have so called deferred query execution
which means that if you don't have this
to list and this is a link statement
that you
use with a single server you don't get
any data until your materialize them and
utilization is just a call to lease to
array single first to default anything
that actually require actual data
retrieval the same is with streams this
is just a blueprint so it's a
specification how stream should work and
in order for this stream to work you
should create an octave system and this
is as easy as just calling active system
great so you don't really need to have a
knowledge of how active system works and
then you create materializer which is
disposable object you can equally
materialize three multiple times and
probably will get different data if it's
a really live stream and then as long as
you have a runnable graph you can just
go run and you will start getting later
then stream can produce materialized
values if you think about stream
processing stages you have source you
have some flows of sync on each stage
data are coming and leaving the stage
and if you don't retreat them if you
don't specify that you want to get hold
of them they're not used and so here for
this dream we have be getting a runnable
graph of not used which means that we
have a stream we can run it but it
doesn't produce any materialized value
even though it's actually in this think
it actually populate the list but this
comes just as a side-effect
alternative is to run stream to
materialized so you want to produce some
addressed value of some of the running
stages so here we have a sink where were
some integers and we can say that we
want to have a right part of this
processing stage to be materialized so
we want to get this data so then we
getting not runnable of not use we get
runnable of tasks of int and we can
retrieve materials values from multiple
stages and then here we will have some
tuple
of values so this is very convenient way
of just taking care of intermediate data
without going to infrastructure level so
how do you consume extremes what do you
need to do to start consuming them of
course as we saw that building sources
business or stages they provide wide
range of streaming data and the easiest
is just use from a numerator or from
from input stream profile if you're
using aapke and you're using persistence
actors then you can use a persistent
square it's a module that lets you
stream data from event beta event
database of actors so you get either
life of snapshot stream a bit of
historical stream and then it's open
source initiative is called out Parker
connectors both on Scala and dotnet and
like with David's talk we showed plenty
of application from Gigi a.m. and just
one for dotnet here the major of
connectors there are 4 GB M so this is
just extract from the list you get much
more we have Kafka of MPP and so on
HBase when it comes to dotnet the list
is currently quite modest it's a utter
we have storage q7 hub and service bus
and we have signal R and I'm QP is in
work and this is a quite fresh tweet it
was about 10 days ago David Fowler he
said that now signal our friend with
reactive extensions and butter is one of
key contributors to a cadet net he said
that by the way we we had this connector
thing off for a while so if you're using
signal you have a stream for that now so
now as we have gone through some
definitions of what streams
how they work then let's go through some
cases we've got we'll go to a couple of
small case studies first if it's
actually how I was exposed to extremes
in our project swimming event journal
and then later we'll look at how we can
stream commits so everyone who is
working with streams create examples
with reactive streams like swimming into
it that's probably the most common
ground for twelve developers so a
streaming event journal so this is a
dashboard that we have in our project
and it's actually it's a dashboard that
is dynamically changing all the time so
it shows we distribute some files and it
shows the status of files that we'll be
distributing it's a Cabana dashboard and
it's based on elastic search index and
it shows data that's populated based on
some actors that we have persistent
actors so this activity dashboard and
these are principles that we used to
build it elastic search cabana who is
using elastic search yeah more than
happening and index like with elastic
search indexes it's recommended that you
don't use them as your primary source of
data you just create index and we create
them on demand typically when we change
the model the the layout of a bunch of
data that we want to show that this is
ongoing project so it's changing so and
I'll react our position axes are stored
in event Journal which is based on
sequel server and this is stable and we
don't have a control over the of this
table it's actor this is event journal
table but we need to in order to build
our dashboards we need to create indexer
that first gets historical data from
event journal from SQL
and on the top of it will run the life
event that our persistent actors receive
so we started thinking with my colleague
parallel banker about how we should
build it and then whatever solution we
came with is we were not really happy
because you have this relatively small
piece of code that we don't really need
for to solve our domain tasks and then
we need to do something to grab data
from sequel server and then in to
synchronize it so we start from where it
ends we start with life events so we're
not happy with what we're getting until
its structure that we could use just
ARCA streams because our provides
persistent query and there are six
predefined specific queries and this is
what we needed
so it's event by tag and current events
my tag all we start with current is just
a snapshot from the beginning of time
until now all that doesn't have current
it's a life event but you can actually
give them from the beginning of time so
it starts from the first event ever
received by actors and then it continues
streaming all events and then just
fluently goes into life events so this
was exactly what we needed we didn't
really need to build this hybrid
component that takes things from signal
server and then combine them with life
events and this is a resulting code and
you can recognize probably already that
this is something about extreme it's
written an f-sharp but it's very similar
how we would have written in C sharp
because it's this part is common more or
less so we have event by tag and they
apply certain flows to that and then we
send result to elasticsearch so this is
example of once you get hold of stream
of data how easily you can use it to
produce things like dashboards
in this case and how little cold it
requires you to write because of these
primitives that available to you and now
something that probably more usable for
everyone it's how we can stream tweets
its rectified it's a sample that written
boss for actor scholar and a kebab net
and I have written my own based on their
on the same library which aqueduct net
uses Scala uses different but a cadet
net using open source library called
tweet and me
so this line provides several streams I
didn't want to filter anything I just
wanted to get sample seams so I will be
using sample stream and tweet and it
doesn't support reaction specification
which means it doesn't support back
pressure and you have to do something to
convert it into a reactive stream debate
based streams but that's very easy
thanks to a lot of available primitives
in extremes so what we're going to build
we will start with very simple workflow
but then eventually we will have a
broadcast so these are tweet feed
sources we'll run them through broadcast
on the first channel we just format them
and send to merge on the second channel
it will throttle them because we are
going to send them to weather forecast
service and if we send too many of them
then they can ban us and so we get back
results and then we format results and
then we merge everything and then write
to the console so let's see how this can
be achieved so I'm switching to visual
studio okay and yes I need to pull it in
this monitor
so first is this is a program and here
we have huge cash tweets false so first
we will try with live tweet but with
live tweets we don't get them at very
high rate and also usually most of them
don't have locations but I want to play
this location so that will then I will
switch to cash tweets so first is just
to demonstrate if we can get live feeds
from Twitter so let's see how it works
so if I go to you choose yeah so this is
a method to get our last we'd start with
stream so we this is tweeting we API
create sample stream and then we
register some event receiver so what we
do with it
like okay here this are the extreme that
we define source flow and thing so what
we do we create an actor and we send
live tweet to this actor then we create
a flow where we format the street and
the same to sync the just writes
everything to the console so if you run
this program
yeah so here we're getting a live stream
of tweets from Twitter that was simple
but it doesn't show us really advantages
of occur streams so now let's go to back
to program hard times risk yeah
now we set use cache street street queue
and the first thing which we try we we
just try cash please and here the
difference you could compare the trash
Queens series if you compare with how we
get life with these life speeds we
created it from actor but here we
already have file with cash twist we
just create cash trees from enumerator
very little difference and if you around
this program okay yeah we're getting
tweets on a much higher rate because
this is just contest on the file but all
the the format is the same so now what
we're going to do next if we try to see
twitch with this broadcast so now we'll
start broadcasting them and this is how
our graph will look
so here is something more interesting we
have a tweet source the same source and
then we sending data to two channels
first channel is a tweet will be
formatted and only user name will be
written the second channel we will just
show only tweet coordinates then we
merge both channels and we send them to
the thing so if you do this if you run
this program yeah see we're getting two
channels and at the same rate this name
also user and coordinates where he was
tweeting from so we getting more
interesting results now so next thing
which we are going to try is we have
tweet with throttle let's see how this
is implemented we could stop
yeah so here we have a broadcast these
two channels and let me start throttling
them so let's try to throttle them first
without using buffer here so the
throttling at the same rate like we're
sending ten messages a second and see
what happens then yeah you see that they
are we getting these tweets and they're
written at the same rate so now let's
change this and instead of having ten
assists for second in a second for the
coordinate Channel
we'll just use one message a second okay
where is my coordinates yeah it's here
so what do you think will happen so now
we request tweets at the rate one
message a second on one channel and ten
matches second or second channel will
they get messages at different rates or
they will get both that first one
message a second or both at ten that's a
second who think they will be getting
message to different rates very few that
they will get majestic messages at the
lowest rate bit more hands and they will
be getting messages at the highest rate
nobody actually they will be getting
messages at the lowest rate as we can
probably demonstrate now
Sorry Sorry
uh-huh let me see okay
oh yeah I'm so long yeah so it's wrong
if I go to mr. O'Toole yeah I mean this
is the the throttle and then I have we
are ten and then we want to have one
here
I'm turn there let's try again
thank you yeah so now this is it looks
like this so you've only just one
message a second and why is that because
we have a source stream source we have a
broadcast and then we'll request one
message a second and the request a
message a second but the this stream
source is just one it's a think of theme
source so it can't start producing seems
a message to different rate so what it
does of course it satisfies the lowest
requirement and this is how it works
so back pressure from flows the
strongest requirement will be satisfied
but this is not what we want so what can
we do you go back to to this file and we
introducing a buffer so here what we say
we want to buffer up to ten elements and
if we just let's have it here one buffer
here and here then yeah so we want to
bother a up to ten elements and after
that we'll just flowing dropping
data that overflowed the buffer yeah so
now we're getting one tweet one
coordinate a second and 10,000 a second
oh sorry
don't names a second so now we see that
this different flows they receive data
with a different rate why can this be
useful for in our case we want to send
the coordinates to weather service and
then we don't want to be banned so if we
look now at the last file which I
mistakenly took for real this time
so here it is yes
so wherever just users here created by
and here the channel that get tweets and
we have buffer and throttle and the
throttle data be sending to Weather
Service so here you select I think so
this is one of utter primitives actor
has a boss select and select a thing and
install it's got my passing so we can
just map a synchronously our data to
some external service and this is a by
the way it's a relly lism so we want to
do it in parallel up to 5 connections so
if you run it now then we should be able
to
no it's not it's I think I think I
didn't change the in the program yeah I
didn't change what runnable drop I want
to use weather okay yeah so you see in
the beginning actually it was buffering
something so we saw more weather
forecasts in the beginning but now we
see names and approximately for every
tense name we get to organize oh sorry
we get better coordinate sent to weather
service that returns back the weather so
to summarize what we have seen and the
examples we have gone through with akka
streams I first thought about writing
some bullet lists of takeaways but then
I thought that it's better probably to
have some final thoughts or more
conceptual level because the extremes
started developing approximate design
where we first heard about serverless
and those two technologies that are not
comparable technically because serve
less it's much more spread extremes and
streams in general it's a much more
narrow than service but like we serve a
less we go from server bound computation
towards setting up environment where we
don't care where which service will be
used to run our domain communication
rather all right I'll run our business
workflow so of course it will be run on
some servers and probably on the bigger
number of servers then if we configure
everything manually but we sort of don't
err and this is conscious choice which
let us focus more on solving domain
specific tasks the same way those of us
who have experience with akka we will
focus on active bound computation like
we were creating actors we were
carefully designing communication
between actors instead just like with
link statements we run this we create
using grab yourself the graph that shows
declaration of what we're going to
compute we define sources flows and
Street and things and active streams
using stream metallization and let us
achieve same results with the same
performance but in much more code
compact way and shifting our focus to
our domain specific tasks rather than
focusing on infrastructure on plumbing
so this is what probably sort of the
main takeaway which I would like you to
take from this session and this how much
time we have yeah we have some time so
this completes my technical part of
session but I often complete them with
something which is not technical and I'm
going to present you musical
implications of interpretation of what I
just said which is called extreme right
we're going to go through some extremes
primitives which will make it easy for
you to use extremes in practice so if
all the works let's and you can sing
along of course
this is up the street and this is the
source that pieces at the street this is
enough at least that much from the
source they feed the artistry this is
retarded force Matt I think that mask
from scissors that be state actors dream
this is image that flag from broadcasted
for smashing that mask from the source
that piece take up the stream this is
amount that electrons emerge the
electron broadcast the port mapping this
map from the boss that we will act as
dream this is the balance that we fail
to notice the leg from the merge desk
electron drops out that both map I think
that math from the for that piece these
actors dream this is to be that combined
on the talented pieces you know that
electron beam a desk electron the star
performer I think that much from the
source that people act as dream this is
the drug that really from busy that
combines from the balances pieces will
notice connect on the method selection
discussed at both maps in this map from
the 3rd St the actors dream this is that
while that pull from the drug that
remove from the Fitness conversions and
balance and precinct and all that
connects on the madness collects on the
darknet both laugh I think there's math
on this all that these three actors
dream this is a struggle that people
acquire they've put from the group that
remove from the piece that combines of
the diamond that difference in load
estimates of the magnet
I said I've got the first mass of
investment from people that B we packed
up dream just a bit of law that don't
like the throttle that we sounded while
that proves on the drop that we move
somebody that combines on the Ballon
d'Or pieces notice collect from the
merge that collects on the process both
mass in that mushroom because their
feces actors dream this is the think
that feel from the applause that don't
back the throttle that big sound that
one that pulls from the drop that
removed from the reset combined from the
talent that we fail to not that select
want to match that the like from the
start that faults master things that map
from the first that feeds these actors
green thank you enjoy the rest of the
conference and I think you still have a
few more minutes so if you have any
questions that I'm here questions yeah
yeah you can I didn't go into details
but you with dreams you have difference
between error and failure of course when
stream fails it's like it's done that's
it but individual elements may fail it's
just an error and you can still continue
processing and yes you can of course
that that would be more code to write
but you can you can back up with
supervision strategies that that
provides like individual handling on
each processing take more questions good
question and I didn't mention in my talk
for the time being
there is no distributed motivation for
ARCA streams that means that the stream
declaration will be run on the same node
of course you can call external services
you can run at a enclosed environment
you can so different stream instances
may be run in different across the nodes
but you can't split processing stages
between different nodes so it's only
local scenario for the time being and it
looks like for some time because I saw
discussion on forums and then people
from Scala Hockaday some contributors
said that it is not going to be
prioritized in foreseeable future and
probably it means that it won't appear
on academic two more questions okay
thank you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>