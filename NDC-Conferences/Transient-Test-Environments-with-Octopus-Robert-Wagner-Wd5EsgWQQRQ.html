<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Transient Test Environments with Octopus - Robert Wagner | Coder Coacher - Coaching Coders</title><meta content="Transient Test Environments with Octopus - Robert Wagner - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Transient Test Environments with Octopus - Robert Wagner</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Wd5EsgWQQRQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">thanks everybody for coming to my talk
I'm Robert Wagner I'm
versus the lead today I'm going to take
you a little journey through setting up
an integration test environment from
scratch every time so here who who has
integration test put up your hands
good good who leave your hands up if
you've got if your integration tests
test more than the one project just odd
yeah so you've got multiple projects
there and pull into any integration
tests no not not to surprised they're
really hard to set up because you've got
a lot of dependencies you need to manage
and get in there particularly if you end
up with in a microservices you might
have 3040 things you need to deploy onto
the one machine - or the one environment
to get a full end-to-end system working
that's hard it's time-consuming so we
usually just have the one environment
called UAT right the right or staging
right the thing you do just before you
go to production and there's only one of
them who's got multiple test
environments yeah cool awesome
are they are they automated or they
manual manual
hen's right okay cool okay no so I just
want to know a little bit more about you
guys who's who knows about cloud
formation has used it oh yeah good good
good
I'll show you that then what about
Packer No okay awesome cool so uh good
thing I won't be covering things that
you already all know which is great yeah
that's the whole point so what I'm gonna
do is I'm going to show how when you
create a brand I'm gonna create a branch
in a repository pretend to do some work
and then show you how you can stand up
an environment from scratch just for
that branch and optionally also taking
other projects which you've used say the
same branch name and may change I see so
you had two projects teds work together
and a third one and deploy use octopus
deploy to automatically deploy the right
version into that test environment so
that you get an environment that looks
like production except for your changes
every time
cool so I'll show you off I went to I
didn't go to talk to you about all about
the one about the lifestyle companies so
I decided to last week start my own
lifestyle company so please don't steal
my idea but I'll show it all to you
right this I've decided to go have a SAS
product it's it's to do with mass it
works at the highest common denominator
of two numbers that's the code it's it's
beautiful it gonna be the next unicorn
and it's gonna make me Millions alright
okay so anyway this this is the example
web service it's NBC app and I'm going
to be deploying it to Linux to a number
two box let's have a look at what's
who's used octopus before yeah okay cool
oh my go to vine to all the features but
this is this is the my environment or my
ecosystem I've got three projects mine
next new big unicorn system and the two
things that really relies on your
requires rot13 encryption and a widget
spinner because apparently everything
everybody needs whatever those things
are right so what I want to end up with
in this integration test environment
here is I want to end up with this
version from production plus my branch
of the widget spinner I've already made
a change on and my new change from the
highest cannot comment denominator
project and I'll set up a little test
project here just to corn ate everything
and make everything hang together yeah
cool so first thing I want to do who's
used octopus tenants yep who's heard of
them before
okay cool who are those who's heard of
them before who understands them
alright they're not they're not the
easiest thing to graph so I'm gonna give
you a quick pitch about what they are so
say so you had a white level products a
hotel booking website it's just one
piece of code but you need to deploy it
per client and say for each hotel so a
core gets its own deployment Hilton get
to know your deployment
might be on different versions it's not
a sat it's not a SAS products more per
client hospitals as well you know you
each hospital may be on a different
beliefs cycle and some may the month
later some may just want to freeze for a
while forgot a big thing on and that
sort of thing it's a multi-tenancy you
set up a tenant on your project one per
client client essential end-user so you
set up Hilton and a core and so forth
right and deploy your product to that
you know I'm gonna Bews this feature and
set up a tenant per branch of work you
could also apply the same thing and set
up a tenant per developer so I develop a
machine it becomes a tenant with its own
tentacles and owns deployment target and
deploy use octopus deploy to deploy your
30 micro services that they don't need
aren't working on but need to make to do
end-to-end development testing right so
your client instead of cloning cloning
the Bri 30 repos making sure they're up
to date building them executing them
just use something like to push deploy
to put those services on to that
person's machine in Deb's mo obviously
not in private not for production but
and and then whenever a new release
happens you can automatically deploy
that say the other team is working on an
update and releases that the production
you can then use octopus deploy to
automatically deploy that to all the
other developers you know nightly or
on-demand or immediately right so
they're always working against the
latest other code otherwise they might
be three weeks out of date because they
just haven't pulled from getting built
in three weeks of the other project data
not directly working on so tenants are
another dimension so you usually have
projects and you move them through
environments tenants provides another
kind of slice of granularity in your
deployment so you may not have a tenant
in development or testing but in
production you may have a hundred three
hundred tenants and you use three
different slots to deploy to you know
they can a each have their own machines
and so forth so that's that's tenants
so what do we want to do is we want to
create a tenant anytime in github we
create a branch
alright just just to set up it's a
little a little bit of contrived tonight
but I want to show how you can use some
automation as your functions to automate
octopus and Link it with your other
services the other dev tools
so get github has web hooks and octopus
has web hooks so you can respond to
events write a little bit of a sewer
function or a lambda function to China
join the two systems together if the
system doesn't do something out of the
box you can just write that yourself you
know like Auto scheduling tasks we did
we we don't have a Tasker so if you want
to deploy a project every day we don't
have that out of box but you write a
scheduled as sure as your function to do
that for you okay and since they cost
you practically nothing it's almost a
no-brainer so here's me as my sewer
function if if you haven't used a sewer
functions before there you can either go
through the web UI to edit them or you
can upload via our source control I'm
just going to go through the UI and set
it up because I'm a dirty dirty hacker
and um but I'm using his dual function
because I like writing c-sharp so if you
get to this screen and you're confused
by can't find many options it's because
you've used this this plus button
instead of this plus button
it's create a new function and
thankfully the Azur team has actually
given us a pre-baked web hook web hook
handler for github so i'm going to
create a github webhook called create
tenant create a cool and save time I'm
going to upload the code that I all the
code up did earlier
cool okay great resolution change
windows so what I've just uploaded is
I've got an image that I want to just
set on my tenant just for fun I've
uploaded a project up Jason so this is
dotnet cool thing where it tells it what
framework I want to compile with and any
new get dependencies I want in this case
I'm using the octopus library because I
want to talk to the server and tell it
to go do something
I've also so this is my script which I'm
going to copy into the thing that is
going to get executed when my function
gets called so this kind of function
runs whenever the API or the URL is hit
with some data so github is going to
post some data to this function and I'm
gonna get it here as a HTTP request
message is that big enough for everybody
to read yeah cool shout out a shout out
if you can't see anything I'm gonna I'm
gonna pull the the branch name out of
the data which is the ref the new branch
name and then I'm going to connect to
the octopus endpoint and create a new
tenant and link that tenant to all the
projects for now obviously you do
whatever makes sense for your company
all right that's why something like this
isn't built-in it's easy to script this
up and make it just right exactly what
you need to do know so we create the
tenant if it doesn't exist and then set
the logo okay so I'm gonna save that and
then I'm going to set up my web book so
I get the function URL come over into
github so whatever aldo code i'm going
to show you is in this repo Dryad in
integration test demo so can go have a
look play around with it steal it
it's MIT license so go for it yeah so
I'm gonna go into settings I am going
and then web hooks do add a web hook I
know
please be nice I can factor yes good
yeah it's remembered my second factor
good it's gonna I wanted to post Jason
and the secret Microsoft has given us
this it's really simple I mean it's so
easy and I want to only send individual
events on branch or tag created and not
that one right get hubs gonna invoke my
a per my function any time it's happened
my function is going to octopus create
myself a tenant all right so I'm gonna
go make my wonderful code change that I
want to test out which is adding a
readme alright doesn't really matter
demo purposes right and I'm gonna put in
a new branch and really I hate this look
patch one whatever that so and but I
understand it naming things hard so I
don't want to call them David you know I
always wanted caller so I'm gonna create
this David branch proposed new file
excellent get hubs done it and
everything if everything works and the
demo gods in my favor it has now created
a tenant over here so go here
environments back
there's by david tennant excellent good
yeah cool the other file uploading into
my into into into here is test so this
is some test data this is what github
sends over the wire so I can take that
come over into this test tab paste it
into there and hit run it'll go and post
do a virtual post to that into my
function and I can see all the upward
there and it should have created a test
tenant so okay
got my test tenant I'm just going to
delete that just for clarity sake all
right so that's just a sample what how
you can use something like us herbalist
lambda functions and and Azur functions
to just
why are your systems together right
automate that thing that you're doing
every other day all right cool
and team city should have now oh it's
almost there building my things that's
good just refresh never runs it's faster
when you want it anyway cool
so next step let's let's create our own
integration test so I've got my tenant
now I've got my environment all set up
I'm sorry I've got my the basic set up
now I want to write the scripts that
actually stand up a CloudFormation
template run some tests and tear it all
down again on it yeah so let's have a
look at code so cloud formation is is
basically a definition of what you want
AWS to do so you're in this case I'm
sure I'm saying to AWS please create me
to Linux servers and I had opened some
firewall ports for me so I have where is
it here we go so I want a AWS instance
please with a network interface using an
existing subnet I'll bring two set up
public ID IP address please and I also
want a web server instance please t2
micro with this particular base image so
this is kind of if you're not used to
AWS this is the image to use like this
is a a bun to image you know just
one-off hard-coded in there
and then you know you've got port 22 in
for SSH because I wanted to connect to
it so I can deploy something to it and
I'm opening up port seven thousand to
seven thousand ten and that's where my
wonderful web service is going to run
okay
and again another egress yeah so
basically this is a definition this is
kind of a command to tell AWS please
make it so right now if I spin up to
machines they're just going to sit there
all right
I have no currently no way of octopus
has no way of knowing that they even
exist right you could go in interrogate
a DBS every now but wouldn't be great if
we
could get it to reach out back to when
the machine starts up to reach back to
octopus and go hey I'm here and you
achieved that by using user data so user
data is a script that runs on Windows
so PowerShell on Windows bash on or
whatever on Linux just gets executed the
first time you launch a VM all right so
in this case I get the public hostname
in the instance ID out of the AWS meta
data of the machine and I get the
thumbprint of the SSH connection then I
post that information to use to the
octopus API
you know format you know with a register
request body and in that register
request body I basically I tell octopus
please set up a SSH machine as s is hate
in point with this particular policy
these roles in this environment in these
tenants okay in this case they
hard-coded in there for now so at
runtime the instance ID and thumbprint
is substituted into this bits here but
before I do the actual standing up of
the cloud formation I replace
environment ID and tenon idea using
PowerShell so I've got a deploy
CloudFormation PowerShell script which
takes just the things like the 10 and ID
the environment the am I want to deploy
and so forth and mushes those three
files together I've separated those
three files out just for ease of
maintenance and I've written a script to
kind of put them all into one file and
then send it up to AWS using
command-line tools all right
so essentially I put the right variables
into the register JSON file then merge
it into the user data file use a data
file and then basically for encode it in
the special way that AWS wants use it
all right
it's not which is not as you do expect
it you have to put actual slash ends in
the end for some unknown reason okay
right does that make sense
Connor I'm gonna I've got this thing I'm
automating octopus is going to
run this script put some variable
substitute some variable into it to tell
a DBS to spin up a environment that
looks in a particular way alright so I'm
gonna do that as the first thing so I'm
going to add a process add a step and
run a script so I want to deploy my
CloudFormation on an octopus server I
put everything this time I put all my
scripts inside source control and
uploaded it using a zip package to
octopus so that I can I don't have to
cut and paste my my steps are basically
what scripts to run out of that zip
package so my zip package is called
integration test AWS and the script file
name I want to run these cloud formation
ps1 and I want to yeah run it cool so
they'll take care of setting up my
CloudFormation my service alright next
step is to deploy all the current
projects to all the right projects to
that environment those new machines so
I've got another script called deploy
projects this time written in C sharp or
C sharp script it connects to octopus
and goes please tell me what what
releases you have what's the latest one
in production do you have any that
ending say the David extension you know
the pre-release tag with David in it if
so choose that one otherwise use the one
that's in production for me alright so
that when we we actually do the
employment this one gets deployed and
these two get the one with the David
extension in it alright well David and
you get pre version tagging it alright
so yeah using again we're using the
octopus client DLL and using the API to
script it all up so we do we deploy the
projects we wait for the project's to
complete just polling it because we want
mean one all the projects to complete
before we can run our integration test
against them so
again just make sure I'll get it right
you add that step which is step inside a
package and this time it's the
integration test package script file
name is c6 octopus automatically detect
that it's a CSX extension use the rice
runner for us which is awesome and it's
safe alright third thing we want to do
is run our tests so I know which is
another step script inside a package run
tests and just make sure I get it
the test is are basically I'm just gonna
I connect octopus get all the machines
for that environment that our web
servers and I'll just try and ping them
on the like a door request if I get a
for a 200 response to test succeeds
obviously you want some more
comprehensive tests when you do it for
real
again integration test package script
file names run test CSX and we run it
cool all right now that's good and since
these are the disposable environment so
I want to tear everything down when I'm
done okay so I'm going to add a step to
tear everything down so leet cloud
formation server it's not a package this
package script file name is Gleek lay
off from formation this this is the
command-line tools they're pretty good I
tried the c-sharp API wasn't wasn't as
good the command line seemed to be
probably the most understandable thing
when you're getting started so cloud
formation ps1 and I want this to run
every time so even if my tests fail or
my deployment fails I always want to rip
it back down otherwise next time I
deploy I've got style machines kicking
around and lastly I want to delete all
the existing machines out of octopus on
that environment because I don't
about them anymore I could hook up a
degree s to when when the Machine goes
gets deleted I could hook it up to
Colleen to octopus and pull it down but
I'm just gonna delete them outright all
right I know I'm done with them
so leet machines cool okay so that's
that's their last last group you want to
do remove machines good stripper name
CSX and again always run done so that's
that's our five-step test process set
them things up run some tests tear
everything back down I didn't make that
one run always denied yes cool
so before right before I actually run
this I just want to protect myself here
that I don't actually do this it for a
production environment using production
variables and production credentials
right that would be bad so I'm gonna
change the life cycle and restrict this
project to only integration tests so I
can't accidentally slip and hit the
wrong button right I'm in my
environments I've got guided failures
turned off on by default for this which
means that if if a step fails it's going
to pause there and let me go and
investigate right so it and it's like a
manual intervention step if something
fails cool and finally I want to set up
my project to use the version number
from a package so I want my bit because
I'm only gonna I only gonna set this up
once for all my projects right these
scripts are reusable for for this
particular integration test right
so I want to base it off my run tests
package because that's the one most
likely to change right so when so my
version number of my release is going to
match the version number of my
integration tests so the reason the
reason these integration tests I would
sit outside often of your main repo it's
because it does it does
apply to just one project it applies to
your whole suite of applications that
are related you know it might be five
six seven projects for example at
octopus we've got end-to-end integration
tests where we pick up server the
tentacle databases and we set up a big
environment and then run this
integration test across it which
represents five or six different reap
actual repos underneath so there's no so
it's kind of a cross-cutting thing yep
hit save and was that I always require
tenant just you know so I'd actually
myself in the foot all right so I'm
going to create a release you could
you'd probably do this automatically
after you build just create a release
when you do a new package front at least
everything's fine 1.5 it's safe and I am
going to deploy now usually you wouldn't
deploy it right away you would after
your dependent project say my highest
highest common project built you would
say team CD would call out and trigger
this deployment right it would sorry it
would reach to this integration test
protein go please run all right and you
could split up you could say I have to
two different projects one which sets up
the environment then let team City run
you all your tests you know using any
unit or selenium on whatever and then
tell octopus to tear things down at the
end right just split up however makes
sense for you but I'm just going it as
one process just for clarity cool so I'm
going to manually deploy this done well
mainly kick off the deployment cool so
what's happening now it's it's employing
the cloud formation so let's have a look
at how that looks over in ec2 so cloud
formation it's created a new cloud
formation stack in here and we should
see our ec2 instances spinning up
there you go we've got our two te 2
micro spinning up one of the reasons I
used Linux is we don't have all day to
wait for Windows boxes to spin up this
this takes about two minutes so yep so
we can have a look at what's actually
deploying point aggression tests good
waiting for the stack to be created any
any questions so far while we're waiting
named yep that's right yeah I've I've
just decided I needed to run on a
tentacle you could have a blessed
tentacle with the particular role that
runs on but in this case it's running on
the actual box because it's not
modifying any state on the machine it's
purely scripts that call out to web
services cool so we've got our deploy
project it should be it should have you
go it's deploying all our projects so
it's automatically picked up the right
builds all the right packages releases
from these for my David branch and the
production one of the rot13 encrypt up
right so it's run run my tests right so
the test assist succeeded and I can go
in here and I can check - yeah go
manling test it and I should get a
result back from that oh no sorry
they've been ripped down re so yeah
cool anyway so demo gods didn't like me
this was meant to fail right because
somebody forgot to install the.net
framework but I did not change the a my
ID in my configuration so my very in my
variables for the integration test
environment I've got an a my ID and a
all my API keys that I need to tell to
tell it which one to to upgrade so if if
I ever creating new ami I just swapped
the new one into here
cool and so say there was a problem with
some with your ami you had a dependency
that you no longer needed how could you
get that on there so one one option
would be to use you user data to install
that at you know launch time but that
adds to your launch time so what you
want to do is you want to get at that
base image put all your dependencies on
top say Visual Studio for build agents
dotnet run time got it core whatever you
want write install services configure it
snapshot it and then persist it back
into AWS as an ami ami is a image ID and
use that for every new launch you know
so you create a template and you launch
it pretty sure we're all familiar with
that pattern the way we used to do it
and I'm sure everybody has is you spin
up a new instance in AWS or on your
local machine you log in configure
everything manually run some scripts and
then hit snapshot right which is great
except when it comes to security updates
so who updates their machines every week
with security updates their servers yeah
cool so up until we did this automation
we our build agents we're never updated
they had Windows updates turned off and
nobody was looking after him they ran
for months out of date on the Internet
and open with so we started using Packer
instead so Packer is a tool that lets
you automate this here you write a
definition file and some scripts to
install the right things and it's got
plug-ins for something like for for AWS
and the other cloud platforms which take
care of all the routine of standing up
an instance running the scripts and
tearing it back down testing and all
that stuff right it's kind of a
framework to do that for you cool so
where is it
so that ami that I actually branded with
was used was a base bun to image built
just the other day with the latest
updates because
AWS however maintains the abun to images
always put some new new security patches
on as soon as they can and creates a new
base image I want to use that base image
just check my other stuff on top and
every day or every every Monday run
rebuild all my base images with with the
latest security patches already done for
me
plus all my dependencies all right and
then capture that as my new thing new
secure am i that I want to use in for
the future ok so what does Packer look
like so this is a packer configuration
file Jason of course could be worse
could be Amal so it's it's so we've got
a couple of variables is there a WS X is
key you know I can pass those in that on
from the command line
I tell it what kind of plug-in I want to
use I'm gonna use the Amazon one place
and that and I provide all the variable
barely sorry various things for it
documentation is pretty good on this I
basically grabbed the example template
pasted it in ran it ran packet XE set up
my access keys 20 minutes later I've got
a brand-new a my image right
I'd never picked up packet before that
it's quite good and then it took me a
little bit longer to write the writes
the script the right way because Linux
isn't my forte so we we want to say
which region do you want to use to build
the image and where you want to save it
find me the sauce ami and I want to use
the latest bun to Zenon server 16.4
server done by whoever that is the
official a bun to team and use the most
recent image out of this kind of wild
card that you can find so I don't need
to continually update to tell it what
base image to use and then what instance
type so this is the instance type just
to build the image so if you don't wanna
windows get get yourself for a cause and
with lots of memory you know because
there's only up for an hour or so to do
all the installation all
three hours if you're installing Visual
Studio so you tell ya we install
Beatrice there yeah
and then just a name you know
integration test demo with the current
timestamp and then you've got
provisioners and this is the scripts
that you want it to run and it can do
phases so you can do reboots in between
so if you're installing updates on
Windows why are you stalling our
component that needs Windows to reboot
you can have a section which everything
read to do before reboot put a reboot in
there Packer or wait for it to shut down
and start back up and then run some more
scripts on it right cool
and it's the the shell scripts of the
things we want to run the actual scripts
themselves pretty simple there are just
bash scripts right or PowerShell scripts
if you're using Windows you can probably
run PowerShell on Linux now haven't
tried but I don't see one yeah it's
basically just gonna start process of
these files
alright so install.net install mono with
you know just a apt-get install right or
chocolaty install whatever you want to
use alright cool
then they kick it off I've got to build
ps1 file Packer build past my two
variables in and the configuration file
I want to do right so I'm gonna do that
now the command I prepared earlier
so what it's what it's doing now it's
going to go find me find the latest
image base image service want to use
it's gonna launch launch this instance
here and then it's what gonna wait for
it to boot up and get ready let's have a
quick look at what that looks like in
ec2 thanks Packer so I've got a packer
build a micro image it's running it's
starting up this whole process is going
to take about two minutes right so I'll
move on yep so it's waiting for us at H
four you know it's trying to ping in
every couple of seconds to connect SSH
excellent good and it's starting to
update mano
I think yep something like that
cool yeah so the we we use this for our
build images so we've automated we have
a bill that takes a windows-based image
installs Visual Studio 2015 on it that
takes about an hour and a half and shuts
it down images it and then the process
picks that image up and inputs window
Visual Studio 2017 on top of that and
then captures it again just for our
different use cases of build agents
right we sometimes we just want 15
sometimes we want 15 and 17 on the same
machine cool any questions while that's
running all right so all right let's let
that run right so finally we
everything's tested tested passed and
all that sort of just right let's have a
look at our environments everything
should be torn down and clean
I have nothing all right cool but I'm
ready to go production so I this special
widget spinner thing let's change fact a
bit a little bit and normally I'd have
servers already running because I'm just
updating an existing app but say you
were doing machines that were transient
the classic example that we use is
garbage trucks or trucks rolling into a
Depot there is tentacle or SSH machine
installed on them and you want to deploy
to them when they rolled in right there
might not be any in the depot while
you're doing your release but they will
appear randomly ad hoc on your network
for to deploy to another example is like
laptops you know you've got it you've
got something you're deploying to
desktops and the person nobody might be
in the office or connect to the network
right but you want as soon as that thing
comes back online you want to deploy to
it yeah so I'm gonna go and deploy my
project now the production hires common
I think this one why not let's let's put
pre-release versions of production for
fun
no no Tennant production and hit deploy
dam octopus has saved me saying I can't
deploy if there's nothing to deploy to
right so I'm gonna tell octopus I'm no I
really do know what I'm doing and go
allow me to deploy when there's nothing
deploy to please okay let's redo that
this is the fastest deployment we can do
because it's done all right I don't know
how long that took a few less than a
second right cool so my application is
now in production except it's not really
running anyway let's have a look at
dashboard there it is looks like it's
running right so now I want to set up a
trigger to say that when the machines
come online please deploy so I go in
here go triggers create a trigger go
deploy II so you know I want to deploy
when the machine is created and when a
machine is whenever when it's found
healthy let's say that right and if it's
already deployed in this case I just
want to redeploy right so I've got a
trigger now set up so that when a new
machine comes in wine I automatically
deploy to it so I'm going to use the
same script as before cloud formation
script I should zoom that in anyway
it basically says cloud formation the
stack name is production environment
environment 3 no tenant this time and
use the ami that I know it's good so you
don't obviously could automate this part
so this is probably just in your larger
kind of provisioning so this would also
work with Auto scale sets and all that
sort of stuff you know you don't have to
run a new machine combine just please
deploy it with so inside ec2 are not ec2
AWS let's have a look at cloud formation
so that thing I'm deploying cloud
formation calls out a stack so there's
my integration test stack
integration test production aww stack
its unique name gives me a log of
everything that's happening you know ec2
instances doing up I can have a look you
know what what's the actual IDs that are
being created you know all sorts of
things I can actually have a look at the
ending template you know this is the
template that you just used through the
API and again we should be getting two
instances pop up yeah yeah cool all
right okay I'm gonna switch over to the
dashboard and hopefully we see it deploy
if I set up everything correctly all
right any any questions all that happens
yes
yep it has it has to start and report in
so usually you'd run a health check to
ping it to say I'm here like octopus
need to know somehow that that machine
set up in that case I would set up
possibly iOS as manual start and use the
deployment to actually start iOS or the
web stop the website or something like
that there we go
it's automatically deployed because
machine machines have come back online
yeah cool refresh cool so that's it
thanks for listening and any more
questions oh cool thank you very much</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>