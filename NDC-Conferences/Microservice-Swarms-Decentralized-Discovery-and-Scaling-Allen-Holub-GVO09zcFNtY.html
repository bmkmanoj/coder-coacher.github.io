<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microservice Swarms: Decentralized Discovery and Scaling - Allen Holub | Coder Coacher - Coaching Coders</title><meta content="Microservice Swarms: Decentralized Discovery and Scaling - Allen Holub - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Microservice Swarms: Decentralized Discovery and Scaling - Allen Holub</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/GVO09zcFNtY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">i my name is Alan hold I am usually when
I talk at conferences I do it on one of
two subjects that are related as I other
talk about agile process or I talk about
architectural topics that are related to
agility and micro-services are right in
the middle of that space is the micro
servers architectures are almost ideal
when you're developing an agile
environment because the small size of
the micro service works really well with
a small team that's doing the agile
development so the tool related is that
I talk number of subjects said I should
say about this particular subject I'm
going to be doing a full three day
tutorial on Microsoft in an hour I can
only talk about the basics I can't talk
about any of the in-depth stuff as we'll
be looking that November class I'll be
talking about some of the same subjects
I'll be talking about today but in much
greater depth so if you want to follow
it along further do that and the slides
are on my website is the URL is
sometimes the URL the total comm slash
slides I'll have that URL up in the last
slide also let's talk about swarming and
what that's all about
first of all swarming systems are
systems where you have objects
cooperating with one another without any
controlling agent at the top telling
everybody what to do and in the case of
a flock of geese each bird is just
following the bird that was that's right
in front of it and interestingly in the
swarms in the murmuration of starlings
we were looking at on the initial slide
the same rules applies every bird is
just looking at the bird in front of it
however the the behavior of the system
as a whole is much more interesting than
that it's much more interesting than you
would guess by simply looking at what
any one bird is doing at any given
moment
now the systems are not chaotic is the
bird in front for example this guy will
be in front for a while it'll get tired
he'll fall to the back of the V and one
of the other birds will come forward so
there's a there's a coordination going
on with inside the clock as the flock is
moving but at any given moment everybody
is just looking at the birds that are
right in front of it now one of the best
examples of that in the mathematical
world is
Conway's Game of Life which I'm sure
some of you at least have seen what
we're looking at here is a this is
called a glider gun and objects that are
appearing out of the out of the bottom
here those are the gliders now the
interesting thing about this is that
this game is following the same sorts of
rules that the flock follows when it's
moving is that every cell is determining
whether it's alive or dead by looking at
the state of the surrounding cells if
there are too many cells that are alive
around you you die from overcrowding if
there are too few there you die from
loneliness if they're just the right
amount will pop into existence or
continue to exist and those are the only
rules that are involved so this entire
this behavior here we're seeing this
interesting organized behavior is not
actually programmed into this system is
that it behaves in a useful way without
us having to program that specific
behavior now this is particularly
important in micro services because when
we're talking about lots and lots of
micro services all operating at the same
time and when we can't predict how many
of them that will be at any given moment
having a overreaching coordinating
entity telling the services what to do
is just too hard a problem to be
solvable and a lot of the big
coordination systems if you will have so
much in the way of coordination code and
so forth in them it's there it's
unconvincing to me that they're going to
work is that we have to have this we
have to have systems that are more
flexible than that so a system that's
adaptive is always going to be better in
my mind than a system where you've got
some controlling agent that's in charge
of everything and the game of life is a
good example of that it's an adaptive
system but it was but the main behavior
here is not programmed so microservices
then are a way of applying that kind of
thinking to a programming environment to
a server environment now I could spend
several hours talking about the
characteristics of micro services but
let's talk about a few of the most
important ones in this context first of
all the micro service has to be a
completely standalone thing you have to
be able to deploy a micro service
independently of any other micro service
so that's the first problem with the big
systems is they need to know too much
about the micro services them cell
in order to get them up and running so a
micro service should be implementable as
a standalone process that you ought to
be able to just launch without having to
have any kind of complicated system
around the outside of it in order to get
it launched and hooked into the system
properly and that's that's the only way
that you get the independence that you
need for a micro service to be useful
whole point of a service in other words
is that you can work on it independently
as you can not just work on the code but
the point independently bring it down to
independently deploy new versions you
ought to be able to test things into the
system manually by injecting services
into the system manually instead of
seeing if they work or not you can't do
any of that if the micro services depend
on other things and in fact anytime you
have a situation where in order to
deploy a service you've got to do
something else as far as I'm concerned
that's not a micro service anymore is
that what that is is a monolith with
plugged with plugins and a monolith with
plugins is not a micro service by
definition it's a monolith the second
characteristic that's important is that
micro services are small the usual rule
of thumb that people have been using for
the last years so at least as they say a
service should be the size of your head
and the way that I interpret that is
that you should be able to have
everything about how the service works
in your head at once the best way to
think about this is that you should be
thinking in terms of object size it's
that I think a good size you know
service should be implementable is it
implementable as a single class and it
could be a class that follows all the
usual rules about classes and how big
things should be so you get smaller than
that and you have what I guess they're
calling nano services now and there's
Amazon lambdas and that kind of thing
but at that level you have two finer
granularity is that the things that are
related to each other are not lumped
together physically which makes them
harder to maintain in other words the
controlling principles here excuse me is
the so-called single responsibility
principle right this knife violates the
single responsibility principle it's
doing it doing way more it should it's
more to the point all of the things that
it does are not really related to the to
the other things that it does so this is
a clear violation of single
responsibility that simple
responsibility doesn't mean you only do
one thing so this corkscrew for example
is also satisfied or does satisfy the
requirements of simple responsibilities
even though there are four things that
it's doing the thing is is that all four
of those functions are focused on a
single goal which is to open a bottle of
wine so the idea is not that you want an
object to do one thing but rather you
want the object to be coherent in the
sense that the group of things that it
does are all related to one another in a
in a tight way so if something if you
call some method on the object on the
class on the service that that method
might need to change some kind of state
one way or another whether this urgent
service is stateful or not is actually
kind of irrelevant here and a subsequent
call might need to know that that change
has happened well if you've got two
separate functions to Amazon lambdas if
you will you can't do that or at least
it becomes very very difficult to do
that so simple responsibility really
applies the other principle that's
essential here is the notion of
simplicity this is a quote from the
agile manifesto but it's not which is
not an accident its simplicity is
central to agile thinking also
but services should be as simple as
possible and that's another problem that
I have with the way a lot of micro
services are being implemented on the
big vendor frameworks right now is that
you have to write the service in such a
way that it supports the framework and
that not only violates the isolation
issue right that standalone issue of the
services but it it also means that they
can't be simple this complexity there
that shouldn't be there
any time I hear the word it's simple I
get scared right anytime somebody says
oh this is easy right as I think that is
one of the two phrases in other words in
English that scare me more than anything
else is oh it's easy and this is awesome
and when you hear both of those things
together you know it's neither and so we
want to keep things as simple as
possible so my rule with all kinds of
programming and this includes
microservices is the so-called fool me
once rule is that the first time you
implement something you implement it in
the absolute simplest way you possibly
can and by simple I mean really simple
so I never even do things like add extra
arguments to functions on the off chance
that that will make the function more
flexible if I will implement exactly
what's new
nothing else now there are a lot of
advantages to that the coders to go very
quickly for one thing it's easy to test
it's easy to debug and it more to the
point is more likely to work than not
because there is less in it to go wrong
now if I find myself refactoring and I
and I say if I had done this somewhat
more complicated thing if I had this
design pattern in place for example and
the refactoring would have been easier
then I will add a little bit of
complexity in order to support the
refactor so I add complexity as a
side-effect of refactoring when it's
necessary and that complexity tends to
take the role of a design pattern or
something along those lines
but we want that characteristic on our
micro services also we want them to be
as simple as possible and still get the
job done without any kind of extra stuff
so if I'm writing code in order to
support my service framework there's
something wrong I don't want to do that
a couple other kind of basic issues
before we start you go to talks at
conferences like this and Netflix always
comes up
we are not Netflix but if anybody in
this room writing the system right now
that has to be the size and have the
scalability of Netflix I don't see
anybody raising their hands right nobody
ever does right so we don't have to
worry about the things that Netflix
worries about a lot of the solutions
that we see a lot of stuff in Azure for
example is meant to solve the Netflix
problem we don't have that right is that
most of the systems that I work on we're
just fine in one fork or VM in a cloud
in the cloud someplace I can get
reliability by cloning that three or
four times not done I don't have to have
any of the fancy stuff that you see
supported and pushed by a lot of these
micro service frameworks because our
systems just don't need them so part of
the simplicity rule is that we don't
want to build the service for a system
for a situation that does not exist if
we're lucky enough to have to scale we
want to build a service in such a way
that it can scale but we don't need to
build all of the scaling in from day one
because if we do that it's going to take
longer to get to market it's going to
make the system more complicated it'll
be harder to debug all of the other
negatives that are associated with big
monolithic systems so as simple as
possible
the other problem that people don't talk
about a lot is locking is that a lot of
vendors do what they do in order to lock
you into their systems and a lot of what
they're saying is essential is not
essential but if you buy the if you
drink the kool-aid right if you buy
their argument you end up implementing
this stuff in such a core way that you
are incapable it's not possible to take
their system and move it to some some
other vendor and that is always a
mistake is all of the vendors have
advantages all of them have
disadvantages you might not want to do
them at all you might want to be running
inside your own data center at some
point and you might want to run on the
cloud at some other point you want that
flexibility and you want the ability if
even if it's nothing that cost that's
driving it to move from one vendor to
another so as soon as you start
leveraging the facilities that a
specific vendor is providing then you
are locked you're locked in now that
doesn't occur with all facilities right
every vendor has some kind of storage
mechanism and the api's might be
differently but you might be different
from vendor to vendor but of course you
can wrap those api's in a very simple
shallow class that isolates you from the
specific API so that you can port more
easily but other facilities are more
tightly integrated into the way the
system works and I avoid those like the
plague almost everything that I'm
implementing right now is done on top of
one nano VM which costs about five
dollars a month depending on who you're
getting it from is Amazon and
digitalocean both charge five bucks a
month for their nano VMS and in fact
Amazon's nano VM if you if you are
running a computer or a service on one
VM you'd probably be down in the free
tier most of the time is that you're
using it so lightly in other words that
it's not going to cost you anything so
things like Amazon lambda and stuff I
hate long guys I think it's a disaster
and but more to the point it's what they
say which is you're only paying for the
time that you're spending well that's
only true up to a point if you spend
more than 100 milliseconds inside your
function then they start charging you a
lot of money and you can open your bill
from Amazon next month and find an
eighty thousand dollar bill from Amazon
or eight hundred eight hundred thousand
kronor bill from Amazon and their 80 a
Hollywood ticket times 100 whatever that
is
every times 10 and the
the point is is that you get surprises
when it comes to when it comes to
billing if you're talking about five
dollars a month for an endo VM there are
no surprises there you know exactly what
it's going to cost them it doesn't cost
much and most of us can run our services
on nano VMS without any difficulty at
all so you don't want to be locked in
the other issue is the complexity and
the hideous difficulty of doing things
like configuration and just look at the
service fabric this is not following the
single responsibility principle at the
service fabric is a monolith it's among
the worst kinds of monoliths it's huge
it is hideously difficult to configure
you need an expert just to configure it
whether it works or not depends on
whether you have it configured right but
it's something so hard to configure you
don't know whether it's configured right
if you're going to work on the service
fabric all of a sudden you have to spend
a lot of time learning how the service
fabric works when that time is better
spent programming it's just adding way
too much complexity so I I reject these
kinds of systems just out of hand this
is a monolith into which you are
plugging things and micro services have
nothing are not plugins they're meant to
be standalone independent units of
computation so as soon as you're
plugging your micro service into
something it ceases to be a micro
service anymore it becomes part of the
monolith thing you have all of the
problems that you have associated with
monoliths so I really don't like this
kind of stuff I also really don't like
the notion of orchestration is that the
idea of an orchestra orchestration is
that the somebody from outside is
telling the services how to work and
again if that's happening your services
are not independent of each other
anymore they're not independently
deployable anymore my service is
typically run at standalone processes
and nobody is telling them what to do so
I don't like orchestration either is
what we should be doing in other words
is not orchestration but what's called
choreography where the individual player
is here the individual dancers are
paying attention to the dancers around
them they're all following a general
theme but they're not it's not like a
orchestration system where they're
behaving to the to the note in order to
do whatever is on the score
so when we implement these things
there's lots of ways that we can
implement them typically one implements
them with some kind of HTTP front-end
typically that requires you to have load
balancing and things like that on the
front of the front-end that in itself is
a problem is HTTP is not zero overhead
micro-services do have to talk to the
web but in most micro service systems
most of the services spend most of their
time talking to each other not talking
outside most of the micro service
systems that we work on will run in a
single data center they're not you're
not going to scatter your services over
the whole planet you might replicate
your service system in different data
centers but you're not going to scatter
the service across data centers if for
no other reason it's impractical if you
put your data in the EU and you put your
your functions in the US there's going
to be hundreds of milliseconds of lag
every time you need to access your data
it's just not going to work so generally
thing generally speaking everything is
concentrated in one place which means
that we don't really need HTTP as HTTP
remember HTTP exists in order to be able
to access data across the Internet if
we're not accessing data across the
internet we don't need that overhead the
other problem is that it makes our
systems harder to implement again the
micro services should be very small as
soon as you start building a web server
into your micro service it's not small
anymore as soon as you start bundling
your micro service with apache or nginx
or iis or any kind of web server in
order to have a web front-end then it's
even less small because now the web
server is effectively part of your
service and you have a lot of
configuration and coordination issues
that you would rather not have so having
your services talking with HTTPS or HTTP
at the highest level is not actually a
very good strategy is that it adds in
efficiencies adds complexity it takes
away independence and you don't want any
of those things to be happening so what
do you use when services talk to each
other and the answer is that you should
be using some form of lightweight
messaging now messaging is one of those
topics that everybody really desperately
needs to know about and nobody knows
that it's always presented is this kind
of minor side issue because people are
so focused on the HTTP thing that
they're not thinking about
how you actually coordinate effectively
there are a lot of messaging systems out
there there's rabbit there's Kafka
there's zero MQ which I'll talk about in
a moment and there are bigger systems
like TIBCO in a micro service
environment you want the system to be as
lightweight as possible you want the
least amount of configuration the least
amount of programming overhead you just
want to use messaging in other words as
a way to talk to other services in an
efficient way so lightweight is a key
part of this equation now just an
address for a few minutes let me talk
for a bit about what messaging systems
do for you
messaging systems basically are doing
Network communication and they're doing
it using one of two metaphors the first
one being a queue message queue works
like any other queue it's a it's a
first-in first-out
system the way that two objects on the
network talk to each other is literally
by sending a message the message is a
physical packet of data typically in my
systems I always use JSON for my
payloads because Jason is completely
independent of languages that it's a
important characteristic of a micro
service that it be both platform and
language independent I want if I'm
writing a micro service system in other
words if I'm doing string operations I
want to write the service in Python I
don't want to write it in C sharp or
Java if I'm doing something that's got a
lot of logic associated with it then I
want to go to c-sharp or Java or
something like that where the logic is
going to be easier to implement I want
to use the appropriate tool in the
appropriate place which means that micro
server systems are typically both
polyglot in the sense that different
services are written in different
languages and also platform-independent
the messaging system allows you to have
that independence because two things
written in different languages can talk
to each other across the network and if
the information is flowing back and
forth in some sort of uniform format and
Jason is a good format for that then
you're isolated from the implementation
language and even the platform if you
have the system so you could have a
service running on Windows talking to a
server the services running on Linux and
there would be no problem there the
messaging system in other words would
absorb that so the basic idea then with
our queues this is the zero MQ situation
so you have a producer and a consumer of
the message
on the the what blue line here is the
network you send a message obviously
from the producer to the consumer in the
case of zero M Q 0 and Q is a
point-to-point protocol which is one of
the things I like about it so the
producer talks directly to the consumer
now the problem with that is that if the
producer and the consumer are not
talking to some through some central
coordinating entity it becomes difficult
to make a connection and then make sure
that that connection is reliable if the
connection drops you need to be able to
re-establish the connection and it
should be completely painless 0 does
that for us which is a good thing that's
one of the things reasons we're using
messaging systems as all of these kind
of reliability issues can be handled by
the messaging system itself rather than
by you it's code that you do not have to
write but it's a strict point-to-point
thing I want to make that work the
producer doesn't know when the consumer
is going to connect or vice-versa either
one could come up first
so if the producer comes up and starts
sending things off to the consumer and
the consumer isn't in the system yet
it's got to store messages locally on
the producer side and so that when the
consumer finally connects it can then
send them across so everyone following
what I'm saying same thing applies on
the consumer side there could be many
producers all sending messages to the
consumers well you need a queue over
here to hold the ones that you haven't
gotten around to handling yet so the
queue has to be distributed in a
point-to-point system now also connected
to this is the notion of connecting and
binding one side has to have an address
an IP address of some sort the other
side has to connect to that IP address
interestingly in 0 at least you can put
the bind on either side so it doesn't
matter where it is the question is where
is it most convenient is that in order
for this guy to talk to this guy it has
to know its address in order for this
guy to talk to that guy it doesn't need
to know the address
so topologically you've got to decide
how to make that work I'll talk about
that a little bit more in a moment
but the binding can happen anywhere you
can put a broker in the middle of the
system a broker is a separate entity so
if you talk about systems like 0 mq or
Kafka or any of the larger messaging
systems they all have brokers I don't
like brokers a broker is a single point
of failure in the system it is difficult
to configure it
couples the end points together which it
shouldn't the only thing you get from
having a broker is that the addresses
the bindings are bound at the broker
side so this guy can talk to that guy
both of them know about the broker but
neither of them need to know about each
other and that's convenient but it is
not convenient enough to make me think
that I want to use these things is that
brokers again are very very complicated
they're hard to configure they're very
heavyweight you just don't want to deal
with them if you don't want to or if you
don't have to rather they're also again
a single point of failure if the broker
goes down the entire system comes to a
halt and I don't like that I want my
assistants to be more resilient
micro-service system should be resilient
they shouldn't they shouldn't depend on
one piece of the system functioning in
order to function so when you have
point-to-point communications you don't
get that dependency the final thing you
get with a broker while we're on the
subject is you can have multiple queues
the queue is actually in the broker so
you can have multiple queues and one
broker but again what that means is that
you take all of the queues for your
entire system and put it in one single
broker when that broker goes down the
entire system stops nobody has any data
any more until the broker comes back up
again and from a resiliency point of
view I don't like that now in terms of
sending messages typically the producer
will talk to multiple consumers with
some kind of queue there could be a
broker in the middle but there doesn't
have to be typically when the producer
sends messages out they get sent out in
a round-robin sort of fashion as they
just go to the various consumers that
are connected the thing to notice when
I'm talking about that is that this is a
kind of load balancing so we talked a
lot about load balancing in Microsoft in
the micro service world the question is
do we really need to worry about
full-blown load balancing and the answer
is when it comes to multiple instances
of the same service no right because if
you have multiple instances of the same
service they're all doing about the same
amount of work in about the same amount
of time so if you pull that out of the
load balancing equation what you have is
around Robin scheduling and the message
system will do round-robin scheduling
for us just fine so by using a messaging
system and having the producer round
robin ting out to the various consumers
with subsequent
messages with a series of subsequent
messages we eliminate the need to load
balance between multiple instances of
the same service we just don't need to
do it anymore
so we can simplify things a lot again by
just relying on the messaging system
also say as an aside here you often hear
about message buses a message bus is
nothing but about a broker if you had a
situation when you had one queue in the
broker right so you can think of a
message or a bus as just being a fancy
way to say queue is that it's basically
the same thing
now the other metaphor that people use
in messaging systems as the
publish/subscribe the type of sub
metaphor you have a publisher that
publishes events you have a bunch of
subscribers that are interested in
hearing about the events what you
publish is a specific topic in this case
there is there may be a couple topics
I'm assuming there's a blue topic and
there's an orange topic so you could
subscribe to the blue topic or you could
subscribe to the orange topic or
subscribe to both of them when the
publisher publishes they publish on a
specific topic and then that is routed
to whoever subscribe to that topic so
there there is no round-robin it's a
broad broadcast kind of situation
pub/sub is a little bit faster
it's a little bit better in many
situations than queueing is but it's not
a replacement for queueing it's very
difficult sometimes you just need queues
and one of the downsides of some of the
messaging frameworks that I've seen like
Kafka is they just give you pub sub you
can you can fake it in Kafka you could
have a have a single subscriber
subscribing to a single topic but that's
kind of work that I don't want to do I
don't want to worry about it I'd rather
have the message messaging system in
other words handle both metaphors for me
so ideally you went both
publish/subscribe and some kind of
queueing system and of course you could
add add a broker to the middle of this
if you wanted to but there's no
requirement that you have brokers there
assuming that you've got a messaging
system that can do point-to-point so by
going to messaging we get a lot we've
got a lot of simplicity in our system
we're pushing a lot of stuff off to the
messaging subsystem that we would
otherwise have to write ourselves things
that are giving us reliability and so
forth inside the code we get a lot of a
lot of efficiency when compared to the
HTTP or some sort of heavyweight
protocol for talking across the network
it's easy to distribute this stuff in
the case of 0 mq everything is done with
see IP addresses so if they're all in
the same machine your system is running
on the same machine if there are
different machines than suddenly running
on different machines so it's easy to do
distribution and we have complete
language independence because the
messaging system itself is language
neutral we can have a service written in
any language talking to a service
written in any other language so looking
at zero it's called zero because there
are a lot of issues I will apologize in
advance for the fact that they used a
know instead of a zero here is they
don't understand the differences in
letters and numbers I think but the but
this is the official logo zero I'm Gill
the the it is zero all of these things
no broker's is not zero latency but it's
close to it it's very very fast compared
to a lot of the other protocols there is
there is literally no administration the
only downside of that is there's no
administration console so if you want to
monitor the system the behavior of your
system with a pretty picture you have to
write the program that's doing that
that's not part of zero as other
messaging systems will have monitoring
consoles that come as part of the system
it doesn't cost anything that's open
source it's free it runs on every
platform it's generally a good thing to
be working for I'll skip past this slide
quickly because you'll you have access
to the sides if you want them but you
can get information at this URL
it was written originally for financial
applications so it's very reliable and
also very fast right is good for
real-time it runs on pretty much every
platform runs fine on net it runs fine
on Linux it runs fine on the Mac it also
actually runs on several of the IOT
platforms as well as in the IOT
operating systems as well more to the
point there are bindings in every known
language including oak is that I don't
know if anybody here is an oak
programmer but I didn't even know what
it was until I saw the zero had a
painting for oak but if you want to
program a nuke you can do it but more to
the point it supports the languages that
all of us are using the C sharp and C
and C++ and Java and Python and
obviously all of the standard languages
so you can write a program in any
language and it can talk to 0nq it
supports pretty much all of the
networking program or protocols you
would care to use I usually use TCP
because it is the most common of them
work everywhere and it has a security
wrapper that goes around it that you can
use to make your messaging secure one of
the big flaws that I see when I look at
micro service systems is that people are
not thinking of security inside the data
center and you have to write is if you
think about the notion of a denial of
service attack in a Microsoft in a micro
service world the denial of service
attack isn't necessarily outside the
data center if a service goes crazy
it could be sending out hundreds of
thousands of messages and receiving
those messages could generate hundreds
of thousands of more messages and you
could have a cascade of messages that
makes the system completely
dysfunctional and that could be
happening entirely inside the data
center and that might happen because of
a bug and that might happen because of
something from the outside but it will
happen so thinking of security as being
a boundary thing something that if you
don't let in the bad guy you're okay you
can't think that way so one of the
things that's nice about Xero is that we
can encrypt the actual messages that the
users elliptic curve encryption around
the actual messages the final thing I'll
say about it before we start going a
little bit more into architecture is
this is the entire API for 0 mq and half
of these functions or functions that
I've never used because I hadn't haven't
needed to so it's a very very simple
system to learn as you can learn it in
and after an afternoon is that they get
up and up and running efficiently in an
afternoon the basic metaphor is the
notion of a socket this is not a
unix/linux style socket it's really a
port in the messaging system the basic
idea is that you plug into a socket the
socket is an asynchronous front-end to a
queue of some sort or it does a pub/sub
kind of thing you can have multiple
endpoints so a socket could have
multiple IP addresses bound to it on the
other end a socket could connect to
multiple IP addresses so you can feed
into a single socket for multiple
sources or you could have multiple
sources feeding out into as many targets
as they want you could have different IP
addresses associated with the same
socket if you wanted to more commonly
you'll have different port numbers
associated with the same socket or
different protocols associated with the
same socket
you can even have multiple transport
protocols associated so you could have
TCP and something else for your two
protocols it does all of the threading
for you so your services can be single
threaded which is a good thing is that
in general you don't want to put
multi-threading into services because
they are it's another layer of
complexity that you would rather not
have it's another other source of
difficulty if you think about queueing
instead of doing four things at once
if you for if you coup those four things
up and do them one at a time you don't
need to coordinate anymore there's no
need for threading any more connection
and reconnection we already talked about
so let me look at just one simple
example so you can see how this all
works this is a simple request response
request reply system this is the easiest
kind of connection to make in the zero
world you make a request to some kind of
client makes a request to some server in
this case the server replies this is
synchronous in zero MQ is that you can
make a request to the server that you
can't make another request until you've
gotten a reply back you don't have to
block while you're waiting for the reply
but generally you do so you make a
request you get a reply and a client
could be requesting things from multiple
servers here I've got to connect on the
request on the on the server side in the
bind on the client side but it doesn't
again have to be that way you could flip
things over if you wanted to so that's a
two objects talking to each other if we
look at the code for this I'm going to
skip through some of it but the basic
idea and this is this is the way zero
works pretty much everywhere and this is
Java but the c-sharp API is look almost
exactly the same you start up in this
case I am implementing the client and
the server on separate threads so I'm
going to start up the server with this
is just a just a call that's going to
start to serve with your head running
this is the zmq stuff you create a
context you ask for a socket in this
case it's a request socket so you have a
request socket talking to a reply socket
you might also have a publish stop
socket talking to a subscriber socket
there's a push socket that you can talk
to a pull socket and so on and so forth
so you decide what the socket type is
and then in this case on the client side
I'm connecting and then I send messages
off
just by saying requestor dot sin in this
case it's just a string couldn't you
couldn't get much easier than this right
as you you establish the connection you
send strings across in the case of the
micro-service stuff what I'm doing the
strings are Jason strings they are you
can think of them as an RPC system is
that I don't use I don't do use rest
right if you think about rest rest is
really a data centric protocol right is
the idea in the rest protocol if is pure
rest is that the URL spells specifies
the location of some resource and the
verb right get put post whatever to verb
you're using specifies what you're
supposed to do to that resource when
we're talking about micro services
you're not getting and putting stuff
we're thinking objects so you shouldn't
be getting and setting things from
objects in any context what you should
be doing is asking the objects to do
work for you so the basic idea here then
is that the protocols will be used to
request some objects so we'll look at a
little bit of Jason in a moment but the
basic idea here is that what you're
sending is a json packet that's
requesting that the service do something
for you it tells you what you want it to
do you pass arguments in it responds
with the json packet that's got the
result in it alright so this is our
basic sending code the receiving code
looks almost the same you have a context
you get a socket out of it you bind on
this side remember we connected on one
side I'm binding on this side
on this side I'm receiving the string
instead of sending it and then I'm
looking at it if it starts with stop I'm
going to stop the service gracefully if
it doesn't all do something and then
spin back up and get another request but
the point is the point of this is not
this is not a zero MQ class this is but
I just want to show you that this
actually is easy so I said I usually run
in terror when I hear somebody say that
but then hopefully you'll make an
exception here because I've proven to
you that this actually is easy so and as
I said their bindings were pretty much
any language you want to program in to
work with this so moving back into the
direction of the swarming systems this
farming systems that I'm building are
all built on top of messaging the
microservices use messages to talk with
each other now let me explain them
kind of the evolution of my thinking as
I moved in the direction of the system
I'm going to get at this is uh where I
started with a web server called mongrel
to mongrel to is it's a written in Ruby
so people in the Ruby community know
more about it than anybody else does but
the basic idea of mongrel 2 is that
mongrel 2 is a translator it takes HTTP
in on one side and it generates zero MQ
messages on the other side so the way
that you plug a service into this web
server is by writing a service that
pulls messages off of some queue where
the portal here mongrel itself is
pushing messages so that means that the
service is not plugged into the web
server in any in any physical ways the
service could be running on a different
machine in a different data center they
connect across the messaging system
using a TCP IP address so it's a
standalone thing mongrel the the way you
configure mongrel is with a simple
simple table that just Maps URLs to IP
addresses says when something comes in
at this URL send a message all the post
data and stick it inside of a 0 mq
message and then send it off to this IP
address to a to a queue on this IP
address and then it gets a response back
since it gets a response back in
interestingly enough using pub/sub so it
pushes and pulls here and then it
publishes and subscribes to get the
result back I'll talk about why in a
second
so what this got me thinking about is
that HTTP is just another service at
least HTTP translation is just another
service if you look at your services in
other words there's a cloud of
stand-alone objects that are sitting on
a message bus and sending messages back
and forth to each other and they're not
using HTTP to communicate with each
other well we do have to talk to our
services from the outside so that
talking can be done with others just
another service something that does
nothing but receive HTTP POST requests
for example and turns them into messages
and routes them off to the correct
server the correct micro service if you
will so that's where I started now
mongrel is not good enough as it stands
to run to run a micro service system but
it's it's you're thinking
is good huh then your don't then your
doing right so that's it
however you can run multiple instances
of it so you could put all of the usual
infrastructure in front of this you
could have multiple instances of mongrel
you could have a load balancer in front
in front of that you could have a
reverse proxy in front of that and then
your isolated from the from the mongrel
itself going to so you can use
replication to do that we can have
multiple services on the bus of course
and remember they're going to
round-robin so the portal is just going
to if they're all if they're all bound
to the same socket here on the portal
side they're just going to round-robin
through them so we can scale simply by
replicating the service so that's the
first thing in the direction of swarming
is that the first characteristic of a
swarming micro service is that it
observes when it's too busy and clones
off in instances of itself to handle the
extra load so a swarming system the
services are self-replicating the
service needs to happen needs to know
how to make a new version of itself and
framework that I'm using it does that by
just shelling out to a shell script
which does whatever it needs to do in
order to get a new instance of itself
running I might be using them kubernetes
cluster to do it it might just be
spawning process so the point here is
that the service does need to make a
copy of itself though when load
increases and what will happen then is
the way you handle load is that as the
service gets too much load on it starts
making clones of itself since the thing
that is making the call is round-robin
the clones then the load is now
distributed pretty much evenly between
the clones and your load goes down your
loan factor goes down you can keep the
extra ones around indefinitely I don't
like to do that so I do have a mechanism
for getting rid of the clones when
they're not working hard enough I'll
talk about that in a second but that's a
less crib time critical issue right if a
clone hangs around for ten minutes it's
not what doesn't happen to be working
it's it's not a big deal it's not going
to it's not going to cost you much in
any way in any in any way that the word
cost means next order of business is
that we could have more than one portal
as I was getting at that earlier that
way they could be running in parallel we
can have a little bit of a robustness
will put the normal load balancers and
so forth in front of the front of the
portals in order to get load distributed
properly
the reason it's pub/sub is that what
happens is that when the portal gets a
request it puts the topic name into the
request that it pushes to the service
the service then publishes the result to
that topic so all of the requests that
came from this portal will have unique
topic IDs that match the request of the
response and all of the ones that come
from this portal will have unique and
different topic IDs I guess that's what
unique means it could be different but
the point is is that the service that
handles the requests just publishes the
response and it doesn't care which
portal it goes to is that it's going to
the one that subscribes to that topic
and the one that subscribes will be the
one that generated the original request
so pub/sub on the response side makes it
much easier to set it to reply to a
service to send a result back because
you don't have to know who sent it to
you it's kind of a basic rule of
object-oriented systems that you
shouldn't know who sent you the message
and then finally we can put things like
logging just right on these buses and if
we do that we don't even have to log all
right now also we could have multiple
portals feeding multiple buses so every
one of these blue lines is effectively a
broker in them in the Mongo system and
so you'd have one broker per micro
service and then on the other side of
those brokers there would be as many
instances of the servers that you needed
services that you needed to handle the
load handle the current load and of
course we could have multiple portals
feeding multiple buses if we wanted to
do that this is characteristic of
messaging systems as they get really the
diagrams get really messy very quickly
okay now so I started out with Mongo and
then I started thinking mongrels not
good enough really for doing a micro
service system it's it doesn't handle
security particularly well it there's
just a bunch of things about it that I
didn't like the fact that I had to
implement services using but or using
brokers was the worst part though but
even then even saying that I started
building a micro service platform which
I'm calling Janus this is there's going
to be a URL Janus framework org that's
not doesn't quite
just yet is I'm not quite ready to put
it up on github is that I should be
ready in a month or two if you go to
that three day thing I'm going to do in
London in November it'll be done by then
and we can analyse planning on spending
a lot of class time analyzing the source
code for it that it that in that class
but this is version one I'm not
completely happy with version one I'll
talk about version two in a second but
again I want to talk about my thinking
as we went from point A to point B here
I had the browser this is a very Mongo
kind of system right is that here's the
HTTP service which is just a micro
service running on this system there
could be multiple instances of it
there's a simple naming service so we're
using 0 m2 to talk between these two
elements the naming service is going to
do a mongrel like thing it is going to
connect IP addresses to URLs essentially
this naming service was a somewhat more
complicated service naming service than
I wanted in this version one system in
particular when a service instance when
I had what I created a new service I had
two choices either I could have a broker
or I could eliminate the broker and have
the broker have each service talked to
the naming service every time it came
online so the naming service could
effectively do and be doing my
scheduling and that was making the
naming service way too complicated it
wasn't just naming anymore it was doing
too much so I reluctantly put a broker
in place but now I've got a broker in
place so the service then is effectively
the broker which is talking to the
individual instances now these
individual instances were self scaling
in the sense that when they notice there
was too much load they would spawn off
in two instances of themselves and talk
to their broker the broker had a single
address it knew about the addresses of
the instances that the outside world did
not so this is most of the way there but
I still have this single point of
failure sitting here and I really didn't
want that to happen does everyone
understand what I mean what I'm saying
here architectural so this was a
reasonably good approach but it had its
issues now in the system though there
were a few things that two design
considerations that I had that were that
applied to version 2 - so let's talk
about those
the first question is what do you do
with the singleton the singleton is a
one-of-a-kind thing right and those are
our simple points of failure those are
the places that I want to avoid so in
the case of the of this original system
and I'm just still doing that I'm
handling the singleton problem in the
easiest possible way I'm just spawning
off multiple instances of it is that
most of us get by just fine with two DNS
servers right that's enough robustness
to handle most of our problems
I think if you had three or four DNS
servers that was important that you
could ever need
right I've had no problems with - I just
run them in parallel they both work
exactly the same way I'm using pub/sub
to talk to him I asked for an address I
get two responses back and I throw one
of them away
and that works just fine the the so I'm
requesting by pub/sub there because I
don't really want to write I don't want
the naming service to know how many
things are talking to it so by using
pub/sub to get this stuff to get the
replies back that handles that problem
reliability monitoring is also an issue
here I have to have a monitoring system
the log the logging system is a is
another singleton there's a logging
service two instances of it that are
running in parallel and the logging
system does accumulate logs but I'm not
really doing much with them I really
dislike the idea of having some global
level service getting reliability by
observing the logs observing when a
service goes down and then relaunching
it because we're getting back to another
single point of failure in another place
where we have complexity I would rather
that the system scaled by itself so
we'll look at the the final architecture
in a minute the way I saw the
reliability issue is by handling
heartbeating between the sender and the
receiver of every message so if you
think of the idea of a heartbeat is that
if something is unresponsive or just
isn't being used for a while you ping it
to see if it's still alive and if it's
not alive then you could do something
about it you can launch launched a new
instance so the basic idea here is that
if I'm going to send a message to a
given service if I'm sending messages at
a fast enough pace I know that the
receiving service is alive because it's
responding
if I don't need to send a message for 10
minutes maybe five minutes into that I
might want to ping it to see if it's
alive so that another five minutes from
then I can send the message and not have
to worry about it getting there so I'm
putting the responsibility of detecting
when a service goes down on the message
senders Matt is everyone following what
I'm saying it rather than on some
centralized system that is keeping track
of what all of the objects in the system
are doing so that again distributes the
reliability out amongst the entire set
of micro services so I don't have those
single points of failure anymore the
ramping up algorithm is pretty straight
forward is that zero doesn't give you
access to Q so you can't do with cooling
so I'm just doing it by load I'm if I'm
if I'm so busy that I that I'm hardly
ever doing anything except working then
I'll spawn off in your instance
now let's the rest of this stuff let's
just table that for a second I want to
I'm going to go to the next slide to
explain how the rest is working all
right now so it's it's a simple matter
though every service is responsible for
cloning off itself when it gets too busy
so I'm going to do I'm going to fit on
this slide for a moment I'm going to go
to talk about how it works and then I'll
come back to it we have a requesting
service and we have a receiving service
and remember everything is a service so
the HTTP is being handled by a service
that is no different than any other
service the only difference is that it
has a port to the outlet port 80 HTTP
connection to the outside all right now
the payload here is going to contain the
name of the function if you will that I
want to call and the arguments to that
function and some unique request ID so
that's just generated by the sender
actually it's generated by the framework
is that I probably should have shown it
here but there's a framework class here
and there's a framework class there so
in terms of implementing on this thing
you don't have to do any of this
overhead it's done for you by the system
but the basic idea is that it will push
this request down to the service the
service will then do whatever it has to
do and then it will respond and it
responds again ignore this for a second
it will respond with the original
request ID so that this guy can match
the request
to the response and then there's some
JSON that describes what the response is
and that's going to be unique to the
request so the basic idea is that I'm
pushing and pulling here and then I'm
using pub/sub to go back in this
direction now for this to work the
binding has to happen on this side has
happened on this side the requesting
service has to know the address of the
service that it's talking to for this to
work so does everyone follow me here all
right so this guy is going to connect
this guy's going to bind and also this
the sub the subscriber connects to a
bound socket on this on the service that
you the publishers the response so the
requester knows the address of the
requested of the requested service so
the hard part here is discovery the hard
part is how do you learn what the
addresses of the services are so let me
go to the next slide and as I said I'll
come back to this one I have my HTTP
gateway service here I have a couple of
logging services running in parallel
I've got a couple of naming services but
and then I have the service I want to
talk to now this naming service is a
very very simple naming services the
role of this naming service is to get
the first one it has one service name in
it that's matched with one TCP IP
address so the way this all starts
whether the way the whole system starts
is on the very first call to the system
the sending service goes up to the
naming service and says get me the
address of the yellow service that I
want to talk to all right so it's now
got that address over on this side since
it's got that it can now send a message
off to it so now the sending service and
the receiving service are happily
talking to each other there's nothing
earth-shattering here now what gets
interesting is how does the system scale
the sending service in that JSON packet
I'll come back to it in a second had a
table that had all of the addresses for
all of the instances of the receiving
services in it initially that table will
have just one address in it so
effectively the sending service is
sending the address of this service to
to itself to that service in the first
time what it gets interesting is that
this service then gets so busy that it
needs to scale so it clones often
instances of itself the cloning service
knows the address of the cloned one so
it modifies its internal table to now
have two addresses in it both the read
address and the yellow address and then
when this guy replies to the request it
sends the new address back over to the
requester as part of that response so
now the requester has both addresses it
adds the new service to its socket and
now it's round-robin in between them so
everyone is saying how this is working I
can't see most of you so if you're
nodding I probably can't see you but so
and the same thing keeps happening right
if it spawns out if it has to spawn off
a closed and the thing that did the
spawning knows where it is and then one
replies to that message it sends the
reply back up to the original requester
and away you go so if there are multiple
requesters these tables this table I
should have shown it on both sides
exists on both sides right everybody
knows everybody's address so if another
requester comes in it'll get the first
one from the name and service but in the
reply it gets a list of every instance
of the service that exists right now so
I'm essentially doing discovery inside
the request in the reply services by
passing this table around again this is
not code that I have to write I'm
writing a micro service framework just
to do this right it's doing all this
overhead for us but what this means is
we can eliminate the need for discovery
the discovery is happening dynamically
just as a side-effect it's an invention
consistency system because you don't
know the addresses of all the service
instances immediately but they will
propagate out to the entire system
eventually
is making sensitive so if we go back to
the to the authentication I forgot to
mention that I'm doing authentication
here in the and in the framework class
but that's on the client side it's on
the service side so the the throttling
is also happening here it's not really
it's I've been going back and forth
about the throttling you really want the
throttling to happen here but that's
hard so I'm doing the throttling on this
side the way the throttling works is it
just immediately rejects the request so
it it doesn't take much time that it
takes some time to throttle alright so
getting back to here so here is that
table right this is the list of
instances so the list of instances goes
across as part of the push if it clones
off something it just adds the IP
address and then it goes back and I'm
I'm using the very simplistic rule that
if the push-pull pair is that a given
address the pub/sub peril via that
address plus one added to the port
number so I assume they're on the same
machine obviously but they'll be at
different port numbers right it's red
they're consecutive alright so the
addresses are always even is the odd
port number is the pub/sub here alright
the question aside as a service
basically transmitted the information
about the service as a replication
happen the the short answer is that
every service instance has a copy of the
complete table and every service
requester has a copy of the Khmer B
maybe it may be a complete copy maybe
not but the point is is that is that
table goes from the client to the server
every time a request is made so if
there's any communication happening at
all eventually your tables are going to
get updated right when you spawn off
into instances the existing requesting
services will not know the new address
that's correct but the next time they
make a request they'll get that address
because the service that they're making
the request to does know the new address
its eventual consistency it might take
two or three calls before you get it but
you will get it eventually
and eventually me the worst case is you
have to hit all of them I haven't seen a
situation yet where I've had more than
about seven or eight instances of a
service running so it's not it's not
going to take that long it's not like
you've got thousands of them we're not
all Netflix all right everyone saying
how this how this is working so that's
that's the basic system so I'm basically
taking the discovery issue and I'm
putting it into the request and reply
services so that they can scale
automatically and by doing that I
eliminate the need for any kind of
coordination orchestration framework
right is that the services just launched
you know the thing that starts it up is
the simple naming service which is just
simple key value pairs right has given
this logical name and a physical name
for the first one the other thing I'm
doing is that I've built into the code
for the system a little bit of load
balancing in the sense that the service
instance that is on the in the naming
service will be used less often than the
server than other service instances
more than one of them because
everybody's going to hit the first one
everybody's going to hit the naming
service and then hit the first one the
first time I make the call so I want to
keep the load on that one a little bit a
bit a little bit lower and I'm just
doing that with a constant value right
now I just you know don't call it half
the time all right
the only other issue here is shutting
down we could just wind down easily or
run down quickly if a service just shut
itself down abruptly the only downside
of that is the tables will now be
invalid but that's an easy problem
because you make a request and you get
an error back from the messaging system
and you just remove that one from the
table the downside is that if the
service has just shut themselves down
abruptly you have a sick you can have a
situation where no instances of the
servers are running they all decide to
shut themselves down and I didn't want
that I wanted I wanted one of them to
continue to exist so I hit a hit on this
algorithm to do it I'm still fiddling
around with this algorithm but the basic
idea is that when a service wants to
shut down it locks itself so that all
subsequent requests are rejected and
then the service that is shutting down
remember it's got that pub/sub socket it
publishes a request out to all of its
siblings saying I'm about to shut down
if any of them reply with a I'm locked
right in other words if they can't can't
send it out then it says okay there's
another one shutting down so in that
case what it does is it gives up on
shutting down backs out of that process
by some random amount of time and then
tries again so this is if you've ever
programmed in Corbin this is the way
corporate work I'm beginning to think
that this is probably more complicated
than it needs to be I could just say if
you are the first one to be launched
don't shut down and if you're anything
else just shut yourself down abruptly
and don't worry about it and I'm leaning
in that direction right now alright so
that's the system I've been working on
is that the basic idea then is that the
services are completely independent they
are not sitting inside of some elaborate
framework they are sitting in a
framework in a sense that they're
sitting all sitting on the same message
bus there's a certain amount of work
that has to go on to get all of the
communication that we were talking about
working but that's a relatively small
amount of work and that will be the code
that's comprised
is the system that I'm working on if
you're interested in following up on
that by all means feel free to send me
an email address or a DM on Twitter I'm
doing that session in London in November
so you can get more information and
that's in in the London conference if
you want to go there and I'm of course
happy to answer your questions we don't
have any time for that now but I think I
will have to hang out here and hang out
outside and I have happy to answer your
questions so thank you very much for
coming to my session</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>