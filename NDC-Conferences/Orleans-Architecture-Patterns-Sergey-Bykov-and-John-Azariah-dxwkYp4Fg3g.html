<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Orleans Architecture Patterns - Sergey Bykov and John Azariah | Coder Coacher - Coaching Coders</title><meta content="Orleans Architecture Patterns - Sergey Bykov and John Azariah - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Orleans Architecture Patterns - Sergey Bykov and John Azariah</b></h2><h5 class="post__date">2016-10-18</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/dxwkYp4Fg3g" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so good morning
who here builds applications for living
who was distributed applications for
living who would like to have the
problem of scale so that's actually the
biggest problem that we face at some
point in the in the app dev cycle right
and we all want to be successful but
then sometimes successes they actually
the dragon that kills us and scale
becomes the enemy rather than the friend
that we want to have and in in many ways
we have had over the last few years
since the birth of the internet and so
on various technologies various tools
platforms rules of ways of building
applications to try and get us to build
scalable applications to defeat the
scale monster so we're going to talk
about Orleans which is a platform that I
think that is the problem fairly
squarely and in some sense I think this
is the way in which we should be doing
highly scalable applications in the
future so welcome to our talk my name is
John Ezra I work for Microsoft as a
software engineer and this is Sergey
back off he's me
it's actually been Deb lead for project
or lean since the beginning so this is
kind of a cheesy slide and actually I
think correctly the slope should be the
other way around it's our PowerPoint
skills are not great to express what you
want to show so it shows the general
kind of scale growth but you think about
if you step back it's not just scale in
terms of a huge number of servers their
architecture is hit their limit with CPU
sizes in terms of number of transistors
we can put and the scaling out even on
the silicon to silicon level so at some
point the movement promised 100 core
CPUs a few years ago at some point they
will arrive and interestingly enough in
that case you cannot have character here
memory even at the processor level so
you need to do some kind of message
passing and scale out even at the lower
level
so this patterns in general conservative
scale they apply
I believe all the way from the silicon
to the cloud scale of the cloud just a
quick intro to your liens for somebody
who is unaware so at least is the
virtual actor model where you program
kind of like in distributed C sharp
paradigm so you start by defining an
interface which has a synchronous
methods return tasks GPL tasks it
promises for future values like in this
case say hello method takes a string and
returns a promise for a string that will
be fulfilled at some point in the future
so you define this any faces and that's
one hard requirement you have everything
asynchronous and then you can use it
it's gonna code in this way so first
line you get a reference to the grade
the logical reference we're saying
factory class give me a reference for
grain that implements this interface
which was defined for identity of the
actor recalled on grains the user ID and
that proxy you get back at implements
already in FA so you can make a call
right away so it's totally local
operation doesn't require any
round-trips lookup to just construct
identity essentially in the form of this
proxy object underneath and then make a
call and so the magic of GPL async/await
you can await the call without blocking
thread and then continue execution when
response actually arise so that that's
the basic constructed very basic level
and when you implement you implement a
class that extends the base class grain
and implements one extensive base class
grain and implements one or more grain
interfaces like in this case our user
what you get here is the single threaded
execution guarantee so this method will
never run concurrently with any other
methods or any other calls to the same
method so that's the guarantee of the
framework and it allows me to have a
private variable counter and you just
increments on it without worrying about
data races concurrency and I need logs
semaphores so this is what the the
probably model is for developer but
under the covers this actual grains they
go through this lifecycle so
logically they always exist logically
can make a call to any grain with any
identity of any type in the system you
don't care you don't check if they're in
memory or in storage but most of your
grain is actually in storage they're not
in memory because they haven't been used
recently and so as you make a call as
the method call arrives it gets
activated boots and memory and one of
the server's handles requests as they
come in and as it becomes cold they
request stops coming in the runtime
knows that it's not used anymore and can
deactivate it and the process it makes
calls to the grain cold say I'm
activating you if you need
initialization do it now or I'm about to
deactivate you do something before I
remove you from memory that that's the
basis on which we're going to build the
rest of the patterns just kind of a
primer to the general model that's right
so in another thing that so it's okay so
we we have basically the act as the unit
of computation that's a traditional way
of thinking of actors right but one of
the extensions that are present in in
this whole activation deactivation cycle
is the ability for a grain to actually
store a little bit of state so not only
is it the unit of computation it could
also be the unit of data storage so the
very very simplest pattern that you will
likely use at some point is please allow
me to store this bit of information and
access it later and the address of the
information is its identity right so in
in in a distributed environment we have
the ability to say here is a grain and
it's only reason for existence is the
ability to store a bit of information
and give it back to us when we need it
the beauty of this is that the the
access to the state will always be
serialized as I pointed out we have a
single threaded model for accessing
everything so you never have a
concurrency issue when it comes to
dealing with that so you can think about
the the grain state pattern as the
simplest way to deal with distributed
data and you know in the smallest very
possible so the pattern so by the way
let me let me take a step back
little bit about what it is that we're
actually talking about in this talk
right we have a fair bit of experience
in building real-world applications and
we've used Orleans to build real world
applications and there are quite a few
common patterns that we come across so
for example in traditional way we would
deal with a three-tier model we would
talk about you know entity relationships
for the databases and then you have a
domain model for defining humidity and
so on and so forth these patterns are
equivalent in terms of how we build
applications so all the code that I'm
showing you is freely available will be
pointed to the github repo take the
patterns and use the masses I'll spend
some time explaining some of the complex
patterns how they're actually
implemented but you actually don't need
to even know about those you just have
to use them so in the case of the object
store in the case of the object store we
start by basically defining the entity
that we want store and this is if you
did design this would be a domain entity
right and all we have to do is make it
serializable as part of a pattern what
we have is an interface that's the laser
you know so this interface is actually
part of the pattern library you won't
actually see it but I put it up here to
show you what it looks like and like I
said it has only one raison d'être life
it should store some key item and give
it back to you when you wanted right so
we write this bit and we write the
underlying green implementation for you
so in order for you to use it the
simplest pattern can possibly think of
create an item grain that just extends
from that define your grain
implementation as base class
implementation and provide a storage
provider which tells the the runtime
where you want this grain persistent and
that's it
it's actually a simplest bit of code
you'll write and here's an example of
how it actually works is the form too
small is it too small
oh okay it's on github fundamentally
I'll smoke it through you know you
create the grain State this is an
instance of the piece of data we want to
store get a reference to the grain as we
saw earlier and then store the reference
store the data in there in that grain by
calling set item and that's you creating
the item and you reading the item is
exactly get item on this so this is the
simplest piece of programming that you
would use to simply store and retrieve
data right not all the patterns are
going to be this simple so the next
pattern is an interesting one so if you
think of that as the row of your
database table this would be the table
here we have registry which is just a
grain that keeps references to other
grains and you don't actually the the
grain does not intervene in the
conversation with with with the things
that are stored all it does is keep a
group of grains related grains together
this is a fundamental pattern again we
will see this being used all over the
place and the state management of this
registry grain is taking care of in the
pattern so you don't have to write the
management of the list of grains and so
on and so forth so again the usage
fairly trivial this time we we say hey
we would like to store or we would like
to register a bunch of I catalog items
into your registry and again very
complex implementation which simply
write underneath the covers the registry
grain knows how to take care of doing
stuff so where we use it um sorry for
the small fault but it's on github
we do them much the same thing create a
catalogue item set the item and then
once you get the item set in the grain
you register it in the registry right
and then when we need to use the catalog
then we can just pick things off from
there now let's take a look at this code
from the point of view how we're going
to use it so you know let's say you're
building the next time is alright and
you've got a bunch of things that you
want to keep track of that you need to
sell each item is virtually independent
of each other I do every other item so a
good thing to do then is to model each
of the items that you're gonna store in
your catalog as an individual grain and
then every time you want to say group a
bunch of grains together so say I'm
stirring I'm planning to do clothing
right so every kind of shirt that I sell
or every kind of pant that I sell is its
own grain but then I can have a registry
that says this is a list of all the
things that pertain to shirts and this
is another registry of all the pants and
then I can have multiple registries that
talk about the various sizes so give me
everything that you know fits in this
extra large size or whatever it is so
you can have multiple registries having
references to the same grain and you can
have the same grain register in multiple
registries so that kind of a matrix
model vastly simplifies any and because
the the registry actually doesn't
participate in the conversation and the
grain all it does is hold a reference to
it it doesn't add any performance
implication to you receiving information
from it and there's no consistency
problem either because all that this
thing is doing is keeping track of the
reference has nothing to do with the
material inside the grain itself so as
you can tell right this is already
starting to be
a fairly powerful sort of introduction
to how you use storage patterns with an
audience now of course you know we don't
just read things and then we land up
having to persist the things the
traditional approach to doing this is to
have you know caching pattern where you
have front ends talking all the way down
to a source of truth that would
traditionally be a database but for
performance reasons you have multiple
levels of caching in between and then
you have the interesting problem of
trying to figure out when should I
invalidate my cache and how do I make
sure that the right information is in
the right place with the right freshness
guarantee right so audience has an
extremely elegant solution to this
problem and so the release model of this
virtual actors it essentially creates
the cache pattern by itself so did this
virtual cycle of grain getting from
storage to memory and back that
essentially gives you a cache so you can
encapsulate individual pieces of state
like catalog items in John's example the
individual grains and whenever they're
used there will be lifted to memory and
then all read access will be from memory
but then the writes instead of going
directly to storage and then causing
this cache invalidation problem can go
through the exact same item and all the
concurrency issues of concurrent updates
those issues disappear because all the
writes will be routed for the same piece
of code that executes in single threaded
manner and and talk to storage alone so
in the simplest case you have read-only
so you have many many reads that you
need to serve like a web page but by
going to its storage only once and
lifted the storage it stated memory you
only solving a lot of problem of latency
and throughput and reduce load any
database without introducing a caching
tier like memcache the Redis or what
have you so read through is when you
write through that grain into the state
so presumably you have mostly
but some rights in this case you get all
the benefits of read-only and you only
pay for rights when you need to
interestingly enough if you think it
this is trivial but this this fact that
you remove a concurrency on the right
axis is actually very powerful when you
use key value stores with the attack
protection and things like that
we had an example where one described
services
you got great benefits on performance
and costs reducing the cost because they
eliminated all the right conflicts
they've been processing telemetry and
aggregating story into an azure table
and because they were coming to
different front ends on being processed
and try to try to update a row in the
table and yet I eat tag by relation
because some other code already updated
so you need to reread reply and retry
and then the other guy is trying to play
the same thing there are links based
cache essentially eliminate this problem
altogether so they get to zero or right
conflicts effectively in case there is
no failure and then if you want you can
also do right behind if you can afford
to infrequent to lose some of the rights
in case of an hardware failure in
network or availability issues like you
can write say every minute or every and
number of updates or some combination
thereof by just using the timer and say
hey accumulate writes and Android and
periodically begin reducing load the
storage system if we put it into the
catalog terminology hope this font is a
little bit larger can you read it no yes
No
so you say we can define two different
interfaces one for read access and one
for write access and we can define
semantic operations that we don't have
to necessarily load everything we can
say give me just details or all the
information or key data so we can
program in this kind of object-oriented
way or we have this object and has
methods and you can do semantic
operations in a comparative talking to
key value store we say give me value of
this key thank you you have to translate
it yourself here everything behaves like
an object and if you see here in real
example you just have a couple lines to
call to get data and couple lines to
write data and you don't have to worry
whether the data is loaded to cache or
not or whether it's it storage it's all
automatic and when you implement this
code it's equally simple you just need
to put this data in either return the
state or put it and then write to
storage and it's very trivial code I
would argue so even though we refer to
this pattern is smart cache it's just
the case where we couldn't come up with
a better name you could call the active
objects or distribute object but those
terms were tainted essentially or abused
over decades so we didn't call them that
but effectively you have this active
entities that have their incarnation
cycles or you can get activated on
servers in your cluster and they live
there for when they need it and
disappear they always addressable you
don't have to take care of loading them
into memory and removing them from
memory and it's actually the most
popular pattern and that's sort of a
foundation for a lot of the services
that people build on top so that's like
I would suggest even though we call it
smart cache it's much bigger than that
in reality in this case we persisting
data persistent state as is but as John
would argue that's not necessarily the
best solution to always save update and
he's gonna talk about the event sourcing
option yeah so this is probably a good
time to tell Sam that decom is not a
good name for this
better right so we resisted the idea of
doing that anyway so we've we've had a
whole bunch of problems that we've
figured out over time in terms of scale
with updating state and as a functional
programmer every time I see a shared
mutable state I have a problem now
clearly you know audience is gonna grade
to great lengths to make sure that the
state writing and mutation happens in a
serial fashion so I get the guarantee
that only one thing can actually change
the state at any given time and with the
smart cash pattern I can actually pull
stuff back but I still have a problem
with that because I lost context why did
the state change you've tried you've
tracked the fact that state has changed
but I actually don't know why and I and
it turns out that in in the business in
the business world a great deal of
secondary information can be derived
from analyzing the events trains that
caused the chase state to change over
time which is why when you put something
into an amazon shopping cart and take it
out they can actually predict hey it's
the 14th of the month you're probably
blowing budget you really want this
thing you're likely to buy it in the
next two weeks they can actually derive
that information whereas if you hadn't
had the event stream in place what would
have happened is all that would have
showed up in the database was the
updated you know shopping cart so to
prevent that kind of thing from
happening we have an event so the
sourcing mechanism now at this point
things are going to get a little hand
wavy and the reason they're going to get
a little hand wavy is because we are
going to augment not just the Orleans
pattern but progressively going forward
we're going to update the type system
that c-sharp uses and eventually extend
the language itself to be able to
to support more complex patterns right
so the park is going to get a little bit
complex at this point here's so think
about what it means to store an event
that is going to change state well the
event has got to be a type of some kind
and there may be a bunch of
specializations of that type based on
the business event so for example let's
think of a bank account and you can
credit money and you can debit money
both of those are events and we have to
somehow formalize the relationship
between the event the thing that is
changing based on the application of the
event and to make sure that we don't
have random things being passed off as
events you have to somehow contain the
structure of the event into a type so
think of T event as an enum four types
except that it's a little bit more like
an enum on steroids
not just on values but on types
themselves so people they have sharp
community or any of the functional
programming community will recognize the
event as a discriminated Union type
which doesn't exist as a fundamental
building block in session we're going to
fix that problem in a bit in fact we
have fixed the problem in the patterns
you'll find that there's actually a
pattern for creating this community
Union types and we use that for the
event right but in the pinch you can
actually use the F sharp type itself you
can define your TF and type in a library
with that shop and have a succinct way
of defining what that looks like now the
green state is another interesting piece
here because if you think about events
touring we're storing events a list of
events that affect the grain state so we
have to somehow augment the information
about the grain state to say hey this
particular event changes me in this
particular way where you're going to get
that information from so you have to
bring that information in as well so we
have to make sure that the grain States
not just any old state anymore
it's a state that has an implementation
of a method and that method is specified
in that I can apply that it's kind of a
cute name
simply because your stick in front of it
but it's really I'm capable of consuming
an event and changing my own state right
so again fontsize sorry
but really what you're doing here is an
example and I'm gonna show an example of
a credit and a debit we have a bank
account grain that we pulled out and
we're going to show the account state by
just looking at all the events that have
actually happened but then we call
credit amount and it should change the
balance but not just change the balance
but also add on the fact that it
recorded that it changed the balance
because of a credit and those the the
sequence of events over here will
actually land up accumulating over time
I'll be happy to show you the code for
what the event actually looks like but
it's really really really complex
anesthesia it's four lines in F sharp
well it's about two hundred and C so C
Leone is smiling if you if you think the
font size is small on this one you'll be
much worse if we do this so just take it
from me that the concept you have to
realize is that now we are really
talking about encapsulating intent in a
type that's your event type and
encapsulating the ability to consume
instances of that event and change your
own state and that's the bit that
actually implements the I can apply
event okay those are the two fundamental
pieces that allow us to build this
complex pattern I'm going to go on a
little bit and talk about something that
everyone asks me all right now we've
managed to put stuff in into some kind
of an object store we've managed to read
it out so we have the ability to do
cataloging type of thing using that
smart cage pattern and registry I can
put things on same I can say all shirts
my size
that a pink in color 20% off I can do
that by basically creating a registry
for the shirts that fit my requirement
and then through that through that
registry go and get all the items and
update some state associated with it
right so if you think about it that's an
that's a pattern that we can already do
but how do I report on these things
people asked the question about how do I
find out an ad hoc query select star
from and it turns out that's a difficult
problem to solve because we've kind of
sacrificed that for the ability to talk
about the individual units of state and
individual access to that state so
because of that we now it's still a
valid use case it's still absolutely
essential that we want to be able to say
for example figure out how much money we
made that's a very good thing right
meaning you have to figure out how much
we sold and then how much money we got
and how much stuff we had to give back
in refunds and all of the other stuff so
that's important so we're not
downplaying that we have a new pattern
for it this is the first example that
you'll find in our pattern story where
we take existing patterns and compose
them so if you take a registry pattern
now and the events are same pattern we
can process the events in more than one
place so the event comes and changes the
state of grain forward that event onto a
registry that holds a bunch of grains
that were interested in and now we can
aggregate by applying the event to the
registered aggregate if you get my drift
right so we create a green which
aggregates events from a set of
registered grains and then we can apply
those event processing things with a
various set of strategy so for example
the simplest strategy that we have is
the one that is lazy load you want a
total I'll go and compute it for you
right I'll compute it for you by asking
each of the grains to give me the set of
events that I haven't seen already
and I will consume those apply that on
to myself and then I will hand you a
total and that is now valid as of this
time so inherent in this is the concept
of eventual consistency because stuff
may be happening all the time
but your total will be valid as of a
given point in time which if you really
think about it that's all you get in a
guarantee from a database anyway the
fact that you can do a select star from
something and sum it up only tells you
the validity of that sum up unto the
point when you did the query we get that
from here again this code is already
there it's written please go and look at
it it's quite complex
the purpose of this talk is to walk you
through the possibilities of what we can
do the actual bit about actually
aggregating stuff and playing these
events and so on and so forth the codes
there and hopefully it's readable there
are very few for loops in it those
people attend my talk yesterday you know
what I'm talking about
so here's here's here's what the
aggregate pattern looks like and it says
hey I'm a registry of tea grain so now
I'm going to have references to a bunch
of tea grains and each tea grain is an
event source screen that has a bunch of
events that are gonna fire it and my
grain state is going to be an aggregate
as well because I need to be able to
handle the event so just by looking at
the type signature of this interface you
can get a sense you can reason about
what it's actually going to do and as it
turns out we have to introduce this
concept of a timestamp to value because
we actually care about when the events
come in so that we only play the events
one at a time and once at most once and
we're able to do this so again the
implementation is fairly straightforward
but this is interesting because I want
to just show you what it looks like
build the drain state class to implement
I can apply event and in this case the
apply event effectively does a pattern
match on the various operations that
come from the discriminated Union I was
talking about and you only need to
provide the bit that says please add an
amount when I want to credit and
subtract an effect this is all the
business logic that you really need to
write and you can even unit test those
bits independently so with that with the
kind of composite patterns that we have
now you can actually build a fairly
sophisticated system with minimal amount
of clutter from your site and that's the
goal of what we want to use orleans for
is to be able to say hey don't think
about it as a distributed sea nor think
about it as reactivating a green on a
remote server and all of that what do
you really want is I have a bunch of
bank accounts and I want to keep a total
that's what creating the bank account
looks like and that's what aggregating
it looks like that's really all that we
need to worry about
in fact that's all you have to provide
this you will definitely not be agreed
because I could read it but I'll just
walk you through what's happening you
get the account aggregate you get a
bunch of grains there are ten of them in
our system so you get a whole bunch of
grains here and you register the grain
because that's what you do with there
with this this is now behaving like a
registry credit a hundred dollars to
each of the accounts and then read the
balance from the aggregate and magically
in the background because you're going
through the registry at this point the
aggregate value will go off and in the
lazy strategy go and pull all the
information update itself and provide
you the value and this value is now
eventually consistent so you can now add
this lot another $100 for each of the
accounts and you'll find that this will
actually land up being to the
so this is a way of aggregating stuff
now one of the things that this is
simple scalar aggregate there's nothing
that prevents the aggregate from being a
vector so you can actually keep track of
other grains so you can say you know you
can get a multitude of rows you can
aggregate down to a list of things and
therefore at this point we have if you
think about it implemented an object
store just to be a platform with minimal
code that you need to write to make it
work we have the objects living in a
scalable way we have thread safety
safety guarantees to make sure that you
have concurrency management you have the
ability to eventually you compute
aggregates with the eventual consistency
you can create materialized views those
are the standing queries that that those
that I will get plus if it could be lets
you set up and you can actually build a
fairly sophisticated system without
deviating too much from the domain model
that you would have come up with when
you did your domain driven design to
begin with the single anti-pattern in
this whole thing is the ad hoc query so
if you feel the deep desire to have an
ad hoc query the first question you
should ask is why because at the end of
the day even in a traditional
application you are not giving a sequel
interface to your applications database
you're only using the ad hoc query to
make it easy for you to do development
well you can do the development
internally it's a little bit more work
you have to formalize what kind of views
you want and so on but the building
pieces for the object store are already
here now we have spent about 35 minutes
going from a very very trivial a single
object store all the way down to a
scalable object
database and I appreciate the fact that
the levels of complexity that you've
been asked to simulate significant so
I'm going to take a pause here and see
if there's anyone who has any questions
because I think we will we will address
these questions while you still have
them fresh in your mind does anyone have
any issues they want to discuss that's a
brilliant question so the question that
was asked was does the aggregate pattern
introduce a bottleneck because now you
are processing updates through the
aggregate the answer is actually it
depends on the strategy that you pick so
that the pattern that we have allows you
to update and send events to the greens
themselves that's what the traditional
events closing model was we then queried
the grains for the events that we
haven't seen yet
on-demand so there's no throughput
bottleneck when you're writing stuff we
don't broadcast the the events to the
aggregate at the time when you ask for
the total then we say hey let's see how
fresh my total is starting from then
till now has any of the grains that I've
referenced do they have any events that
haven't processed
right so there's a strategy pattern
that's built in called the lazy loaded
strategy which does that for you now you
can replace that with a more eager way
of doing it there are actually far more
sophisticated approaches that you can
take for example when Sergei talks about
streaming you can actually publish the
changes that come to you and consume
them as and when you like so you can say
for example have a thread that runs off
and every 10 seconds keep your data up
to date right if that's all you're
interested in that's all you'll need to
do but the decoupling of the computation
of the aggregate from the writing of the
individual events into the grains that's
the fundamental reason why the stuff
works so we actually deke up with those
and separate them out and make them two
separate problems updating the state via
saving events is one story computing the
total in some form either proactively or
reactively or lazily or whatever that's
actually a separate concern and we had
the ability just plug whatever strategy
you want in there to be able to there is
also another pattern which we're not
covering and reduce pattern where the
aggregation can be done in layers so
instead of having one aggregate at half
like at first later I could get a second
layer aggregator and that's very
scalable because instead of going to one
you pulling it pushing you go through
several layers of aggregation just we're
not talking about in this talk but it's
there and then I release can't reap repo
it's also there
so um one of the recommendations in
event sourcing is actually taking a
snapshot every X events so you don't
have to replay a million events is all
liens doing a similar thing so remember
that all this stuff is not actually
being done as a foundational piece of
our lanes the the reason we have this
talk is because all means is
extraordinarily scalable it's totally
powerful and people build all kinds of
cool applications on top of it but when
you want to write applications you'll
find that you will have to replicate the
same similar patterns so what we are
talking about is actually a level above
the fundamental set of orleans right so
in terms of the questions that you
raised that's a separate strategy for
creating the materialized view you can
have the materialized view update itself
every ten minutes and if ten minutes
resolution is all you need
well you don't even have to go and ask
at that point you just take whatever
aggregate value having passed that along
and knowing full well that in ten
minutes someone else will come and
process all the events that have
happened since then the pattern that
we've shown you is an example pattern
how to create a lazily loaded aggregate
the fundamental interface that we have
here will not change depending on which
pattern which strategy you use to get
the aggregate plane this specific
aggregate Green turns out to be a lazily
evaluated but you can most certainly
have to keep the materialized views
up-to-date any other questions
sorry other events actually sort of
persisted with the grain historically
can you go back and replace them that's
an excellent question so this is one of
the reasons why we use composite
patterns so if you look at the aggregate
grain there are composite patterns in
this so we have a system now where the
grain state of the brain itself is going
to be able to process its events so what
did we do when we wrote the event
sourcing pattern we actually said hey
the grain state that you want to you
want to store information about a shirt
fine I'll do that but I will also store
all the things that happen to that went
so in the case with the example we had a
bank balance with and all the credits
and debits and the Augmented green that
we've generated for you when you say
this is in the aggregate Green takes
care of storing the events and
persisting it so you don't have to worry
about any of that so as far as you are
concerned you send an event by making a
method call please credit me $100 or
whatever it is internally what that
translates to is I will instantiate an
instance of the event called credit with
the argument of a hundred time stamp it
with now store it in the sequence and
when the aggregate comes and says please
give me all the events I haven't seen I
know which ones to pull out and give
back so the storage of the events and
all of that all of that stuff is
abstracted away for you and implemented
in the pattern so you can use the
pattern as is so you can extend it to
how to be whatever you want but this is
one of those powerful patterns that you
can use it's the time chugging we have
15 minutes can we hold your question
till the end
excellent thank you actually at this
point is a good time to actually stop
and switch gears entirely so I'm going
to ask Sergey to talk about it so far we
talked a lot about the managing state
and you created this object store but
what we didn't talk about is the
relations and in this data so we kind of
have this top-down view you have
individual items you you go and call
them but in reality in many scenarios
you have relations like in this picture
it's a multiplayer game like a graph
where it shows players that have shortly
relations for game sessions but
longer-lived relations is part of a
client or a group of friends whatever in
this release model it's very easy to
very initial to model because this
reference to your grain that you get
from the system it's actually just
identity so you can easily save it as
part of your state and establish this
age would be a relation with with
another grain
and because that other grain doesn't
need to be in memory when you have
relations with it that makes it very
easy to program this is where the
virtual actor model works much better
than the traditional approach to actor
model with the kuru lank
akha where you have to have a physical
reference to all these objects so in
order to have a graph of relations they
all have to be in memory and have
physical references or your eyes or what
have you there and this actually is a
very popular I think that's used in
production in many services where in
gaming the main but if I switch to this
slide
nothing is changed except for I change
words they put in those in those boxes
now I have devices IOT devices or
sensors and controllers and in rooms
where they belonged it's the same kind
of problem but now it's it's a much more
static graph than than the game graph
where a relation is changed that's why I
like when we talk about social networks
people immediately jump into Facebook
Twitter but in reality this network of
relations in graphics is much more
general problem and it's very easy just
all here but but also if you look at it
you kind of get back this
object-oriented feeling of your program
which we sort of give up early on say oh
yeah everything has to be a service
oriented so and all kinds of variations
microservices they all kind of push you
to think of your program from the
services perspective but as developers
the natural way to model things is
through objects and narrow relations and
this distributed network of objects or
you see with network of entities sort of
gives you that power back and that
sanity of dealing with objects and
relations like a graph of nodes and
edges between them and because of the
virtual actor virtual actor Natura
berlin's you can program as if all of
your actors are in memory so you have
this kind of infinite virtual naming
space or address space that you can
program without worrying about do you
have enough memory or they need to
always something to unload so you get
automatic resource management and of
course there ant anti-patterns
so if you have too small of a grains
there
too much connectivity so you need to
send too many messages we have to course
of a grains they become bottlenecks
because you trying to process all the
stuff there on the single within the
single thread guarantee concerned so
chatty communication in distribute
system is always pain
another thing sort of orthogonal to that
is the early streaming feature which we
added two or three years ago I think
what we show it so far was RPC style
communication between actors or client
and actor where you get the reference so
they make a call and get a task back
which covers a lot of scenarios but then
in some cases you want to decouple
producer and consumer or you want to
make this messages this events to be
reliable because RPC may fail if you
don't have a network connection if
something happened if machine went down
with streaming that can go over a
persistent queues you solve this problem
because the moment I published and got a
confirmation that might then get written
to a persistent queue I'm done it's it's
the problem of the receiver of
subscriber to process it later so this
is a very powerful feature that enables
a lot of scenarios like that back in in
the energy case devices may ingest data
into the queues and not worry about them
being processed they can a done their
job as the queued events and the key
thing here is that there's no notion of
logical stream so we call them virtual
streams you have virtual actors with
virtual streams so they all you can have
again infinite amount of them because
it's just identity but physically they
get multiplex over physical cues whether
you use AWS sqs or Kafka or even hub as
your queues the under the covers get
multiplex or those physical pipes and
here's an example of a streaming
analytics kind of case where I have
grain that is explicitly told to
subscribe so it has this let me try to
use this fancy laser pointer so it's
explicitly told to subscribe to a stream
and pass the source stream and an
identity of the source stream is a good
and identity of the alert stream so the
I keep receiving events and process them
and if there is some condition is met
like i exceeded threshold or I have five
bad events and we didn't spend every
minute I need to raise an alert so to
set it up when I call subscribe I get
the stream provider in this case in just
the name of event hub provider and I get
a stream for source stream so I pass the
ID and the name space device events and
I subscribe this class that implements I
sink observer of device event so that's
all I need to subscribe explicitly to a
stream of events but they also get a
stream for alerts so I use the LR stream
ID and a different namespace of streams
this is the stream where I'm gonna
produce my alerts to do so when the
event arrives this uh next async method
is called canna rx ish API I process
this event and I get an alert and if
alert is set I just do on next async on
the other stream that's my output and
it's kind of all I need to do to receive
advance process them and I can run many
of them in parallel so you can have this
one per machine and monitor and one for
device for monitoring it's very easy
with this addressing scheme but then if
you look on the alert side we use a
different feature here I apply this
implicit stream subscription attribute
which allows me not to subscribe
explicitly to a stream so this this
grain class alert processor great it's
already subscribed to streams within
this namespace device alerts remember we
use in here to produce device alerts so
I'm associating this grain class with
the namespace of streams and then these
goods would map to a goose of grains and
my grain you can get activated right
away so in my own activated sync which
is kind of like a constructor of a grain
I set up a subscription it's because
they cannot persist lambdas and then
when the event arise I can again process
it and if condition is met I can do
whatever I want they can make a call to
your web service I can write to database
I can make a call to another grain so
it's kind of freeform model so why we
build it so we needed this ability to
process
large streams of advance a large number
of streams of events with low latency
and high throughput and it came from
sort of another set of Halo game
scenarios were streaming a latest
defense during the game keep coming in
from consoles into the cloud they need
to be processed at the end of the game
you need to show all the statistics all
the results like headshots and kill
death ratio all of that at promotions if
you calculate it by the time the game is
done so these calculations happen as
events arrive and get processed in the
grains and at the end they just get
quarried in return and there are many
others many other applications like
detection is no different from credit
card for detection because you see the
patterns you follow you monitor a
particular credit card number you don't
need to monitor all of them you can do
this grain per credit card number and
seed events coming in and analyze their
relations and then race alerts if you
see things like that but you can also
apply streams for the aggregation where
instead of signing data directly
accordion you can just publish it in the
aggregation streaming and process them
separately in decouple your event
sourcing part from from aggregation part
so this covers kind of our touches at
least in larval state and some their
relations but we haven't talked much
about compute this is where John will
continue yeah so state machines they're
actually everywhere most of the code
that we write they're actually
concurrent state machines that need to
be run in a scalable way think about
shopping cart let's go back to the
e-commerce thing each shopping cart is
actually a state machine it's it's you
if the state if the shopping cart is in
an empty state well checking out
shouldn't really be allowed
you can abandon something that has
something it's full and you can check it
out if you want but you shouldn't check
out an antique shopping cart now this
business rule for example is really
something that should be modeled
somewhat formally as a state machine but
usually gets modeled informally and the
source of most of our bugs actually
comes from the ability to my inability
to reason about these side effects that
are encoded implicitly in the code and
that you have to then discover the
intent off by walking through the thing
to see how did we even allow this to
happen right and anyone who's done stuff
in this earth in the service arena knows
this is why logs exist and so you're
sitting there mostly trying to do printf
debugging on something that happened you
know in a server that sits in Sweden
which you have no access to and you're
trying to reconstruct you know what
killed the patient right we don't want
to do that be much easier if we had a
formal way of actually managing state
within the context that allowed you to
formally talk about it right and so one
of the approaches for this is typically
I mean if we use steepness
micro-services and then manage the data
in the implicit form to achieve this
ability or you could use the actor as in
effect a stateful microservice that had
the logic built-in in any service
nanus service nanus - - is because
whatever right and so like I said we
have now taken this pattern and come up
with an example of what that would look
like and again I'm not going to show you
the code itself it's really horrendous
in indicia because of the lack of
discrimination unions we will see why
that is in a minute
but further we've actually formalized
the business logic of say a bank account
is a toy bank card over here so let's
say that you have a bank account it's
identified by an ID you're interested in
its balance it can be the you know
accepted a deposit or a withdrawal or
you can close
it initially when you bring up a
bank-owned please don't put money into
it it's a zero balance account right and
if it's in zero balance then you put
some money in my deposit it becomes an
active bank account or you can close the
zero balance account and go to closed
when it's active we can deposit some
more and it'll stay active if you
withdraw depending on how much you
withdrew it'll either be an active or an
overdrawn or a zero balance right and if
you're overdrawn please don't let them
take any more money out of the thing the
deadbeats have already taken the money
out of the account you want to take some
more and depending on how much they
deposit and either get sent back into
grace or they stay overdrawn or we can
finally get to the point where there's
zero balance and notice now that you
can't close anything other than a zero
balance account now by embedding this
kind of logic into the the formal
description of the business you've
eliminated entire swathe of problems
this is a whole bunch of unit tests you
never had to write write so of course
you know people owe me is the dude so or
as an F sharp dude so my problem
everything here is a type problem as far
as I'm concerned if you look at this
that's a discriminative Union a message
can be only one of those three things
that's a type the set of states is also
discriminated Union can only be in one
of those four states that's also a type
each message that is acceptable at a
given state that's also a type each
return value that is possible when I
receive a message that's also type so
now you've got a whole slew of
discriminated union types each of which
four or five hundred lines of co-op code
so the faults really really couldn't be
smaller when I show you what the code
looks like right but you can actually
generate most of it so there will be
another talk at some point in the future
shortly where we have gone ahead and
built a tool that pauses this language
and generates the Orleans green for you
but in the meanwhile you can actually go
and see
what that looks like and see why there
is a need for a generator because really
what you want to do is what do I want to
write when I want to create this bank
account
I want to write what does it mean to do
this when I deposit something what does
it mean when I would draw something how
do I know which of these three values is
returned that's really the entire
business logic of the application that I
wanted right I don't want to worry about
scale I don't want to worry about where
this object lives I don't worry about
grains grain States none of this I am
only interested in writing six functions
in this entire thing and I want to have
the guarantee that I couldn't make a
mistake and with that motivation in mind
you know we can actually build an
audience grain back-end that supports
this behavior in a scalable way allows
you to run 10,000 of these accounts in
parallel if you like manage each
individual account state independently
and concurrently and allow you to
interact with it in a sensible way so
rather than show you how it's done I'll
show you how we use it because we're
really really short on time at the
moment so here's how I create a bank
account state machine and if I get this
balance at this point I would expect
that it's zero and then I create a
deposit of $100 I expect it to be zero
but now my state better be active which
means that I should be able to withdraw
$20 from it and my state better be
active and if I try to close an active
state machine what do I expect an
exception I expect not to be able to
close that so if I had ran this code I
would actually get an invalid message
returned as an exception saying I tried
to close an account which was it in zero
balance State and I failed as I expected
it and this whole thing comes with
intelligence because of the type system
that's really the state that we are
trying to aim towards right make
developers productive and give them the
ability
scalable applications so I'm gonna wrap
it up with just giving you an overview
of the cross-cutting benefits of Arlen's
and we've talked about all of this stuff
you can build very complex things with
it you can build things that require
tools to generate the Orleans grain for
you that's the story that I would like
to leave you with we have one of those
examples in place so the goal behind it
is to let the system manage the
lifecycle of the actors manage your axis
in a type safe way give you a natural
idiomatic
c-sharp way of talking to these things
give you the capacity to deal with
exceptions and type safety and then have
linear scalability when it comes to
actually throwing more Hardware on the
system you so that's actually the cost
cutting benefits of using Orleans and
using patterns that sit on top of
Orleans you can build very complex
things and we have these libraries that
allow you to do that
so the Orleans is open source there's a
very active community that's out there
there's contributions accepted from the
Orleans community in fact all the code
in the patterns that we talked about
will eventually show up over there in
the meanwhile you can come to my grubby
little grid tab repo and take a look at
that and then there's a gator site that
allows you to go and have a conversation
with anyone who's in the audience
community saying would you please help
me with this and then that's that's
where we are at mode I think we're 2
minutes over time thank you don't forget
to leave green feedback I will take
questions actually
so I'm gonna the question is about so
it's it's it's a very deep question
about delivery guarantees so the the
default delivery guarantee in Orleans is
at most ones so we can configure it to
have retries and if you can hear it too
high enough number you can get at least
once in practice what we've seen that's
a not a great idea to do because usually
you losing messages when they're
failures like fillers of machines
fellers of network and in that case if
you keep retrying keep reciting all the
events you're not making things better
making things worse so that's why
default is we deliver a try to deliver
the message and in most cases will get
delivered in some small percentage of
cases when they're failures we get an
exception back and usually the
application code knows has an idea do
you wanted you to try and not said we
thought it needs to be an explicit
decision at the application layer
instead of blindly trying to resend all
old messages which application may not
want to send and then make recovery from
say network partition even harder
the question is what when you send a
message to an actor that is down so the
technically actor cannot be down the
machine can be down and and because all
the methods that you have in in the
grainy face is returned in task you
always have this clear either you
succeed it or you get an exception back
so if we send a message and a machine is
down it just died a millisecond ago we
haven't discovered that it's dead we
just failed to deliver the message we'll
get in a section exception back we
failed to deliver this message which
industry billet systems is always
ambiguous because maybe the message
actually went through connection died
later and we didn't get an act so you
always have this ambiguity with the
tribute systems but with with task based
async RPC you have this very easy a
correlation idea under the cover well
instead of saying one-way messages and
receiving one-way responses and
correlating what went through or not you
get this task back that tells you there
was an exception if you need to retry
Ori or not the queuing yes you can use
only in streaming for this if you like
you can basically put it onto your queue
subscribe some publish some event and
then let the recipient pick the events
of so the queue centric workflow is
typically the answer to the question
that he just raised the way you
implement queue centric workflow is to
go through streaming so from that point
of view you you couple queue centric
workflows and virtual virtual actors
which basically have no beginning or end
they just exist when you need them
those that combination actually gives us
the ability to build systems so Q
essentially give you at least once they
still have this kind of dead letter kind
of handling where it would keep trying
to deliver and keep this legate in
Arabic and there is a mechanisms to
indicate well we're dropping because
because there's no failing to deliver
but other than that it it's at least
once with streams
any other questions oh we made
everything Thomas I'm clear</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>