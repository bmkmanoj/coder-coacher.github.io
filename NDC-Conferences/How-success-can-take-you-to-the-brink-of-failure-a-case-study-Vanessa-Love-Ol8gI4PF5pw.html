<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How success can take you to the brink of failure: a case study - Vanessa Love | Coder Coacher - Coaching Coders</title><meta content="How success can take you to the brink of failure: a case study - Vanessa Love - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How success can take you to the brink of failure: a case study - Vanessa Love</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Ol8gI4PF5pw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">good morning everyone
thanks for joining us here I hope you're
having a great time in DC I welcome to
my talk how success can take you from to
the brink of failure so Who am I I am
Vanessa Lowe I in a past life was a lamp
developer and then that led me a bit
into Linux hosting support currently I
am the lead Support Engineer at octopus
deploy and I've been there for over
three years
I actually specialize in scale the
doctor first we do a lot of
specialization within the teams and
within the support teams and I
specialize in scale one of the things
about me that led me from being a
developer into support is I like talking
to people which is rare among the IT
community I also like helping people
which again is fairly rare but I really
love building relationships with
customers and trying to understand their
needs and experiences so who's heard of
octopus deploy he uses octopus deploy
who sent me a support ticket that I've
answered so close so octopus deploy is a
deployment automation company it was
founded in 2011 and it's the market
leader in dotnet deployment tools the
team that worked on this specific case
study was Damien Brady um you might have
heard of his now Microsoft Paul Stovall
who is a CEO of octopus and myself the
company that we're talking about during
this case study is essential so who's
heard of essential anybody who work for
Accenture Australia
so this is from wiki just to you know
it's obviously the gold standard of what
Accenture is it's a global management
consulting and professional services
company that provides strategy
consulting digital technology and
operation services we were working
specifically with the CIO team in
Chicago that team has six deliberate
delivery centers around the world the
team we were specifically working with
was Jim Schubert that is Parker and Ian
Paulin so I might say their names
throughout the talk so I don't have an
agenda so much as this is a case study
we're going to go through a timeline of
events and talk about what happened
during that there's no no real agenda
apart from we're trying to learn lessons
here and talk about a situation that
happened how it was resolved what we
learned from it
so essential wanted to understand about
deployment automation ian was given the
task to evaluate two different
deployment automation tools so why don't
things I'd like to point out is I've got
a little time over in the corner as we
go through just so you can't sort of
figure out when this is happening so
this was late 2013
ian was asked to figure out which
deployment automation tool would be
better octopus deploy or release manager
they had at the time over 300 apps which
were primarily dotnet apps they handled
their deployments back then via tickets
to an ops team and everything was
tracked on a spreadsheet and it was
really not sustainable but a lot back
then in fact a word that I've seen here
many times is intensive I've seen it in
ears blog post
Jim mentions in a Channel nine talk it
was intensive it was a lot they
determined that octopus was best for
them which apparently surprised
everybody good to hear back then octopus
was very new there were two people
working in octopus it beeped out release
manager so some of the problems that
they had to specifically solve where
their team
needed to be isolated teams couldn't
share projects they shouldn't be able to
see each other's projects they
definitely shouldn't be able to change
any processes that the other teams were
working on
they couldn't share targets shouldn't be
able to turn off machines interact with
machines that another team had and
packages as well and when it comes to
packages not only not being able to
touch other people's packages they
shouldn't really impact each other and
when it comes to packages and naming and
we all know how good developers are at
naming things there were chances with
300 teams that they were going to have
very similar names so they had to have
packages that were just not going to
impact any team they also had to
integrate with existing tools at the
time it was TFS and Active Directory so
these are two very common very commonly
sneered at but very common products that
are used at an enterprise level and they
had to easily onboard the new teams
their pilot project was to get ten teams
into octupus some with very legacy and
some with very new at the time very new
Azure deployments and they didn't want
to micromanage teams and people
Accenture has a very high toner
turnover of people and developers
especially over a couple of years they
didn't want to have to go into octopus
and micromanage any of that so the
implementation it was the beginning of
2014 at the time they had Active
Directory and Visual Studio so an
instance of octopus deploy was installed
back then this was version 2.2 and he
used Rayman DB it was a single
self-contained octopus on a VM so they
had three they have three levels of
teams for every team and admin deployer
processes and then just a player's the
good thing is with octopus you can
easily integrate with Active Directory
and set them up with Active Directory
groups so they could be managed and
Active Directory which they were already
and all they had to do for octopus was
settled up once and
to the right group great and then they
started sending up projects but then we
have the package problem octopus comes
with an internal package repository but
it's shared it's in the library anybody
for any project can upload can use it
can take those packages so the solution
was they installed nougat server on
their own hardware and they set up
individual feeds every team so team
service team foundation server was
directly pushing the packages onto
nougat server which was then consumed by
octopus and then they could easily set
up their environments so when it came to
setting up the second team how do you
completely isolate these teams in a
shared
octopus instance and the good news is
outside of the library octopus is very
granular in its permissions so they
could for projects and environments that
they'd preset up assign them only to
teams and then teams wouldn't see each
other they had Jim Ian and Thad and
others of the CIO team did have admin
accounts across the entire instance
where they could do things but nobody
else could set anything else so then it
became really quite easy they had a
system they had namespacing there is
lots of name spacing when it comes to
teams for the teams themselves as the
projects and the environments they got
so good at it that they automated it
they're very very good automating so
they had a script for any team that
wanted to come in and be introduced to
octopus they just had to run a script it
got really really easy really really
really easy this this is an under
exaggeration this is me trying to fit it
on the slide they ended up with over 200
teams on a single instance of octopus
using raven DB then the inevitable
happens
as well as you can implement it one of
the things looking back on this case
study is if Ian had have specifically
come to us at the beginning and said how
do we do this we probably would have
told him to it exactly as he did we
would have said well we've got
permissions and they're great until it
up it wasn't really a consideration
about what would go wrong so we get a
distress signal and if we look we're
actually in April 2015 so we went from
the beginning of 2014 everything's kind
of okay they're upgrading so they went
from 2.2 all the way up to two five four
but we get a distress signal it's a
Saturday
and I just happen to be on my computer
and checking email as will work really
terrible hours an IT and we can't help
ourselves when the computers there their
octopus instance was completely
unresponsive
previously when they'd be having a few
issues they'd have been out at least
resuscitate it but they could not get it
back it ended up being a specific issue
with our Raven implementation and it was
pullin high-jumping on a call to Chicago
at night on a Saturday just getting the
service back up by teaching them how to
do specific things with indexes and all
fun manual Raven work they actually had
some consistent and reproducible errors
they would have times during the day
where this service would crash or the
CPU would spike or everything would get
really slow and then they started just
having different load causing crushing
errors there were many things that
contributed to what was going wrong they
made use of polling service in octopus
you can have listening or polling
polling as you imagine polls the octopus
server and says does it do I have a job
if it's misconfigured back in their
version again we're on to five thirteen
it would DDoS the octopus server so you
could miss configure a polling tentacle
and take down octopus with it
it wasn't really
something we considered one of the
things with this implementation and what
makes it different from majority of
people that years octopus is the teams
didn't really have an understanding of
their impact to octopus as a whole or
they didn't really care about their
infrastructure they weren't looking at
all my machines online are my machines
beautiful they were building packages
pushing them and just expecting the
other side to work regardless of if
machines were online if they were
correctly figure configured which is
something we had never considered as a
problem that our customers would have we
all assume that you're watching your
servers and that you know if they're at
least online and this wasn't considered
by the teams that were using this a
second thing that would happen is teams
would write bad scripts happens in IT
I'm sure we've all done it but things
like they would write a recursive backup
of their backups and take down a server
they would write other things that would
hammer the octopus server itself and
take it down so unfortunately one single
team in this case because we're at such
capacity with data with Raven with
octopus could easily take down the
server with a really small scripting
problem then the octopus server itself
may be in famously our implementation of
Raven wasn't perfect there were things
that we implemented with Raven that
wouldn't work well at scale they would
get to a point whether it be so many
documents being accessed in specific
ways that could stop the service from
running so there were problems with the
implementation at this scale
another problem we had in this version
which we rapidly fix so if you know
anything about octopus is that we will
rapidly fix problems if there's a bug
there will be and it's affecting quite a
few people its deployment related its
server related we'll fix it very rapidly
and we'll get it out in the next few
builds we had a bug in this version
where health checks would only run for a
minute
they wouldn't timeout or stop being
responsive for a minute they just would
stop running after a minute and with
that many tentacles and machines it
meant that they could never successfully
health check all of their machines the
men octopus didn't have a current state
of what those machines were in and in
this version again I'm gonna say in this
version a lot because there were a lot
of bugs that were rapidly fixed but in
this version if you attempted to deploy
to a machine that we thought was online
but it wasn't it would stall and it
would continually try and contact that
machine which would cause problems and
like I was saying these teams weren't
conscious they weren't active in the
state of the machines they were
deploying - so as well as that octopus
would have actively stopped them from
deploying to offline machines but we
didn't know they were offline because we
couldn't health check them so if you
were running a deployment to any one of
these machines in an unknown state that
was actually a flame it would start
queuing deployments which would bring up
CPU usage server usage and affect the
entire octopus server the final problem
we had was in this version the nougat
libraries that we were using had a
handle leak it wouldn't really affect
people with smaller instances it would
take months sometimes many months to get
to the point where it would stop working
unfortunately when you have this many
teams and this many packages that could
happen within 24 hours and the only
resolution to clear the handles was to
restart the service so I want to talk a
little bit about expectations
would we have expected octopus to work
with this many numbers on that version
and the answer is we had customers with
parts of all of those numbers we had
customers with lots of teams but not
lots of machines not large processors we
had customers with lots of projects but
only one team and maybe only deploying
to a couple of machines all of those big
numbers worked in isolation but any one
of those things when you're doing it as
a massive team would bring it down did
they expect it to work
they weren't expecting the rapid success
that they had internally they weren't
expecting so many people to come through
and start using octopus at such a rate
at such a load they did say that they
knew they were pushing octopus to the
bounds and we would probably have to
agree with that we get requests
sometimes that a customer says do you
handle 30 tentacles I feel like I have a
lot of tentacles it's 30 big like we're
cool with 30 is okay that is gonna be
fine we have other customers and say but
I only have a thousand tentacles and
it's the expectation of what they think
of size they think a thousand is small
again we handle thousands that's fine in
the current versions but the expectation
of what customers are expecting of you
versus what you're expecting can differ
an octopus pretty much during the 2x
phase our customers were small we had a
few big customers like essentially we
had a few around them but an average
customer would only have 10 projects
maybe 30 machines at max majority fit
onto the community license of 20 things
that was our majority base of using
octopus and at that level seamless
perfect everybody is watching everything
so we had to go into rapid firefighting
mode we had to help them get stable this
became a bit of a crisis for us and for
them we wanted them to be able to use
octopus they had a lot of teams relying
on it but then we found out that they'd
been burned by
grades and while I said octopus itself
we rapidly fix things and rapidly get
things out in early mid 2015 they
attempted to upgrade
well they successfully upgraded from 254
to to 512
unfortunately the shutdown of the
service it usually takes between five to
eight minutes which is in there
acceptable range took over 40 minutes to
the point they manually had to crash the
service to stop it
this time they're hundreds of teams
can't access a server their global there
are teams that are awakened trying to do
things their raven database size was
more than 800 megabytes a stable octopus
in that version was about 600 was the
limit so they were over that on startup
of the service we re-index i took over
two hours every time they had to restart
the service it took over two hours
ribbon to re-index and this downtime of
this one small upgrade the upgrade
itself was very quick is just replacing
a few binary files but the configuration
of the upgrade took so long it was
exponentially larger than any other
upgrade that i've ever had they then
once they're finally back into the
servers have to upgrade their tentacles
they had 700 machines or just over 700
machines and the the process just
wouldn't run they found that they had to
script a batch upgrade of 10 machines at
a time which is 70 times they had to do
it back in that version you could deploy
to a tentacle that hadn't been upgraded
because they were the same 2.5 to 2.5
however if there were any new features
it could have caused problems back then
our versioning wasn't terribly semantic
so they passed an internal upper
management protocol they're not allowed
to upgrade octopus again until all of
these things are resolved while we
resolved some of the issues polling
tentacles no longer killed Europe the
server if there were misconfigured some
of the load was handle
we didn't have we couldn't upgrade our
nougat libraries at the time so that was
always going to be a problem for them
but we'd fixed quite a few of the
different issues but they couldn't
upgrade the amount of times i sat in
calls and said yeah we've fixed that in
2.6 and be really cool if you could
upgrade um so we started just constantly
fighting fires with them the first port
of call was we need to get the load off
the server no matter what they need to
get some of this load off the server
they need to deploy a lot so we asked
them to start migrating in teams off
that instance into other instances any
new team coming in because at this time
even though though having so many issues
there was still so much success with
deployment automation and getting your
ownership of your deployments our team
still wanted to be included so we asked
them to on board any new teams onto new
instances stop overloading there's
currently working big incidents they
started enforcing nightly restarts which
fixed quite a few problems it fixed the
handle leak problem meant it gave it a
nightly restart it reset quite a few of
the load problems that it was having
they changed to a listening tentacle
policy only one of the things with the
CIO team is while they were controlling
octopus and controlling the setup
they weren't controlling the tentacles
or the machines all the teams were doing
that so they changed it to a listening
tentacle policy only because it couldn't
bring down my server and we helped them
right at the very top of every process a
health check for machines just to see if
it was on line before it would start
deploying the problem with this is teams
could go in and turn it off
delete the machine we were using to do
the health checks cause all sorts of
problems it it was not very successful
we did ask them to change their nougat
feeds from URI to file share because the
bug only existed if you were using the
URL nougat if you change it to a file
share I broke down the back is going
really yeah really it what it didn't
work on file share because they were on
the nougat server they could easily just
link to it as a file share instead of
accessing it over the web so that was
successful and it took away that the
handle leak problem for them so we were
very active in trying to resolve the
problems bring them online and learn
from this it could have been a case of
not caring we entered into weekly
meetings until we got them to a stable
point from there we went into
fortnightly meetings that lasted a year
and a half because we were helping them
get stable but also upgraded we needed
them to upgrade to 3.0 because it's
going to resolve all of their problems
we learnt a lot from this every lesson
we took from our meetings we then had a
chat and determined what could be done
in 3.0 to fix this how do we fix this
how could we change things we actually
came up with some interesting models and
fixes that every time they say yeah this
happened again we're like yeah we've
fixed it just you wait so we got to the
point of stability
finally they didn't have emails flooding
their inboxes saying what's going on
with octopus I can't deploy they have
five servers with single octopus
instances on them they had 1564
tentacles which were all listening 255
teams across those five servers five
hundred and nine projects on their
busiest day they were doing a hundred
and five deployments and they were doing
roughly one hundred and four hundred and
fifty deployments a week so we went into
full planning mode how are we going to
get them upgraded what would be the best
model to handle their scale to handle
their growth how can we get them into a
completely stable octopus happy happy
nirvana land one of the things we
started off saying to them there's
something Paul had in the presentation
for them is you just can't expect
perfect software we can't know that we
are going to create software that in the
model they're using is going to be bug
free as
going to just magically handle those you
can't do this but what we can do is we
can consider what do we want to solve
and how we can make that happen so one
of the requests checklist was can we
have different upgrade paths for our
teams some teams are more forward than
other teams and they want new features
that are coming out in the old model
they had you would have to upgrade all
the teams at once they want an ability
to be able to have teams on different
versions and different maintenance
windows as well because they had six
different locations being able to take
do maintenance on the Argentinian
nighttime when Argentina is asleep for
their service would be beneficial
because they don't won't intersect
interfere with India or any other
country that is in an awake and alert
and a deploying time they don't want
teams to impact other people so if a
team is going nuts if they do something
wrong if they write a recursive loop
they don't want that team to be able to
take down any other teams and yeah a
team should only be able to break
themselves teams are going to break
themselves that's going to be you're
going to have in an organization like
they knew they would have mature teams
and they would have teams that would
write scripts that would do bad things
so our solution was we want full
isolation for all of these teams let's
break them apart
let's do terrible things to tentacles
when I was looking for all of these
images there are lots of pitches of
cooked octopuses I'm a vegetarian I just
couldn't do it so this was the most
appropriate image I could find of
breaking apart an octopus while we were
developing 3.0 and while dealing with
this situation we developed a model
called high alert high availability so
what high availability does is you can
have one octopus instance you can have a
secondary instance but they share a data
base and they share a file share so
anything on disk that you need
packages toss logs it gives you the
ability to take one down do maintenance
on that server do whatever you need
while the other ones still up and allows
you to deploy so we wanted to go full
isolation we suggested that they have
multiple instances octopuses always
allowed you to do instancing on
tentacles and service so that was
already a feature and we wanted them to
do that but then we took it a step
further let's give you everything you
want let's do this in a chain so they
would have what they've called a node
set where it's every team has two
different octopus instances that have a
shared database and have shared storage
and they had to go big we suggested that
they have multiple of these node sets
which will allow things like one nodes
that could be on a different version
from an other node set if they were
having really high traffic or one team
was over performing compared to the
others they could move it to another VM
that had less traffic or had less load
it gave them more options about what
they could do if they were having the
problems that we knew they were going to
have but it came with some added bonuses
suddenly they could make use of all the
library features that they'd never been
able to use because they weren't sharing
their octopus instances anymore so they
could use the internal package
repository which meant some of the teens
who were using SSH and Linux targets
could suddenly upload zip packages and
do those kinds of deployments they could
also use the step templates they had
tried to use the step templates in the
past but it's but because it was there
and available if one team wrote a step
template that was really specific for
their project another team could find it
and use it and then ask where everything
was breaking so they'd never really been
able to fully use those features and now
they could they can be picked up and
moved like I was mentioning another
problem with our granular permissions is
you can get somebody to create a project
but if they are limited to projects in
their team that project gets created
outside of their team it now has to be
given extra permissions get back in
their team move you needed an admin at
some level if you're creating teams or
environments even if you had that
ability now they could control their all
of the projects in their instance and
all of the environments so the plan we
know we need to separate all teams into
isolated instances and they're on to
point five so that means they'll have to
upgrade to point six we're going to
somehow have to specifically separate
the data they're on a shared instance
it's a single Reb and database when we
moved from Raven to sequel we have a
migration path it needs a 2.6 backup and
will move all your data into sequel they
need to create these new instances and
then they're going to take all of their
packages that they have a nougat server
and put them in the internal repository
so we suggested a path for how they do
this partway through they're going to
have to upgrade from - 5:13 to 2.6 just
to get the correct backup they're going
to have to somehow isolate the team data
so by importing maybe they could delete
the data and then create a new backup
and then that goes into the new instance
take that back up and then install an
instance of 3x on the new VM and migrate
the data into it and then they can move
the packages over I really like this
image because from a support point of
view it's kind of like works on my
machine because it's an octopus right
it's an octopus there's nothing wrong
with this octopus except it's an image
so they had problems with what we'd
suggested we were thinking at a high
level of all the steps that needed to
work but putting it into practice is
another problem it worked in theory they
tested it in one instance and it took
about three or four hours
for 300 teams it would take them years
to migrate it's just not possible
also part of it couldn't be automated
and it meant that they'd be man powers
and hours and just monotonous repetition
in 300 times it also required quite a
few temporary VMs to make it happen
especially if you want to show it in
parallel so we needed to refactor our
thinking on what we could do to fully
automate and really help you so this
could have been a time where we just
stepped aside and left well this is your
problem to solve
figure out a way to do it instead we
created a very special version of the
migrator for them where it would take a
2.5 backup we also extended it so they
could give it the taint team namespacing
and it would only migrate the specific
team data through it was all available
via command-line tools and suddenly they
were using a single backup so where do
we go from here
hopefully at the moment I'm tweeting a
few things and one of them is a blog
post that um Paulin wrote which includes
this quote they are graded automate
automate so for him he thinks octopus is
not just about deployment or animation
but it's about automation and we do get
that comment a lot a lot of ops teams
use us to do Windows type things they
don't have to RDP into servers anymore
they can create a project that run
upgrades that do all sorts of things on
all of their targets and servers it
makes the ability for them to manage
their service by automation they do it
through octopus so what did they do like
I said they were going to automate
everything they have an octopus server
that creates octopus service they have a
management octopus server that has
scripts in it that they can easily
create all the instances they need it
connects to all the servers it sets up
everything they can create octopus areas
like octopuses where rabbits
testing this is another one things like
obscure pictures lie lights because when
you're testing you're not really testing
what it is kind of looks like an octopus
but it's not really you're kind of
testing it so we had a few problems when
we were testing their process it was
working in all their tests and then
suddenly we got on a call when we were
fairly close to one of the first
kickoffs of migration we're in two
points we're in 2016 now they had latest
test of their script and their
automation was importing all the data
and taking ours in something grander on
luckily it just turned out to be an
error in the PowerShell scripting they
had some legal issues with data the less
data you import the quicker the import
takes but they had sometimes due to
legal reasons who needed to keep a year
worth of deployment data so that had to
be accounted for in some way this
migration might take three times as long
as the other migrations and they were
scripting it and they found it couldn't
be run from the secondary machine they
had this management octopus that was
trying to call a command line tool on
the other servers but it just turned out
again to be a bit of a configuration
issue they weren't calling the right
flags and that didn't wasn't actually a
problem when we started getting more and
more into this the problems weren't
problems they were just missed
configurations misunderstandings but the
good thing was we were there to say no
you just need to do this and it will
work and it would so their entire
process was that they had a project in
this management octopus that would
prompt for the team names that they were
migrating they would create a new
instance on the VM using scripting as
part of the process using the latest 2.6
backup they would migrate the team data
their process would look for a recent
backup and if it didn't exist it would
go and grab one completely automated
it would also set up all of their hosts
details for these teams because they all
needed a different point of access there
they use a SAR for their load bar
set up all the certificates again
completely scripted and it was taking
anywhere from 30 minutes to 90 minutes
depending on team size so we're taking
the dive we're getting into it they told
us the date and time of the very first
one and they asked will somebody be
available and I'm like oh that's 5:00
a.m. I'm sure I could be around
everything would be great
so it went through six stages they had
five different servers but they also had
special case teams who refused to have a
downtime so they were leaving those two
last though everything was too important
they couldn't have a down time they
couldn't they couldn't go down for those
few minutes to get it up they started
with the smallest instance so we're
gonna do one instance at a time single
backup get all those teams up starting
with the smallest the least lesser Asst
they ran over scenarios they did a lot
of testing they even had backup plans
the thing about the migration is while
it's doing a lot of stuff the
two-point-six instance does still exist
and if anything went severely long wrong
the teams could just go back to using
2.6 it went really well actually so that
day waking up a bit early and checking
my email from bed seeing if there's
anything I need to do to help nothing no
no emails no problems there were a few
little things but these were all
slightly expected all of the teams would
have to change where they're sending
their nigut pakka jizz but they were
sent emails about that and told what to
update so that just was communication
issues and education issues there were a
few minor problems potentially with
things like step changes we deprecated a
few different step types there were
little things like that but nothing that
was urgent enough there required that
they had to go backwards and a lot of
people were a bit upset about the cheese
move so if you know anything about the
first 2.5 it was vastly different to 3.2
so buttons moving people are a little
upset and again education issues about
making people try and find
to where things were so it was actually
very very successful we didn't have to
get involved after that first migration
we got updates it took them I think the
first one started in March and the last
one was July so it took them a while to
get ready and set up and train and get
all the teams ready for the migration
but all of their teams now are on at
least version 3.2 this was another quote
from Ian's blog so what used to take 30
minutes and I'm not talking about the
manual process as I'm talking about in
2.5 it would take about 30 minutes to do
a deployment they were now doing in
under a minute
or within minutes and they didn't have
to interact as much with octopus but the
second sentence is the one that I love
the most the time gained and budgeting
recouped from all the deployment
automation has been estimated to be at
least seven figures that's what a
company of that size can get back in
time when they don't have to worry about
their deployments they don't have to
micromanage their teams when teams can
own their own deployments and I am happy
to report there is complete stability
teams can no longer take teams down in
fact I haven't even heard of a team
taking itself down recently which is
nice there's no more cases of multiple
downtime for teams specifically not all
the teams in the company or all the
teams interacting with octopus the H a
means that they can keep maintaining
their Windows servers take down a node
but keep the other node up and keep
deploying 24/7 as they need and more
importantly that they're not having any
load issues anymore the amount of load
that was happening on the service has
completely gone away but potentially
that's because of the architecture which
I'll talk about in a bit
the CIO team is very happy to report
that they're no longer fighting fires
and getting emails about how unstable
octopus is they're just worrying about
onboarding teaching teams how to package
how to send packages around what
deployment automation
they say they've gone really back to
basic 101 deployment automation but they
still do use their management octopus to
onboard new teams the process has
changed slightly that after the
migration but they do put in details and
it creates their octopus over there over
there network so what does it look like
so they have these VMs that are a dot
large that have lots and lots of
octopuses on them in fact they've got
two for every team and they call that a
known set well actually they have eight
node sets or sixteen large VMs is
anybody doing the mental calculations of
cost they have to Windows DFS servers
that serve all of the files in the
system and they have sequel always on so
they feel that they're in a fully high
availability model with backups and
disaster recovery and they're very very
very happy and this is all in the cloud
as well and it's working for their teams
obviously some teams are getting faster
latency to the servers and others being
they have sometimes in Argentina and
America etc so let's talk numbers this
was as of the beginning of the year they
have 320 instances of octopus well
actually they have two times that
because that's only counting per team
they have 413 project teams the reason
they have more teams and instances some
teams do share things they share
projects they share machines they have
three three thousand-plus deployment
targets I think this is a slightly
inaccurate number because they use Azure
as well and we don't count accounts in
our target numbers so they'll be playing
to more things than just 3,000 the
numbers came in and they're doing 13650
six deployments a month they're doing of
those 1500 and 34 are in production and
they
a thing they saw between January March a
6% increase in deployments for us the
biggest thing about this is a lot of
people go through a center a lot of
people a lot of developers use it they
then get exposed to octopus how octopus
was running for them in 2.5 wasn't good
for us and people seeing what we were
doing and it didn't it didn't show what
octopus really could do it wasn't
designed in a way they could have at
that time because we did have it could
have gone the instance method but
licensing costs and all of these on
things it just wasn't something that
anybody really considered going forward
it's given them complete confidence they
know that they can onboard anyone and
they're not going to have technical
problems they're not going to have load
problems I have seen graphs of their
memory and their CPU every time they on
board a little team it goes up a bit and
then it just completely levels out we
learnt so much from their information
about how we should be doing our
processes we use CPUs we do all sorts of
things now that we hadn't really
considered to be at scale so what is the
future for teams like this for
enterprise the doctor booth we're going
with something called spaces so every
octopus in its face we have a product
called OD cm that's coming out so again
if my tweets are working I've got a nice
little tweet going out now giving you
the link to our RFC we found that while
there aren't that many customers that
are Enterprise there are enough
customers at enterprise that need to do
what we're calling what we have been
calling the ascension model they needed
to get to a point where they had lots of
instances of octopus because it's the
only way they're going to be able to
scale and grow so we were working with
these companies saying you need to do
this they came back to us and said well
that's well and good for Accenture who
are really good at automating and really
happy to do it but we don't want to
really manage all of those things
ourselves right the scripting so we have
a
product coming called OD CM which will
let you easily spin up instances build
relationships between the instances
upgrade them individually they don't
even have to be managed on the same
network as long as they're accessible
it's going to give people the ability to
create these environments that are
easier to manage for these situations
thank you I have quite a bit of time if
anybody has any questions yes in the
cloud yeah dot large servers in the
cloud yeah no it it just gave them the
ability to easily expand and you know
the way the cloud works scale it up if
they needed to it's so much easier
because that it's that case of it they
don't have to worry about hardware
anymore that's somebody else's problem
no anybody else yes yes sorry
okay so the question if I had to correct
it was do we have any of the numbers
about productivity savings on time is
that correct yeah yeah
we don't have we're not necessarily
given those kind of numbers by our
customers if you know what I mean we've
definitely seen cases where even though
as a presentation the other day that
Honeywell gave about how that saved them
a lot of time we get told those stories
but nobody ever is willing to give us
their nice little numbers yeah that
there there are things here that even I
couldn't really talk about I had to use
all the information that their team had
used publicly if you know what I mean
and talk about octopus
wait we we hear things a lot or we
definitely hear about problems but
nobody tends to hand over their
financial statements as much as we'd
like to see how how much it helps them
and how much time is saved anybody else
yep
okay so the question was could they run
in containers to reduce the cost of
running all of these my understanding is
octopus doesn't work currently in
containers but mostly that was because
of docker itself and it's Windows
networking I'm waiting for Rob to nod at
me or not yes excellent yeah we are
we're at that point where we really want
to get octopus into containers and that
comes down to we're about to offer a
hosted octopus service where we do our
in hosting we'd like to actually see it
in a Linux containers so we are doing
the work unfortunately we were a bit cut
off at the knees by the technology
itself and because we're running on
Windows so it was a networking problem
we just couldn't finalize we're hoping
with them things like dotnet to being
released now that we can work on getting
octopus table and Linux environments
news Linux containers so it's something
we're actively working for absolutely
and it could potentially change the cost
for them yeah anything else I've gone
fairly under time but it's lunch so I
don't know if you're going to complain
all right thank you very much for coming</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>