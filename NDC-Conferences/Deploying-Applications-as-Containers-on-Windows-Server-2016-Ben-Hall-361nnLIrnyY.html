<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Deploying Applications as Containers on Windows Server 2016 - Ben Hall | Coder Coacher - Coaching Coders</title><meta content="Deploying Applications as Containers on Windows Server 2016 - Ben Hall - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Deploying Applications as Containers on Windows Server 2016 - Ben Hall</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/361nnLIrnyY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so over the last couple of years
Tucker has definitely made an impact in
people's lives it changed how we can
deploy applications on to Linux
conferences like ourselves have got some
awesome speakers talking about how we
can change deployments make everything
more scalable and easier and how
wonderful the world of Linux is yet for
those of us who are still in the Windows
focus world it's not been for too great
story like we don't have we didn't have
containers we didn't have such a
deployment strategy and everyone in the
Linux world with having so much more fun
well thankfully with the arrival of
Windows Server 2016 that now changed
Windows containers are now native
they're part of the operating system
itself and so we can have all of these
fun which limits containers are having
yet deploying our windows focused apps
and so this is what I'm going to be
talking about today and I want to
introduce what containers out the
concept but more particularly how they
apply to Windows and what benefits and
value that brings so my name is Ben hall
I am the founder of a company called cat
coda cats coda is an interactive
learning platform for software
developers we host interactive
environments that are accessible via the
browser and neither pre-configured with
docker kubernetes and very thin windows
containers and so you can experiment and
play around without having to download
or install anything and to give you some
tips and hints and so you know what you
need to learn and what's important we
included that web tutorials and so you
can follow those along and learn all of
the skills and technologies which I'm
going to talk about today then what
Emily actually gonna talk about well I'm
gonna start with an introduction into
building and deploying windows
containers I'm going to compare this to
how it looks in the Linux wheels for
those who are familiar and kind of
played around with dock on Linux look at
hyper-v containers with a slightly
differently how we can start deploying
can they containers at scale using
things like Kiba Nettie's and swarm and
it finally looked towards the future and
where I think the container landscape is
going so before we get into this
take step back and let's look at what
containers up and look at where
containers are important and if you
think of where we are previously and
before what we had containers we
generally dealing with virgin jinx and
as I'm sure many of you is very aware
virtual machines have many different
problems they're very big very heavy
resource intensive and we totally wanted
to deploy a very simple done application
or very simple node application if you
wanted to rely on a thumb box in
isolation it would have to have a
virtual machine wrapped around it but in
order for that machine to learn we'd
have to have a guest operating system
and so we'd have to pre allocate four
gigs of RAM certain amount of this space
settlement of kind of resources in order
just to have that know process in a
secure stable way and it kind of had
overheads but it also had slow boot
times which made a difficult scale or
dynamically because we'd have to wait
for our ec2 machine or sure machine to
be took it would throw to build and
maintain and keep up today and generally
it just wasn't that fun and so what
containers have started to do they've
started to allow us to think about how
we can separate our application and our
deployment from our infrastructure level
concerns and as we thought of how many
separations we started introduced
flexibility in flexibility into how we
build applications but more importantly
how we scale in Windows in production
and so if you think about where we are
with the container software process we
still have our based operating system so
we still have Linux CentOS or in our
case in Windows Windows Server 2016 this
will be running on a bare metal box
somewhere or likely Azure which has got
some great support for Windows as did
giggle if you got to be to the guys
upstairs Downstairs I don't know which
way where but go speak to their beef so
we have this operating system would you
expect and then when we build and come
to deploying our applications we can
build out the container and then that
gets rolled out and so when we look at
things like Arthi itd pipeline developer
to the git push instead of traditionally
that going to a teamcity a gem which
would become
with particular versions have done their
particular versions of Java and we have
to manage those if we want to talk later
apps instead we now do a docker build
and that duck-billed encapsulate all the
instructions about how our application
needs to be deployed how it needs to be
bill if dependencies that builds the
image and that's what we push out and so
we have diff middle set which is
produced in this docker image and our
previously therefore they focused on
Linux but as I said we now have our
beautiful Windows support and if images
what gets promoted and pushed through
the various different stages and they're
kind of going up and so if if introduces
the concept of ensuring that we've got
consistency and repeatability and we're
not getting side effects between
different versions of what may be
winning and staging compared to the
version of.net which is actually winning
in production and oh this is jiminy what
i'm sure many of used to in the
hypervisor world we've got the
hypervisor and the guest operating
systems running on top of it - which
have this overhead and this resource
attached to them and then kind of
mohamed describe it now now in a
container world we've got order
containers winning they're all sandbox
and isolated and I'm running on top of
this container engine and each one has
you can kind of think of docker and
containers as just a glorified process
manager it's still the same processes
which were used to launching it's still
the same applications the only
difference is now that they're winning
in a secure sandbox mode if taking
advantage of hooks in the kernel
separation that comes with Linux and now
convinced windows and just defined
enough for you in a very nice accessible
way everything which we could do with
docker had been around for the last ten
or so years it was just very difficult
very hard work with docker just cleaned
that up and made it accessible and so
people generally say that this container
win time sits in between your own system
and your applications in reality it fits
alongside your application your
processes are still talking to you in
your line operating system that they
would before the container engine if
this wrapping air making it easier of
processes to be managed and started
and for this is why I think containers
are very similar principles and very
similar properties to virtual machines
in reality they're just processes they
have processes and we can build these
images which are encapsulating what
opposes needs to be had to start and it
is what doc had made them accessible and
if for a long a great development
experience and to go alongside that but
they're also realistic doc and know that
I can't answer every single problem and
try and invent and solve every single
part of the production story so instead
they have a mindset of batteries
included but removable so if you have
certain very interesting networking
requirements or you have very
interesting expensive storage devices
docking no that is probably not the best
person on the order to be able to solve
those there's going to be companies like
HP there could be EMC and dal which will
stove and create their unique targeted
solutions in order to solve their unique
high-end problems and the duck is made
accessible they've made it
they plug and driven and so you can swap
how an interchange certain parts of the
software stack in order to meet your
requirements but fundamentally there are
three concepts we've got the containers
which are fundamentally winning
processes we've got docker images which
are fundamentally layer dip files is a
zip file of everything your process
needs from operating system up to your
packages including your application and
your binaries itself and then you've got
a docker registry which is images sit
and if bridges the gap between like your
CI server and your build servers to
production itself and so many say docker
burn it goes off to the registry grabs
whichever version you need that is what
gets downloaded and launched and
Felicity what we have with docker
and now with the advantage of Windows
the docker itself has been extended and
for taking advantage of the multi
architecture and multiples of golang
these aspects of the Duck Sauce code had
been prefixed so if this is part of the
windows build looks eels but we've got
some really interesting kind of
abstractions that docker has introduced
and also Microsoft the Microsoft have
completely done it in the open more or
less anyway and so you can see them I
could go Windows io abstraction and so
you can see that duck with trying to
work and collaborate with my aft in
order to build something which feels
very natural and coherent to what the
rest of the docker story is and I said
we get very natural and seamless
experience from a development and
production because it's actually part of
the engine itself it's not an add-on
it's not a fork if not from out of they
build instead it embedded and it's
integrated into the entire docker
process and a build process and the
testing phases and everything would say
go through in order to release the
applications and so docker has made
effort most of the made effort to make
it feel natural and consistent with and
the docker experience and alongside that
obviously the windows needed to be
easier in order to be able to support
these container concepts darker motived
have tried for many years in order to
have containers at part of the operating
system they've tried to secure operating
systems different research projects and
it's only now with 2016 that they
finally managed to introduce being able
to how processes which are thumb boxed
and lob down and secured in different
ways and her abstracted and thumb boxed
from other things winning on the system
and as part of this story they needed to
add different aspects to the Windows
operating system as a whole and
therefore key concepts which came with
the introduction of Windows Server 2016
we have Windows server core and Windows
Nano he either knew our plain systems
designed to learn inside of container
and see the bootstrapping your process
and given it all of the API that you're
possessed needs and they field winning
on a Windows operating system virtual
machine itself and then in order to
manage
we've got windows containers and windows
hyper-v containers they work and operate
very similarly the main difference is
that hyper-v containers have a more
advanced security model around them and
we'll get more into the details as we
progress towards the end but just
understand that food if of those being
reality they work exactly the same way
they were going to same processes the
same images hyper-v is just in a more
secure mode and the architecture of
docker and windowed containers feels so
he can system very coherent to what we
saw before we have our operating system
we have two windows kernel which had got
all of the hooks that containers need
and then a dock of engine will talk to
the Windows kernel in order to launch
processes such a sequel server asp.net
applications is etc and Adam sure some
of you are aware with Linux containers
the windows kernel or the Linux kernel
it said every single process if you
think that shared same kernel and we're
taking and trusting the security which
had been built in to make sure that of
the applications called communicate and
I can't break how and interfere with
other processes now in certain
requirements differs entities some
concerns that no no they were outbreaks
at the moment that no container breaches
but it still raises film insurgency and
from question marks and this is where
the Windows hyper-v container comes in
it's specially designed to deliver a
separate kernel from the other
containers which are running on the
machine and so you can guarantee that
there's isolation because it's been
backed it died of a hyper-v virtual
machine and so now can be confident that
our sequel service process while it's
still willing in a container it's
running on a different kernel inside of
the virtual machine just said we were in
think'll server natively the main
difference is that we have the docker
images the dock workflow around that and
this window the utility VM which had
been added is super lightweight it's
starts 8 milliseconds it barely any
overhead and he can't really notice any
performance impact and like winning a
guest operating or
additional virtual machine instead of
just there in order to be able to offer
this separate Windows kernel and so the
reason it is important is that generally
windows containers I've known of
containers are secured they're effective
they're highly scalable except to an
order benefits which I'm sure many of us
know and love these hyper-v containers
comes in we're dealing with
scenario if it's a shared hosting so if
you're willing a jaw or hurry coup or
things you like at Skoda you may have
cold which is completely interested then
our code may be maliciously targeting
other parts of your system now if you're
willing something like assured that
could be potentially dangerous because
they're constantly competitors which are
winning on the same scene the different
government agents other things which
probably don't want to be accidentally
sharing information and again
multi-tenancy where you may have to myth
which you're hosting we you don't want
them to be able to interact or interfere
with the code which is happening on your
system
and so this is where you have that added
value of Windows hyper-v containers in
your Linux world you may have come
across a concept core from Intel called
clear containers it's the same concept
and the fame approach clear containers
again wrap a Linux process inside of a
very small lightweight search machine in
order to be able to deliver that
separate kernel and Windows hyper-v
containers are delivering the same
concept so we have these two win times
and throw our application now needs in
order to have something which wins
inside of the container itself and so
the first weight through this in Windows
server core Windows server core is
nearly Windows 32 compatible API which
means it's got all of the lovely parts
of the windows kernel which are still in
there it's got all of the functionality
and applications which you would expect
from Windows itself it almost works in
exactly the same way and you can use
existing tooling at least in packages in
order to be able to win your
applications as we saw because it's
windows and it's pretty much everything
you would expect from a Windows
operating
system it's also rather large the base
images are roughly 10 gig vary in size
and so you do have that initial
dependency in that initial hit when you
start playing with containers and start
deploying them but remember docker
images are layered and so you only need
one copy of the operating system on the
machine if not you haven't download if
10 gigabyte operating system every
single time you roll out an image
instead you just need that one layer in
place and that will be purposed for all
of the different containers I would
deploy which we'll see more in a moment
on the flip side we have Windows Nano
windows Nano it's a new shiny operating
system which had been completely
stripped how is down to the bare
essentials of what Windows really needs
in order to be able to run and so we're
talking things like clustering storage
i/o networking to donate framework
itself etc and so it's try to get it
down to something a little bit more
reasonable and a little bit more size
that you would expect from something
comparable to the Linux world and as we
thought it's about the twentieth of the
size and so we know Civic or roughly 10
gig Windows Nano more a gig in size and
we don't know know you may know that
Microsoft made a big deal of this it's
gonna be like the future of how our
playing systems learn on hyper-v they've
recently had a change of heart and so
now Windows error will be solely focused
on supporting Windows containers and
supporting applications winning inside
of a container itself and if we're gonna
do this allows them to reduce it even
more and for the now targeting Windows
Nano to be more like 70 Meg or 80 Meg in
size still have all of the same window
support through or support things like
dotnet and exist in a they don't exist
in Windows binaries but that much
smaller much reduced footprint even more
than what it is today and so you can see
the Microsoft are still innovating still
trying to improve this story of window
containers and they're progressively
getting better and better and when you
think about with what you should pick
between Windows Live a corn windows no
no I make the analogy to
Linux and how we have that so we got a
boot to an Alpine and b2 is like the
operating system everyone owns and loves
its got packages which everyone familiar
with it's got a very well-established
API and pretty much you can take any
Linux application run it on a little
booty box or an imputed container and it
will work the side effect it is slightly
larger and slightly bigger because it
got more API support and this is him to
window server core we no no no is
similar to Alpine there is small they
focus so streamlined however you may
have to have some modifications to your
application in order for it to learn
effectively of them properly in order to
be able to build and this is where I see
the mindset of two differences so we
know they've acquired more for
traditional applications applications
which you don't want to modify you just
literally want to pick up and deploy at
the container where we're not nano if
all modern it for your their core
applications which you're actively
working on and it can spend a little bit
more time optimizing a making sure that
they were effectively and this is the
differences so how did actually look how
do we start playing with these core
technologies so the first thing we need
is docker so we need a windows build of
docker on Windows server core 2016 and
so you then the beautiful PowerShell we
can install the provider and install the
docker package and that will give us
everything which we need in order to be
starting winning windows containers
themselves in reality if we won't have
something like a sure that's why we're
winning they have already got templates
a machine which has been pre-configured
and set up and so that they can learn
containers out of box so they don't need
to go through this additional step and
from the viewpoint of consumer sides
everything looks and feels consistent we
still have a docker client
they've got the commands which you can
convert and that client can now talk to
Windows or Linux machines
one point to note before we get into
details as the Linux Windows Linux
subsystem which was introduced and
Windows 10 this is completely different
to Windows containers this is an awesome
approach so that you can run Linux
binaries on Windows without natively
this is a different concept to Windows
containers Windows containers allow us
to learn native applications a native
Windows binaries and selected thousand
to different problems it's not like was
shoehorning on and translating docker
Linux images to word on Windows we're
talking about full support so what is
this Windows docker image which we all
know which we can all build so we need
our base operating systems
I said we need that for the support for
that our applications have something to
learn inside of a container and so we've
got Windows and we've got Windows Nano I
need to sit at normal images on a
machine and you can launch them as you
would any other container
so in this case on my blue screen that's
my host I'm winning docker burn window
server core and when in a command line
and then within our container in the
black screen we have a command prompt
separated isolated sandbox do everything
else winning on our system and so my
hosts you can see some different scripts
winnows as your folders yet that's not
visible in my container I view it expect
now what actually happening in it covers
is a little bit more than what you would
expect if you looked at what winning
inside of a Linux machine Windows is
still Windows at the end of the day and
so they still needs to be processes
which exist in order to support the
applications and the processes which are
winning and so we'll still see if we
look at what's winning in front of
container things like FPS V the host and
we'll still see PowerShell winning which
is the process which launched it other
things like twisted installer
etc these are there because processes
expect an assumed that these commands
will be there and so there were window
that in itself has to have these things
running in the background in order to be
able to support it
so this gives us a lair in an
infrastructure and make sure that
anything willing inside of a container
feels natural and feels like it's it's
running on Windows because actually it's
a full Windows installation and so we're
trying to think about what a good
example would be how can we demonstrate
that this is how this will actually work
in reality and so try to find an example
which is representative of certain
applications which are dealt with in the
past and the one which I came up with
was a beautiful asp.net MVC 2.0
application which job always quite
handsome and a few other people built
and released in May 2010 so it's been
sitting there on coal Plex
for the last seven years if not been to
adopt me and we updated it anyway but
it's got everything which the
application needs it's been built so
let's see how we can take this exist an
application and win it inside of
container and then use the benefits of
docker and it brings so the first thing
we need is a virtual machine sewn if
case I'm using a jaw a jaw I've got
great support for windows container that
you would expect and it's a much quicker
way that if you want to start playing
and experimenting then you can use it or
until cat coda have released it windows
contain a functionality which would have
been this week if I didn't have
Australian Wi-Fi but never mind
we nose and big windows Australian Wi-Fi
do not mix I made for a happy
relationship so we now have our virtual
machine it's got everything which we
need so we need to bring it up to a
certain standard so this are you
chocolaty chocolaty it's awesome it was
a revelation I hadn't come to Windows
for quite some time and so I didn't
really have channel see you there
but by using it it is just like the best
way to set up and install everything
which windows needs and so if you
haven't have played around with it I'd
definitely recommend it but this allows
you to do things like
chucko install docker this installed
everything it's an alternative way than
the packages which I read and said
before and this will give us
duck client the server components and we
can now do things like docker PS and
ducky images that beginning you can see
the sizes windows civic or 9.4 geek
windows nano 800 meg and then hopefully
that will go down to more like 80 Meg in
future releases so one point which I
want to highlight which is the problem
with this screenshot is the youth of
latest tags dupatta latest times are
very problematic because latest is a
moving target you never quite know what
latest is pointing to and so when you
actually look at what's available for
the operating systems everything has a
built up and everything had a build
number from Windows and if it's very
similar to if you download the ISO or
download the ISO for memory and
everything had particular builds and
particular patch versions and this is
what are actually being pushed and
released onto the docker hub itself
though that can build on and so while
latest will give you the latest greatest
windows build
it didn't give you there a good insight
into what version of Windows that is it
doesn't tell you what patches have been
applied it didn't tell you whether it's
Windows 2016 ie that you exist on one
today or whether it's the new shiny nano
server which is going to be released if
a more opaque so instead I always
recommend that you pick
pick a particular third set that version
and so you have a known starting point
to start building your images and so
when you actually build and do it
quickly instead of just download the
latest and you pull up a particular
version and then that will download the
latest updates the latest security
patches and that Microsoft have rolled
out a part of the image now notice in
this version we have Windows Live core
which was five weeks old with with
knowing 9 gig when we updated the
particular version of Windows it's only
downloading the latest layer it's only
download in the security updates and
patches that have been applied based on
what your system did them have already
and so in this case we're not
downloading the full nine gig again
instead we only download in Hainan 900
Meg which encapsulates all of the
security updates have been released and
a new builds I'm since the last how much
we pulled and so now we can be confident
that we're building from a known image
we know the security updates are
included and feel when myself do another
that's Tuesday or rolled out some
updates we can pull down the latest
image update the Windows version number
and again be confident that we're
starting from that secure base and
that's secure foundation so just like
with Linux containers we still need a
doc file this docker file defines how
our application needs to be built and
needs to be defined in order to win and
so in this case we're defining of
Windows server core and again given a
particular version number so that we can
be confident about what patches have or
haven't been applied and because it's
now in Windows we can do things like
power shop and so we can use with no
features and PowerShell features like
install feature in this case installed
the web server web server being iOS and
so if you build out again using exactly
the same api's and conventions that we
do with Linux containers we can say
build give a nice friendly name in this
case I is and that will go ahead store
installer is on top of our windows and
we'll now have a container which has got
the windows setups
and is winning and thankfully Microsoft
had also sought that it is probably a
very common use case and many people
will probably want is at the dependency
and for their applications and so they
have built a pre-image that you can use
as your base image so you don't have to
go down and install iOS each time you
need it and again when you look at the
tags mugs are very explicit that nano
version that windows have core server
server versions depending on what your
application needs in order to be able to
win and it's got a build number included
there so you can know what
building on and what releases have been
included and so now we can use out our
foundation we can say from yes
in this case Windows server core because
it's a feed on net 2.0 it's probably
gonna need some more windows
functionality and then what windows
Quarters so he can't use nano but at
least I see we can't at this point in
time but now we've got our ass installed
we can start customizing he container
based on what our application needs and
so again it's a speed on there so we're
gonna need to install windows feature
we're going to install the on f45 if you
don't have framework and we need to
configure the AP dotnet and the donna
framework itself and this will go ahead
and add we building up our container
will install these requirements it's a
now age and if we are so now we're
automating the configuration of Windows
itself and so something which I'm sure
there many of our scripts for our
deployments we can remove the default is
website because it's no longer required
we can make a nice directory for where
us application needs to live and then we
can create a new iOS directory set
things like the application pool the
port numbers and the physical path about
where our application will be so far and
so now as we're configuring our image
did he now configure in iOS to make sure
that everything is in place as you would
expect so that other people know how to
launch application we can say expose the
application is running on port 80 odds
need to be made available and then
finally we copy over our source code and
so the release which the team did for
dinner was already pre-built and so we
don't have to go food the build process
we can just take the existing build
binaries and copy that into the
directory which I is expects and we can
start serving our images so just as you
would expect from Linux it feel very
same when you burn a duck a building
windows ridden through all of their
commands we can feel that it's
winning I asked configured everything
which we need and then we can do a
beautiful dock of win and because well
it will allow us to win the windows
container we can expose ports in a very
similar way and now we have our
beautiful new dinner application
winnings which has not been modified it
hadn't been changed as I'm interred from
the last seven years but we can affect
it we can effectively and easily darker
eyes are an employer using docker api's
and then scaled that out for our
application so this in their winning as
the windows container so again the
normal standard containers which we knew
or don't know any love if we wanted to
win this at the windows hyper-v
container we simply define the isolation
which we expect and so we can say that
the isolation isolation needs to be
hyper-v and so when that container
starts it will be wrapped in its very
small lightweight Thirds machine in a
slightly more secure mode than what we
had before and this is now the
difference between running Windows
container winning hyper-v container the
image itself didn't change the way we
launch containers doesn't change we can
just set this additional isolation mode
and would he go to image it's fixed
missing changes everything which we have
before they say man if we wanted to roll
out a new image we'd rebuild and we push
it out and we release our new image and
this kind of feels a little bit like
what it did with no dinner it was lift
and shift its I picked up an existing
application I didn't need to change it
but I could effectively and easily win
it inside of a container I'm Mike soft
and are very aware that this is probably
gonna be the journey that most companies
are taking they're gonna take existing
we know thirty machines which they
companies don't want any easier way to
manage probably would we move and reduce
some of the license fees and win them
now inside of container and so tomatoes
easier they've got a tool called image
to docker image the docker will take a
we'll inspect a existing Windows machine
they would expect how it been configured
what packages what window features are
installed and as we know it will build
your docx file which is of the
configuration of that virtual machine
and then you can build that as a base
image use as your starting point and
then deploy your application on top of
it and so when you can see here when we
install it it's wind things like get
Windows artifacts know it's got is it's
got MSM cute that's equal so configured
and all of those will be encapsulated
put into the docker file itself so this
gives us a really nice way that we can
still continue to embrace this lift and
shift mentality and a tooling around it
to support it and giving us this
foundation to build upon and move
applications into this new world but one
thing about having this I am immutable
and unchanging image it what about
Windows updates now if it's a full-blown
Windows operating system then we know
the updates will be happening in the
background and then we kind of break
that kind of mindset of containers if
it's continue updating then everything
breaks so this is one of the bits where
it window through the corners now though
are slightly different because certain
things have been disabled because they
don't need to be writable shouldn't be
willing inside of the container itself
so one of these is Windows updates an
example is Windows Defender an
anti-virus software malware detection
etc because that should be happening on
a host and not inside the container
itself so instead of Windows updates
this is why the build number of the
document which we're using is important
because that build number represents
what updates have been applied and so we
can't expect Windows to keep itself up
today because we know the updates aren't
winning we want immutability from our
duck image so instead we word when I
knew we these comes out we change our
build number
rolled out and I'm be comforting instead
of a thing changing in the covers
doctored might self to made it the more
easy
if you do something like doc you inspect
it shows you hashes of what's running so
if he didn't inspect inside production
and said which security updates have
been applied it will give you the layers
and then from the layers and from the
hashes and the chars you can get back to
the original Windows version number
which was actually used as that baseline
information and again from a security
auditing point of view and monitoring
and making sure that you are with them
today this gives you some visibility if
you accidentally lose that docker file
the doc file isn't available just like
we have with Windows containers with
Linux container if we can persist data
so we can use the same approaches and we
can mount him directories from volumes
so like sauce on our hosts maps into
destination inside of a container so if
we're winning things like sequel server
and it's writing and persisting data
that can still be mapped onto a host
using the same approaches that we have
with Linux and similarly we can start
limiting them strict eing processes and
security around that container so in
this case limiting how much of the CPU
shares it should have limiting the
memory which that container can use in
exactly the same way that we can in
Linux world and for those who are more
familiar or want to combine docker and
the build processes or deployment
processes with existing scripts there is
a PowerShell API and they can do things
like get container image which is
basically which is the same with doing
docker images and that will give you
back oddity information but other
PowerShell object another power Salvage
all if you can start piping it into
other scripts I know the processes and
the same things like launching new
containers instead of doing dock and
room we can say new container it's a
little bit more Debose but it did allow
us to integrate combined with other
scripts in our system so from this point
we have no dinner we successfully
built it based on iis and windows server
core it launched and everything seemed
happy but we also have their
dependencies and other things that need
to be winning inside in order for that
application to work as expected and one
of those is sequel server so hopefully
soft I've also made it possible to win
sequel server both are they Linux can
tailor after migrating the source code
but also now either windows container
and so if we want to take the sequel
server which we all know and love from
Windows that can successfully win either
windows container on our servers and
they also have Windows Server sequel
server for Windows Express sequel server
Express if we want to win it for
development purposes for example and it
works in exactly the same way we'd
expect from winning Linux containers few
advantages we get we need to set a
password
such as password we need to accept the
end-user License Agreement because at
the end of the day it's still Microsoft
and if they'll has things like tick this
box in order to continue installing a
process that's a little bit difficult
when you're winning at container so
instead they you have to set the
environment variable - yes - in decay
and finnaly ticking the box which no one
ever reads so when we launch it will
download all of the windows the sequel
server image and the wall of the layers
and we can do things like docker logs
and view the output from sequel server
in this case it started it kind of felt
the password complexity because I said
password and suprisingly and so you have
to give it something a little bit more
secure and long in order to be able to
get it to successfully start but once it
started and we still got that thing
through the ability and inside the logs
configure I think was over started when
it beated chained TSA credentials based
on what we set in what we passed in and
now we can use that from our nerd inner
application to access it in exactly the
same way as if it was installed and a
host somewhere
so we now have these two containers we
now need to be able to start them and
stop them and manage them effectively
and so this is where docker compose
comes in docker compose is now has a
Windows binary so it winds natively on
Windows you thin chocolate II it's very
simple and easy to install and have
exactly the same structure which would
expect so we can define our two
containers
we've got sequel server our database
running sequel server defined ports the
passwords environment variables and then
we've got our new dinner application at
the bottom and we do docker compose up
and then that will bring up everything
all the processes which are application
needs and we have application when I
first did this I thought the team I
thought the team had done a better job
then kind of like what the box is so
when you'll folks typing and playing we
name that I is an edge on Windows Server
rin a slightly different more secure
mode and say the basically block of him
and treated they fit winning if the
application itself detected that their
fee was winning on a mobile device so
once installed something more pretty
like Firefox it operated and it worked
in exactly the same way and we had the
entire application successfully deployed
which I was pleasantly pleased with and
we back the awesome days of 2010
applications and like we can start
winning their dinners again which would
be great so in order to make it
accessible you can firewalls rules for
80 in iOS acceptor and in Azure and now
will operate in the same way and we can
then because we're using a consistent
API we use in a consistent experience
Aarthi icd process for Windows looks
almost identical to what it would look
like in Linux world we have our get lab
or CIPD teamcity etc and would start
build the build is duck a build and
which calculates all of them window
functionality which we need Purdue to
the image we push it up to our registry
and then
something like that compose in order to
be able to download it and start it on
our server so if it's similar what is
the actual difference obviously we can
win Windows binaries is how the kernel
virtualization works so looking at in
the covers of what's happening on docker
and Linux we have things which we know
and love like the dock client this talks
of an API to the engine and the engine
is broken up into different parts we
sold 13 different problems like our
networking container D which is an
obstruction over Linux api's and deform
Linux and how is this unboxing words is
made or per things like the groups and
namespaces and the capabilities that's
going to make in a container be
contained and knitted what docker is
configuring with Windows it looks and
feels very similar
we still have think I can take P we
still add for configuration for
configuring the windows networking and
we still have things like control groups
and namespaces and layering capabilities
it's very similar it feels very
consistent and coherent the main
advantage main difference is that we
thought this compute service and its
compute service is an API into the
Windows kernel and so it means that
while docker is the only one launch
container today going forwards anyone
can buy a container runtime and
container API to launch container
directly against the Windows kernel and
so if you particularly don't want to go
via docker or you want to play around
and customize it yourself
then you have to capability than the API
in order to be able to do that and so
dakka dakka and Microsoft are
interdependent connected they're not
most of isn't dependent upon docker
in order to deliver this container
support instead anyone can write a
client on top of it what I think cool in
terms of in the covers when it comes to
Windows hyper-v again we've got this
problem Chad kernels and we've got this
problem of the security restrictions and
so the Intel career containers it was on
Linux and Windows we have another so we
started windows utility so when your
operating system boots up and this is
how I get it performance alongside
booting up Windows
it also boots up to a utility VM inside
of hyper-v boots up windows utility
inside of hyper-v it then takes a freeze
and a snapshot of that virtual machine
and basically puts it on a course and so
it's running it's got everything it
needs it's just not taking up any
resources our container it takes a
snapshot or a fork of that virtual
machine which is winning but in a frozen
state and then splits it and so the only
additional memory allocation start that
virtual machine is using is actually the
bit which is required for the container
all the other memory is in this frozen
shared State so very similar to doing
copying right if you're not familiar
with how that works where the only
things which you are persisting is
changed windows and the utility vm is
basically doing up before memory and so
this gives it that really fast launch
time thought to make that we weight
anything visible from the container
point of view they can't tell that
they're in this separate shared in this
separate virtual machine but if they do
manage to prekow and attack of do is
manage to get a day we can be confident
they can interact if they write anything
to that virtual machine it's instantly
forgotten and when I contain a stopped
it completely gets removed removed from
our system and so this allows us to be
secure allows it the images but what
about developers like we don't all want
to go back to the days of winning a
thorough operating system on our laptops
in order to be able to be confident that
what we're building is what we deploy in
production and so now we have support
for windows in Windows 10 we have
container support and so we can build
and deploy and test windows containers
on Windows 10 in exactly the same way
that we do
Server 2016 the way this happened and a
way this works it by using that third
machine this hyper-v hyper-v
functionality and so when you were in a
container on Windows 10 it's wrapping it
inside of this hyper-v isolation mode
and so that's what gives it the kernel
that's required to have windows
container functionality and for this how
we can test an experiment on different
operating systems and different version
of windows because I said kernel it been
repurposed inside tightly and so it when
you're on Windows 10 it looks and feels
very similar to what we would know and
love so this is Linux if you're winning
things like docker for Windows there's
now an option if you go switch to
Windows containers that will make the
client instead of talking to the Linux
VM talk to the Windows VM and so when
you do things like dock assertions
you'll see that it's now talking to a
window the architecture and if he lists
or the image if you have things like
Windows Nano which had been downloaded
and so this allowed this to experiment
and prototype and build and construct
both sides of the Linux and windows
world so when it comes into production
we're not necessarily we don't want to
go and remote desktop into every single
Windows machine and do a dock of word
because that can be error-prone and time
consuming instead we wanted more of her
container orchestrations of that problem
for us
so docker have their own solution called
docker swarm and this allows has got
support for Windows containers for more
importantly allows us to have hybrid
modes and hybrid support for both
Windows and Linux containers winning
within the same cluster and so in this
case we're deploying two theories one is
a Windows hated speith nervous we are
specifying a constraint we're saying
that this container should only ruin
operating systems which are of type
Windows it's a Windows container the
windows binary so we need window there
in a first place and so when we deploy
and tell swarm to deploy this container
they will thirds and identified Windows
machine
the most appropriate to deploy
application our container onto and then
on the flipside when we come and deploy
our duct service we can set another
constraint say and deploy on to Linux
and that will deploy on to Linux modes
in future it would be nice
sworn Cydia sure of eight images it
knows that one note for Windows I'm one
it built for Linux so hopefully in
future we can remove this definition of
the constraint but wouldn't it have been
employed there all winning over an
overlay network so they can communicate
and they can talk internally as if they
were on the same machine but you they
cost machine different architectures but
for a viewpoint of the application it's
all a seamless lovely experience and so
has this hybrid mode built in today if
you were there am i talking yesterday
with kubernetes cuba netted in a more
advanced scheduler it got more
capabilities than what swarmed it at the
moment at least and it's driven by some
of the thoughts and some of the opinions
which came out to Google before it
donated it to the cloud native
foundation thanks to work I mugs off at
reader and at hat which I thought was a
great collaboration and show the new
change in it the Microsoft landscape
they've collaborated and added support
inside kubernetes so that can also
deploy windows containers and so again
very similar to how you have a hybrid
swarm cluster you can all have a hybrid
kubernetes cluster which can manage both
your windows containers and your linux
applications through this single control
plane for scenarios such as deploying
single server applications using single
server on Windows but then having your
base modern shiny doneck core
application deployed G's in Linux and
using that scale out about having
everything in this one single deployment
approach it DCOs
which have got lots great into I think
under the covers is powering the ashore
container service and this is where it
can you smile
so at the Third's we swarm you have to
define the constraint with D cos you
don't D cos has holes fingerprinting and
so it understands the type of workloads
which you're asking it to learn and it
will find the most available host for
that machine to winner so if it of
topics we've got Linux
we've got Windows and we've got
something important like a jar file
which convert on both Windows or Linux
things to be amazing JVM you give it
into the DT OS scheduler which is
marathon and amezo
in the covers and then it will map
attack which host and that workload
should be written automatically so for
example Linux you don't even on links
nodes windows only on Windows but
something portable like Java it will
pick the most available box based on
available resources and other workloads
happening the windows azure the azure
container service also has support for
windows containers you can specify that
you want um hi mr. zuv both Linux and
Windows machines and have that
capabilities built-in and so now we have
this really great approach where we get
this hybrid approach we can deploy
things consistently whether it's on
Windows or Linux we can take a distant
applications move them into this
container world and now deploy them in
exactly the same way that we're
deploying applications using things I
swore or kubernetes but where does the
future hold and what does the future
look like
for containers so we have windows we
have Linux but we also have IOT we have
armed devices we have raspberry PI's we
have other things and cool complaints
like rezian are building experiences so
they can deploy docker containers in
exactly the same way but targeting arm
and iot devices and so now we have that
consistent experience but we can target
everything including our small micro
devices and they have really good demos
where when they do a darker deployment
to one image you can see it rolling out
across other IOT devices in a cluster
and kind of like a swarm mode
one of which is literally flying drums
they deploy an image to a flying drone
either is going around and that will
automatically update the other versions
of the flying drone software running as
they're all flying within a cluster
which is the definition of their own
town time deployment so we have this we
have IOT devices we also have sequel
server winning of the container so we
don't have to go through the same
process and thiking 15 checkboxes in
order to have sequel server winning
instead we can deploy other container
books question in tow how long did it
take until we have things like Visual
Studio winning other container why do we
go through the steps of downloading 4 or
5 gig images to then spend another hour
have an installed and optimize for a
solution where if it's running inside of
a container that could be done in
advance instead of having Stan are the
updates which could potentially which a
game takes time and interferes with the
fifth on we could download the latest
layer just as we do with windows
containers and windows serve the core
today and so change the commitment more
reduced we can amend a bill time a much
better experience but also there's an
boxed and so one version of Visual
Studio wouldn't interact and interfere
or modify the registry of other visual
studios so we can run things in parallel
side-by-side because this is a whole
nature of what we're not containers and
what containers
I'd be timeful and this gets at a point
where we have everything being deployed
as a container we have our Windows
applications we have our Linux
applications we have our development
experience and our development scripts
and we have even have our door sensors
and other IOT devices all going through
this docker container docker images and
dock over in style experiences and
thanks to the cloud and services I swore
and kubernetes they can be deployed
anywhere we can have hybrid clusters
which are distributed across multiple
clouds would all manage our workloads
and certainly the regional filiz bait
center or an even an entire cloud
provider our systems will still learn
still maintain a still and delivered a
performance would check we expect so
this is all of fast-moving
cabe containers especially windows
containers are coming and adding cool
new functionality and if you want have
reasons why we built cutta cutta cutta
code of a free interactive platform
we've got different scenarios which
explain and go into more details about
wire talk today and the platform where
you can play and experiment and try
different things out so with that as a
summary we talked about the four new
concept which were introduced into
Windows Server 2016 we've got the new
operating systems which is designed to
were not posted inside a container and
delivered to support API that that
process needs if we come more
traditional applications we target
things like Windows server core if it's
a more modern application then we can
use something which is a little bit more
streamlined little bit more cut-down and
Windows Nano we've got Windows
containers that allow us to process it
in a sandbox secure nature but if we're
gonna run in and then flame or sensitive
environment we've got Windows hyper-v
container to give us that additional
security give us that additional set Pro
kernel to keep our security auditors
happy we've now got support on Windows
10 so exactly what we've talked about
the building of Windows images can
happen locally we can test to make sure
applications work and then we can use
that image and push it and win it on to
Windows Server 2016 and when it comes to
winning a production we can do things
like swarm or hybrid kubernetes clusters
and we'll start having that for that we
just issue the workloads and that all
might find the most available most
appropriate box regardless of underlying
operating system to deploy our workload
on to in terms of next steps obsolete a
decoder if you want to play around with
Windows containers do not know sure it's
a great starting point as I said the
operating systems are fairly sizable
downloads and so winning it in the cloud
favor your local SSD and it's also
significantly quicker and we've got
Windows 10 support so if you do want to
play with it locally when you install
docker for Windows you can switch it and
say switch to Windows containers and you
can have an experiment with order
functionality what you need if
have any questions please let me know
please have me an email or drop me a
tweet and with that thank you very much
enjoy the rest of your conference</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>