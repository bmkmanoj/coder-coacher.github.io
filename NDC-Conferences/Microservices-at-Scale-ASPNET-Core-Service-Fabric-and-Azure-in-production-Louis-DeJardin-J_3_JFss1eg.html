<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Microservices at Scale - ASP.NET Core, Service Fabric, and Azure in production - ​Louis DeJardin | Coder Coacher - Coaching Coders</title><meta content="Microservices at Scale - ASP.NET Core, Service Fabric, and Azure in production - ​Louis DeJardin - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">⤵</li></ol></div></div><h2 class="post__title"><b>Microservices at Scale - ASP.NET Core, Service Fabric, and Azure in production - ​Louis DeJardin</b></h2><h5 class="post__date">2017-09-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/J_3_JFss1eg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">hello everybody I hope you're having a
great time Australia has been very
interesting I've enjoyed the visit so
far I hope you are as well today during
this hour we're gonna be taking a look
at micro services at scale and although
this is based on the way Bing manages
its services in production with its
development teams and how it does its
operations
I wanted to organize this talk in a way
that was something that you could take
back with you so that it wasn't
literally the same as Bing but was based
on things that are commercially
available the azure in the visual studio
product line and scaled down to a small
toy system that you could scale back up
so that you could you could go back to
your homes or offices with something
that that you can apply it in the
interest of doing that I set it up in a
way that might potentially be a bad idea
you can if you want to log in to the NDC
Bing Visual Studio com
I created a guest user name and DC guest
at nd C bing.com and the password is
hello Sydney v capital H capital S
number five that user should be
read-only so you can take a look at the
code you can take a look at the release
histories and things like that but you
shouldn't be able to push code or change
things in deployment the one thing that
you can do and I would ask you not to
it's change the password I couldn't
figure out how to reset and stop
password resets so if you do that
basically you're just ruining it for
everybody else so if you do login there
there is a project named Sydney and you
can click on the wiki to find a page
that has links in it that said while
you're logging in there and feel free to
if you want to a bit about myself I am
currently like I said on the Bing team
prior to that I was on the asp net core
team and helped rewrite asp net with
David Fowler and Damion Edwards and
Barry dorrance I believe Barry and
Damien are actually at this conference
so say hi from Lulu if you happen to
bump into them and before that I did
work in the real world is
as to working in Microsoft and that was
largely in the online financial news and
data industry it was in market watch and
big chart so and I did the sparkvue
engine open source and Dow Jones and
that's why as asp net core became a 1.0
product i kind of looked at my career
path and found that I actually missed
that production environment the the live
site and you know how some doctors say
they they enjoy working in the emergency
room that kind that kind of experience
which is why I transitioned from being
brought from asp net core over to bing
and oh also my wife always asks me when
i go to work if i talk about her or if i
mention her presentations and of course
the answer is no because she has she's
not based on software but if you do
happen to see her she's the one on the
right feel free to say hi her name has
been Brenda so now now I can say I have
mentioned her in a presentation and
hopefully she doesn't mind that picture
otherwise I'll be in trouble but like I
say I my my own history has come from
the online production live site realm
for for quite a while like a decade and
then within Microsoft I've returned to
it so there was a gap where I I wasn't
really involved in that from 2009 to
2017 and when I joined the Bing team
there were a couple of things that were
actually kind of amazing when when I
when I saw how their systems were
working and how their teams operated and
one was that in 2009 there was a
distinct division between operations and
development development is about making
change and deploying change or changing
coding rolling it out operations is
about stability if something breaks it's
because it changed so there's always
that tension and back in the day they
tried to separate those two even to the
point of having two departments where
development would describe two
operations what you need to do and
operations would do it ironically that
made things even less stable because as
long as you could write down the steps
they would do anything you told them to
do in 2017 the refreshing thing is it
seems like those roles have been merged
back together into devops powered by
automation and that's where that image
comes from the
idea that a two meter tall person can be
powering you know a 70 meter tall
utility mech and control thousands of
machines one person can affect so much
capacity in a way that scales because
one person can control any number of
machines and that's that's the thing
that's kind of striking when I went to
Bing was that it's so large you think
it's intimidating but it's really a
website it's just that the slider is
cranked all the way to the right in 2009
the buzzwords were continuous
integration and test-driven development
that you wrote tests and as you checked
in code it was constantly merged into
the codebase and constantly tested and
in 2017 has taken the next logical step
to continuous deployment continuous
deployment being once the build is done
you are going to production your master
branch's production and that requires a
lot of automation and a lot of unit
testing and a lot of discipline it's
that kind of setup that we're going to
be taking a look at putting in place
with a commercial product line the
reward for that is agility back in the
day there was six to four four to six
week release cycles or sometimes four to
six months depending on how large the
project was and banging genuinely
deploys more than once a day it takes
four to six hours to release the entire
application and that's kind of amazing
to me that it has that much automation
yet that much size combined with that
much agility this is where it also
really pushes towards the micro service
direction which is kind of service
oriented architecture done correctly SOA
kind of missed the ops part of it how do
you know where your service is running
how they're talking to each other how do
you make sure it's all live and and
you're aware of everything that's
happening and so the system we're going
to be taking a look at and basically a
model of how you set up this kind of
thing is is basically these four parts
you have production in the center and
none of this is rocket science this is
not an amazing dazzling presentation
this is
very practical practical working kind of
common-sense things you have production
in the center that's where your service
fabric clusters are in your eyes REM
scale sets on the left your DevOps actor
has two arms he needs to get code into
production and he needs to get telemetry
out of it
the actor on the right is your client
that is going to be getting information
out of production through routing
anything whether it's a mobile
application desktop application web
request browser it all comes out of
production through routing those three
code telemetry and routing if you
implement those in a stable way you can
do as many development changes to prod
as quickly as you want to in a way that
does not impact your availability and
stability you can get as many nines as
you want to you just have to set them up
properly and have a certain amount of
discipline before I set this up like I
said I did want to do it in a way that
you could take back and apply yourself
so I started with a clean slate and I
also wanted to sort of place a
constraint on myself to stay within a
budget I wanted to know how much this
kind of thing would cost in practice if
you did want to scale it out so I did it
first by creating an azure subscription
on on my own you know credit card and a
visual studio team services account the
average subscription envy STS were first
set up using a live login you know is a
live.com Microsoft account you know I
think you can use Gmail or any other
kind of accounts you want to but it
should be must be
two-factor off and you should not know
the password to your own login how many
people show of hands have to factor off
and use a password manager okay if your
hand is not up right now the reason it
should not be up is because it should be
on your phone going to Gmail and turning
on two-factor off and also searching for
a password manager like dashlane or
don't actually cost $10 a year those are
invaluable if you are compromised in any
way those will stop anything bad from
happening especially when you have
something that's an account that's for
personal or business use the third thing
that was on the shopping list after we
have an azure subscription and visual
studio team services set up is DNS
domain I set up NDC bing.com and that's
the first thing that actually cost money
so for seven dollars
I had a domain and then I set up an
azure aad domain called NDC Bing talk
you do that in the azure portal what you
get within a ad domain are 5'4 users and
you can create as many security groups
as you want to and then you can use
those users and groups to put into roles
for your address subscription and for V
STS so that login you saw at the
beginning is a member of a group called
vs readers and I took that security
group and put it into the azure
subscription so you can go to the portal
to log in and see the resources and you
can go into the STS and logon
once that was set up it was just a
matter of doing everything else these
are the three different arms we were
looking at before one for code one for
routing one for telemetry and the kind
of service fabric clusters that are
running in the center in production
we're going to be taking a look at these
in about this order and it is it is
about what you would expect some of the
routing is actually really interesting
if you haven't seen an azure traffic
manager before we'll take a look at that
it's very powerful if you want to get
extremely high availability and then
failover in there the only two that do
not scale disproportionately our dev and
ticketing systems so only the code
development and only incident handling
are things that are limited by the
number of humans involved everything
else once you've set it up it can scale
disproportionately so very small teams
can do very large work the first branch
we're going to jump into is the code
branch how many people here are familiar
with Visual Studio comm the STS team
services it's pretty good pretty good
pretty good portion that was never
actually my favorite historically I have
always been a fan of well you know it
gets back in a day also team city cruise
control net Jenkins github of course for
open source development
it wasn't until coming to Bing that I
was first an actual active productive
user individual studio.com account and I
have to say they have really they have
really nailed that product I think in
the last couple of years especially for
the build and deployment pipelines they
have as well as their get source control
the thing that's a little lacking I
think you would say is their ability to
support open source projects just
because they don't give you the idea of
an anonymous login and you know free any
number of people can fork off of your
code so that's still where github
really
but if you are doing commercial work a
private work a visual studio is
fantastic and like I say this has been
set up without paying for it yet
so all of this stuff really had not hit
the point where I had to go beyond the
free account in order to create
repositories and create any of these
these kind of artifacts these four steps
are in Bing what we call the inner and
outer loop kind of like a nested for
loop the dev is the inner loop so like
an inner for loop it's more rapidly
iterating you check out code you make a
feature branch you make changes you run
unit tests you push and you keep doing
that and you're working with other
people on the same branch and that is
pretty much exactly like you would
expect it to be I mean here's a small
example of a web application that we're
gonna be taking a look at and we'll walk
a change through these four stages the
first is making a change let's see the
about page will say this is the NDC Bing
demo web app you can run all of our unit
tests we can run the website itself this
is a asp net core running from the
command line so there's no is involved
it's set up as an exe so it starts as an
exe at lo Davis peanut chord listens on
a port and it serves a service one of
the things you might be wondering is why
is it an ace peanut core exe if it's
actually a service fabric application
service fabric can host guest exe s so
that's that's actually kind of one of
the ways I like to run it myself the
project is set up so it will publish a
service fabric application folder layout
but for development I really like the F
I've plain old Exe you know like the the
whole UNIX mantra if it ain't broke
don't fix console applications are
fantastic
we have logging information coming out
this is Cyril log that's connected and
we can see that I've got some list of
thoughts added to the home page from my
Jack Handley the old Saturday Night Live
bit and then the about page will see
that I have updated the the texture so
it seems to work and we ship it by
jumping over to get and within get we
work on the right directory and say
updating the about text committin bush
yep new branch is fine tracking
references fine
so now for the first time let's actually
look at our visual studio account
within Visual Studio in the code we can
see that there are multiple repositories
set up one for each microservice
essentially so they each have their own
history and in the website we do have a
new branch that was updated and we can
create a pull request for this is now
the first time we're entering into the
second box there is a branch policy on
this repo that says you cannot push the
master has everybody familiar with that
should I or should I show that quickly
but we'll see if we have time we'll take
a look at that in a second
you cannot push to master there's a
policy on it that policy says that only
changes can come in a master if they
come through a pull request so let's
create a pull request the policy also
says it must have at least one other
person review and approve and they can't
be yourself for the purpose of the demo
I said I can't improve my own changes
also it has to pass a build so there's
already built in progress creating the
pull request kicked off a build so the
first step in the pull request is
creates a build that's going to compile
run the unit test deploy to a testing
cluster run functional tests in addition
to unit tests and only if all of these
have passed will it enable you to merge
as the build has been going in the
background we can see how many steps
it's gotten through already and like I
said I use console applications instead
of service fabric applications and when
you do that you do have a couple of
extra steps here this just copies the
application manifest and service
manifest in the right spot and then this
is running msbuild with the target being
published and so it says in the code
subdirectory of that new folder put the
Exe and all the things that you need to
run so those two steps are basically
creating the service fabric application
directory layout there is a built-in
task that you can use that says update
service fabric app versions so the build
number is going to be put in the end of
that service fabric application so it's
0.9 normally this is build 209 so my app
will be zero point nine point two oh
nine and now it's deploying it to the
testing environment you can see the
version number there once it deploys to
the test environment it should run
functional tests I ran out of time I
don't have a functional test project in
place but you have to imagine that
functional tests ran after this
deployment finishes back at my
definition I can go to the pull request
and we don't really need to wait for
this to finish because as this is going
on I can just say set autocomplete and
to prove my own change there so now it's
going to wait for the bill to finish and
I've already approved it this should be
a co-worker not me but when this is
finished it will autocomplete how bills
exceeded great and it merged the change
so we now have the change we made in
master and like I said if you agree to
master the next step is going into
production
so your master because everything is a
PR you have one change at a time they're
all squash merged and the rest of it is
also automated the pull request is now
finished now it's time for continuous
integration o
CI continuous integration CD continuous
deployment the next step is continuous
integration there is a build definition
that triggers whenever master changes
let's jump over to the builds again this
is the build definition that was
attached to the pull request policy this
is the one that is attached to the
master branch commit appearing as you
can see it's already in progress when
the pro request
auto completed because the unit test
succeeded for the PR this build was
created and it does mostly the same
things and it's also getting ready to
basically finish up its work by
deploying the service fabrica
application to a testing cluster should
run tests and then it creates a drop we
might even be able to see that happening
so as your automation is amazing it can
do so many things see there it's
upgrading the background already so you
can you can watch it happen in many
different ways the automation is amazing
you can create a hundred machines in 15
minutes where it used to take an entire
team a weekend of you know install a
thon and then they would all fly out to
the data center and rack'em now it only
takes 15 minutes which is an awkward
amount of time if it was 45 seconds we'd
be hard to be talking about something
else right now because it's 15 minutes
it's short enough to put in a demo but
long enough that you have to
occasionally have these little parts
where you're filling
the first two things we took a look at
the pull request build and the
continuous integration build those were
both build definitions Visual Studio for
continuous deployment has a thing called
a release definition how many people are
familiar with that maybe you have to ask
got the other way around how many people
have never heard of release definitions
in Visual Studio mmm all right I think
there's a lot of dark matter here and I
don't think that added up to the total
number of humans the release definition
can be thought of as kind of like a
collection of environments and we'll
take a look at the website release
definition it's a collection of
environments and here I have staging us
east and us West defined and each
environment is a collection of tasks so
really what it is is it's kind of like a
bunch of different builds each
environment works like its own build
definition it's the same tasks even so
if you have a task that deploys a
service fabric app and you used it in
the build you can also use it in a
release
the build definition here you can see
it's already starting to go out to
staging the build definition here is set
up to trigger staging for example I'm
getting a little lost here I don't
remember how to find where the
deployment configurations are here we go
staging for example will kick off as
soon as the release is created the
release has created as soon as the build
is complete so as soon as the build
completes it goes out to testing
succeeds creates a drop folder as soon
as that drop folder is created the
staging environment begins to play
so that's what this number three is it
deploys the staging tests staging and
then deploys to all the production zones
and then tests the production zones
that's pretty much it like I said a lot
of this isn't very fancy but it is
stable if you have functional tests at
each of those they should stop they
should stop the deployment right there
if you have circuit breakers that's the
way that you can have continuous
deployment changes going out multiple
times a day anything bad happens it
stops right there and that's something
you can tell your new employees to and
they do it Bing and it's true if you are
there for your first day and you make a
change and you break the website that's
not your fault
you get congratulated for that because
you found a gap in the testing it should
not be possible for you to break the
test and break the break the website by
deploying code inside service fabric
when it deploys to a cluster I'm not
sure if you're aware but it does it in
20 percent increments so it'll deploy 20
percent of the machines wait for them to
see if they're stable or not and deploy
another 20 percent and go forward from
there so even within those zones those
zones are each 20 percent increments in
terms of 20 percent can go out it'll
break and it'll revert so even within a
cluster it can do a partial deployment
see that it's unhealthy and then
rollback and that all happens within
this single task this deploy service
fabric application tasks
well staging is deployed and now it's
deploying the to production
simultaneously we can jump into WW
staging and DC being calm if we're
curious and you don't trust automation
or you want to get into it incrementally
you can also go to an environment and
say it needs manual confirmation to
proceed like you can put an exit gate on
staging that says a human has to go here
check it and then go back to visual
studio and give a thumbs up to continue
to production but that's what we're
doing right now is we are going to the
dub-dub-dub staging in DC going in the
about and we can see that we now have
this is the NDC Bing demo web app so our
changes made it all the way through
you can even check here to see if we
have to plug it or not no hasn't ray
traced us yet so that took I don't know
how long maybe deploying to service
fabric itself is actually the long pole
on this operation
but in that amount of time you can do a
stable incremental deployment out to
production the next thing that you need
to do is get that material out to the
clients in the way that we basically
just did I went to WW staging and EC
comm NDC bing.com and it routed me to
the staging implementation of that
service the total topology and we've
also moved to the second arm of the
three arms now we're talking about
routing which is completely distinct
from code were there any questions on
code probably not yeah
yes oh so every cluster it runs in an
adder region so it knows what region
it's in and also when the applications
deploy that deployment has given a
surface fabric variable for the
environment itself and that is put into
place in the doodoo duty to do
environment variable HP net core
environment so here we have a parameters
for the different sort of zones so when
we're deploying to staging we use this
file and it says the environment of
staging that will go into an environment
variable at launch time so when the
program starts up that you actually
launches it has this environment
variable that changes the HP net cor-ai
hosting environment dot environment
property to staging that's where there's
a lot of little goodies buried in there
which is why I kind of really do want to
at the end of this talk turns maybe into
a github repo so that we can continue
this and maybe I can turn into its own
little toolkit but but this is how you
know you kind of get if it ain't broke
don't fix it it's an exe with
environment variables and when this
instance is launched its told you are
running in staging to route to these the
way I have this organized is it's a very
complex picture and then I deleted
things until it was simple and then put
them in reverse order so the simplest
thing to do is to have a DNS point and
name pointing at an exe and this doesn't
scale of course because that service
will eventually need to be running on a
mainframe to handle your capacity so to
work around that you put a load balancer
in place so several computers can each
be running the program and the load
balancer decides which one is going to
get the request whenever one arrives now
that you have multiple axes you need
something like service fabric to manage
them that's basically service fabrics
job you have three computers or 30 and
you want five copies of the CXC it
figures out where they're going to run
and launch with them you now have a
different DNS name
- the fabric cluster itself on port 19
no 80 we did see that briefly here so
this is the DNS name talking to service
fabric exe itself and seeing the
information it has about the state of
the universe as far as its concerned
that's fine for one service the second
you have another service you have a
choice to make you can either have
multiple domain names each pointing to a
different IP address and load balance
those IP addresses to your different
programs a different way you can
approach it is to have an additional
service that you're right and call it a
gateway which will receive any request
for starter comm so all requests for
port start phu kham go through for her 3
or 82 the gateway and then the gateway
based on the DNS name decides which
service that they go to does that make
sense
so the gateway talks to service fabric
and says which computers is be running
on and then it goes through that list
and order and then sends the request and
returns the response so the Gateway is
the request router the load balancer is
your TCP layer routing the last thing
you need to be really redundant and
resilient is geo routing and you can't
really do that with a load balancer
effectively but you can do it with Azure
traffic manager which is a fascinating
piece of technology it operates at the
DNS level so when you go into after
traffic manager you give it rules for a
few com that say this DNS name and it's
not a TCP level thing it's a DNS level
thing when somebody does a DNS lookup on
that name it decides which of these two
clusters or both is currently serving
that properly and then it responds with
the DNS information to connect to one of
those two it can even use information
about geo proximity so that your
customers go to a region that's closest
to them at the time for performance
reasons we can take a look at that
in the azure setup and I should add that
all of this relies on automation there
is a repository that has the azure
resource manager templates that create
all of these artifacts in the
subscription and I created a release
definition that runs those templates for
me so I don't run these manually I kick
off a release and I tell it deploy the
environment which contains the arm
templates to configure DNS you know what
I mean so I actually deploy my resources
I don't run them from a PowerShell
locally yes mhm yep right now when we
were taking a look at WWE Jing and DC
Bing this DNS name was actually taking a
look at these two region specific DNS
names so there's two clusters and like I
said I was trying to be cheap I'm
actually using the u.s. West cluster as
staging and as testing as well as
production so I'm sort of overloading
that one but it also makes for a good
example of how the azure traffic manager
sees that staging is degraded in the
east because the app has never been
deployed there so by going to that DNS
name it's already doing its job sending
us to the West US and then the West US
is taking this first part of the DNS
name
ww staging that first part is what's
used in service fabric to find out what
service it should route to and I don't
know if you noticed but when you take a
look at these clusters the fabric
application name matches that DNS name
see what I mean fabric ww testing is the
fabric application so the Gateway really
doesn't have any brains to it it just
takes the first part of the DNS name
uses that as the service name asks where
it's running and forwards the requests
to it
you can take a look at that code it's a
little interesting
so it's implement it as an asp net core
middleware no this is a custom gateway
there is a gateway that ships with
service fabric it has a policy of
putting the service name into the path
which unfortunately does kind of expose
a service name in to parts of the path I
like to keep the path unchanged which is
why I like to put the service name in
the DNS oh you mean the to be able to
change that name yeah that's a setting
that you can provide in that's one of
those same files we were just looking at
here mm-hmm
yep in the application parameters in the
application parameters for the different
environments you get to say what the app
name is mm-hmm so this is kind of its
trick but you can put DNS information in
there if you want to get the information
out of there and then here's how the
Gateway is working it's basically saying
you know splitting the hostname up it
sees if the first part is numeric if
it's numeric it's because the load
balancer is doing that keep alive a
status health check which is the last
thing we should mention about routing is
how these systems know if your app is
alive or not and that's a Status page so
the load balancer and the ATM the DNS
based one so the alb a driller balancer
for TCP balancing and the ATM as your
traffic manager for DNS balancing both
have probes that probe is basically
sending an HTTP request to till the
status and looking for a 200 result code
so here we have it looks up what the
service location is and then it forwards
it
this really isn't I mean it's
interesting but it's not interesting
enough to spend time looking at it does
its job the request goes through it the
third and final part is telemetry so so
far we have a stable way of getting
changes into the production we have a
stable way of getting requests out to
the user oh it's worth mentioning
because of that tilde status any one of
these can go dark and it will route
around it so you have to have many many
simultaneous failures before you will
actually get a failed a failure
situation you can even have a way of
informing an application to stop doing
200s for the tilde status and that's a
quick way of taking an app offline you
can just decide I want service B not
come out of cluster one by flipping a
bit somewhere and having service B stop
responding to hundreds to till the
status requests in flight will still
succeed the only thing it'll do is it'll
announce to the traffic manager stop
sending new people to me
so it'll eventually drain with without
any without any failures which is which
is fantastic if you're trying to get
four or five nines you you do need to
worry about how can you direct traffic
away without suddenly killing the things
that are already in flight so we've
talked about getting code into
production and we talked about routing
requests the last part is telemetry
which is extremely important you have to
know before your customers or before
your boss knows that something is going
wrong and you have to have enough
information to evaluate what's happening
and do something about it
inside HP net core is a new logging
subsystem it's an abstraction really
it pairs very well with sewer log which
has the idea of properties on events so
when you see something in your code like
log or log information fetching a
thought ID with a number this looks like
a console.writeline when you see all the
text scroll by but when you put it into
a database like elasticsearch or elk
this thought ID is actually a property
it becomes a multi-dimensional database
that you can query any of these
properties and kestrel the server in asp
net core and all of those subsystems
they're also using this logger to say
what events are happening within them so
if you put your application events in
the same log stream and direct it
someplace where you can you can navigate
it then the amount of information you
have at your fingertips is tremendous
we've already seen this page run a few
times every time we visit one of these
pages in any of the environments it's
creating a number of log messages and we
can jump over to an instance of
elasticsearch I was going to set up
elasticsearch on the subscription to get
an idea of how much it costs there are
some templates created by elastic that
make it very practical to deploy but for
expediency I just hooked up a demo logs
IO accountant so you can go here and get
a 15-day free trial so you can
experiment with how elastic search looks
and feels inside the application itself
the logging really doesn't look very
complicated that that example is
literally coming from some of the code
the logging is hooked up through seer
log in a common dll so it's not code in
each exe I put it into a common nougat
package and each exe imports that and
without doing anything it's specific in
the application it just streams out to
this target
you can take a look at a dashboard and
some of the features of a solid logging
solution give you things like this is a
query of the difference summaries per
request query so per request we can see
what some of the status codes are what
some of the latencies are and we can
also see here two charts and here's
where you really start to play around
with the tools to see how many
dashboards you need to get good
visualization of the health of your
application
everybody's application is different
everybody's telemetry is different in
this case there were so many tilde
status messages that it almost hid
everything else so I created two queries
one would tell the status one that
excluded tilde status so these are all
of the health probes that we have for
production staging and testing
environments and we can see how many are
returning 200 and 400 so these 400 oh I
don't know we could we can experiment
and drill down and see where those are
coming from it might be some of the apps
that are not running in the other
cluster ah no it's admin in this demo I
set up W W and API so the website is
calling a Web API site to return data
and display it I also set up admin as a
name but I never wrote in had been app
so these four o fours are traffic
manager asking who's running admin and
both of the clusters are saying 404 not
me so that's why those have 404 here but
these are all the keeper lives these are
all the status requests and here are the
requests that are everything else
here we can jump in here and see these
operations
one of them let's go here this this one
looks like an interesting response
because it's for the /resources and you
can fold open this log message and see
all the properties that are attached to
it is this large enough can this be seen
or should I
shred you this trick ok so here are all
the properties attached just to that
single log message and we can also do
something like find this operation ID
and say filter on it when I hit that
little plus it added this operation ID
to the restrictions in the query and I
can pin it and go back to the full log
which is just like all the messages
except that operation ID is now in
effect so I'm taking a look at all the
log messages from wrong request more
interestingly these are actually
requests that go from the website to the
backend because this code has a system
where when it makes a client request to
API is also running in the cluster it
goes through a component that's adding
the operation ID to the downstream
request so when the web application gets
a request it makes up an operation ID
and it flows down the rest of the way
so we can add additional fields here
like the application name
and see that this is actually a
combination of the Gateway and the
website and the web api all of the
things that happened across multiple exe
s or any on multiple machines are in
this single story and it's in one sense
it's kind of an advertisement for
elastic search the elastic table is
right outside this door and it is
fantastic I encourage you to say hi and
thank them for having a fantastic
product but there are lots of ways that
you can kind of put this sort of log
capturing and analytics together and
this is the kind of thing that you're
going to need in order to troubleshoot
especially once you start to do micro
services because you don't know which
computer any particular service is
running on it could be running on any
computer it could be running in
different data centers and you will need
to do things like say this operation
executed in these 17 places I went to
see all of the logs at once once you
have the kind of log navigation and a
visualization in place you're also going
to want to create alerts once you know
what your data is supposed to look like
you can start to create alerts that will
set off alarms when it looks wrong for
example in this visualization we take a
look at the exceptions that are
happening maybe for the last four hours
I have to get rid of this operation ID
constraint there we go and we can see
productions that have happened or
exceptions that have happened in
production exceptions that have happened
in staging and what exception class they
were and this is just because I these
are panels I put together because they
seemed like interesting queries again
you play with a tool you find queries
that are meaningful to your domain and
you
and you put them up ah interesting
Kestrel through a bad HTTP request
exception somebody is attacking the web
application so there's a lot of things
that happen in the dark that you don't
know about things like being attacked
with malicious requests
there's BOTS out there that are trolling
and looking for things left and right
and it's it's amazing what you can
uncover when you look for it even just
spending a day leafing through the logs
you'll find bugs in your program you
didn't even know we're there on top of
the benefit of being alarmed to alert it
when when the application is you know
genuinely down for something that you
know might have happened and took into
account so that actually has gone
through the three different arms of the
kind of production architecture we can
spend the rest of the time jumping into
some of the common code that is in place
to hook up these features through things
like seer log but I should stop and ask
if there are any questions that people
have on this sort of like architectural
setup Before we jump into the actual
implementation
well and so the question the question
was they are using a lot of this
technology in production and they are
seeing some issues that seem to arise
from service fabric itself specifically
when you're doing stateful services some
of the partitions seem to go rolled some
of the information seems to need to get
a hard hard reset before it'll become
green again exactly yeah
for that reason you might have noticed
that these are all gas deoxys it's not
really using service fabric features
these aren't even really stateless
services so the extent to which this
demonstration and some of the systems
within Bing
our using service fabric is as a process
manager so we keep state in systems that
are optimized for storing state like
that blob storage and the well and you
know it depends they give you a tool
they give you a tool and so you know
like any tool you you evaluate it you
you see if it's comfortable you see if
if you know if the bandsaw is taking
your fingers off too many times I'm
really the wrong person to ask like I
say I came from asp net core and also
from you know other production rooms in
working in Bing so my take on it is
there are a lot of cluster managers
available mesosphere kubernetes service
fabric they can be used in a way where
they are sort of like a resource
management and load balancing and I I
suppose in the short term until until
you can see that those are resolved you
might want to lean more on things like
you know the blob storage or the or the
attached you know sequel databases for
persistence hmm the question
ah okay thank you so service fabric
itself is the expensive part at the end
of the day when you have a cluster it
needs to run on virtual machines and the
smallest VM though the question was
related to the total cost at the end of
the day the smallest VM size on Azure
that you can use for service fabric is a
d 2v2 not a ds2 v2 but a d 2v2 and those
I believe are about a hundred maybe 140
per server per month within a cluster
you can do a dev or staging cluster with
three machines if you go for bronze
reliability durability but for
production clusters they say the minimum
is five so five d2v twos in two data
centers would be sort of the minbar for
industrial production application so
you're probably looking at ballpark
about a thousand a month twelve thousand
a year for budget everything else is
fairly cheap the other thing that I
spent money on was $30 on visual studio
comm to add more build agents because
the free lets you use one build agent
which means my environments in my builds
were lining up behind each other so by
paying that $30 a month it was it was it
made it possible to have simultaneous
builds going on and simultaneous
deployments going on so this demo is
made up of two clusters of three
machines each and I killed them
overnight I turned them off deallocate
and and that comes to one of the things
you're mentioning when you deallocate a
machine it actually gets rid of the D
Drive so when you reallocate them in the
morning
they are amnesiac they have no
applications they have no state so when
you turn them back on
you have to redeploy the last known good
web application so that's something else
to keep in mind in production if your
fabric cluster needs to be torn down or
restarted or if something really bad
happens you should know what the last
known good version of each of your
applications was so that you can go to
visual studio comm wipe the cluster
to play them all and be back up and
running within an hour maybe 45 minutes
depending on how quickly the automation
can run yeah
the advantage you get there though with
those d 2v2 s is the minimum size is
about 10 of those but now you have 20
CPUs in the world and you can run a lot
more properties than than those 20
machines so you can run 30 40 50
different micro services on those
machines
you only need to grow out once you start
to utilize all of the CPU that they have
available if that makes sense so in the
long haul they're more efficient than
doing like a PA's v1 because there you
have one virtual machine per web
application mm-hmm all right
the other things we can take a look at
or maybe some of these common libraries
like I mentioned there is an API which
is returning thoughts that are being
displayed on the front of the site
and so it has two applications one for
the front end and one for the back end
they both reference a common library
that common library exists in its own
get repo and it creates a new Capac egde
and pushes it onto a feed both of the
other websites depend on that nougat
package and in Visual Studio you can
create your own nougat feeds and push
things to them so the common code
involves things like program startup
inside this API the program main just
says use the bootstrap of classes main
function and I'm gonna hand in a
reference to my startup class so all
that code has been duplicated because in
the two examples it was the same in the
common project we can see what that is
it's a bootstrapper class that does the
web hosting it grabs this environment
variable from service fabric service
fabric has been doing dynamic port
allocation this environment variable is
how it tells the instance which part to
serve so it grabs that port passes it to
asp net core by changing the environment
variable name and starts up kestrel and
runs the site it adds a few common
services one of the services is a
startup filter that startup filters sort
of wraps around your startup class and
lets you put additional middleware in on
every web application so everybody who
does bootstrap Romain gets middleware
for free that startup filter basically
is saying if it's development use the
friendly exception page otherwise use
the exception handler which does not
leak information you should not use the
exception page in production this is
development in HP net core is driven by
that environment variable we took a look
at earlier if that environment variable
is set to the string development is
development is true here is where it's
responding to the Status page if you've
gotten this far you're healthy
it also does a thing where there's an
HTTP client in order to get that effect
of having the operation ID flow I wanted
to have all outgoing calls go through
the same code paths in the website that
looks like this so in the home
controller I get the thoughts client
ooh that's that's actually talking about
swagger so the thoughts client is
generated by swagger you can take a look
at that also and it depends on i HT TP
client of high thoughts swagger okay
hmm trying to think of the best way of
explaining this well basically the
client here you use it by calling this
get API that get API is going to be
creating an HTTP client and wrapping an
operation ID injector in as the call is
going out
and it does that here actually this is
going to be at this point I think this
is too random and there's not enough
time to really get value from just
hopping around in the code but suffice
to say I think that something like this
if you're going to have micro services
which you want to have consistent
logging consistent telemetry and a
consistent operation ID so that you can
see everything that happened for one
logical operation you are going to need
something like this common code where it
has the same setup for your startup this
same setup for your logging and the same
setup for your outgoing HTTP calls for a
service to service calls all right well
thank you very much for coming out today
I think that's pretty much the end of
who you have time they're every bit</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>