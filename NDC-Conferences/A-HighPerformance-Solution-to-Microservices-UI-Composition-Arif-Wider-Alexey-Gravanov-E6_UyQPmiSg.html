<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>A High-Performance Solution to Microservices UI Composition - Arif Wider &amp; Alexey Gravanov | Coder Coacher - Coaching Coders</title><meta content="A High-Performance Solution to Microservices UI Composition - Arif Wider &amp; Alexey Gravanov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>A High-Performance Solution to Microservices UI Composition - Arif Wider &amp; Alexey Gravanov</b></h2><h5 class="post__date">2016-07-21</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/E6_UyQPmiSg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so then so then let's start
welcome everybody and thank you for
coming
my name is Arif I'm working as a
consultant and developer for thought
works but the last about 18 months I've
been working with these nice guys from
autoscout and this high performance
solution to micro service UI composition
that we're going to present to you today
was developed during that time in a
joint team of thought workers and
autoscout Ruiz hello guys my name is
Alex I am working as software developer
at autoscout24 before we go into the
topic of your composition I'd like to
give you some background about our
company our motivation why we are doing
it and some context in which we
developed a solution to your composition
in no way out of Scout probably not that
known does anybody knows autoscout from
here oh ok couple of you so for
everybody else
autoscout is a marketplace for new cars
and used cars and motorbikes and stuff
like that their present is in 17
countries in some countries we have full
presence like full-featured marketplace
where we having contracts with our
dealers and stuff like that and in other
countries we have just translate a
translated version of our search funnel
when our platform we have about 24 2.4
millions of cars and motorcycles and our
platform serves about 3 billion patient
patients we are not his but a real page
page impressions per month is that about
one and a half years ago we started a
project that we call Tatsu yeah just
because every big project
have to have a name that's who means
dragon you see that logo on the
background and it's a dragon
because project is more or less rewrite
of all of complete platform of outer
scale so we compare it in our minds
we've dangerous but quite powerful
dragon yeah in this poor in this project
we are doing five things at the same
time first of all we are breaking old
and rather monolithic system into a
bunch of self-contained micro services
we call them vertical slices because
they having everything they need inside
of them from database to UI and that's
actually why we are talking about your
composition today we're also moving from
self hosted data center in the cloud
well not in Asia but in AWS and because
as small as building all the stuff from
scratch on a green field I wouldn't call
it migration we just selected not dotnet
platform but Linux and JVM platform to
build it from the beginning just because
it's not enough for us we also do in
some internal changes some changes in
our internal structures we change in
structure from hanging separate
operations department and development
teams to full-featured teams where
operations people are members of every
team and teams having knowledge to build
to build and run their stuff on you
build that you run at approach that
means team is responsible to build stuff
to test stuff to deploy stuff and if
something breaks and therefore o'clock
in the night
well to fix stuff
yeah and just because otherwise it will
be too boring for us it's also so-called
shiny new card so our platform is a
couple of years actually more than ten
years old and over the last years there
are some features which built at some
point of time but I'm not even not used
by majority of our customers or not used
at all so we are thinking what features
do we really need and cut in everything
else out and yeah that's what shiny be a
new card means this whole project
obviously is a huge effort so why we are
doing it one of my main reasons for that
stuff is to reduce time to market so we
can respond to needs of our users more
quickly for this it's really important
that we can release new features very
quickly also having possibility to test
abs doing a/b testing of some features
and get early user feedback so the idea
of that is to having possibility to
release staff within minutes not not
days and not even hours and we believe
to do that our team should be enabled to
be in to being able to innovate
independently we believe that key to
achieve this autonomous team that means
they should be able to work
independently on their services
therefore we believe that it's crucial
to avoid any form of any tight company a
coupling as much as possible so if team
wants to improve their stuff but they
have to wait for other teams until they
will be able to release their services
or their features it's not real team
autonomy so in fact we will you team
autonomy that much that we also accept
certain trade-offs like in some cases we
would rather copy code around and
introduce a shared library which will be
used by multiple services at the same
time we don't want to compromise page
speed
does anybody of you knows what PageSpeed
insights is no just couple of you so
PageSpeed insights is a tool built by
Google that analyzes a structure of a
page in terms of how fast page could be
rendered particularly on mobile browsers
and Squa of page speed goes up to 100
and good score is considered starting
from 85 we also strive for a low latency
obvious that pages should be rendered in
South fast that means that we heavily
rely on different cache layers and that
our pages shouldn't have any blocking
content in content of my context of
microservices it's actually a bit tricky
to achieve both high PageSpeed and team
autonomy all right thanks alexei so now
in order to explain why this actually so
hard to combine a good page performance
with good team autonomy I'm now going to
present to you two different ways how to
generally approach this problem
and the first of the two ways is the API
gateway pattern does anybody of you know
the API gave my pattern alright so so
let's take the autoscout24 comm page as
an example here actually the German page
is much more complex but I think this
dot-com page here serves as a good
simple example so you can see that yeah
it consists of a main content and then
there's a header and a footer I mean
that's not a very surprising structure
of a web page so if we approach this now
the API gateway pattern then this could
look like this so here you see that in
the backend
the monolith is already broken down into
several independent services such as the
home page service here or the header and
footer service and now for example this
red UI component here could represent
this main part of the home page which is
content which comes from you know which
presents content which comes from the
home page service whereas you could
imagine this or orange part here as the
footer which presents some content which
comes from the header and footer service
so now you see in the backend it's
broken down into services different or
independent services but in the front
end you see that it's still one big web
application which takes care of the
whole web UI and now in order to avoid
that just when performing a simple
single action the web application has to
start several requests to several
different back-end services it's
generally a good idea
to introduce such an API gateway here in
between which aggregates requests and
thereby dramatically reduces the number
of requests that is required for a
single action which is particularly
important when you view the page on a
mobile device so this is generally the
idea of one of the main ideas of the API
gateway pattern so it's actually great
for page performance because you have
this request aggregation and also this
single web application it's fairly easy
to optimize for good page loading times
because you have all in one application
you can optimize it all together and
thereby get good page performance
however there are quite some drawbacks
to this API gateway pattern and the main
drawback here for us is that there are
that truly independent feature releases
are not possible at least not if those
feature releases include something being
changed in the back end and in the front
end so let's say something needs to
adjust something in the footer needs to
be changed so there's some change in the
header and footer service and something
visually needs to be changed in the web
UI then in the worst case three teams
have to be coordinated to just make this
single change the web application team
or the team that takes care of this web
application the team that takes care of
the API gateway and the team that was
responsible for the header and footer
service so this is nor we know truly
independent feature release and that is
because the yeah we basically just went
half way here of breaking down the
monolid because we only broke it down in
the backend but we still have kind of a
UI model it so
to sum it up this approach is good for
page performance but it's rather bad for
team autonomy and now because we
actually do this whole effort of
rewriting the Auto Scout site to get
more team autonomy and get faster faster
and releasing new features this drawback
really Imran at this if you get to a
pattern no option for us at least not
for the web page so instead we went for
another pattern and this is another
second pattern I'm presenting which is
the UI composition pattern so the same
thing now with this pattern would look
like that so again imagine the otoscope
page and now in this example here the
homepage service would contain the
backend logic for the for the home page
service but would as well deliver the
actual HTML Javascript and style sheets
and similarly the header and footer
service would contain the backend logic
and would also deliver this yeah the
HTML the JavaScript and CSS which is
required for that footer piece of the
otoscope page and because and yeah
that's the reason why we call those
services vertical slices
Alex I already mention it because with
this pattern basically each service
contains the front-end part a back-end
part and everything in between
so there's no classical layered
architecture anymore and this way each
team can basically change their back-end
and their UI at the same time pretty
much independently
of course just as long as it doesn't
affect other parts of the page but if it
doesn't they can really completely
independently release their change and
do not have to coordinate with anybody
else
so this UI composition pattern approach
is really great for team autonomy
however there are quite a few challenges
that come with that approach so um first
of all all those pieces of the page that
come from different back-end services or
different services have to be combined
into one single HTML page in the end
because that's what is delivered to the
user furthermore we must enable each
service to deliver not only the HTML but
also the style sheets and the JavaScript
at the same time then the page structure
must not break order the final page
structure must not break the page
performance and that is actually already
getting tricky because any single
service that is part order that delivers
some content which is displayed on the
page in the end could introduce some
render blocking content and thereby
basically pull down the page performance
of the whole page and the same goes for
the request latency because of course
the latency is determined by the slowest
of all services that are involved so
generally you could say where as team
autonomy is really good with that
approach achieving good page performance
is a bit tricky here and then finally
also independent testing of those UI
components and also testing them with
integration is in chela is a challenge
for that approach now in order to
illustrate you how much of a challenge
such a high performance UI composition
is I'm going to quickly tell you the
story of our first well not particularly
successful
approach to solve this problem and that
approach was based on Barna Shandy si
who of you knows what varnishes alright
quite a few so um varnish is an HTTP
proxy cache you can also call it an HTTP
accelerator and two of you knows what es
is okay not that many so yes I means
each side includes and yes an ESI tack
is basically an HTML element which can
then be replaced with some content which
could come from another service so um
let's see how this looked in our
particular environment which was or is
AWS based so you see here there's an
instance of this varnish proxy cache and
there is an elastic load balancer ELB in
front of varnish and then we have those
upstream services how they are called in
a terminology and there is a ELB in
front of each of those services now if a
request from a browser hits or is now
requesting the home page then this would
hit the varnish varnish would route this
to the home page service the home page
service would deliver an HTML page which
consists a con contains some years.i tax
for instance for instance and yes i tec
saying here comes the footer and then
varnish would go back to the footer
service retrieve the content of the
photo service replace this in here and
delivers this back to the client
so um let's have a look how this looks
in code so this yeah would be a really
dumptown example of how the content
could look like from the home page
service
so you see this is a normal HTML page
with HTML tags around it and then you
see up here the head section with
already minified style sheets and down
here you see also JavaScript which is
already minified and here you see there
is the ESI tag which simply says yes I
include and then you see here the source
routes to the German header so now this
gets replaced by a varnish and then you
see this is the content which is
delivered by the footer service note was
the header actually so just a header and
you see now there is the style sheet of
the header the actual content of the
header and the JavaScript of the header
now the problem of this page structure
structure as this is that the page speed
would be really bad or it's really bad
because we have now render blocking
stylesheet links and JavaScript
scattered all over the place all over
the page so yeah from the page speed
inside score would be what we're really
bad ok so then we thought how can we
improve this and an idea that we had was
to split up this include into auditors
they are getting the content from the
different services into multiple yes I
includes so basically include the
content at three places first here one
include for the styles and then and that
is already in the head section here and
one include for the actual content and
then another include for the JavaScript
so in this case if this now gets
replaced
we have a good structure so the page
speed would be much better that way
however we now have another problem and
that is really tricky as well
so an S that is a set version
inconsistency or possible version
inconsistencies so imagine now we would
release a new version of the header and
this new version of the header would
come with a new some new HTML content
and also some new style sheets now of
course because we want to provide good
page performance we're caching
everything right and especially varnish
is a cache so we're actually cashing
those responses from the upstream
services so now those different things
here could have different times to live
or basically the the cache could be
invalidated at different times so that
means it could happen that we already
get the new content the new HTML content
but the cache is not invalidated yet for
the stylesheet so we still get the old
style sheet and therefore we have
inconsistencies here so and right away
we actually did not see with this
approach of separate yes I includes we
did not see a way to solve this so this
was a huge problem here also another
thing is that the assets are not
combined yet but it's even a minor issue
in comparison to the version
inconsistency because this may not be
such so much of an issue if you only
release once a month or whatever but as
we release several times per day yeah
this situation is much more likely to
come up yeah so basically what was the
situation at that point we had the our
team had the job to build a solution for
the UK UI composition of the new
autoscout page and with the first
attempt with varnish and ESI we
had either a bad page performance
because of a bad page structure and then
attempts to optimize the page structure
let in to an increased complexity
regarding the asset handling furthermore
this approach with having multiple yes.i
includes puts a high burden on the teams
actually providing this content because
they have to provide three different end
points for the 40 different things and
also combining assets with ESI is
possible that also adds more complexity
and then above all those issues we had a
specific issue an issue specific to our
environment there because we are using
AWS elastic load balancers so an elastic
load balancer actually consists of
multiple IP addresses because of the
multiple availability zones but now
varnish actually says as a upstream
service
I want one IP address otherwise I'm not
going to start to work so that was
basically an the killer issue that we
could not go down that way so yeah we
kind of had a bad week so yeah we had a
lot of problems but at least we knew by
now what were the requirements for a
better solution so we knew that the
solution that we need to provide in the
solution it would need to be possible
for the upstream services to provide the
links to the assets and so on as part of
the HTML itself so that we do not have
those version inconsistencies and at the
same time in order to get a good page
performance this means that we need a
solution with some post-processing
furthermore we wanted to have some
support for combined assets to get a
better
page performance and also in lining CSS
and JavaScript would be nice and finally
it would be nice to have support for
shared cash between instances because
we're using immutable servers and
therefore yeah it would be really nice
not to kill the cache with every release
right yeah so that were the requirements
that we came out of this first failed
attempt to solve the problem and now
alexei is going to tell you what
solution we then came up with yeah so we
finally found a right solution that
satisfies all our requirement and at the
end our solution consists of three main
parts so it's at first its Ingenix if it
says I'm module to resolve include so
it's basically SSI model is very similar
to what is high functionality in varnish
is doing second part of it is PageSpeed
module for in drinks which is developed
by Google and which is doing post
processing post optimization for
composite pages and third third part is
a AWS elastic cache which is nothing
more than memcache D it was basically
externalized - so our services
completely stateless and in Azure world
they will be windows edge caching
something like that
we checked exactly like memcache D yeah
so let's check what how the cross flow
works
so when request is coming from browser
to engines engines
results from configuration that for this
path is some service responsible and
sends requests to a service service
returns page with SSI includes which
gets passed and in jinkx and SSI module
resolves all SSI fragments on the page
and loads them from different upstream
services afterwards pages given to
engines page speed module which is doing
post processing in particular it
prefetches all assets all styles all
JavaScript combines them and generates
single link out of it places JavaScript
just below the patient style all styles
in the header and yeah and in addition
to that we have two level cache but
we'll talk about this in a minute and
afterwards post processed page sent back
to the browser and as we found at the
end it worked much much better than our
first attempt with varnish all right so
I'm now before showing again how this
all looks in code I just want to explain
that we conceptually distinguish between
what we call a page and what we call a
fragment so um pages are generally
publicly accessible yeah URL whereas a
fragment really is just a part of a page
so pages get call get called from the
client so the browser
whereas fragments really just get called
from engine access as as I'm module in
this case
a page can include fragments obviously
but also fragments can include fragments
so we can nest fragments but of course a
fragment cannot include a page then a
page could be cacheable however there
could be various reasons why page could
not be cached such as cookies or so a
fragment on the other hand should really
be casual so the ideas that a fragment
is a rather static thing
static small thing that can be cached
easily and then finally pages define
contracts for fragments and fragments
have to drop to adhere to those
contracts so they have to behave well as
part of the page for instance not
consuming more space on a page and are
allowed to so um now let's have a look
again on a simple HTML page here coming
from the home page service again you see
now um this looks very similar as in the
ESI approach so again you see here the
minified and actually already combined
style sheets and down here at javascript
and here this is now the SS I include in
contrast to yes I Tex SSI includes are
basically just HTML comments which then
say hash include virtual and then again
you see there's the yeah the path to the
German header in this case so this gets
then replaced by engine access as I
module and again you see here that this
is the content that comes back from the
header service here and you already see
the content that it gets delivered by
the header service has a nice normal
structure it has a head section with the
style sheets in there then the actual
content and then as you would do it
normally at the end there's the script
section so I'm
from the perspective of the team that is
delivering that content that fragment or
the content of this fragment is
relatively easy to to test also to
display in isolation and so on of course
now we have the same issue as before the
page performance of this page as it is
would be really bad so therefore now the
nginx PageSpeed module or mod PageSpeed
comes into play and this mod pagespeed
provides several filters and one of
those filters is combined heads and
basically those filters are post
processing steps and so now going back
here you see there is a head section
here and the content that has been
delivered by the header service and
there is a head section here and then
the combined hats filter would do what
you would assume that it does and
thereby basically pulling up this star
sheet link up here into the head section
so this already improves the page speed
but it's not that great yet and then
there's the next filter that we apply
which is combined CSS and JavaScript and
this filter now really combines all
those stylesheet links up here and also
it combines all the JavaScript down here
so now really we have a really good page
structure with a good page speed and in
here the only thing that is left is the
actual content left untouched is the
actual content that came from the header
service so actually with those more or
less with those two filters there are
many more filters of mod PageSpeed we
were able to get a really good PageSpeed
score so of this small page that we
developed that uses this UI composition
we were able to get a score of 97 for
desktop and even 96 for mobile so
those are actually really great numbers
although I have to warn you if you go to
that page or the otoscope page right now
it will actually show lower numbers
because we have ongoing this discussions
whether we want to load the font
synchronously or asynchronously and
because right now the decision was to
load it so currently the page speed is
rather bad which is an example of how
one page or one fragment being able to
pull down the whole the whole page speed
off the whole page but generally apart
from that the page speed um that can be
achieved is really great so ya know X is
going to tell you something about
caching yeah alright let's talk about
caching small recap of how the whole
staff is working so request is going to
enjoying this is a module Croatia's low
the fragments resolved page is passed by
Page Speed module and then I said
prefetched
and let's check how one of our two cache
levels and why it's working
so first of all we have so-called proxy
cache which is basic sits at the lowest
level of request processing pipeline and
it cached actually responses from
upstream services this adds additional
level of resilience that means if some
service will go down yeah we will be
able to get content out of cash
well better stale content then no
content content at all right second
cache headers from upstream services are
always respected so we think that teams
know how to cache
their stuff should be cached so we not
forcing them to do anything here we also
support cache key modifications via very
clear I will talk about this in one of
the next slides and the whole staff is
externalized and AW elastic AWS elastic
cache which is nothing less than name
cached memcached could not be attached
directly to and drinks and drinks can
read out of it but not write right into
it so we enabled it by using an Jenks
cache module as they see cache model
yeah second level of cash is cash for
post processing post processed and
optimized pages and assets that means
that all generated assets which are
already combined and minified and stuff
like that are stored there again it's
same elastic cache which basically
enables us to to throw away servers so
our servers are completely stateless
yeah it also allows us to do a rolling
update without having any question
organization and the cool thing about it
we never have cold cash and since cache
is completely externalized this solution
is scaling horizontally to almost
unlimited number of instances serving
our requests well of course limitation
of memcache the still applies but yeah
it also can be scaled horizontally
pretty good
so how cashing of assets working working
here all our assets pictures and styles
and JavaScript's are fingerprinted that
means that during compilation they there
are hash is generated out of content of
files and hash is added to file name
that means if you do some modification
to those files you will always always
always get a new file name that means
every single version is unique as unique
file name that means we can cache it for
like forever
yeah well forever probably not good idea
because sometimes your cache will be
filled and so we said let's catch it for
one year and this thing is controlled by
our micro services 7 assets and our your
composition there is just respecting all
cache videos coming out of upstream
services I am second level of cache
which is basically sitting on a near
pitch pitch speed module is caching all
combined assets when I was talking about
processing page he said that all assets
are prefetched combined and there is one
single link generated out of it where
all assets are just put together and
just to not burn CPU every time when
yeah because processing cost cost CPU
just to not be on CPU every time pay she
served
we are caching calculated versions of
our assets
okay let's check how a question of
documents is working so it's more or
less the same cache of proxy mode you
still respects all cache headers coming
out of upstream services the only
difference is that at this point you
have only one level of cache because
yeah there is nothing to combine so page
is basically get soft get short from
services and it's not getting minified
or combined or something like that there
is possibility to control cache behavior
by adding very hidden
why we don't need this on the front from
outside our website is visible on 17
different domains right and having all
17 different domains for all services
upstream services which are serving
content is quite overhead yeah so we
decided to keep one single domain for
upstream services but we still need to
catch somehow different versions of
content because of different languages
right and our proxy module is
transforming what is doing is
transforming cookie where user stores
his language settings into a you see
here here here the X cookie culture
taking value out of culture cookie and
sending this header to underline
services to while retrieving fragments
because otherwise underline services
cannot see the line services serving
fragments cannot see additional areas
they are so called
requests in nginx so only page requests
ICS original original requests and
fragments just don't see it this way we
enabling the enabling services to say if
you have some content based on language
it's also possible to evaluate language
by transform transforming cookie into
header variable and series can say yeah
my staff should be cached based on this
cookie and then value of based on this
header and this value of this header is
added to cache key after words okay
testing when you're developing your
stuff of course it's good idea to test
it I release and stuff untested this
doesn't work that well but how to test
your single service which you runs on
your machine if everything else served
from I don't know from maybe 10 services
or 20 different services let's check how
it's working it's already useful shoot
already in all these pages our
international home page having three
fragments header footer and main area
which comes out of home page service and
let's say we want to change it in test
header locally so you have your
developer machine where you develop your
header and you want to check how it fits
into the patient place if it plays
nicely together before other parts of
the page so we built a docker container
which is basically same tricks or
configure it same way we from the
difference that caching is completely
disabled there
all other parts of functionality are
absolutely the same and it's possible to
say to this docker container please take
my service from my local machine while
all other services will be still taken
out of the cloud so this way in jinks
combines content delivered by your local
service from your local machine well
everything else is yeah get out of
production basically when Tim started
using this solution they sometimes had
unexpected behavior and sometimes we're
getting unexpected page speed scores and
long rendering times so when we started
from realizing what's going wrong if you
do a town that we have some some errors
which some mistakes which happening
quite often so we built so-called best
practice analyzer and it's nothing else
than some script analyzing fragments and
HTML pages for some anti patterns for
example differ I think if you say yeah
in fragment my JavaScript should be load
it is differ I think PageSpeed will say
no I will not do anything with it
because it cannot predict in which order
your stuff should be load it and execute
it another way another thing is page
barrier in PageSpeed mode there are so
called page barriers it's inline script
inline JavaScript which are not loaded
externally but just yeah inline in this
case order of execution is important and
PageSpeed module cannot combine assets
across page border so that means if you
have Java some fragments above page
border and some fragments below page
border
PageSpeed module will unfortunately not
combine anything which will affect your
page page speed score again another
thing is styles outside of head or style
sheets references with different
attributes and a couple of other things
and we build it as a script which can be
run in a development pipeline different
pipeline which means if something is
going wrong here yeah you'll feel just
break that's it
of course the whole staff even if it's
working pretty well the whole staff is
still work in progress
right and not all problems are solved
and we have couple of things which yet
has to be solved have to be solved and
one of those things is authentication
what to do with pages which requires
authentication and how to serve content
which should be protected for particular
users another thing is native mobile
applications if it's possible somehow to
benefit from combining parts of your in
native mobile application well you
cannot solve everything that it was
alright so let's come to the conclusion
so yeah what other features of the UI
composition solution that we built with
this solution which we call jigsaw
internally teams are really in full
control of their services UI and do not
need to rely and coordinate on our on
others when changing it at least if it
doesn't affect others so we have really
autonomous teams also fragments have a
simple structure with a head some kind
of body and script section or part so
it's relatively easy for services to
provide and
their content page performance is not
compromised in any way on the contrary
page performance can actually be really
high because of the good post
optimization also beyond that jigsaw
serves as a really effective cache layer
with multiple cache levels and as Alex I
just showed you with this jigsaw docker
solution fragments can be tested in
isolation and also an integration with
other pages or fragments yeah and most
important thing of all its life and it
serves thousands of requests per second
flawlessly its life with a current
German autoscout home page and I think
the dot-com list page and we're actually
really happy with the solution whereas
we came from from a point where we
thought wow this is a really hard
problem and we had at some point in time
we're wondering how we're going to solve
this and now we're really happy with a
solution let me show you one thing well
I hope it will work somehow great here's
a result page when user whoops where's
my mouse and use a searching for
something
well I Drive out the a4 so I'm looking
for out the a4 usually when do tests and
pages pages so in this case out the a
for the couple of thousands of search
results
well connection here the venue is not
that fast as expected but you see a just
reloaded pages render it almost
instantly and what's interesting in this
page which contains some results we have
Oh
thirty fragments so actually every item
showing here in this list is a fragment
so every item which is yeah single car
displayed on the result page is a single
there is a separate fragment yet yeah
and this means that actually also every
of those items can be cashed at those
multiple levels that we saw yeah I think
that's it and we're happy to answer any
questions that you may have thank you
for your attention
oops into first but anyway yeah so so
far we're just using javascript packages
and style sheet namespaces for this and
we were afraid at a point that this
would not be enough isolation so far it
actually works fine so yeah we come in
communicate well and actually it's also
part of this best practice analyzer
which detects that you use namespaces
for your service and so far this is
actually enough so we were afraid of
this as well because the solution
provides no actual isolation but yeah so
far we're haven't run run into any
problems yeah we had the same the same
fear in our mind about this thing part
of our company
culture is to give people a lot of
freedom and if you are given good people
a lot of freedom and hope all our guys
are good guys you figure out that people
actually don't misbehave so if you say
guys please do it like this and they
actually doing it like this of course
nobody is nobody stops guys developing
homepage to call their Styles to put
their styles in footer namespace but
well it will be kind of stupid yeah and
I mean it is really interesting because
this page gets combined really late
basically any service can mess up the
entire page I mean we we check a lot of
things and it's best practice analyze in
the pipeline but still really teams have
to rely on other teams not messing up
with a page but yeah this gives a lot of
freedom and agility to the different
teams and so far it's working very well
I mean we had certainly small incidents
but yeah made some pretty good
experiences with this model so far
yeah yeah the point is that user
experience well in the past it was not
that not the case but now user
experience is the most important thing
for us and rendering of a whole page
should be blazing fast that means we are
trying to avoid using any heavyweight
libraries like jQuery so yeah if Tim
needs some functionality there feel free
to use some smaller libraries and we
have just avoid using some huge
frameworks like angular jQuery or
whatever yeah yeah you know so currently
we approach this the following way we
import those libraries or some libraries
or also as I mentioned before the font
as part of the page so not as part of
the fragment so and then the fragments
that get included on that page assume
those libraries and fonts to be there so
there's kind of they they rely on this
we don't know whether this is going to
be the final solution to this but this
is currently how we approach this yeah
and thereby yeah the page is responsible
for providing those those libraries and
the good thing here is that the
responsibility is pretty clear so the
team that maintains the page or
responsible for the page is responsible
for the page performance and thereby if
any fragment providing service messes up
with a page score or needs
needs another version of a library or so
they have to talk to each other and the
team taking care of the page is actually
taking care that everything is all right
with that page yeah pretty much
yeah it's yeah it's a good question I
mean basically we were looking into
varnish and SSI and yeah we had all
those problems and then we basically
went into the weekend and then a
colleague of mine mobitz hiber is from
taught works as well just came back from
the weekend and said well I have an idea
there's this PageSpeed module from
Google and it can be used in nginx
and what we had ideas before to use
nginx in order to make varnish work with
elby's to put an engine X in between so
we already had nginx on the on the page
kind of and then here he remembered that
there is this PageSpeed module for nginx
and that it could actually solve all our
problems but yeah so so our mood really
turned from a while we're really
frustrated to oh wow that's the cool
solution
well that is a really good question to
be honest we have not thought about this
at all because yeah this is not harder
autoscout page currently works so I
guess for now we don't have any any
pieces of functionality which builds
built as a single page application
probably it will not work if we will try
but for now we have no answer for that
yeah yeah you could try to come up with
a similar approach like having some
post-processing on the client side but
yeah maybe you could use the same
approach and adapt it to that but yeah
we haven't looked into this at all yeah
we actually have a completely continuous
integration and delivery so um to be
specific right now every commit that is
pushed goes automatically through
through product to production if it
passes all tests so yeah yeah yeah right
oh yeah at least if it fells
dramatically and then of course with
monitoring which checks the page speed
as well so of course if if it's going
from 95 to 94 of course it will be this
still deployed but if you if it's going
from 95 to let's say 60 yeah tilt will
be a problem
listen that's you do you switch to to
Java have you been internet shop before
yep well let's have each other
afterwards I mean we we basically
switched or well we have to say they
because I was only involved in the
project at that point where it was
decided that would be the the migration
to to Linux and JVM
so we basically went at Auto Scott from
c-sharp being the main language to Scala
being the main language because I think
was agreement with the developers that
they didn't want to go from C sharp to
Java not even Java 8 so yeah and then I
think yeah I think it has been quite a
challenge the migration but at least
from my point of view
um developers are generally quite happy
with Scala
I mean yeah you have to say so
yeah but of course it's it's a huge
migration with lots of knowledge sharing
and knowledge build up needed yeah it's
not it's not like c-sharp is a bit
language for something or dotnet is a
totally miserable runtime no of course
not unfortunately now it's getting
better over last year or two there was
lack of automation for Windows platform
so it was possible to automate a lot of
things but since we've thought about two
incompletely automatic continuous
deployment right our our infrastructure
is completely coated yeah
and checked in in repositories so the
zero manual intervene intervention
in provisioning services configuring
services and all that stuff so basically
changing they are not changing to Scala
as a as a target right we were changing
to platform which allows us to automate
all the stuff better than it was
possible at that moment with Windows
platform and unfortunately now it's as I
said getting better and better at this
point of time it was not possible to run
dotnet applications on Linux so yeah it
was smallness of this decision yeah I
think the main strategic decision was to
move to AWS and then and then decision
for Linux and JVM followed from that
yeah I know it it's not that cool to
explain all that stuff at dotnet
developer conference but well it's our
locations anymore yeah
why not know Jesus well well I mean well
I mean when we're using NPM in the front
end at all kinds of places but yeah
we're doing server-side rendering we
used to play framework or server-side
yeah frameworks yeah I think there was
no specific decision about this all
right so far so far not all right thank
you very much and have a good evening</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>