<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Keep you data safe in a containerized application - Hagai Barel | Coder Coacher - Coaching Coders</title><meta content="Keep you data safe in a containerized application - Hagai Barel - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Keep you data safe in a containerized application - Hagai Barel</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/Sh-kRv9Yemg" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">all right so um good morning everyone
thanks for coming a very 93 cent for
quite a while first time speaker sort of
data access and excited so go easy on me
we'll be talking about containerized
applications now and we'll be talking
about how to properly design and
structure when container as an
application in such a way that you won't
lose data and data and storage is an
issue when it comes down to containers
and applications and something that you
need to consider when you're removing
your architecture from those big servers
that you used to run and move them over
to containers well discuss what
containers are give us a good basis for
our discussions and we'll talk about
build containerized applications and
then we'll move on to storage options
and see what kinds of solutions we have
when we want to run our containers
applications we'll finish we'll finish
up our talk with a use case will
actually take real live use case and see
how we build the solutions to keep it
running even though it's still in a
container so um talking points um basic
introduction Who am I
well is there an idea we'll give some
introduction to containers containers
101 will dive into some theory of what
containers are actually are how they
work how they function how it can build
them how we can put files or manipulate
them or run them we look at how some of
the challenges of running a distributed
system
break down small containers and lots of
containers one of some of the challenges
the wave minor counter will move on to
storage picking the storage solutions
we'll take a look at several solutions
with written examples when and how to
use the proper solution for each case
I'll take a look at these case and then
we'll summarize and have some questions
alright so let's get started
um this is me my name is Caleb Odell and
I'm singer DevOps consultant at a
company called code value or an Israeli
based company I'll talk about the next
slide I've been doing a lot of
containerized work as a past year year
and a half
a couple of systems planning and
production some on staging some one
testing all kinds of interesting use
cases of containers as per the
application lifecycle I do a lot of
designing infrastructure design and to
support those containers applications
some are on-premise systems running in
the local data center summer cloud
deployments as your AWS other than that
I did talks and I teach me and I try and
so that's basically me cause value where
an Israeli based services company with
the professional services in the
software world everything from URI
unique software design agile mentoring
and process implementations DevOps you
name it and we also have a extension
called auth code which is a visual study
extension physician debugging and with
the ton of cool features link debugging
heads-up display all kinds of
interesting stuff we have a booth in the
entrance to the floor go check it out
really cool features of great great
stuff all right so that's basically me
and us so let's talk about it about
containerized application those are
containerized okay that's the way you be
used to build software okay now this is
a pretty common setup for you know just
any self resistant we have your three
layers your three tier setup you have
your presentation layer you have your
business there and you have your data
layer the presentation layer it's pretty
common it's pretty standard
it's nothing you make about that your
presentation layer is the interface the
graphical interface that you use or
interacts with the system all your heavy
lifting
or your logic or your code data
manipulation happens in business layer
the data store actually stores that data
long-term now the problem is such setup
or one of the problems with the
old-school big fat monolithic setups
it's really hard to build these things
now writing the code by actually
building it compiling the solution the
solution can have hundreds of projects
if you want to change one line of code
we have to build that solution from
scratch basically you got coupling
inside your projects they reference one
another or the reference other projects
and other solutions you got a big giant
mess of components that you can't really
easily reuse if you want to introduce
new features if you want to fix bugs you
have to build that solution again again
compile the whole system and climate is
one big unit to the staging environment
it goes through a pretty long cycle an
app of lifecycle just to get your system
up to production 16 your code oh
introducing a new feature it's hard okay
because having experience has been
working with the clients and they have
this big monolithic applications it's
hard it's really hard to build this
system which has like hundreds of
dependencies NuGet packages references
dependencies on databases it's kind of
looted it's a mess oK we've been doing
it for a while it's a mess a solution
okay so let's not work in this big
monolithic fad application let's try to
break it down and the solution is
actually breaking me down to small
components Thanks each one of those huge
layers and just break it up to simple
components small components atomic units
the each component does just one thing
okay and there's a high cohesion
it's very granular it's very small it's
very atomic this also means that I can
work on each component independently of
the other system no dependencies or very
low dependencies between two components
I can actually build a whole lifecycle
for each component so then it is this is
a really new concept in software design
and the microservices concept we've been
doing it for a while we haven't called
it micro services we call it
service-oriented application massara for
a while but micro services actually is
an extreme so means take that service
break it down to very very very small
components build and develop its
components its component on its own
independently from the rest of the
system now the problem with such a setup
micro service serve it's hard to deploy
it to production if you had early
previously we have that presentation
there with one chunk you build it it
took it the deployment you deployed it
to your environment now we have to
deploy a lot of small atomic units each
one has to be packaged each one has to
have its own dependencies binaries its
libraries each one has to be packaged
independently from the rest of the
system sorry so that so what are
containers then and how do they help us
build these applications there's
distribute these applications containers
and we'll discuss them in just a bit are
exactly that missing piece in the
deployment cycle it can help me actually
package and isolate each micro services
and deploy it independently from the
rest of my system all right so that's
the high level view overview let's take
a theoretical spin
- what containers are those are
containers whether it's a shipping yard
in England I think summer
all right so containers well
theoretically and very very very
high-level look at the containers
containers are basically a method of
operating system-level virtualization
that's fairly complex enzymes let's
break it down a bit
take vo missions okay a virtual machine
is basically a computer it's a virtual
appears there's not physical hardware
that's associated with that virtual
machine
it runs on a hypervisor software
component that actually mitigates
between my machine and the hardware
requirements on the method it emulates
there's all the resources for mine and
from my machine for my virtual machine I
have the chance appealed and virgin ram
answer this storage I got everything I
need to run lines answer machine
containers on the other hand are similar
in that in that way that they actually
virtualized and isolated but they don't
require a hypervisor in order to run you
don't need to emulate a whole computer
just to run a container instance it's
small it's isolated and it runs directly
on the kernel that means it's really
quick
it gets the resources directly from the
kernel now containers actually allow us
to run applications in resource isolated
processes very similar to virtual
machines these are isolated from the
rest of the operating system then unlike
virtual machines then I have this huge
computer this huge machine that
multi-process this is a simple process
very small that happens in the OS level
alright that isolation encapsulation is
achieved using two features called
namespaces and control groups
let's basically give us something like
this all right this this little box over
here
that's a container alright that's a
namespace which is isolated from the
rest of processes and the system now the
process is running inside namespace can
affect processes outside of that
namespace
meaning that the process is running
inside the container can affect or
modify other processes in the system the
other processes can affect those inside
the namespace inside the container but
not the other way around and that's the
isolation and the encapsulation that we
get by using your container okay it's a
single process which has sub-tree of
itself but that's basically it right so
whenever you hear the word container
this is it okay
small namespace that is the confines a
subset of the process stream now control
groups is the counterpart of noise and
namespace control groups actually
allocate resources from the operating
system to that namespace meaning how
much RAM does my namespace use I want CB
how much I am what's networking how much
storage okay so there's two features and
a counterpart they actually complete one
another all right so those are
containers but how do we build them and
how to run them so the containers
actually are well actually running so in
order to build one we have to use an
image right now an image you can think
of images think of an image as a
blueprint pruning a container okay
it holds all the relevant information
than my container needs in order to run
you can think of it as the image is the
design time construct and the container
is the actual runtime constructs okay
so the class of an instant a ssin of
that class it's basically just a file
okay it's a compressed file which has
everything inside of the code of the
dependencies all the references the my
code actually needs in order to run now
there's other ways to build an image urn
using the text file is pretty the most
out is it is :
you write the inside your text files you
declare what the things you need inside
your image is a basically just a set of
instructions
and how to build an image think of all
the usual things you did when selling on
the new server okay you go out and you
install the updates and security patches
and stuff like that then you go out and
install all the third-party dependencies
you need a framework you need whatever
you cook needs and then finally you put
your code inside that so there's like an
image it's pretty much the same thing
okay I started this base something okay
and then I put in here I put inside that
my dependencies and my third party is my
name's Mike Lammers
and I just put my clothes in silence i
package it and fun that's the base of
all containers containers aren't
mutually exclusive to an image meaning I
can run several containers from the same
image okay now a key point to this image
container thing that images are
available meaning you can't change them
once you build that five people anyone
which is great you can't change the over
a build file it's really if I have
changes in my account I just build any
image put the updated code inside that
okay all right so to sum it up what's
the benefits of actually using
containers well the first and foremost
main benefit is using containers it's
really really fast
all right so start at times fast
shutdown times it takes about half a
second to second to get a running
container once you have that image on
your computer okay just put in the
command on the command interface on your
CLI then you got a container okay
again this is an a-list level
virtualization you don't have to go
through the hypervisor okay just create
the namespace allocate the relevancy
group and you guys can carry you get
your container so
really fat where is really scalable
because it really fast meaning I can
have like five six seven eight instances
of that same container and that image
that we just discussed can contain just
assess of microbeads okay and then the
whole computer I mean the whole
operating system that has things or
baggage that I don't need okay only two
and a half gigabytes of Windows server
just to run five BLM's
and I need compatibility two printers or
whatever I can use just stuff my code
actions needs my diner is my parents and
my madam Michael all right and again the
process isolation we discussed earlier
which means they flying container
crashes or I made a new one
it doesn't affect the rest of the system
so these are main benefits of using
containers and that's actually much
makes them so so perfect in a micro
service based operating table okay my
code and service based design they're
small they're Atomics of granular it
boot up really fast really fast and
they're really easy to scale and we
please but micro services and
distributed systems have challenges
major challenges and while again once we
got our head wrapped around the concept
of containers let's move on to someone's
challenges of running a dis to be a
system alright so we got like a bunch of
containers running there's all like
three servers we used to have in the old
days where we knew exactly where each
one of them is what kind of operating
system it runs
what's it storage needs patches they
want to give you guys a bunch of
containers running which is great
because one it's capable one small we
wanted greater now there are some new
challenges and we need to consider now
these three challenges or issues or
challenges of every system okay
you can break them every system to
basically the three main pillars
same thing needs to run in its computer
means meaning with each CPU needs rent
the actual stuff that runs in from code
you need to network to communicate with
other components in that system or
external and they need storage now first
is the main issue of our tottemo will
further dive into it later but let's
briefly talk about compute and
networking okay so um compute well yes
several issues we need to discuss over
you need to attend to in the compute
section you have to make sure your have
resources enough resources that your
code needs in order to run and it means
it has enough memory it has enough CP it
and you have to allocate the resources
to the components to actually use them
now one of the main tools you can do
that as we're using scaling okay those
are you're familiar with the scaling
concept it means how much dynamically
allocation resources I can do or how to
do it to a single component Eckener is
vertically which means more and more CPU
that instance or I can do it
horizontally meaning more instances okay
take a look like a matrix it grows on
the y and x axis okay vertically and
horizontally okay more instances or more
power to one instance more instances
means you need more machines obviously
okay maybe more hosts we can place all
your instance in something
well vertical means I need to be here
and instance more resources to that
instance now scaling horizontal staring
at that's an issue over itself and it's
actually a little more complex problem
and you might imagine because once we
grow multiple instruments we need to
start thinking about placement that we
place instances we got like a bunch of
holes let's say that time change tendons
running inside of our system and we are
like a thousand containers so we need to
allocate those containers
place them on the host Sparkie or
intelligently or maybe just distribute
them Italy so it's an issue all by
himself and its container placement okay
where they put them once I got other
issues like how to keep them alive how
to get their heartbeat is in our life is
dead if it's dead let's schedule a new
one
let's put any one how do I replace all
containers with new one
I do update the system the roaming do it
black out a lot of concerns around that
alright let's talk about network some of
the challenges we realize discover or my
channel and running a distributed system
you need some kind of mechanism for
discovery ok maybe you have all your
components running in the system and you
need to find one another way to
communicate with one another ok my dear
is over rest calls am i doing it keep it
disappear
whatever protocol but they need to
somehow find one another it's like ok
where are you I'm there okay here's my
IP great and when you're running a
distributed system a lot of containers
that becomes a real issue okay how does
how does one component finds the other
one in its how do we keep that list of
services relevant when containers are
replaced when they move between hosts
and they die when you should really
start up the service discovering
furniture growling again love you so
much so discovery but how does data flow
inside my system
how does my system communicate with
external services or internally policies
firewalls ports so like that all the
issues revolve around security are we
running HTTP or not is my network secure
or regarding SSL certification
what's the trust level between
components inside my system load
balancing some other challenges another
challenge which is even more of a
challenge now that we're running in
containers because we got like eight
instance
of that same container how do we balance
load on that instances okay how do we
grow again scale and connect that load
balancer to our scale to our instances
there are other challenges revolving
around network these are just example of
definitely we need to consider a third
pillar is storage every non-trivial
application in the end of it has to keep
data somewhere okay
it could be user details okay it's may
password ID which you probably saw in
the database it could be files image
files PDF files just static regular
files whatever it is if the end of it
will have to keep your data somewhere if
you're keeping your days somewhere you
have to make it available to those
instances that need that data okay now
again we're running in a distributed
system multiple hosts that means that
that data needs to be available from
multiple places
okay well discussing the delay
durability I want to my data to be there
when I needed okay
I don't wanted to get corrupted and I
want to get it erased and I want to get
deleted I wanted to be there when I need
it and of course scaling as my system
grows my data stores and my storage
needs also group which means I need to
somehow think of a mechanism that can
allow me to scale my data accordingly
with the scale of next system again
other issues revolving around our
storage but some of the challenges are
so it's those options storage solutions
or storage options what kind of
mechanisms
do we have some of them are old-school
okay some of them are solutions that
we've been doing for a while and argue
some of them are a bit different when
we're talking about containerized
applications so the first solution or
maybe the most trivial and strays for
one just put your files in the container
okay it's cheap clothes you don't have
to do really anything just files that
are stored inside that containers
control group of name space it's really
fast because again you don't have to go
somewhere else to look for your data
it's there on your local disk and
there's no sub specific configuration
just as you always did just save your
file to the file system and just read it
from that file system that's like the
most trivial and Beeville simple storage
solution now the cons of that issue is
you can't share that data again it's
bound it's inside that namespace inside
that control group and no other
containers can read or access that data
unless expressly allowed and again this
has very low durability containers a
very short lift okay it can die which
means a schedule anyone will have to
start the new container we can get
replaced which means I now have to take
down the old one and start at the new
containers so the durability using in
container storage option is very little
when should you consider using in
container storage well static files okay
static files are part of your image you
don't really have to keep them somewhere
else they're already inside the image
and once you get up or start up a new
container from that image those static
files will be there so there's nest
storage consideration as you have to
take when using static files cache data
again sketch data it's very disposable
just you know the next time I can't care
and startup just build your catch you're
running and I have to keep it somewhere
else and to save it or consider or
design a whole solution around cache
data
another option is manually and clustered
application we means that my instances
now find and share data between
themselves and then data will require an
external or storage options a great
example of using container based storage
in elasticsearch okay if you're not
familiar Laster search your last search
is a database sort or storage mechanism
there is especially designed and
optimized to deal with textual data now
plastic size comes by design in the
clustered model which means I can run
multiple instances of that same elastic
search and they know how to share data
between themselves which means there's
one instance dies the other have has
copies or replicas of that same data
you're not losing anything so even if I
haven't designed a persistent storage
for elastic search and I'm just running
it inside the containers again those
containers can find one another
so this discovered we discussed another
and they know how to share data with
windows self using index is a
replication all kinds of neat stuff okay
if you're now running in clustered
application nothing you can't afford to
do okay
that's maybe the main Kinane point here
if you want if you can't afford to lose
it then put in a compare okay put it
somewhere else
where you can put it well again got
couple of options you can put it on the
host okay those containers they running
on someone okay they're running on some
kind of a beer some kind of operating
system so you can just put those files
on that okay did that computer style
system this is great because it we now
share volumes or share files between
containers they are running on the same
host again you have to do a special
configuration about the sharing just to
just make sure okay that folder of that
mountain point is a shared mount point
and all the containers can access that
folder it's really fast again it's on
the host level saying is the container
based storage there's no network calls
there's no dad whistle overhead stuff
like that it's on the local disk you can
just read right to that disk now the
comments here is that data is down
through the host place okay which means
leave your host machine dies because as
maintenance because of failure because
of whatever that data is lost
okay so again it's a bit better the
durability that we got a deep in
container solution but again it's down
to the hosts life okay which means when
people want to move from let's say
on-premise data center over to the cloud
they'll have to take on my grade that
deal with you okay it does require some
additional configuration it isn't that
complex configuration but it's a bit of
an overhead when you're using it when I
use em when should you consider to use
it really really really a good example
of using host based solution it's for
longest okay just write all your logs to
a central point on that host I have a
log harvester just look at that folder
and ship it out there into the central
this moment it's a great example of
using shared storage announced or a
cycle set up okay so I feel set up
basically means I have two containers
okay there's one another one of them
stitches
the other web reads that Lee okay now in
order to keep that data available for
both containers that can use host
storage okay so let's say I have an
application that reads tweets on Twitter
okay one part of it is the actual API
caller that pulls the tweets from
Twitter and the other component raised
those streets and displays them to the
user in the list or whatever okay so I
have two containers here and one fetches
the please save them on a shared host
folder and the container of that
displacement just read from there and
this place okay that's a sidecar set up
which is great if you have two
components they actually use or need
some kind of shared volume to really
write data to okay
you have a place innovation here because
again when we discuss compute earlier if
you're running a multiple host cluster
okay we have to make sure those two
dependent containers end up on the same
host machine because we need to read and
write from save data store okay a great
example is solve it for D is the load
harasser very similar to and
functionality speaking very similar to
locks - apology elk step slow G we can
run it in a container again and head and
look at a shared folder the oak
containers right there logs to just
picks up those locks from natural volume
shut them out to elasticsearch or
whatever maybe get your centrioles
logging anymore in place and you don't
need to interfere would be handle
containers you need to grab send your
hand inside a container and grab those
logs so settlers log saved on the host
and so they can read the fast on the
host and ship them out
all right if there's option or a third
solution is it isn't an external storage
okay again this is the most random Bell
proofing technique that we have we've
been doing it for a while now
most of our application used some kind
of external storage it can be s3
metamorphoses and meta you name it
okay there's a storage and that's
externally from our system there is
accessible to all our environment for
computers or a hosts running in that
system we can share it on all Health's
not just one hosted anyone can access
that data store it's scalable okay just
putting any disk then you can do storage
okay if you're running on if you require
provider lets it be easier because you
get scale as the box you may need to
configure a do anything special about it
and it's durable again if you back up it
it's one centralized storage just back
it up if you have some issues with it
along the way just restore the backup
and you're done okay cloud providers
have that scalability and durability
already built in so it's a great
solution when you're running on up and
cloud that you find it the columns here
there's some additional configuration
substantial ok we have to set up the
external storage if to buy hardware is
running on premise it's not as you have
to configure your cloud providers
storage options you have to configure a
host and say network or some kind of
mechanism that they can access that
those latency that can be an issue okay
again you're not reading from the local
disk you're reading from place on the
network so you might get some encounter
some latency or performance issues okay
read/write locks
if one instance writes to a file can the
other instance read from that file or if
we both write to the same file the same
time who has precedence who has a lock
on that site what concerns that needs to
be
when you wear with external shared
storage now when you use whenever you
have clinical data okay we have data
that you can't afford to lose and you
need to stare store it and save it for
long term tailors time put it externally
okay it's not down to a host life it's
not bound to container lives it's an
external it has its own life cycle its
own management it's on mating cycles and
it's a headache of Albin by itself but
it's their long-term and skinnable and
durable tons of options for external
storage we mentioned s3 we mentioned NFS
storage blobstore is running around here
tons of external storage options all
right
that's a very use case ok this was
actually part of the work at this for
the client and the story goes from
terminalia the whole application web
based application the dates and
calculations on maps okay I'd like this
giant matter of your country it drew a
polygon inside that that's nap
it's said when I say that a signal
crease data get some image manipulation
it's from all kinds of crazy stuff but
in order to run that these maps and
those queries and polygons then is some
kind of GIS engine geographical
information system okay
I decided to use Gale sir okay um does
the wanted to do it inside a container
and Gale server by design is a stateful
application it needs to save its maps
data store somewhere and we we had to
design a whole solution how to run game
server inside a container so that's game
server it's all open source you can find
it online it's a java application it
runs on top of the tomcat web server the
application itself okay
the server behind Java server underneath
does all the heavy lifting on the data
manipulation and retrieval so it's stuff
like that the client is just too thin in
a REST API call client and those calls
are processed by the server map data
file stuff like that are all saved and
stored in a file system ok some kind of
file system it can be local can be
remote with those stores actually are
designed in a file system so the
solution is actually a two-part solution
the first part was actually billing that
Gale server client that instance inside
the container ok we based that on top of
official town cat image and we just went
on and grabbed the static files of your
server and place them inside image but
you say below is an actual s crap from
the text file the darker file we used to
build an image again it's just a set of
instructions and how to build an image
and then run instructions if that that W
get thing if it goes out to the Internet
pulls down from the air service files or
zip and then in fact from inside that
image so those are the static files case
again with your server client and
handles there is a REST API calls the
other part was actually designed with
datastore okay we based on the NFS as
much file system share this is
on-premise systems within the cloud
based system so we have an NFS
accelerating system we basically just
said ok this is a give server folder and
we mounted that chair to the host an
only data center so they can access that
and share that was the actual vocal
command we used and to run it okay
the - the flag means it's attached to
this macro process that's - v flag
that's the actual interesting part let's
the volume maps ok
which means we have a mount for
code NFS share Gale server data and it's
mounted and convicted a nurse storage of
guilt server and that host mount was
actually an offence announced okay so we
had the container not in the host folder
which mounted an adventure as a great
set up because again if Gale server dies
crashes from some reason and another one
is being good enough to replace it it
can access that same data store and it
shared around all instances of get
server all right so that summarize
things up okay um containers are shows
with this okay by design their shows
please okay it's not some bug or flaw in
the system in the content by designers
on it which is great because again when
we're running adjustable occations and
we just wanna fix one line of code we
just start building your image start at
the new container and there you go okay
never put critical data inside your
containers okay because they're
shortlist
okay the things which you can afford to
lose casually static files stuff like
that okay
host they say okay they go down for
maintenance they crash they fail they
die they burn up in flames
okay then put stuff there tip again not
stuff that you actually care about that
you actually want to keep long term okay
if possible use cloud provided storage
solutions they're scalable durable on
the maintenance headache that's not your
problem anymore
it's your cloud provider problem okay
but performance of the nation okay when
you're using external storage and we'll
consider that performance test bit say
they it meets your expectations and your
criteria when you decide between those
storage options lowers remember when
you're running a distributed system
distributed storage as well okay has to
be accessible absolutely build has to be
durable
well that's it um questions if you had
any
Wow have a great audience
now I said the docker containers get
their risk of Sal occations from the
from the host you can use 150 you can
use to you can use fight yeah yeah you
can you can grow it vertically okay up
to the to the resources you have in your
system share volume between containers
you put data in the data and then you
can like destroy the container and then
we can it's the same data so as I said
that the challenge with that is open
data containers can sometimes be deleted
by mistake
don't put it in their bones better
models are great data volumes is a XO is
a great concept around containers it
basically means I can have a container a
data container okay and other containers
can mount or share that data container
okay it's kind of like host-based
storage but in containers okay that
files in storage inside a container
Raymond all the other instances just
look at that containers and shared okay
now what happens to that data container
dice well your data isn't really lost
okay it saves in belukha file system so
when you build up a new container it can
access that same data volume fishes
around this and it's not real scalable
okay when you're running a multiple
hosts you need to make sure that that
data container is available and
kinds of hosts which can cause some
great overhead and performance issues
that's one thing and the other thing you
might have some orphaned data volumes
around and from deleted or obsolete data
containers it's a great great options
for mocking okay we need me to you know
mark a data store and you don't want to
set up a whole new server or you know
put some additional software on your
computer
mocking is a great great option or great
use case and for using data container
just build a new image in the container
put your mark data inside the container
and every time you need to write API
calls or fetch that data it can just
start at the container that has that
data inside it is a little scalable and
it isn't really doable
so not really production greater yeah
database well girls are is kind of the
database okay that's great that's why
it's a great use case keep your file
okay
even a database and in an SQL Server
database in the end of it it has filed
as to keep somewhere as LDF or MVS files
or whatever okay and it can keep those
files on external storage okay
which means you're safe okay again this
is critical data it's crucial data I
would have done it I'm going to put in
the host probably written on an external
sponge yep you can you can performance
to be a sucky thing your detested but
again if it's not critical data to
though it's not real-time data okay the
yoke
scuri okay if it gets like a half a
second delay it's fine that's okay
it isn't crucial in a time-based data
then it's great okay put it outside okay
if it's critical data this need some
additional consideration subtype
critically they're all great Laplanders
ubuntu soda is highly tested okay most
new docker container features or mostly
Ana tested on Ubuntu server I have a
great great experiment sentence some to
seven Red Hat has some issues with
running Ducker very very very very leash
use cases stuff like that the most
modern Linux systems with 4.0 kernels on
above can run containers pretty much
great
now witness sorry does not guys why with
us that can be whatever you want you
don't really even need an operating
system inside the container offerings
insulin is a very convenient base for a
container image because by default
operating system has a lot of what my
codes really me
and network interfaces and it has
environment variables and a bunch of
stuff that my codes agent meets so
usually we base our images on top of an
operating system okay let's take a
bundle for example and then put my
dependencies on top of that ability and
then put markers on top of those
dependencies and you get an image that
already has an operating system inside
it isn't a requirement you can deal with
all the operating systems okay
I've seen projects are basically just
compiled binary inside a container it's
a binary in a box okay and that binary
has everything he needs to run okay
proxy HTTP a winner okay so binary in a
box again
containers are more of
packaging mechanism and distribution
mechanism when an actual environment to
run the code you really need an
operating system this I want the bells
get really really really hazy I've been
doing it on my personal computer okay I
understand which has darker on a
vacation it works it should work fine
okay as long as containers are agnostic
to the operating system okay
they're agnostic to the host okay the
same way that virtual machines are
agnostic to the hardware okay you got a
hypervisor that actually does the
resource allocation between the virtual
machine and the physical hardware
containers are agnostic to the operating
system okay then we'll really care if
it's Alex what kind of flavor is Linux
or whatever and the D don't even care if
it's a virtual physical machine it's a
visible the variable subscribe oh it is
yeah it's new she's not great
that's my completed them right a better
solution will be running es6 which is a
vmware solution on top of your hardware
and then your virtual machines can you
just drop with this you know didn't
really need it as a mediator
well great guys you've been a great
audience
thank you very much keep your data safe</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>