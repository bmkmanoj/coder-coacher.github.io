<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Machine Learning for Muggles -  Martin Kearn | Coder Coacher - Coaching Coders</title><meta content="Machine Learning for Muggles -  Martin Kearn - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Machine Learning for Muggles -  Martin Kearn</b></h2><h5 class="post__date">2017-04-28</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/f5TWQq_A4_0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">okay thus I ready to start thank you for
folks on there this is like the last bit
of the conference you know
also got to see that I've got a few more
than two people so mine is Martin Kerr
and I'm from Microsoft's I'm an
evangelist here in the UK and from
Microsoft I did a lot of work of web
with AI and machine learning and
cognitive services it's those last two
things I'm going to talk about today
we're going to cover quite a few things
around kind of high levels of machine
learning and also some of the cognitive
services which are machine learning
based API is you can use new
applications so before we start does
anybody recognize this guy
this guy a boffin so this guy is called
a buffing a boffin is a person engaged
in scientifical technical research and a
person with knowledge or skill
considered to be complex or arcane a
computer boffin with anybody
self-identify as being one of these
there any data scientists in the room
anybody that likes to do mathematical
algorithms and those kinds of things
good because sometimes I do this talk
and people put the hands up and it's not
this talk is not for those people so you
guys are all muggles you don't that you
don't have the magic that boffins have
in terms of data science and
mathematical machine learning algorithms
you just want to get to use machine
learning see how it applies to your
applications and see what you can do
that we could win in a good place so and
we have boffins at Microsoft we keep
about a third of them in Cambridge in
our Microsoft Research Center in
Cambridge and we've got other boffin
pens spotted around the world so most of
our machine learning work comes out of
our research labs and one of the main
labs that did a lot of the work with
machine learning and cognitive services
based in Cambridge which is great
they've got it's really lovely building
in Cambridge it's kind of custom-built
just for the boffins they're vey
beautiful very serene environment it's
very academic and they're all professor
some preneur other and they've got lots
of letters after their name there and in
the walls of this building they've got a
scientific art I've got no idea what
this means and what what the what this
represents why I'm sure that it's
definitely something scientific if
anybody knows what this is
shout out but I've not been able to find
out so far and possibly it could be it
feels like it should be more scientific
than that though it feels like it's it's
like a bit bit more than just that
they've got a grand piano in the 4a
there in the offices so I work in
reading and we've got an hour
got an Xbox and these goats are a grand
piano so yeah we weren't the same
company with a very different breed of
people very academic that piano was
donated by Professor Andrew Blake in
2015 when he left us the facility as
they call it or the lab so very very
machine learning is a very academic
world it's it's a world of mathematics
and algorithms and these kind of things
these long equations that you see
written on there movies and it can be
quite scary they do scary things in
machinery so these words here these are
machine learning algorithms so if you
are a data scientist you'll be red
you'll be familiar with things like
support vector machines and artificial
neural networks and those kind of words
and that diagram there that's a machine
learning diagram that represents one of
those algorithms so it's quite a scary
thing machine learning is a scary thing
so if you're into this world of data
science and machine learning you are on
these boffins and it's and for people
that aren't familiar of that world it's
quite kind of scary to get into and you
kind of think well do I have to learn
about all this mathematics in order to
endure some machine leg and that's not
true so machine learning is for models
too hence the titles of torment this
talk is about machine learning for
muggles it's about how you can take or
the benefit of machine learning and
bring it into applications out needing
to do all the scientific stuff and hope
for you guys or muggles and therefore
you'll you'll get some benefit from this
so and so what is machine learning just
a high-level so nobody put their hand up
when they said they're a data scientist
a data scientist is a job role that's
been around in the lot certainly last
few years but most prominently but it's
been around for a while a data scientist
is somebody that works with machine
learning processes to understand data
and get value out of data a machine
learning really is all about data it
finds patterns in data so if you've got
a data set of any size you it doesn't
have to be big data that's one of the
misconceptions around machine learning
is that people think you have masses of
data it's not true you have to have a
decent amount of data but you can do
machine learning on something with just
20 rows in it it doesn't have to be huge
big volumes of data and a machine
learning will find patterns in that data
and it will allow new data to get
insights based on those patterns so if
you think about a scenario of credit
card fraud if you've got a hundred
transactions you know which ones were
fortunate from those transactions their
historical transactions
if you know which one's affording you
can get a machine learning algorithm to
figure out what the patterns are within
that data set over 100 to make them
fortune transactions and then if you've
got a new credit card transaction coming
again you can then compare it to that
pattern and see what likelihood it is
for this new one to also be forged them
and and I use the word likelihood
because that's an important thing as
well you're never going to get a black
or white ants with machine learning
you're always going to get a likelihood
or a percentage score it's never going
to be this is definitely going to be a
foregin transaction it might be 99% sure
but it's never going to say it's
definitely hundred percent a forging
transaction it always gives you a score
and then you can use those scores in
your applications to judge what you want
to do with that information
so there's lots of use cases for machine
learning it's all around us whenever we
force something on Amazon we're using
machine learning the recomendation stuff
that they've got in there whenever we
play music on Spotify who used to
Spotify the display shows families a
case of about half of him so you know
that discover weekly playlist the one
that give it seems to give you songs
that you've never heard before from
bands that you've never heard before but
you like them and that's because it's
machine learning it's figuring out what
you listen to the music you normally
listen to and it's giving you something
new that space that matches stuff that
you normally listen to that stratified
you loads of machine learning in their
apps most modern apps most modern
websites full of machine learning dating
sites are absolutely full of machine
learning those matches when they match
people together that's all machine
learning based so there's some common
scenario so credit card forward is one
that I've outlined an interesting
scenario and predictive maintenance so
interested rolls-royce with their jet
plane engines do this
so most people don't realize this but
airplane manufactures like Boeing and
Airbus they actually lease engines from
all sorts I don't buy an airplane engine
they don't own the engines that sit in
their aircraft they're actually leased
from walls released directly and with
that lease comes a maintenance contract
so it's real sources responsibility to
maintain and look after those engines
are in all the airplanes that flies
around now what used to happen Rolls
Royces they'd have a specific cadence
for replacing parts and maintaining
certain parts of the engine and they say
after so many flight miles this thing
needs replacing after Sony for miles
just needs a thing the most like with a
car but
they're much more complicated way
because it's a much more complicated
thing and they found that they were
maintaining things that didn't need to
be maintained because they just had
these fixed routines and schedules they
did some machine learning to actually
try and predict when things were going
to fail and actually be able to do
proactive maintenance just before they
do to fail so based on things like how
long does that airplane fly if it's
Seattle to London that's a certain
region it's going through certain
atmospheric conditions weds it sighs
it's short haul is it long haul what
type of airplane is the engine fitted
into and all these factors come into
predicting for that particular airplane
this engine is going to need that part
of facing at this time and they're able
to just get in there just before that
and save massive amounts of cost in
terms of only maintaining when they need
to based on the machine learning
predictions rather than maintaining
according to a some fixed schedule so
that's predictive maintenance we've got
computer vision where computers can
understand images and understand context
images we'll have a look at some
examples of that natural language
processing where computers can
understand speech and understand the
intent and what's meant in the speech
and what the user is actually looking to
get so lots and lots of snow isn't
really any scenario where a pattern can
be recognizing data it is a sari that
could be used for machine learning so if
you've got some data does matter what it
is and you think it might be some
patterns in that data you can
potentially use some machine learning
algorithms to find out and give you some
insight in that data that you won't be
able to spot just as a regular human so
let's have a look at a scenario around
car price prediction so let's imagine
that we're looking to buy a new car and
we want to figure out how much should I
spend on this new car I've got a sort of
criteria in mind those you that have
bought new cars you've probably been
through this process
I kind of know what I want but I'm not
quite sure how much I should be paying
so if it's a second-hand car so let's
have a look at how we might approach
that now typically - let's say we're
looking for a car at 130 brake
horsepower we're going to use a data set
of 20 cars we're going to go on for
thogh trade or eBay or some other place
that sells cars and pick those 20 cars
that are roughly about the same as the
one we're looking at we're only going to
get price and brake horsepower data so
we're not going to get all of the data
for every car and we're going to do this
without a computer so we're going to
look at a process for how a human might
naturally prey
his problem versus a slightly different
way of thinking so the way human would
naturally approach this problem so take
that date and they'll plot it on a on an
Excel spreadsheet or a chart of
something like this nature so you can
have all the brake horsepower for each
card and the price for each car and you
might look at that and you kind of we're
looking for 130 brake horsepower here so
you might look at them and you might
kind of say were these 3 seem like
they're the closest match to the thing
I'm looking for I've only got the brake
horsepower data to go on so these seem
about right
we've got 120 140 235 so you'll pick out
those three and you'll say well the
prices that are in those three cars they
kind of seem like it's about twenty
thousand five hundred they're about just
just looking at the data that I've got
this is the way a human my approach that
a better way to do this a more
scientific way to do this with the same
data is to take those those 20 data
points and plot them on a chart like
this so you've got brake horsepower down
the bottom you've got proton on the left
there now each one of those dots
represents a row in the chart that we
just saw but you can see straight away
there's kind of a correlation here
that's kind of you can see immediately
how the pipe the brake horsepower
affects the price of the car and what
you might do then if you might draw a
line through the middle of that that
chart and that gives you an axis that
you can work on now we're looking for
something that's 130 brake horsepower so
we might do all these lines and that
actually tells us of the same data that
actually the typical price 130 brake or
suppose 17,500 so our rough guess was
3000 pounds out I'm using exactly the
same data I only got 40 data points here
and we're not using the computer to
taking a slightly different approach
we're able to reveal a very different
figure there and you might draw a line
around that and say well I'm looking for
a range and that might give you a range
between eleven thousand twenty four but
you get the idea that but I take this
this is the way computer thing they look
at the data rather than just taking a
good instinct which is what humans tend
to do humans are very very bad at
spotting patterns and data we're not
naturally good at doing that
but computers are so imagine though if
it is this data set so this is this is
car data as well but we've got many more
fields we've got things like is it a
hatchback is it four-wheel-drive is
these little petrol engines and what my
because it what models in what color is
it all of these factors affect the price
of the car because a bright green algae
i3 is probably going to be less valuable
than a gunmetal gray algae a tree all of
these things come into it and all of
these things affect the price of the car
so if we had maybe 15 data points and we
had maybe a few hundred cars to compare
against there's good there's definitely
going to be patterns in that data but
it's not a pattern that a human can spot
as humans we're never going to be able
to see what the patterns are we'll make
assumptions based on preconceived ideas
of what makes a car worth a certain
amount but we're never gonna be able to
spot the actual database patterns and
that's what machine learning is all
about it's all about spotting those
patterns so it's all about data you have
to have data you have to have good data
as well you have to have good consistent
clean data in order to feed into the
machine learning processes in order to
get those predictions out of it let's
take another example and look at
credit-card fraud and this is like that
the number this is like the 101 scenario
for machine learning and can anybody in
the room spot based on the data we've
got on the screen here what makes a
fortune and transaction based on what we
can see up here just shout out as you
can see yeah exactly the name begins
with the letter P so is there anybody in
the room whose name begins as the letter
P
good we've got no forces in the room
here with safe we're not going to we're
not going to get our money stolen so
based on this data quite rightly the
gentleman says the only thing we can
assume those the main begins as a letter
P that's not corrected it there's not
that it's not K to everybody whose names
are given as s appears and forward so
that's we haven't got enough data to
draw a sensible conclusion here it would
have more day to day yep so there we go
if we have more data we can actually do
all half-decent patterns so this is
again a very tiny data set but there is
pattern a can anybody spot the pattern
based on this data about what makes a
fortunate transaction just shout out as
four data points four things that you
can you can cause you have just shout
out if you can see
you
Russia yeah that's right so they're in
the 20s what was it about Russia
it was used in Russia the card used in
Russia okay yes that's - there's another
- in there issues in the USA yup that's
three and there's a fourth data point
here anybody spot in the transaction
amount is in that is over a thousand
pounds so we're a ream of what maybe
thirty developers great quite quite
smart people you'd like to say and it
took us maybe a minute to extract those
they're those rules so yes so it's over
a thousand pounds issues in the USA
using Russia and the age of the person
with the card is in their twenties if a
transaction meets those four criteria
there's a good chance that it's going to
be a forging transaction based on the
data we have here now again this is a
tiny tiny data set this is not a
real-world scenario you probably to do
credit card forward you would need many
more transactions than this you might
not need many more data points so these
might be the only data points that you
have available and they might be good
enough but you might need more like 100
transactions as a minimum to draw a
central kind of pattern but the point
here is that as humans we didn't spot
that it took us a few minutes
collectively as a room of people to spot
what the patterns were a machine spots
that instantly and using cloud
processing power you can spot that a
massive amounts of data instantly as
well and that's where the values of
machine learning so imagine if it's six
10 million records 60 columns there's no
way we'd ever spot that as humans but
machines can so what's the process
behind machine link so hopefully you're
convinced that machine learning is a
good thing so how do you actually
approach the problems start to do
machine their link well there's a
standard procedure so you start off of
data have to have data as we've
mentioned that it has to be good data as
well you can have multiple data sets you
don't have to have just one data set it
doesn't have to be some huge giant
database it can be just a CSV file or an
export of some sort from some system
there's many many formats whatever
format your data is in you'll be able to
use it machine learning and you also
have to size a question so what's the
thing that you're trying to learn about
the data and this exercise so in credit
card fraud we're trying to get some kind
of a formula that allows us to predict
whether a new credit card transaction is
fraudulent or not that's the question
that we're going into it with you go for
this process of cleansing the data
one of the things about machine learning
it doesn't really matter if you've got a
thousand or 998 rows what does matter is
that it's clean and consistent data so
if you've got any bad data so characters
missing empty rows empty records any of
that sort of stuff you need to throw
that data away it's not useful in terms
of the Machine being now to learn the
patterns it needs to have consistent
rows consistent data that's all in the
same schema all in the same format in
order to be able to learn so we have
this process called preparing the data
and we use data modules to do software
modules that will identify where the
data is bad and help us throw away that
data or change it so that it's good data
and you would go through this process a
data scientist would go through this
process of preparing the data they might
iterate a few different times until they
come up with what's called a prepared
data set the next procedure is to apply
machine learning algorithms so all those
words that we saw in the chart at the
start the Bayesian neuro networks the
linear regression all those things those
are all machine learning algorithms and
these algorithms are mathematically
academically proven algorithms are not
they're not things that companies own
Microsoft doesn't own a machine learning
algorithm Apple don't own one Amazon
don't own one they're mathematical
equations that are in proven and
academically certified and and these
algorithms get applied to the data and
they can learn things about data these
are the what these are the kind of rules
by which the machines learn and there's
lots of different algorithms and the
algorithms can get applied to data you
might use multiple algorithms in
combination to get to the data set that
you need and you interact through that
process again and you end up with this
thing called a candidate model a model
is basically the rule set this is the
rules this is the output of the machine
learning process a model is the thing
that your application uses to get
insight on new data from the machine
learning process and you end up with
what we call a chosen model so this is
when you've completed all the process
you're happy with the results you have
this thing called a chosen model and
your application will use that model or
make calls that modeling auditors when
it's got the new credit-card transaction
so it's based on your model what do you
think about this is it likely to be
fraudulent or not the model will say
it's 97 percent or 72 percent or
whatever
says so in the jaw we have a piece of
software called as your machine learning
which helps you do all of this so as
your machine and gives you those data
processing modules so there's a load of
different ways you can clean your data
and they're available is just software
modules you simply drag them onto your
machine learning experiment and they
will do the work of cleansing your data
the machine learning algorithms are also
available as software modules so you
just drag those on if you want to use
linear regression you just drag that
onto your canvas you don't need to know
the maths behind it you don't need to
know science behind it you just need to
know that for this data you need to use
linear regression which is a skill in
itself but we'll come to that and and
finally it will expose your experiment
as an API so your model your chosen
model gets exposed as an API that your
applications can call so they can post
in some data to it based on whatever the
transaction is and it will give back at
what's called a scored label which is a
percentage score of how well answers the
question so the way they maps on that
we've got the processing modules the
algorithms we've got the API that sits
between your application and the chosen
model and then depending orders this
regarding called is your machine
learning studio this is kind of like an
IDE for machine learning it's a
web-based interface that you can use to
pull together your machine learning
experiments so let's take a quick look
at that I'm going to do I'm going to do
the car price prediction thing that we
just talked about I will do it in
machine learning this time with a
computer and see see how that comes
together so we'll start off with a mouse
hopefully okay and I'm in CG that as
your ML botnet so this is this is the
place you go to you can get this from
just go to Azure and you'll find your
way to this I will do logged in for this
and they've already uploaded the data
set this data sets called car price data
so the screenshot of excel that we saw a
few slides ago that's what this data set
is based it's just a CSV file with a
load of data about car sales in it and
what I want to do is create a new
experiment so I'm going to go to new
notes experiment I'm going to use a
blank explain there are lots of
something there the kind of the whole
marketplace for machine learning
experience that people can upload their
experiments
the people can use them or buy them even
we just start with a blank one so you
get the idea of how to how to build this
so the point of me showing you this is
not necessarily so you can then go away
and build your own experience it's just
to show you that there's an interface
it's quite easy to use it's
drag-and-drop and and how it roughly
hangs together so the first thing we
need to do is that process of preparing
my data so this data actually have some
some errors in it so let's just have a
look at the data set so I'm just going
to take my car place data and it should
just drag it onto the canvas here with
all of these modules this kind of blob
thing is called a module with all of
them you can click on the output there
and do visualize what this all that we
do is it will let you as you're building
up your experiment it gives you a visual
representation of the data so we can see
that this column here called normalized
losses which has a lot of bad data in it
there's lots of empty cells there so we
don't really want that we also might say
well we can see the various makes and
the fuel types and all the other bits of
data in here as you scroll down you'll
see that some of them have got missing
get missing entries in there that's not
particularly good so I want to do some
cleansing where you can see there are
some with more missing entries in that
one there I want to cleanse this data so
the HSU things i'm going to do and
there's a module called select columns
in data set I just search for that there
is I'm going to drag it onto my canvas
here and the way this works is you
connect these modules together so I'm
gonna take the output of my CSV and make
it the input to that select data one and
if I click on that I can do a column
selector I'm going to go to withdrawals
and I can sort of exclude all columns
excludes column name so I'm gonna choose
normalized losses so notice how it's
actually given me the columns of the
data set I haven't done anything to do
that it's just so it knows it's a CSV
file it's looked at the CSV file and
those are these are the columns in that
CSV file so I can just pick them so I'm
gonna take the most losses I'm going to
take weight out as well those those I
don't want those things in my data set
and if I now run this it's going to do
that piece of processing it's going to
clean up that data to that extent if we
look at the visualize now
see we've got no normalized color losses
column and we say we'll see we've got no
weight column as well so we get we're
starting the process of cleaning data we
do still have these empty cells which
you need to get rid of like I said
before it doesn't matter quite how many
how many rows you've got if it's got bad
data in it get rid of it as generally
the rule so this is bad beta and we need
to remove some of those empty cells so
there's another module called clean
missing data we're going to take on a
drag into here and just like before I'm
going to connect the two together now
there's various rules I can set about
how it cleans the missing data in this
case I'm just going to remove the entire
row so this will basically mean that if
it sees any if any of the cells are
empty just get rid of that row throw
that record away we don't need them so
that's clean the missing data I'm just
going to run the experiment you have to
keep sort of running as you go along so
it knows the latest thing so what we're
going to end up with the output of that
module is basically a clean prepared
data set we now need to start applying
some machine learning algorithms to it
so before we do that one of the things
that's important when you're building
these experiments is start to reserve
some of your data for testing so you'll
use the percentage of it to actually
learn from and then you have another
percentage to test that what you've
learned is accurate so what we need to
do is we need to split our dataset and
there's a module to help us do that
split data and I take the first output
of clean data and put it into there and
say that I'm going to split 75% so what
this will do is it socket number one
will have 75% of my data socket number
two will have 25% of my data okay
next thing I need to do is add one of
these machine learning algorithms so you
remember I said all these out these
these academically proven algorithms the
one that we want to use for this
particular type of experiment is
something called linear regression which
is one of the more popular ones now the
skill of a data scientist is really
knowing which ones to use in which
scenarios so I only know that it's
linear regression because this came from
a demo script and he said put linear
regression in today I don't know what
these modules actually do but I know
that that's the right one for states
that I'm not a data scientist I'm just a
regular developer so if you're going to
get into this machine learning space
this is one things to learn is what the
different algorithms are what they do
have when to use what rich algorithm and
in which scenario but we know that we
want to use linear regression this
scenario the next step we do and this is
kind of the main where the main work
happens is you want to train the model
so we look for the train model module
and just place it there so this takes
two inputs first it needs some data and
then it needs an algorithm so I'm going
to take my data so remember that for 75%
of my data and then I'm going to take
the linear regression algorithm rhythm
and then I need to choose which column I
want to train it on so remember we're
looking for price here we want to
prediction on price so the column or on
to train arm is price so I can just type
in make sure I'm doing this right price
there we go
I don't you could train out multiple
things but we want to keep it simple and
just train down price so that's trained
model and just run now
so we're now into the stage we're
actually going to start making some
predictions and we need to UM now score
the model and use that remaining 25% of
our data to see how accurate it is
because I need to know I need to know
that it's doing the right prediction so
we add in something called score model
there is so I'm going to take the output
of my train model on one side of it and
then I'm going to take that remaining
25% of my data as the other side of it
so what this basically does is it says
you've used a 75 cent of data to learn
about the data and come up with a
prediction and I'm going to test this
prediction using the remaining 25% so
I'm gonna take the every field apart
from price see what the algorithm comes
up with and then compare it to the
actual price because the price is in the
stage as well and see what the gap is
see what the rate of error is that's
what we're that's the process of scoring
the model okay so that once we've pretty
quickly hopefully yep so that's
visualize what we've got here so for
each of these rows we've got a price so
this top one is at seven nine five seven
and the scored label is basically the
predicted outcome so again we're
predicting price and the predicted price
is eight six three three so you can see
that they're all in roughly the same
region so the six on eight four nine
nine and then it's predicted in $7.99
it's within a thousand or thereabout
this one's a little bit further out this
one's close again this one's a bit
further out but we kind of are in the
right ballpark the scored model is not a
million miles away from the price for
each new star of course there will be
some deviation the score model is never
going to be exactly the same surprise
because it's a prediction based on all
of the other data we've gone so what we
need to do now is the thing called
evaluate the model which again we have a
module for we can drag that into here
can take that and push it into there and
we'll run this what this will do is it
will do that process like I've just
imagined is comparing the price and the
scored label price and seeing what the
difference is and it does it in a
software way that is quicker than me
going for everywhere and doing it and
this will give us a set of errors now an
error isn't a bad thing it just means
we're the predicted price is different
to the actual price which is going to be
the case in every single one of them I
mean I won't go through what all these
mean the one that we're really
interested in is is coefficient of
determination that basically means how
far away typically was the actual price
compared to the predicted price and this
is very low and that's what we want we
want something that's very low if the
areas were huge if the actual price was
2,000 it's predicting 11,000 clearly
something's gone wrong in the model
that's not a good prediction but we know
from looking at the data visually and we
know from this that actually we're
pretty we're about right so I'm happy
with that now I'm going to proceed and
with that and go on to the next stage so
the experiment itself is is complete now
I'm going to save it and and we what we
have is the output of this evaluate
model is we have that's we're at last
stage now where we've got a chosen model
what I want to do now is publish it as
an API so that I can start calling it in
an application start getting some some
data back from it so we've got this
button here called separate websites I
just need to run it one more time I
think
is it what we've done so far is what's
called a training experiment so
basically we've we've made this
experiment that we can train the daytime
and come up with this model what we're
going to do next is turn it into what's
called a predictive experiment which is
where we can apply a new data and and
then get some outcome forms so we're
going to go to predictive web service
what's actually happening under the hood
here is we're creating a Turner's your
app service and we're hosting a website
it's actually going to get hosted as an
API we don't need to worry about any of
that stuff because that's all abstracted
for you by the BI interface here you
don't agree about virtual machines and
servers and all that kind of stuff this
is a path service which means platform
as a service you don't need to worry
about the infrastructure that sits
underneath this so that's my predictive
experiment I need to run that as well it
takes a little bit longer to run and
then we can just deploy this as an API
and start making calls to it and see and
see how accurate it is it takes about 20
seconds typically to do this deployment
and this is one of the reasons why this
has to work as a cloud service because
obviously there's a lot of computation
that's going on here every time I click
run there's a huge amount of CPE where
that happens and to do this on premise
with your own servers I'd have to have
software packages to do that which
you're very expensive and because have a
lot of resources to do that
that's why machine learning is becoming
more more popular now because cloud that
enables us to do that
other men we need to rather than having
to invest in infrastructure so let's
deploy the web service
and it gives us in
this is now an API and you can see that
I've got an API key there which is just
like every other API key I can go to
that there's two ways you can call this
you do it's a request and response where
I send it some data and it sends me a
prediction or you can do like a battery
execution which is where you kind of
stream data to and it streams data back
we're going to just do the request and
response and you can click on this to
kind of see an API help page so this is
public we can see that we need to post
to it that's the request URL we need to
post the various headers that you need
to pass in you need to send some data to
it so what we're going to do send some
car data which is going to include the
make the fuel and all that kind of stuff
it tells you what you can expect back
and it's an all like art uses HTTP
response codes all that kind of good
stuff we've got this little test
interface which is quite handy as well
which is which we're going to use now to
actually test a new piece of data
against a model so I've got the details
of a car here that I've got a photo
trader I'll enter that in and see what
it predicts the price is going to be and
so the make of the car is an Audi the
fuel is a diesel doors is four it's a
hatchback it's going to be front-wheel
drive the weight of the car is 1900 the
engine is 150 bhp is 150 the miles per
gallon is 55 and the price of this car
is going to be 23,000 okay so this is
the imagine sorry you're looking for a
new car these are details like are you
looking at let's see what what does that
batch will price should be based on the
data that we've had so we can hopefully
I'll zoom in so you can see that so the
actual price of 23,000 the scored label
either predicted price is twenty
thousand nine hundred pounds so you can
see there's quite a difference between
the actual price and what the price
should be for that type of car which is
of course you'd expect this because it's
now the right so now these are always a
little bit more expensive than they
should be aren't though because it's now
D it is a VW of this same spec it
probably closer to the actual price but
hopefully that gives you a flavor of
kind of how we can learn from the data
set again it's a tiny data set really
but we've been able to learn
sufficiently from it that we can
the price based on all these factors
that make up the card decision and we
can get some useful insight that format
so that's the Azure machine learning
service Cara carp addiction price so the
problem with this though is it kind of
is still a bit technical it's definitely
easier because you've got the
drag-and-drop interface you've got these
nice modules you can drag and drop but
how do you know which modules to use how
do you know how did I know that I need
to choose linear regression there and
split data and train the model it's a
skill it's not a skill that most
developers have it's something you have
to learn there's a whole breed of
technical people called data scientists
to do this for their for their job and
so it kind of is still a bit for buffing
those data scientist folks they are a
little bit buffing like you know they do
get quite excited about these algorithms
and things and and it's not a skill that
I particularly want to take on and I'm a
developer and web developer I don't want
to be doing astir so if you if you're in
that category les is where Microsoft
cognitive services comes into it now
cognitive services is a set of API is
that we've built at Microsoft to help
you add these kind of smarts to your
applications without you needing to do
the actual machine learning bit we've
done that for you so the separator is a
built based on machine learning that
they've built using exactly the same
service that we've just used of our car
prices and they're exposed as simple
api's so you can go and you can call
these api's in your applications just
saw the same way you would do with any
other api and they're quite they're
quite frankly quite cheap so for most
cases they're free up to a certain
threshold and there's one that we'll
look at in a bit that detects the
emotion in human faces and that's free I
think it's up to 10,000 transactions a
month so that's not a trial that's just
free to use if you're a small app or a
small service and you can just go ahead
and use that if you need to go over
those thresholds it's very cost
effective its pounds per month it's not
it's not a cost prohibitive thing
they're very very forcible way to get
some of those smarts into application
and there's lots of them as are the 25
API is in total and across those 25 API
is a 66 different functions 66 different
API functions that you can actually call
with your data I just pick out a few of
them so computer vision that is able to
detect things in images if you give it
an image it'll be able to say what
image what the colors are in the image
and all this kind of stuff about the
image we've got the face APO which can
detect human faces and and detect what
we call face landmarks are where your
eyes are where your nose is where the
end of your mouth is 27 of these face
landmarks and it can do this because it
might stuff what we've done is we've
taken millions of pictures of human
faces and we've had humans go and say
that's a nose that's an eye that's the
end of somebody's mouth give that data
to the machine learning process and it's
been able to then learn what an eye
looks like and what a nose looks like
it's something we can do naturally as
humans but can for a computer to do that
it's quite quite a quiet thing and we've
got a speech API so you can do do speech
to text and text to speech conversion we
can do we've got a thing called language
understanding which is where you can
give it some text it can understand me
intend for that text figure out which
words in those words in which words are
the actual words are important for the
text we can do sentiment analysis on
text to figure out how positive or
negative some text is the
recommendations API way you can do
things like frequently brought together
all the stuff that Amazon tends to do
and so it's a whole bunch of these API
so we're going to look look at just a
few of them so let's not confuse these
api's in action there's me okay so I'll
start off and with is anybody there any
parents here anybody got children so I
show from under the age of five - okay
you're looking I've got one and the age
of five she's called Madison and this is
Madison so I think this is quite an
interesting photo of Maddie she was
three when when this was taken
and so I don't know what's what's going
on here frankly she's got quite a
strange expression on her face I don't
know she's happy or sad she's definitely
not happy but is she annoyed is she
scared is she sad in some way but
fortunately we've got a machine learning
API that will help me determine what the
emotional state of my daughter is here
and it's called the emotional API so if
you go to Microsoft comm slash cognitive
you'll get your land here this is the
web page for cognitive services these
are all of those API so I just mentioned
and one of those is the emotion API
now what the all of the AOS have this
similar kind of interface they have it a
page which kind of explains all the
functions of the API so this one can
recognize emotions in image images and
also in videos as well it can recognize
eight global cross-cultural emotions and
they are anger contempt disgust fear
happiness mutual sadness and surprise so
every every human on the planet will at
some point in their lives display those
emotions probably every day they'll
display those emotions and we've trained
the machine learning process we have to
recognize what those emotions look like
on the face so they all have this kind
of little sample app that you can use
there are stock images but that's let's
just upload that picture of medicines to
try and find out exactly what's going on
in terms of her emotional state that's
what's coming
yeah
just refresh that I think my browsers in
the process of crushing let's try a
different browser everyone can tell at
this point their game
so let's try and upload the photo to the
website there
so what it's going to do is go
why's her face and it's going to see
which emotions are being displayed so
the first thing that's good news is she
does have a face and what it's what it's
done there is it's giving me a thing
called a face rectangle so it's giving
me the bounds of her face within the
image so in my application I can maybe
do something that maybe extractives that
part of the image I know where the face
is it's recognizing where the faces in
the image well it's also done it's it's
given me the emotional state by way of a
set of JSON scores so we can see there
that the overriding emotion being
showing those contempt 58% of her
emotional state is down to content there
so we can see the score there is 0.58
for contempt
we can also see that follows up with
contempt is 20% anger and then just a
light smattering of disgust at 9% so
she's contentious angry and discusses
with me at the point of that photos
taken that's what happens when you go
through you I'll charm anymore chocolate
before bed that's what happens she gets
contentious with you so that's good so
that's helping me be a better pair and
that's we're happy with that and the
next website I want to show you is
something called twins or not now you
may have seen this website before oops
get me to the right place what this does
is this is just a sample site we built
that takes two pictures of two humans
and tells tells you how similar they are
facially so based on their facial
features how similar are they so I've
been told in the past I look a little
bit like Jake Gyllenhaal
you know the American actor the handsome
American actor I've been told I do look
a little bit like Jake so let's just see
if we can find out whether that's true
or not so that's what made a picture of
me and then let's upload a picture of
Jake handsome chap he is and just see so
there we go so according to machine
learning and data science and all these
good things I'm 90% similar to Jake
Google I I do i we are in fact besties
according to this this procedure here so
it's able to take our two faces look at
our facial structures all that kind of
stuff and determine how similar we are
so I'm really pleased with that
I do actually look like Jake I know
after all and another one we've got is
called how old so you can imagine what
this one is going to do it's going to
take a picture of a human face and
determine how old that person is so
let's upload some pictures of me and
Jake to this just to see so I was 37
when that was taken and look at that
it's determined that I'm 39 years old so
I look two years older than I actually
am which is quite disappointing the only
good thing about this is that it has
correctly identified me as a male
so yeah I'm winning in some ways here
but I do look a bit old to my age so
let's try another photo and that's just
what though the picture of Jake just to
see so Jake is is about the same age as
me it's about 600 younger than I am so
he would have been 36 ish when this
photo was taken
that's just upload Jake and just for
comparison there we go 43 years old
according sister Jake actually was even
older than he is
Leidy so I'm quite happy about that and
I'm sort of feeling quite good about
that so that's a few little silly
examples another example I want to show
you is an app called the live camera app
now this is an example app to show you
it's a Windows application to show you
kind of how to work with these api's and
what it does is it it basically takes a
picture every three seconds lot loads
into the API so this is how we work with
videos and video streams and so I've got
a webcam down here somewhere
and I'm going to set it to assistant to
camera three which is what this one is
I've got it on faces mode at the moment
so if I start the camera
it should totally start to figure out
there we go so I look a bit younger now
I look 28 years old now I'm not facing
the camera but I am a male which is good
so I look directly at the camera I can't
see because I'm looking at the camera
but hopefully that should you should see
facing camera and not facing come so I'm
streaming these image so what's
happening every 3 seconds this is taken
photo sending it off to the face API
getting the data back and it's showing
the results for us on screen here the
various modes that we can do we can look
at emotions using the same thing so
what's my emotional state our mutual at
the moment if I got if I can't see
because I'm looking at the camera but I
hope that says happiness there we go
that surprised so it's giving you notice
it's giving me a number as well it's
given me how surprised am i and if we
can also do tags this is using the
computer vision API so what this is able
to do
is look at the images they're being sent
up here and actually figure out what's
being shown so it's saying laptop indoor
computer electronics which is right we
are indoor that is a laptop as though
developed Ronix there let's look at the
little Zambian monkeys anybody got a
mere monkey today from the Microsoft and
there you go so that is a stuffed toy
this Australia doll in fact is what that
is
if we look down here this is a bit of
backstage for us there look at those
those are hopefully bottles of water so
it sounds trivial because we as humans
we know this right but for computer to
be able to look at these images in real
time and actually say what what it is if
we look at all you guys blow around they
go conference room a crowd its able to
figure out what this what this is
incredibly powerful stuff really so
that's the computer vision API in real
time using video technology and like say
the code for this is that it's all open
source so get her to go to get her view
about to see how this is written and go
to build that kind of stuff into your
applications and another application I
want to show you is slightly more
serious one is actually this time it's
an Excel application who knew that
office had that store nobody nobody
knows office has an app so it does have
an app store and you can have these
things called office add-ins and they're
basically apps that do things with
office so I'm going to I've got one
called sentimental and what this one
does is it takes any text I put in
office and it can analyze the sentiment
and extract the sentiment and also the
key phrases in that piece of text so if
I say I really love London especially
the piece of London help I could spell
if I could type and spell so if I just
select that cell in Excel click analyze
it's going to take that piece of text
send it to the text analytics API and
give me some results so it's determine
that that's an 82% positive sentence
which sounds about right
it's to turn at the key phrase in there
is east of London so it's figure though
I've mentioned London twice it zoned in
on the east of them because that's more
specific than London so it's very clever
in terms of determine what the key
phrases are and then this app lets you
kind of
insert the score back into the
spreadsheet so they can you imagine if
like you guys a little hopefully provide
some feedback for this talk I'm sure at
some point or the conference as a whole
you'll provide some for bait and
feedback the motives the guys that
organized NGC could analyze the
sentiment as that and figure out the key
phrases of that and then insert it back
into their spreadsheet very very
powerful stuff we've used this
internally at Microsoft when we do our
own events we run all the data through
this tool so we can get a sentiment
score for the feedback rather than just
saying it seems like it's okay
we've actually got score based on the
data science and also the key phrases is
really important whether some of these
complaining about something they now
just pull out those key phrases is
really useful because it just picks up
the two or three words they really key
to what their complaint is so you can
get to the bottom of the issue quite
quickly so that's that's sentimental so
that's just a few examples of cognitive
services in action
okay that's not Madison thing she thinks
you can be a better pair of vise off
cognitive services and I good so let's
look at another application that I've
built called how happy so this is again
it uses emotion a favor it uses another
service called Lewis and so let's just
have a quick look at this you can go to
this yourself if you want to it's called
that's completely gone I'm going to just
use this how happy Cove at UK and what
this does is it lets me take it all
loads of photos a group of people and
determines who's the happiest Sousa
saddest who's the third most fearful etc
now what I need to do this is a photo of
a group of people now you guys a group
of people aren't you so if you don't
mind even if you do mind
when the fake photo said look really
happy the that Peter can possibly look
okay there's some it looks this bit
blurry so hopefully I'll come free and
let's upload that photo to the website
and see see who's a happiest person the
lighting might might might cause us some
problems here but we'll see so it's
going to take that photo takes and
upload it to the API so we found five
faces and the only reason it's not far
more is because of the lighting
conditions but this lady here in the red
is the happiest person in the room thank
you for that well done and who's number
five this person over here is the least
happiest of the five people that I
recognize so that's very good so we can
do things so that's what that websites
all about is about determining the
happiest the emotional state of the
audience and been out to rank who's the
happiest and who's the saddest and so
how does this work so it uses the
emotion AP I've already looked at the
emotion API with that picture of Madison
it also uses a thing called Lewis which
is language and the slamming intelligent
service I'll show this in a bit bit you
can filter and sort this API based on
natural language queries which I'll
demonstrate in a second and it's just
built using asp.net in JavaScript
doesn't really matter what it's built
it's a web application I hope you'll get
the idea that this is completely
platform agnostic it doesn't matter
whether you're writing Android apps or
something to run on a fridge or a web
application or whatever it is it's fine
it's just an API that's that's the whole
point of this really so Luis is an
interesting one so if I just go back
over to the website here I can do so by
default it's sorted the five faces by
happiness that's the default state but I
can do things like who is the happiest
one here so this is a natural language
the way human might talk to a know who's
the happiest one here what that's going
to do is it's going to say this we found
five places places we're showing number
one so it's determined that my intent
there was not to show all of the faces
but just to show the happiest one there
I might also say who is the saddest one
here that might change the emotion same
same query so we found five faces we're
showing number one for sadness so who
was number one for sadness the person
who's least happy so and about that I
hope it's not my thought that's making
you sad but the interesting thing that
I've asked the question using natural
language and I've changed what's called
the entity the emotion that I'm asking
for is called an entity now we're
digging just a little bit more later but
one thing that's useful here is that is
able to take general words and pin them
down to the word that the API needs is
happiness or sadness and I search for
happiest or saddest and it is able to
determine that those mean the same
things we can say things like who is the
third most surprised person here so two
things happening here so the third most
surprised person just in case you're
wondering it's at gentlemen there again
the two entities are being used here the
first one is what's called an audial
which is the number so I'm looking for
third it could be first or second I've
written third I could have written it as
in thi Rd as well it would have meant
the same thing and also surprises the
other entity that we're looking at there
so what we're looking at there the
breakdown of this is these phrases are
who's that happens person here so the
intent of that phrase is find out the
most emotional person and the happiness
is the emotion entity so the words happy
s maps to happiness the sex race who's
the least angry person you might say
that's the intent those to find the
least emotional person with the emotion
of angry which could have been happiness
could have been side basically etc the
next one is sorted by emotion so show me
all the scared people all the fearful
people it would use that emotion sort
them by that emotion the other one
that's not up here is show me the third
most surprise so when that's to look for
a specific person in the list so that
it's able to understand the intent of
what I'm asking for I've used natural
language it doesn't really matter how I
phrase these questions is able to
determine what they actually mean the
way the way we code this application and
this is some see sure who's the C sharp
just by show of hands
okay good to love you so I'm using a C
sharp here because that's what I use it
could be JavaScript it could be some
other language it doesn't matter
hopefully this look quite familiar for
those you that do do c-sharp so the way
that works is I'll load the file the
image I've got an API endpoint there
just like a regulator I just use a
regular HTTP client I add this thing
called an ACP subscription header this
is basically the API key to all the
talkative services have that API key and
I add that in there I then stream the
content I say it's something called an
octet stream and it gives me a JSON
result set back and I just do something
with that JSON is also I go for the
details of exactly how that works and I
convert it using JSON got that to a list
of faces basically a faces as strongly
types dot that object that I'm working
with once I've got my list of faces I
then need to get the Lewis intent so
what do I want to do with these faces
same thing there's an endpoint there as
set up by HTTP client I've got my
subscription key and
a thing called a Lewis query which is to
put a bit of text that I typed into that
text box there it gives you some JSON
back
and then I use I extract the emotion
intent from that JSON and use that to
sort the list of faces and that's why
that's how I can sort the list of faces
shown on screen
very very simple the reason I've shown
you that is because it's really simpler
just api's there's nothing you don't
need any special software on your
application it's just a standard API
cool if I doing this in angular it would
be however you normally call API so
angular it isn't jkirby however you
normally do it in jQuery it doesn't
matter it's just like okay the final one
I want to look at is recommendations API
so this one is very good
is anybody in e-commerce just a show of
hands does anything read commerce one
just a few views so this hopefully will
be really useful for you so this gives
you that item to item frequently bought
together recommendations type technology
that you see on the big ecommerce sites
but it does with your inventory with
your usage data so what I want to show
next is an example of this so M one of
the API is in our list here is the
recommendations API and this does like
say this frequently brought together so
people that bought this also bought this
item to item recommendation so this item
goes particularly well with that item
like this pair of jeans goes well with
that P shirt for example and it also
does personalized user recommendations
as well the way you use this is you have
a data set so I've got a data set here
with a load of books in it so the these
are books each book has an ID it has a
title they figure they're all the
category of book and then it's an extra
data here so as I've got author
publisher and the year the book was
published it's just a CSV file I've also
got another CSV file with some usage
data so this is basically user IDs and
book IDs so the first one is a user ID
the second one is the book ID so this is
telling me which users use which books
and using just those two bits of data
are able to build them a machine
learning model that that make those
associations of which books go together
and which books don't the way I do that
if I go to something called the
recommendations UI
I've already created the project there
the books project I've already uploaded
the catalog and my usage files and I
create something called a build what I
build is is basically way it takes all
of that data and comes up with the
recommendations models so again we come
up with a model here that I can test new
data with and what's important with this
one is you can have multiple builds so
in a real world scenario where you
actually if you've got any commerce
store this this stuff might change
according to season according to what
the weather's doing you might want to do
a new build of this every day because
your recommendations are going to change
every day based on what's going on in
the real world and the promotion's all
that kind of stuff so you can update new
builds and each build has this ID now
all I need to be able to call this is
the build ID the model ID for the actual
model that I'm going to use and and then
I just use the API reference to actually
call into it so and what I'm going to do
now is go to the API reference there's a
load of API for this one a lot of them
are to do with managing the build the
one that I'm interested in in terms of
actually getting recommendations this
one calls get items like an item
recommendations most of the API is in
cognitive services have a thing called
an API test console which is a little
web interface that you can literally
test the API with with your data with
your keys and all the rest of it so I'm
going to just put in some data here so
the model ID is this guy here
the items I'm going to look for I know I
got the item code for the line the witch
in the wardrobe so we're going to put
that in I'm going to say I want five
results back the minimum score I'm going
to set to zero the build ID I'm going to
set to this one here now you don't pass
a build idea we just use the app what's
called the active build which is the
most recent one and then finally I need
this subscription key as well which we
can get which is the same for any
cognitive service before that in this
end it's actually going to make the
request use my real data starts give me
a 200 ok and it said these are the
recommendations for that particular
title so Prince Caspian has got a 66%
recommendation horse and his boys got a
65% of accommodation and so on and so on
so you hope you can see that that's a
very useful data set now to finish this
off we've got an a website which again
you can you can look at this yourself if
you want to
HTTP recommendations API dollars your
website's I'm going to blog about this
too probably next week so if you follow
me on Twitter
you'll get a link to all of this stuff
and there's a github with this on as
well its recommendation he's probably so
this is just a very very simple against
asp.net because that's what I know but
it wouldn't have to be very simple site
using that same data set there's all the
book probably not probably don't do this
in terms of you I like having 2000 books
as bits of string on one page but I can
click into any of these books and it's
in again make that call to those two
api's and get me item to item
recommendations and also frequently
brought together so this one doesn't
have any frequently bought together so
let's click into a different one okay so
that one doesn't either
keep going to a finder on there we go so
so this book based on that data set and
that usage has got these these items
item recommendations and these
frequently brought together
recommendations all of them there's a
simple API call I've got the model based
on my own data and and then some cool
stuff of stuff so just to wrap this up
I've seen you a lot of silly demos now
this is a video of something a guy at
Microsoft who's visually impaired he's
been blind since the age of seven and
he's used this to build
some some really useful applications
that kind of make his life better and
that's just some quick videos all about
I don't like stop ten years ago as a
regular I not making things which
improve people's life and one of the
things employees Gravatar some time
where they deserve these was the idea of
something tell you that I would
I think it's a man jumping in the air to
the country on a skateboard
my teachers 126 days to make that which
lets the view and what surrender in
based on top of the Microsoft
intelligence APR which makes authorities
can make this kind of thing the after
arms are smart friends but also on the
predicates smart classes when you're
talking to a bigger someone together
talking talking they're responsive
things is everyone listening really well
or are they half asleep and he never
left I CQ famous 40 years old men to be
really surprised 20 year old woman
looking happy we have to describe we
general age and general inner area of
the relations are which is credible one
thing that's messy so that the active
ability to read our text
I can use the Allen County takes picture
of the baby and it's gonna join me on
1/2 Sigma correct citation when Canara
to the bottom right and away from the
document and then they'll break make the
text be better I see an appetizer salad
honey me pizza years ago it was science
fiction I never thought it would be
something that you could actually do the
artificial intelligence did it remain
active in the pasture right let me try
to see where we play today at this day
with always standing on the shoulders of
giants build a bit of a forward before
I'm in this case you've taken years of
research on Microsoft leaders to pull
this off I think it's the end girl
throwing an orange filly in the park for
me into maintaining that far-off dream
and building it one step at a time I
think this is just the beginning so
there we go so that's quite a nice
example of you know we've looked at
twins or not and all these silly
examples that's actually a real-world
example that's really making a
difference for the sake of their general
life there so thank you very much we've
covered a lot there and machine learning
in general what are some the principles
it's all about data is all about
patterns and data we've got to the
machine learning service which is the
software that we've got in the cloud
that helps you build those machine
learning experiments with your own data
and if you don't want to do any of that
stuff you just want to get some of the
benefits of machine then we've got the
cognitive services set there and there's
a bunch of API of a bunch of stuff that
you can then look at that
so thank you very much - Watson can and
you can treat me an email me if you go
to this URL at the bottom here you'll
get the slide to this and various other
links as well so feel free to contact me
I'm happy to take questions now but and
there we are over time so maybe tweet me
those and and also please do feed out
the did a little thing when you exit
their use of voting cards if you've got
detailed feedback please contact me was
this detailed enough was it too
technical is it not technically enough I
do this talk quite a lot so I'm happy to
adjust based on feedback I just seem to
love the color green I don't know what
it is but just seem to love the color
green there so thank you very much
thanks to your time and I'll be happy to
take any questions</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>