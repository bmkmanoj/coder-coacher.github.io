<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>How to build real-world applications with Orleans - John Azariah and Sergey Bykov | Coder Coacher - Coaching Coders</title><meta content="How to build real-world applications with Orleans - John Azariah and Sergey Bykov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>How to build real-world applications with Orleans - John Azariah and Sergey Bykov</b></h2><h5 class="post__date">2017-02-16</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/7OVU9Mqqzgs" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">you
anyone wanna do any form of distributed
application any form of application that
involves more than one user right I
think we colored the room right so
success what does that look like success
is when you can actually satisfy every
user that wants to use your system and
in some sense that's really the problem
we want to add we want to have the
problem of scale we won't add lots of
users and we want to successfully
satisfy the request that they put it
right what success is actually also
double it so because in many cases the
applications that we build when they
start getting successful land up falling
over because they're so popular and
scale is really both the friend we
wanted the party in the monster that we
want to display at the same time and
over the over the years we've had many
ways of trying to battle this problem
right so we've got rules of thumb
different platforms returning usually is
this tool of that just in writing cold
this don't don't follow this pattern
this is kind of the evolved sort of
knowledge that we've picked up over the
last few decades of how to build
scalable systems now we are still having
a problem you select college again solve
it and I think there's a way of actually
approaching the solution approaching the
scales problem a little differently
and that's kind of what we're gonna be
talking about over here my name is John
Ezra I work for Microsoft as a software
engineer in the LGI division and she'll
give work a fire for Microsoft as lead
of the project frantic down leads right
so we hear Darlene's always has now been
in in the wild for some time now it's an
open source project and all of that so a
fairly successful in the sense that halo
runs on it and we end up having quite a
bit of a scale issues
and we found that as we we go forward
you know we see this very simplistic
diagram it gives us an idea what what
the kind of issues that we solve that at
different levels so when you talk about
single cell type applications we tend to
write application particular way there
is going to be simple to try it simple
to read simple reason about but they
don't scale and then as you go up you
take different approaches going higher
and higher to different environments so
by the time we get to the point where
we're dealing with situations like halo
where you have to provide low latency
services across the globe a very highly
to speak the scale problems you're going
to solve over there are quite different
from the scale problems you have when
you have a single server so it also
means that the approach that we're
taking is going to be varied across the
spectrum also you think we'd like to
think that going forward we should
probably find a way to have the same way
of thinking and allow some other system
like the platform to be lifting for us
and in some sense that's kind of where
Orleans fits in so which are what it's
just me or everybody else but sometimes
I find it more difficult to explain
something simple than rather explain
some complex concepts I know that
engineering the brain is wired this way
that's easy to explain complexities and
distill it down to something very basic
so I'll try it here so there are
different opinions of the
object-oriented programming right but I
think the truth is that probably 90% of
software is done this way so the essence
of object oriented the right
object-oriented approach is that you
have encapsulation of entities in
objects incapsulate their state and
their behavior so they expose
functionalities or inner cases
and the process income in the request we
method calls a yield hold the reference
to the object is maybe call some factory
class get the references object make a
call and if there is some exceptional
case you know to put try catch and
handle it I'm not going to get into
argument with the functional people and
this is the reality of how most people
write code this is all possible and very
simple very straightforward when the
iran is a single process of the single
machine single server application
because you have access to memory it's a
shared memory space we can have direct
memory references which underneath the
covers is a pointer so this nice model
breaks down when we go beyond the
machine the single server no matter how
DC machine you put has limited capacity
in terms of CPU memory throughput so the
moment we go into multiple machines we
don't have access to direct direct
access to memory another machine we
cannot have the reference to an object
on difference or we cannot easily
coordinate and decide what to do
so what we've been told and what we've
been doing is switch the stateless model
it's going to forget all we've been
doing all these nice object references
method calls now we do differently so to
request the rights to the server it
usually goes to storage to fetch data
for whatever item the request is
concerned with it may be a user profile
it may be shopping car that may be
inventory item order doesn't matter we
need to go and read the state because we
cannot have it in memory and every
server so we're in the state and if it's
read request just return it like for
example give me user address if it's the
right request if we need to apply a
change for example update user address
then we try to write it to storage
try try it because in reality we
potentially competing with other
requests coming to other servers that
may be concerned with the same item for
example if you're trying to update
inventory on some popular inventory item
you may have requests been randomly
distributed across multiple servers they
all trying to update
say numbers inventory numbers on the
same item and that's not really a
pleasant thing to deal with so we lost
all the benefits of the object-oriented
programming we learn this new stuff and
it's inefficient in addition to that
because I process the requests I just
got this data from say sequel sorter
which is an expensive operation and I
throw the state away even though in the
next second I may receive requests for
the same item because it's popular so
it's very inefficient to go in storage
every time so if if I wanted to explain
Arlene's in five or six lines of code
it's really about this it's getting back
to object oriented view of the world
because that's how our brain
I believe works we see entities we see
interactions we have different levels of
abstractions so no liens you get back
interfaces and objects that we call
grades that implement those interfaces
and you get back method calls so an
object grain can hold the reference to
another object and make a call and that
just works if there is an exception so
if there is some error situation
unexpected situation on the kali side
you get an exception you can put
try-catch around it just like in a
single server code the difference is
that this code that looks very similar
to what we have before now transparently
run it can run on the cluster of servers
so you can ants on a single machine as
is no problem but if you add more
machines if you add more servers they
will automatically form a cluster and
this object can leave anywhere in the
cluster you don't have to really deal
with that you just program as if it's
still a single memory space but now it's
scalable and because this objects are
isolated they encapsulate their state
and we don't see any physical address
here we can easily scale out we add more
hardware we linearly get higher
throughput so in fact this model has
even more benefits than the original
model in the original model if you shut
down the application all your references
a lot because the physical reference
remember
in this case we have logical references
that none of the covers gets resolved so
we can save these references to storage
read them a month later and those still
work so in fact I would argue this model
even more powerful than the traditional
one and there's this interesting
conundrum when there is something is
that simple that our gut reaction as
engineers is that if it's simple it's
probably too good to be true and I've
seen this reaction like for years when
we started we started showing in work
the initial reaction was this probably
toy because it's something like you
writing a few lines of code and the
scales in the works and it's performant
you fooling me somewhere that was kind
of explicitly or implicitly stated
response but like John mentioned we've
proven that by writing very demanding
workloads like anybody who knows what or
least knows what hello because they were
the first Markey customer dear on
services for tens of millions of users
and hundreds of thousands requests per
second a process so it cannot be joy if
it runs that way at that scale and we
have properties like sky 4 or ash or
some services in Azure trying it at a
very good scale so it's not a toy so it
is kind of something that takes time for
for engineers to get to believe that
it's actually true
because of the simplicity but it's
simple and it's very basic but it
enables a number of scenarios the number
of patterns on top of it and that's what
we're mostly going to be talking about
different patterns that emerged over the
years because at least been used in
production for more than five years now
and it's been available outside of
Microsoft for about three years it was
open source two years ago so what I
notice that once developers go with a
hump of disbelief and see ok this
actually works to get the other
sometimes go to the other direction and
they so enthusiastic they don't apply it
everywhere and sometimes that's you kind
of curb their enthusiasm saying well you
probably don't want to put this code
onto your mobile device because we
didn't care about power efficiency
that's not the good place
but with the simplicity and ability to
create many different pattern generators
enthusiasm but what actually you get
from it is you have to write less code
by some conservative estimate so we've
seen it's like three times in some cases
five times some people claim ten times
less code and it's simpler code because
you get things like single thread
guarantees and done the entrance fee by
default so you write less and simpler
code so you get developed for the Qt
same developer can produce a lot more
functionality and focus on actual the
main problems not on the plumbing on
sending messages on handling machine
failures and things like that and as I
mentioned it scales by default because
of the model because this objects can be
isolated that is message passing on the
colors so the model is simple there is
this complex machinery under the covers
and all these runtimes it enables it but
the program model is kind of scary
sometimes simple so this kind of
December already covered so we open
source the project two years ago and it
created it attracted interesting set of
people so it's the interesting community
of people all around the world it's one
of the probably friendly is the most
Vulcan economy that's what we're hearing
that these people are so so awesome just
you kind of spend time virtually and
make it a chat so we did they keep
producing features and give feedback and
seeks bugs and do a lot of good stuff
but we never actually look at the number
so we've never really cared or had time
to look at the github and then enough
known this guy Matt Warren he few weeks
ago ran this analysis across all repos
in that net foundation organization for
the last two years and now a nice
surprise to our so these came up at the
topic number two on issues number one on
pull requests in terms of percentage of
contribution by the community GT me it's
a sign of very healthy community and
then very good progress I think we
strike good balance there because there
is constant investment from the
corporate side which is given by
internal priorities and our
collaboration with Mike
research and steady stream of
contributions ideas implementations
extensions from the community so the
case is healthy balance of kind of on
both sides so now we'll actually look to
wish to the patterns that yes I'm sorry
Thanks so so let Circuit pointed out the
whole idea of the traditional way of
looking at objects you know back and
cs101 when they introduced objects to
you and you started talking about
encapsulation abstraction the ability to
hype data and provide controlled access
to modify it so on and so forth that
benefit kind of went away when we went
to the stateless world we try and
reclaim it and bring it back so what
exactly are we trying to do if you look
at a single object there are three kind
of key pieces in you know in the object
Italy attributes of the object of your
life specs of the object that you want
to think about of course there's the
initial piece which is the encapsulation
part of it right we hide data and we
allow controlled access to it but the
objects are basically centered around
some form of data so you can store later
and there there's an object piece and
then of course there's operations on the
data and the object allows you to sort
of make sure that all the related
operations on the data are present in
the same place and so there's and then
there's communication between objects
over objects a can talk to object B by
by budging method call and that's so if
you look at the structure of an object
the three facets to it is the state
Placid which could be a passive the
communication pattern taking modeling
and applying the object-oriented
paradigm you will find that there are
several applications and still get
pointed out that have been developed and
one of the things we notice when we look
at the kind of application that are
developed is that their patterns that
emerge from each of the different
conferences so there are data centric
patterns that you can apply
there's compute centric patterns that
keep in place and there is a class of
letters that come from the fact that
objects can communicate with each other
so I'll talk about the state centric
ones first the first and most basic
thing that you can do with a piece of
data is to store it and Orlean allows
you to basically encapsulate a piece of
data in a green give it an address a way
of identifying it persistently over time
and store it somewhere this is quite
useful and for example if you want to
write Facebook and you want to have a
profile per user that profile is kind of
an object it has an address which is
some form of the user's name and you
want to be able to store it and retrieve
it so a common pattern would be to
create an object for that profile and
effectively use the or means going to
search so one of the things we've done
is we've been able to come up with a
commonly used set of patterns and pieces
of code that you can just download as a
library and you'll get that for free at
this point please because we haven't
really talked about Orleans in some
detail how it actually works I'm going
to talk a little bit about what it means
to store an object normally right so if
you think about a persistent object you
have some model you have some amount of
working space memory spaces then you
have a whole bunch of disk space
somewhere database so as your storage or
whatever it is some persistent storage
in some working memory so the way all
these works is you never a new up
anything you ask a factory to give you a
reference to this grain which could
basically live somewhere else but you
get a reference to it locally and what
that means is that grains effectively
are eternal they always exist because if
if you don't if the system doesn't have
a grain with that address already it'll
create it when you ask for it and it
will store storage where you tell it to
store it
so the lifecycle of grain kind of looks
like this either see you have persisted
or it's not non-existent when you ask
for it we will the system will activate
it and give you an active version of it
so that the point where the grain is
active there's a machine somewhere in
the cluster that has this thing in
memory with an address on it that you
can actually talk to it it and so when
you call use it or do something what
actually is happening is a call is being
made that machine with the message being
sent to go and do something with those
arguments and then you await on that and
you get by the response so you have
persisted grains that are effectively in
cold storage and you can have no limit
to them so it's not like it's not like a
toy database or anything of that you can
literally have terabytes of grains lying
around you activate the ones you need
and the system takes care of bring it
into being and giving you a reference to
it it becomes active in memory and when
you stop using it for some time and the
system decides that you know long ways
there is no longer needs to keep the day
in memory it will be activated and put
it back into storage for you so in some
sense it's like virtual memory but
virtual memory across a cluster hilarity
might be you don't really care which
speak of RAM in your machine has the
memory that a single object lives in you
don't care about that there's something
that labs like wait at a higher level or
liens abstracts away which machine in
the cluster has this object that you're
talking to you just deal with it as if
it was always this right so pattern like
that fairly straightforward to use so
let's assume that we were writing some
form of the e-commerce thing and this is
the object I want to store and I create
one of these things and make it
serializable and then we have this
cached item grain like a set of grain
improve interfaces that are already
available that you can just leverage
and what that they give you two methods
on it once within an item and the other
one is to set it and effectively this is
how you'd use it can I do and see the
scold is it too small no I'll just give
you an idea the first four lines the big
block is basically just creating the
grain state itself that's that's the
instance of the object I want to store
the data that I want to store and I try
to get the grain and then set it and I'm
done and when I want to read it I just
asked for it by ID and it's blaze so
effectively this way of doing it means
that I don't have to write any ordinance
left behind if the stuff even the even
the interaction with your lean systems
abstract away by the pattern which is
kind of useful if that is so popular
that it is it more or less become
something that you can use right out of
the library itself another thing that
might be useful is to keep track of a
set of grains so in the case of an
e-commerce thing say you wanted to get
you know you're running a shoe shop and
you've got different models so you have
a grain associated with this model and
it keeps like how many Abbie's you have
but then you also want to keep track of
all the shoes that belong to children
all the tools that are for women and all
the shoes they're for men and in some
sense it's a registry of grades and when
you want to keep track of a bunch of
items that are of the same type you can
use the registry pattern again the the
code I'm showing you here is actually
the stuff in the library is already one
there you can just call it a registry
grain and use it effectively the same
way if you look at what's happening over
here the grain that we first start with
is a standard it's an object storage
brain and that one is being registered
with something else so effectively the
state of the second grain is actually
the list of grains that it needs to keep
track of and it doesn't mean that you
have to only interact with the
registered
Green's through the greens and through
the register evening you can actually
interact directly in the grain itself
which is kind of useful if you think
about the orange that you've dealt with
in the past when you get back a set of
things from the database you can't
really interact the individual objects
themselves and expect them to persist or
have a life cycle of their own you
effectively get something as a result of
a query that is equivalent to the
register claim but additionally every
row that you would have gotten back is
equivalent to a grain that lives by
itself and has its own way of managing
so you can talk to the grain independent
layer of the registry both these these
patterns together allow you to set up
groups of things that you want to keep
track of and one of the places where
that becomes very very useful is in a
caching layer so having a system like
memcache D allows you to keep a bunch of
cash items in memory right in many cases
we can do similar things with our means
and in fact there's a whole pattern of a
smart case that that still gets my talk
about so first why do we need caching so
we need for caching comes from the same
challenge I talked about a few minutes
ago because we're stateless when we go
to storage the storage has a limit in
capacity and go in there to read that
for when you have a lot of read requests
go into storage every time is indecision
when you have high scale as your storage
cannot keep up or it's very expensive so
of course we put cache layer like
memcache de or Redis in front so that we
read input data in cache and then we
leverage data toting in memory it all
sounds nice except for now we need to
talk to two storage systems very
different semantics and give them very
different characteristics whenever there
is a right we need to write the cold
storage like this clickable database or
key value store and we also need to
either update or invalidate cache
because we've just changed value
and there's this a famous saying that
there are two hardest problem in
distributed systems it's naming things
and cache invalidation this is not an
easy thing to do to coordinate a little
richer and outdated data but also either
on the separate layer so you need to
deploy a cluster of memcache de or
reddish and or use separate service and
which may not be as obvious you moving
data between machines so your data is in
memory which is great but then you send
it over the network to another set of
machines for each operation so it's much
better than going to storage but still
sending data over the wire so the Lynch
rinse approach is very simple there's
really no approach because by itself
grains our initial cache when grain gets
activated it state gets loaded from
storage and it just naturally cached in
memory there is no separate statement or
effort at the line of codes right it's
only cache there so we eliminate the
need for extra layer next week here
right away but we also get more benefits
unlike in say memcache D with key value
based cache where I just write some
bytes of data or strings here we have
semantic operations so when request
arrives to update user address it may
arrive as a move with new address and I
can the process that way or there's a
community operation one which could
change in the last name of the person so
this operations can be expressed in
natural way instead of just saying
overwrite whatever we have there with
these bytes of data of the string so
that's good you have semantic operations
but also now we're shipping functions so
we never request the rise we don't move
data we don't send data over the wire
data sits in the membrane the machine
and the function to request the right to
to that piece of data that piece of
state and actually this is the most
popular pattern
altogether I think over all the
applications we've seen so there are
different variations the simplest is
read-only so when we need to serve video
files any files any kind of items
catalog items or descriptions data that
kind of never changes
it's immutable we just cash it in memory
it's very easy so grain gets activated
lo it states once there's only one
round-trip to storage and after that you
can serve this data as long as you want
until that item becomes cold and if it's
not used for extended period of time and
doesn't exactly keep it in memory we can
remove it from memory and next time
there is a request for it will activate
it again and do another round trip to
storage the most popular one is right
through so in addition to read the mail
you see right and because right go
through the grain they don't go directly
to storage and doesn't go to two places
like storage and cache you go to this
grain which has data in memory and then
grain rice into storage you have this
very important property that your right
to serialize they would never compete
with each other you eliminate this
situation when two servers can dry to a
single line and storage like and in
table and again you get semantic
operations all I can is with normal rice
and you would think that your Eliza's
right may not be a big deal because you
have protection you have each arc
support and in most modern storage
systems but in fact that may be very
significant performance books a couple
of years ago maybe three years ago some
people in Skype create a service which
was probably like a hundred lines maybe
200 lines of code
because it's very simple very trivial a
grain class but all it did receive
telemetry which is routed to specific
identity so all rights to a single line
in storage was they all were going
through a single grade which eliminated
all right conflicts very simple
application but because of that because
of elimination of storage conflicts
right conflicts they received four times
throughput improvements or if you flip
it around they reduce their cost by four
times which is merely eliminating a
contention on storage so even simpler
parents can pay back pretty well on if
if you don't have to write necessarily
every item reliable the storage
for example you are writing a
performance information performance
counters and you can afford to lose some
of the readings like once in the blue
moon
or you login there is then you can batch
your rights in this case you can write
behind you can receive requests but
don't write them immediately your
storage you can accumulate either a
number of them or for theories of time
and then right from the grain it's very
easy to implement because there is
support for timers you can set timer for
every minute or count number a lot days
or combination of both any code is
simple because you don't do anything
special so there is if you use
declarative persistence here you have a
state object you can declare separate
interfaces for reader and writer so you
can give retention case or grained
reference that implements the redundant
case to the reader and different one to
write or you can combine them and give
it to some other entity in the system so
you can do all the same except eration
of concerns and this is kind of trivial
example we get a reference for
particular industries reader alright and
then you do either operation define an
interface and when you implemented it's
that simple because you have your state
object and then user updated or
recurrent and when you update you just
call this base class method to write
state storage and there's persistent
provider the kind of plug-in system
there so you can do that this is the
built-in default but it operates with
declarative persistence but you can
write any code you like
what's important here from
from a performance perspective it's
important to come partition you stay
yeah they gotta go yeah yeah
so basically if you have reasonable
persistence and you can pretty much just
use this out of the box and I'll move on
to the event sourcing one because this
is the one that seems to be the one that
causes a lot of confusion with people
and it's one of the living at the moment
persistence is you write whatever you
want to through the right all right
strategy
so grain is associated with the class
this is that is the kind of data that it
stores and you can actually use that to
right now Sergey mentioned semantic
operations which is actually just a
second mentioning semantic operations
which is kind of the same as sending
element to in order to declare what you
want to do love and mutating something
in things of it right so the concept for
example of updating somebody's home
address can be done using a semantic
operation saying update the address
which then becomes a kind of event that
you can log on the side saying I updated
the address with this now I doing that
you get a couple of interesting benefits
you for example keep track of all of the
things that mutate the object in an
immutable stores so you have an
append-only store so you have a list of
all the things that cause the object to
become what it was which is a different
from traditional relational stores where
you call update on something and because
you are updating that something you lose
to piece of information immediately and
you gain a problem the two piece of
information is losers why did this thing
change right what caused this change to
happen because all you're saving is the
fact that it's changed and the context
in which the change has happened lecture
so our changes apply and accumulate you
lost the history of the things that have
caused the change to take place
additionally because you are mutating an
existing object you have welcomed in
very unwelcome guests which is the issue
of concurrency you now have to do things
like do optimistic concurrency or some
form of strategy to make sure two people
aren't overwriting each other's changes
right
the third thing because also one way to
solve that problem is to basically keep
track of the intent of the change rather
than the change itself and we can do
that by storing that in a green - so
rather than just so when we have
semantic operations taking place we will
store the sequence of the operations
that took place apply those operations
to keep track of an aggregate which is
kind of the updated version if you want
to think of it that way but at any point
in time we could throw away the updated
version and replay all the events to get
to this state again so the important
piece is actually the sequence events
and you can then talk about is like
eventual consistency because you don't
have a concurrency problem there is no
even if two people try to make the
change and make changes at the same time
they will get serialized into a log and
you'll find that somebody change the
home address and somebody change their
phone number and they didn't collaborate
as exchanges they just get applied one
on top of the other so by doing this you
can vastly improve the architecture the
scalable architecture of your
application itself because you are not
now bound to some form of two-phase
commit atrocities to build system or
anything this you can actually just keep
pluggin eastery in this run with that
so with that model we actually have we
have a pattern that actually keeps track
of times x values and all you have to do
is provide the semantics
set of operations that you can apply to
the service so the tea event over there
is effectively equivalent to the set of
operations that you have such as you
know change address or change phone
number or change shipping address or
whatever it is that you want to do and
then this object the events of grain
will automatically keep track of the
history of the event and their flight
and then you can provide so let's give
an example before let's say that I have
a bank account name up there so that's
an eye bank account grain I can show the
account state which is the current
balance of the account and then I'm
going to call credit amount on it
but what happens neat colors on credit
amount is that that gets converted into
a message an object that can be stored
so rather than just update the value in
an in a standard object-oriented way we
create an object called credit amount
with that value store that and then
apply that object to the total to the
aggregate know what that's what will end
up happening is that the balance will
still get updated but you kept track of
the fact that you've updated you've now
created the amount of and run it or
whatever so all of the score by the way
is live code it's there on get up if you
get it down and play with it and it'll
actually you run it you'll actually see
the sequence of it going up to $100 and
then $50 and then a 150 dollars because
you credited debited and credited again
the value will continue to be a hardened
will be just as you expect it to be but
I will also be able to tell you first
you cuz it's me on our dollars then
debited 50 and then credited a another
50 on top of it so you I'm sorry so it
will go back to being on $2 right my
match is not great anyway
right so the other key thing is to
realize in this whole thing is that this
has all the hard work already done for
you so the library pattern that has this
thing already has even something built
in so all you have to do is provide
event and the other type arguments and
you're done you can actually just go
ahead and use it right right aggregates
so as we start looking at various
patterns one of the things that you'll
realize is that you can form bigger
patterns from littler ones and they
become patterns too so when we talk
about say for example objects tools
what's the first question you're going
to ask me and it is how do I keep track
of a total right so you're giving me all
of the stuff about the eventual
consistency and all of that how do I get
a report how do I get a set how do I get
a total of something and one way of
doing that is to keep track of the
things that is going to affect the
aggregate and then keep a registry of
your total always in place so an
aggregate basically allows you to bring
events from a whole sociality you have a
bunch of bank accounts you keep a
registry will keep you a bunch of bank
accounts and aggregate can listen to the
events from each of those grains so that
you can now keep a set of events that
come from all of the grains into the one
place so if you think about why total is
formed from us from a data set it's
effectively what you're doing you're
able to reduce across a whole bunch of
grains into the one thing and you
provide the function that does the
reducing in the aggregate grain and then
in a very general way you've solved the
idea
of being able to run a query but even
that terminology is wrong we don't run a
query anymore because running the query
assumes that the data is basically
useless the moment you finish cleaning
something may obtain this one is
actually going to aggregate and keep
qualifying it's a standing query every
time an event takes place you can
actually collect the event and then
apply the event the set of events to get
you the result that you want so you can
basically ask for an aggregate on demand
in which case you don't actually let the
event do anything other than say hey I
happen and then go away and then when
somebody's interested in the total
that's when you go and play all the
events together to get the total that
you want and then you can get it back or
you can do a title based thing I used to
in a past life work for an accounting
company end of day is always useful
because the end of day reports is what
you kind of need so I can quite easily
keep track of all the transactions that
took place during the day and at the end
of the day automatically computes a
transaction now if you think about that
that I think makes a lot of sense
because everything is immutable because
the events once they happen never change
so the reports that happen in the
aggregate as of a given time is also
immutable and so you can run it you know
very efficiently and never have to pay
the cost of running the same query query
twice and then of course you can have
any kind of strategy that you want to
actually bring the aggregation to pieces
so here's where you do the get aggregate
value and effectively you can see that
the functions at the bottom tell you how
to deal with the credit and a debit the
basic these lambdas they allow you to
plug in whatever functionality that you
want but all the plumbing associated
with keeping the grains in a single
registry getting the events to be
propagated to the aggregate Lane
and then applying all the events at the
time when you need them all of that
comes for you automatically
so Bank eyes are on the aggregate
balance will now keep track of a whole
bunch of bank accounts and be able to
apply the events as they come come to
the pipeline right so let's see right
this is actually an example of how this
would be used so this is actually the
internal structure of what the bank
account aggregate balance would be
because you have to provide me the fact
that there is a credit and a debit and
what is grab it in credit and debit mean
if you can provide that information from
here then I can let you write code like
this and then I'm going to create a
bunch of accounts right go to the
account grains I'm going to register
them all in the aggregate grain and then
take the first in accounts and credit
$100 to each of them and when I do that
I expect the B aggregate effectively
should be 10 times 100 so if I were
running a bank
it means 10 accounts I'd $100.00 32 then
I jolly will have $1000 somewhere I
should and then you can take it and add
another 100 and you'll get Banga at 200
at the end of it and effectively the
programming model if you notice it's
still very object oriented he says that
we've started composing more more
complex objects together to give us
quite useful functionality from that
point of view it should be said that you
can then go the aggregate grain and then
look at what caused the value to be $200
and it can report to you that it is that
way because these accounts have a $1
reach and then these are concise credit
$100 each over a period of time and
you'll get a timestamp list of all of
the things that you can work with so it
also means that you can build up totals
out-of-band you can delay building the
total until the end of day
it's all depends on your computational
strategy the other cool thing about
event sourcing which works out after
your system has been in place for some
time is that you can build aggregates on
data that you can build aggregates on
old data that weren't there when the
data was being formed so let's say that
I'm interested in new piece of
information when was a critic when when
do people most actively credit money I
could create a new aggregate that
actually filters everything and the same
time of day on them and then run it on
all the historical data and get back the
information I haven't lost anything from
that point of view and so the this event
sourcing approach is fully supported in
Orleans and it's as native as you can
expect any other form of books to be if
you think about that we have actually
kind of created a full-blown object
store I had we sold individual objects
and got them back we kept track of
groups of objects we were able to get
standing queries at up and we were able
to do event based semantics operation
tracking right and in many cases that's
pretty much what you use your database
for so if you squint a little you can
potentially get by quite a far way and
get rid of your separate relational
store by keeping a stateful set of
objects in memory and be able to handle
everything that you want in fact in the
roadmap is Sergey will point out future
of still spans on how the people in
Mike's of research that are actually
talking about putting transactions in
play for this so now when we want to do
up and and sending information across
it's not just let's just make one thing
happen we can actually give you a
guarantee that
all of these will happen or none will
happen at the same time at that point
you've actually converted this thing
into a kind of object database now
there's a whole bunch of baggage
associated with the place so let's not
go there the reality is that in in more
than one occasion it is entirely
possible to write a full-blown scalable
web application without using a database
at all just using the all names
middle-tier to keep track of just the
data side of things I think we've done a
little bit about data I was happy to
take questions but we can we also have
time for questions later I think we're
going to talk about the communication
side now we remember we talked about the
three different aspects of objects the
data storage piece is what we just
covered there's an patterns around
communication that Sylvia is going to
get into but if anyone has a question I
have to answer it now seems to me that
you multiplied the risk of a machine
dying and then all of a sudden you've
lost some some amounts of grains and how
does the system cope with that how does
a kiss' system cope with failure sure
let me repeat the question and I've been
eking analyst yeah so the question asked
was now that you've actually taken your
objects and put them on multiple
machines how do you deal with the fact
one of them may fail and take some of
the Greens video well this simple simple
the answer is grains never fail because
they're logical they have their state
persisted so if one machine blew up the
the released runtime will recognize it
remove that machine from the cluster and
reactivate grains are needed on other
machines and reload their state there
and because you've completely location
transparency don't only carry those
grains moved
a slightly higher latency when whenever
you're talking to those particular
grains that have now oh you know we're
living in memory on a machine that has
now died although we in memory another
machine and latency between machines is
under milliseconds so you will not see
any latency just think of it as the
cluster reconfigured and it keeps going
okay thanks can you your events say you
you Division you event and then you
would like to actually apply them to
your two grains can you do that sure I
mean it said red and green is just an
extended version of a the standard event
right so you can potentially extend
these patterns however you want but
remember that none of the stuff if we
are talking about building patterns to
make stuff useful the primitives that
we're talking about are effectively
object-oriented programming so they'll
be coming back to the same thing if you
can do it with an object somewhere we
can do it is all names and usually with
not much more difficulty so the
versioning is exactly the same story you
think you can revise you write the
history basically on the grain if you
want to here
you can sorry yeah so the next pattern
is the object graph so it's kind of
tattered and not at the same time when
people hear about graphs they think
about graph databases immediately or
what face book was the graph of whatever
billion plus users but in reality a lot
of things are like graphs so like in the
gaming example you have this players
that form a short term relations you're
in the game session when they
participate in the same game and then
the game ends those relations end but
they also have long term relations if
they're part of a clan or a friends so
you can communicate that way as well for
example they chat with each other
send messages invites to each other and
so
for that inner lease you don't even need
a pattern because you can have these
references you can hold them you can
store them which you cannot do with
objects and have just lists of your
prints faith and database and anytime
you need to send the message you just
make a call if that grain is not a
memory will be activated but it's a look
at this picture it's intentionally the
same but instead of gaming there is IOT
scenario here
53 devices and rooms and control objects
or something else for example the
popular pattern is with tracking
vehicles you divide your geographic area
into trials as vehicle moves and reports
its position of a cellphone reports its
position this vehicle grain or avatar
that gets updated with position and can
we register itself with different tiles
as that moves on so we need to send
notification to all the grains where
they put all vehicles in a particular
tile just need to talk about tile grain
like would aggregate pattern or with
registry patterns say they update all
this vehicles in the reverse was also
possible you can analyze data inquiry it
across the geographic hotels for traffic
optimizations they think that but the
program model is exactly the same to use
references into the dynamic relations
that you establish for a short term or
long term that's what it's about so
we'll go through streaming quickly so we
introduced a lean streaming about two
years ago and assuming is a very
overloaded term including video streams
and data streams and Kafka in Arlene's
what she means is the logical
obstruction of a named entity so just
like grains have identity unique
identity genes early in streams have
identities and how long do you know the
identity of a stream you can always
either produce in Malaysia the stream or
subscribe to consume messages from the
stream so they kind of always exist just
like grains at the logical level but
physically they're multiplexed over some
physical cues usually
for example if you have hundreds of
millions of users with individual /
users genes you will have a hard time
finding a streaming and queueing
solution I would support hundreds of
millions of individual cues but they get
automatically as logical streams
multiplex / physical cue so you may
multiple like this 300 million users or
work say a thousand queues because your
events are infrequent per user and it's
a matter of event frequency and then
this logical seems they can easily be
mapped to grains that are interested in
processing them and the mapping can be
done either through explicit
subscription say I'm interested in
events on the stream with this idea or
even implicitly like in this example by
merely putting an attribute implicit
subscription I'm declaring that grains
of that class whose identity matches to
the stream identity within the namespace
device alerts they should automatically
receive events of those streams so by
just putting that you eliminate the need
and we need to install a handler pointer
to a method to handle the message and
those stream messages are delivered to
the same exact mechanism just like
method invocation so in terms of writing
code and implementing grain and handles
messages delivered through one and more
streams it's the same as processing and
eppley an ethical their various
scenarios for that this enables one that
I wanted to point out the key detection
in gaming tears can be very poisonous if
you find somebody who misbehaves or find
a way to exploit the system you want to
shut them down as soon as possible it
then temporarily or forever so it
automatically detected somebody is doing
that for example if somebody exited
multiplayer again more than five times
over the course of 10 minutes that's a
sign of a cheating one pattern but
interested enough another customer Allah
leans was using game patterns for
detecting credit card fraud transactions
because you receive the dancer and you
look for patterns if somebody did a
couple of gas-station transaction and
then once your shoe store that
suspicious
are interested in the us that they block
the cars immediately so by subscribing
to enhance input in this logic and very
simple pattern matching you can do it
the most advanced state the most
advanced pattern is a state machine
pattern and actually we're not going to
talk about it today in this talk but
later today John will be talking about
just that pattern in one and the tooling
he created for it so they can define the
state machine within the grain with a
simple declarative definition of a state
machine so it's going to be very
interesting talk I promise you we didn't
talk much about the cross-cutting
benefits of our lives but it's worth
mentioning them because because the
questions of what happens in case of a
failure naturally emerge or liens
candles all of that so it handles the
cluster state and understands if
machines go down if Network partition
happens there is physical sending of
messages over the network to ping and
check that the machines are available
the messages to go through so it release
runtime by itself automatically detects
failures like if you have network cable
failure and will automatically readjust
so that grains will get recreated on the
machines that are still part of the
cluster one thing that is not
immediately obvious that the fact that
Arleen's deactivate grains that are not
no longer used actually that gives you
complete automatic resource management
so you just ask give me a reference to
grain with this idea give me a reference
to getting release ID and they get
activated automatically but you never
need to do anything to clean it up
because they get collected garbage
collected effectively at a specified
time you can say keep them in memory for
two hours or for five minutes you can
specify it by type and can even
programmatically tell so that eliminates
a lot of the concerns of resource
management and it's very efficient
quickly what is on the horizon we
published the end of the year the does
not tech review of dotnet core
compatible version
there's a lot of interest rying or liens
on Linux and docker and things like that
we recently enabled this very
interesting feature of support for do
distributed Multi cluster were in
addition to being able to run a single
cluster of servers like today you can
also run multiple clusters that are
logically combining to distribute do DC
with clusters are they aware of each
other so you keep the same probably
model of the single grain when a cluster
but now it can be anywhere within this
sort of constellation of clusters they
can deploy to multiple data centers for
availability or for latency so you can
have grains automatically activated near
the user were the requests are from the
user company so the Australian user
doesn't need to talk to Dennis and the
US can talk to Darren in Australia but
if that same user happened to travel to
in DC London
he's grain if he launches an application
we activated the news data center or
automatically routed to we also
continued collaboration when MSR
actually for the project adult lives
originated in Microsoft Research now
it's in the Prada group for a couple of
years but we continue to work on other
interesting extensions like for example
support for full asset transactions that
John mentioned indices so you could
query and say finally all the users with
such-and-such characteristics or in this
geographic code and some other
interesting stuff so we have links to
the resources here the code base which
is obviously on github we originally
started the blog we have this chat and
gather where the community leaves them
it's very nice to kind of look what
people are talking about and participate
we have a stage in repo Orleans can see
for things that are not ready yet but
kind of being incubated and as John
mentioned code so this talk is available
thank you very much
any question just come to us yes option
any questions
with little the time limit on the
knowledge itself yes
similarly to answer correctly that it if
you compare with akka streams that you
can define your process workflow and
then you can materialize it in a similar
way without explicitly getting your
grain so it will be created for you or
is it something else
it is kind of decouple there allows it
to be decoupled like for example your
ingestion layer that ingest data into
queues like in the event hub or so Azure
queues may have nothing to do with the
consumption cluster it doesn't even have
to be part of the cluster so you have
this because of the queues you have
separation of concerns on the processing
side you just define declaratively or
programmatically what streams logical
streams your your grains which should be
subscribed to and whatever data comes in
were either from grains of form or
leaves or from outside will get yet
process and this declares the
definitions they don't need to deal with
grains explicitly they sort of on a
function level or you need to do some
grain processing but they're done on the
grain like a class definition layer if
you use implicit subscription so it
Eclair this class needs to be subscribed
to such as such stream namespaces check
in to that but it can also be very
explicit thank you I think we should
take it offline now it just just comes
out because come talk to us is very
available also please come to the 540
talk because it's really all about the
whole state machine problem and we'll
talk about how to write safe scalable
access that embody state machines and in
the cloud thank you yes
hmm</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>