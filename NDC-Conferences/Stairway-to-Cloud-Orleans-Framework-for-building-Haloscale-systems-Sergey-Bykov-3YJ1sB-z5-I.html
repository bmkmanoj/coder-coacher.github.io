<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Stairway to Cloud: Orleans Framework for building Halo-scale systems - Sergey Bykov | Coder Coacher - Coaching Coders</title><meta content="Stairway to Cloud: Orleans Framework for building Halo-scale systems - Sergey Bykov - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Stairway to Cloud: Orleans Framework for building Halo-scale systems - Sergey Bykov</b></h2><h5 class="post__date">2016-10-25</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/3YJ1sB-z5-I" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">so welcome my name is Serge Ibaka from
I'm dev lead at Microsoft they're
working in this project for many years
first in Microsoft research now in Prada
group so it's very dear to my heart and
welcome from rainy Seattle to sunny city
as I was thinking that most of the
people here will be from Australia New
Zealand I was thinking maybe I should
change the title and look at this tweet
at some point then I decided to keep it
as is otherwise the message may not be
as positive so when we talk about halo
scale I didn't want to explain it so I
thought I would cheat and just play
media wear hoops so more is playing so
much better than I can
so let's wake you up and I'm gonna cover
that piece
halo is a rich immersive story with
millions of loyal and dedicated fans we
deliver an exciting and engaging
experience to these fans they need to
know what the hot playlist is today they
need to know what the challenges are
they need to know where their friends
have been what their friends have been
playing have their friends got more
medals than them they need to know all
of this and they need to react to it to
interact with their friends in real time
we need to deliver harness to the
thousands of updates per second to
millions of players across the Halo
universe we need to get in the right
information at the right device at the
right time
there was nothing off the shelf that
solved the problems we needed to solve
at the scale meaning to dissolve so we
need turned to Microsoft's extreme
computing hundreds of thousands of
requests per second across thousands of
servers in real time these guys are
crazy
but in the stream computing those are
the kind of challenges will like to
tackle yeah we made this video couple
years ago when I was still in Microsoft
Research and you can tell by a lot of
hair I had that teenager keeps teasing
me um so I like it because whoo packing
in two minutes explains what the scale
challenges they had to deal with and and
that's how the collaboration started and
right now hoop is actually technology
advisor to the CEO of the company is
such an Adela please brilliant guy um so
we're gonna be talking about the cloud
but we're also gonna be playing named it
you in game who knows name the tune okay
so if you see sentence and quotes in in
a part it's right corner if you know the
song is from our or who played it just
yell and you'll get a point and whoever
gets more points we get a prize the beer
at the party so anybody knows just the
power to charm David Bowie okay I win
the point so the cloud right that's what
we're all talking about and people have
different definitions and and whatnot
but really it's about this power of
renting hardware at will so these power
resources used to be available only to
big corporations multi-billion dollar
corporations or two governments now are
available to everyone so long as you
have a credit card and
limit their you can just rent infinite
amount of resources so it's great power
that is available to us but with great
power as they say comes great
responsibility so we started seeing all
these challenges how do you program for
for this powerful platform so you have
to distribute your computations you have
to deal with concurrency at that scale
and and who enjoys debugging
multi-threaded data rates code anybody
okay there's some people like that's how
Aaron you enjoy it I don't so when you
extend this problem into debugging
across a set of machines where you can
actually debug there you get a look at
the bunch of logs and trying to figure
out what happened it's not supposed to
happen it's impossible that's kind of
our normal state of is engineers we're
gonna this isn't impossible and I'm
trying to figure this out but also with
the scale failures have just happened
routinely what used to be a rare
occasion now the Machine decided to
reboot order it as far as hardware
failure or your cloud providers I did is
something things happen and your code
needs to work correctly but those
expectations have changed so we're not
now when I see that banker and I log
into my bank and trying to look
something up and it says we're down for
maintenance this is very rare now like
it's it's very strange
I'm get frustrated it used to be the
norm every Saturday they just shut it
down and say anymore down for
maintenance
now people expand expect that your
services your application that available
24 hours seven days a week 365 days a
year and so we we deal with challenges
how to build this kind of systems that
the resilient powerful scalable and and
this is where businesses hear the
cacophony of messages from various
consultants and analysts and they give
all these stories trying to sell you on
something so like my favorite example is
PHP my sequel and say Facebook was built
with PHP in sequel in my sequel that
means you can build anything like
there's a solution just use PHP and
simple soap was a similar solution
before where we just build web services
on so protocol and everything this
brilliantly works so they keep coming up
with new solutions that go right is the
new things language docker was really go
everyone is right and go
and of course as you experience a
generous no never there is a solution
that solves everything so they're trying
to sell you on this elevator to the
cloud called wonkavator if you watched
Willy Wonka and the Chocolate Factory
this is a pin out button so you just
push the button you're up in the cloud
it's magic wonkavator but here it's like
oh you need to be stateless and some
money savings and people make and some
observations that the good term micro
sources get abused so fast that
everything is micro sources now unless
you do micro services nothing will work
and this is my favorite one from 2010
when you major fully wrote that the
release will be a solution for all cloud
problems I always thank Mary Jo they see
this quote you look at this but then you
see this picture who has heard the calc
is Barry talk--i Jepsen told me maybe ok
almost nobody I would encourage you go
to youtube search for Kyle's start it's
a brilliant talk brilliant guy who took
a beefy machine in his apartment he do
not run a bunch of DMS and took
commercially available open source
databases and then cash systems like
elasticsearch MongoDB and show that in
certain conditions when you start
cutting artificially and network
connections between these virtual
machines they really don't deliver the
getting his acclaim they deliver
so he started posting this blog post
called me me about this technology in
that technology and suddenly this single
guy became very famous in leadership in
systems community because he showed that
look this is the proof that new
technology doesn't do what to do and
people had different reactions to that
so yeah this picture were at the top you
have this brain beause of the API is
everything is fine there you have
rainbows and unicorns but underneath a
look under you see the tire fire that
the databases storage layer nothing
really works the way you expect the way
you promised so this is the challenge of
the businesses of CIOs of CEOs of how to
deal with this complexity all that
Google it Carol all that gluten is gold
anybody knows you know points yes
thank you all drink beer together so
this is how I look at it so this magic
triangle fill it up
they have compute and concerns state
concerns and connectivity concerns there
is trade-offs so who are you what have
you sacrificed baby knows from Jesus
Christ Superstar so the point is to get
something you need to sacrifice
something you have this cap theorem that
sort of reigns over the whole picture
it's also it tells you when you do any
distributed systems we have network
partitions guaranteed either real
network partitions or or GC collections
and machines rebooted you'll have
partitions and you cannot get
consistency and availability at the same
time so you have to choose and you have
to make all this trade-offs as you build
in the system that's the reality so how
do we deal with this this is one way so
your hire would call hero developers or
in Microsoft and FD we used to call them
Einstein level developers in this
taxonomy so these people can't solve
this problem somebody built Google
somebody built Facebook so I'm
rebuilding being an MSN and Skype all
the systems it is possible to build you
can write C++ code to make it work but
if you try to hide his developers and
realistically I think you have a problem
a cool nose Erlang in the audience who
used or lank never okay Errin scowl up a
little bit okay
couple of people I F sharp more still a
minority right so all these here
developers they're great I have utmost
respect today their knowledge of these
technologies the ability to build system
but if you look at from the business
perspective you try to hire these people
they all happily employed the old
solving very interesting hard problems
they're well compensated for that and if
you start a company trying to hire all
Ohio developers you either run out of
budget or you just won't be able to
attract them to your company that's the
reality but even these people make
mistakes if you look at history of
properties like Facebook or LinkedIn
Twitter use
that they really ejected their system
three four times as the load grows as
the popularity grew and we are detected
not just refactor not just kind of patch
it they had to rip and replace
everything it's very risky so your
business is growing user base multiplies
and you have to go and ripple and plays
the whole thing it's a very dangerous
even with hearing developers that's a
risky proposition but business people
look at it this way they need time to
market you need return on investment and
they can see the cost those are capex
and OPEX what's gonna cost me what did I
get for this that's why I thought about
stay away as the real practical analogy
what we need we don't need a wonkavator
with popping out button we don't want to
climb the ropes like the heroes can we
need something that is practical and
usable by very mobile sites like
ourselves and that's what this business
requirements see translated into
developer productivity and linear
scalability that if your business grows
you expenses girl linearly ideally
subliminally but it was literally not
faster than your user base need to be
efficient at the scale because if you
spent 2 times more power cycles you
spend 2 minus 2 times more money for
that and like this quote from Alice in
Wonderland and it says it takes all the
rain you can do to keep in the same
place if you want to get somewhere else
you need to run at least twice as fast
because this analogy is you're in
competition other companies running as
you walk in they may be running so if
you walk in one day iran you'll lose the
competition so you have to move fast you
have to be cheap you have to be
efficient you have this humming and in
one go but he knows this is how we've
been building services and websites for
I guess almost two decades now this
picture should be familiar to everyone
like three-tier ante architecture right
so you have stateless front ends that
terminate client connections they they
do HTTP termination they do admission
control they do
DDoS protection syndication all of that
and then
forward request in the middle tier can
be single layer multiple layers doesn't
matter your middle tier also stateless
and then you have storage were actual
data leaves so request arrives it's
beautiful model very simple you can add
servers and scales easily request
arrives it goes to storage say give me
his user profile apply an update user
profile right back to storage great
they're easy to reason about very easy
to build until you run out of your
storage capacity because storage
especially databases lexical Oracle they
have limited throughput so at some point
he overwhelmed the storage by going to
it for every single transaction all
solution was for we now put cash in the
middle like Redis memcache D so instead
of going to storage you go there only
first time then you put data into your
cache layer and then when you need the
operation to perform an operation on
data you get it from a cache not from
storage brilliant third would multiplies
easily the problem now is that you
dealing with two storages they have cold
storage the real source of truth and
they have cache and whenever you do an
update you need to update your cold
storage in updated cache or invalidate
the cache and I think there's this
famous saying that there are two hard
problems in these pivot systems the
naming and cache invalidation so you get
a solution that solves one part of the
problem but introducing another you lose
all semantic guarantees or which is
actual guarantees of your storage like a
single database that you lose together
this performance without the fire Queen
I keep main points
so I would argue that we want to put the
stateful middle tier in the middle so
instead of having this stateless middle
tier and cash later we want to combine
them and glue together and have it
managed it is one and the same we could
be so good together nobody else the
doors this is how we approach it so we
started building the middle tier and who
knows about the actor model okay it's
good it's about half the people if not
more excellent for those who don't know
actors think of them as isolated
distributed objects there is objects
that do not share state they don't allow
to touch the state directly instead they
receive messages they can send messages
to other actors so actors can talk to
other actors to messages and they can
create other actors in the system it was
invented in 1973 by Carl Hewitt and his
colleagues and the context was very
different at the time the context was
they needed the concurrency control
model for AEI to simulate this energies
interacting with each other in the
complex in complex way it was purely
concurrency control for a single machine
in the 70s didn't have the cloud do you
have clusters but interestingly it got
rediscovered in the late 80s I believe
early 90s at their exam it was
implemented Erlang and that's where what
sort of popularized active model that
people start using Erlang to control
Ericsson the user to control a telco
equipment have a backplane management
back playing for it but if you think of
it in the cloud case it's the XML has a
very same property because if actors
talk to each other through messages they
don't really care if they're on the same
machine the same process or on two
different machines so it makes it very
easy to distribute them and still have
exchanged messages to give the same
model with isolation with the tight
control encapsulation state but now you
can put them in a distributed setting
and you probably know like what's up was
written at the back end of what suppose
being in or like for this very reason
it's very efficient and very easy to
scale
so we used if the actor model is the
base for for leans but here's what we
had his goals when we started the
release project so we wanted to have a
program model that is called natively
easier than what we have today not just
improved developer activity by 10% 20%
30% but try to improve by 3x 5x ideally
10x that was the goal but the same time
we didn't want it to be kind of
simplistic that expert developers
experience as you say no it's it's too
simple I cannot use it because it limits
me so it needs to be simple yet flexible
and powerful that was on the programming
model side and the only way we knew how
to make developers more productive is
that you make them write less code it's
really the best code you can write is
the code you don't write paradoxically
because that the code that doesn't have
bugs right the more code we write the
more work we need to do the more we need
to maintain and box to eliminate on the
code so if we can qualitatively reduce
the amount of code engineers write
without constrain them entirely into
like toy model we do you want to say we
didn't want people to say this is the VB
for the cloud there was another goal
even though I have nothing against VP
it's a good thing well this conversation
people have so at the same time we want
it to be scalable both by default and by
that means like learning from the
experience of the successful properties
when they grow their business and they
have to rip and replace when have the
model where you billet wants and kind of
works even if your business grows by 10x
100x and nearly a thousand x you may
need to tweak a few things may need to
change some of the pieces but you should
need to throw away and replace the whole
solution those are goals and to scale
you need you should not have bottlenecks
in the system that it shouldn't be any
single point of failure and things like
that but in reality most of the patterns
and practices in the disabled space they
were invented in 70s and 60s sometimes
in 80s there's nothing new Under the Sun
in the space
so really it's in the encapsulation of
known best practices we took well people
already knew already proved and then put
it in a different package with a
different approach
and this is what we called it the
approach calling virtual address we
didn't come up with the name until much
later
we just we implement the model through
try and enter have several versions in
the prototypes and then we eventually
came up with this model then much later
for the paper that we published that we
called virtual actors and we call our
actors grains the reason for that is
that our actors in Orleans are so
different from actors in Erlang and and
Acker which is going to JDM :
essentially of for length so why don't
you have a different term even and find
out one we just published and release
the code the first reaction from the
actor model community was this they're
not is not actor model you don't have
supervision geez you don't have all
those things that we expect from your
line or like and we had to explain it
really those properties and our
properties of the action model this is
just a relaxed implementation of it so
the key about virtual actors that day
logical they can always exists virtually
the analogy is like virtual memory when
you have a page file and your code tries
to update a element in the array you
never call it and say for this item when
my array is the page memory page in
memory or is it in page file and it's
not an in memory load please for me from
the page file you don't do that you just
say I want to update this item in memory
and it's not for existing businesses
they are having the memory updated oh no
I don't have this page I need to load
from page file and then your update
execute execute so you kind of program
against the whole virtual memory space
and you don't care where a page file is
or what pages are so it's a similar idea
here so idea is that you program against
virtual actors they kind of always
available you can always make a call to
any action you never create them you
never delete them and how we arrive to
this as we started working with the halo
people we initially had the same kind of
standard thing we create a grain and you
delete a grain and the biggest problem
is we have concurrency so you have say
three front as a receive requests in
parallel for the same actor in the
system so the first thing they need to
do you need to call some registry and
say you have an actor for user X and
they all get no
an actor in the system for user X so all
three of them independently said we need
to create an accurate for user X when
you decide where to place this actual
user X they need to register this actor
fuser X in this registry and they all do
it concurrently and all but one should
fail and fail gracefully and sorry using
the actor that the winner registered so
you have to write all this code any
application code that's what we
discovered we saw and later we heard
that that was the biggest complaint from
Erlang developers that they have to this
coordination of creation of actor is not
really trivial because need to have this
registry it needs to be playing it
correctly and it needs to scale and
needs to be reliable always properties
so we said ok we'll do differently you
can program against every actor in the
system is if it's always in memory
that's why it's virtual it's always
available it does need to be created it
cannot be created it cannot be deleted
you can yeah it can always be addressed
but as a kind of the flipside of it
actors never fail because they can
always available in the system there is
no way to fail an actor the operation
may fail you may call and get an error
back but the actor from the mentally
always exists because it's a logical
construct and then how works and then we
describe in details in the paper the
release runtime does all this kind of
operating system job of PGE and paging
out so when you call an actor and
started in the system
the runtime release runtime realized oh
I need to load it you created in Peaks
the server where it needs to be created
so it coordinates with itself with
sentences running in your cluster
there's all the operations of
preparation calls were kind of a moral
equivalent of a constructor method say
I'm activating you if you need to
initialize something do it it allows the
state of this actor so it does all this
job and then if it sees that this actor
hasn't been used for for a while and
that's configurable time by default to
hours but you can say for this actor
class I won't have five minutes if it's
not used for five minutes
feel free to remove it from memory and
and the runtime does the reversing say
I'm about to remove it from memory if
you need to do something it's your
chance then it removes from memory but
the actor is still available you can
always call it if it's in memory if it's
in storage and even if it's in
transition
can still make it call they call
generally succeed unless there's a
failure in the system or in the logic
this approach also allows to remove
failure recovery logic most of the
failure recovery logic from the
application because now the system
manages state of this actors whether in
memory or that machine failed it can
realize and do that and and as a result
the minimize the amount of code
application developer writes that sort
of targeting this goal of reducing the
amount of code people right so let's see
how it looks sort of in reality when
people ask what is our leans so one
sentence explanation has been disability
sharp and as any one sentence
explanation it's never I'm saying
correct because it's not about C sharp
early it's it's just that kind of
distribute that net but the point is
that behind that sentences that you
program is if you you've given your
normal object-oriented application so
you have you start with the interface so
you declare your grain interface which
extends one of the marker interfaces
they define the key space like in this
case I extend I agree with good key
saying grains of that class of that of
that type will be addressed with the
good key which Maps do a lot of cases
you can also use a integer or string or
combination of Google and string or
integer and string so for convenience
because really in this room maybe you
could encode everything and now with the
vicinities you define the methods that
constitute this interface one
requirement one strong requirement we
have that all the methods have to be
synchronous they have to return a task a
chest cavity is everyone familiar with
the TPL task we seem to wait but
presumably one at this point should know
it and if not should immediately go and
learn because that that's the the best
thing that happened in c-sharp I though
a single weight so we define the
interface right this i user and here's
how greens that implements interface are
addressed so you really need three lines
of code two lines of code to invoke the
grain in this case
the first line through the study class
grain factory and you say give me a
reference to grain that implements the
signifies a user for a user ID X right
user ID would past good and what you get
back immediately is a constructed proxy
object
it's totally local operation takes no
time to execute there's no round-trip no
registry just it creates this proxy that
essentially encapsulated said anthea of
that actor it has type information and
identity the user ID of the specific
actor but that proxy implements the very
universe we defined above a user and
because of that I can make a call right
away so in the second line I call user
say hello and pass some argument and
with the magic of a wait c-sharp 500 I
can just write a weight and get a string
back so the code looks serial very
simple but in reality is you sure you
know the compiler reaps out to remain a
remainder of the method puts a
discontinuation executed later when the
response come back question yes that's
correct
so the question was what the way it just
hides away what happens right so this is
the very important question so this is a
synchronous RPC pattern so we're making
a remote procedure call and we're
getting a promise back and then we await
with the magic of the weight keyword we
do the continuation style we write
simple code that actually runs this
continuation style without blocking the
thread it's very important for
performance for scalability within the
system within the cygnets RPC in
Arlene's there is always a default
timeout so unless you you reconfigure it
by default if the reply didn't come back
within 30 seconds you get a timeout
exception so a wait will always resolve
your promise
either successfully or by throwing an
exception so this is the synchronous RPC
pattern that allows you to write two
lines of code and get resolved back and
then send it somewhere or output it but
that one you implement implement a green
class you also write very little code
because you need to extend this Base
Class grain Patel's in my class will be
a grain and then one or more interfaces
that this class implements in our
example I user and you see and say hello
I get a string in and I do something so
this classical hello world example but
also notice that I have this counter
variable that increment there and the
reason I don't need any locks I don't
need any synchronization is because the
Broglie model the release runtime
guarantees that all methods of all
actors that will run only in a single
threaded environment so within my
migraine my actor I'm guaranteed to
never run on two threads so I have to
worry about I always have exclusive
access to my variables not only they're
isolated from all others only I can
touch variables on my actor but I can
only touch them one at a time from one
three at a time so that allows for
simple code like that so this is a code
you write them in the hello world case
but what happens behind it sees there's
this lifecycle of an actor of grain so
most of them most of the time are in
persistent storage because most of them
have they don't have to they can be just
in memory state volatile state but in
reality in most system you have some
persistence data associated with the
user objects and then the runtime
transitions automatically that
particular grain from persisted to
active in memory and back to persisted
and it goes to his activation process
and deactivation persons were methods in
special methods get called
activating you you have a chance to
initialize it with deactivating you you
have a chance to notify that you have an
out of memory if that that's important
and all this is triggered by method
calls messages to the grain so under the
covers it's all message passing like
enact an actor model but messages are
exposes method calls which is not a
controversy or we had with sort of
Erlang guzel as I say unless you have
one way message passing that's not an
actor model and we argued no it's that's
much better because if we didn't have
this async RPC and we were sending
one-way messages say say hello send a
message and we need to senders and get a
response back me
coordinators to events and if you send
multiple requests and getting multiple
responses you need a state machine and
in some correlation it needs to
correlate this thing's well the task TPL
does it for you you send a call you got
a task that's your correlation ID
implicitly it's all that magic is done
for you again that minimizes the amount
of code and complexity of code you need
to write and if we go back to this
picture with this actor is running as a
stateful middle tier what really is
happening is that what you have in
memory on this cluster of machines it's
just a sliding window of actors for
example like Halo or Call of Duty 8 is
this major gives award they have tens of
millions of copies of users they sold a
game too but at any point in time if
they have a million people playing
concurrently that's a good day so you
only need to have in memory actors for
those players and their sessions and
their data actually on right now so you
have the sliding window when say halo
releases it starts in New Zealand funny
enough so midnight in New Zealand first
people are out to play and you see that
initial initial spike in usage then goes
to Australia and a Europe in the US so
you see this sliding window of users as
people go to bed in Australia New
Zealand some people don't take them game
1 just staying away several days but you
see this nation finding window user base
going around the globe and that's the
idea here that you only have actors in
memory for people that actually doing
something or for entities for devices
actually on that actually running some
code in technically or leaves runtime
runs on each server in the cluster
we call them silos have grains and
silence just to agricultural terms we
use them in the end no more just two so
as a silo process that usually want per
server the transit the container of
grains that's the earliest runtime
instance on the server you can have
multiple you can run more than one
doesn't matter from performance
perspective usually it doesn't make
sense unless you want to combine
multiple micro services on the same on
the same physical hardware so it doesn't
kind of overlay layer
in it transparently creates the cluster
so you just starting machines with this
processing machine with the right
configuration and automatically find
each other
the arrival equally form a cluster they
start pinning each other to say to check
is this machine still there
or if this machine didn't apply to me
three times I suspect there is a problem
there is enough balls to say of this
machine here applied to several
configurable number of other machines
then we can mark it as there even if
it's life and will force it to remove it
sorry I'm losing my voice for some
reason it's or may die as we discovered
but the distributor on time will detect
that the server died and will remove it
from the cluster and because of the
wrong time it knows what what actors or
grains are it come already the server so
again
what's one key the pause button
any questions the counter question is
about the counter example and race
conditions if multiple actors try to
increment the same counter the counter
is actually within the context of the
actor so other other actors do not touch
it it's only within this user or within
this device actor
there is no shared state so it's all
internal private to this specific actor
does that make sense or not confused
it's just a private variable so it's a
private int within this object
essentially so I can increment and at
will and nobody else will touch it only
I have access I know yeah but access
from single the question is does it mean
that only one average current through
the actor yes yes yes so it physically
runs you have a small thread pool that
runtime maintains usually one hand
thread per processor core you need I
have juggles all the actors within the
process because those say eight threads
on the eight core machine and movies or
in unknown
the question is yeah you need a mic take
more from Mike so the question was when
you use the grave you reuse the grain
for more than one user there's actually
a fundamental difference between
activist programming in the traditional
stateless service that you have right so
if you had in the traditional way
stateless class would be populated from
the database on demand then you use it
so the counters you'd have to worry
about
serializing they're easier and so in
this particular case all of the
serialization deserialization is taken
care of for you by the actor runtime and
you model the planes as if they're
actually individual objects that
represent each item in your domain and
then you leave the management of the
lifecycle of these things to the runtime
yes thank you
right so the question is what's the
lifecycle of this object do you really
think that it's visit always there is
the question to ask right and the answer
is yes and that's the whole point of
using the virtual active model is to you
don't worry about you just address it so
you should always make them non-blocking
but single-threaded is actually
consequence of the design to ensure that
all the state that is stored within the
actor is consistently accessed so you
can't have race conditions within
reactor itself so you have two methods
updating the counter you guaranteed the
question is that's right
so wondering about whether this recipe
of state from previous activations don't
think of it like that just think of it
as I have this object I have a reference
I'm using it and when I come back to use
the same reference to the same object or
different reference to the same object
it actually doesn't matter you're
getting the same object so you're not
getting to black cab in London you're
giving in to your own car that's being
chauffeured and when you leave it which
is parked for you in the garage and then
brought back to what John said the
question of what to model is as an actor
as a grain is actually the fundamental
design question it's kind of easy for
some questions like user or device but
when you go into more murky static you
have distributed computation very fine
grain a coarse grain that's one of the
important design decisions most
important design decisions you do what
when you program a system like that so I
think I covered that the release on time
handles failures of the hardware so it
runs as a resource management layer that
knows how many resources we have you can
place activations incarnations factors
physical machines and handle their
failures
hmm let's look at it more elaborate keys
so we have hello world it's too
simplistic so say this is a social
network and we say social network it
doesn't necessarily mean Facebook it
didn't the gains of social networks are
you teasing areas of social networks of
entities are having some relations and
some graphs and interacting with them so
let's say you have this notion of a user
and then want to add a friend operation
that's print to user so the simplest
case I define this I user as I'm having
one method and a friend take notice that
it takes an argument of type I user the
very same interface which is defined and
as ok because the runtime knows when you
pass actual argument that this is a
reference to another that current system
so this is what I do to add a friend so
first twice I get references to two
actors one for me and one for future
friend of mine and I just passed the
wooden table it's at friend operation
just pass a friend reference as an
argument and that's okay
then await the result of its operation
but nicely try-catch right so we have
try and catch because the operation may
throw an exception like this add friend
may throw and say this friend is not
allowed or you only have this person as
a friend
but if you think of it it's really I
have my code writing here and my actor
here on another machine on the server in
general and this friend actor on another
machine so I'm doing this distributed
operation and the exception is thrown
and I can handle it
so really like yeah we passed growing
differences in argument but if we
illustrate it so the request comes to
the front end it makes a call to grant a
and grade a to fulfill the completest
operation needs to call another grain
generally on another server grain B
which you needs turn calls grade C in
say green C throws an exception
if you write no code if you do nothing
that exception ibly automatically
delivered as a message to the server of
the caller green bean skis and grain be
can have code like this try catch and do
something but if it doesn't if it does
nothing just cause a weight with no try
catch that exception would deliver to
color of B to a and if a doesn't have a
try catcher will deliver to the front
end that started the whole chain so if
we look at it we really got distributed
asynchronous try catch the matrix for
free so this code is really is if it's
running within a single process but as I
showed it actually runs on of cluster
observers and all this just works
you don't write code to two passes
messages to just exception you throw
so the question is if they at forint
operation is for the single user versus
like munich and current operations
that's fine and actually I'll have an
example later you could do anything you
want and in this method you can do
something persist updated state I think
a team execution you can make a call to
set of actors
I'll show you this question thank you so
this is another example from kind of
same social network analogy say I need a
method that returns status of all my
friends and imagine having thousand
friends in my social network so if the
ladies have a single call to a single
friend to get the friends statuses 10
millisecond if I were to call them
serially thousand friends times 10
millisecond beach and second that the
best so here's how we do it in Orleans
right so we first find out requests so
in this for each loop which executes
within again milliseconds microseconds
we're just sending messages to thousand
friends in parallel and we add tasks
that they return into this list of tasks
we created and then we we join with this
beauty of TPL tasks class we just join
all this promises into one and the way
this joined promise so wait wait without
blocking and thread again for all these
operations to complete and once they
complete we can go and process the
results with another forage so we
implemented we found out in my example
thousand requests two thousand friends
of mine and we get all these response
has been others request processing in
parallel in the ideal case that we have
enough concurrency in the system
then all the responses will arrive with
ideal latency that's probably not the
case on real system but again a delays
will be 10 millisecond in my case which
is much better than 10 seconds
but even if case isn't ideal you still
have much better responsiveness and much
better throughput so this code doesn't
have any multi-threading again so with
because of this guarantees of single
threaded execution we write very simple
trance tracks that have no racist no no
synchronization of coordination we don't
block threads through the magic of GPL
so very efficient we don't do a context
switch things like that so we get it's
easy parallelism in the system and who
programmed MPI
ever ok joined it so they then is Gannon
needs to be professor in the enemy you
said like we don't want to teach our
students MPI anymore because we release
with these patterns is so much easier to
distribute your computations in general
you can fan out you can do this scatter
gather patterns so it's just the
mechanism that makes it easy Carl Hewitt
the inventor of the action model had
this interesting code that I'm proud of
a couple years ago thing and his survey
paper about actor models that releases
is an important step and further in the
goal of the actor model that application
programmers need not to be so concerned
with low-level system details that's
exactly what our goal was to raise level
abstraction so that you don't have to
deal with low-level like message passing
failures so I even joke that now I can
retire because Carl Hewitt acknowledged
her contribution then I look at my bank
account and decided to stay in the
workforce
it's so talking about persistence one
feature that we have which is an opt-in
feature is not required but you can
declaratively have persistent state
management so for that you need to
define your property back like poco
class they can use example users stay
with a couple properties and then when
you declare so you define this property
back class and then when you declare
your user brain class instead of
extending grain you extend grain of T
where T is the property back so you pass
this type argument and then once you
update your state you can just write it
to storage
with a single ohryan this asynchronous
operation right staties think so you get
this state property which is of type
user state on this example and then
operations like right we also read and
clear but in most cases you don't need
to use those at all because when the
grain is activated the read operation
happens before a control is transferred
to your application so when when your
grain starts its state is already read
from persistence and you only have this
property's initialize you just need you
can initialize some in memory variables
negation so they said just very simple
declarative persistence but if you
notice there is also this line with
storage provider so this model decouples
you from the actual physical storage so
notion of storage providers plug-ins
extensibility points in the system so
that you can switch between different
storages and decouple those concerns
because it's opt-in feature there's
limitations but you can use it so we
included if you are the providers but
there's more that community build
somebody build just now for EWS
email for one of the soldiers in AWS
another important feature I want to
bring to you there is a lot lots more
features like placement different
strategies for placement there is this
notion of stateless workers work for
functional operations the observer
first timers reminder so you can say
I'll wake me up every day or every
couple hours don't have time to go over
all the features but this one I want to
highlight so we added like a couple of
years ago with the same concept of
virtual actors we had a notion of
virtual streams so kind of extreme
sequence of events that the stream has
an identity and you can always produce
events or a stream or or consumer that's
from a stream without creating without
deleting kind of the same idea that if
you know identity
just like with a grey and with an actor
if you know I didn't see the stream you
can make operation sign so if you look
at this code I get stream provider by
name which is a pointer you can speak
and I can have again we have provider
models you can have providers for
different persistent queue systems and
then I just say give me a stream of this
type with this identity like a path idea
and the namespace and then I can either
produce to this stream like on the next
async async version of rx style on API
or I can consume my subscribe in a
handler so we created a couple years ago
and at first they were around in
production in halo 5 and launch of
processing of statistics that coming
into the system through event Hawking
persistent in queues reliably he's done
with virtual streams and now it's being
used more and more but just just to
illustrate for that to be simple to work
there's a lot of machinery in the
runtime that has this notion of pulling
agents that get distributed across all
the servers you get coordinated and they
pull from different partitions and they
then have in this example in Caucasian
is Kafka in Azure queues and they send
messages to consumers so of code that
runs in the runtime system you don't
have to write it named attune anybody
knows when tomorrow comes nobody knows
it makes any point so when we started
talking to people early on well here's
what we're working on he's the release
model with his brains and seemed like it
worked it solves a lot of problems for
this coming cloud computing and people
like within the
they didn't really believe us because
somebody comes and say hey I have a
solution
another want to be here for you and
that's understandable and then this guy
came so the story that hoop was talking
about briefly in the video is actually
real they came to say hey we want to use
your stuff because we had this
architecture we created and looks like
you implemented 80% of it already in our
links let's work together and to finish
like missing pieces when we need to be
in production three months by the way we
launched in a title that's literature
Mikey Messiah this guy's a crazy week I
want to take technology from
researchable in production three months
I know what they're thinking but let's
drop everything that's helped them
because that's a great opportunity and I
was a yellow anniversary edition for the
actual name of the title with a single
service that they put out as a test
correct does it work
and they liked it so much that for Halo
4 so was there a test for the next big
release halo 4 it was happening almost a
year later for he LaPorta just energized
and saying we already building cloud
service release because we get so much
out of it so once people heard about the
link is done this whole question I'm
always a toy does actually work the
sexual scale is reliable because almost
disappeared because he ever works for
Halo now much smaller and scale must
work for me so we had this I got a
gaming company is giving out game
studios within the company came I
mention Halo 5 for launch almost a year
ago including streaming but not knowing
gamers I connect Skype or some other
analytics monitoring in this thing is
the IOT project of launching balloon
into almost you space this this apps
that you see on windows I can assign
absolute being apps that used to be
called I mean they may not be fanciest
but they have hundreds of millions of
users age and years of war is shipping
this fall it's also running heavily on
release on the same code base but there
is a reason that gamers come first
because when they lodge
their product they seem to like this
it's like a movie business where you
make most of your money within the first
two three or four weeks and if there is
a problem in the first day first you are
worse first week you lose a lot because
the only angry fans will go online
you've seen all the stories and there's
some reason ones even so it's very
unforgettable oh it's not like a service
where people learn about it over time
and your love grows kind of steadily
even if it's a hockey stick it's still
growing
here it's the opposite we can jump right
away when you zealand australia wakes up
and starts playing but but also they
rewrite all of code so they good users
because they need to replace a lot of
code very frequently so they open to new
technology it's not like they've been
running it for 15 years they have to
innovate very fast it's fast pace
innovation but also they're looking and
economics that they have more trouble
selling these discs now they want to do
more in a cloud the more julik ingame
purchase the more have more features
that delivers over time which turns them
to cloud earlier and then other users
under pressure yeah thank you so
drinking beer together this one so every
analyst that really that Gartner they
have this magic quadrants and I thought
why can't I have my magic Sergey
squadron's I define my own so we start
with the interactive entertainment so
these games but also like interactive TV
like delivering content coordination
cloud assisted compute all the scenarios
kind of similar so that's one bucket but
if we look at a near real-time analytics
is not far behind because you have
aggregation monitoring and alerting for
detection is interesting very similar
for credit card comes and they have
credit card companies during fraud
detection using release but also even
games they have children cheating
detection and banging automatically it's
very interesting overlap all of these
things but then I you tease the hardest
that I think subconsciously made it
right because everyone wants UI
again the sensors or devices they're
kind of like users they all interact
they have relations the send messages
thing to be processed the project I'm
most proud of in this space is this 500
megawatt power facility in Oahu in
Hawaii
I just came from Oahu I wanted to visit
the facility was too complicated set it
up but they managed this system that
direct green power to the smart water
heaters and accumulated there so
essentially they're on somebody said
equivalent of small nuclear power plant
which is all renewable energy and
another fancy project is they it's just
to control 2 million mousetraps but then
if you look at it is many more like
there's all the kind of real-time
collaboration scale out computers as a
show that's very simple primitives so
that's why that there's plenty of space
to to apply this discount section and
these tools if you love somebody set
them free just happened to be the
concert of mr. sting and I feel Gabriel
in Seattle the week before so it took us
a long time we started in 2009 and we
like I said several prototypes and a
kilo for or the first really big launch
was in 2012 I wish we publish it earlier
but we ended up open source and in
generally 2015 and I was serving an
amazing experience we're dealing with
this open source community it just
completely exceeded all our expectations
you have these people make yourself
there they're seasoned engineers they
collectively know a lot more than you
can ever know like it's a very humbling
experience you get chapter to this world
of people they do it for free for fun
because they think it's better or
because they use it in their company
it's great experience so since then we
all develop in open and in github and
open source I know where it is smiling
because that's what he's doing as well
but that's really key to its MIT license
no strings attached go use it in any way
we could a lot of developments happening
there
spreading wings and fly away but knows
yeah it's also sting oh sorry it's the
Queen so the key things for links are
the women's run anywhere so you want we
wanted you to run it anywhere you want
the way you want there is no law like
attachment there's misconception in the
release for a jerk it's not you can run
anywhere in Azure in AWS and Google
Cloud on the premises on the developer
laptop it's all possible within the
plugins you can run against any storage
systems the thing that I'm proud of is
that we used to having clothes and in my
case of a co system from other
open-source technologies here we have
the reverse orbit was the buy where one
of the Electronic Arts companies they
create a clone and were released because
there were GBM shop they said we like
the model ovaries so so much but we're
GV and we couldn't use that net so you
just ended up creating the clone and but
like it because they pretty good
I think light band is doing something
similar we moved out of MSR Microsoft
Research to the polygroup point we
didn't stop collaborating when the
Mossad don't stop you know yes thank you
so we have the one project we merging
right now we're actually in the process
of reviewing marine code is Jo
distributed or these so instead of like
I show you this picture of a single
cluster running a bunch of for aliens
runtime instances and lots of grains
there but now this is the picture that
we get with multiple classes running in
geo distributed environment and
collaborating but you still have the
same simple programming model where you
the actor represents you user can be
only one of the servers on one of the
clusters
and it's one of the models there and
then Phil Bernstein famous a few birds
didn't know less it's working and bring
asset transactions so you can have cross
accurate transactions with complete acid
guarantees he's been working it for a
couple of years to summarize I think you
think why Arlene has been successful so
far is that it maps to many workloads
easily because it kind of
you can pose your state into the smaller
entities so how to distribute your load
even before some people realize that
because you encode your application
logic and the notion of this actors of
these types and their instances you
decompose your state instead of having
one single blob of color user data
you're not being with these pieces and
chunks there is no prescription size of
the actor we don't say it has to be
small or large it's up to the
application but most workloads tend to
have a large number of smallish actors
but nothing is very difficult to do in
traditional approaches in horizontal
communication and with actor model
that's its nature that's the essence of
the model it can send messages so these
actors they can talk directly you don't
have to go outside and call the web
service they can choose invoke in our
case invoke methods on other actors and
it just works and I mentioned several
times that Arlene's runtime manages
resources so it places and handles
failures and things like that so you can
scale out it can be elastic you can add
more resources have more capacity or if
you load a always done you can remove
resources and readjust the cluster size
but also I would argue that it brings
the object-oriented of the world back we
would keep hearing for last several
years of service O'Neill's for us every
decade
sorry-sorry at architecture but if you
look at the real world like once a
Hawaiian interacts with the kids they
all I could it doesn't track with
gazelles service it just compute
instance of the gazelle type so you have
this really object-oriented analogy that
map's the Manning workload is much
better than service-oriented
architecture I would argue and we've
proven that with this graph in the paper
but I think it we can raise the bar we
have like 50% more throughput right now
then so we've proven that we scale
linearly so we go back to to this
picture I hope I proved that we covered
most of this points so we have developed
productivity linear scalability and high
efficiency in the model and how its
implemented the sub linear cost is hard
linear cost is already a winner but
sublinear is much more challenging the
Pipers calling you to join him yes so my
message is that you can take it as is
you can join a community and enjoy the
collective mind are all these people all
over the world they participated some
people they can't use their links at the
work because of the company they work
for
then still hang out and the community
because they like the community like the
people there they just chat about some
technical questions sometimes a
non-technical question if you owe more
of the jvm if you give e I'm shocked you
can use orbit which is very close they
just literally copied that in general
like look at what we did at the model
maybe you can apply the same the same
learnings the same approaches to your
the main not necessarily directly taking
the code is that I want to thank you and
any questions of the happy to answer now
or later rights mentioned that virtual
meetups that we do periodically will
record they're all on YouTube but we
also have the gira channel so in Gitter
that's where people hang out and all
people know what kidder but we have link
on our github page go together and
people there they always answer question
of people come and questions about them
can you talk a bit about Herald lanes
managers persistence and storage every
time I tell something or Dwight yeah
thank you so that's one of the kind of
key questions in the application how to
manage persistent state and or at least
doesn't really prescribe how you do it
because it depends right in in many
cases any update needs to be persistent
and then either you use declarative
persistence feature that we have or
write it own code charts of storage
before you method return success from
from the operation you want to make sure
you persist it your result that's the
most typical case because you don't want
to lose right but you can also do like
right behind so if you can afford
sometimes and frequently to lose some
updates you can accumulate them in
memory and say write every minute so
that's the application writer decision
and again it's sort of our Fagin all too
early is because you can use declarative
persistence or your own persistent
library and still decide how you doing
oh thank you for this question
because I forgot to mention that Friday
John and I had given talk about patterns
and event sourcing one of the patterns
there so please come for a Friday talk
will cover it so if you look at the unit
test that we have on github we have the
space classes for unit testing where you
essentially you run a cluster within a
single process within there's different
abdomens on the client and you can
easily test the a5 from visual studio
and just run it within single process
you don't have to deploy it anywhere
it's very easy to run those tests so we
have this facility from Justin please
due to the single single donation to the
grande sorry hue one call together at
one of the grants running along
long-running process how do we how do we
take care of it so there are two cases
so there's long-running that somebody
else is doing for you like you you're
doing a you made a call to remote
storage or something in remote service
on your waiting for it to finish
that's very easy because we're the
weight you just need to make sure use a
sink API so you make a call a way to
task a retirement task and it just works
brilliantly if you want to run a
long-running computer so it actually
uses CPU what we recommend is to move it
to like dotnet thread pool or to some
custom thread not run it on the runtime
threads so can I release the runtime
ties as soon as possible and run it
somewhere else I can maybe a different
process you start with you execute the
request all right thank you any other
questions before we lose the room well
you can catch me later I'm here through
Wednesday and the Melbourne Monday</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>