<!DOCTYPE html><html lang="en"><head><script async src="https://www.googletagmanager.com/gtag/js?id=UA-114897551-4"></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-114897551-4');
</script><script type="text/javascript" src="//platform-api.sharethis.com/js/sharethis.js#property=5ac2443d1fff98001395ab6c&amp;product=sticky-share-buttons" async="async"></script><title>Using F# on Azure Functions in Production - Nikolai Andersen | Coder Coacher - Coaching Coders</title><meta content="Using F# on Azure Functions in Production - Nikolai Andersen - All technical stuff in one place" name="description"><meta name="keywords" content="education, coding, programming, technology, nodejs, mongodb, software, computer science, engineering, teaching, coaching, coder, learning, java, kotlin, machine learning, AI, ML, tech talks, angular, javascript, js, typescript"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="/css/font.css"><link rel="stylesheet" href="/css/bootstrap.css"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/coder-coacher.css"></head><body><div class="container-fluid"><h1 class="site-title"><a href="/">Coder Coacher</a></h1><hr><h4 class="site-subtitle text-right">Coaching Coders</h4></div><div id="amzn-assoc-ad-99d6751e-2392-4004-ad16-73aa8385d9d0"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=99d6751e-2392-4004-ad16-73aa8385d9d0"></script><div class="post__breadcrumb"><div class="container"><ol class="breadcrumb"><li><a href="/">Coder Coacher</a></li><li><a href="/NDC-Conferences/">NDC Conferences</a></li><li class="active">â¤µ</li></ol></div></div><h2 class="post__title"><b>Using F# on Azure Functions in Production - Nikolai Andersen</b></h2><h5 class="post__date">2017-07-05</h5><div class="container"><div class="video-responsive"><iframe width="560" height="315" src="https://www.youtube.com/embed/pabo99C6_JA" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div><div class="post__text">the goal is to get cold running
introduction that's my mantra as a
consultant when I get go to work if a
feature is not in production and usable
by the user then it's not providing any
value so that's kind of how I think
about my job when I go there every day I
want to get called to production
currently I am at the Regent Directorate
for education and training in the region
you thumbing static data and our team
there is around advice a bit between
sixteen and thirty people and we are
responsible for three rather big systems
and we have three kind of sub teams that
we go between and we do continuous
delivery we deploy to production as
often as we can and as soon as we have
something of value usually we deploy
only two three times a week not because
we can't do anymore but because and I'll
get back to that we have a kind of gated
deploy to production we consider the
master branch ready for production at
any time some of you might know this as
the github flow and that means we use
feature toggles we have peer reviews
that are we put a lot of trust in our
colleagues in peer reviews and we have
short-lived feature branches so a
process kind of looks like this
you start by branching out from master
you write some code add some commits you
guys open a peer review it gets built to
check if it actually compiled tests or
on somebody from the team player reviews
it says this is good and then I want to
point out these two kind of manual steps
we have if you have a database migration
in your pull request which means that
when the
change reaches production if it migrates
the database you should mark it in the
title with this hashtag DB migration
I'll get back to that we also have the
manual task of if your changes touches
any tasks in our work item in our work
management system you put the ID in the
title so it's easy to see ok this work
tasks these commits touch this work task
doesn't matter if it's done or if it's
in progress or anything a work item like
a work management system that we use is
JIRA Atlassian JIRA so that's an example
but it doesn't really matter in the
scope of things here it could be Trello
it could be whatever but we put the JIRA
code of tasks we're working on in the
title and we merge in and as soon as
this merge into master master just
builds itself more thorough tests and
then it gets deployed to the devs or
Qunari environment whatever you want to
call it so the merge commit can look
something like this just to get it
absolutely clear we have a zero tossed
in there we have the DB migration check
you can see that there is a bill that
has to pass and it also says approved on
the bottom line which means someone on
the team approved it and I wrote a
little text there that is DB migration
hashtag that could probably be autumn
eyes with simple code analysis so that's
the way from a developer to development
environment which we call dev so it hits
dev and that is deployed to tens of tens
of times a day and we promote to the
test environments when we want to do
some more thorough testing so we have
three test environments as you can see
tests test two and integrations
integrations is where we test other
systems tester integrations towards us
so it's a bit specialized for that and
in the other customized we have more
automated tests and thorough tests for
integrations we have so
when we are done and feel that we have a
candidate for production we put it into
the QA environment and the process we
have is that when we put something in
the QA environment the customer wants
their testers to approve the changes
before we roll it out to production and
we're doing continuous delivery so it
might be only three small changes but
still they want to check that these
three things are ok before it goes to
production the reason for this is that
of course they are a government agency
and they care a lot about their
reputation and they care a lot about the
services they provide to the rest of the
sector because they are doing that as a
government agency for the government so
they are there they want us to be served
they don't want things to break so this
is kind of a middle way between
continuous delivery and a bit strict
gated deployed with testing so when the
testers get their hand on a version in
the QA environment the first question is
what is the actual change here what is
the actual change is going to go out
into production that I need to look into
and at first they started looking to
JIRA and seeing what in JIRA has been
put in the progress for for for testing
and they would use that but of course a
lot of things that was going to
production was feature toggled away or
there were code and architectural
integration changes that didn't really
touch any user stories or maybe tasks in
JIRA so we wanted to automate these
tasks and find out what are the changes
and how can we give these changes to the
testers so they can test and approve the
version for production so I like to
think of it as this we need to get the
changes between environment X and
environment Y for a given project or a
given application that's going to go to
production so you can look at it like
this this is kind of a grid so given set
and X I can find out what version is in
queue a given set and why I can find out
which version is in production and now I
have the two versions of our or two
artifact versions so now I just need to
somewhere find what are the changes
between them so you can look a bit like
this let's think of it as a application
or a function that takes this input and
gives us the changes in the other end so
what we need to determine giving this
input because I wanted the input to be
the environment name and not and any IDs
or anything I wanted this to be this
function or app should be able to be
called from a console app from a web app
directly from the deployment service or
application that we're using so we need
to somewhere to get the version in
environment X now I'm thinking of the
how to implement this we need to get the
version environment X we need to get the
version environment why we need to go
somewhere and get the changes between
those two of course we're going to those
are in gate so that's where we need to
go somehow and it comes in the kind of
bonus where we have these DB migration
hash tags so we can find if there are
any migrations in this deploy and we
also have some work items so we can go
to our work management system and fetch
out some summary some statuses and link
everything up so we get a smooth nice
list so these are kind of the four
things we're going to have to do inside
our function go get the two versions get
their diff between them parse them for
migration and work items and if there
are any work items doesn't have to be we
go and fetch them
in our case these are the three systems
involved we use octopus deploy for
deployments we use teamcity for builds
and JIRA for our work management or
project management so this is great
because Optimus deploy of course knows
which package it is its job to know what
package is in what environment so I can
just do two calls there what is the next
what is in why I'll get those bags and
then I can talk to the team CD API they
have a very good REST API so I don't
have to touch gate at all they have a
REST API over gate perfect so I go there
tell team city what are the changes
between the two these two versions and
then we parse them and what do you know
Java also has a API so we're going to
integrate with their API to what we did
and we fetch stuff from that so we
basically need two things here to solve
this problem we need one tool or
technology that is good at integrating
through and clear and easy with api's
and other systems and we need somewhere
to put this app or function when we're
done without any hassle and I guess by
the name of the talk you're gonna buy
now you have understood what these two
tools are when we encountered this
problem we knew that F sharp was the
right tool for the job because we had
experience with that sharp from before
we'd written like some rule engines
domain-specific languages we have an
entire solution in F sharp that heavy
uses type providers and all of the good
stuff but just to take a step back we
knew about what problems does F sharp
solve that it actually solved for us we
ended up writing less code that gave us
less errors that's a given but
especially the last two in a very
complicated domain where we're doing a
lot of work and there is a lot of room
for errors we noticed that having option
types and no
No and having a super-strong type system
if you catch the Scots talk the last one
in yesterday in this room you saw how
powerful the type system is but
combining all this we didn't get any
loose cases or or invalid states in our
program so we were able to solve a very
complex domain in an easy way
which is where F sharp really shines and
of course the biggest thing for us was
maybe PI providers because we had a lot
of different sources we had SQL we had
Jason we had CSV and with PI providers
we got all that easily in two types
without having to write user generated
code we didn't have to do code
generation which is usually what you
would do in C sharp but user generation
is not PI providers type providers you
can think of them as code generation
it's just you don't have to think about
code being generated into your project
if you have ever right-click and data
Dunham's add service reference in your
web project you will know it generates a
lot of code then if they API or service
changes you have to go in again generate
more code to get the changes and type
providers they it kind of takes that
away from you they they do it for you
they are lazy loaded so you can use them
on big data sources without your app
generating thousands of files if there
are thousands of types in this service
and there are type providers for
everything SQL which I will show you CSV
JSON XML there are even a swagger type
provider so we still have an API that
uses swagger you want to integrate with
it from a client you can just use the
swagger type provider and you will get
all the types all the functions you can
call in this API everything
strongly-typed
and feedback directly in you should
studio code or visual studio or whatever
so we had a big project in c-sharp where
we had the data layer also in c-sharp
and we were using Babur I have to say
this is a great piece of code for being
c-sharp at least but this works and it's
easy to read you understand right away
what it does of course we have much
words queries than this in our
application this is just to point out a
few potential errors first of all this
can result this can return null you have
to remember to handle no compiler that
can help you so you have to have a null
check somewhere here because first or
default returns a result or no so
further up in stack you need to have
it's statement to check for unknown
value also notice that the SQL here is a
string so if I have a typo in the string
it would crash at runtime not a compile
time so I'm going to have to write an
integration tests or something for this
of course most likely I'll do that
anyway but I'd rather typos were caught
a bit earlier and I didn't have to run a
lot of tests and to see that I have a
typo you can also see that the
parameters we send in is an anonymous
object so it doesn't have any mapping to
the actual parameter that is inside the
SQL string so if I have a typo there or
it doesn't match runtime error and also
when we used Apple we ended up making a
lot of types to map our database into
our C short code that weren't domain
objects so we ended up writing code for
the database to easily map everything in
could write mappers but this is what
that was the easiest way to get data
into the c-sharp app and then map them
over to the main objects not the worst
thing but bit annoying so when we were
making a new project and we wanted to
use the same stack that we have from
before because we wanted new developers
to be able to work on both applications
without too much hassle but we dig one
change and that's we decided to move
from dapper as the data layer
to the F sharp data SQL client type
provider
it's a t-sql type provider so it's
specific for SQL Server that we were
using and we only changed the data layer
so the rest of the application will
still see sharp only the library just
before hitting the database was F sharp
and this is in production now so when
students take national test is autumn
all six eighth and ninth graders and
have to take the specimen for it the
results will be saving and loaded with F
sharp I think that's cool and before you
say what the to this code you might
say why is this better is just more code
and it looks almost exactly the same
well before I explain why it looks like
this I'm just going to say if I were now
to write something in there you see the
SQL is still a string if I was to write
any typos there I will get a red
squiggly line under the whole string in
Visual Studio right away
and it would tell me that this is not a
table in the database this is not a
column it actually checks against the
schema of your database that you are
writing valid SQL and you get compile
time errors if it doesn't match and this
is why it looks like it did a lot of F
sharp code because we discovered that C
sharp F sharp interrupts it's a bit of
pain but it's absolutely worth it but
it's something to be aware of I don't
want to come here and preach like use
that sharp as your data layer in your
c-sharp app you should if you wanted the
same things we wanted but there are some
things to to note here first of all I
just want to put out out here with the
async execute function recalling it's a
strongly typed input to the SQL string I
had before so if I were to in the string
on the top here if I was to change the
where Clause use the ID instead then the
signature of the async execute here we
change from okay he shouldn't ask for a
string anymore I should ask for a
it she gets safety between the
handwritten query and calling it from
your code as you can see we knew up an
object down here mapping it from the
magic type of the type provider to our
domain type I really regret us not
writing hard the main types in F sharp
because f sharp records are super easy
to write and if you use them from C
sharp they are idiomatic
C sharp objects you initiate everything
to the constructor and you don't have to
you only have like gathers so it's kind
of how we write C sharp cause it's just
so much less code and it would look much
nicer here still the same from C sharp
we have somebody on the team made like a
options.you tool so you see almost in
the end here because when we come to the
C sharp side it expects not an option
like something or nothing it expects
something or no and the last thing we
have to do is map from the beautiful
async API in F sharp over to the TTL and
async/await in C sharp so most of this
code that makes this a bit hard to read
and be messy it's because of the C sharp
F sharp interrupts and yeah code like
this writing code like this in enough
short lead keeps me awake at night a lot
of people ask me like how did the team
handle f sharp and I just want to say
that I have amazing colleagues they
really are positive and they really see
the benefits of it so even if they are
the ones much more than me working at
this level and jumping between F sharp
and C sharp they they really see the
benefits even though it's much harder to
navigate initial studio because if you
try to shift up twelve like go to two
definition on a or go to find usages on
an F sharp function it will start to
decompile your C short code and show you
where it is it doesn't understand that
I'm in the same solution
so the trick is just don't teach them
the mutable keyword in F sharp and they
will learn okay
so now we kind of find our first tool in
place to integrate with these systems we
already have knowledge with F sharp we
know that type providers are the best
tool to use to do this so we're going to
use it so now we need somewhere to put
our function and of course function
start thinking about yeah everything
everyone's talking about server less or
and functions as a service so that
sounds like exactly what we we need and
that's you probably have heard several
times during this conference like
servlets is of course a business leading
there are servers running your code it's
just that you don't have to think about
these servers at all that's a concept
that you just throw out the window you
don't think about servers so like
scaling and patching and problems
related to uptime these are things you
don't have to think about anymore when
you run service code or run service and
you're outsourcing everything about the
management to someone you trust and
usually that is or if you're going to do
this you should use a public cloud
provider like Microsoft of Google or
Amazon and yes you can you do server
this in-house but it's not really
service because you're still doing it on
premise and have all the problems with
that and so you can focus on writing
code that provides business value like
this is the whole point here you want to
put as much of everything else away so
we can focus on writing code that brings
value to our business or to nonprofit
whatever value so usually you see this
like graph like why do you what do you
have to stop thinking about as you move
from on-premise to software as a service
which is an example that it may be all 0
which has so
the problem or Asher b2c they've solved
the problem like of authentication and
authorization so you pay them to to give
you that service you don't have to worry
about it you can provide value by
writing business code so to move from
on-premise to our infrastructure as a
service you stop thinking about power
you stop big you stop thinking about
cooling you stop thinking about the
toilet the security guy at the data
warehouse have to have the in use while
he's there and as you move from
infrastructure to service over to
platform as a service you stop thinking
about networking and firewalls and all
this stuff if you reach platform as a
service and are doing it now that you're
doing pretty good
then you have a lot of worries thrown
out the door but you still have to think
about a few things related to uptime and
scaling and I'm thinking this quote from
Martin Fowler's blog where there's a
very good resource on service if you
want to know more and this is a good
quote if your platform as a service can
officially start instances in 20
milliseconds to run for half a second
and call it service that's like the
point here you actually pay for what you
use so if you're running server less and
in the middle of the night nobody is
trying to reach your app then you're at
zero you scaled your no down to you
don't you don't do it it's just zero
nothing is running because there are no
requests or input to handle where you
usually would in a platform as a service
world have an app running ready to
receive a request and if it suddenly
comes four thousand requests it has to
usually about order scaling or something
like that it starts scaling up but with
service if the thousand request comes in
the middle of the room in the middle of
the night then a thousand requests are
processed in parallel because they start
up they run and they quit do their job
so you can look away from this scaling
issue and you again you can think I'm
coming back to all the time which is
like the main point it's right cold but
actually it's useful to you
of course you should be careful with
server lists that you are not running a
denial of service attack on your wallet
because it will scale unlimited I
actually read a blog post a few days ago
about a guy who put up two ashraf
functions that were calling each other
two queues but everytime they called
each other they think he doubled the
number of requests so if it's just
getting more and more and more and more
he just had to stop it in the end
because he lost all his lecture credits
or something but just be be aware of
this and also i just want to note that
this is like surveillance or functions
as a service it's not a silver bullet of
course as with everything there are some
things to think about as I said you
scales to zero so you have to something
has to start when your request
it's the your app which means you have
some kind of latency where a platform as
a service application could be ready and
primed cache running everything and when
I request hit is like boom we function
as a service there are all the time
working to get the latency down but
there is something that has to get
injected and started for your request to
be processed so there is kind of a like
a late start up cost every time you
started and of course since it gets
stopped after it's done you have to
think about state in these functions if
you want to have some kind of state it
needs to be pulled from somewhere some
kind of document to be you have to run
it through your state machine and then
save it again because the function
doesn't have any state also running
these things locally on your own machine
it's a bit of a the more you like put
the things in the cloud the harder it
gets to get a short feedback loop
running on your machine you have to have
a dev environment in in your actual
cloud provider and you're working
against that all the time does something
with your feedback loop for you with a
normal little program can be on your
machine and everything happens there and
of course
vendor lock-in is a problem with
surveillance if you start using these
services of course you should write your
code as you always do it with good
modulation and libraries and everything
but you will most likely start using
services that and should probably in
most cases but just be aware of it if
it's very important to you that you can
change or switch your provider at any
time so we're going to go to asha
functions not because the code we're
making or made doesn't run in any other
cloud provider but because I should
function supported the F sharp straight
out the door and we already had after
subscription so I'm not going to be here
telling you actually functions is the
best function as a service platform I'm
not sure I think that myself it's just
food that our needs the best and we
already had a sure subscription so and
it works the cool thing about our
functions is that the runtime is running
on top of App Services which means that
all the things you get from app services
that you love and hate you get them in
an actual functions to things like
deployment slots authentication in front
of your function you get this whole
dashboard you're used to and also a cool
thing is that the runtime of a sh
function can run locally on your machine
so you can run up your functions on your
machine and debug to them set
breakpoints and everything as far as I
know no other child provider offers that
with their service offerings and of
course you have a lot of triggers in
integration to services already in usher
which I will show a bit later the bad
thing with this runtime is of course it
only runs in Windows and I prefer to use
OSX so I don't get too much gain out of
that I guess they will make it
cross-platform like everything else
they're doing now Microsoft but right
now I can use it on OSX
that sucks a bit okay so now we have the
two tools we want to use we want to
combine F sharp with Asha functions to
solve our problem to find the changes
between these environments let's get out
of the slides and actually show
something so the code base looks
something like what you can see on the
left here it's a normal solution that
you would make in Visual Studio or
anything have the this is how I would
make any bug net the solution these days
but what's important here if you look
away from the name cell I call function
this is interesting as well like the
main thing here lives in a library
because even if I'm going serve less
still going to write my business code
I'm still going to write modules I'm
going to put it in libraries I'm not
going to change my good habits of doing
that just because I'm suddenly running
functions in the cloud so this is a very
simple library where we basically have
one entry point and it's a function to
get changes between environments just
what we wanted it takes in some
arguments and those include some input
which we saw earlier the input it also
takes some things it needs to know in
our specific case for finding this out
and if I was coming here showing you
best practices this will probably lying
in a key vault in usher or some more
secure place but right now there are in
the environment string
don't do that it's your in if you have
sensitive information or something it's
it's not best practice but anyway this
is I input to the function and I just
want to be very clear that what I'm
about to show you with the tie providers
and everything even though I you see G
Ryan TTC 14 CD here it that's not really
bad relevant that's just our like a
implementation detail that we use those
systems doesn't mean you have to so we
take in these arguments and here we see
the first sign of a type provider
because we actually have a config that
gives us some more information it
actually holds the URLs
it holds the link to github so we can
hook up commits and I have clickable
links in our change log it also gives us
the mapping between octopus deploy and
team cities so we know which team city
build configuration is related to what
octopus project again this is just
implementation details it doesn't really
matter it's just for mapping between the
systems small and easy but the cool
thing here is that I'm using the llamo
config type provider from f-sharp
configuration and I'm reading in this ya
know file to any creates a type for me
and as you can see here from the
signature I get the things I provided in
the config as types of strongly typed I
get them strongly typed and you can see
here that it even discovered that these
URLs are your eyes it doesn't give it
strings it actually gives me your eyes
and it creates another type inside my
project because it saw okay you have a
list of something in your country
so now I can set pull out these values
that I want from there and I
of what I need to start fetching the two
things I was wondering about which
version is in environment X which
version is in environment Y and these
are of course the same the same function
is called but just two times one time
for each environment x and y so inside
here this is again this is just
implementation details basically but
what we do we have to put like the API
key in the header and then we have to
call the projects list to get the list
of projects so we can get the project ID
you get my point this isn't this isn't
relevant for this this is it costs the
way the API of octopus is built built up
I have to do a bit more calls than I
would actually like to but the cool
thing here is again type providers this
time I'm using the JSON type provider
and I've provided samples for these two
endpoints on calling one is the project
list which is an endpoint then this is a
what I do I just call it from postman I
get the response and I paste it in here
as a string when I put a literal over
it's just as it's the same as a constant
in this eShop
what it means is that I now have a
sample here that my type provider can
read and make pipes from so it doesn't
have to be pull polling there API that
provides me this Jason in any way to to
create the types because I don't want
that so in this case where I pulled
Jason over the net I want a sample here
like to create my types from when we use
the SQL type provider we have a like we
did in the yellow project that I'll show
you earlier then we actually have a
local to be running or on our own
machine with the latest and greatest
migration and it checks constantly but
what you're writing master schema
so I'm basically reading these two
samples and what octopus no sorry what I
provided us Jennsen typewriter is to
make me types so when I then go on and
do a HTTP request and get this project
list JSON back from the API it can parse
it with my type and then I get I have
type safety here and I can start I can
map it over to the items and then I can
go in and I can see okay
which project in the list has a name
equal then project name that was the
input to my function I get some I just
crash everything if I can't find it of
course you can do whatever you want
there then I have the project ID then I
can do another API call to get the old
information about the project and in
there I can find out which version of
the app is actually deployed in the
environment that I'm interested in so
update of the back and forth but I get
type safety the whole way so I'm not
really scared and if there's something
with the JSON response that it's not
possible in any way I can still kind of
access the properties unsafe this is a
bit the reason for this is that the
octopus API puts things like IDs here
not inside some kind of value but in the
JSON as a as an object so this ID I
don't know what it is or I need to like
parse the deployments to find it so
anyway a lot of just working with the
octopus API but type safety and it all
fits here on a pretty student in screen
that's cool and in the end it returns
the version of the release so basically
super simple function taking these four
things puts out a version eight now you
can see that we do the same for the two
environment version and then we have the
two versions that we want to find the
difference between what we do then is
read from the config file again where we
had all the projects so you can see here
we have a list of projects we have we
now have the we have the octopus deploy
name because that's our input of how we
reference to the project name and now we
want to go to team city to find the
difference between the two version with
just versions we just pulled from from
octopus so basically this is just code
for mapping from the octopus named the
same team city name and then we have
another function which basically does
the exact same thing of the first
function just towards the team city API
so specific things here that are not
important from troubles with the team CD
API we have to handle a bit it's not
really important is probably a nicer way
to solve it but basically what we do is
call the team CD API and we ask for one
build and we want everything that's
happened since another build and we are
interested in things like the number of
version the status of the build but
especially this is what we're here for
changes and we want the we want the ID
in the comment we only care about the
comment because remember from before
that's what we're going to parse so we
parse in we get the changes and we get
them type safe with the type provider
not too much code it's more like just
handling the data and we end up with
sorry and we end up with the built in a
what you see here that we have a
sequence sequence in F sharp is similar
in innumerable of build because what we
do inside here is that in the end we
actually mapped them to our own type of
B
we don't we want to just put them in a
type for easier to easier work with them
later then we have the builds and then
we can just start here some hard coding
by the way but we have this info here in
the in the config so this should
probably read from the config and not do
this horrible hard coded matching here
but basically we just go through all the
commitments just reg X them finally G
your keys and then the same thing again
I don't even have to go into this one
because you know what happens take some
input uses the type provider and a
sample from the JIRA API to get type
safe access to the GOI API and it gets
the things I am interested about in
these issues so we parse them and we do
this thing that we mentioned earlier we
parse parse the the merge commits from
there because we pull the changes from
teamcity and that's all the changes so
we want to find what are the merge
commits because we want to show the
merge commits in the bottom of our
change log for our for developers we
check if there is the hashtag DB
migration even if you don't know if
Sharman this looks like a lot it's just
it's super simple what we're doing here
just doing some reg X testing to filter
on that and we're just checking if
something has this DB migration tag and
then we have everything we need we can
create our change log type and that's
what we will return from this module we
get that project name we get an
environment that this change log is from
which includes name in the version we
have to send their name and version we
have all the commits in between these
two versions or order all the merge
commits we have all the JIRA issues
mentioned by our developers in the PR
title which becomes the merge commit
and we have info if there is a migration
or not so that's basically the library
that lets us get create the changelog
and now it doesn't matter where I host
this like this is this was a module or a
project that solves a specific problem
and I made it this way so now if I want
to test it I want to run it up I can use
swab or anything else I don't have to
use actual functions so basically just
put in the parameters here hard-coded I
map up some few endpoints just a test
and I added like a just a small module
to take the Jason and turn it into
something that is readable so now if I
build it well hopefully be able to find
actually do don't build in parallel here
so it's my fault that it's not it's
taking some time now we built swab and I
just want to run it up here to mono and
I see it's running on 8080 so if I now
go to 8080 basically all you should do
is get changes as marked down it calls
my library that we looked at before and
it takes this change log type and turns
it into something that's readable to me
basically turns it into markdown because
that's easier for me to write and then
just uses a library that takes markdown
and makes it into HTML if I now go to
localhost 8080 now
betting everything on yeah there we go
now I change I checked actually between
the Devon environment and production so
as you can see there is a lot of stuff
here but the cool thing is that we have
now linked straight into yireh
where we can check out these tasks that
was very poorly formatted and we can see
what kind of is it a task is it a bug
what this starters status in our camera
mode is it under peer review is it done
what is the person story and we see all
the merge commits and this package
changes the SQL schema and possibly data
the reason why we're wondering if there
is a DB migration is because we do
rolling deploys and if someone does a
breaking change we don't want people to
do breaking changes in the database over
just two versions if somebody does we
during our rolling deploy we will have
two versions in production until the new
version is all the way have replaced the
old one and it's we have two versions
that don't work against the same
database then one of the versions will
crash so when we do a break and change
in the database we want to do it over
three versions so first we make a
version that implements the change but
in a way that also works with the old
version and then when we cut that
version out and the old one is gone then
we can make a new version that actually
maybe deletes the or does the breaking
change towards that version before so
you need to have kind of a middle
version to take stuff which you don't
need if you have like a more appropriate
data store or blue-green deploys or
something like that so now we have
something that they can use and they can
test with to see if the change is going
to production work we have it running
here it is from between QA and
production right now for one of our
systems piling up because everyone is at
NBC
and we put this like as a minimum viable
version of it we just put it in actual
functions as one function which means
like this they think what we do is that
this is a function that takes our HTTP
request and returns a HTTP response
can't get more easy than not and this is
a one of two files you need to do that
here you basically we just in an ugly
way parse out from the HTTP URL get
parameters what these parameters we need
are and we have one next time that says
like okay I can give it to you in JSON
or I can do this ugly thing we have here
like if you pass false to the j-jason
parameter it gives you a markdown this
was like the first thing we just write
down to get it out and it worked so this
is now hosted in and I should function
up this is a function app UI it's a bit
different than some of the other UI is
one on Asscher but if you go to platform
services you'll see what I mentioned
before that actual functions has the
same a lot of the same stuff that absurd
is has because it's built on top of us
AB service so here's our function and I
can't see my function here all I see
here is the function that JSON file like
you put next to your function it tells
something about what I should function
should expect in and out of your
function so here you can see what
triggers the function yeah is a HTTP and
it only works with get and it responds
with HTTP but what you should notice
here is that the reason I can't see the
code is because before we deployed it
we've compiled it to get compiler
feedback
so basically we're saying we have a DLL
which has a namespace with this run
function I showed you just up and run
done
I can't do too much here and you see
here says your app is currently in
read-only mode because you have source
control integration enable so it's a lot
of power in this this tool they have
here you can create new functions and
work with them but they are it's we
notice quickly that we don't like
working with Asha functions in the UI
here we want to do compiled functions
and that we know will work when we put
them up here because if I put a script
file up here it might run fine I change
one line and suddenly it gives me a lot
of errors like but I can't even fathom
what they are about
so that's my kind of my problem without
your functions right now is that they're
moving very fast to implement everything
they need to implement and I feel it's
not really their instability I'm hoping
to catch some tricks tomorrow in Matias
talks we're talking about f-sharp
functions - and how to scale it but
basically what our conclusion is that we
need we only wanted to put compiled
version on all the functions on partial
functions because if you don't if you
put a script file like CSX or SS X file
it will compile it on in your app and
might get errors that are completely
different from when you do it in the on
your build server so basically of what
is in this function all we have here is
just a function but Jason we have our
change of provider which is the library
that we looked at before and we have the
actual functions function itself as a
dll that we are bootstrapping in here we
have some dependencies that we just
included here but another thing with
Asha functions is that it it includes a
lot of dependencies for you
automatically
so like Newton's object up Jason is just
there f-sharp is just there of coure and
a lot of other things are just magically
there so when
you try to work with it on your local
machine it's pain because suddenly you'd
pull a sample and you put it into your
editor and you want to work with it and
it's just red squiggly lines everywhere
because there are some dependencies that
are just there magically oh god I hate
done but it's easy to get started and
like many things I feel Microsoft doing
though always easy to get started going
further on it's usually a bit more
difficult another way of looking at this
application would be something like this
now we're looking at three functions and
a lot more complicated architecture to
solve a simple problem if you'd said if
you'd say now we're suddenly in a
resource group where we have some
storage you need storage for a function
of any way or we're using it in our
functions we have a cosmos BB which is
where we basically just use the document
ID to save the Jason and I also tested
in it works using service bus but in
this solution we basically use the queue
of the cause storage accounts can upload
files tables and queues I would never
use these queues with if I have high
latency and now sorry if I have a high
true put system that I'm trying to make
server list I would never use these
queues I would use a short service bus
so what we got here is basically
actually we can look at it in the editor
it's easier we have one function that
basically does nothing other than taking
an HTTP trigger on an HTTP request and
put something on the queue and then
return the reason for this is that we're
contacting three different systems so I
don't want people or systems calling for
it for change luggage generation to have
to wait
to contact three systems and generated
changelog I just wanted to come out in
the other end somehow so this one just
puts it on cue and return to this you're
good so basically as you see here we
just check the variables and we pass on
them on to a queue and we have another
function which we call the generator
function which basically triggers on
something coming on to that queue and
outputs into document DB because we want
to store the changelog for historical
reasons but it also has another output
which puts it in another queue called
send mail and we have a third function
that listens as a queue trigger in so
triggers when something comes on this
send mail queue and it reads in from
document DB which is included in the
message which document is ID we should
pull out and it uses the SendGrid the
integration that Microsoft has same grid
is a software to service email list for
email sending so we can use the output
here to send the email and then
basically we create this same markdown
each HTML that we made before but it
goes through this whole super
over-engineered solution to send out an
email to a email group that cares about
these things in the other event this is
like a way to do that here you see I'm
using scripts and everything and but you
can see here to get things to work on my
machine I have to download the actual
function tools from NPM
I have to start pooling DLL thing to
make sure that I I have all the all the
dependency needed and I think I saw a
blog post for Matias oh I think he's
addressing this a bit and on how to work
with it tomorrow
so that's does another solution which
feel which feels a bit more more server
less but at the still at the same time
since I'm working on OSX I don't have
compiled function so it's this is hard
to
to work with as you see here is like
something I don't have this Vienna DLL I
haven't included that has this which
magically is there on actual functions
so if you're going to work without your
functions right now
and do something complicated I would
probably use Windows Visual Studio and
actually functions one time and it hurts
to say that so I hope they really work
on these these things yes
so that was like I was like basically my
conclusion so I'm pretty sure nobody's
going to run out of this room now super
eager to start using actual functions in
production but I think you maybe saw
some some cool use cases for it and to
start using it like we've done in our
project we like the small things and
then you can build upon that it's the
second architecture that you saw where
we put it in the document DB then you
can build on that and like make pipe
lines that diverge and solves different
problems but it's the more of a scalable
architecture or expandable architecture
so it feels a bit wobbly to work with
for me there's not a Windows in the
visual studio I hope you are feeling
that F sharp is the thing you're going
to look at next time you're going to
integrate with other systems or read
from any kind of data source because F
sharp I providers will save you a lot of
time doing that if you're a bit smart
about it you can easily do it from a
c-sharp solution like we are doing it's
worth it I also want to say that the F
sharp or the functional not F sharp I'm
sorry functional programming lab our
there's going to be Elvin people there
if you want to look into Elm and
probably elixir people because it was
just the elixir talk and and it's out
above the entrance and all the speakers
are going to be there to answer your
question if any of you have any
questions to what we looked at in this
session just come there talk to me if
any for those of you who are from also
make sure to follow any mu D the dotnet
user group and also which also has the
also F short Meetup and thank you that's
it
you</div></div><div class="container-fluid bottom-ad"><div id="amzn-assoc-ad-6a809dda-347a-4187-8a86-91faf94575da"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&amp;adInstanceId=6a809dda-347a-4187-8a86-91faf94575da"></script></div><div class="text-center">We are a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for us to earn fees by linking to Amazon.com and affiliated sites.</div><script>(function(w, d){
    var b = d.getElementsByTagName('body')[0];
    var s = d.createElement("script"); s.async = true;
    var v = !("IntersectionObserver" in w) ? "8.6.0" : "10.4.2";
    s.src = "https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/" + v + "/lazyload.min.js";
    w.lazyLoadOptions = {};
    b.appendChild(s);
}(window, document));</script></body></html>